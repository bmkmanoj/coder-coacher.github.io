<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What's New in Scala 2.10 | Coder Coacher - Coaching Coders</title><meta content="What's New in Scala 2.10 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Oracle-Learning-Library/">Oracle Learning Library</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What's New in Scala 2.10</b></h2><h5 class="post__date">2013-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EULAeVejzZ8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome to my talk which is some
what's new in skala to point 10 I'm
going to talk a little bit about the
actual things that we go on going to put
into this next release which is going to
come out very soon but also some
somewhat about the philosophy behind
Scala where it came from where it's
going and how did this shape the next
release so who here has already written
Scala code ok so I'm don't need to give
you the background I guess so the
benefit of those who haven't just where
it came from so in the 90s I was heavily
involved in Java I wrote a language
called pizza which we named pizza
because if java is a hacker's drink than
we thought it should become complimented
by hackers food so that's why it's
called pizza it was essentially an
extended Java and that led to GJ + GJ
led to essentially the core of Java
generics and during that time I also
wrote the compiler for for Java Java Sea
which is the compiler today so the
Senecas java compiler of course has gone
as undergone heavy maintenance and
extension and so on but the chorus is
the Java Sea I wrote in 1999 over the
last 12 years or so I wanted to do
something a little bit more radical than
extending Java also i found out that
it's actually very hard to do because
Java is a big legacy it's a big language
it has lots of interactions which made
it make it very hard to add stuff
cleanly so instead of being a superset
of Java the scala experiment was to say
well can we do something which is
interoperable with java fully
interoperable but which gives you a nice
combination of functional and
object-oriented programming and let
started out as a essentially is a
research experiment can we do it and
then afterwards we wanted to find out
well is it useful do people use it and
they did and since then it has been
grown a lot in open source and industry
and so on so what's color is that's the
slide i have almost in every talk i
can't repeat it often enough
it's a unifier it's a unifier first
between this world of functional and
object-oriented programming and with
unify I don't mean well it's two
languages in one it has an optional
object-oriented subset in the functional
subset but really that it tries to take
something and see it from both an
object-oriented and a functional side
for instance functions in Scala they
actually objects so objects equals
functions modules from the functional
side equals objects and so on and what
that actually gave us sort of by
accident was a language that's very
scalable in the vertical axis so it's
used in a lot of applications
mission-critical applications in large
enterprises and are highly trafficked
websites but it's also actually a pretty
good scripting language so if you want
to give a shout-out slats kada you can
go to the script bowl which is a
competition of scripting languages where
we have competed every year over the
last year's and actually last year we
tied so tied for first place so maybe
this year we gonna win oh we won already
oh sorry I was afraid huh that's great I
thought it was going sorry I cut my
temper no I didn't get the news that's
very welcome excellent so so this
functional aspect that's really
something that I was very fascinated to
see how functional programming seems to
be on the rise I'm as I said I come from
from University so I go to scientific
conferences and also to Java one and
then developer conferences but that's
more lately so in scientific conferences
there's essentially there were two main
object and conferences one was called a
coupe european conference and object and
programming and the other is oopsla and
12 years ago eco pet about three times
the attendees of ICF p which is the main
conference on functional programming and
equip at about ten times the attendees
of ICF p now I cfp has about three times
the attendees of eco and oops I stopped
existing is an independent conference
it's now one of the tracks
of the splash conference so it's hard to
tell what it is but you see a clear
trend curve in two different directions
and the other really amazing data point
is that over 46,000 as of last count
have signed up for the co 0 course on
principles of functional programming in
Scala that I'm giving so 46,000 and it's
going to be it is a really hardcore
functional programming course so we're
not going to dilute the industry
adoption also is is very very wide sweat
and and until very recently the opinion
widespread opinion was that scada is
cool for essentially hot web startups
with smart programmers and it's true
that a lot of them are using scala very
heavily for sometimes most of the things
they do but it's also true that lately a
lot of enterprises are using scala for
with large groups for very important
applications so this is just a some some
summary of some of the companies that do
with it have no problem with being shown
publicly so you could ask why now why is
functional programming suddenly so
important and I believe it's really
largely driven by hardware trends so I
think that's the immediate need why the
industry is moving to function
programming so here you see a chart on
clock speeds and we all know that they
have pretty much flattened out they're
not getting faster anymore that's a
transistor count that's still growing
exponentially for a number of years
eventually that will probably level off
as well and right now he is he here you
see number of course per per chip and
that's also growing here quite quite
significantly and here we're just
talking about multi-core but you have to
add other forms of parallelism such as
GPUs so for instance that's an nvidia
farm I and latest generation GPU if you
want to keep that fully loaded you need
24,000 fully loaded threads running
parallel so it's 24,000 so you can
imagine well but that's that's quite a
challenge from there from the way
from this from the software that we are
currently writing now okay so in that
new world we have a triple challenge
which comes from parallel processing so
how do I make best use of all these
processing elements whether they are 90
cores or GPUs or clusters or data
centers and the second challenge is
asynchronous computing because that's
really forced on us with in particular
with essentially web services that we
every computation is nowadays
essentially an event processor that
takes events and has to deal with them
asynchronously and finally distributed
which has essentially all of the above
plus the added dimension that things
might fail nodes can go down and
messages might be delayed indefinitely
and it turns out that in this world that
every piece of mutable state that you
have is a liability you have problems
such as ensuring coherence of caching
whether these are Hardware caches where
the hardware does it for us at a great
expense in transistors in x or in
software we also catch all the time
things we are we have some piece of data
here we computed we cash it well if then
the the underlying reality changes under
us then we have to invalidate those
caches and very hard to find out when
when to do that at reasonable cost we
have data races that we have different
computations that might give different
results we have versioning problems and
so on so the problem if you look at it
in a nutshell and I would say it's this
one the problem is that computations
that have are built from concurrent
threads that access mutable state shared
mutable state are inherently
non-deterministic so here you have a
simple example where we have a shared
variable X and we have to asynchronous
computations which can run at any time
one adds one to the variable the other
multiplies it by two and depending on
how you run these things that can give
zero one or two in the end and even if
you say this async block is something
that is atomic so think of
synchronized then you can still get zero
or why sorry one or two depending on
what order these two blocks are run
because that order is again not
deterministic so non determinism then is
caused by parallel processing and
mutable state and non determinism and
determinism is something that we are
deeply uncomfortable with because it
means that most of my testing and
debugging methodologies won't work
anymore debugging means well I hugging
the assumption a debugging is that I can
replay things like they were when the
fault came if I put if I afterwards I
see the things in a debugger and they
won't happen anymore because the timing
structure is different than what do I do
we also of course assume that we can
reproduce faults at our client on our
machine so again if it's done
deterministic that's by no means assured
so it's we i think we are really not
really we are we're really quite
dependent on this idea of
reproducibility and replayability and
for that reason non determinism is
something that's deeply problematic so
parallel processing that's something we
can't avoid any more hardware trends
software trends with data centers and so
on is something that we say that's
inevitable the only thing in the this
equation that we can change is the
mutable state so we can try to reduce
that ideally may be eliminated totally
and if you have parallel processing
without mutable state then we can get
back the deterministic computation and
programming without mutable state means
programming functionally so that is
really the real reason why i believe
functional programming has this sort of
blossoming that even though it existed
in in research and academia for our 1960
50 years it never really was was was
very very interesting for industry
except for a short blossoming in the 80s
where it was very much tied to a I and
the Japanese fifth generation problem at
the time it died off again because of
hardware trends
as functional programming was
essentially inherently tied to San see
exotic machines and it turned out that
at the time every new generation of
impeller MIPS or spark micro processors
was faster than the fastest our machine
people could build so it was pointless
at the time and people would just go
with normal processes and normal
processes would work very well with
standard imperative programming but it's
the same Hardware transit now I think
favor functional because they
essentially in involve parallelism so
another way to look at this is if you
have program functionally and since most
of you say that you have already written
Scala code yeah I guess that's true then
you know that writing programs
functional programs feels completely
different from writing imperative
programs writing imperative programs is
very much a matter of thinking of things
in terms of time I have to set this
variable then I can use it I have to
grab this lock then I can enter the
critical region and so on whereas in
functional programming that doesn't
enter the picture in fact there's a deep
theorem which is called the church raza
theorem of lambda calculus which says
the order of execution in a purely
functional program does not matter you
can execute it in any way you want to
including parallel the result will
always be the same and that means that
the thought process of functional
programming is really quite different
you think more in terms of what do I
need to build this thing I built this
thing out of these other things and then
I have that assembly and then I use that
to build that other thing over there and
that formed lack of a better word is
really like thinking in terms of space I
built things spatially one out of the
other and if we add parallelism to that
then thinking in terms of space is very
compatible with that because it just
means that different things of my
spatial structure get executed get built
by different threads and since I think
in terms of space it doesn't really
matter when they are built it they can
be built in parallel
but when I think in terms of time then I
have a problem like this one that I have
all these different times threads and if
they intersect on some piece of mutable
state and have a problem I have a data
race I have to put in a lock to avoid
this so I have to put all sorts of
preventive measures to keep these things
tidy and not really conflicting and we
are really bad at coming up with these
preventive measures because that's not
how we like to think I believe we like
to think in terms of what's our
objective whether when I go what do I
need to do to do that rather than that
mode here which says well think of all
the possible bad things that could
happen all the data races put in a lock
to prevent each of them but don't play
to put in too many because if you do
then you might get a deadlock or you
might get bad performance because you
forgot your parallel ism so it's sort of
this type trope where you say okay I
want to put in the minimal amount of
synchronization because synchronization
is expensive and at the same time see
avoid all possible things that can
happen badly and that's something that's
very very difficult it's not we're not
really adapted to that mode of thinking
at all okay you could say so that was
the case for functional programming
should we all program in haskell now
well maybe but my opinion is actually
not so it's up to you my opinion is that
actually object-oriented programming is
really valuable what we've learned over
the last 40 30 years in object-oriented
programming is very very important and
the in particular what concerns
object-oriented analysis and design
because the importance here is that it
answers the central question which is
what do you put we're in a large system
you can't really have this assumption of
a global namespace anymore just dump all
your methods in your in the global scope
and you will deal with it we know that
what that won't scale that won't work
for systems that go beyond a competent
couple of tens of thousands of lines
maybe once we go beyond that it's
hopeless so we have to answer this
question how do we structure our program
and object-oriented programming has very
good answers for that so in the end we
need to put things somewhere
oo can do that good so I said we want to
have functions and object and
programming that's something an object
Mary programming have to change yes I
think we have to give it a little bit of
different twists so previously there's
one characterization which is very well
known known by Grady Booch who said that
objects are characterized by state
identity and behavior and I think he got
it wrong in two out of three counts so
so if you look at that state and by
state I believe everybody means mutable
state we don't we just that we want to
eliminate that or at least reduce it so
that we would mean that a lot of the
objects we construct should not have
mutable state and of course we know
objects like that already from Java jive
strings in Java java.lang.string is a
class that does not have mutable state
it's all immutable and we want more of
that we want many more of that so we do
we want to get away from the case where
the default is immutable state I thought
that was something that everybody
accepted that was uncontroversial that I
was actually recently the conference
with language designers and I think it
was both good or funny or an awesome and
better my added designers of eiffel and
python who disagree to said no no no
objects need mutable state otherwise
they're not objects you have to call it
something says something else so just to
tell you there is disagreement on this
thing but I believe really we have to
get away from the mutable state the
other one is identity and with identity
its what one what one generally means is
reference equality so essentially two
objects are the same if they're the same
address and I believe that's another
notion that we want to get away from
where we want to have structural
equality or user defined equality but
not this sort of reference equality and
finally behavior yes absolutely object
object encapsulate behavior okay so the
other often quoted phrase and
interesting phrase is think there was
martin sarah who said tell don't ask so
that's a good idiom for object-oriented
programming
Cal don't ask well that's problematic
for functional objects because if you
tell an object something then it has to
do something and in the end that would
mean it has to change its state in some
way right if you just tell and don't
want to get a result back then either
it's a no op or the object changes this
state you can't do anything else so that
also we can't do that so I believe what
the advice is really fundamentally do is
because of this fun Newman a bottleneck
which says well we have this tendency to
come you communicate with small
immutable values it's even embodied in
in Java I would say to say well I can
return only a single thing I can't
return more than one thing so we have
this very simple what we return and i
think the functional way is to say well
let's just ignore all that and you know
return very very rich things whole
object graphs it doesn't matter because
we wouldn't have a problem with
ownership or copying or any of these
things so that's why i think that that
that Dogma here is doesn't really apply
once you buy into the other ideas of
functional programming okay so i told
you that hardware trends we're really
the reason to adopt function programming
and i think that's true that sort of the
trigger but once you do the jump you
really realize that there's much more to
it that object oriented protocol
programming is also shines in terms of
its simplicity its productivity and just
the pure fun of doing things so I
believe these are sort of in the end
more important for me than to just say
we have something that runs well on
power processes but it's always that if
you have an industry shift then these
are sort of soft factors that don't
really count so much because you can't
measure them very well so often you have
the first factor which is a hard factor
which says well we must do this because
otherwise we can't solve our problem and
then afterwards you say okay this is
great what what we did object oriented
programming was actually very similar
when it came out in the in the 80s
they're the big problem was to design
gooeys so graphical so before you know
you had all these character inted
screens and then you had the bitmap
screen so you could do a lot of user
interface rich user interfaces and it
turned out that the previous mode of
structured programming didn't work very
well for these things you needed objects
you needed the dynamic binding and so on
so that was the thing that really drove
the industry to say adopt
object-oriented languages and then
afterwards the other the secondary
concerns were saying oh well that's
actually great for reusing great for
modeling they also came in but I what
really happened at the time it was
gooeys without gooeys maybe we wouldn't
we would never have have taken off even
though in retrospect that seems crazy
but I think really it is you need sort
of a forcing factor okay so one thing I
said here simplicity of functional
programming and there you might wonder
because it's God I got quite a
controversial and the press and quite a
lot of bad press to say it's so
complicated so terribly complicated so
how can I mention scalo it's the same
name and simplicity well actually turns
out that scala can be as simple as or as
complex as you like like most
programming languages but I firmly
believe Scala is best when it's simple
and it can be really really very very
simple much simpler than than than Java
so one example here is the kojo
environment which is a wonderful
learning environment for kids there was
a it was lolly punt who did that it's
used in a school in India with I think
three hundreds of girls aged 12 to 13
that's how they learn the the first
steps in computing and mathematics so
not the first place types in mathematics
but more mid so essentially it's a
environment for computing mathematics
it's all written in Scala it uses Scala
as essentially also the extension
language for writing these things or
there's sad I alidad if you look him up
on the Internet here's a series of
absolutely great talks where he takes
you through a set of problems Euler
problems Game of Life games and so on
and he's very extremely refreshing
oh it does that it does it all in
Scotland is very beautiful scada it's
very easy to understand and you use you
see that here's fun so what I wanted to
do is I can't be sad I and not nearly as
as funny as he is but i still can try to
get gay to go give you a little bit of a
spin to show you what the feeling is of
this thing so let me just open here the
right package okay so what I'm going to
do is I'm going to use something very
new which is called a worksheet which
will be released in the next version of
the Eclipse IDE that we work on so let's
call this problems okay so we have a
problem oops i just see that's not a
good screen resolution let's change that
another must have jumped back
no that wasn't it sorry oh it's it's all
sorry yeah yeah okay yeah okay thanks
apply pepper yeah okay there we go so so
we see you have this worksheet and what
we can do is we can write stuff and have
it evaluate the thing so here we on the
right hand side it would always show you
what we evaluate it we can also name
things and so it's sort of like a rapper
but in the IDE and you see both the
important the output on the same screen
on the same sheet so what I want to do
is there's a nice site called 99 scallop
problems so I've taken it from there so
the first problem we're going to look
out is to say well find out whether list
is a palindrome I don't draw me
something yet it's the same no matter
how you read it from the front to the
back code from the back to the front so
how would you do that that's an easy one
what the can't write a function is
paddling drum and that should be a
generic function so it can work off over
all sorts of lists and it gives you back
what should we give you back but we
still have to implement it so I would
propose x s equals x s not reverse and
there we go so then we can write is
palin is palindrome of excess i will
tell us false let's type to another one
is piling drone off let's take a string
this self something like that so that
should be a palindrome oops we could
have error so what does the earth says
oh yeah it we have a string and it wants
a list so our type here was too too
narrow so let's change that and just say
okay we want to apply that to arbitrary
sequences and then it would give us true
so you see you have this nice way of
thinking where you see of all the time
immediately what you're doing here let's
take this a little bit further so I want
to do another problem that's this one
here where we say essentially what what
I want to achieve at the end is I want
to get a run light run-length encoding
of a list so if you have repeated
elements like here and what I want to
say is well the list consists of 4 a's
and 1b and 2 c's and and so on you know
what you see what I want to do there and
the first sub problem to get there is a
method to pack consecutive duplicates of
list elements into sub lists so you see
an example here with 4 a's and Abby so
we want to have 2 4 a's in the list by
itself and then they'd be in a list by
itself and so so how would we do that
well maybe let's do test-driven design
in this to a test case first so let's
say the data would be ie a b c see d be
ii a a a something like that to list ok
so now ever listed on which we can test
that so what we want to say let's call
this chunks so that would be the chunks
of the list of all the same elements so
that takes again it's a it's generic it
takes a list of key and it gives us back
what does it give a bag back a list of
lists of tea and what is it well I don't
know what it is yet we'll get we'll get
to that immediately what you can do is
we can write already chunks of data so
that's our test case so that should give
us what we want right now what we get is
you get a not implement it error because
it turns out that that's one of the cute
new things into 10 so we have the triple
? yay i'm now
I'm normally very hesitant to put in
symbolic operators but this one is
really worth it three three times so so
what that is is here you see it so it's
type is nothing and it throws a new
error everytime you selected this throws
a new not implemented error it's defined
in class pre-death which is the class
that's automatically imported into every
scholar program alright so we better do
something about that so let's do an
implementation well one standard way if
you don't if the problem is not solved
immediately is we pattern match on the
list and say ok what if the list is
empty what do we return well there are
no chance to return we return the empty
list and otherwise if it's a list that
consists of a head why and some elements
why yes what do we do well then we need
to split the list in to the first one
would be all the elements that are the
same as Y and the rest is the rest of
the list there's a function for that in
the collection library not exactly sure
what it is but we can try it out i think
it's called span so let's try this out
here span and then what should my
function b equals equals a so also it
doesn't compile of course so let's just
put another strategic triple ? and that
lets me a look at span yes band seems to
do the right thing it gives me a list of
fours forays and the rest of the list ok
cool so let's delete the span here it
was just so essentially a quick SI quick
trial on the side so what I want to say
is well the first chunk and the rest
should then be the list XS span and
what's my element what's my test well it
should be is the element the same as the
element Y that i have here because i
want to collect all the wise in here and
once i have that i know method my first
result is first
the first sub list and the rest of the
result is what while its chunks I have
to do recursively for the rest chunks of
rest I think that should be it and if
you have that then everything becomes
much nicer instead of the not
implemented error I have what I need
here cool so it's the one more step that
was this runtime encoding let's see what
we do there so what I want to want to
right now is a function sorry Deathwing
code and it has a similar signatures
chunks but it would return a list of a
pair of tea and an int right so we want
to have the element and then the number
of times its appears okay and how would
we write that well let's start with
chunks let's do chunks of excess and so
on once we have done that then we had
need to pass processes because yeah oh
yeah sure yeah yeah yeah egg do some
okay better okay so you have chunks of
excess and now we have need to pass
process it so we post post process each
element so that's a map and that would
take one of these chunks and what should
it return what I would should return the
first element of the chunk they're all
the same but let's just pick one and the
length and so we have the encode
function and finally we can test it with
encode data and there we go oops we get
the the encoded list that we want it so
what you see is it's a very nice way to
interact with a computer because it's so
immediate essentially there's no way to
there's no need to set up a file here
then go compile it there start a build
tool
run your tests collect the test output
it's all in the same sheet it's really
like a spreadsheet or like a math like a
mathematica sheet yeah yeah that's a
good point i guess it would it would
help you in the sense that if you look
at the documentation and you see well
that might be the function you can try
it out immediately and see whether it
actually does what you think it does
after the documentation but for actually
first getting it you have to look at the
documentation I agree yeah so it doesn't
solve our problems yeah yeah that's a
good point so right now the worksheet is
stateless it means every time I press
save it gets recomputed from the
beginning not good if I want to sort of
set up my database and keep the
connection open because it would we are
but it's the beginning this is sort of
really beta and it's the first version
that's coming out we have ideas how to
make it state full so the idea roughly
would be to say we we have this
worksheet object and what you can do
then is you can have you can follow it
with other objects object my state or
something like that and those objects
would not be re executed every time we
you save the worksheet so that means you
could use that object down here to
essentially set up your state and refer
to it from your worksheet but these are
sort of yeah refinements we're getting
there I think the here the importance
was really the the immediacy of the of
the user interface and what I believe
that to make it work you really need
code that is essentially no boilerplate
very concise
direct to the point if your simple
method would take already 10 lines or
something like that each time then it
wouldn't be a good usage of screen
estate so it really works only with
essentially the functional mode of
writing code that says well just
function equals expression here's the
result no complicated flow no returns no
semicolons no nothing so I think that's
actually very important for the user
experience here ok good so after the
speak little parenthesis let's go and
look at Scott a two point 10 so we're
very close to rc1 its latest count I
think we have seven remaining blockers
too soon uh of uh no not exactly sure 33
blockers that involve touching the code
base the rest is documentation and
hopefully we will be able to stage that
for a first preview with essentially
decoys other cuz its color core packages
in a week or so and maybe have have it
for public release in then in two weeks
the currently under code freeze work on
the remaining blockers most of them are
ducks this new features in scalar to 10
it's for the first time all discussed
and vetted in the so called sip process
so sip stands for scada improvement
process so i can show you an overview of
what what that is so essentially these
were all the proposals and i'm going to
talk about quite a few of them the ones
i'm not going to talk about is the
futures and promises even though that's
huge so futures and promises is
essentially the new foundation of
concurrency that is used in acha is used
in Twitter's libraries it is used in the
play framework and is essentially the
fabric that makes all sorts of
concurrency work it's not tied to
actress it's more more general than than
what actors are acha of course then
builds its actors on top of that there's
another talk by victor clang on that on
acha and he will also talk about about
futures
okay i'm going to talk about some of the
others so let's start with something
very simple string interpolation so we
all know that assembling strings with
plus is not super convenient so you have
to write things like books written by
and then we have the author in year in
and at least I always get the space is
wrong I always have to go through
several cycles there to debug that
because I always forget to put let's say
the space in here just right in and then
is it I don't have a space between the
author and D&amp;amp;D in work you enter so it
would be much nicer if you had string
interpolation so if you could write
books written by dollar author in dollar
year Colin books it's immediately
obvious how this this thing is going to
be formatted and it's it's shorter it's
safer so that would be nice there's only
a problem with that and that's that
dollar is already illegal character in
strings of course we can't just
reinterpret that because that means if
somebody won't meant the dollars to
appear in strings then that wouldn't
work anymore we would break existing
code so we can't do that so the proposal
was well let's make a special prefix s
in front of the string where we write s
books written by and then the
interpolated one so essentially if a if
the opening quote of a string has an S
in front of it then we interpolate
otherwise not okay so that was like a
reasonable but this is cara and you know
scala doesn't really work that way so
what's Cara doesn't really want to do is
introduce special tricks for one of
convenience things we always try to
generalize something that can be used
for many things at once and not just a
single convenience thing so how can that
be generalized so there the idea is to
say well instead of the S let's have
generalize that to an arbitrary
identifier that we can put in front off
with the quotes of a string and that
identifier then would determine how the
string is parsed so let's see how that
would work so if you write an arbitrary
identify here just for example i wrote
ID that would be
expand it into this thing here so
there's a new class called a spring
context and here i create a new one and
that class takes essentially all the
string parts of the interpolated strings
so it takes the books written by and be
in and then the colon and then the
period in here and then on that string
context I would call a method it so it
would be the method ID that i'm going to
call and that method gets as parameters
d interpolated arguments off a year and
books good so that's the mechanics how
it would work but that means that i can
add further for my interpreters to my
toolbox so here's another one that's the
formatted interpolated just within f and
it is different from the s interpolator
in that it doesn't just interpret
dollars but also percentage so if i
follow a interpolated constant with a
percentage then that's a format string
so that thing here would print margin
with two digits in front of the debts
decimal point and one digit up after or
here's another one that might be useful
occasionally the raw interpolator that's
essentially just like s and F but it
doesn't do any escape sequence
processing so in particular the
backslash here is a legal character
whereas in Java we have to duplicate
them every time which is quite a painful
let's a regular expressions if you want
to write a rec X because we have to
duplicate every backslash they're good
so these these two are actually given in
the standard library but it doesn't end
there actually people you could add your
own processors and they could do amazing
things so here's one we already thought
about the XML processor that says well
let's just put XML inside an XML string
and what that thing would do is it would
parse the string
would return an XML tree in our XML
library or another one we could either
then use the scholar standard XML or
empty XML or another XML library that
builds a tree from that you could say
well why do that it's kind of Hassocks
in the literal so why should we do that
well maybe at some point we actually
going to suggest you do that instead of
the XML literals that Scala has just
because it would make a language smaller
and it would no longer tie the compiler
to a particular XML library that's
that's that that remains to be seen but
I think in retrospect adding exam L was
probably a thing in Scala that didn't
pan out so well at the time it was
something very important because when we
came out with Scala there was no
parallel ism so we had to find a good
reason why people should program
functionally and because I mean early
2000s 2000 2001 that was a preposterous
proposition to program functionally that
was true completely in the face of
everyone that program so the observation
was that XML trees are actually a very
good example of data that doesn't can
cannot come with methods you can't put
methods into an XML note not specific
ones for the nodes because the data
format is standardized and given so to
process it you have to come from outside
and that's something that functional
languages do well so that's why I Scala
has a xml in there because XML was also
of course very hot and very important
then and we felt that functional
processing does a good job with XML
which it does but of course nowadays XML
is just one among a set of interchange
notations another one would be Jason and
it's fair to ask well why has gala XML
literals or not Jason literals and not
the next interchange format which no
doubt will also appear so with string
interpolation you can do it all in a
user definable way which is really cool
but that brings us to one problem and
saying well I've shown you the SF and
raw interpolators and there were all
methods in string context
so now I have this idea to write my xml
or json interpolator how does the method
get into string context because string
context is a library class you're not
supposed to change that so in scala we
had of course ways to do that we would
say well use an implicit conversion so
the way that would work is to say we
would have this class add jason and it
would take a string context and it would
build sorry it would take a string
context this parameter and it would have
a method named jason that takes the
arguments and build such a sentry and
then all we need is an implicit
conversion which says well if we have a
string context and we really want to
call this method on it which of course a
string context doesn't have there's an
implicit conversion that would map a
spring context to one of these eight
adjacent instances and that has the
method and then you're good so the
implicit conversion gets inserted
automatically by the compiler if you've
been in Venkat super mayans talked
yesterday then he showed you that as one
of the tricks that that you can do with
skaara okay but there's a problem with
that all that is a bit boilerplate e to
have some do something as
straightforward and say add a new method
to this class having to go through all
these steps feels a bit heavy weight so
repeatedly people have said well why
doesn't skala have extension methods
other cool languages have extension
methods why not Scala well the problem
with extension methods is that you can't
abstract over them so you could argue
that the one of the main purposes of a
method is to implement some part of an
interface methods don't exist alone
methods are essentially the
implementation bits that implement
contracts and contracts are interfaces
or traits in Scala and that you can't do
with an extension method an extension
method never can implement an interface
also you might have essentially more
complicated patterns where you define a
Adam extension method for all types that
already have another one again you can't
do that with extension methods because
it's always one or or one or nothing
whereas with implicit conversions what
we could do here is we could have a try
tried Jason provider which says well
that's everything that has adjacent
method so that's my contract so in Java
that would be an interface and then I
could have a class at the class adjacent
as before but now it extends Jason
provider and there you go so that's my
implementation now my extension method
can actually implement a new interface
the Jason provider interface so I can
come from outside string context and in
effect make it implement something that
is in an interface that it didn't know
about beforehand so that's cool and
that's very general but it's still
boilerplate key right so well that is
that that's definitely an objection so
what we did in Scala 210 is to say well
let's make it less boilerplate II and
the way to make it less broiler party is
actually pretty straightforward we just
say okay just go back of these two
things one of them is superfluous that
conversion here essentially just as well
it's a thing that takes the class
parameter and gives you back a class
object you can generate that so that
that thing here you shouldn't be need me
to write explicitly so what the way we
do that is simply that we allow you to
write implicit in front of a class and
what that means is that the class is a
class like you define normally but you
also get an implicit conversion method
from the class parameter into the class
that's all that it says and that then
starts to be rather nice so that now
you're actually you know syntactically
in a space where you say well now
there's nothing to complain anymore but
there's another problem with it and
that's the runtime overhead that you say
okay what you do here I'm
I can extension method I create a new
object of this class HSN every time I
want to call Jason and once I call Jason
the object goes away well it's true that
on on modern JVMs often this object
actually will be optimized away so if
the hotspot is warm and can inline that
then there's a thing called escape
analysis which will get rid of that but
their strings attached if the if the JIT
compiler has done it and if the thing
managed to be inlined so if not then
used to you will still get be the object
here ok so there's another sip and that
value classes that comes into play here
so previously all classes extended
object so that was here so that's this
car a class hierarchy we have a class
any and we have two subclasses any well
and any referent any refuse and alius of
object and any valid was the parent of
only nine types and there were all this
the Java primitive types + void so that
that's the that's the subtypes of any
well and every other class that you
define extends from any rest directly or
indirectly so the question is what would
happen if classes could extend anywhere
so what we do did is we let you do that
now so you can write here a class that
extends any well and those classes are
called value classes and the elements of
value classes are always unboxed so when
I right here like a a class meter so
that would be a class that expresses the
physical dimension of meter a unit of
measure of meter and we would have then
operations that are checked in the unit
of measure so to add two meters to each
other you get a meter to multiply a
meter with a factor which is a double
you get a meter but if you would
multiply two meters with each other then
you would get not a meter something else
maybe a surface if you have that and if
you add a meter and the foot then that
shouldn't be allowed right so that those
things are quite useful and again just
like with the implicit conversion here
is the reason people are hesitant to
write that is the
time overhead every time I create a
meteor object I have to create an object
here which is annoying so what value
classes do so essentially by the simple
fact that this class extends any well
what that does is it gives you a
expansion that is essentially the same
as extension methods so here's my class
after the compiler is done with it or in
the first phases is done with it and has
mannered it so all the methods that you
find here would no longer have their own
implementation bodies but would simply
forward to three methods in the
companion object of meters so these are
essentially static methods and the
methods here but would take not meters
and they wouldn't return meters but they
would take always the underlying type of
meter so all these methods are simple
methods on doubles and then if you have
a usage example so here's a user code
where we say let's take a meter and
multiply it by 2 what that would be
translated to is the meters would go
away at runtime and I would just return
a use double as the underlying types so
if I here i have the multiplication
operation on the meter class what that
would expand to is this extension
message star extension and a passive the
double and another doubles the two and
then that extension method woodridge us
two double-double multiplication as what
you've seen the only time that is not
the case is if i take a meter and I map
it into an any or a generic parameter
because at that time if we just pass the
double the knowledge that this would be
a meter would be lost so we have to give
you a meter we have to at that point so
I the latest possible instance we say
well before I forget a meter and here
you go so I quickly box myself before i
go into something that is generic and it
actually turns out that if we are use
primitive types in scala they are also
automatically boxed when we need to it's
exactly the same scheme so when we take
a
type and we pass it to something that is
on any or generic parameter boxing
happens and value classes are the same
ok so that was lots of use cases and one
of them is implicit conversions because
if you have this implicit class eight
Jason and now we write extends any well
then what we get in the end is we don't
only get the conciseness which is close
to the extension methods but we also get
the speak no more objects and the
objects are all static so we have
exactly the same thing ok you say but
hasn't venca told you that implicit
conversions are complicated and you
should be careful and he hasn't he was
right so shouldn't be she shouldn't be
be hesitant to essentially make this
into a general usage pattern well in
fact it turns out that the implicit
class ones they actually turned fairly
uncontroversial be it's the other ones
that sort of map from from to existing
types those conversions are more more
more difficult so but we did something
about that as well and that is
essentially to counter so this Galloway
really is to have a few constructs of
maximal generality so to talk about
implicit conversions implicit
conversions are more general than
implicit classes and those are more
general than extension methods java
escala always tries to get the most
general and orthogonal mechanism so it
got implicit conversions and they're
very powerful but they can be misused we
know that in particular when there are
too many of them so they're sort of like
chocolate one of one is one piece is
very tempting if you have too much of
them you get a stomachache so what we
did about that is invent a mechanism
that demands that some problematic
features are explicitly imported and the
motivation behind that is to say well if
you have a very powerful and orthogonal
language then that's in a sense also
complicated because you have so many
features that you can continue combined
in so many different ways and some of
them are maybe not for everyone
maybe only for very few people maybe and
to give you a better guidance they're in
for software engineering purposes we
don't want to get rid of the
orthogonality I think in the end that
would be a losing proposition you always
want to be essentially have something
that's very general and orthogonal but
what we can do is we can identify
certain problematic areas and make you
declare that you want those areas
explicitly so here's an his thing we did
there that's language imports so say you
have a simple object let's similar
JavaScript and you say well it isn't
JavaScript cool it can convert a string
into an integer automatically so I have
a string and even int well just pass the
string there you go and we can do that
in Scala right an implicit conversion
that converts strings to int good idea
well you might think so but others might
disagree right so what you do now with
that is you get a compiler if you
compile that now you get a message that
says there were one feature warnings
rerun with feature- feature for details
and if you do then you get a long error
message that tells you that implicit
conversion method should be enabled by
making the implicit value language
implicit conversion visible and it shows
you a point where you can look up that
value and the Scarlet doc will tell you
more about the discussion what's good
about implicit what's bad about implicit
and you can shut the compiler app that
due to that it won't give you the
warning anymore by having an import like
that one which says I want to import
language implicit conversions and that
means I know what I'm doing but if
you're working in a group then the other
people would also know what you're doing
because they could look at the import
statements and say ah yeah this guy used
implicit conversions and maybe that's
not a good idea and we applied that
eating our own dog food to the scalar
compiler itself and indeed I found quite
a lot of usages of very dubious uses of
implicit conversions that way just with
that feature I followed everything and
yes there was for instance one implicit
conversion that we decided was a bad
idea so initially it was a global
implicit conversion we removed
and then we found I think 10 copies of
the same conversion in different pieces
of the code because locally people
thought it was a good idea so let's just
reintroduce this conversion in my piece
of code that sort of the things for
general cleanup it would be really good
if you have the import warnings ok so
I'm almost done with her with time the
other big thing I believe that is at
least as important as the language
features are better tools so here the
highlights are a new incremental builder
with plugins for maven pants and soon
also cradle ide improvements scholar
worksheet you have seen so I don't need
to go into many words to explain it to
you so the future what i want for scala
and scott has a very wide tempt language
so there are many possible directions
that you can take it but where i want to
take it is i want to make color the
language of choice for smart kids that's
really that I think the ideal what the
language should be so bring out the
simplicity in skala focus on the
beautiful sight avoid of our
complications and one thing that
hopefully will help here is we're
actually running a developer contest
which starts monday this week and runs
until end of november and what we are
looking at is essentially small
self-contained beautiful applications
that we can show to other people that
bring out the beauty in scala so if you
know of something then we would love to
hear from you and their prices to to to
to to be one for the winning entries
thank
but it would be my definition of
simplicity that they're different
they're different ways to define simple
but that's not the one I would be after
my mice notion of simplicity is this not
simplicity it's I would I do not do not
want the language in which you can only
do simple things I want to have a
language that has simple means to do
interesting things macros so macros are
into 10 and experimental feature that
means we have them we are putting them
out for evaluation we want to see what's
the best version of macros we also want
to see what are people doing with it is
it worthwhile what they're doing it with
it or is it rather not with the the
effort of doing that I believe the
upside of macros if they work out like
we hope for would be again that they
would give you the power in the sense
that they could keep the core language
simpler there would be stuff that we
wouldn't have to do in the core language
anymore that we could just as well do
with a macro one example was the things
we do let's say with manifests and
implicit implicit type reification
that's something we could very well do
with micros if marcos were standard in
the language yeah
the annotate exactly the same
annotations as in as in as in in Java so
it you can use you can define Java
annotations we have you can define
scholar annotations and the compiler can
act on them with a compiler plugin or
the runtime connect on them no no the
debuggers work actually very well so the
it becomes simpler in the end it becomes
simpler when I say it's functional what
I've shown you here is purely functional
so there was no not a single very
variable of course Scala has them also
but I didn't show you that but in an
actual application in a large
application they will probably also
always be some imperative computation at
the outside but it probably there would
be more functional pieces to do sub
computations purely functional than in a
classical imperative program and that's
good for the debugger because when you
do that then you can just essentially
skip all that because you know it won't
have a side effect it won't have won't
affect affect anything it will just give
you the resultant there you go so I
think it's actually the load on the
debugger will be will be much lighter it
will be much easier to deal with things
that that will also change in the depth
that was the thing that I yeah that's
good point here where do we have it
skaara debugger so that that's one of
the things that will come in there in
the next version which will ship with to
tend and expression with eclipse so what
we had to do there so that's why the
debugger didn't work very well is that
the translation from Scala to Java has
to insert quite a lot of forwarding
methods and things like that
so for performance it's usually another
problem because these are the first to
be inlined but for the debugger it was
weird because essentially the different
forwarding methods they had the same
code points so you clicked on the thing
next next next and you essentially what
happened is the compiler you went
through 14 wedding methods after the
other but you before for your user
perspective you were at the same piece
of code and that that's gone so the
compiler now knows about what abouts a
forwarding method it won't show it to
you anymore the debugger will know that
yes that's an ID feature yeah yes yeah
yes yeah string interpolation yes no now
we won't do that no no no with the
interpolation you need to write in front
of the screen what you want what
interpolator you want yes
what
one word when was 18 I'll get it to ya
to it I think to it yet to it to try to
10 yeah so so I think the it's already
stabilized quite a bit so what you seem
here is sort of in the end there are
minor variations minor refinements on
something but nothing nothing too
drastic i think what string
interpolation value classes but it's in
tactically it's not it's not huge so
definitely as the codebase increases the
your your ability to do large jumps asst
is largely diminished and that's that's
forced on everyone including us so yeah
right right right we are actually having
seen quite a lot of teams like that and
i believe it's actually so what you need
is a clear understanding what kind of
code you will write as a group so you
shouldn't go out in all directions and
and once you have that what i heard is
that actually the the effort to learn
Scala is is actually what I heard time
and time again it's actually much less
than I anticipated so that's what almost
everybody everybody I I talked to has
been saying look we we get people and we
train we get people on the job and after
a couple weeks they're productive and it
doesn't really matter who that is
because if you stay with this simple and
and and beautiful subset and it's really
not not very dangerous it's really not
very difficult and the one thing you
could do is follow the because error
course that's sort of a introduction to
functional
ramming and it goes slow enough I hope
so we'll see how that goes yeah yeah
yeah yeah you mean helping with
completion and things like that I'll
document idea yes absolutely yeah and
vivi are we have we are relying a little
bit here on the community also to help
us with with documentation and end with
with with tips what to do with
suggestions what to do with concrete
things what to do I agree that there's
definitely things we can do to help help
new people with better documentation the
other the other thing we can do and we
will do is do some more with this
Caradoc because as oh so one thing I
saved a lot of the people who say we
come into scholar and now we've found
problems and it's not for me it's too
hard typically people who use scholar
doc as the primary means of information
so then they know nothing they're going
to the scholar dr. try to write it and
so skaara that's actually not the right
way so there are some concepts that we
should go get beforehand like read a
book do an online course these sort of
things if you just want to say hack
blindly away and look at the sky
reductant often you're confused and part
of that is the fault of the scholar doc
pages which part which have been
atrocious to say the truth I have
improved a lot 4 to 10 but I think
they're still there still work to do yes
available such as Ruby and Ruby well
compared they're all sign languages
skaara is statically typed which the
groovy so far wasn't and Ruby isn't I
heard there's a static type version of
groovy I haven't seen it yet so I don't
really know whether that would change
anything in terms of feature comparison
i would say skylights a far simpler
language then groovy in the sense that
it had that its feature of count is far
lower than groovy because groovy has all
of so roughly speaking I would say
currently skala is about as complicated
as Java 7 and will be less complicated
by the time Java it comes out whereas
groovy is all of Java plus quite a lot
of extra features so it's by necessity a
bigger language there the builder in the
Scala IDE is a user's I essentially a
part of SBT yeah not the naughty you can
you can there's a--there's a plug-in
called SBT eclipse that lets you do that
you can use a separate SBT process yeah
we we won't do it we don't really have
the capacity to do it we we all we can
do and that's already a quite a lot of
drain of resources is to say show the
welfare one existence proof that you can
build a great idea jetbrains has a
fairly credible job with IntelliJ they
have a completely different approach but
there are a lot of people are preferring
IntelliJ over Eclipse that's sort of a
very much a matter of taste you can't
convince 12 you give the other try and
then there are also alternatives such as
sublime text or emacs even and the day
also have finally rich skala modes now
there's a plugin called enzyme for emacs
that essentially gives you sort of
eclipse like experience for for for
emacs yes shared mutable state here
perfectly absolutely yeah I fully agree
it's a sharing not to necessarily the
mutability it just turns out that and in
fact skala makes it just as easy to
write mutable code as immutable coat
it's completely not prejudice so you
want immutable you right Val you want
mutable your you right where it's a
single letter difference it's just that
the point is i believe the default
should be immutable you make fewer
mistakes that way to say well if you
want to introduce a mutable variables
perfectly fine but you should you should
reach for it explicitly whereas in java
it's the other way around to make things
immutable you have to add a final so by
default you write always mutable mutable
and then you say well yeah i had a final
here because it should be immutable it
goes the other way around so scholar
sort of is it sits in terms of lengths
of notation it's exactly the same but
the recommended default is to do to go
immutable and unless you have a reason
yes
that's true yeah yeah well no no no no
it's a tradeoff i believe for i'm not
sure what so it depends what you whether
what is in your language how
straightforwardly that maps into
standard java bytecodes and essentially
scholar maps varies very
straightforwardly into java bytecodes
that's why it's a very close to java
performance sometimes better than java
perform and so it's sort of a wash up
yes it will be yes sooner or later we'll
be able to invoke used to invoke dynamic
probably only when Java 8 is out because
what I my impression is that evoke
dynamic is actually not very fast on
Java 7 so I think we want to give it one
more iteration for being optimized until
we use it so but I think on the Java 8
platform what we're going to do is we
are going to change the compilation
scheme so if you target is Java 8 then
we will use the same thing as what what
Java will will have namely method
handles and we both dynamic to use this
thing because it i guess the definite
once essentially on the JVM they got the
the problems out of invoke dynamic and
method handles is definitely the best
implementation scheme to use for the
sort of thing
so the no it isn't so the the scholar
numbering scheme is essentially if it's
a major new version and that's 2 so 2 is
essentially language version so it's
it's a it's a tubes version of scholar
which has been with us since 2005 so
it's very stable and then so it's all
sort of like Java one instead of Java 7
and Java 8 the other numbering scheme
scheme would still be it's 1.7 and 1.8
JDK and things like that so for we we
use that scheme so from nine to ten it
was a major version and four major
versions there are problems with Scala
that prevent us from being fully binary
compatible so we're not so you have to
recompile we make it much easier because
the the tools are are there now and we
will have community builds way
essentially all the standard scholar
libraries that you would look at that he
would would typically use would come out
of the box with 210 so what we want to
avoid is this problem that well there's
a new scholar version and but that
library here hasn't been upgraded yet so
I can't I can't move so we want to
essentially move everything at the same
time but the be the policy is if it's a
minor version so from 229 1229 to their
binary compatible now and we have a tool
that verifies that but a major version
we have to break binary compatibility
it's sort of i really believe java is
very special here enviably special
there's no other language that has a
similar binary compatibility record as
java for instance c-sharp also breaks
binary compatibilities between major
versions and in the Microsoft where
people are just used to that but in Java
it's this thing is sterling binary
compatibility back to Java 10 and the
reason why they can do it really is that
they have the JVM to play with so
without the JVM there would have been
several instances where they would have
to break binary compatibility but they
could make a special trick in the JVM to
paper over it so we can't repeat that
unfortunately yes
why is what important
well it's mostly when you have systems
with many dependencies that you want to
avoid the versioning problems so you
want to say what I can always use an old
binary library sometimes I don't have
the source what I want or I don't want
to recompile it depends on your business
so Google for instance as a policy where
everything is built from source all the
time so for them it wouldn't wouldn't be
an issue but there are many others that
that are different and I think the whole
maven culture is very much built around
binary compatibility so that's something
we have to recognize okay thanks all for
coming in</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>