<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 17 - Random Forests 2 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 17 - Random Forests 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 17 - Random Forests 2</b></h2><h5 class="post__date">2017-05-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-MmmomryKHs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in this video we're going to look at the
way each feature carries in deciding
whether a tumor sample is predicted to
be malignant or benign random forests
which is the subject of this tutorial or
collections of decision trees and
similar to decision trees they have the
parameter called feature importances to
help us get an understanding of feature
weights now I would think that the
future importances of random forests
provide a better and more balanced
overview of feature weights compared to
single decision trees but let's see so
let's first remember how feature
importances looked like for the single
decision tree we built back in video 14
of this tutorial
now in this case the feature worst
radius carried a significantly higher
weight compared to the rest of the
features which were 30 or so now let's
see how it looks like for the random
force classifier we built in the
previous video we'll basically do the
same thing and first we'll start
importing what we need to do the
plotting so we're going to import mat
plot lib by plot as PLT we're also going
to import numpy as and B and we're going
to do the magic man matplotlib and line
so that we have our plots within the
notebook displayed within the notebook
not in a separate window now let's run
this and do the rest of the plotting in
another cell
so instead of me just typing everything
out let me just copy paste this and do
the necessary adjustments so we'll have
to basically replace tree with forest
which is our forest that we built in the
previous video so one over here and I
think that's basically it now let's run
this and see how it works and now this
is a much different perspective we can
see that many more features have a
nonzero contribution that is they play a
heavier role in decision-making compared
to the single decision tree over here in
which worst radius had the highest
contribution this makes me think that
for our specific answer data set and so
I could learn if I were to choose
between single decision trees and random
forests I I would go for the ladder
because it appears to provide a more
informed choice now in the next video
we're going to go over the strong and
the weak points of random forests as
well as some of the parameters that we
can tune to optimize the classifier if
you liked the video please hit that
thumbs up and subscribe thank you for
watching and I'll see you in the next
one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>