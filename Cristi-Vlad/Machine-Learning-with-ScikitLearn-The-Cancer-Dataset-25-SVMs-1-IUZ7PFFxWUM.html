<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 25 - SVMs 1 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 25 - SVMs 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 25 - SVMs 1</b></h2><h5 class="post__date">2017-06-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IUZ7PFFxWUM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today we're going to start discussing
about and implementing support vector
machines in scikit-learn
we're working with the Wisconsin breast
cancer data set that comes pre-loaded
with Saiki learn so what are support
vector machines and how do they work as
machine learning models now we can use
as VMs for both classification and
regression and they can work on both
linear and nonlinear problems in our
case we'll use in SVC or support vector
classifier to classify tumors into
malignant or benign
now you may probably guess how it's
going to look like if I could learn
since this is very similar to what we've
been implementing with the rest of the
algorithms so far and scikit-learn
anyway let's first go through some
theory now you can recall from logistic
regression for example that the purpose
was to find the best separating line or
what we like to call a decision boundary
for the classes and with logistic
regression we did that by measuring or
by determining the distance to all
points now what SVM does differently is
to look for the largest margin or
distance between points on the sides of
the decision lines and these are the
support vectors now the classification
in this case may be more accurate
because you add another layer of
complexity or requirement from your
model for decision making now let me
just execute this cell
so in this very crude drawing which kind
of illustrates how good I am with arts
we see that d1 could be
decision boundary for our two classes
over here so this is one of the class
and this is the points or the features
that represent samples in the other
class but so d1 could be the one could
be a decision line but in this case d2
if we'll look if we look at it through
the spectrum of a support vector machine
d2 is the optimal choice since it
maximizes the distance between these
class points and like I said these are
our support vectors in essence the idea
is the decision line to stay as far as
possible from the closest or nearest
training instances now another thing in
this specific case and for this drawing
we have a linear representation of the
data or or we're dealing with a linear
problem here however as VMs are more
powerful than that they can also be used
to
fits nonlinear data or they can be
trained on on - non non linear data and
when we apply as VMs to nonlinear data
so different from this case we're
basically leveraging on a strategy which
I find very interesting and it's called
the kernel trick now even though the
kernel trick may not be relevant to our
linear classification I'm going to
devote the next videos to look at it
specifics in more depth we couldn't deal
with as VMs without talking about the
kernel trick anyhow this is kind of a
simplified introduction to SVM and I
hope you learned something from this
video if you think you did please give
me a thumbs up and subscribe thank you
for watching and I'll see you in the
next video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>