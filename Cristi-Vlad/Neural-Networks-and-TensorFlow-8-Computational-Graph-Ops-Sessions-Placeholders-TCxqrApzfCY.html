<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Neural Networks and TensorFlow - 8 - Computational Graph, Ops, Sessions, Placeholders | Coder Coacher - Coaching Coders</title><meta content="Neural Networks and TensorFlow - 8 - Computational Graph, Ops, Sessions, Placeholders - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Neural Networks and TensorFlow - 8 - Computational Graph, Ops, Sessions, Placeholders</b></h2><h5 class="post__date">2018-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TCxqrApzfCY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">before moving on with coding let's talk
a little bit about a few important
aspects of tensor flow so in earlier
videos we mentioned the computational
graph now what is this computational
graph well in mathematics the graphs are
made of interconnected nodes and they
are connected to each other through
edges now these edges allow the flow of
data from node to node as we've said in
tensor flow nodes are operations and
we've given a few examples here so
element wise operations operations on
arrays and matrices and so on and so
forth and edges represent the data or
control dependencies now one of the main
advantages of the computational graph is
that we can isolate dependencies between
nodes which will allow for better
allocation of resources across the graph
thus making the computation much more
efficient ok so far so good right so
when we work with tensor flow we usually
divide our process or our project in two
stages creating the graph and executing
the graph when we create or when we
construct the graph will be using
methods like TF constant EF variable TF
placeholder etc to define values and
methods like TF add TF matte mall TF and
and sigmoid and many more similar types
of operations a sidenote
a built-in tool to visualize the
computational graph and the learning
process is tensor board all right now
after we've created the graph we move on
to the second phase of a session so the
second phase of a tensor flow project so
that is executing the graph within
within a session like we've seen in a
previous tutorial so let's do it here
so with DF session as success so with
the F session and since will say cess
run our operations and after that we're
going to close this session so we
actually have to close the session after
running it this way so it is best to do
this because this way we free or we
release the resources we used for
running that session now it is important
to point out that when we define
variables and constants
we're basically sticking to using our
model once and only for a single scope
so reusability is pretty much lacking
that's why in terms of flow we can use
placeholders and these are components
that we can populate with different data
every time we execute the graph now
let's say for example we have X which is
going to be a TF placeholder TF float32
we're gonna give it a name X and a shape
of 4/9 so DF float 32 is the data type
we don't have to give it a name but it's
always better to do it for readability
and better understanding of the code in
plain language this actually means that
f that X can have any data you want as
long as it's of float 32 and as long as
it's of this shape okay so you need to
understand that first you create these
placeholders and then you will have to
populate them or to fill them in with
data when you're
running the session so in the second
stage or a second phase of the project
okay
now how do we use these placeholders
within the project let's say we want to
compute so let me just execute this one
let's say we want to compute y equals x
times W so y equals x times W plus me so
we want to determine the output based on
our inputs multiplied by weights to
which we add a bias term and we did this
in previous videos so we have our
placeholder X now let's create WM B so W
let's create them inside this cell as
well so W is gonna be ATF placeholder
place holder of the same data type and
we're gonna name it W and the shape is
gonna be so W and the shape is gonna be
9 1 and our bias so B is gonna be TfL
let's say for 1 minus 1 and we'll name
it bias so B is gonna be a constant
filled with values of minus 1 okay and
now our output so let's say Y is gonna
be a TF matrix multiplication between X
and W 2 which we're gonna add the bias
so we'll also define a variable as to
determine the maximum of our output and
we'll use the reduce max method which
reduces our 4 unit vector to a scalar so
we're going to use
d/f reduce max our output now let's run
this okay
let's actually create some data for X
and W and I'd like to give credit for
this example to Tom Hope whose book is
linked in the description so let's say X
data is gonna be numpy random R and n
for N and our W data is gonna be and P
random random 9 one let me make sure
I've imported number I hear ya now let's
create and run a session so let's say
with TF session as assess our out P is
gonna be SAS run s so we're gonna run
this operation and the feed dict it's
gonna be a dictionary X is gonna take
data from so our placeholder is gonna
take data from X data and our W
placeholder is gonna take data from w
data okay so this is where we're
actually feeling our placeholders with
data using feed dict
so as you can see it is a dictionary now
ultimately let's print the output so
let's say print output format out B okay
let's run this so I made a mistake here
okay so every time we run the data and
so as you can see we we've got a value
for our output but if I run this since
our data is gonna be always populated
with different values we're gonna have a
different output every time we run this
I know this may be a bit too abstract
but you need to understand these
concepts before we get into very
specific examples of tensorflow and in
deep learning such as when we get into
using it to recognize handwritten digits
alright so we discussed operations
sessions the computational graph and
placeholders I think we can now proceed
into more advanced concepts and examples
so we'll stop here with this video if
you enjoyed it and you want to see more
of them coming please hit the like
button and subscribe if you want to
support these educational videos you can
do that by following the patreon link in
the description thank you for watching
and I'll see you in the next one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>