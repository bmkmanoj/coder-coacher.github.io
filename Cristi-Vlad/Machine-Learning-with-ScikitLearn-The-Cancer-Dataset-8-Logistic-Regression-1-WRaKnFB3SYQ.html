<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 8 - Logistic Regression 1 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 8 - Logistic Regression 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 8 - Logistic Regression 1</b></h2><h5 class="post__date">2017-03-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WRaKnFB3SYQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to another tutorial on machine
learning with scikit-learn as a reminder
the data we're working on is the cancer
data set we're doing supervised learning
and to be more precise we're doing
classification by looking for a binary
answer is this image representative of a
malignant or benign tumor now you might
hate this but we need to go through a
little bit of theory so in supervised
learning there are two major types of
problems classification and regression
in classification will try to predict
from a list of predefined choices it can
be binary like in the cancer data set or
multi-class like for example separating
books into 10 categories so we're
dealing with categorical data on the
other hand in regression problems we're
dealing with continuous data such as
predicting someone's income based on
their age education and so on predicting
stock market prices and predicting any
kind of price and in similar problems so
far we've used the ke neighbors
classifier for our classification
problem there is also a cane neighbors
regressor and so I could learn which
deals with regression tasks but we won't
use it in our example maybe in another
series then there are linear models
which can be used for classification and
regression in short with linear models
the prediction is made according to a
linear function of the input features
there are many linear models and
scikit-learn but for now we're
specifically going to focus on logistic
regression which counter-intuitively is
a classification and not regression
algorithm despite its name another thing
to point out is that many of these
machine learning algorithms can be used
for both classification and regression
with scikit-learn
so let's apply logistic regression to
our cancer data set and see how it
performs compared to KN n which as you
might remember from our previous videos
got about 94% accuracy on the test set
you can watch the previous video for
that now I want to repeat myself by
saying that I get a lot of inspiration
from Andrea's Muller and Sarah guy does
this machine learning book which the
link is here and also went to in the
description now with that in mind let's
finally jump into the code so logistic
regression from SK learn data sets
import load breast cancer
okay so we're actually doing this from
the beginning to have a clean and
tightly organized code so from SK learn
data set import load breast cancer from
SK learn linear model import logistic
regression now we're also going to
import train test split from model
selection
okay now matplotlib by plot SPL t we're
following the convention here
now the magic commandment plot not block
let in line
okay now let's instantiate the data set
load breast cancer now as you might
recall we're going to split the data
Xchange x test white train white test so
features train features test targets
train targets targets test
trained to split cancer data which holds
the features cancer target which holds
the labels Mulligan's or benign
we're going to stratify by cancer target
okay and we're going to use random state
it's 42 as you might know the answer to
what is the meaning of life this is for
randomization now this is basically
similar or now like almost exactly as we
did with the cannon and this type of
prop like process applies to most
machine learning algorithms and
scikit-learn okay now let's instantiate
our logistic regression regressor I mean
classifier with its default parameters
now let's fit it onto this or basically
train it extreme white train and we're
going to print its accuracy in the next
cell so we're going to run this with
shift enter to make sure we didn't get
any errors shift enter okay so these are
the default parameters we're gonna talk
about them in more detail in a future
video now let's see the accuracy so
print accuracy on the training let's
call it not set but subset okay and
we're going to use like three fixed
points
format log-rank let's score the score on
our train subset okay now let's do the
same thing for the accuracy on the test
subset with three fixed points so X test
why test all right now let's run this to
check the accuracy
okay so ninety five point eight percent
on the test set that's much better than
Canon which got actually 94 well I see
much better because even though there is
a big difference between ninety four
percent and ninety almost 96 percent
over here so that can make a huge
difference in reality and we all use the
default runners of the logistic
regression algorithm once again this
basically means that in ninety five
point eight percent of the images it is
being provided after it is trained so
after we fit it the algorithm can
accurately predict it for dealing with a
malignant or benign tumor
the next question follows can we play
with its parameters to optimize it for
even better results on our cancer data
set we'll find out in the next video so
if you enjoyed this one make sure to hit
that like button and subscribe thank you
for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>