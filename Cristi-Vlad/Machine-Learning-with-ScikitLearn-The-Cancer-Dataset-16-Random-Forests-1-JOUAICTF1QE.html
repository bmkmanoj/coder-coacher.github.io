<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 16 - Random Forests 1 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 16 - Random Forests 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 16 - Random Forests 1</b></h2><h5 class="post__date">2017-04-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JOUAICTF1QE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in this tutorial we're going to start
using ensembles which combine multiple
machine learning models into a more
powerful model and the first model we'll
explore is random forests in later
videos we'll also work with gradient
boosting decision trees which is another
ensembles method for now we're going to
apply random forests to our cancer data
set and have it learn to classify tumors
into malignant or benign
now recall from a previous video that
I've told you how ensembles of trees are
often preferred over a single decision
tree classifier which can lead to poor
generalization and the tendency to over
fit the training data you can think of a
random forest as a collection of
decision trees funny enough in the
physical world forests are indeed
collection of trees now I guess you
could use this analogy to better
understand random forests in a
machine-learning context now how are
random forests better or different from
single decision trees now a single
decision tree has a good predictive
capacity but it is prone to overfitting
on part of the data we've discussed this
in a previous video combining multiple
trees retains the predictive power and
it can reduce overfitting by averaging
the results this is well explained in
the machine learning book of Andrea's
Muller and Sarah Godot which I'll link
to in the description now a
distinguishing powerful feature of
random forests is that it applies
randomness when building each tree thus
making each tree kind of different and
the averaging of results is done
afterwards it's quite easy to build a
random forest the major parameter
you have to specify is an estimators
which refers to how many trees to create
now theory aside let's implement a
random forest classifier and so I could
learn for our cancer data set now here
we're starting clean using a new Jupiter
notebook so from SK learn ensembl import
random forest classifier then as you are
getting gives to from SK learn model
selection we'll gonna import train test
split we need this to split the data
into training and testing and from SK
learn data sets we're going to import
load breast cancer okay now we're going
to instantiate our cancer data set
loaded breast cancer and then we're
going to split the data into thanks
train X test Y train white test train
test split cancer data cancer target and
we'll have a random state of zero
okay now let's build the classifier so
let's name it forest random forest
classifier and as I've told you the
parameter is an estimators and
estimators equals so we're going to have
100 decision trees in it and a random
state of zero now let's fit it on to the
data forest set
egg strain onto the training data and
all let's finish by bringing the
accuracy on both the training and the
test subsets of our data set so print
accuracy a cue receipt on the training
subset it's going to be three floating
three fixed points
okay format forest score X train white
rain and now for the test subset
accuracy on the test subset the same
thing three floating fixed point format
for a score X best wine test and now
let's run this with shift-enter
hopefully we're not getting any errors
over here so an accuracy of 97% on the
test data with the default settings I
guess that's pretty good
remember the single decision tree with
the default parameters only had an
accuracy of about 93% we could obtain
different and possibly better results by
adjusting the parameter in random
forests called max features which
controls the randomness of each tree or
we could also apply pre pruning which is
similar to water is done in single trees
also random forests like single decision
trees have the pair
feature importances which helps us
understand the way each feature carries
in the decision-making process now since
we're dealing with multiple trees and
randomness applies to each of them that
is common sense to think that future
importances of random forests is more
representative than any single trees and
this is what we're going to look into in
the next video so if you enjoyed this
tutorial please give me a thumbs up and
subscribe thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>