<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 9 - Logistic Regression 2 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 9 - Logistic Regression 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 9 - Logistic Regression 2</b></h2><h5 class="post__date">2017-03-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/n_hwKk5LcLk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is the second video on logistic
regression applied to the cancer data
set and scikit-learn we finished off the
last video asking whether or not we
would be able to optimize the classifier
to yield better results we worked with
the default parameters and we got an
accuracy on the training set of
ninety-five point three percent and an
accuracy of ninety five point eight
percent on the test subset which is
actually quite good but what are some
parameters that we could tune to improve
the accuracy of this algorithm so in
logistic regression we use something
called regularization to avoid
overfitting logistic regression uses l2
regularization by default which counter
to l1 does not assume that only a few
features are important now we'll lift
this parameter as it is thus we're gonna
use l2 regularization now the main
parameter which controls the strength of
regularization for logistic regression
is called C a lower value of C causes
our classifier to adjust to the majority
of data points while a higher C
emphasizes on the correct classification
of each data point so with a higher C
each data point will have to be
classified as correctly as possible now
by default C is 1 and as we saw over
here it yields good performance but
since the accuracy score for both
training and test subsets is close to
one another
chances are that we may be under fitting
now we can play with C
that's exactly what we're gonna do so
let's create another classifier that
uses C equals 100 so let's say log reg
100 is logistic regression and C equals
capital C equals 100
now we're gonna fit it to our X train so
I already executed all these cells which
is why I don't have to import everything
again so I'm just gonna fit it to our
training data X train Y train and now
let's once again print let's just grab
this from over there and modify here and
we'll see how it works with AC equals to
100 so it looks okay let's shift enter
all right as we can see with C equals
100 there is an increase in both
accuracies and the gap or discrepancy
increases as well which is good and
which actually means we're moving away
from an under fit model and basically
this means that our classifiers
performance has been improved okay now
let's try it the other way around let's
see what happens when we use AC a lower
C AC that is 100 times lower than
default so AC equals 0.01 now log rank 0
0 1 is logistic regression C equals 0.01
and we're gonna do the same thing fit on
our
train training subset and once again
we'll grab this
okay let's modify here so 0 0 1 0 0 run
and now let's run it
so 93.4% on the training subset and 93
on the test subset so we have a lower
performance on both subsets and a
similar discrepancy to c equals 1 over
here so a similar gap between these
accuracies which is not good so we have
an overall worst performance compared to
the defaults let's stop here for now and
in the next video we'll plot some of
these results and draw a few conclusions
about logistic regression thank you for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>