<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - 44 - Automatic Feature Selection - 3 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - 44 - Automatic Feature Selection - 3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - 44 - Automatic Feature Selection - 3</b></h2><h5 class="post__date">2017-12-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VvJcmxnAmxA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's now discuss about another method
of automatic feature selection with
scikit-learn and this is model-based
feature selection has said in the
textbook this method uses a supervised
model to determine the importance of
each feature and then it keeps the most
important features then the same model
or another model is used for the
training process okay so first we need a
model that shows the importance of each
feature and as we've seen in previous
tutorials a decision trees and random
forests have the feature
importances attribute for this purpose
now there are other models that provide
similar methods but here we're going to
use a random forest classifier so we'll
do some imports first so from SK learn
feature selection we're gonna import
select from model and then from SK learn
ensemble we're going to import a random
forest classifier forest classifier and
then we're going to create our model so
let's say select equals select from
model and we're gonna use our random
forest classifier with n estimators of
100 a random state of 42 and a threshold
of median so the model will select only
the features that are greater than this
threshold as you might recall from the
random forest tutorials and estimators
refers to the number of decision trees
in our forest and according to the
textbook a model based feature selection
is a more complex and more powerful
choice compared to univariate statistics
over here
okay so moving on let's first run this
one so we're gonna fit our select on to
X train and on to white rain and then
we're going to transform the training
set so let's say X train s equals select
transform X train and then we're going
to look at the shapes of x-ray and x-ray
s to see how many features are in each
one but since we've chosen a median
threshold you might easily guess the
output so let's say front the shape of X
train as
and let's say X train dot shape and the
same thing for extra nests so the shape
of X train s s X train s dot shape ok
shift enter so the Select method applied
on the X train as will reduce the
features base to 240 features so we know
that 80 is the number of our features in
the original data set plus the the noise
features we've generated okay so now as
we've done for univariate statistics
we're gonna apply a boolean mask to see
which features remained after the Select
method has been applied so let's say
mask equals select dot get support and
then we're going to view the mask
so using PLT Metro we're gonna mask
reshape 1-1 and we're gonna use a color
map of gray are okay and let's also give
it a label so let's say PLT X label as
index of features now let's run this
okay so this is somewhat similar to
univariate statistics over here the
difference being that the model based
selection selected all but two features
from the original data set and more from
the noise features that we've added ok
so finally let's transform the X test to
train a logistic regression and see the
performance so let's say X test as
equals select transform X test and then
do the logistic regression instantiation
feeding and score visualization in one
line and kudos to the textbook for this
so let's say score equals logistic
regression so the instantiation the
fitting on to X train s and y train and
then the score so X test as Y test ok
and now we're actually going to print
the score so let's say print the score
of logistic regression with the selected
features on the test set and we're gonna
use three fixed points okay so this is
gonna be format score score
okay let's run this one and we have a
score of ninety five point one percent
on the test set which if we look up here
is better than unit various statistics
feature selection so the second method
model based feature selection performs
better than univariate statistics so far
so good let's see how another automatic
feature selection method fares into all
this so in the next tutorial we're going
to tackle iterative feature selection
now please make sure to LIKE the video
and subscribe if you enjoyed it and to
get notified about all the videos you'll
have to click on the bell button when
you subscribe thank you for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>