<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning with Scikit-Learn - The Cancer Dataset - 10 - Logistic Regression 3 | Coder Coacher - Coaching Coders</title><meta content="Machine Learning with Scikit-Learn - The Cancer Dataset - 10 - Logistic Regression 3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Cristi-Vlad/">Cristi Vlad</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning with Scikit-Learn - The Cancer Dataset - 10 - Logistic Regression 3</b></h2><h5 class="post__date">2017-03-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9MsBYWiGYQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in the previous video we saw how
adjusting or increasing the C parameter
of our logistic regression classifier
improved the accuracy of this algorithm
on the cancer data set let's understand
how this works in a bit more detail so
logistic regression and other linear
models make predictions or decide based
on a linear function of the input
features you should remember from your
math class that y equals MX plus n or to
be more relevant for machine learning
y equals W times X plus B denoting the
equation for a straight line or decision
boundary
now Y would be W would be the slope or
coefficient and B would be the offset of
the y-axis or the intercept W and B
represent learn parameters while Y is
the prediction now for linear models we
can access these learn factors using the
dot Co F underscore and the dot
intercept underscore
if we are dealing with a dataset with
only one input feature this will look
like the equation would look like this
now we can graphically see this using
the mg learn library which is a courtesy
of Andrea's Muller and Sarah guy roses
machine learning book which I linked
over here so let's see it we're going to
import I'm not sure let me see maybe
I've imported it above I have not so
import mg learn and let's say credits to
Muller and guide o 2016 link above now
and and from mg learn to better see a
graphical representation of a linear
equation mg learn we're gonna use plots
plot linear regression wave
right so this is basically the decision
boundary and they'll learn parameters as
you can see over here to W the weight
and be the offset of the y-axis now in
in the case of a logistic regression the
equation so I've been talking about
linear models in general but in the case
of logistic regression to be more
specific the equation looks like this
the difference is in the addition of the
greater than zero sign which means that
we set a threshold value for the
prediction which needs to be greater
than zero and since we're dealing with
binary predictions over here like
malignant or benign cancers if the
functions value Y is lower than zero and
the classification would be minus one
which let's say let's call it an
abstract placeholder for whatever we
name one side of our binary
classification and it would be plus one
otherwise now linking back to our C
parameter let's let's now look at the
learned coefficients for the the three
different sees that that we have so see
the default one is C equals 1 then we
used C 100 and then C 0 0 1 so we're I'm
gonna let me say I'm gonna keep
inspiring from Muller and guide of this
book so for visualization will use PLT
plot the first one was log Rag the
simple one and we're gonna use Co F
underscore dot T we're gonna use the own
notation and the label is gonna be C
equals 1
okay now we're gonna do the same thing
for the other two C parameters so log
Rhaego
the other one was 100 KO f underscore
dots team and we're gonna use this sign
to denote that and the label is gonna be
C equals 100 and the last one PLT plot
log rags 0 0 1 co f underscore dot t and
let's use V for denoting it and the
label is gonna be C equals 0 0 1 was it
like that it was 0 0 1 okay well let's
make it 0 0 1
now we're also gonna do our X ticks the
range cancer data shape one cancer
feature names and the rotation is gonna
be 90 degrees cancer data shape okay
remove this one now PL th lines is gonna
be zero zero cancer data shape one the
limit of the Y is gonna be minus 5 to 5
the range now our X label is going to be
coefficient and X and our Y label is
gonna be coefficient magnitude so how
each coefficient contributes to the
decision boundary and all finally we're
gonna plot the legend wherever it finds
it best best to put it now let me make
sure everything is looks good here okay
let's run it see if we get any error if
or if we get the visualization so shift
enter now okay so here we have the hour
I'm not sure if you can see it well but
these are basically the the input
features the descriptors of each sample
of cancer so what does this
visualization mean what what is it that
we can get out of it now as you can see
for C equals zero zero one this denotes
a stronger regularization and this
basically shifts the coefficients toward
zero but they are in zero
conversely less regularization as I said
previously emphasizes on trying to
correctly classify each point now and
you can see this for C equals a 1 or C
equals 100 this type of visualization
lets us better interpret and also
determine how each feature contribute to
the decision boundary or the prediction
or classifying cancers into malignant
and benign tumors in this case a good
interpretation as well as an appropriate
build of a machine learning model are
very important if you want to be
successful in learning from big data and
this is kind of an accordance with the
garbage in garbage out saying ok will
now leave linear models aside noting
that they work well with large data sets
and that they are faster trained and
faster predict however there are other
models that generalize better in low
dimensional spaces as this has been
thoroughly explained by Muller and Godot
in their book so in our next video we're
going to start looking at decision trees
and how we can apply them to help us
predict on the cancer data set if you
enjoy this video please hit the thumbs
up and subscribe thank you for watching
and I'll see you in the next one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>