<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of JavaScript | Coder Coacher - Coaching Coders</title><meta content="The Future of JavaScript - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/freeCodeCamp/">freeCodeCamp</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of JavaScript</b></h2><h5 class="post__date">2018-02-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pTCPPy_lC7s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright and with that I'd like to
welcome everyone to our little debate
panel or discussion panel where
hopefully we will have a friendly
conversation with one another and I
noticed some fish some people have
joined me up on the stage here but who
are these people I have no idea can you
maybe quickly introduce yourself sure my
name is Brian Charlson I work at
Microsoft on the language side at the
track record gin and also on typescript
I also go to the tc39 meetings and do
that standards work as well I think it's
a little bit of an understatement to say
you do a little bit of standards work
you're the editor of the ACMA scripts
back true mean gonna get an applause for
that yeah and who are you yeah my name
is Benedict I already spoke earlier
yesterday you might have seen my talk I
work on the v8 engine which is the
engine in Chrome and yeah I do a bit of
performance work sometimes another
understatement I guess wait that's
that's an interesting coincidence you
both work on a JavaScript engine Wow
maybe we should talk about that yeah
okay but you mentioned that you work on
typescript it's one of the things you do
and we see a lot of developers using
things like typescript and flow and our
developer tools in their in their
workflows and you also work on standards
do you think types is something that
should somehow be added to equi script
as a language itself or should it remain
at a build level and my personal opinion
I think is that but in as far as types
being in the in the engine and
understood by the engine and used to
produce optimal machine code in sort of
the same way that a C compiler might I'm
not convinced that that is really
possible javascript seems sort of
fundamentally opposed to that kind of
work I think probably Benedict can share
some actual data and
based on strong Road investigations but
I think there is some a space for types
in in the tooling space is sort of
erasable type layer like like typescript
has where there can be you can you know
maybe even see them in the dev tools and
get feedback in your dev tools and the
browser about what's happening with
types and you know get errors at runtime
for for type mismatches and that kind of
stuff I think that's an interesting
Avenue to pursue but it is also very
difficult to do because we have a lot of
type systems now we have typescript we
have flow there's also closure compiler
and these are all kind of occupying the
same space and they all have different
ways of doing things so I think we'll
see over the next few years whether
there's coal there's a kind of
coalescing of these ideas and sort of
rallying around one sort of system to to
rule them all or if as I actually
suspect there's actually value in having
type systems that make different
trade-offs so I think that might be
actually an interesting place we might
end up yeah I agree with many things you
said so I I don't really see types as a
way to speed up JavaScript performance
because you cannot really rely on them
and the types don't operate on the level
that the engine needs to operate on what
I see though is the value for developers
and I think the missing link that we
have so far is that the browser doesn't
give you or the engine doesn't give you
feedback on whether you actually it
doesn't validate the types really so you
validate ahead of time but then at
runtime
anything can happen many ways you can
pass objects that don't have that type
because those are just living outside of
the typescript world and we recently
launched a new system that we call a
type profiling which your aura might
have seen already actually Apple has
this for some time in the web inspector
and one use case that we could imagine
is we collect the types at runtime so we
know precisely what kind of
object we have seen and we could use
this information and combine it with the
aesthetic information that you have in
typescript or in flow and signal arrows
if you see a type an object of at
runtime that doesn't match the type of
the typescript declaration for example
and doing this I think you can produce
pretty good code because the engine you
keep your code monomorphic just because
you use the types to restrict it you can
get if you subset javascript like if you
get rid of eval and you get rid of the
function constructor and a few other
things you end up with the sort of
JavaScript subset that could be strongly
typed but that doesn't I don't know that
many people are interested in using
something that's not really JavaScript
and you can't like use JavaScript
libraries you briefly touched on strong
mode before is that something you have
some more background I don't have a lot
of background on throat except that this
experiment was discontinued because we
found that so the idea is that we are we
have a subset of sort of soft subset of
V a of JavaScript running in a dedicated
mode similar to a strict mode there
would be a you strong and it would be
restricted so that many of the things
that make your program slow or behave in
the wrong way no longer happen but I
think that goes against what the
standards community is currently
interested in in having this one jeaious
approach we also had an experiment on
track record he had an awesome intern
who wanted to investigate how good what
what kind of performance gains we could
get if we built in types into JavaScript
and these types weren't typescript types
these types were actual native types you
know so here's annotating variables as
this is in 32 and this is you know and
in 16 and that kind of stuff and we
found that as long as you just blindly
trust the types which is not something
that you can actually get away with and
in practice but if you blindly trust the
type so you can get some pretty nice
speed ups across the board on the order
of
10 to 15% but the real trouble is we we
have this awesome ecosystem with so much
stuff in it and we just can't we can't
break that we need to find a way to
evolve from where we are and it's not
entirely clear what that looks like yet
and speaking of standardization at DC 39
there is a stage process for new
features to be added to the language
would you say there is a similar process
that happens once a feature starts
getting implemented in the engine itself
a similar process like what kind of
stages does a feature go through once it
starts to get implemented on the browser
side so outside of the DC turning on
process and yeah I mean at least on our
team we usually start with some kind of
prototype or a spike so we'll start
doing this work on you know around stage
3 in the in the standards process that's
that's a stage when the committee says
we're pretty much done making changes to
this and we really want implementer
feedback and then it's just this a
matter of getting all the tests to 6 do
pass test passing after that no small
feat and then after that it's an
iterative cycle of you know shipping
these features to developers and
developers tell us hey this is great but
you know XYZ we go fix that again
and this whole cycle just kind of
continuous so those wouldn't be bug
fixes anymore because you already passed
the test suite with a bit more like
performance optimizations for common
yeah yeah it's usually performance
optimizations and it's really hard to
anticipate in advance what patterns you
guys are going to be using like it's
it's it's it's a hard game to play and
if we try to guess what you might use we
might get it wrong we might spend a lot
of time optimizing something that just
isn't important
so this feedback cycle is really
important to us that we can you know
hear from developers how they're using a
feature so that we can optimize it and
improve economic Sande other things like
tooling and
that kind of stuff what are your
thoughts on that it's actually very
similar so we also start looking to new
features once once they reach the end of
stage to early stage three
usually it's right nowadays we try to
work together with Abel for example to
also make sure that things are aligned
because it would be really bad if you
use the feature at stage one already and
then you rely on Babel semantics and
then the browser gives you completely
different semantics once it hits the
engine on the performance side we we
have to wait until some use appears so
even before it hits the browser we can
often see it when we just look at the
actual code that people write and then
transpire by our Babel
but it's hard to estimate what is
important so for example we just now
start optimizing proxies just this year
we started looking to proxy performance
and foxes have been there in year six
since two years already so this is
roughly the timeline when we noticed
that okay maybe it's time to look into
how people use it and then optimize the
relevant cases so it sounds like engines
optimized for a real world code which
means that there's a bit of a
chicken-egg problem where if there's a
new language feature that lands in
browsers a lot of developers maybe they
think oh it's not going to be fast yet
in engine X or Y so I'm gonna not use it
for now and maybe still transpire my
code and avoid using this feature
directly but that means that all so it
won't get optimized so how what is the
best way to break this pattern and break
this cycle so in my experience since we
have ever between browsers nowadays you
should go for it as early as possible
maybe just ship it to a subset of the
users and see can you do this this is
viable this is a no-go and specifically
on the north side you completely control
the version of node and you completely
know exactly which version of chakra or
which version of v8 is inside so it
would be nice if you try it earlier and
provide feedback and then we can look
into this
yeah I definitely agree with that and
also I find that a lot of times you can
get away with using these new features
and areas of your application that
aren't performance critical so that's
that's sort of my approach to this
problem is to like I can't wait to use
these features after they get
implemented but you know I'm not going
to be using four of and in a hot path
because it's well now it's pretty fast
but it wasn't as of six months ago so
yeah I think there is a little bit of a
chicken and egg problem but yeah I just
you know we would really rely on
feedback and you really can't get out of
out of that out of that problem
benchmarks are interesting
especially when they go out of their way
to try and emulate real-world code as
much as possible but benchmarks just
aren't aren't enough like we really need
to hear from developers and on top of
that I see a danger one head-on that I
see in the wild is when people use babel
and try to optimize the transformation
so that it produces the ideal whatever
transpired code and I think there's some
danger in doing that because long term
you don't want to transpire this code
anymore or ideally you shouldn't
transport it anymore so I see the value
net but there's also a lot of danger
because then once you stop transpiling
you'll be set and then you go back to
transpiling and you don't make progress
so the set of features to be transpired
should be a moving window and I think an
easy way for developers to make that
happen is to use babel preset end which
basically it's like autoprefixer for
bubble so you tell it the browsers that
you explicitly support and it won't
transpile anything that it doesn't need
to transpile and that kind of solves the
chicken egg problem as well to some
extent right to some extent you know
it's the the performance of the
transpiled code isn't particularly
relevant to the performance of the
feature that you're trying to use but it
you know if you're using something like
preset and it does mean that
you know once browser is ketchup you're
gonna sort of immediately be opted into
this new feature which is certainly
helpful yeah and on top of that there
are many options to even ship modern
code already to modern browsers so one
option that we have been discussing a
lot in the past you can just ship
modules to the browser nowadays and
there's a fallback you can just provide
the full transpired bundle two browsers
who don't support modules but all the
browsers that support modules support
year six so that is a good way to
upgrade without breaking all process so
we should be transpiring to two sets of
two bundles basically essentially it
produces two bundles so there's a
wrapper example configuration for this
or that problem also roll-up
configurations to do that and I think
this is a pretty safe way to move
forward and it buys you a lot because
the untranscribed code is usually it's
up to orders of magnitude smaller than
the transpired code okay so that's
something that we all can do to make I
mean to give better feedback and more
data to browser developers so that they
can make all these new features as fast
as possible that's great cool and we
have I want to stress this again we have
evergreen browsers report the bug we can
look into it if we don't know that
there's a problem then we can never fix
it unless we stumble over it by accident
and then six weeks later up to 12 weeks
later you have the new version and the
feature is optimized ideally that sounds
pretty cool I'm sold now we're here at a
conference with lots of JavaScript
developers and we've talked about
standardization a little bit earlier how
can the JavaScript community directly
contribute to the whole standardization
process and there's a number of ways in
fact I'm giving a talk at Dooley 4:30
today on that topic essentially but
spoiler alert via spoiler alert
you should still attend my talk even
after I say some things so the the the
best way
is of course to to just try these
features as they come out and get us
feedback but even in the earlier in the
process
tc39 is now entirely on github all of
the standards work that we do plays out
on github very little of it happens
behind closed doors it's usually just
like administrivia and you know IP
related discussions and stuff like that
so github.com slash tc39 has I think
there's like a hundred repos now and
like every proposal has its own github
repo that you can follow so if you're
really interested in our particular
proposal like pipeline or the bind
operator or whatever you can go to
github and find that repo and you can
watch it and the issues are used to
discuss you know issues and pull
requests you can send actually pull
requests and that's fine we can take
those and so that might update the you
can spend your own spots make your own
spec updates that's a really great way
also like we're all on Twitter you can
talk to us on Twitter we have an IRC
channel on freenode I know IRC is not
the easiest technology to use but we do
have that as well
so that that's another way I remember
times when things were different when
the ACMA script spec was published as
like a word document it was literally
maintained as a word document where
annotations for the diffs yeah so for
each new release you would have to
download it with annotations enabled go
to the annotations figure out what
changed and then even for small typos
people would have to report a bug and
create a tracking issue and then the
court editor would have to go and fix it
in the word doc and upload it somewhere
and now most of my job is just accepting
pull requests from various people so
it's pretty nice it sounds really good I
remember at the time people actually
ended up writing a script to turn the
word document or even the PDF version
generated from the word document into an
HTML version so that it could be posted
online yeah link to
yeah that actually turned out to these
transformational work because it was
that work that enabled us to actually
move the speck onto github because we're
not just dumping the word doc in a
github repo right we have a whole new
HTML spec format and the whole tool
chain built on node to make it like
really easy for web developers
especially to write spec text and read
spec text and contribute right what
other challenges would you say there are
when it comes to measuring the
real-world performance because you
mentioned before that there is a lot of
micro benchmarks out there synthetic
benchmarks and they're useful certainly
but what we really want to optimize for
is the real-world performance of the
code that people end up writing right
yeah this is a very complicated topic so
for for one thing there's the web we can
just browse around and check that pages
and we do this we actually take the page
replay to make it reproducible and we
look into the web pages what they do
like top thousand web pages but we have
a lot of trouble on the node side
because we don't have access to your
applications and you should better not
give everyone access to it so getting
useful workloads there is very hard plus
the workload on the web are just one
aspect of the problem it's not it if you
load a web page on your mobile phone
then the engine does something
completely different then you then if
you I don't know use Google Maps or use
Google Earth on your desktop and the
same for node and there's also the
developer tooling side so we last week
or the week before we launched the new
benchmark suite that is set up tooling
benchmark and we really literally just
drop the code that is shipped on npm
into the benchmark and run exactly the
code that runs on your machine to so
that we make sure we don't just have a
proxy for the application but we measure
the application itself so the goal is to
make the build times of developers tools
faster like NPM run builds you're
speeding that up yes so to it's like
epic
or parts of Ã©poca included baby listen
typescript is in uglify sand all of the
things that take up all the time on your
machine and then when you deploy it to
somewhere under the continuation
continuous integration service for
example benchmarks like these can be
used by all browser and engine
developers right it's not just a
specific to one engine yep yep we've
been looking at the web tooling
benchmark as well I appreciate that
benchmark since NPM build is or NPM run
build is well that's my get coffee time
I guess yeah does anyone have a question
from the audience ask us a question come
on asking us a question would be less
awkward than not asking a question at
this point so we're gonna just gonna be
quiet up here and stare out web assembly
I never heard of it you guys i what is
this technology I don't know
I love web assembly so I work on
JavaScript the the language side and I'm
kind of a language geek I guess so like
while I appreciate a bunch of the
interesting things with web assembly you
know regarding you know compiling native
applications to run on the web and and
you know getting really close to native
performance and all of that really I'm
just excited about the prospect of other
languages becoming first-class citizens
on the web I think that's going to open
up a huge window for innovation from all
of you in the audience and I'm really
excited to see what that technology
enables yeah I I agree I personally I
would love to see like next year or 2019
having one big game publisher published
on the web like next version of
Assassin's Creed runs on the web only
that we also Mouse yeah how many
megabytes would it take though yeah this
is unsolved problem plus all the deal
issues that they have right yeah so
there's some technical details but it
was just be awesome on the other hand
for a game it's different than for
downloading a website where you want to
view some content right so you might be
willing to talk to pay a little bit more
and get all those megabytes in do you
find if I wouldn't run on my phone right
that's happy okay the use case is
completely I misspoke I think there's
also a lot of room for like you know
these 3d engines have these massive
asset pipelines and I think there's it's
we're in the very early days I think
we're gonna see tooling that's going to
enable sort of streaming of game content
and and that kind of stuff too to help
help address this problem of like hey if
you want to play a game you probably
don't want to download it you know all
of those assets again like even just
checking if it's fresh could be could be
expensive that make sense that was a
question oh yeah sure okay so the
question is about the binary ASD
proposal just so everyone hurts okay
okay so what is the status of the binary
SD proposal that there's tc39 and what
is your stance on it so I don't know you
can probably talk to the state but my
personal opinion on it I think it would
solve some really hard problems that we
currently face in the JavaScript land
but for every new thing that we add it
also adds a lot of new problems that we
didn't have to solve as well so baaaaad
generally in favor of it I'm not the
expert there so I I leave it to the
expert to decide yeah Brian has been
open and I'm also not an expert on on
this so the basic idea of this proposal
is what if we instead of shipping
JavaScript source code to browsers what
if we ship some packaged binary that
includes that source text but also
additional information that is sort of
shoved up front so that engines don't
need to scan over all of your code and
collect all this information about like
what variables have you captured and you
know are using eval and the scope and
all of this sort of information that our
runtimes need to produce optimal code
it's a great idea like the there are I
definitely agree that this is an actual
problem like this addresses like the
goal of this proposal is to address that
parse time bottleneck that many of you
with massive code bases are feeling you
know it can take seconds to parse
JavaScript on mobile devices on some big
properties so like that is not a good
situation
but in terms of difficulties what I what
I'm really interested
to see is how this proposal will handle
all of the different kinds of
information that engines need to collect
because we all actually collect slightly
different information because we just
have different implementations and
different trade-offs so I think this
proposal will only work if it is a sort
of superset of all of the information
that all of the implementations need to
collect in order to produce optimal code
I'm not super convinced that that's
possible but I think Mozilla is going to
work on a prototype and once that
prototype comes out I think we'll know a
lot more about how feasible this idea is
and what's the current status of the
proposal is it at stage zero one it's
probably stage one I don't I don't
remember offhand it's really easy to get
to stage one stage one is yeah we agree
there's some problem here and there's
definitely some problem there so let me
let me say one thing there will be a
session in the deep' trek by my
colleague Maya on the pawza so that
would be an ideal question for that
session oh yes okay and with that I
would like to thank you for your
cooperation during this debate such a
debate like you agree about a lot of
things
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>