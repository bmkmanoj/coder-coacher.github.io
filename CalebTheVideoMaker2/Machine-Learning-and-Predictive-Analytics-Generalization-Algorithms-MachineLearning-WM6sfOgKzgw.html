<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning and Predictive Analytics - Generalization (Algorithms) - #MachineLearning | Coder Coacher - Coaching Coders</title><meta content="Machine Learning and Predictive Analytics - Generalization (Algorithms) - #MachineLearning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/CalebTheVideoMaker2/">CalebTheVideoMaker2</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning and Predictive Analytics - Generalization (Algorithms) - #MachineLearning</b></h2><h5 class="post__date">2017-12-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WM6sfOgKzgw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome back guys it's Kayla from Caleb
the video maker - this is going to be a
continuation from the previous video
which talked about a machine learning
algorithms ability to generalize did I
even say that in the video crap I
totally forgot that's kind of important
anyways
that's okay it's part two I still got a
chance we're gonna be talking about
generalizing oh man continuing from the
previous video we had these two rows
here that we did not have enough data
for because our historical data set was
not large enough and didn't have all the
different combinations of data well I
wanted to talk a little bit more about
when we have the four different possible
models how the machine learning
algorithm is going to choose which one
of the four besides just magically we
are going to try to come up with a
legitimate reason as to how the
algorithm knows which one is going to
best represent reality and as always
it's always going to base off of the
historical data so I did change this
table a little bit this part is the same
because this is just all possibilities
of data but I did change the actual
results just to make my example a little
bit easier because like I said it's very
challenging to see trends in data so I
made the data very trendy so I could see
those trends and then point them out man
I sound terrible
I don't feel very good no gosh previous
video we took these two rows and we came
up with all four possible models that
could represent reality and the reason
we had four is because we didn't have
all the data we needed so we had to
write down every possible model to
represent reality and there was four of
them as I explained in the previous
video so now how do we choose which of
the four is the best and this is
something the algorithm is going to do
so we don't really have to worry about
it but it does make sense to
you know comprehend such actions of
machine learning algorithms so that's
what this video is about we have these
two rows where we do not have enough
historical data to represent because in
our historical data we did not have
anybody who was a female who was older
than 50 and did have a family history
and we also did not have anybody who was
a female and was older than 50 and did
not have a family history of diabetes so
our data set is lacking so we are able
to guess the values here most
appropriately using the other attributes
that are available up here this will
make a lot more sense once we talk about
the id3 algorithm later on in this
series but for now just follow with me
and we'll try to get the bare minimum
needed to understand this concept so how
does an algorithm generalize beyond the
data how does it make predictions like
that it has to do with attributes that
are very discriminatory and we're going
to be talking about that as well in an
upcoming video so machine learning kind
of requires a lot of words that you know
take awhile to understand so I apologize
if I throw a lot of information at you
that I haven't really explained just
bear with me and it'll make more sense
as you go on in this series but if you
look at our historical data you can see
a trend you can see that anytime the
family history is yes the person ended
up with diabetes it's awesome you know
that makes it so easy if they don't have
a family history then they did not get
diabetes so that means we are able to
look at these two rows and predict what
these values would be based on the data
we already have so even though we don't
have any data that represent these two
people we don't have a complete
representation of reality we can still
figure out the data
so following this pattern here this
person does have a family history so yes
and this one would be no nail goes like
a female who's not under 50 and has a
family history would have diabetes a
female who's not under 50 and does not
have a family history would not have
diabetes this here is the missing piece
allowing us to completely model reality
even though we don't have enough data to
do so boom and that's the beauty of it
all we can know what's going to happen
even though it hasn't happened yet it's
crazy
now obviously it's not going to be that
simple in reality because you know we're
not going to have this one-to-one
correlation here so that is why we use
computers because a computer might be
able to look at all the little things
and find the most likely correlations
between data to get the most likely
model simple but super complicated and
confusing now there's one other thing
you look at this and you're probably
like okay this this is faulty because
you know for one this is not enough
information to determine whether someone
has diabetes or not and to you know like
you could have you can have two people
that are exactly the same using these
attributes and one has diabetes and one
does not yeah that yeah you totally
called me out because this is very
faulty the reality is that this kind of
system here would be perfect for
something that's very concrete in black
and white for example if we wanted to
classify whether emails were spam well
that would be very simple you know we
could have does it contain images or
files is it from an unknown sender is it
from out of the country
as has this person sent you mail before
etc and we could make rules to say that
oh if it if it has images attached and
it's from an unknown sender and it's
from out of the country it's
automatically spam guaranteed but
diabetes is a little bit more
complicated because it's not so black
and white so keep that in mind as you go
into this series that this is going to
make predictions but it is not foolproof
it will get better over time and that's
one of the key the key things with
machine learning is it's continually
improving but they're just the reality
is we can't know for sure whether
someone's going to have diabetes or not
just based on historical data we can get
pretty darn close though so that's what
we are trying to do we are trying to
predict what's most likely and how do we
deal with issues when we have people
with the same attributes and they the
end result is different well when we
define an algorithm it's going to be
done in a group kind of system so we're
going to need more data than just one
person who is you know female overly
under the age of 50 and has a family
history of diabetes that's probably not
going to be enough because it's going to
be more of a kind of like a balancing
system to where we look at maybe let's
say we look at 2,000 people with these
attributes and let's say 90 percent of
them had diabetes so 90 percent had
diabetes and 10 percent not well this is
more likely how it's going to work
because it's it's not black and white in
this situation we can have two people
with the same exact attributes but
different results and it's going to take
the majority based on a large group and
use that as its basis to define their
right here for this simplified version
of reality I hope that made sense if it
didn't make sense I'm sorry but just
think we need more than just one
instance of every single possible value
because one is not enough to represent
reality you're going to need a lot more
data when you're not dealing with black
and white things like classifying email
as spam</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>