<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learn You a PyTorch! (aka Introduction Into PyTorch) | Coder Coacher - Coaching Coders</title><meta content="Learn You a PyTorch! (aka Introduction Into PyTorch) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learn You a PyTorch! (aka Introduction Into PyTorch)</b></h2><h5 class="post__date">2018-05-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/X8gWWKfym3Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I would like to first start off this
by saying that this isn't a sponsor talk
by pi touch of Facebook but if you guys
are out there I wouldn't mind some
sponsorships so Who am I I'm I'm
Kendrick and my languages of choice are
Python in Haskell and I'm currently
pursuing my bachelor's of IT at the
Queensland University of Technology it's
a kind of work in progress at the moment
might not finish it I don't know
so my day job I work as a machine
learning engineer at Popkin da da and we
try and kind of teach computers how to
interpret music and responds interpret
and responds music so even though my day
job sounds fancy this is this xkcd comic
kind of reflects how I feel I'm just
kind of stirring a big pile of matrices
to try and fit my data in so what this
talk covers is why you should use PI
torch and not say there's sixteen
different other frameworks out there
like tenza flow MX net Caffey t know and
so on what this talk isn't covering
however is me explaining back
propagation regression matrix
multiplication and so on I don't claim
to know everything so if you feel like I
got something wrong or you want to
clarify in anything feel free to hackle
me but I would appreciate if you don't
harass me so these are a couple of
thoughts that I a granade it from the
machine learning subreddit and thoughts
on using PI touch and the bottom one
actually resonates with me so much
whenever I write tensorflow code it's
great when you're not trying to reinvent
the wheel so that many things today that
I could talk about PI touch but today I
just want to focus on these five topics
a standardized minimal abstraction API
this results in a non leaky abstraction
allows you to reason to easily reason
with your code so all you researchers
there I love your work but the code you
write is really really hot to follow you
have you have a class get that get get
that gets passed into a function and the
function implicitly mutates the class's
state and then you call several subclass
functions to mutate the state again it's
just so hot to follow my spell even
worse when it's written an intensive
flow it's just so hard to follow but
with PI torch you're able to minimize
that the kind of layers of abstraction
and I have clear and concise code
multi-gpu support and PI torch is easy
as it should be for those of you coming
from the numpy or sy pile and PI clutch
has deep integrations with PI tour with
Python so using PI touch should feel
like second nature to you a big part in
machine learning is actually the data
cleaning data purchasing data
augmentation stage and PI torch actually
has some pre it actually has some
pre-built tools that allows you to
leverage it so you can use your custom
data set with ease including the
documentation and pre-processing stage
PI torch exterior actually runs in
something called a dynamic computation
graph which is different from static
computation graphs and I'll talk a bit
more on that later on so this picture
this network picture is just to give you
guys a visualization on the newer neck
neural network that will be building
later on in pi torch to familiarize
yourself of you guys with PI torches API
we have 28 by 20 as the input 32 has a
hidden and tendance the output the
numbers for the hidden layer were chosen
arbitrarily so pay no attention to that
and this is this is how you define a
fully connected Network in pi coach
which is what we did which is what is
shown in this picture so on the left
hand side you can see the network
architecture being declared and on the
right hand side you can see being
constructed and called so to define your
network you're a neuro network your
class needs to inherit inherit from
porch NN
module and if you can see here I'm
defining two class members in the
constructor FC 1 and FC 2 now FC 1 is a
linear linear unit a linear layer which
takes in 28 by 28 and outputs study 2
which is the first half of this this
network architecture and FC 2 is a
linear unit which takes in 32 and
outputs 10 which is the second half of
this of this network and you can see so
when the class is being called it
actually invokes the forward function
and you pass in the variable X as your
input and as you can see here input is X
and so you pass the input through FC 1
and you returned a 30 to length tensile
and X is passed again into FC 2 and your
return X which is essentially what this
picture does as a whole and so the issue
with this code is that it only runs in
CPU it's not crude I support it doesn't
isn't supported on GPU just to make a
GPU compatible what you do is call CUDA
and that's it that is all you do to turn
your CPU Network into a GPU compatible
network how easy is that that that that
would have took me at least two hours
intensive flow but in Python
all I do is called dot CUDA now this one
more issue with this is this is only
supported on one GPU but say you have
you want to paralyze it what would you
do and then you kind of encapsulate in
data parallel and that is it that is how
you have multi GPU support for pi torch
on networks look how easy it is
multi-gpu GPU now CPU and I'm back to GP
multi chief you so easy
so again Pike watch has deep
integrations with Titan and so say you
have the output so now you have your
output you want to say turning into
numpy array for whatever reason and
chuck it into a CSV or something what
you do is called dejara
dot numpy and you returned a numpy array
but if you're on CUDA you call dot CPU
numpy that's it oh there's actually a
typo here sorry if it's if CUDA you
called dot CPU numpy sorry and that's
how you turn your tensor into a numpy
array and to turn your numpy array into
tenses all you do is call torch dot from
numpy and your numpy and your returned a
tensor again these features are baked
into the framework for your convenience
you don't need to go to like a third
party contract library to to streamline
this process it's built into the
framework so a big part of machine
learning again is the data
pre-processing and documentation stage
in pi torch land this is how it works
you have a data set which you say you
have a list of x and y's which sits
inside a data loaded the data loaders
job is to augment and pre-process the
data from your data set and batch them
up and put and kind of feed it into your
model so normally if you don't want to
write a multi multi-threaded
pre-processing utility it could take you
a couple I don't know for me it took me
a couple of days but in Python it's very
very easy to do so you define to define
your custom data set you just need three
special method functions the constructor
get item and length so the constructor
and and and your class needs to inherit
from torch YouTube you need you toast
the data the data set and there you have
it you have your custom data set ready
to be put into your data loader but say
you want to populate your data set
you do is this in your init:function you
supply say say X and transforms and
transforms is a pre-processing utility
which is built by the PI Torch team
which I'll talk about more on the latest
slide so as you can see I'm just
defining my class variable X as X and
transforms s transforms and when you
index it it gets X at that index and if
you defined a pre-processing or data
augmentations that it augments and all
pre-process your data and returns X the
length of your data
well length just is just the length of
your data so yeah so going on to touch
fission so it transforms transforms is
actually a is actually obtained from
torch vision which is a computer vision
specific pre-processing library there's
also text and audio coming along and all
done by the amazing PI touch team so you
can compose your transformations so for
example Oh again sorry transforms
contains the commonly used pre
processing and data augmentation
functions like scaling converting your
pillow array to a tensor flipping your
image or randomly cropping it randomly
flipping it and so on so you can compose
multiple transforms so say I want to
scale an image and I want to transform
it to a tensor so all I can compose it
into t2 and I pass t2 into my custom
data set so now when you call D set to
its actual it actually returns you a 28
by 28 tensor but if you call D set one
it returns you an N by n tensor so now
we have our custom data set what do we
do how do we put it into data loader we
just put it in as a special keyword
argument s dot and data set and your and
your custom data set is now
multi-threaded by default and whatever
transformations you define will be
performed during runtime
in multiple threads and that is that
your custom data set can now be can now
be utilized and put into your model so
all you do use your data loaded all you
do now is enumerate over your data
loader and you can sort of just pass X
or Y's into your data into your model so
dynamic graph computation or DGC is what
pipe which runs on as opposed to static
graph computation which is what its
cousins run on such as again tense flow
caffeine or torch so a really good way
to describe PI torch is that you define
your network by running it but static
static graph computations you define
your network and then run it so it's
really hard to kind of visualize this
process so I included a Jif so this is
stolen from the PI torch website and so
what you do is you kind of you kind of
define your variables and describe how
to interact with each other and the
graph is created during interpretation
rather than being interpreted then
created and you might ask me why what's
the benefit of using the GC over SGC and
here's a couple answers well for
starters dynamic graph computation is
actually really easier to debug than
static graph computation if your little
black box near a network suddenly during
our intense flow you'll be greeted with
like a ten lying stack trace which is
quite an ideal when you're trying to
debug it and you have limited time on
Python or in any other framework that
utilizes the GC you actually you know
which file and on which line your
network failed on which is really handy
and saves a lot of man-hours you're able
to process inputs of variable sizes in
DGC which is really which is which is
kind of like key when you're doing
with machine learning for text and audio
there is no tensorflow sessions
absolutely none and you can do some
interesting stuff such as manipulating
your grade in this during a runtime so
this piece of code snippet if you
include it into your training logic you
can clip away the gradients to prevent
grade and explosion which is quite handy
when you're trying to train something
that is really unstable during the
initial stages like again so one of the
most common questions I get asked from
people who want to use PI touches how
can I visualize my training output or
progress because there's 10 support to
tensorflow
so what's there to vist what's that PI
torch well the nice folks at Facebook
actually created a library cursory a
tool a very powerful visualization
toolkit called vishton what's great
about it is its platform agnostic and
you can communicate via HTTP rest which
is really handy so this is a nice fish
nice drif and how it works
so yeah you have vishton 4pi torch how
do I go back present
so in summary why you should use PI
torch it has a non leaky API and allows
either easier reason about your code
especially when it's a black box code
commonly used features are baked into
the framework for your convenience like
converting from a tensor to numpy enum
pH a tensor documentation data
pre-processing multi-threading and so on
I understand a community is a really big
part of whichever framework we choose
and it has a really vibrant and
supporting community on the both on the
forums and on the slack Channel plus it
has really good docs and yeah that's it
any questions
sorry what this one yeah something you
mentioned here that you actually
automatic to get the math multi-threaded
yeah they did all that I mean not native
threads you mean Python threads right uh
I'm not too sure about that but it's
nothing threaded yeah I haven't even
looked into it but yeah all right any
other questions
yep thanks for good talk so you talked
about why it's good to use part torch
what why would you what are some of its
shortcomings or why might you not use it
hmm well for starters that that's not a
lot of the document it's kind of still
in beta mode so the the API actually
changes quite a bit and you have
existing modules which gets put into
legacy modules so if you if you want to
run on the bleeding edge it shouldn't be
an issue but if you want a stable
production level sort of system I
wouldn't recommend using it but if
you're doing research I would highly
recommend it as for the shortcomings
other than that other than the changing
API I haven't personally oh that's not a
lot of that's not a lot about guides on
how to use it online when you compare it
to 10th floor that's pretty much it it's
more at the community rather than the
framework itself any other questions
yep sorry so you just said that it was
kind of beta mode is there a date that
you guys are working towards for when
you like PI on releasing a stable
version or is it oh I'm not part of the
do you know if there is a date so
there's monthly releases on the website
so but it's still in beta so it's very
rocky very very unstable as in the API
but you can fix that by kind of
specifying a version what version of Pi
torch you want to use okay so do you
know if there's a plan for a 1.0 or
something like that where it starts
no okay any other questions I've got one
so it was probably just because you
showed us the EZ in your network but it
seems to me that if you're defining the
network in you know posh partial pi
torch and partial Python code so for the
forward function here you can imagine if
you've got tens of layers you'll write a
loop and then everything goes through a
Python loop does that cause issues or do
you have to use other PI torch classes
too so there's actually a module call
and n dot sequential and so it's like
you can compose multiple multiple layers
together which if you look at the source
code is actually just a for loop but
yeah yeah because that's one of the one
of the key bits about ends flow and
numpy and stuff like that is try to push
everything down to those lower layers
and try to come up to python as as
infrequently as possible yeah so this
kind of abstracts away that concept so
which is which is why I love it so you
rarely see that
rarely awesome alright any final
questions no okay well thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>