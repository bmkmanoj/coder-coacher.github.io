<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Predicting Titanic Survivors With Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Predicting Titanic Survivors With Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Predicting Titanic Survivors With Machine Learning</b></h2><h5 class="post__date">2017-12-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fS70iptz-XU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so Titanic who has seen the movie come
on who has liked the movie come on in
their youth I mean anyway we know
Titanic's about it's a love story right
there's a ship the ship sinks other
people die yeah it's really good it's
really good so I happen to have here a
folder with some files here and there's
the surprise SH that's the script I used
to do like image to ASCII but there is a
file which is called train CSV and this
file contains some actual historical
data of the passengers of the Titanic so
you can see there's the passenger ID
there survived which means they survived
or not and the passenger class the name
the sax the age the number of siblings
or spouses the number of parent or
children which ticket they had how much
they paid for the ticket which was a
cabin where they embarked so what I'm
planning to do today is to basically
investigate if the movie had any sort of
like historical truth to it or not and
that's my only goal actually when I
started project so yeah whatever
so we're going to use some really cool
Python libraries to do that and I'm I'm
not really a Python guy I'm not a data
science guy so like the journal like I
think thing is if I can do it anybody
can do it I just can copy some code of
Internet to get it run understand like
the basics of it try to change the
little bit and then I mean like if I can
do that anybody can do it so I'm just
gonna write I'm going to write a lot of
code in this presentation hopefully I'm
not gonna mess it up like too badly
probably I will so let's start visualize
that P I so we're going to import this
library which is called pandas it's an
amazing library and you should like take
a look at it and using pandas there's a
way of like loading a CSV directly
and they call it a data frame so I'm
going to call it a DF and if I do PD
read CSV and I'm going to pass train dot
CSV I'm going to have this object which
I can print the shape and I can print
some count right and if I save this I
run in Python
you'll say okay we have 891 bros twelve
columns and then the count we can see
that for every one of those columns we
can see which rows had that information
so we can see that in this case for
example we didn't have H for some of
those we didn't have the cabine for some
of those with me some in March but like
in general like the data looks pretty
good so what are we going to do first is
to take a look at the data because it's
pretty useless to try to run some
machine learning algorithm on Sunday I
have literally no idea what it is about
so and it's also pretty fun because you
get to create some cool graphs so
there's that to it okay so let's try to
do something with it so I'm going to
import a library which is called mat
plot lip and has a little function it's
called pipe lot as PLT I'm going to
create a figure with PLT dot figure fig
you have to pass the fixed sides and
you're going to pass something like this
and now I'm going to delete this no need
to show something at the end of it and
now I'm going to do DF survived value
counts and now methods Lib adds this
amazing plot you just do a kind bar and
I'm going to pass an alpha just because
otherwise it's a bit too painful on the
eye so if I run this something I'll turn
on the back you can see this is actually
the survived column on those 900 words
zero means unfortunately deceased and
one means survived and we can see it's
like more or less 350 survived 550 died
right but our human brains aren't really
so good at reading raw numbers so I'm
want to use some like percentages
and luckily it's quite easy just do
normal is true save run again and now
you'll see actually this is like
something can reason about 40% of the
people survived and 60% of the people
died it would be interesting to take a
look since we have the information like
all the age of the passengers to take a
look at what relationship there is
between the age and the survivor right
basically right so the library provides
a really nice function which is called
scatter and if I just do scatter I can
pass DF survived yes H in this case I'm
going to pass a lower value of alpha
because a lot of dots are gonna like end
up on each other and let me also add
some title to these things so survived
and this will be survived no actually be
like aged with regards to survived and
in this case actually if I ran this girl
right now you'd like display all the
like graphs like on top of each other
and we don't want that so instead we're
going to use this function which called
subplot to grid and you can just pass
like these general dimensions of your
rectangle and then like this is the spot
this graph will take so I'm just gonna
put like this first and the second and
if I run this you'll see you have this
really nice looking rough if we take a
look at this it's pretty interesting
because we can see that 0 0 means
deceased and 1 means that survived sorry
and we can see that it is true that like
some of the older people died and
instead some of the younger people
survived more but actually like the bulk
of all the dots are pretty much in the
same range they're between the 20s and
the 40s and there's no like huge you
know change in the data at least like it
doesn't show right so I thought just
like it's really really interesting as
soon as you get this like raw CSV of
stuff like you can't really figure out
just like to try to cut it through like
some sort of dimensions and take a look
around and you know like maybe there's
something in it
okay cool so something else I'm gonna do
is just like take a look at the
passengers class distribution so I'm
just gonna do some but quick copy paste
instead of survived I'm going to do
Oakes pre class and here this will be
class Python and we can see that a 55%
of the people were in third class so
like there was like the poorest class
and 25% of the people were in first
class and the rest were in second class
so there is like a pretty uneven
distribution of the passengers in those
classes now there's something pretty
cool that you can use when you want to
correlate two different dimensions so
basically one of this is the scatter
plot another one is called a kernel
density estimation I won't bore you with
what it means but it really looks cool
so I'm gonna build one for you and
basically I want to correlate the class
with the age of the passengers right so
I'm gonna and also like this has like a
nice you know little thing so I'm sure
I'm going to trigger some PTSD around
the room because I'm going to write
something which looks like this Col span
yes
no no web developers using tables no one
wants to admit it right so call span to
so this graph will take two columns I'm
just gonna do 4 one in one two three and
then do D F H and in this way I'm
filtering like like what I want to
extract this the age of my passenger but
between the square brackets I can filter
stuff so in this case I'm going to
filter their passenger class let's do
something like this and then I'm just
going to plot kind equals KDE which
stands for kernel density estimation and
now I can just give it a title so this
would be basically their class word H
and just for your safety I'm going to
add a legend to it so it's just first
class second class third class
okay and this looks pretty cool what
does it mean if you take a look at the
average of the ages the third-class
parents teachers are younger and instead
the first class passengers are older
it's sort of like there was some sort of
relationship with how much money people
had with the type of tickets they were
like they could buy and I think it's
just like some like good ways of trying
to make sense of information just like
try to visualize it a little bit and as
you can see it's really simple to like
do these graphs using matplotlib like I
don't know what like I get I don't know
if I had to do this using like d3.js
probably just like gave up the project
so no offense so I'm just gonna do add
one last image to this which is just to
show where the passenger embarked on the
Titanic so he I'm just gonna do here and
here embarked and this is like very
useless information but I think it's
funny because I never knew this myself
and actually I thought that everyone
just like got on in England but actually
only 70% of them got on in Southampton
and then the Titanic stopped once in
France in the ship booth and then
stopped again in Ireland in Queenstown
so like this is like set of information
shows also like where these passengers
are coming from and probably the data
could also tell us there is some sort of
relationship between like where they got
on the Titanic and if they died or not
which is creepy
but if you take a look at this I think
this is really cool I'm just gonna
screenshot it
I think it's yes and if you take a look
at these graphs there's something
missing which is the gender right
there's like no like cut out on the
gender of the people who were on Titanic
and the reason why I did that is because
the gender is really interesting so I'm
just going to do some simple copy-paste
I'm gonna copy this I'm going to create
a new file which is called visualize
gender pipe oh yeah
and here I'm going just to keep the same
structure I'm gonna add a couple more
graphs so you're gonna make like the
rectangle bigger and here I have
something like this and actually in this
case I want to drill down a little bit
so I want to check if the sacs of these
passengers were male and just do this
and here just do men survived and copy
this again and just change this to
female and this would be well men's
arrived
cool so here one two just as more little
detail I'm going to change the color of
the grass for the girls so it's going to
be F a0 0a0 0 nope there's no land here
I'm going to do color equal female color
okay and I have to show the graph again
so LT show if I do this they look quite
good I mean unless you realize that
actually in the case of the women's
graph the columns are inverted so
actually of all the men 20% survived and
of all women 70% survived so when they
say like women and children first was
actually quite true
and if we wanted to see just like the
disparity of these legs like the sexes
comparison like you know the survived
people we could do that quite easily
just like in the exact same way so just
like copy this little thing and we're
just gonna set it like on the last cell
we're going to we want to show the sex
now but now we want this filter to act
on the survived column we're gonna do
one and here we're gonna do
sacks of survived and I'm going to add
like two colors in this graph so we can
like the favorite
differentiate between them so this
should work and you see like this is the
difference right like of all the people
who survived the Titanic at least like
on these data set we have I think these
data set has only a thousand like
passengers and in total like in the
Titanic words like three thousand I
think it's like a pretty good way just
like you know like looking at things
like in a sort of like almost objective
way and you see that like of all the
people who survived seventy-five percent
of them were women now I'm going to do
something really similar to what we did
before which is kernel density
estimation I'm going to try to use the
class of the passenger to show their
survival rate this let me know if I'm
going too fast or if there's like
something which is boring so what do we
do before said like the same thing using
call span again so this is like on the
second row starts from the zero call
span equal four and here we can just
like do some good old copypasta from
here yeah and paste it here cool and
what we should want to show here is that
age anymore is the survived right and
here would be would be survived no would
be actually class with regards to
survived okay say and there we have it
so this quite like I mean it's quite
scary in a sort of way because you see
that the third like class passengers had
like such a higher mortality compared to
the rest and instead you know like you
see like the first class passenger so
yeah I mean it's not like the best
holiday they had but no it's pretty good
so this made me think well what about if
you try to combine this information
about the sacks and the passenger class
like together and try to show that like
all the different spots if you remember
the movie there's this guy who is like
very poor and he's a man and this girl
was a very young and very rich right so
we're just gonna see if you know like
the movie holds on on this like core
criteria so what are we going to do is
to just like copy some code which I'm
just gonna do a lot of like copying of
code basically like my daily job say
there's like some colleagues as well so
so zero and here I'm going to add two
filters together so I'm going to select
people which are male and DFP class
equals equals one so we're selecting the
rich man rich man hopefully it's not
like not the rocky train anyway p3 and
this would be poor man and I'm going to
put it like one close to each other
right yeah there it goes so we can see
that actually like in the poor like in
the rich man like they're not doing
great but they have like certain 5%
survival right and instead the poor man
doing horribly they have basically like
over like 10 percent survival rate so
what if we try to like replicate this
experiment with the women so we'll refer
to some good old copy paste again here
copy paste here I mean like you either
have some like code prepared we have to
copy paste so I mean no shame here
female female and it here will be rich
woman and here would be poor woman okay
and also here I'm going to let me just
convert this okay color equal female
underscore color and I'm going to do the
same thing here okay
and I think upgraded the columns as well
so I'm just gonna run this
so um yeah it's pretty brutal right like
you can see like basically the rich man
had a survival rate of 100% like if you
print out the actual data there's like a
hundred rich women and only three of
them died if you take a look at the poor
women like they're not doing like
they're like doing okay but there's
still like 50/50 and if you take a look
at these graphs it's like pretty clear
why you know this is Jack and this is
rose so right like you know okay so I
spent a lot of time just you know like
showing data and doing stuff like that
so I hope I mean it's like time
well-spent
I'm going now to do to use some
algorithms to try to you know like
predict this data so the first algorithm
I'm going to use is very simple well
like you know like the simplest
algorithm will just be random and you
have like more or less fifty percent
chance of like getting the right answer
because it's either survived or deceased
but taking a look at this data one could
think of a very simple you know
heuristics right would be if you're a
woman you survive with your man you die
I'm sorry for the audience because you
know this case would be pretty brutal
but so I'm just gonna exit from here and
create a new file which I call predict
gender pie and here I'm going to import
pandas again as PD here I'm going to
give like a name as train because like a
machine there and there's a lot about
the training set and test set so I think
it's good just like to call it train set
of DF which is a panda specific term so
I'm just gonna do read CSV train that
CSV and inside here like as you've seen
before like we have everything we have
like all the columns you can filter
through them
and what is cool is that you can
actually add more stuff so you can do I
can add a new column which I call
hypothesis and in this I'm just gonna
feel every route zero and then I'm going
to use the cut
a method which is called luck which you
pass a condition and the column to
update so the condition B if the sacks
of is female and the column I want
update is the hypothesis I'm going to
set one so these are quite simple it
means if the passenger I'm like taking a
look at she's a female I'm just gonna
keep like like my hypothesis just she's
gonna survive right
and now we just need like a simple way
to check if our hypothesis is correct so
and just do luck again and here would be
if the survived column is the same as
our hypothesis okay I'm going to update
the result column with one okay and now
we can do print train result dot value
counts right so I think this like makes
sense or way you think okay here's my
hypothesis if she's a girl she's going
to survive and then I'm going to compare
my hypothesis with the actual recorded
value which is the answer which is
survived so if I do this did I say no DF
is not well I just said I'm going to
call the Train so I'm gonna replace the
F with train and done and now it says
701 is like like we know that one is
good right like one means that our
hypothesis is like the same answer as
the survived column but as I said as
humans we can't really read these
numbers so I'm gonna play the same old
trick which is normalized true and you
see Wow seventy-eight percent it's like
such a simple heuristic but it gives us
like a 28 percent increase on just a
random algorithm so I think this is like
a really good like reason why you should
always take a look at the data first
before running any algorithm on it
because sometimes just like a very
simple you know like hint could give you
some like really good answers and it's
and you will see
the future that the more complex
algorithms we run the one give us like
such a massive increase anymore
because like there isn't like that much
more truth in the data anymore
okay but I think this is pretty cool so
I said I was going to write a lot of
code but actually a light because there
is some code I didn't want to write just
in front of you because it's like boring
as hell
but I'm gonna explain like what it does
so there's a function we clean data we
pass some data it feels all the rows
which don't have the fair information
and we'll like fill them in with the
average value they do the same with the
age they're going to transform the sax
from a string to a number and this is
because a lot of these machine learning
algorithms are nothing but basically
number crunching algorithms so they
don't really do well with the categories
like our human brain deals with but
they're really good was trying to
optimize numbers and that's why you
usually always want to do this sort of
normalization and transform these things
that we know means something into just
like pure numbers in this case integers
and so I'm going to do the same with
like male so like zero will mean male
and one will mean female and I'm going
to transform also the embarked
information as well okay so I think now
I've learned something from new school
before so I'm gonna cheat as well
there's like it's I love the web
so there's let's try so um yeah so this
is just you know like some graph we have
some leaves here we're just like data
points and if I were to ask you what is
the general trend of this data you'd say
well you know it's like something like
this right like yeah like more or less
like everything is there and like the
simplest machine learning algorithm just
as this like it's no magic it's just
like takes a look at the data points
tries to run some server like number
crunching algorithm on it to try to
understand
what is a good line that fits the data
and it tries to minimize the error
between what he thinks the value should
be and the actual value so like the
first time you see a machine learning
algorithm run you're like yeah whatever
like this is dumb I could do it right
the problem is like we're really good as
humans who do this on two dimensions but
if I were to ask you to do the same
operation in 15 dimensions yeah right
like I can ask you know time zones who
understands time zones raise their hand
really phone numbers who understand like
phone numbers you know standards it's
really really hard like if you try like
to read the source code of library hood
like trust to do that for a job you're
like whoa this is so hard like I can't
keep all these like things in my head
I think the same happens for like
different dimensions just like too much
stuff like our brain is just oh it's
just like struggling a lot and this is
the reason why like a good numeric
approach beats the human brain because
like we're not really good I like
dealing with 20 dimensions if you think
about like image recognition tasks they
usually sign different dimension to each
pixel so your have an image which is 50
by 50 pixels you're trying to solve a
problem which has 2,500 dimensions like
who can do that I don't know I can't I
can't like I have like some issues like
with this to be honest so yeah so I'm
going to create a file which is called
predict logistic regression pie and I'm
going to import actually maybe I can
just like cop some stuff I mean we're
copying anyway so audio is called for
the gender I'm just going to well
actually there's nothing good copy
system but I'm going to use my utils
which I just explained before and then
we're going to use this extremely good
Python library which is called
scikit-learn so scikit-learn implements
a bunch of machine learning algorithms
just basically you don't have to do
anything and what I've shown here this
is usually called like in machine
learning terms as a linear model and
it's pretty clear to see
it's just like trying to get like a very
simple explanation of the data and from
socket this is like no surprise in there
it's just important in her model right
cool so here I've like import er CSV
I'm going to use the utils to clean the
data so I'm just gonna do train right
and here I'm going to have to do a
couple of things so I'm I have to pass
this algorithm what is the desired
output which is usually called target
and it's quite easy to do this just to
survived and do values and then we have
to pass a set of information which are
called features which are basically what
we tell the machine algorithms that
these are the hints you have to figure
out stuff like we're like really kind of
like you know like the cousin which is
sort of like berates people like oh yeah
just like get this and do it I don't
really care like how you do it so the
way we're gonna do that we're just gonna
pass like some information like the
passenger class class like this the age
these sacs I mean we can pass you know
like the number of siblings and spouses
the parent and children I think that's
enough and just pass these values and
now we're going to create this object
which is called a classifier and it's
called a classifier because it just
needs to take one of these passengers
and decide like which one of these
buckets like he needs to assign to so
I'm just gonna call it a classifier and
we just take linear model logistic
regression yes cool and we just do
classifier fit we pass the features we
pass the target and actually maybe we
want to assign this to like another
variable so I'm just gonna do something
like this and now we can print like the
results of this classifier so basically
when as soon as I set fit and the
classify rest goes to through every row
of the data and tries to find like some
hidden relationships in the data and
then just as a way
like basically double checking if the
the thing is like doing anything at all
we can use like this score and we pass
the features in the target again and
this thing will print out like the
accuracy know from know from import
right
I don't know Python I said it cool and
you see it says like 0.79 percent so
like it's 79% which is better than our
like naive interpretation and I'm sure
that like if we add like some more
information let's say the fare and like
where they embarked probably algorithm
will do a better see basically we're
just like telling him okay like you have
like all these things to work with just
like find me a good explanation of this
and I go back to some drawings because
like when you see something like this I
think it's pretty clear for us okay like
this is the trend right but if we try to
fit the same line like through here like
we're human brain is like oh wait a
second like this doesn't look right you
know like the data is like showing like
a different behavior and like this is
usually known as a quadratic behavior so
like we as humans we have to say oh it's
basically something like this right it's
a curve and I don't want to trigger PTSD
again but like in math it's called like
a polynomial so usually it's like a
first-degree polynomial it's a straight
line it's the second-degree polynomial
it's like more of a curve and then you
go crazier and crazier
so no PTSD please but like there is
something in in a socket learn which
help you to do this and it's called
pre-processing and what we can do is to
take our linear features and transform
and combine them into setting
second-degree polynomials so basically
it's a way to say okay maybe our data
could be described battery with these
curves instead of straight lines so I'm
just going to need to accentuate this I
think it's something called polynomial
features they're pretty good names
- and here I'm going to create some
polynomial features am I'm going to do
Poli that fit transform and pass the
original features that we had okay and
here basically we can just like do the
same thing again we're going to do
actually we don't need to change the
classifier because we didn't override it
right so I'm just separated it's a
little bit and I'm going to print this
thing out on the polynomial features
poly features in the same thing here you
see like using the polynomial features
like a pretty big win so we started but
like as I said before like it's not like
really that much of a wind like
considering like what's like like it was
simply a human intention like intuition
goddess to write so I thought like this
is like yeah okay I mean computers are
work pretty well but like we humans like
don't suck that much unfortunately there
is like something which I haven't said
because like when you see like a code
like this they're like well this is like
really really easy right so like what's
the trick like why is like like your
neighbor like not doing machine learning
for fun and the reason is a lot of these
algorithms are a lot like black boxes so
you don't really get you understand too
much what's happening in them so I'm
going to show an example and then I'm
going to show some tools that we can use
to try to prevent these biases of the
machine every time you see I say biases
or the machine seems like some like dark
you know like sci-fi future so let me
just do something which is extract this
feature names I'm going to call these
feature names and then paste this okay
cool
and now I'm going to copy this into a
new thing which we'll call predict
decision tree paste here we won't need
the pre-processing or just need module
is called tree and basically what this
algorithm does is to create
simple decision tree so we will take a
look at the day that every row will take
look at like all the characteristic of
it and we try to build some sort of like
decision tree like a literal decision
tree so we'll start this is like the
biggest decision that like moves me or
not just me in a certain direction or
not and as you'll see like the like for
me it's like really simple I'm just
gonna do decision tree equals tree I
forgot the name of it decision tree
classifier decision tree classifier and
here you have to pass something which is
called random state one just because in
this way you initialize the decision
tree with some random values and
something which happens a lot in machine
learning because if you start a decision
through with 0 these optimization
algorithms are going to struggle a lot
because they're doing about derivatives
I didn't want to say that but they're
doing derivatives to try to improve
situation so if you start with 0
they have like basically no direction
where to go to instead you start with
random numbers it'll like nudge a little
bit like into the right direction
instead but for me as a user of the
library this like makes no difference
whatsoever so I'm just going to do a
decision tree underscore equals decision
tree dot feet and we have the feature
saying we have the names right and here
I'm going to do print decision tree
underscore score features names no names
not defined its called target and the
same here and it's 97 percent that's
really good right unfortunately not but
I wish would be like so good but
basically the reason why this thing I
think he almost got it right is because
machines are quite ruthless as we know
and if you just give machine free rein
he'll just like try to do like the
dumbest thing possible which means that
it will try to fit a very basic like the
the intuition of it it will try to fit a
very high order polynomial to it so you
will see something like this I will try
to fit a curve like this
and we are like what this makes no sense
right but the thing is seems like most
of these methods are numerical they
don't really you know like they don't
have like our sense of judgment so
they'll just try to fit as much as they
can and then since we trained this like
classifier on all the training data it's
always going to do okay I'm just trying
to like you know do my best and it's
going to come up like really weird
results like this so of course they
tried to came up with a to come up with
a lot of techniques to try to limit this
to try to fix this and one of the ways
is basically apply play hide-and-seek
with the algorithm so you're just gonna
intentionally withdraw some information
so I have this ten points but only going
to pass the Eiger than six points
because I know that the algorithm
otherwise is going to get like
overzealous and it's going to try to
read too much into the data but what I
want the algorithm to do is to try to
keep like a sort of like generalization
right and this would be like quite hard
to do it yourself but of course there is
an amazing model like a module in
scikit-learn
which is called model selection and I
mean I think it's like the general like
gist of the talk is just like learns
like you learn because it's amazing and
yeah but if you you take this thing and
there's a function which is called model
selection that cross Val the score which
is called a cross-validation score so as
I said before when you're withdrawing
information from the algorithm like in
machine learning turns the part of data
that you're not using well it's not
completely true but whatever just back
bear with me the part of data you're
hiding from the algorithm like it's this
journal names cross-validation set it's
not always true but bear with me and so
here you pass the decision tree you pass
the features you pass the target you
have to decide like a scoring like
algorithm for the thing in this case
we're going to use accuracy and then you
specify basically how many times he has
to do this operation right and now we're
going to print the scores and we're
going to print the average of the scores
as well and remember this is something
where we had 98
scent like accuracy before but if we
hide stuff from the algorithm the
algorithm actually reveals that this
yeah almost right you see like the
average of like these 50 runs was like
0.78 percent we're just not super bad
but it's basically just as good as like
the super simple approach that like my
cat probably could like come up with I
have a picture of my cat here I use this
yeah anyway so like a good way to try to
fix this is to try to create to
basically tell the algorithm well try
not to read too much into the data so
here there's like when you're creating
these a classifier you can specify some
information which is a max depth so
basically we won't try to create a tree
which is deeper than seven like levels
and then you can control also the sample
split so it's basically when he decides
that he has to branch out in this case
I'm just gonna say two and also in this
case I'm going to replace decision
underscore with genera
how do you spell generalized yeah and
it's one two three four five this looks
good so if I run this you'll see that
like other like generalized version of
the tree was like way less confident on
the first run is that like 88% which it
was like still higher than the average
when we tried to hide data from him but
Lee in general was like gave like a much
better performance than the like
over-optimistic one right and one of the
huge problems in machine learning is
that it's really hard to understand what
the machine is thinking and luckily
there's some really good tools
especially in decision trees which will
allow to visualize this information so I
have to remember the correct API but
it's something like tree export graph
this and you pass our generalized tree
underscore
you pass these feature names so that you
can like associate with something and we
say outfile equal tree dot and it's a
dot file right so if I run this it
worked I'm gonna switch to try to switch
to another shell I was in the shell okay
that's cool
and we see there's a tree dot it's here
and if we take a look at this is tree
dot whoa it's like not for humans still
but like since it's a dot file there's
this is amazing tool just called dot and
you can transform a dot into something
which we can process with our brains
which is a PNG and if I open that you'll
see this is what the algorithm sees I'm
going to zoom in if I can cool
say do you remember like what was like
our simple heuristic is the sax and in
in the process of cleaning up the data
we set sex to zero if you're male or one
if you're a female and you see that the
tree makes that like the top decision so
the decision tree understood that the
sex is like something really really
important and you see that it like
splits off the sample so like we have
891 here but then if your man we have
577 samples here while on the other
branch will only have 340 it's for 314
and then the immediate decision after
that is what is your age if you are kid
you have to go on this side and there's
only 24 deceased people here and instead
here there's like 500 and what's not be
seized but there's like only a subset so
the maximum like this is people and this
side could be 24 and here in the other
hand side will be 543 so in a sort of
way the algorithm understood like the
human notion of women and children first
right and it's here it's not like a joke
right it's like he actually built this
and it's an algorithm who did this like
just like by looking at the data
cool how much I don't have much time I
think that would be it
just small things so I've put like most
of this code on my github there's a repo
which is called Jack dice yeah so
there's also like all the instructions
to set it up like on Mac OS but I think
like the same thing just works on Ubuntu
or whatever you're using I'm going to
live tweet this technology so here is
the repo of no slides good
there's also more algorithms on the repo
because I couldn't fit like all the
material in here so for example
something which i think is super cool is
that they have this thing which is
called a grid search because like like
most of these algorithms have a lot of
parameters that you can fiddle with and
so they came up with this little thing
which just like dumb like in every
damned wavelet just like try out all
these different algorithms with like
different parameters and just figure out
which which is the value which works
best I think in this specific example it
doesn't really work that well because
you only have you know like 900 routes
but like in the real case example you'd
have you know 20,000 rows or 40,000 rows
so if you're Google you know billions of
billions of rows and actually like these
things like worked much better so I
think like you don't like even if you do
that yourself like don't get too you
know stuck into oh my god these are
things I'm working because machine
learning like I think a paper came out
five years ago we just said your
algorithm doesn't really matter that
much who has who has the most data wins
so yeah questions
come on I'm I mean I think someone said
they're not I'm not gonna leave like let
you guys leave if you're not asking
questions say it's a standoff yeah one
there that's how okay
as a developer I think a lot of people
is like me here with the know where to
start to do this stuff yeah and because
I tried with Coursera there's stuff like
that but they are too tutorial that's
and we have another kind of approach
that's it's fine but we can start to to
do this stuff but I think that the
teacher and that course is really good
because it says okay this is the math
but doesn't matter as long as you
understand the intuition between like
some of the machine learning concepts
that's fine and it's just like you just
search for a Coursera machine learning I
really recommend this course and this is
the guy who actually created the
Coursera this guy he's like the CTO of
Coursera and this is really really good
but something I have to admit is I stole
a lot of stuff for this talk from this
amazing website which is called Kegel
comm it's a data science competition
website so they do real stuff as well so
if your competitions you'll see some of
the top competitions have you know a
hundred thousand like $150,000 prize
right it's called Kegel calm and some of
the like this Titanic is one of the
challenges and for example this is like
where you get the data they just like
expose the CSVs
and there is also you can make a
submission so they also give you a test
set where they don't give you the answer
so you have to train your machine
learning algorithm and fight against
each other that would be the idea but
then the internet came along and people
you know like started to figure out the
real historical data so that their
algorithm would get a hundred percent
success rate so you see like the top the
tops of meters are like cheating a lot
and this is not actually what like data
science is supposed to
but anyway like that's the end of the
rent but if you go here there's like
some really really good Python notebooks
so if you take a look at I think it's
here say it season like you can use
Python because you are and they have
like really really good explanations
about everything so what I did at the
time is just like go through you know
they're like ten of them and just like
take a look at water they're like the
best techniques and the things which I
found more like more interesting like
something I'm really really interested
in personally neural networks but I
think like for example and on these
problems specifically it's not a good
fit for a neural network so like you
don't see like many people using it and
if they do the performance is not great
if you want to play with neural network
so there's another is really sort of a
classic problem which is the hand hand
written recognition task and that's
really cool because like you get to
write a program which reads something
like this and actually assigns it like
the correct class and it's like such a
it's like sort of the hello world of
data science and it was only invented 15
years ago by young Laocoon which now
which is now head of the Facebook AI
group but it's like a very very
classical task it's just like so
satisfying when you write the neural
network and you see that it's actually
recognizing handwritten digits
especially since you are developer so
you know how you did solve it otherwise
right you think about the digits you
think about the shapes they are you try
to run some stupid like image conversion
algorithms or like some algorithm to try
to rotate the like the number in the
right position ie you have like this way
of thinking and instead the neural
network just applies this sort of like
brute force it it's just like there you
go this is like the result and I think
the you know like the industry standards
for this problem now they have
ninety-nine point eight percent accuracy
and human beings have something like
ninety eight so in something like these
things are already unbeatable and they
have been unbeatable for the past 15
years so but it's really fun so I really
recommended they have a lot of like
examples in code there so if you want to
learn it's really good
so how do you decide which algorithm to
use do you just throw all the algorithm
set the problem and look at the Mach
numbers or are there any heuristics yeah
that's the hard question because
basically I mean from what I've seen I'm
not an expert whatsoever but from what
I've seen the people who are expert will
just tell you well over time you'll
learn which algorithm works best with
what problem so a lot of these
competitions on Kegel for example I
haven't seen like good applications of
neural networks and I'm kind of pissed
at that because I really want to see
like how like one of these like
real-world problems can be solved using
machine learning but like there are some
really good papers about you know like
how like you use like neural networks in
image recognition and stuff like that so
I think there's a sort of like general
feeling the community which are the best
algorithms like which solve like some
sort of problem and every year they like
publish like a crapload of papers like
trying to prove that their algorithm
works the best well I think I'll read
like five years ago they sort of came up
with the idea that the best algorithm
doesn't really matter that much so they
they did like this really like serious
experiment which is just like ran you
know like ten different algorithms and
they changed the how much data they had
and they started when like they had a
lot of data like all the algorithms will
pretty much like converge the same point
of performance so it's mostly like how
much you can afford like what is like
your you know like machine learning
architecture but they seemed like most
people care just about like how much raw
data you have and I think like since I
learned this I'm much more understanding
of like why Facebook where Google are so
interested in your data because that's
the real valuable stuff right like a lot
of like data set that we have just like
to play around are like you know a
thousand two thousand three thousand
data sets like rows and I'm sure that
the internal data said that Google
engineers have to train their algorithms
is just incredible right and that's like
the real value of it and that's why
they're much
learning algorithms worked so much
better than the rest but they're really
smart you know they have also a lot of
data is it good no more questions okay
thank you thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>