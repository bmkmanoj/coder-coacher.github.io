<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Gentle Introduction To Deep Learning with TensorFlow [Intermediate Level] | Coder Coacher - Coaching Coders</title><meta content="A Gentle Introduction To Deep Learning with TensorFlow [Intermediate Level] - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Gentle Introduction To Deep Learning with TensorFlow [Intermediate Level]</b></h2><h5 class="post__date">2018-04-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6g0lPlHc-E8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hi everybody thanks for coming so
welcome to a gentle introduction to deep
learning and this is going to be an
intermediate level talk so I'm going to
assume that you know the concepts of
supervised machine learning and are
familiar with linear and logistic
regression so those are going to be our
starting point and our target end point
today is going to be an in-depth
understanding of the most fundamental
class of neural networks feed-forward
neural networks which looks something
like this
and we're going to talk about how
they're constructed why they work and
how to train and optimize them so along
this completely made up deep learning
learning curve I'm gonna put our target
here and the way in which I hope to make
this talk gentle is by convincing you
that if you meet the prerequisites for
this talk then you're not here or here
we actually here
in other words if you know logistic
regression you are about two tiny steps
away from understanding deep learning to
put things another way if traditional
machine learning is a hammer then deep
learning is just another fancier hammer
it might not it might not look like a
hammer at first but you know you look at
that thing you can pick that thing up we
could start bashing things with it it
uses the same technology sort of based
the same laws of physics but at the same
time it is a pretty weird hammer has all
these extra knobs and whistles and we're
going to talk about what those extra
knobs and whistles bias in terms of
power and performance and we're going to
learn how to do all this intensive flow
which is an open source deep learning
toolkit out of Google so let's talk
about linear regression and in this
section we're going to code up a linear
regressor from scratch using numpy and
as we go through the section I want you
to focus not so much on the code but on
the pieces the ingredients what what
they are and how they go together so
here is a typical linear regression
problem we're trying to predict the
prices of individual houses and we're
given three pieces of information of
each house in other words three features
floor area distance from public
transport and number of rooms and we're
going to represent these features in a
matrix with as many rows as we have
houses and three columns
one for each of our input features and
we'll call them matrix X and what we're
trying to predict is this vector Y which
represents the housing prices and here's
what that looks like in numpy we're just
going to use numpy arrays to represent
those next we have to consider our model
the model is their family of functions
that we're going to consider in mapping
X to Y and since this is linear
regression what we're going to do is
multiply each feature by a weight and
add them up and then we're going to add
an additional intercept to get our final
estimate and whether it corresponds to
geometrically is simply drawing a line
of best fit through the data so the
parameters of this model will be the
three weights one for each feature and
the intercept and the key operation of
this model will be matrix multiplication
of X by the weights followed by addition
of the intercept element-wise to get our
final prediction so that's what that
looks like in Empire
now the next ingredient we'll need is a
cost function also called a loss
function and we need this to measure how
good or bad a set of parameters is how
close our predictions are getting to the
actual values for example this is a
really badly fit line we can see that
but how do we measure it what we're
going to do is to take the difference
between the prediction and the actual
value and squaring that okay so this
looks a lot better because the length of
those lines is a lot shorter and that's
what it looks like an M pi now we need
to actually find the parameters that
give us the best fit in other words we
want to hold x and y constant and adjust
our parameters to minimize
the cost each set of parameters will
yield a cost so we can plot cost against
parameter values so the x axis here is
parameter values y axis is a cost our
goal in optimization is to find the
parameters that correspond to that
lowest point and we're going to do that
by trial and error and by this I don't
mean just trying random sets of
parameters and seeing what works best
but the kind of trial and error you do
when you're safe practicing how to shoot
hoops and you're trying to adjust your
angle and your shooting you're missing
by a couple of inches you're too far to
the right so you adjust your angle to
the left you try again and that's what
we're going to do also so what we'll do
is try a set of parameters we'll
calculate our cost and then we will
follow the gradient of the cost curve at
that point down towards the minimum this
process is called gradient descent and
so we're gonna just move along the cost
curve in this way so we need to be able
to calculate the gradient of our cost or
error and that's depicted at epsilon
here with respect to each of the weights
and the intercept those are our goals
applying the chain rule we can break
them up into two pieces so the gradient
of the cost with respect to the
predicted y y hat and the gradient of Y
hat with respect to the weight so let's
calculate those the gradient of Y hat
with respect to W naught and say it's
pretty simple so all of the cop terms
are constant with respect to W naught so
except for the one on the left so all of
the others go to zero and we're left
with X naught for the second gradient
we're going to just bring down the power
and then apply the chain rule internally
to bring out a negative sign so that's
the gradient of the error of respect to
Y hat so to get our final desired
gradient we just multiply those together
to get this expression and this goes for
all of the weights as for the intercept
B we can consider that a special weight
where the X there corresponds to always
takes the value of one so we can just
substitute
one into X in that previous equation so
this is a form the gradient will take
with respect to B and that's how the
code will look like in um PI we first
calculate the Delta of between the true
Y and our predicted Y y hat and then we
just calculate the gradients
correspondingly and then what we want to
do is update the parameters we want to
move the weights in the direction of the
gradient and we do that by subtracting
the gradient from the way now but this
is a possible problem here because just
like when you're practicing basketball
you may over correct you're too far to
the right yeah just your angle to the
left but you wind up throwing your ball
too far to the left so you move right
and now you've overshot in the other
direction and maybe you're getting angry
and angry with yourself so you want it
even more wildly off as time goes on and
we can do this in gradient descent also
and it's called overshoot or you might
have the opposite problem you're too
timid and making your corrections so it
takes you forever to get to the minimum
you converge really really slowly and if
you have a cost curve this uglier than
this with lots of local minima if you're
taking steps that are too small you may
get stuck inside that local minimum so
that's a bad situation so what we're
going to do is to try and be Goldilocks
we're going to aim for something in
between those two and we regulate this
how big of a step we take using a hyper
parameter called the learning rate and
the larger the learning rate the bigger
the step you take putting all that
together here's how training goes
whatever our current weights and
intercept are we calculate our
prediction then we calculate our error
we compute our gradients and we update
up parameters by a gradient descent that
was a single run of training so the
entire training process involves first
initializing our parameters and doing
some number of training rounds whatever
the ways to intercept are at the end
that's our final model that we're going
to use to predict testing is going to be
really simple we get our estimate and
find
and figure out how far off we were on
average and on this particular housing
data set we were about six thousand
dollars off the house okay so you may be
wondering at this point I came here to
hear about the learning and neural
networks why are we doing something so
basic as linear regression and the
reason for that is surprise we actually
just made a neural network linear
regression is one of the simplest
possible neural networks it's so simple
that we don't even call it that because
it preceded neural networks but if you
look at the definition of a neural
network the inner regression fits the
bill exactly we have an input layer
consisting of those 3 X 2 X sub I input
neurons and we have an output layer
consisting of a single neuron and we
have weights on the edges between those
neurons that's exactly what a neural
network is so now we know that linear
regression is simply a neural network in
disguise we can rewrite it in tensorflow
and what we're going to do is to take
those seven ingredients that we went
through and numpy and just recast each
of them intensive flow so ingredient 1
inputs so already this looks very
different instead of supplying the data
directly in numpy arrays we're gonna
have something called placeholders and
this X placeholder says I'm gonna be a
matrix of floats and I'll have three
columns the none here means that I'm
going to push through a variable number
of houses each time if you want you can
specify a specific number here but then
you'll be stuck with it you always have
to put through like 60 houses at a time
so for flexibility we'll just say none
similarly the Y placeholder corresponds
to a single value so it will be a single
column our parameters will be
represented by 10 to flow of variables
so we're mapping three neurons to one so
the shape of our weights would be three
rows by one column and we can specify
here how we want to initialize our
weights which will sample from a random
normal distribution and the intercept
we're going to set to zero our operation
will be matrix multiplication
followed by addition and our cost
function just looks like this
reduce me and just means mean now the
optimization step will specify that
we're using gradient descent with a
certain learning rate and that the
quantity we want to minimize is the cost
that we just define in the previous
slide now for the training process so
first of all notice that we're going to
do this within a tensor flow session
intensive flow nothing happens outside
of a session all you can do is define
variables and it's only within a session
that you can start writing to the CPU or
GPU and performing computations you
can't even add two numbers intensive
flow without going into a session okay
the next thing we do is to initialize
the variables according to how we define
them earlier and now we're going to go
through the actual data so extreme and
white rain here are actual numpy arrays
and we're going to use mini bash
training meaning that we will random to
shuffle the data and feed the data
through small batch by small batch and
we pass these batches into the optimizer
inserting them into the respect to taste
holders says training so here's all of
that previous tensorflow code in one
place and I want you to notice a couple
of things so first of all remember all
of that math that we did to calculate
the gradients so the numpy code that
came out of that is gone okay it's
disappeared the other thing is that the
code is divided into two parts the part
outside the session and the part inside
the session and I want you to think of
that first part as like the blueprints
for something well the part within the
session is like actually building that
thing and that thing that we're building
is called the computation graph and this
is where we take all of our variables
all of our operations all our
placeholders and sequence them together
so here we have the dot product and the
addition of the intercept but that's not
all the computation that we need to do
we also need to compute the error so
let's add that on
okay so what do we do with the
competition graph so first we do a
process called forward propagation we
take out current weights and the X's and
Y's that got fed through and propagated
them through the graph by performing the
designated operations so for Ford you
get Y hat and then compute the error and
that corresponds to these two lines from
our numpy code next we need to calculate
the gradient of the cost with respect to
each of our variables and this process
is called back propagation or back prop
for short so we started at the end and
work backwards first off we have the
derivative of the error with respect to
the error and that's just going to be 1
and from this point on what we're going
to do is calculate the local gradient at
each point and multiply it by the
gradient computed up to that point so
let's work through a concrete example
the function here is just taking the
square the derivative of that is just 2
Delta Delta here was minus 2 so our
local gradient was negative 4 and we
multiply that by the gradient calculated
so far 1 and so the gradient of the
error of respect to Delta is going to be
minus 4 and we're just going to do that
over and over again back propagating
through the graph you're welcome to look
at download the slides later and take
them and I work through it yourself and
finally we get that the gradient from
respect to W naught is negative 8 I mean
so we can just check right that's 2
minus 2 times the Delta minus 2 times
its corresponding X naught also minus 2
so that's minus 8 so that corresponds to
what we did at numpy ok lastly we have
to update the variables so let's just
drop everything that is in a variable
and then we just take the weight without
B naught 2 and we update that to the top
number minus the learning rate times the
bottom number which was the gradient and
we get our new weight
can do that for all of the weights and
the intercept so that course wants to
these two lines in on that pike code and
I just want to take a moment here to
appreciate how much work tends to flow
save this so all those lines of code in
the previous slide basically correspond
to this one line of tensorflow code once
we define the computation graph which is
implicitly encoded in the optimizer
variable then all of the steps within
the training were handled by tensorflow
including the grading computation which
was a very painful in the case of linear
regression but it can get tedious really
fast once we start adding more layers
and operations to our model so thank you
thanks participa
all right our last step is going to be
testing so within the same session we
run a separate set of data X tests
through the model to get our predictions
and we compute the error
okay so that was linear regression but
what if we want to do something pretty
different where we want to do
classification so an example
classification problem is the emne
status set these are small images of
handwritten digits 0 through 9 and our
features are the values of the pixels
and we're trying to predict which digit
is which now before we get to the 10 Way
classification case let's talk about how
we would tackle this if we were just
doing binary classification we have a
bunch of samples that are positive and a
bunch they're negative and we want to be
able to classify them and we can do this
using logistic regression our model will
be this so first take a weighted sum of
the features and add a number that will
call the bias this was sown a lot like
the inner regression I said that we give
the output a funny name the loggia then
we'll convert the logit to a probability
of belonging to the positive class via
the logistic sigmoid function so this is
what this looks like in neural network
graphical style we compute a lot logit
and then apply this long non linear
activation function which I'll depict
with this red semicircle
and this is what the logistic sigmoid
function looks like and their key thing
to note is that it is between 0 &amp;amp; 1 so
it gives us something that looks like a
probability so how do exactly do we do
classification with this so we'll take
0.5 as I'll cut off if the probability
is greater than 0.5 with a clearer
sample positive otherwise is negative
and the further away you are from the
line in the positive direction the more
likely you are to be a positive sample
okay now let's go back to the 10
dimensional problem we'll have 10
Euron's in our output layer
corresponding to each digit and
therefore we'll have 10 times the number
of weights and 10 different bias terms
we'll also need a way to turn those 10
logits into probabilities we can't just
apply the logistic function to each of
those logits because that won't give you
numbers that sum up to 1 instead we're
going to use the softmax function which
is just the multinomial version of the
logistic sigmoid function so it takes
all of these load rates and transforms
them into a probability distribution
okay so that's the graphical
representation of that the boss is just
to show that the e is this so it's red
so it's the same function but the ball
shows that is operating on all of those
neurons at once and we can start coding
all right so our X placeholder is going
to have 784 columns that's because our
images are 28 by 28 pixels and we're
going to use one-hot vectors to encode
our digits with a 1 in the position
corresponding to the correct digital now
for the variables so we're taking 784
input neurons to 10 output neurons so
weight matrix will be 784 by 10 and we
have ten separate biases ones one for
each output neuron our operation is
going to be matrix multiplication again
and you're probably thinking wait we're
missing one operation what happens to
softmax but remember from the
computation graph that the model and the
cost functions sort of meld into each
other so we're just going to push that
to the cost function so this is the cost
function we're going to use softmax
cross-entropy
and you can see that this particular
function expect slow dance and does the
softmax internally if we computed the
softmax in the operations part and then
supply the probabilities to this
function will be implicitly during the
soft - twice and that's wrong okay this
cross-entropy
incidentally is a crop as a cost
function that's very commonly used in
classification and what it basically
says is whatever the correct wires I
want the probability of being that Y to
be as close to one as possible and it
imposes a logarithmic cost for your
distance as you go away from one okay
optimization our optimization code is
exactly the same as a linear regression
and ditto with the training code testing
is a little bit different because when
we compute how accurate our
classification algorithm is we don't
want to use the vector of probabilities
we want to get back a one hot vector
with our predicted digit so we'll define
a new operation called predict that
takes the Arg max of the loads so we run
our test data through this operation and
get the predictions and we can compute
our accuracy which in this case is
ninety two point five percent
this may sound pretty good but it turns
out that ninety two point five percent
for M miss is pretty bad the state of
the art on this task is upwards of 99
percent and one reason for this is that
we're using a linear model and linear
models are pretty weak so here's
something that we can't we can't
classify using a linear model when all
you can do is draw a straight line
you can't approximate a function like
exclusive-or and you can't do something
like concentric circles either so what
can we do well I've heard that there's
this magic thing called deep learning so
we're going to try to add to go deeper
and see whether we get a good result so
what we're going to do is to add a
hidden layer to our neural network
it's called hidden because we have no
idea what its values are supposed to be
we know what our X's and Y's are
but we have no idea what about the
values of those internal neurons so
we're going to need two sets of weights
and biases and we'll do two rounds of
matrix multiplications the rest of the
code is just the same so let's check on
our results okay hmm
wait a minute so I was told the going
deeper was going to help but my accuracy
actually went down what gives
it's deep learning just hype so the
problem is that a linear transformation
of a linear transformation it's still a
linear transformation we need a final
way to add non-linearity to the system
and we really know how to do that right
so before we applied a nonlinear
activation function to our output
neurons now we just need to do the same
thing for our hidden neurons and there's
a whole bunch of nonlinear activation
functions that you can consider some of
them work better than others and the one
on the right which is called rectified
linear units or relu for short it's
pretty popular so we'll use that okay so
we'll just amend our operations to apply
relu to the loader's of the hidden layer
and yay Oh accuracy went up so what
exactly do the hidden layer by us well
it can classify things like exclusive-or
so here's what the classification
boundary looks like and I think this is
with four hidden neurons we can also
classify concentric circles with three
hidden neurons so let's take a look at
how classification boundaries change as
we add more hidden neurons so this is a
data set that's a little bit like XOR
but is three by three and this is why
the classification boundaries look like
with two neurons and you can see that as
we add neurons our classification bound
gets more and more complex until we can
perfectly classify everything so what we
did here was to transform our 2d space
into a 5d space where the positive and
negative samples could be linearly
separated so we saw that we could make
our classification boundary more and
more complex by adding neurons to the
hidden layer and it turns out that
there's a theorem that says you can
approximate basically any interesting
function using a single hidden layer you
may need a lot of hidden neurons and it
may be almost impossible to actually
train but theoretically it exists okay
how are we deep learning yet know so we
only have one hidden layer and you don't
qualify as deep until you have at least
two hidden layers so I'm sure you can
guess by now how to define the variables
and as for the operations we just need
to add another round of matrix
multiplication and reloj okay just a
couple of slides ago we said using a
single hidden layer we can approximate
just about any function so why would we
ever need to add more layers and there
are three reasons for this so the first
reason is that deeper networks are more
powerful so there exist functions that
can be approximated in a deep network
with say K layers containing a number of
neurons that's polynomial in the number
of inputs however if we take even one of
those layers away we have K minus 1
layers we will need an exponential
number of neurons you know hidden layers
to be able to approximate the exact same
function the second point is really a
bit more about narrow layers but deep
and narrow sort of go together so
narrowing networks a less prone to
overfitting and when I say overfitting I
mean something like this green boundary
over here which is so determined to get
each and every point in the training
data right that it sacrifices
generalizability
now the thing is if you're funneling
your data through a narrow layer you're
going to have to make some tough choices
about what information to pass through
you can't just say I'm gonna allocate
these five neurons to take care of that
one outlier instead you have to figure
out how to communicate the best features
of your the most useful features of your
data as best you can when passing the
information on to the next layer
incidentally this is the principle
behind Auto encoding networks which are
a neural network where you're just
trying to impregnate your input data so
this sounds really trivial to do right
except that you're pushing it through
this really narrow layer which forces
you to come up with a compressed
representation of it and then you can
use the compressed representation in
place of your sparse representation when
doing some other tasks okay onto the
third reason and this is probably the
most important reason for going deep so
deep networks learn a hierarchical
feature representations we can see this
most clearly when we look at the kinds
of neural networks that used an image
classification we input the pixels and
get out a determination of the objects
seen in the image and if you examine the
kinds of features that you Slayer is
detecting you'll see that they build on
each other so the first hidden layer is
detecting things like edges and the next
layer is putting together edges to find
things like corners and then at the next
layer maybe have to round things over a
curve and it says aha I see a face and
up and we go up and up and so we can say
this is a person and one trend that we
see as a result of this property of deep
learning is a movement towards end to
end learning where you feed in the
rawest form of your data like pixels and
characters into your system instead of
first computing hand engineered features
the deep learning system learns all of
the levels of the features for you okay
so let's go deeper
all right that didn't really work out so
well and when this happens to you there
are a couple of things you should
consider so first of all is this a
problem that requires a deep network
maybe solving the problem requires
combining the features in very simple
ways in which case a deep network
doesn't really do anything for you
the other question which a suspect is
more often the problem for most of us is
do I have enough data to train a deep
network to go deep we need a lot of data
and M&amp;amp;S is not a large data set if you
do have a large enough data set however
you can expect your test accuracy to
gradually increase with the number of
layers but we don't have that instead
what we see is that we have overfitting
our training accuracy increased but our
test accuracy went down and I said
before that overfitting was something
shallow networks with wide layers were
more prone to but you can also get
overfitting with increasing layers
because that increases our model
complexity so what do we do we do
regularly regularization so the idea
behind regularization is this up till
now our data has always been in the
driver seat whatever the data says goes
if I have an outlier over here and
there's no other data points to argue
against it I'm going to contort my
boundary to accommodate that layer at
the outlier now what we're going to do
is to put the brakes on the Train on the
training data using regularization and
we're going to do that by enforcing
constraints on the parameters that we
learn so you're probably familiar with
l1 and l2 regular regularization because
you also see them used in linear and
logistic regression SVM's cetera and
what l2 regel regularization says is
simply I want my weights to be small and
it does that by imposing a cost or loss
on the weights that's the sum of the
squares of the ways so the larger the
way it's the bigger that cost
and we'll add that regularization loss
to our existing data loss which we
already encoded into the cost function
and we have another hyper parameter here
that determines how tightly releasing
the data and here are the results that's
pretty good now let's talk about a
different regularization method which is
called dropout this isn't really
applicable to linear methods but it is
something that we can do once we have
hidden layers and what we're gonna do is
this at each training step we're going
to randomly knock out half of our hidden
neurons and at first glance this may
seem like a really crazy idea why would
we want to forfeit half of the modeling
power of that layer why would we want to
lose half of the information in our
weights well we do it because it works
and here are some reasons people cite
for why it works so firstly every time
we drop some neurons out it's like we're
building a completely new prediction
model and when in the end we take all of
the neurons together it's like we're
averaging together all of those models
so if you're familiar with ensemble
learning it's just like that I said they
are doing it internally the second
reason is that it forces useful features
to repeat themselves and that makes our
network more robust the third reason is
that well you can't have a good
conspiracy if your co-conspirator might
drop out at any time so hidden neurons
must be individually useful and again we
can't have three neurons over here
corresponding to accommodate an outlier
because one or two of them may be
missing at any time okay
so during training we drop out half the
neurons but at test time we want to keep
all of those hidden neurons but that
creates a problem right I'll notice a
huge point are going to be twice as big
as they were in training and to solve
that problem what we're going to do is
that
training time for all of the neurons
that stay at alive will multiply all the
load loads by two okay
so now let's look at how we do that
intensive flow so the first thing we do
is to add a new placeholder and what the
placeholder does is to define the
probability of keeping a neuron and we
usually set that to 0.5 and then we're
going to add a dropout operation between
the hidden layer and the output layer
supplying it the key probability and
during training we pass it a key
probability of 0.5 which drops out half
of the neurons and during test time we
supply it a key probability of 1.0 and
tensorflow will handle all of the
dropping out of the neurons and the
scaling of the logits another thing to
note is that training is generally a lot
slower with dropout because you're
considering all of these different
models so you want to bump up your
number of training rounds ok so this was
the accuracy that I got a little bit
better all right so where do we go from
here
so we saw that there were a number of
ingredients we had to define and
consider in every single model that we
created these ingredients also
constitute a good roadmap for exploring
deep learning further so we're going to
ignore placeholders and cost function
because those are pretty much problem
driven those are all their training and
testing don't differ much by problem so
let's look at the others in terms of
variables we can consider varying the
number of hidden layers and the number
of hidden neurons per layer we can also
explore different methods of
initializing the variables so here I
used random normal and I use the
constant initializer but you can try
things like yet random uniform truncated
normal etc you can also consider
different nonlinear activation functions
so relu is the current recommended
starting point but you kind of play
around with all these others
you can also consider an entirely
different architecture than feedforward
neural networks if you're doing anything
with images take a look at convolution
you're on your neural networks and if
you're doing anything with text
sequences or time series then look at
recurrent neural networks okay
we used gradient descent exclusively in
this talk but it's actually one of the
slowest converging optimization problems
and this Jeff is the red straggler and
the current recommended one to try first
is add as the Adam optimizer so just
give that a shot and so it's it's all
intensive flow lastly there are a bunch
of regularization / optimization
optimization techniques that can help
with training and reducing overfitting
so in this talk we looked at l2
regularization and dropout but also
check out l1 or batch norm and they are
norm also in this talk I used the tensor
flow library exclusively but there are
lots and lots and lots of other the
learning tool kits out there and these
are just some of the that I've heard
good things about so you can try those
all of the steps that we defined before
will will apply also in other toolkits I
also want to give a plug for Karis so
this is a higher-level library that sits
atop of tensorflow and there's also a
Theano back-end and caris is sort of 210
to flow as scikit-learn is to numpy and
as some simplifies things considerably
so this is how the tensor flow code that
we've been using they've been working
with so far it translates to Kharis and
hopefully with the background provided
in this talk you can go through this and
understand what's happening in every
line intuitively ok final thoughts first
is that if you're familiar with
traditional ml I hope I've convinced you
that you can do deep learning but in
order to devoting you will need data
lots of it
so what I recommend is trying
traditional ml first and just seeing
whether it works well enough for you and
if it doesn't then go on to try a deep
learning and just go forth an experiment
thank you
thank you everybody we probably got time
for one question if anyone has a
question there are microphones in the
aisles just over there oh oh in a
statistical analysis you usually need a
reason to choose one tool or one
particular analysis technique over
another do you need that here if you
were to pick a different activation
function or any of the options you have
here she just play with them until you
get good accuracy or do you need to kind
of have a justification for that okay
I'm sorry can you just say that again
really slowly in statistics you
typically need a reason to use a
particular approach if you're going to
take the log of your data you have to
some theoretical reason for that yeah
you need a similar thing here or can you
just use a different activation function
because it gets better accuracy and
that's good enough okay so the question
was about other basically considered
reasons for using one activation
function over another and there are some
so let me see can I go back okay all
right so what okay well okay I'm gonna
I'm not gonna go for the slide what you
can do is so there are reasons for
certain activation functions being
better than the others so for example
hyperbolic tangent is like strictly
better than sigmoid function and I don't
actually exactly remember the reason for
that but one reason that people use relu
over like the sigmoid and the hyperbolic
tangent functions is that it has like
more room to grow it doesn't get capped
at between minus 1 and 1 or between 0
and 1 and as a result of that it's it's
better for doing the learning because
you can like propagate the gradients
better along the various layers whereas
if you're doing you're doing the same
thing with the cat activation functions
then you're going to have a problem
where everything gets squished
too much and you don't actually get a
lot of movement on your gradients okay
that it again Michelle</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>