<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>On-device Machine Learning With TensorFlow | Coder Coacher - Coaching Coders</title><meta content="On-device Machine Learning With TensorFlow - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>On-device Machine Learning With TensorFlow</b></h2><h5 class="post__date">2018-02-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vzBpSlexTVY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today I want to talk to you guys about
how to get machine learning on to your
physical devices when there is no
network connectivity and convince you
why you would want to do that why you
would actually prefer even with network
connectivity to leave it aside perhaps
in certain situations but to get there I
want to start back we're gonna go back
in time back to when the computer first
came about right that started this
computing revolution that we're in today
but today we're in what we call an AI
first world how did we get here well
first we had the computer and that gave
us computing then the internet came
right the internet connected all the
computers together and I want to point
out that the internet did not wipe out
the computer right the computer is still
used today
then came mobile the mobile revolution
can brought the Internet to everyone it
brought the connected computers into our
pockets and again we see that mobile did
not wipe out the Internet we still use
the Internet it's still strong with an
IP version 6 we're running out of IP
addresses and so too will a I not
replace mobile but build on top of it
and so I see mobile has a key foundation
for the core of how we will interact
with AI in the years to come and so to
that end I want to show you guys one
approach for integrating AI into mobile
devices and bring amazing user
experiences today over half of the
fortune 500 globally have disappeared
the company's kaput gone since 2000 and
so how can we not have that situation
first of all but also what will happen
to the other half right it's the
companies who embrace AI
these startups who are well nowadays all
the startups are saying we are AI
startup everyone is a start-up but a few
short years ago machine learning and AI
was something that companies would add
on to their product they would say oh
yeah we do a little machine learning
here on the side right but now I root
everyone's doing it it's it's super
popular and for the most part people
trained on the server right server has a
lot of compute power it makes sense and
I'm now going to refute that because it
makes sense Mobile is not a compute
powerful platform so we train on the
server that's fine but what if we did
the predictions on the mobile on mobile
what if we did inference there instead
of serving them from a server web server
and in particular this approach can lead
to amazing user experiences I want to
just show with one illustration example
this is a Google Translate and it has
the ability to overlay the translation
directly in the image that you see now
you can tell just from the the speed
that it can do this that it is
definitely not happening over the
network right the video is not being
streamed to Google servers and then sent
back that's why it works when you are
offline that works it works on a boat it
works underwater well if your phone can
be underwater it would even probably
would work in space and having access to
AI on your phone wherever you go that is
responsive and accurate that can really
change things on a global scale
for mobile for the internet and for
computing so how can we make something
like that right machine learning is hard
enough by itself then put it on mobile I
mean mobile apps aren't easy either
and so combining those that can be a
real challenge
so let me start by showing you guys what
a little demo of what I've kind of put
together and then we'll talk through how
we might build something like this it's
a simple demo just mainly just to
demonstrate the core kind of
functionality and what I've got here is
a phone and I have a little app if we
switch over to the camera here I have on
the table a few different candies let's
see what we see here oh great and so
let's see you guys see this okay so what
I'm gonna do is what we'll take some of
these away and if the lighting is good
you know here we have a a Reese's Cup
right and we can see here know that as
the image kind of isolates down it
recognizes that no I also have a smaller
Reese's Cup which just fell on the floor
okay so we have a smaller Reese's Cup
here and you know and we it will switch
over and recognize that now you might
say well how do I know that he's not
cheating by sending all these images
over the web right well let me first of
all there's no Wi-Fi here secondly let's
let's just go ahead and hit airplane
mode right as well and we'll see here
that you know everything continues to
work just fine these are some more
peanut butter cups I'm a big fan of
peanut butter and so let's push these
guys away and so here we have a shot of
the Justin's see here it says white
chocolate peanut butter cups and you
know one of my hand enters the frame it
may get upset candy is a little bit bent
out of shape from its days inside the
suitcase but you know you can see that
it clearly recognizes that versus a very
similar packaging right but this is milk
chocolate this is a milk chocolate
peanut butter cup and and this one also
updates you know it updates right away
you can see the the confidence and then
we here we have some juicy fruit gum
just for variety you know some people
don't like peanut butter I understand
that so that's that's the gist of the
demo here and so if we switch back to
the slides
we can think about how we might build
something like this how do we go from
collecting data to having an app that
can recognize images in real time custom
images right I just I chose these pretty
arbitrarily if you were to take any
generic machine learning visual model
and pointed them at this
it might take candy candy bar maybe it
even says chocolate maybe it just says
yellow but how can you get something to
recognize something that's specific you
know imagine having something recognize
your particular products your whether
it's your brand things in your home and
so this is my are kind of guidelines
here this is what will follow this our
little nap this is our road map and what
we're gonna do is we're gonna try to
fill in each of these blocks and go from
gathering data to having an application
so the first thing you got to do is
collect data my data collection is as we
all know the most fun step of machine
learning now I've found a bit of a
shortcut for you instead of you know
collecting lots of pictures and then
trimming them down and then labeling
them and it would just be a lot of work
right it's a lot of pictures so maybe we
can shoot some video we shoot some video
and we only take the video of that
particular object so I go through each
one now you can see there I have one of
the the peanut butter cups and we go
through each one and we capture a video
and what's nice about that is that
entire video every single frame is a
picture of that object hopefully from a
different angle so keep that camera
moving and then what we can do is we can
well we chop that up right there's a
command line tool called ffmpeg and
there's lots of tools ways you can chop
up a video that's a solved problem and
we put those pictures all into one place
all together in one folder for each of
the objects you want to recognize so so
one folder for your juicy fruit one
folder for your milk chocolate peanut
butter cups one folder
white chocolate ones and so on and so
now we've effectively just labeled all
of the images right we didn't have to
come up with any sophisticated way to
label it for us with some system so
that's great so we have folders of
images what's next well we take these
pictures and we send them to training
right so in my particular case I
uploaded them to the cloud because my
MacBook was running out of space form
all the images and pictures and so I
zipped them up put them in the cloud and
I happen to do my training in the cloud
you can do them on your data center you
can do them on your local machine if you
have a lot of storage and the training
we did is using transferred learning now
this speaker before me mentioned
transfer learning so I won't go too much
into detail about it but I do have a
kind of little story a little analogy
that I recently accidentally discovered
I was playing with a puzzle this is a
jigsaw puzzle right lots of pieces and
and this is the final picture this is
the box showing what I was supposed to
build and I'm not a very good jigsaw
puzzle person I kind of struggle with it
but as I was struggling through this I
realized you know there's some good
tricks in here I could do first of all I
could separate the the pieces with no
images the white pieces from the
everything else right so I moved all of
the white pieces to one side okay so
that's the obvious step first step but
then what how do we start from there I
also noticed that in this image the
roofs all the individual roofs are very
distinctly patterned and so I said ah I
know I can look for pieces with this
pattern and with that I can begin to put
those together those were easy to find I
could recognize those patterns so my
brains neural network through my eyes
could find those individual small pieces
and combine them together and say ah
there's a roof similarly I noticed in
the stairs the stairs have a distinct
pattern they're parallel lines there's
some of those X's there and I could find
the pieces that kind of looked similar
and begin to squeeze those together
and eventually get that together and
instantly everything else came together
well there was a few more steps right
but that that's as far as I got the edge
pieces they're so hard so so a
convolutional neural network kind of
works in a similar way I use transfer
learning with the inception model which
is a model that the Google brain team
created a few years ago it has 48 layers
and to give you some perspective on how
big or how small that might be just a
few years ago I think it was 2011 or
2012 it was Impractical to train a
neural network that was more than four
layers deep the year before
inception v3 came out the model that won
the International image recognition
competition called imagenet that had 22
layers so in the inception of e3 model
really was a giant leap ahead right more
than double the number of layers it
really showcased the improvements in
both computational power that was
available as well as network design so
we can use that wonderful research and
take it for our advantage so we trained
the last layer right of the network and
leave everything else intact this means
that everything in the visual part of
recognizing those pieces recognizing the
little bits the principal pieces are
already there in place for us so you
have a great model you can train it but
when you're done you look at your file
system and you say wow this model is 84
megabytes
I'm trying to put this in a mobile app
can you help me out sure thing we're
gonna optimize it for mobile what can we
do to shrink down a model well handily
enough there is a graph transform tool
and what that's gonna do for us there's
a couple of steps in there that we can
do the first thing is a technique called
quantizing or quantization and the
floating-point numbers those 32-bit
floating-point numbers that are taking
up all this space we're gonna shrink
that down to just eight bits
how can we get away with this we're
gonna lose so much accuracy right
well not necessarily luckily neural
networks are designed for fuzziness in
their inputs so by quantizing down to
eight bits and and that's just by
rounding but like actually saying these
numbers are close enough we're gonna
make them all kind of say this number
and then this number so we then say the
range we're gonna split that out but
into 256 pieces so if the range of
values is say negative ten to thirty
within there when they divided up into
256 little steps and so that gives you a
little more accuracy than just purely
changing it directly to 8-bit and
additionally that means when you do
compression those values are the same
and so that's what it lets you go down
literally for X so you go from 84
megabytes down to around 20 21 megabytes
and one small additional thing you can
do is take away the parts of the graph
the parts of the graph that you don't
need anymore for prediction there's some
graph pete nodes which are only useful
for training and there's also a tool
that will prune that down for you as
well so that's also part of this graph
transform tool is a whole suite of tools
so that's really useful and I also want
to call out that so far everything we've
done is basically running existing code
and existing tools you didn't have to
custom write anything the only custom
thing you had to do was shoot that video
and run ffmpeg so this really makes it
you know puts it in an immediate
possibility type of stage there is one
more thing one more consideration to
think about when looking at deploying a
machine learning model to a mobile
device and that is whether you package
it inside the app or alongside the app
you can make it a data file or you can
make it integrate it into the app and
some of the thoughts there are whether
you want to be able to secure the model
whether you want to be able to download
updates without pushing a new updated
version of the app itself and whether or
not you care about sizing and how
whether or not you want to
secure the the model from outside access
so that's our our overall design right
we gather it up we shoot up the videos
slice it up and and train and optimize
and then we can deploy so that that's
our of our finished model and this is a
video of the the same thing so I won't
show that and the final kind of point
here is how are we going to be able to
how have we done this right what makes
it possible and that's tensor flow
tensor flow is Google's machine learning
library hopefully some of you have heard
of it it's too dark so I can't do a show
of hands but it's been incredible to see
the community adoption and the reception
to the launch it was open sourced in
November of 2015 and hit 1.0 this past
February and with that we have support
for not just these platforms right which
we expect CPUs GPUs and of course
Android but also iOS and Raspberry Pi so
for those of you who like to tinker with
IOT devices you can load a model onto a
Raspberry Pi so that means you can
recognize things without any network
traffic it can be handy and the
community responds to tensorflow
in the past while now more than fourteen
months but in the first fourteen months
there were over fourteen thousand
commits hundreds of non-google
contributors and now that it's 1.1 of
1.0 it is production ready the AP's
api's are stable and backwards
compatible so things won't change out
from under you so that's really quite
nice and so in conclusion putting
machine learning on mobile will just
make that experience of mobile the
internet and computing that much more
powerful and usher in a new wave of
innovation and open a whole new world of
possibilities and moreover you can build
one easily by gathering your own
labelled data simply by shooting a video
and running basically a series of
well-defined steps and having a trained
model as the output so please use this
to build magical experiences for your
users
and with that I want to thank you and
have some resources for you here we have
a code lab to help you do the inception
retraining and as well as a sample app
for loading models into tensorflow on
github and so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>