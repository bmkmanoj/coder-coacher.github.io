<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning: Client-side ML vs Server-side ML | Coder Coacher - Coaching Coders</title><meta content="Machine Learning: Client-side ML vs Server-side ML - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning: Client-side ML vs Server-side ML</b></h2><h5 class="post__date">2018-02-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0DzNqvs3KQA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I want to talk to you today about
implementing machine learning not
machine learning theory but actually
implementing and to start with I want to
focus on how machine learning systems
are currently implemented on this on the
server some of the challenges associated
with this approach and then I want to
introduce a completely new approach of
client-side machine learning I have a
great demo to show you of a client-side
machine learning application and I'm
going to talk you through the code the
architecture and and then I'm gonna end
by giving you a decision framework for
figuring out if you want to implement
machine learning should you put on the
client or should you put it on the
server machine learning traditionally is
done mostly on the server so the two
phases I talked about training and
inference they're both done on the
server and the client just sends data
which the model then purchases on the
server and sends the output back to the
client there's a couple of issues
associated with this approach and I'm
gonna focus on three key challenges the
first is the infrastructure cost so over
the summer I was working on a couple of
machine learning projects and I was
using an AWS ec2 instance to run a to a
GPU instance to train a model so many I
think many of you must have used areas
before but it was costing $24 per day to
run a GPU instance and this could be
quite prohibitive for many people for me
as a student maybe for other people
working in small companies and so this
is a big challenge the second is around
network connectivity and delay so if
your application depends on having
strong network connection or maybe it
operates in an environment in which
there might be high latency having the
model running on the server could cause
significant problems and the third
problem I want to focus on is the
technical expertise that you need in
order to actually set up a machine
learning system on the server but there
is some good news and the good news is
that end-user devices like phones and
laptops and browsers are becoming in
creasing lis more powerful so the
decrease in cost and the increase and
prevalence of GPUs on laptops and
coupled with the introduction of modern
web api's that expose low-level
technology so like web assembly web GPU
WebGL this enables hardware accelerated
graphics and computation and this is
really enabling the browser to become a
very powerful computational engine and
this is great news for processor
intensive applications like machine
learning similarly on the phone
increased increased power on phones and
low-level api s have enabled machine
learning to be actually run on the
device itself so this is opening up the
possibility for a whole new approach to
machine learning that's done on the
client so training so the two phases
they talked about before training and
inference training is still done on the
server but actually running of the model
on inference can actually be done in the
browser so I want to talk to you and
show you an example of how client-side
machine learning can work and to do that
I have an example which is image
captioning so given an image like this
one I want to be able to generate a
natural language description of what's
happening in that image so here there's
a man jumping into a lake into a lagoon
and the description is generated using a
machine learning model so there's a
couple of steps involved and actually
getting this to work so there's two
models that are involved the first is an
image model so an image is passed
through the image model to generate a
feature vector and a feature vector is
just a fixed dimensional representation
of that image the feature vector is then
passed through the second model which is
a text model and so this is trained on a
large corpus of English language and
this is this models used to actually
generate the catch
so the image passes through two models
and out we get a caption describing that
image so now I'm going to give you a
demo of an application that I've built
which is called lingo lens and it's a
Chrome extension which does exactly what
I've just said so it generates a caption
for an image on a web page so I'm gonna
make this bigger so this is my Instagram
page I'm just gonna refresh this is my
Instagram page so you can see that as
soon as I refreshed these are the
buttons popped up analyzed so I'm going
to scroll down okay this is when I had
sushi couple of weeks ago I'm gonna
click analyze and what's happening is
the image is being fed through this
image captioning model which is running
in the browser it's generating a natural
language sentence description for that
image and translating it into a
different language so in this case it's
translating it into Spanish so if we can
if I hover over this there's a close-up
of a plate of food fairly accurate
description okay let's try another one
so this is the Bay Bridge so I moved to
San Francisco two months ago was walking
by the Bay Bridge took a picture so you
can see that again it's captioning so
it's taking the image passing it through
the model generating a natural language
description and then now it's
translating it into Spanish again and
what does it say so as a bridge spanning
the width of a river so this entire
application is running in the browser
and I'm gonna show you I'm going to
prove to you that this is what's
happening so just as I mentioned this is
a Chrome extension Chrome extension has
a you can inspect what's happening in
the browser and you can see that here
there's a web assembly kernel that's
loaded which is running the model I just
want you to remember this because I'm
going to talk about the architecture in
the code and show you what's actually
happening but this entire application is
running
in the browser and if anyone's opponents
have their Instagram page I can we can
try it on something that's completely
new anyone want to volunteer yeah
psy okay is that set
okay that's Trey Oh private anyone here
anyone with a public pad it says again
MBE G and P G okay alright so this is
public so it's gonna wait for the button
to load maybe I'll try this one
try this one let's see how it works
so it's captioning taking the image
generating a sentence and then
translating it to Spanish again okay
what does it say it says a man sitting
on a bench in a park close enough close
enough maybe you can try another one
yeah we can try this one let's see let's
see if it picks up those two two people
in the photo
so this taking an image generating the
caption and I'm gonna talk you through
the actual architecture of how this
works and accesses a man sitting on a
bench reading a book and today okay
thank you for volunteering
alright ok so now you've seen it work
you're probably wondering wondering how
does it work so behind the scenes this
application uses something called web
DNN so web deep neural networks and this
library offers two components the first
is a Python API which takes a model
defined in Python converts into a format
which can run in the browser and the
second is a JavaScript API which
actually takes this model converted into
a web compatible format and then runs it
in the browser so end-to-end this is the
architecture for the application
starting with the Python model on this
side and then the browser on the far
side I'm gonna take you step-by-step
through how this works see some of you
taking photos
I'll make the slides available after and
say ok so the first step is to take a
model that's defined in pythons and this
can use any of the Python frameworks for
neural networks for example China
caris etc so you take the model take the
weights so the weights are what are
available after the model has been
trained let's take the model on the
weights pass them through this graph
transpiler and output a JSON file which
has the graph as a format that can be
loaded into the browser and this uses
the graph transpiler python api so
there's only one slide earth - and this
is the only stuff that you need to do in
python and here you can see that web DNR
has two functions a Keres converter and
a generate descriptor and both of these
are used to load a model in Python and
then output a graph descriptor and
optimize weights so the second step is
to load the model into the browser and
actually run inference and by that I
mean passing in an image and outputting
a caption
so this step uses the JavaScript API of
web DNN it takes in the model defined in
the JSON file along with the optimized
weights it loads the model into memory
in the browser and it uses one of
several web api so it could use web
assembly WebGL web GPU currently web
GPUs only supported in Safari technology
preview but webassembly is supported and
chrome so after the models been loaded
into browser it can then be run so
images can be passed into it and then
captions can be generated so how does
this work what code do you need to make
it work so loading web DNN is as simple
as including the web dnns script along
with another script called inflate which
is used to load the model and the run
models JS file contains the code to
actually call the model and I'm going to
take you through a couple of the
functions in this script so the first
step is actually loading the model and
the first two the first two sections of
this function load model one and model
two so if you remember model one takes
an image and generates a feature vector
model two takes this feature vector and
generates a caption so load the two
models so load the two files and then
the last step which is instantiating a
class called image caption generator to
encapsulate these two models and make it
easier to call the second step is
running inference so actually passing an
image through the model and generating a
caption so here you can see the two
steps I mentioned first is image feature
so running the image through model 1 the
second step is taking the feature vector
passing it through model 2 and
generating the sentence so the last step
is actually encapsulating this into a
Chrome extension so the first two steps
are talking I talked about transpiling
the model and loading and running in the
browser are applicable to any
client-side machine learning application
but the demo I gave you takes it one
step further
puts it into a Chrome extension I was a
couple of interesting architecture
points that I want to share with you
about Chrome extensions so the way a
Chrome extension works there's two parts
there's a background script and a
Content script the background script
runs continuously in the browser this is
what this is where the model is loaded
and this is where the machine learning
model runs the content script is
injected into each page that's each tab
that's loaded in the browser so the
little analyzed buttons that you saw
there put in by the content script so
the content script takes the images from
the web page it passes it sends them to
the background script which then runs
them through the model and the model
sends that output sentences back to the
content scripts so that's how that's the
architecture of how the Chrome extension
works and Chrome has an interesting
message passing API which makes this
really easy to do so here are a couple
of code snippets that show you how this
works
so here this is the content script the
left-hand side is a contact script on
the far side as the background script so
a Content script takes the image from
the web page sends a message to the
background scripts the background script
has a listener for that message it then
takes the image and calls this function
run with the image and the tab ID that
called this the background script the
image is then passed through the model
so it caused the load models and run
inference functions once we have an
output caption we can then send it back
to the content script along with the tab
ID so it knows which tab to send it back
to and the content script has another
listener which can then take the caption
and then you can do whatever you want
with it on the browser on the front-end
so that's just a quick demo of an
example of client-side machine learning
but there is so much more they can do
with client size ml a couple of other
examples are things like image
classification so given an image is a
cat or a dog can you tell what's
actually in
you could also do things like style
transfer some of you may have seen that
an app called prisoner which takes for
example a van Gogh painting and a normal
image and applies the same applies a van
Gogh style to a normal image you can do
other things like sentiment
classification where you can see why the
sentence has positive or negative mood
so those are some of the things you can
do some of the tools that you can use
our web DNN which is what I've talked
about there's also a couple of others
like chaos there's another chess densify
ojs deep plunge is is a library released
by Google which allows you to do both
training and inference in the browser so
there's many tools that you can explore
and they all have demos and examples to
start but help you get started so what's
best for your needs so this is probably
the most interesting slide for you all
so if you're thinking about implementing
some machine learning into your
application what should you be thinking
about and how should you decide whether
to put the machine learning on the
server or on the client so these are a
couple of the points that you should be
thinking about the first is
functionality and model size so how
complex is the model that you want to
use and the browser is only suitable for
certain types of models that can
actually be optimized so this is
something to think about
the second is actually browser
compatibility there as I mentioned web
GPUs only supported on safari technology
preview so you want to be thinking about
what type of browsers are your users
going to be using and is this something
that would work for them the other thing
I mentioned was connectivity earlier so
depending on whether your application
requires strong now our connection cost
if 24 dollars a day isn't a big issue
for your company or your your startup or
your apps and maybe you don't
necessarily need to use client-side
machine learning and the server is fine
for your needs the last two points
around source code privacy and days
privacy are interesting because source
code privacy if you're running machine
learning the browser anyone can see them
anyone can see your model definition and
yours by opening up the developer
console so you want to think about
whether that's something you want to
keep private data privacy is interesting
because with client-side machine
learning you're not sending any user
data to the server and if this is
something that your users care about you
can tell them that all our machine
learning is run on the client so we
don't actually send in your data to the
server this might be something your
users care about so that was a tour of
client side versus server side machine
learning I went to and by taking you
back to the beginning so I mentioned
this app just idea this vision for
imagining for having the world around
you described in the language that
you're trying to learn and this is what
really motivated this talk motivated
this research into client-side machine
learning and I want to give you a demo
of something that I built with a friend
and that actually enables this to be
possible so this is lingo lens this is a
demo of how a vet working on a phone so
enjoy
I'm Nikki Lee Ravi send me a tweet find
me off</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>