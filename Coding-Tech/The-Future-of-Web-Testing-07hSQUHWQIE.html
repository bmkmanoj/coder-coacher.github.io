<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Web Testing | Coder Coacher - Coaching Coders</title><meta content="The Future of Web Testing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of Web Testing</b></h2><h5 class="post__date">2018-02-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/07hSQUHWQIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today I want to start by talking about
launching a product product launches are
super exciting I can distinctly remember
working on a really important project
that culminated after several long
months of hard work in a couple
pressure-filled days that ended with
that exciting moment where we flipped a
switch in our creation was shared with
the world once it was launched we all
felt some relief right the product was
finally out there we had done our due
diligence tested it thoroughly squashed
hundreds of bugs we knew it was solid
unfortunately in the months that
followed things started to deteriorate
with each release that we sent out the
product started to feel a bit less solid
we knew everything worked because we
were testing but we got reports of it
being slow and some people complain
about it not being accessible it was
functional but the quality for our users
was deteriorating so we became faced
with this problem as we scaled our
product and iterated on it how do we
ensure that we're consistently
delivering a quality experience for all
of our users so my name is Tripp Willis
I'm a senior UI engineer on Netflix
currently and project lead for the QED
unit testing framework and today I'm
here to let you know that maintaining
quality software is hard it's really
hard but I'm also here to talk about the
future and specifically how they
emerging technology for testing Web Apps
is going to make it so much easier for
us to help ensure that we're
consistently delivering that quality
experience that all of our users are
expecting from us so the story I just
shared highlighted that one primary
benefit of automated testing is that it
gives us confidence that our software
works having this confidence provides us
with a lot of benefits right we can
iterate faster because we're not worried
about breaking something and it lets us
fix bugs quicker but it doesn't do a
whole lot to prevent us from digging a
hole in terms of quality for ourselves
that said testing is still by and large
a net positive for those of us that do
it and so we do it but we've been using
the same techniques for a long time so
today I want to
challenged us to start shifting our
thinking slightly and strive towards the
idea that testing should give us
confidence that our software works well
not just that it works but that it works
in a way that provides a quality
experience for all of our users but in
order to do this we have to define what
is a quality experience for a web app
well that's a pretty suggestive thing
and will vary based on who you ask but
there are a couple questions that I've
been considering related to this and
that I want to talk about today and so
those are what if instead of just
telling us that our live web app is
functional our test could tell us
whether or not it was also accessible or
what if our tests were able to us
whether or not our small code change
impacted the performance of our overall
application or finally what if our test
could let us know that we're actually
using all the code were shipping that
it's necessary for the users experience
so these questions go beyond answering
just is our software functional and
start to address is the software
providing a good experience for our
users now there are many more areas that
we could be concerned with but today I
just want us to keep these three in mind
so if we want our tests to answer the
question of is our software accessible
performant and actually necessary how do
we do that well we need to start with
some new foundational technology for how
we test so earlier this year April 13th
3xs a new version of the Chrome browser
shipped a version that supported a
headless mode which allows the browser
to be run without a graphical user
interface so it made its official debut
in chrome 59 and this was a huge deal
because it finally made it easy for
developers to set up automated testing
in a real browser that they could use in
their CI environments often continuous
integration environments don't support
full browsers because they don't allow
graphical user interfaces so up until
this point a lot of developers have been
using phantom j/s which was a headless
browser but it often lagged behind real
browsers in terms of browser
functionality and most importantly
wasn't actually being used by anyone
that you're shipping your code to and
because of this any maintenance cost
that you sunk into that wasn't going
towards benefiting your users directly
and that's a problem right so other
browsers such as Safari edge and Firefox
also either couldn't run without a
graphical user interface or a platform
dependent and so those were out for your
continuous integration environments as
well so chrome having the support was
really a tremendous step forward for us
in terms of setting up real
browser-based
testing but aside from this ease of use
the really big game changer here for me
is that Chrome has an Associated
debugging protocol called the chrome dev
tools protocol which allows for external
tools to instrument inspect and profile
the browser itself in addition to the
code that's running and so that gives us
full access to the information that the
chrome dev tools have natively and
that's awesome so now you might be
familiar with a similar protocol called
webdriver that's been around for a while
and often used to administer end-to-end
testing via tools like selenium unlike
webdriver which is primarily focused on
controlling the browser as a user would
the dev tools protocol is a bit lower
level it gives us access to a much
richer set of data so it can control the
browser by navigating in administering
events in the browser like webdriver
does but it can also let us get access
to knowledge about how much code is
executed or what the performance of the
webpage has been like so far so this
combination of headless chrome plus a
powerful new debugging protocol opens a
ton of doors for us in terms of
automating our web apps so however if
all of our developers have to interact
with this protocol directly it's
probably not going to be adopted that
quickly because it's difficult to
understand but if we can build some
abstractions around it and make it a lot
easier for JavaScript developers to get
on board and try things out then doors
will open a lot faster and so this is
what the Google Chrome team has done
with puppeteer an old library that
allows you to control chrome using a
simple high-level promised based API and
so you can use a lot of the same tools
and techniques that you're using in your
day-to-day JavaScript developer
already so with puppeteer you can do a
lot of really complex tasks easily such
as crawl webpages or get a performance
trace of your application so as a quick
example here's some code that navigates
to a page and takes a screenshot the
high-level api used here makes it pretty
easy to read as we launch the browser
open a new browser page visit the
website wait for the content to load and
then take a screenshot this is a lot
easier to read than the actual protocol
statement and by using native
async/await like Wes talked about we get
really clean automation code and so I
don't know about you all but something
like this excites me a lot because doing
something as hard as automating screen
captures of web pages in JavaScript used
to be really difficult but now we can do
it in six lines of code and an NPM
package that's pretty awesome
but beyond these generic abstractions
like puppeteer we can also start to
build tools that interact directly with
our webpages as they run so an example
of this is Q unit in browser this is a
small extension for Q unit that I've
been working on for a while now
that allows you to easily write Q unit
test that executes against the live web
page so what this means is you no longer
need to learn a completely new
domain-specific language do you do your
end-to-end testing and instead you just
write JavaScript test using the same
tools and techniques that you're already
used to and the only difference is that
these will execute against a specific
webpage instead of in your test Runner
and this is possible because the dev
tools protocol allows us to interact
directly with the runtime of the webpage
that were visiting so as an example
above we have a test where we visit a
locally running web app and verify that
the content is rendered so this test can
be run in a suite with other standard q'
unit tests so your other unit tests or
integration tests and yet
it'll be an end-to-end test because we
can visit a web server that actually has
some production data going to it this
means you don't have to learn a second
testing framework for your inten testing
you don't need to set up additional
configuration and you don't need to have
a second test suite and that's really
great for our developer experience so in
short
this setup is a lot simpler and more
lightweight than old selenium style in
ten tests and yet it can give you the
same level of confidence that you're
shipping functional and quality code so
at this point you might be thinking okay
so we have some new and potentially
better tools but a lot of this we could
already do with existing tools so what
how is this actually the future so
that's a good point a lot of this we
could already do but with easier to use
and more flexible tooling for our intend
automation we can actually start to
think less about how we're writing tests
and more about what we're actually
testing so to put this idea in context
let's start by exploring that first area
of quality that I mentioned
accessibility so there are a lot of
tools out there that have been around
for a little while but the most
well-known is probably from the
accessibility consulting firm DQ labs
and so this library ax cor is by enlarge
the de facto standard for automated
accessibility testing in the industry
right now because it's really easy to
use in terms of its API and is built on
the collective knowledge from a lot of
people that are experts in this area but
in order to use it in order to integrate
it into automated testing we often have
to think a good bit about how we
integrate it do I test my individual
components do I put this in my
integration tests or if I'm writing an
end-to-end test do I need to use the
selenium wrapped API instead of a native
JavaScript API
with an approach like the one queued and
browser takes by injecting code into the
runtime of our live load up a lot of
these problems just kind of vanish right
because we have access to full web pages
as they're running and we can verify
accessibility in a holistic manner so if
we take the code from a before in just a
few more lines of code we can verify
that our live web app that is running
with production data is free of a whole
swath of accessibility violations right
and this is really incredible because if
we take this concept and add another
layer of abstraction or just wrap it in
a loop we can verify that almost every
linkable page in our application is free
of accessibility errors and this is
tremendous for both our end users
because they now have an accessible site
and our developers because this was
relatively easy to set up and that's
really exciting to me because the last
thing we want is to develop stuff that
people can't actually use so on that
note let's shift gears a bit and get
into some more nitty gritty stuff and
talk about performance so performance is
a really interesting topic in computer
science and one that actually has a
direct impact on how our users
experience our web apps however it's
unfortunate that we often talk about it
in terms of intuition or hunches we have
or cargo quilted knowledge that we've
learned from others and not based on
actual data and even rarer do we talk
about it in terms of data from our web
apps so we do this because writing
benchmarks for performance is often time
consuming it's prone to error and often
not really helpful within an actual
application because we usually focus on
micro benchmarks that only test a small
portion of our code but since the chrome
dev tools protocol exposes information
about a webpage as it is running from
the perspective of the browser we can
start writing macro benchmarks
benchmarks that are concerned with our
application as a whole these are
generally less prone to the optimisation
error that micro benchmarks run into and
they give us helpful insight into how
the user is experienced an entire web
app running at once and if we apply some
abstractions here we can make it such
that setting this up is in a very
time-consuming exercise so Chris Selden
a software engineer at LinkedIn and an
ember core team member has been working
in this space for a while now and he
created a tool called ember macro
benchmark which allows you to set up
application level benchmarks for any
application not just an ember app as the
name implies and these benchmarks
control for network variants by using
some pre-recorded Network responses and
so what this means is that we can get
relatively stable results over running
our app multiple times and doing the
same thing and that allows us to get
meaningful information about the
performance of our app as it's running
so as an example this is a boxplot taken
from the ember js2 14 release blog post
it shows that improvements made an
initial time to render as well as
overall JavaScript
time for a real amber application so
this was generated by ember macro
benchmarks and it allowed the core team
and contributors to verify that these
small framework level performance
changes they made over that over this
period of time
we're actually improvements for a real
web app they weren't just hypothetical
or things that they thought might work
they actually verified it and they could
do this in a relatively automated way
and so this is super exciting because we
can begin to track the performance of
our application over time as we iterate
on it and because of that we can gain
confidence that were shipping a quality
experience that isn't slowly
deteriorating over time or if it is we
can put guard rails in place to help us
detect that and so that's awesome
now unfortunately the code to set this
up is slightly too complicated for me to
fit into this talk but if you're
interested I highly recommend that you
go check this project out on github so
finally I want to talk about code
coverage so code coverage often elicits
a really strong usually negative
reaction from developers because we
usually talk about arbitrary quotas set
for testing lines of code but that's not
really what I want to talk about today I
want to talk about code coverage in
terms of code usage and so what I mean
by this is how much code are you're
actually using for users in countries
with developing mobile infrastructure or
just high mobile data cost the amount of
code you're shipping can directly impact
whether or not they choose to use your
web app and so if you're sending code
that isn't actually executing and never
being used you're performing a
disservice to your users not only that
but you might potentially be costing
yourself market share and that's just
not good business sense so thankfully
chrome added an awesome code coverage
tool recently to its dev tools that
shows you what code has actually
executed from a given script or style
sheet over a given period of time so
this was added in chrome 59 the same
releases headless chrome and got its own
tab in the UI it allows you to see what
code is executed in terms of file size
from various files that were loaded and
would even let you drill down into it to
see exactly what lines have executed
so by now maybe you can guess where I'm
going with this since this information
is in the dev tools it means that it's
also exposed to your the protocol which
means that we can begin to automate and
collect that data and test against it
so this codes a bit more low-level using
the profile or domain from the protocol
we can begin to track coverage and then
if we perform some actions they run an
end-to-end test testing a user flow we
can collect the information about what
code has actually been used for that so
we'll need to parse that info to make it
usable but once we do that we can then
track it over time to make sure that
we're only shipping code that's actually
used and so this is great because we can
not only do this for initial page
reloads and make sure our initial page
loads right but we can also see if we
have a really common user flow of like a
user logging in we can make sure that
we're sending optimized bundles for that
as well and so this is really really
exciting to me because when we combine
this with something like performance
tracking then we can begin to build
guardrails that help us make sure we're
consistently delivering fast and
optimized experiences for all of our
users not just the ones on fancy
high-speed internet in modern countries
but those that are out in the middle of
nowhere and don't have great signals so
at this point we've covered a lot of
ground our current reality and testing
is that most of our testing is just
geared towards making sure our software
works and that's a pretty good start but
with the advent of a real headless
browser in a robust debugging protocol
that we can use we can begin to build
really powerful tools for gaining
insight into the quality of our
applications in addition to the
functionality so to recap some of the
ways this might manifest let's revisit
those initial questions that I posed
what if instead of just telling us that
our live web app is functional they
could tell us it was testing it was
accessible they can and by combining a
JavaScript centric into n testing
approach that works directly with the
runtime with an easy-to-use JavaScript
API like X core we get this really
easily
what if our test could tell us how our
small code change and
the performance of our overall app they
can and by collecting this data over
time and using traces from the debugging
protocol we can start to get a holistic
view of how our apps performance is
changing as we iterate or whatever the
test could let us know if the code were
shipping is necessary and actually being
used we can start to do this as well
by tracking code coverage information
and with that information we can start
to build assertions and tools in
automated infrastructure around it and
so all this is starting to become a
reality for web apps today and these
ideas that I presented are just the
beginning there's so much more that you
could do so they're emerging tools for
testing and automation are so much more
flexible and robust than they ever have
been before and so whether you're
launching a new product or maintaining
an existing one there are many
opportunities for us to start building
confidence that were shipping the
experience our users want and will enjoy
so the future of testing for the web is
really bright in my opinion and I'm
excited to see what you all will do with
it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>