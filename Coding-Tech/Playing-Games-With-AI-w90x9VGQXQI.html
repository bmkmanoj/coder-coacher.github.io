<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Playing Games With AI | Coder Coacher - Coaching Coders</title><meta content="Playing Games With AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Playing Games With AI</b></h2><h5 class="post__date">2017-11-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/w90x9VGQXQI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we're gonna talk about what do you need
to do to write an AI that can play games
and we're gonna start really simple with
the most basic game theories even more
basic than tic-tac-toe
I will move our way to alphago oh and if
you're here for this little guy gopher
yeah he's the mascot of golang yeah
that's not gonna happen we're gonna talk
about the board game go so what are we
gonna cover we'll start with a very
simple tree based game and I'll explain
the basics of a tree search which you
probably already know but and I'll
explain minimax which is an algorithm
then we'll move to not say crosses a bit
more complex game and then we'll talk
about perfect information in game theory
then we'll move to chess forward
backward pruning alphabet approving and
then we'll end up at go
our main objective and we'll talk about
Monte Carlo tree search and neural
networks sounds complicated but it isn't
so I want to play a game or s jigsaw not
a Java 9 the reference by the way ticks
off I wanna play a game it's a tree
structure you get the start and the
highest score wins this is our tree you
can either go left
so left 4 viewers or right your
objective is to get the highest score
what do you do you go left it has a 5
right 3 so that's easy right
so the first step it's our turn we can
go either left or right
then the opponent gets to pick and then
we get to pick do we go left or right
all of a sudden this isn't trivial
anymore it's for a computer it's trivial
but for us it's like oh if we go that
way how do you calculate this it turns
out there's a very simple algorithm that
does this for you and it's called
minimax
what you do you try to minimize the
maximum score when it's the opponent's
turn and when it's your turn you try to
maximize the minimum score this is
perfect play back to the example what do
we do we start at the bottom and we
evaluate those notes it's our turn
so we can pick the highest score so in
case of three and five P pick five in
case of nine and two we pick nine let's
review we assume the opponent plays
perfectly as well so when the opponent
gets to pick between five and nine the
opponent will pick five he or she wants
us to have a low score and then we can
work our way up and we'll see the answer
is five so the part you most likely need
to take is go to the left the opponent
will probably also go to the left and
then you can go to the right and you'll
end up with a five this is optimal play
for both players
if the opponent makes a mistake you go
to the left and the opponent says go to
the right you can go towards the nine so
that's even better but a fuming both
players played perfectly you always end
up at five so this is basically our
minimax works and it's a Java conference
so we need Java code this is how you
boot implements minimax it's a function
and the input is a node the starting
node and you have a boolean if you're
either maximizing or minimizing the
score if you are at the leaf node and
endnote' you if you wait and you get the
score so the best score if we're
maximizing we'll start with the lowest
possible integer and otherwise we'll
start with a maximum integer and then
we'll go to all the child nodes so we
move away from the top of the tree to
the bottom and we calculate the score
and we do this by recursively calling
minimax for the child and flipping the
boolean maximizing not maximizing if
maximizing the score our score is met
the next score and best score if we
minimizing best scores met Minsker and
we return the score that's basically it
that's minimax it's that simple
time for some statistics this is our
game it has a branching factor of two
what does this mean well at every point
at every node it splits in two you get
two new options very simple the game
depth in this case is three because the
tree is as a depth of three and you have
perfect information what does this mean
well we know the if the nth score we
know it's a 3 a 5 or 9 a 2 or 6 later so
how do you make a program that plays a
game the first thing you need is a way
to generate all the valid moves that way
you can create a tree so if you want to
play if you want to create a chess but
you need a chess engine and a chess
engine is an engine that gives you all
the possible moves that's the only game
specific thing this thing knows
everything about the game it knows the
rules it knows what you can and can do
the next thing is you need a way to
evaluate the notes in the tree so you
need to you need a way to score all the
nodes this is also game specific but it
doesn't really have to do with the rules
and a final thing which is completely
unrelated to the game is to pick a path
industry that's basically how you play
the game move around to a more difficult
game not sing crosses you'll know not
crosses right it's a game you play
important as well in Dutch we call this
game butter cheese and eggs why I have
no clue tic-tac-toe okay knots and
crosses
it's like knots and crosses makes
perfect sense but butter cheese and eggs
really this is what the tic-tac-toe
through or nuts and crosses three would
look like you start with an empty square
then you get nine options you can either
put it in the
top left square or top square top right
square etcetera etcetera and below that
you have eight moves left and then you
have seven moves left six moves left and
at the bottom we know what happens you
can either assign a one if you win zero
if it's a tie or a minus one if you lose
so the evaluation function for not same
process because you can evaluate all the
way to the end it's easy for a computer
creating this entire three sure it
didn't fit on my slide but for a
computer this is easy it can easily
generate all possible moves in knots and
crosses and it can assign these values
and then you can play the game and
that's it we can just use minimax
calculate every possible move and you're
done you've solved planted crosses or
tic-tac-toe the branching factor of this
game is 5 so the first time you get 9
different moves then you get 8 different
moves and you get 7 different obviously
but on average it splits into 5 the
maximum depth obviously is 9 because F
then I move the board is filled and if
you will remove all the symmetries there
are just 138 different terminal
positions and interestingly if X starts
X wins 91 times the not wins 44 times
and there are just three possible
positions which end up in a draw but if
you calculate all the positions in
tic-tac-toe or knots and crosses and you
apply minimax to the end and both
players play perfectly don't make a
mistake you end up in a tie so yeah
that's to me that was pretty surprising
because there are only three tying
terminal positions but if both players
played perfectly and you counter each
other you always end up in a tie there's
no way to force a winner
to force a loss in tic-tac-toe
for me chess is is the perfect game I
broke my own chess engine a long time
ago just to prove I could make a chess
engine basically and the next step
obviously was to make a checks bot
because well if you have the chess
engine you've written all the possible
rules of chess and writing a bot is
basically pretty easy as you'll see
chess is a noble game if you draw the
tree the complete tree for chess you'll
quickly end up yeah for example when you
start I don't know I think there are 20
different starting moves you can do
below that there for each note another
20 moves you can do this quickly becomes
too large not only too large for my
slide but also too large for a computer
to calculate this table shows the
problem this table is called a perfect
table and if you would write a chess
engine you need those tables because
those tables allow you to do two things
so what is this table when we start at
depth zero there's just one note that's
the starting board that's how you place
the pieces when you want to play a game
from that we can do 20 different moves
so white starts you can do 20 different
moves at depth 2 there are 400 moves
because black can also do 20 starting
moves and at that point there's still no
capture no impose on no castling no
promotions no checks energy weights but
after three moves
there are almost 9000 different
positions on the board that can happen
but 34 of them are captures and you can
even do 12 checks and after 4 moves
there's also 8 possible checkmate in
chess this shows you how fast it grows
because even after six moves they're
already 120 million different
patience and the chess game doesn't end
after six move well it can in 10,000
cases you end up winning or losing at
chess but this three becomes enormously
large it is so large it's too large for
a computer to calculate it's impossible
to calculate all the positions in chess
and just solve chess would be cool if
you could do it right now it's
impossible so why is this table
important if you want to write a chess
engine two things this is very easy to
implement if you have a test engine it
just gives me all the possible moves for
these moves give me all the possible
moves for those moves give me all the
possible moves first you'll find bugs
for example when I did this it had like
everything was okay except it had eight
zero nine zero eight six there's a
bug somewhere
now we need to find it so this is
perfect for finding bugs in your it's
like an integration test for chess
engines because you're generating all
possible moves and acute the number
should match up people have calculated
this for depths of 12 13 so you can
really be sure your chest anything works
if you run this second is bragging
rights
people are like I can go to depth 6 in
in 5 seconds mine does it in 4.6 so
that's another important thing bragging
rights so the problem is there's no
perfect information we can't calculate
all the way to the end and assign a
value either win or lose that's
impossible so how do we evaluate a node
how do we give a value to a certain node
it turns out in chess look it sucks it
turns out the chess it's very easy you
just count the pieces that's basically
if someone's if you know someone who's
very good in chess they'll probably say
oh white is ahead two pawns so that's
basically how how you count the
you've come pieces if you've got more
pieces than the opponent you're probably
winning but that's not all obviously you
can make a better evaluation function if
you for example look at the positions of
the of the chess pieces and you look at
if you've got pins where you pin down
your opponent and you look at the
liberties your your chess pieces have so
the evaluation function can become very
pretty and very nice and but it's easy
to write an evaluation function if you
have a certain board position and you
give it to an to an amateur chess player
he or she can quickly say blacks winning
whites winning or how much so an
evaluation function isn't that hard so
we can calculate up to a certain depth
maybe depth then and then we stop and we
evaluate those notes and then we work
our way up using minimax so we don't
have to calculate all the way to the end
we calculate to a certain depth we
assign it the value and then we look up
but there's obviously a horizon problem
if we calculate up to depth n it's
looking rather good but a depth 11 the
opponent wins yeah sorry we didn't see
that so it's important to go as deep as
possible just to eliminate as much as
possible the best way to do that is to
do pruning what is pruning pruning it
means that you cutback branches of a
tree that's what it says there are two
kinds of pruning you've got forward
pruning which is risky I'll go into that
depth on the next slide and there's
backwards pruning which is safe it's
important to remember in forward pruning
if a move is too bad for you just don't
do it stop it very waiting if you do a
move and you lose your queen there's no
need to calculate all the positions
after that because that's probably of
the worst move you can do just stop it
very waiting
but also if a move is too good if the
opponent sacrifices he saw her Queen
it's probably not gonna happen so we
don't need to watch what happens below
that up to that depth 11 because it's
probably too too good for us
it won't happen but like I said pruning
is dangerous the most beautiful games of
chess have for example situations where
people sacrifice their queen and later
turn it into a checkmate happens so if
you cut back the tree you might miss
this situation luckily there's also
offer better pruning and this is always
safe this is backwards pruning imagine
we go all the way down and we evaluate
that note and we do a Max and min Max
and min just means we are maximizing or
minimizing scores just minimax algorithm
we evaluate the next note it's a 5 and
since we are maximizing there between a
3 and a 5 we pick the 5 just minimax as
we did before so we move the 5 up and we
start to be very wait another node we go
down to the same depth and we find a 9
because we're minimizing and we already
have the value of 5 there and another
value is a 9 we can actually stop we
don't need to evaluate any further we
don't need to go down here and find
value because that 5 will always stay a
5 2 things can happen this can be a very
low number a 1 but we are maximizing
here so that 9 will stay a 9 even if
this is a 1 that value 9 won't change so
that value 5 won't change this can also
be higher 15 so that 9 turns into a 15
but we're minimizing there that will
always say a 5 no matter what happens
that value will never change so it's
safe to prune that so we don't need to
look any further we can stop now if this
situation happens let's offer better
pruning and also works the other way
around so here we've switched the values
the min and the max are switched
so in this case we're maximizing we
found a 5 and there's a 3 there does it
matter what happens here if it's a 1
that becomes a 1 but that's still a 5 if
it becomes 20 that's that's 0 3 and
that's still 5 nothing happens we can
stop your very waiting this is the cope
we already saw this is the same code as
minimax exactly the same but I've now
renamed it to offer better search so the
first thing we need to do to implement
off a better search is to add alpha and
beta and in the recursive call we also
add offer better the next thing if we
are maximizing we update alpha with the
highest score so we max alpha and the
best score and otherwise we update
better with the minimum score and the
final thing you need to add is if alpha
is better is smaller than alpha stop you
can safely stop evaluating this speeds
up your minimax search you mungus lee
you can cut a lot of yeah basically it's
free it's safe you can cut away a lot of
nodes so always try to implement it this
way it's three lines of code extra and
the game area is much faster so how did
I write my chest pot well you need a way
to generate all moves a chess engine you
need a way to evaluate the nodes we can
just count the pieces or maybe something
more elaborate but and we need a way to
pick a path in this tree and we're going
to use alpha better search
I did this in a weekend was one of my
weekend projects I often do weekend
projects and and I was able to write a
chess engine and a chess board and that
but on Monday I I've got a colleague who
is pretty good at chess using he's got
an e low of 20 20 200 it's not that good
it's not a master but pretty good he
spent like 40 years of his life learning
and improving chess and I beat him just
the denying breath writing a chess
engine in a weekend and yeah that was
devastating obviously but fun
nonetheless so some numbers about chess
the average branching factor is 35 so on
average for each chess board you can
have their most of time they're around
35 different position different moves
you can make on average a game lasts for
40 to 50 moves some much much shorter
some longer obviously but on average is
between 30 50 moves and writing an
evaluation function for chess is
relatively easily if you take an advance
yes AI an advanced chess ai it can look
ahead for 20-plus moves humans can do
this so chess has been solved computers
are better in chess time to move on
again so what's a special about go there
was a lot of buzz around the game for
those of you who don't know the game in
the Netherlands it is very popular so I
usually just who knows the game of Go or
any go players a lot of people oh cool
so basically it's a 19 by 19 board
they're black and white stones and you
have to surround and capture areas or
limit the liberties of the stones the
first problem of go is that the
branching factor is about 250 chess had
35 so if we each step 35 times 35 times
five times 35 this is 250 times 250
times 250 so it's a lot more it grows a
lot faster and that's all because the
board is humongous it's 19 by 19 and we
all know 90.9 19 a lot of possible moves
but also the game doesn't stop after 50
moves it goes on for 300 so if you want
to calculate to the end you don't have
to calculate to a depth of 50 you have
to calculate 300 which is obviously 250
times 250 times you get 300 times that's
a huge number but the most important
thing is it's almost impossible to write
an evaluation function even even the
best go players can't explain why they
think someone is winning they look at
the board and they say ah my intuition
says black is winning but yeah it's my
intuition I can't program intuition but
even if you if you are surrounding an
area and you're like one stone left - -
that doesn't mean anything and go
because it can quickly change and then
there is yeah it's it's either you get
it or you don't but so the complexity if
you would make a list of all the
possible combinations you can get on a
go board it's this number which can even
pronounce but the number of positions is
larger than the amount of atoms in the
entire universe which is a lot so what
can we use to play go up to now almost
all the the the go a is which are is
very good are using Monte Carlo tree
search and if I see a Monte Carlo what
do you think about for me it's it's
formally one but yeah but the casino
casino is it's very prominent in Monte
Carlo and that's why Monte Carlo 3
shirts is called Monte Carlo 3 shirts
because it's based on chance basically
how does it work you pick a note and you
just play semi randomly to the end just
pick random loads go to the end see if
we win or not and we do that another
time another day we do that thousands
millions of times and maybe we win 60%
of the time 10% of the time it's a tie
and that says something about the
strength of that move but not really you
know it's still it's pretty random and
yeah but it does give an indication of
the strength of that move but it's not
that good so go a eyes aren't that good
and in 2015 just two years ago the
experts said it will probably take 10 to
15 years before a computer can beat a
professional go player forget that
because suddenly alphago came around it
was like this poor baby and alphago is
using neural networks I probably don't
need to explain this but neural networks
are a computer model based on our own
brain our own brain but a brain in
general time for a little demo maybe my
computer allows it who here has seen
this it's people some people are already
using this this is the the playground of
tensorflow tensorflow is a library where
you can learn how to use neural networks
and this is their playground where you
can basically play around with neural
networks in your browser you should
definitely go here and try this out so
what do we see we can play and we can
restart and that's about it
we have some input data so here you can
pick input let's
this one this is what our new network is
trying to solve
there are orange dots and there are blue
dots and it wants to divide those orange
dots from the blue dots how does this do
how does it do that well we've got input
features for example X and X is a
straight line if we play nothing happens
because we don't have a network yet now
we add a simple single neuron and this
neuron has an input wait maybe I can
show ya I can even chase away and an
output wait and every time we initialize
the network it's filled with a random
value so you can see it change if we
play we can see the network is trying to
adjust and trying to solve this problem
and right now it has found an orange
area where there are orange dots and a
blue area but yeah it's not very good so
what does it do with this X input value
basically based on the weights it can
move it around from left to right so
what happens if we have two neurons the
neurons are all connected so the X goes
to the first neuron the X goes to the
second neuron and the output is combined
here if we have two neurons it can make
two lines and it's already getting
better at separating the orange from the
blue but yet they're still orange in the
blue area it's not very good so this is
not the solution let's go back to one
neuron and let them add another input we
also have an horizontal line and a
vertical line in a single neuron and as
you can see if we initialize it randomly
we can now have a diagonal line oh it's
not working sometimes it breaks
you have Network I hope so yeah yeah so
now it has a diagonal line and it can
find a diagonal area so in this case it
found this area which is probably better
than just one horizontal line if we have
two neurons we can have two diagonal
lines and that's already better and to
completely solve this problem we need
three neurons because in that case the
neural network is smart enough to
basically solve the problem and separate
the blues from the oranges but this
already shows something it's very hard
to create a neural network if we have
two neurons it's just not enough if we
have more than two neurons well it's
enough but if we add too much neurons it
probably takes well in this case it
doesn't take longer sometimes it takes
much longer for it to fast much faster
to find a solution but if you don't have
enough notes you can add a lot of hidden
layers for example this amount of hidden
layers but it becomes slower and slower
and it still can't make the correct
decision because it only has two inputs
to two nodes every time it even goes a
bit crazy but at the moment we add three
neurons somewhere now it has enough
neurons to solve it eventually but a
bigger neural network isn't a better
neural network it might solve it
eventually or not you know new networks
are hard we don't know what's happening
but yeah check this out it's playground
of tensorflow org and it really it it
basically explains how neural networks
work and you can just play around with
it and it's it's addictive and fun but
let's go back to the presentation maybe
or not
go away go away if you want to learn
more about neural networks check out
tensorflow
which is made by Google by the way or
check out if you want to use Java check
out deep learning for Jai and there are
a whole lot of neural network libraries
and frameworks you can use for example
Cafe towards vino but how does alphago
work I still haven't told you alphago
has neural networks they are confluent
at works this means that as an input
they take a go board and they start to
divide it into pieces and each piece
itself is an input node it's used as
input it's supervised learning and it
has just thirteen hidden layers which
isn't that much but they're very deep
very large they made a couple of neural
networks this is the first one it's a
supervised learning policy Network fancy
name but what did they do they took 30
million amateur matches and they gave
the neural network ago predict which
move is going to be played next and the
network of better and better and it was
correct in 57 percent of the cases
doesn't sound that good but it actually
is because most of the time more than
50% of time it will predict the next
move the amateur will play then they
copied this network and they gave it a
new goal instead of predicting what an
amateur who do what's actually the best
move we can do so how did it do that it
played itself 1.2 million times and with
each time it would update the neural
network to pick the better move then
they took Pachi Pachi is a go game AI
and it's not very good
but it's okay and this network alone
without any search yet would win 85% of
the time so that's just given the
current board what's the best move do
that move so there's no searching
there's no Monte Carlo search there's
nothing just this neural network this
proved something they were on the right
track but they wanted to add some more
logic to to two days so they wanted to
have a faster network this network the
number two network took three
milliseconds to evaluate a board three
milliseconds sounds fast but in computed
terms it's not it's very very very slow
so they made a new network they gave it
the same goal but a much smaller network
and I wanted to have this yeah so this
network is much smaller network number
three and it takes just two microseconds
much better so that's about 1,500 times
faster they weren't done yet we're so
good at making neural networks we'll
make a fort one and this is called the
failure Network what does this network
do they use the same 30 billion amateur
matches and I asked it can you predict
the winner based on the current board so
this is basically the evaluation
function initially it had an error of
point 37 where point 5 is obviously a
random pick and after self play this
error came down to about point 23
doesn't sound very amazing but it's much
better than any evaluation function ever
written for go so they thought how can
we test this network how good is this so
for a given board they would generate
all the possible moves and for all these
moves they would apply the value network
the evaluation function and they put
pick the best next move so this is
searching to an entire depth is
one this was able to be the strongest
known AI in go still without any
research just this neural network not
the other neural networks just this one
and then they started to combine all
these networks into one program which is
alphago so they use the policy network
to look at the current best moves what
are the best move I can currently make
for those moves
we used to value network to evaluate
them to give them a value this gives
another indication how strong this
movies and then if there's time left
they would do a Monte Carlo three shirts
to the end using the fast world policy
Network the first rollout network to
give an indication and even better
indication so instead of random moves we
do fast good moves all the way to the
end and we watch at the outcome do we
win do we lose Easter a tie this is
basically alphago but yeah how do you
measure how strong your alphago actually
is they set a challenge
this is least at all these considered to
be the best go player of his decade
people call them the Roger Federer of go
because apparently firstly Ferrer is
very good to tennis which I don't follow
but best of five games and we're winner
gets a million dollars just so lee sedol
really tries his best this is the
challenger alphago it has 1200 and two
CPUs 167 GPUs Oh sounds reasonable
this is game number one a small video
you can see that guy over there that's
that's the the AI slave it's basically
yeah the machine is doing a move and he
has to actually do the move and this is
in the first game move 102 and up to
that bond Lee SEDOL was convinced he
will win because a
first said it would take 10 to 15 years
before he got he gets beaten by nai but
the moment alphago makes this move Lisa
don't see something he starts to realize
I might not win this you actually see
that's your problem what's not be proof
she's like come early this is a movie
this movie is flabbergasted
wait a minute oh my god don't buy this
it's when he realizes he's gonna lose
this and that's actually what happened
he lost the first game which was it like
a devastating blow to him and he didn't
even think it was possible but yeah I
forgot one another fun moment came in
game number two up to that point in game
number one alphago seemed to play very
human-like other game a ice in go we're
playing a bit like a computer a bit
weird but alphago was very human but in
game 37 something strange happened up to
then there are two commentators they are
commentating on the game and they are
analyzing the board so right here you
can see the board you can see alphago
made this move and they are commentating
on what's about to happen but the move
alphago made sleep well just look at
their reaction and it changes the value
of an area when you have a strong group
like this because black doesn't have any
point to approach it because it's so
strong and this is what sorry from the
from the google talk about is this kind
of evaluation value that's a very that's
a very surprising move I thought I
thought it was I thought it was a
mistake what I thought it was a quick
miss but if we click oh yeah it's a very
strange something like this would be a
more normal yeah Dendi well we'll talk
just talk about what we expect and that
was the first time alphago really showed
how amazing it was and the European
champion fine you said it's not a human
move I've never seen a human play this
move it's so beautiful yeah they're very
good in like but that actually happened
to chess the game of chess changed
completely
when computers took over
before that all the humans were playing
what humans are playing it's like I
should do this and this is normal so I
played this and this is very logical we
always do this so that's what we do but
the game of chess really evolved once
computer chess became a thing the game
of chess currently if you look at how
the world champions are playing it's
much more creative it's much more
diverse and this was the first time the
same thing is happening in go and
they're predicting this is gonna be the
game of Go will be changing completely
and will become another a whole
different game maybe much more beautiful
than it was before there was another
spectacular moving game for which was
move 78 I don't have a video but Ghoulie
which is Lisa DOS arts rival said this
move was made with the hand of God
beautiful right but this isn't a move
made by alphago this was a move by Lisa
at all he made another surprising move
which alphago completely missed and
alphago made a couple of mistakes at
least it all actually won but yeah in
the end 41 he kind of got ass whipped so
what can we conclude from this the
amazing thing is nobody thought alphago
what a good or a bad movies nobody
programmed an evaluation function for
alphago alphago isn't an expert system
it isn't made specifically for go sure
it says go in the name but that's about
it
alphago learned by watching others in
self play and this to me is really
amazing because it was using general
machine learning techniques to figure
out for itself how to win a go and
already things started to happen like as
a response to the success of alphago
South Korea announced some safety March
2016 that it would invest 863 million
dollars in artificial intelligence
research
about a month ago there was another
journey they took the best Chinese go
player Chinese and Korean go is a bit
different but his name was cagey and
there was a contest and alphago again
won all the matches
alphago became much stronger this year
and after that they said we're gonna
stop alphago is never gonna play a game
of go anymore it's over because it was
never the goal to win at go the reason
they made this neural network and this
entire system to optimize and self play
was for medical research what they want
to do with alphago which probably isn't
going to be called alphago anymore was
to predict diseases so based on your
symptoms and your past what's the most
likely disease you have and this is the
actual thing alphago was created for and
I really hope they succeed</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>