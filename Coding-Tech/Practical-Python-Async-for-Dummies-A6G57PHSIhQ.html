<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Practical Python Async for Dummies | Coder Coacher - Coaching Coders</title><meta content="Practical Python Async for Dummies - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Practical Python Async for Dummies</b></h2><h5 class="post__date">2018-04-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/A6G57PHSIhQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">some people like async some people like
async because they like the cutting edge
they want to blow their minds for those
in the back what if we used to be able
to make wishes but then someone wished
we couldn't so they want to blow their
minds with async and it certainly can
meet the bill there the basic attitude
is you know async therefore I am
apologies for the bad pun but I had to
stick that in somewhere others are just
doing async because they want they're
doing it for the speed they want it nice
and fast so for those sorts of people
the priority is a shallow learning curve
minimal boilerplate and they just wanted
to go fast so this talk if that's you
the stalk is for you by the way that's
its postman pets banners you've never
seen it before
Roofing along so okay so let's have a
quick sort of refresh on how async is
faster the problem is why a computer so
slow like I'm running something over
there and it's just excruciating ly slow
as far as I'm concerned I've been with
computers a long time and they really
really really ought to be a lot faster
by now given the CPUs they're extremely
fast the science fiction as far as I'm
concerned but lots of programs still run
really slowly you know what's that about
why so slow often it's because the CPU
is waiting for much much much etcetra
etcetra etcetra much much slower
processors to complete and they really
are like that as far as that's concerned
for example getting some data back from
an API call it's excruciating ly slow as
far as the CPU is concerned so here's
something synchronous you do step one
then you wait and you do step two and
the CPU is sort of snoozing in the
middle waiting for the call to come back
and then finally at the end the CPU gets
to process it so synchronous means doing
one thing after the other no matter how
much to be a capacity you've got a sink
and here we've just got three workers
you can sort of do some some things at
the same time and then sort of pull it
together at the end so
I can finish my much quicker so here all
going well as some sort of demonstration
of that so you can see the async that's
already finished and synchronous are
still plotting along and you can also
sort of imagine that if we had more than
three workers we might get a greater
speed-up and so on it all depends on the
nature of the job remember this is not
an advanced async talk so just some
basics is it time to do a total code
rewrite sadly there's no make everything
async decorator so it's not available
but it's not too hard to follow some
simple patterns now these patterns as
far as I've been able to do have been
tested and tried and so on but there may
still be some issues if there are please
let me know but certainly some of them
I've use quite a lot ok these patterns
are based on futures now Python 3 has
introduced a whole lot a good goodness
it's not available in Python 2 and so
futures is a nice way of making async
programming simpler so what is the
future it's sort of like an IOU you'll
get the results sometime later so it's
something you can hold on to you and
there'll be a result so a future might
be a promise to return a translation
once it's complete you hand over job and
when it's ready you get the translation
so the data the results the values will
be known later so we can actually hand
these jobs or these futures to a
function which will iterate through them
as and when they get a result so we
could have something like this somehow
we've got some jobs and for done job
that's just arbitrary name but that
seems quite sensible and futures as
completed and we've hidden all the jobs
we get the result for the jobs as and
when they're done so that's sort of
quite sort of synchronous at that point
and we often call futures jobs to avoid
confusion so we don't go for example
from concurrent import futures and then
talk about futures and they're adding
jobs to them and so on so we just have
we I call them jobs often the examples
do but that's what they are so what's
happening there is a whole lot of
jobs with the results will be known
later they end up and done jobs as and
when they get a result and then we can
process those and so over time the jobs
all get done and end up in the dungeons
on their criteria you've see it you may
have said stop when the first one
succeeds but if you want to see all of
them they'll eventually end up there on
the right hand side some assumptions for
different patterns some important
requirements all the following patterns
assume
independent functions so what do we mean
by that they can be run in any order if
the order matters then then async may
not be what you want to do or at least
not a simple form of async the functions
don't stomp on each other's toes so what
does that mean it's very easy to stomp
functions to stomp on each other's toes
in very subtle ways so manipulating the
same variable altering the same mutable
object for example dictionaries lists
writing to the same file or using a
library which does something under the
hood that you don't know about which may
be they may be sort of colliding and so
on but if you're if those assumptions
are met that you're not having those bad
things happening then can be quite
simple so let's look at some some useful
patterns one pattern I sort of call
results at the end so here we have some
we start off at the top we fire off
three separate jobs in this case those
are cogs for those at the back and then
at the end we sort of gather all the
results together when we've got all of
them and then we process them somehow
we've got them so that's how it works so
the assumptions there are that the
functions can be run in any order can be
run simultaneously all those things pure
functions are the safest bit cure means
no side effects at all not even to the
inputs
that's the absolutely safest way but it
may not matter and you can wait till all
the calls are complete before looking at
the results for this particular pattern
so let's look at the parts I'll sort of
hide bits of the code and show bits of
the code but while it's is there at the
top is pretty straightforward from
concurrent and
futures and then down here there's just
a small amount of boilerplate with
futures thread pool executors and
there's also a process pool executors if
that's relevant twelve is the number of
workers if you're using the latest
version if using Python 3.5 then you
don't need to specify the workers if you
don't want to which is one less thing to
know about and then what we're doing
here is we're giving the results back
using executors map and there goes a
function that takes one input and an
iterable of single and puts goes there
and what happens is we we don't proceed
beyond that point until we've got the
results and at that point we can
actually look at the results so that's a
very simple bit of boilerplate very easy
to memorize I first used that when I had
5,000 API calls to make and I got Malta
in five seconds I thought eight seconds
and then I was able to just crunch
through the results and I thought float
this is worth doing just a couple of
lines of code and it was really fast
okay so what are the parts again we've
got an iterable Bunny got a cold we've
got an iterable of single inputs there
at the top I've just made it very simple
it's just one Sten and that's that's
what goes into the map function over
here that's your iterable so that's
pretty straightforward
in this example I've got my function is
get data and it takes one input that's
an ID does some bogus this or that does
an API call using requests and so that's
what we feed in to this part so I
usually start I write this bit and then
I sort of backfill what I need means how
you're doing it and then interesting
thing about doing it using executors map
is it actually returns things in the
same order that the iterable supplies
them so if your numbers are one two
three four whatever that's how you get
the results it's not how the results are
actually conducted but that's how
they're returned to you at the end so
yeah and that's showing the whole thing
well
yep and this is just to demonstrate that
they you know that's that's the results
coming back as they actually didn't run
I did be a different order if I did it
again but that's how the results
actually get returned once you've exited
the once the map has finished which
could be useful you might want them in a
particular order another pattern might
be results as we go so what's happening
here is we file all these jobs off and
as an as and when they come in we want
to know about them so once again you've
got some assumptions you want to run it
an independent function multiple times
you want process the results as they
come back they could be in any order I
care a better talk about submitting jobs
and as completed some things there
you've got what I've got there as I've
called them comp job but same thing as
done job completed job call them what
you like but once again that iterated
through as and when they complete so in
another thing you might do is up here
jobs you might use a list comprehension
to sort of populate it where you
actually submit the function and the
individual num for num and noms it's
it's recently common to see people doing
that as well so just saves a few lines
yeah and you only accept the context
manager so it's a common you don't have
to use a context manager but the
guarantee you get with the context
manager is when you only exit that when
all the pending futures are completed
which is quite useful sometimes in your
code you can rely on things
okay prerequisites it might be that you
want these things to all happen first it
doesn't matter which order but once
they're all done then this next thing
can happen and then you might process
some results so here's an example from
real life sort of you have to empty the
bin do the recycling and do your
homework before you play on the tablet
yeah easier said than done reality may
vary but that's the basic idea you have
some tasks in
I'm firing off things in parallel all
the time but they just hardly ever get
done they're all failed canceled this
for for-4 for workers yeah that's right
so with the chain steps approach you
have a number of different jobs which
must be completed before another job can
occur that's quite a common thing and
but the prerequisite jobs can happen in
any order doesn't matter win all
simultaneously etc and they're
independent of each other so what we've
got here is you'll notice their boiler
plate at the top you see it again and
again you know you sort of memorize it
it's not there's not they match to it
for some reason I've put in two workers
but it could be something else
info job equals I sometimes people call
it a instead of executors which may seem
a bit funny if you're used to using that
for exceptions but I'm just pointing out
sometimes people do that anyway so I've
done it in this example here we said we
submit the job we've got another job
there and down here we go futures dot
wait and we tell it what jobs we're
actually waiting for in which case it's
both of them and we've got they're all
completed so what we're saying is those
two jobs there we only move past this
line once both of them are done so it's
pretty straightforward and then we might
so we've got there and we might yeah
once we get down beyond wait we can't
guarantee there will be results because
they have actually completed that's what
we specified so we can actually get the
results back and then what we might do
next is we fire off another job the
third job we were going to process those
details and we feed those those
completed results in as arguments and
then we might have something at the very
end where we do some cleanup or whatever
it is we want to do add done call
Becker's sort of quite simple it's one
way of doing it you just say run this
function when it's
all done but you could just sit outside
the context manager and run that then
because that will be everything will be
done by then or you could wait on the
process job I guess for that to be
completed and then do cleanup so there's
a number of different ways of doing it
but this there's not an infinite number
of ways of doing it and that's one thing
I like about this you can learn a few
things and do quite a lot a
synchronously with it
another approach might be you have
multiple chain steps so each of these is
sort of in its own own world but they
sort of that one takes long and when
it's finished then it can do the next
step and then it can do the final step
so the example I've got here you may
recognize this person but I made these
slides quite a long time ago
futures tell me more we have two
functions one function is where we're
getting an image and the second function
sort of memorize that we stick a stick
some text on it obviously you can't
modify an image until you have you've
gotten the image but that's the only
sort of order restrict restriction that
really applies so it doesn't matter if
I'm getting this picture and then I get
that picture and then I finish that
picture and then I finished that picture
doesn't matter as long as internally
there's a sequence so is some
assumptions there each call is
independent of any other call to get an
image same is true of calls to modify
images the only guarantee of completion
order is for the second part of the
chain relative to the first so otherwise
the composite jobs can happen in any
order so the second part of one job
could theoretically happen well will
often happen before the first part of
another so this approach the approach
taken meets us chained together as many
steps as we like and we could have used
the add done callback method or approach
instead in this particular case okay so
what we've got here is that's just you
know just some I've put random I've made
it sleep for a random amount of time so
that I could sort of demonstrate that
things were coming back and what if all
I wanted or not it's just a verbose no
op in the middle saying it's got the
image and then it returns the image
so that's that step and here we're
adding a meme to the image and once
again we're not really actually doing
anything we're just pretending we're
doing it and down here we've sort of
gotten quite familiar with us already
with futures thread Pollux CUDA twelve
workers this time I think I've had 128
and all sorts of things but so once
again we've got a list comprehension
here to populate jobs just using the
executors submit which is pretty
straightforward once again you've got a
function and you can have any number of
arguments you supply the they just come
afterwards so for completed job and
futures as completed then I grab the
result and then I submit it to the next
next round where it's actually adding
the meme to the image and as so
obviously because the first round for
that particular job has been completed I
have the image I can now only the second
stage another approach we might have as
we want to do lots of tasks till one of
them succeeds sort of almost like a life
philosophy but here we go through here
and we do this one every one to cancel
these ones because there's no point you
might have 500 or 600 things you don't
want to go through all of them you've
found the one you found something it's
all you need it so it's not the other
ones off so sorry for the grey writing
but it's just a repeat you want to stop
as soon as one of the functions finishes
and you don't care which one it's the
new bit so what do we got here we've got
we're submitting the jobs it's
straightforward we getting back yeah
we're getting back to things which is
two sets and one of them is called done
and one of them is called not done and
in this case I've said futures first
completed it instead of all completed so
what will happen is when we actually
look at those two sets and done there'll
be one thing and they're not done will
be all the others if you change that to
all completed and you wait to the end
you get done as all full and not done is
empty so it sort of makes sense and the
other one is you can also exit on first
it
exception so here we go you'll have a
done job here with something in it
because we exited on the first success
and then these ones are just still
incomplete and how we get them out is
because it's a set we just pop them out
well in that case we pop out the only
one which is in there and then we can
get its result yeah another thing cancel
what happens is you might want to cancel
all the jobs and the not done job group
because you don't want them to complete
so if we that Ilia over here there's a
little back bars heads we were sort of
not proceeding with them now there's a
little there's some quirks there cancel
what you can I eat what's not already
with the worker so if you fired
something off to a worker it's in
process that's going to to do its thing
but it's not going to end up in the map
not done results you've already
proceeded beyond that but you don't
except you don't get down to here until
no running jobs
nothing's still in process so that's
what that a context manager does
guarantee for you so the program doesn't
finish just because a single job is
finished it even though you're only
waiting till first completed you have to
wait till all uncounseled jobs are
complete to exit that block okay adding
more icing to your code so those are
some basic simple patterns use wisely
obviously async is not who is worth it
like if your script only takes 11
seconds to run and you're not repeatedly
running it all the time then maybe it's
not a candidate for a synchronizing or
whatever another thing is use it wise
using it wisely is make it easy to
reason about your async code so favor
clean syntax and clear naming over
select abstruse awesomeness so sometimes
there are things that if you understand
how it works you can assume this will be
done by this but there's another way of
doing it we make it explicit you know is
completed or whatever
I prefer to make it so that you don't
have to be at your mental best to be
confident you know what your code is
doing or that someone else in your team
understands what it's doing because
because async can go a bit strange
this is joke you know variants of this
joke some people when confronted with a
problem think I know whole new threads
and then - they have their brooms
let's Ned Batchelder and for his good
value so actually there he's got a
collection of lots of those two problems
variants but do use it wisely so don't
hesitate to use async and Python if it
speeds your code up significantly give
it a go ever try and you can cheat using
pre-existing patterns that just work
I hope these will just work that it's
not far off if anything's wrong with any
of them and putting async into the
standard Python toolkit it shouldn't
just be for elite programmers or those
who want to blow their minds the goal is
to make it safe to put asynchronous code
into production with you know teams of
mixed ability in other words the real
world and get it used a lot more than me
you know so acing all the things where
it where it makes sense that is and a
lot of people have helped or a few key
people have helped and this is actually
working code using async to thank these
people randomly in denim and Lee Symes
from catalyst and concurrent on futures
that whoever that represents for putting
this into the standard library so if
you've been doing async using other
things it may be that this is something
you can take for a spin there are lots
of other approaches I don't know much
about them but yeah ok so that's it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>