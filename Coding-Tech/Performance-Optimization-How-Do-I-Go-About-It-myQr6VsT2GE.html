<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Performance Optimization: How Do I Go About It? | Coder Coacher - Coaching Coders</title><meta content="Performance Optimization: How Do I Go About It? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Performance Optimization: How Do I Go About It?</b></h2><h5 class="post__date">2018-03-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/myQr6VsT2GE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is cat thanks for
coming to my talk I'm a software
developer I've been doing PHP for give
or take seven years I also had read like
golang I do a bit of Java at work I do a
tiny bit of Ruby a little bit of bash so
I kind of do a bit of everything and I
quite like to pick-and-mix
i work for a company called bright roll
and they're in bristol
I've lived in Bristol for the last
almost a decade now I'm from Warsaw in
Poland originally so has my slightly
different Twitter handle and today I
want to talk to you about optimizing
performance as developers when we start
working on something and when we were
given a task then we usually probably
like to go off and do a bit of planning
so you either sit down and you work out
what you want to do or maybe you have a
proper planning like agile style if the
sticky notes on the whiteboard and then
you go and write your code and then you
run your tests and your tests pass and
maybe your continuous integration
pipeline passes as well
it's very good to go to production right
well where is performance like we most
of us don't really consider performance
day-to-day when we're working on stuff
and that's a very typical scenario and
you can't really blame developers for
that because analyzing performance is
hard it can be tedious and not many
people know how to get started with it I
mean we all know the theory of what is
it about but how do you actually go
about it how do you actually do it so
today I thought I will show you a little
example of how you can go about it I'm
by knowing and means an expert but this
is just me sharing what I've learned
when I first had to do it for work so
let's start with the first things first
why should you care about performance
I'm not gonna spend too much time on
this because hopefully it's obvious to
most people in case it's not obvious how
about this fast is better than slow duh
memory efficient is good saving money is
good because you may run your app on
less servers if they need less memory
running out of memory in production is
bad and suddenly running out of memory
in production is really bad
I mean probably some of you have been
there I've been there
or maybe you're just forced to look at
performance once maybe one of your graph
starts looking like one of these so the
top one it shows memory that's that's a
typical memory leak up there so if you
have the jaded line at the top and
that's the GC doing its work it's you're
still garbage collecting but overall
over time that line keeps going up and
it just creeps up over time or maybe you
had one of those graphs like at the
bottom with like some spikes in here so
some requests taking 30 seconds or
longer and you're wondering why and
what's going on in here or maybe you had
the dreaded fatal error allowed memory
size exhausted or maybe you just want to
have a look inside the memory and just
figure out what's inside your code when
you're running it so that kind of covers
the whys you know we all have to deal
with it at some point in our lives in
terms of when you should look at
performance optimization you should kind
of be looking at it every step of the
way like every stage of the software
development lifecycle ready so you know
you should be looking at it in dev when
you're writing code or maybe you're
asked to analyze an existing app you
might have a dedicated load testing
phase before you go to production so
after you've done your unit test and
you're your general testing you might
have some kind of performance testing
suite that will run and then see if
you've improved or it may be degraded
performance and then even after you're
done working on your software you should
still still keep an eye on it over time
because sometimes issues only come out a
bit later because maybe the memory leak
is quite small so you only notice it
after some time so you should monitor
your production environment to spot any
issues and then you can just tackle them
right away so that covers the when and
why um what about the what to optimize I
mean we all kind of have a general idea
I like when I like look at problems I
like to start start with this question
do I really need to do this and that's
something that it's so easy to forget
because we're all just like jumping in
and just start micro optimizing right
away and it is really easy to forget
that it is important to take the step
back and first of all ask yourself is
thing that I'm looking at do I actually
need to do it like is this redundant
code maybe it's dead code maybe I don't
need to do it more than once because of
course doing it faster is better but not
doing anything in the first place
is the best kind of optimization you can
make so think about that first and that
applies to you like they said dead code
may be something that you're doing
multiple times instead of ones so kind
of be lazy to start with you know if you
don't need to optimize if you can just
get rid of something and do that and you
know in terms of the general things most
of us have a good idea for what we
should look for so we want our programs
to run faster and consume less memory so
you know we want our garbage collection
pauses short and infrequent and very
efficient so we should we know that we
should probably measure memory usage and
execution time in addition to that you
should probably try and establish your
maximum minimum and average values
because it is important to know what
your apps requirements are and your it's
this adds and your DevOps will love you
for that information and very often
developers just can't answer that
question when they are asked like you
know what kind of server does your app
need you know we just like to chuck
stuff over and go well can you just
deploy that now and then if you can
actually give your sis ads or your
develop some kind of information for
like I'm expecting this app to require
this amount of memory on average they'll
love you for that and then again you
know then what to watch out for when
you're monitoring your production you
know what's normal and what's maybe
slightly off so this is a my very
there's a bit of caveat to this and this
is my very unscientific graph to try and
explain that so we have three aspects we
have memory well memory time and code
and we're all kind of aiming for that
zero point here that Unicorn where we've
got as little memory as we can it's just
the code that we need and as little
times as as possible but it is important
that that's it it's important to keep in
mind that that's zero Unicorn point is
it's not really something that you
should necessarily ain't worth so
optimizing performance is more of a bass
balancing act because it does come at a
cost and the cost is readability of your
code and maintainability
people sometimes just go crazy and they
write really weird coaches because in
theory it performs faster but it makes
sent no sense to anybody else and even
then reading that code three months
later they're like I don't know what I
meant here so it is important to keep in
mind that you do sometimes compromise
readability if you want to do things
faster so you shouldn't necessarily aim
for that zero point like a die hard kind
of thing you should just stop at a
sensible point something that is good
enough for production or for production
it's probably good to stop at so don't
necessarily expect to get to the Unicorn
in terms of again the what there are a
few sort of typical things that we
probably already know when we think
about performance we've got the memory
leaks which is a potential issue so your
amount the amount of memory your program
uses may increase me may be increasing
over time or maybe it is that your app
is just using more memory and it could
use a bit less and you just want to make
it use less memory and that might be
caused by you know leftover
open file handles your overflowing
buffers that kind of thing
timeouts so your app might just be stuck
waiting on something and you don't know
why or what it's waiting for concurrency
if your program is concurrent it's not
something that you typically do in PHP
but you can so if your PHP is concurrent
then you've got all the lovely issues
that come with concurrency like race
conditions and thread safety and
deadlocks and life locks so that's
something to watch out for the tip
normal redundancy and inefficiency so
doing them something more than once and
also dead codes and unused libraries and
you might think that's not really a big
issue but it will affect for example
your deployment speed your compiler
builds step time your a compilation
speed because if you're just pulling
some kind of libraries I don't really
use then you're still taking that time
to do it and then you're not using it so
even stuff like deploy build time might
matter to you and there's obviously a
lot more issues around your server
config you know the where you run your
app have you split it but I'm not gonna
focus on that today so you could do
things like op cache settings
optimizations you could tweak your nginx
and Apache settings and that kind of
thing but I just wanted to focus today
on there specifically the code issues
that you might have
and then when you start googling you
might find some sane advice in the
internets and you know that these are
what I would say just general good
coding habits like sort of that the ones
the two ones at the top and the in the
same ones so it's things like you know
if you have a condition in your for-loop
don't evaluate that every time if you're
doing something you know if you have a
count in there or something don't
evaluate that every time you look for
the function do that beforehand and then
just use a constant in the loop body or
in the loop condition that's pretty
sensible watch out for DB queries that's
kind of very common if you've got really
long if and else ladders and really long
if statements or else statements and
really long blocks and then maybe
somewhere inside you're doing is select
something from the database that you
could have just done at the beginning
for multiple IDs instead of just looking
through the IDs and doing that one by
one something that you know it's easy to
miss and then you get into the things
like you know use empty array instead of
count array equals zero zero or use a
triple equal instead of string compare
for string comparison because it's
faster and then use single quotes
instead of double quotes when you're not
concatenate is which is my absolute
favorite and then you know people say oh
use reg X instead of some crazy string
mangling like that you do manually but
then don't use reg X because it's less
efficient than the native PHP functions
so you're all like what and coming back
to the list of issues none of those
things actually address any of this
none of those tips will help us actually
sort solve the easier xi issues and on
one hand you don't want to ignore these
things because they are just good coding
habits you might as well follow the good
habits and even if they might seem
insignificant on their own sometimes a
lot of tiny optimizations might actually
add up to something
actually making a big difference so
don't necessarily ignore them but and it
this kind of stuff might might matter if
you're not actually addressing in an
actual problem with a memory leak maybe
you're just trying to squeeze out like
the last bit of performance juice out of
your app then yeah maybe those tiny
optimizations will actually make a
difference but you know is it really how
most of us should go about optimizing
performance
and just to show you this so these are
some stats taken from I've got a link
here I've shredded the sides already so
you can check out the whole website so
this is from FEMA Mattox websites so he
runs PC benchmarks live on his server
the server is running PHP 5.3 but it
doesn't really matter because it's kind
of the same thing in seven even and he's
just compared to the typical things that
you find on the internet and just to see
if this is actually true so this is the
single and double quote myth and you can
see here that you're only actually
shaving off two milliseconds I mean
that's a drop in the ocean that's not
really causing your memory issues and
there are some other ones so you know a
lot of us might wonder like oh is
variable before the constant you know
should the variable go before the
constant in on a on an equals comparison
or the other way around no difference
whatsoever three milliseconds you know
if you're doing hey stuck zero is N or
string position to just check the first
character no difference string replace
compared to preg replace only three
milliseconds difference I mean that's
not a huge difference and all of those
tips what they all have in common is
that they are all micro optimizations so
I would say 99% of the time ignoring
them every time it is worth looking into
those things when you have evidence that
they are actually causing problems or
they are a bottleneck and you should you
should try to micro optimize maybe bits
of your code not the entire app I mean
don't go off and start changing it
double quotes to single quotes
everywhere and that's that's probably
not the way to go it's probably not
worth spending time on or arguing about
I mean I've had so many pointless it's
like vim vim versus Emacs like which
quotes should you use and you should
always benchmark and measure to prove
that you're actually improving
situations don't just do this because
you've read about it on the internet
somebody on Stack Overflow five years
ago said that that's what you should do
now always measure always prove that
you're actually doing something right
and most importantly don't miss the real
bottleneck like don't focus on these
things because there's probably some
more important issues to tackle so focus
on the whole paths in your code or whole
areas
well that's all good and well I'm good
focus on the whole paps in there yes if
you know how but the how is what most
people get stuck on and I got stuck on
that as well
if you already know how that's all well
and good but really how how do I know
how do I know want to improve how do I
know my how my app is doing how do I
gain that visibility into my code how do
I know what my app can handle in
production how do I know it's not
leaking memory how do I prove that no
will I run out of memory or maybe I am
over provisioning and maybe my app
doesn't need the massive server that is
running on how do I prove my guesses how
do I prove my theories and the general
answer is of course measure but then how
do you measure and what do you measure
and how often do you measure so I was
there myself I had all these questions
so I thought it might be useful to do a
practical example of maybe how you could
go about answering those questions and
how do you actually go about doing it so
let's start with the tools and this is
potentially the first very confusing
very or overwhelming things when you're
starting out because there are so many
of them and people tell you use this use
that is this and you're like well but
what is everything for like how do i you
know why when should I use this when
should I use that and it is important to
know what each each tool is useful for
like what's the purpose of it over tool
and I've kind of tried to group them
here by roughly what the purpose is so
you've got your monitoring tools at the
top those things like data dog New Relic
Blackfyre IO your typical Elks tag
graphite loads of those things out there
and you might be lucky enough to
actually already have something like
that set up for your system so you may
already have some performance data
available you know if you've got
something monitoring your memory usage
or CPU usage for example you've already
got some data and I will give you the
the bigger picture the idea of you know
how your app is doing in general how
it's doing over time has it gotten
slower hasn't gotten faster and you
might be able to tell from those graphs
and from those tools if there is
anything that you need to worry about
you know if you see spikes if you see
something worrying then you probably
know that you should you should look at
your app if you don't have any
production data available you could use
load testing or the benchmarking tools
and those are basically tools that will
generate the load for you and they there
is a million of them I've only listed
here a bunch of them my favorite one is
go work for simple things that's a go up
and it's just a really simple simple to
use app there are some more complicated
ones that take a little bit more time to
learn and use so things like jmeter or
Gatling and Taurus or Apache bench they
allow you to do a lot more they allow
you to customize your load they allow
you to specify different parameter
varies a load that sort of thing but
they are a little bit more difficult to
set up and sometimes you know just a
really big loop in your code like four
at ten thousand iterations do this
that's also load generation you know so
you can actually just do it yourself and
the goal here like the goal of those
load testing and benchmarking tool
benchmarking tools is really just to
avoid sitting there and refreshing your
have multiple times especially if you
want loads of data like you're not going
to sit there and press the refresh
button in ten thousand times so that's
what those tools are for but monitoring
and benchmarking will only give you a
higher level view and and sort of higher
level data about your app they won't
really tell you what's going on inside
your app and so for it to dig deeper you
need more detailed information you need
things like low-level Stax stats and
stack traces and your memory usage and
execution time for every single function
in your code ideally so you need
something called a profiler and then
usually profilers will do gent like
gather the data for you but they they
will just spit out a bunch of files that
when you open those files they make
absolutely no sense to you so you
usually need some visualization on top
of it to actually help you make sense of
all the data that you have so how does
that look for PHP well for starters none
of this is built into the language which
is great I mean compared to gogo has
most of these tools just shipped with
the language so actually when you
install go you install all those tools
with PHP when you install PHP you
install PHP you don't have any any
profilers available you could roll your
own I mean to be honest I'm not against
just doing micro time at the beginning
micro time at the end and then just to
subtract them that's how long my
function take I mean for a quick and
easy and quick and dirty of
sort of measurements I think that's
completely fine but if you wanted
something you know you're obviously not
going to do this across your entire app
so to do that you kind of needs a more
professional tool and most of those
tools are available as PHP extensions
luckily you don't need much extension
food to get going I mean I'm not an
extension this expert and I managed to
install a lot of them so it's quite easy
so just to recap this is how you can
install PHP extensions I'll probably go
through this pretty quickly cuz
hopefully you you know this your mileage
may vary because obviously depending on
what platform you're in how you know how
old is your operating system that kind
of thing some packages may or may not be
available the you know the actually most
convenient way these days for me because
I run a Mac is just to use homebrew if I
can for all the extensions so if
homebrew or whatever package manager you
have like yum apt-get whatever your
distribution is you just do that
install name and boom done your
extension is on your system you can use
pickle which is part of pear and so once
you install pickle on your system you
can do pickle install name of the
package that should work the S word or
you could compile from source and that's
actually not as scary as it sounds so
what you have to do is just get your
source code down so usually get clone or
something go into that directory you
you're on you run something called PHP
eyes and then you run something called
configure this is kind of like
installing siaps whoever did see
development this will sound familiar
because PHP is written in C any options
for the extensions usually the readme
for the extension will have those
instructions there so always check out
the readme this is just like a
generalized list then you do make make
install and then you need to not forget
to put your any file in your app each
piece like comedy in ease directory
because that's how you actually load the
extension into PHP so tell PHP use that
extension and you can specify your any
values there if you do Pecola brew those
any files are usually created for you
automatically so you can just edit them
on the Mac I believe it's user local et
Cie PHP version and then confidence
where your files live if your is using
brew homebrew which to be honest I mend
it because it's just that the least
painful painful
so let's go get ourselves a profiler
this is a list of the ones that I found
there is probably a lot more in github
the first one APD that used to be an
extension used for profiling and
debugging but it is actually no longer
maintained I think the last main paned
update was 2004 2007 so I kind of cross
that out because I think we should just
forget about it the two most popular
ones and I probably all heard about them
is XD buggers and the exit probe and a
lot of people wonder like what's the
difference between them and which one
should I pick so both are installed as
PHP extensions they are both available
via homebrew for example which is
slightly easier I'm pretty sure like
apt-get has packages as well and the
deal with that is that in the old days
of PHP 5 old some of us are still in on
55 but in the old days xdebug didn't
have memory profiling built into it
so you could do your step debugging and
you could do some profiling but you
didn't have the memory information or is
the xh probe which was developed by
facebook and then open sourced that gave
you all the memory information so you
kind of had to use both but since PHP 7
facebook is no longer maintaining exit
probe because they've moved from Zent to
a to a JVM so they've abandoned that and
luckily some kind souls created PHP 7
for X of the XS rough extension so there
- probably most popular ones are tied
ways and again I've put links here I've
shared the slides so you can like click
through it and find it on github so tide
wise exit rough extension which kind of
is now just becoming their own product
in their own thing and they've slightly
modified the original X which broth or
there's this Chinese person on github
that I will probably butch the name so
I'm not gonna attempt to read that but
that that Chinese person has created a
fork for PHP 7 which is actually very
very close to the original XH profit and
in terms of when you should use these
like they are they are absolutely not
mutually exclusive so you can have both
installed on your system and you can use
both at the same time the one thing to
remember is X debug should only ever be
run in development I mean it will make
your app a lot slower if you use it so
don't ever run it on production
exit proof can be used on production if
you had to it's actually it's it's got
such a small footprint that it won't
really affect the performance
of your app so that's something to keep
in mind if you have to use it or use
something on production it's probably
going to be X 8 prov and then there are
other things like the memory profiler
and the mem info there are two other
extensions that are that also allow you
to profile your memory we're gonna have
a look at PHP memens info in a bit and
there is probably a lot more but I just
couldn't didn't have time to go through
all of them so guessing really isn't
enough like I mean you might have some
ideas to start with for what might be
causing your issues but you really need
to work out and prove what's going on in
your app so doing instituting some
Diagnostics before you do the diagnosis
now so I tried to find a real-life
example to do that demo on and then
anything I worked on at work would just
be too big and I would just take way too
much time to explain what it does and I
would probably bore you to death and I
also didn't want to give you an example
with like foo and bar and Class A and
Class B because that's not really how
real life is I mean we can all optimized
a 5 long feed for you but that's just
not what real life is like so then a
friend of mine Matt that you probably
know well you probably know Bronte he
tweeted about his side project and I
just randomly had a look and I was like
oh this is a really lovely pH v7f that
just just fits that need perfectly to
come and line up so I used brunches off
as for my demo cigar which is the name
of the app it's a smoke testing tool so
what you do is just you specify their
URLs and the expected HTTP code and the
any expected content see if you have it
and cigar will just run through the list
that you specify in the file and compare
what you expected to get with what you
actually got and if everything's fine
you go yep I checked those URLs I got
the HTTP codes that you expected I got
the content that you expected
everything's fine
that's all it does so you already know
it will make some external calls to the
internets and you don't really need to
know the full details I'm kind of doing
this on purpose right now because in the
real life very often when you're asked
to optimize something or look at
something you might know very little
about the app you might not be the one
the person that originally coded that in
so you might even not know what the code
does you know all you have is just some
vague idea for what the app does so
let's imagine the first
now if the app is running slowly now
somebody comes along to us one day and
says hey that's cigar a tool that used
to take you know not 0.5 seconds to run
that's taking something like 3 seconds
what's going on so well we can set up X
each probe to start with and see what
that gives us so the way you set up XH
probe is this is on on the readme so you
can just copy and paste from the readme
x' you basically just add a bit of code
at the beginning of your file and then
at the end so the first bit is just
enabling X which probe and then the
second bit is just disabling it and then
saving the data to to a file and you can
just copy and paste like we did here so
copy and paste in in any file that you
need it doesn't have to be right at the
beginning or right at the end like you
can just profile bits of your app you
can check those two bits of code in a
separate file and then include them or
require them for every file to avoid
copying and pasting this all over the
place or you could use the auto prepend
and order append any directives - then
get PHP to automatically prepend and
append those two bits to your code so
you just don't have to worry about it
and an X which probe gives you a browse
review at the original xh probe gives
you a way to view the results in the
browser
the Tideway extension and that's the
reason why I actually haven't used that
extension for this demo I think they've
gotten rid of the original one because I
couldn't find it anywhere there's there
is a directory called xh probe
underscore HTML which is actually the
HTML viewer and that's not in the tied
ways extensions or at least i couldn't
find it so i think they might have
gotten rid of it in the original xh
probe this is the original kind of UI
that you get when you run it and exit
off will spit you out a URL when you
when you run your app so that you can
just click on it and go to this and you
just give it a run number and some other
stuff i mean this is all on the readme
as well so you don't have to remember it
and that's the first page so what you
see here is well we've got the main
function here and then we've got some
some of our code some of our Sagara code
we've got the parse function we've got
get URL objects and then we've got a
closure here so and those are the top
three ones here and they seem to be
taking over 2 million microseconds I
think that's the unit that they use here
so the first most important thing in us
again what a lot of people tend to
forget is to establish a baseline so
before you actually go and change a
single
you need to know how your app is doing
now so then you can compare after your
changes you can convert results after
your changes and see if you've improved
things or maybe you've made things worse
so always make sure that you grab that
baseline first before you go off and
change things so our baseline is the
three point not 64 seconds that we saw
earlier on and the next edge proof also
whoa this is really bleak but it doesn't
really matter here so exit ref also
gives you a call graph you can click on
the call graph Cobra call graph link and
it will help it will try to be helpful
and you'll try to show your hot path
here so this one you probably can't see
this but this one is the parse function
the big red thing is the parse function
so it kind of agrees with what we saw on
the list so exit proof is kind of saying
that well this parse function is taking
the most time but that's kind of as
close as we can get to the code of xh
probe we don't really know what's inside
that red box we don't really know what
the code is so but at least we know now
what area to focus on I mean we know
this the get URL objects function is
something that is causing problems so at
least we it allowed us to now soom zoom
into the bit of code that we might be
interested in but then how do we find
out what's going on inside that function
well we could obviously look at the
source code at this point which is
something that you might do but let's
use X debug so the way you set up xdebug
this is actually something that you get
out of the box if you use homebrew it's
just three directives you basically just
enable it give you the give the output
directory for where where to save your
output files and then just give the
output name for the files so you save
the files as cache grind it out with
some random number at the end so you
don't get clashes and then what will
that what that will do is every time you
run your app whether it's a browser app
or a command line app X debug will work
in profile your app behind the scenes
and save the results to a file but then
again the file when you open it is just
a random string of nonsense ready it's
not nonsense but it doesn't make any
sense to you so there are some there is
lots of you eyes to view XE bug data I'm
gonna use Q cash grind or K cash grind I
think it's on Linux which that tool
looks like it's from 1995 I mean it's
been around for a long time but it's
see the thing that still most people use
as the default is debug UI there are
other ones there are paid versions on
Apple Store you can use something called
web grind so there is there are a few
options but cue cash grind is actually
not too hard to install these days you
can install the fire brew with the
caveat that you can't see because it's
too it's it's it's not visible enough
but basically on the latest Mac if you
install it via bro because of the
changes to security that they've done
that you can't put binaries into user
bin anymore and they are in local cue
cash grind can't find some of the
binaries it needs so this is a
workaround thing and I'll share I've
shared the slides already so you can if
you run into this this is a tiny
workaround we created a shell wrapper
around it to get it going so it does
work on the latest Mac even though it
really looks like an app from kind of
like a 1995 so first of all you have a
drop down here called sorry there is a
drop down with time or memory so you can
select do you want to view time
information or memory information so we
want to view time because we're we're
now we're looking at time and we've got
the same parser font functions at the
top here so we kind of see the same
results as X X X X H probe and on the
right you've got something called the
color map and that gives you this weird
looking pyramid diagram and it might
look very confusing at first but
basically if you're looking at
performance what you need to what are
you looking for what you're looking for
is big squares with nothing in them
because that means that proportionally
that squared that green square took the
most time in the app but it didn't call
any functions there's nothing inside it
no dots no squares inside it which means
use the last function that the profiler
on the in the profiling trace that was
found most of the time and when you
hover over it that hover is the Paris
class here so again the way you read it
is that those little squares here you
might think that oh that's really busy
that's that's something going on in here
that's actually nothing to worry about
that's just lots of functions calling
other functions and taking a relatively
small time overall so what else can we
get from cue cash grind well at the
bottom there is a tab called call graph
so you can get the call graph and we see
the same same things as I've
xh prof and then we can see here that
this this one is the closure so this is
taking a very long time and closures are
one of those things that are really
really hard to debug to debug when it
comes to performance because the tool
won't give you a name of a function
right away to look into they will just
say like oh in this file there's a
closure and sometimes you might need to
work out like which one is it so that's
that's a little bit tricky to work out
and then if you compare the two that I
just did it for just out of curiosity
comparing the two call graphs they look
the same so they they are from two
separate runs so the overall time parse
in exit row F is shown as 81% of the
time and then here it's 79 percent of
the time but that's because it's two
separate runs so your your data will
vary between the runs slightly but we do
kind of get the same general idea that
that parse function and that one seems
to be taking quite a while so back to
cue cache grind we select the second
function from the top so this was the
top on is main which is always going to
be at the top obviously and then there
is the array map function and here you
can see so the top the top section here
is the colors of that function and at
the bottom one is the Col deze of that
function and in the Calise you can see
that closure well you can't see it
because it's probably op visible but
that is that has the closure in the list
so then you can you can do even more
cool stuff in queue cache Brian can you
view the source code here so when you
click on the view source code well some
weird stuff like hi equals four that
kind of thing or maybe somebody might
have put some code in there to calculate
pi as well as fetching the urls in they
get URLs for objects functions so when
you then look at the code that's
actually I've just I've just pasted that
and it wasn't that it was me so I just
made it slow on purpose to make it show
in the graphs but that's kind of how you
arrived at what bit of code exactly is
taking the most time and so then when we
remove the PI code we've improved things
it's back to not point three seconds
surprise surprise so we've got a reprove
here we've actually you know we've got
some some numbers so it's not just me
saying oh I think that was it you know
I've actually got proof that I've got a
down from three seconds to not point
three which is kind of what you want and
then just for completeness we run exit
off again this is the top of the list of
the functions it doesn't show up there
anymore there's no parse here and
there's no parts here and then somewhere
at the bottom there is the get URL page
and it's now so now it's something like
seven hundred and thirty seven
microseconds versus the over two million
milliseconds so exit proof is setting
saying the same thing we've made it
better and again this does didn't really
show up too well but this is the call
graphs and now so this is the old one
where the parse was here and then parse
is somewhere here which you completely
can't see I apologize but now exit proof
is showing us a different hot path that
it thinks might be now the busiest path
and you also can't see it but this is
all gazelle classes so gas weighs a lot
at an HTTP library that used for making
requests and then we know that this app
is likely to make external requests so
this isn't necessarily worth worrying
because well you know it's what we
expect from this app to use guzzle and
to mostly use guzzle to do its job
so this is not alarming anymore one
thing I would say is don't discount
library code from your from when you're
optimizing performance because the fact
that it's a library it's still code it
can still have bugs it can still have
memory leaks
I mean I've at work we've had a memory
leak on one of the metrics libraries
that we've used so when you're looking
at performance just because you see some
familiar names like always guzzle or
it's Symphony or ads and or whatever you
know most of the time you can trust that
they've done a good job and they don't
have any issues and it's just because
the app you know mostly makes external
calls but it could be you know if you're
if you've spent hours looking at
something and all your clues point at a
library code by all means look at it
because it might actually have some some
issues and they make a pull request
obviously so then back to queue cache
grind we've got parse we don't have
parse at the top there is a handy search
as well so you don't have to look
through it nowhere near at the top this
now looks different and now this is also
guzzle so we can see that Gazzola is
taking proportionally the the most time
so this is kind of what we expect now
that was a good spur step you know that
was like yeah we've done something good
by the way
you can also view xhd
xD bug profiling things in phpstorm for
those of you who use it in tools you've
got something called analyze eggs debug
profiler and that gives you something
like that it gives you nowhere near as
much information as Q cash grind so it's
not really a replacement but if you just
want it to view something quickly you
can do that it gives you something
called like a cull tree so you can like
in a typical phpstorm where you can do
the drop down drill drill drill into the
drop downs one caveat with that is with
p2p 7.2 the stable phpstorm version
doesn't actually work with this it can't
open it X debug 2.6 files so you have to
I have to install the EAP version and
the EP version seems to be fixed for
that so I think it's in the 2018 release
that they'll actually put those bug
fixes in so just to keep it keep it in
mind that you might have to go go for
the EAP version if you want to use this
4x debug so what more can we get here
from from the X debug output and and
what more can we seen and Q cash grind
well one of the cool things it shows you
is this column shows you the number of
times a function was called
which is kind of which is which is
really handy sometimes so here for
example we've got 123 calls to string to
lower and you might be wondering like
you know why is that and then again you
can look at the colors list which is
really handy because that shows you all
the classes and all the functions that
have called PHP string to lower which is
quite handy and here we can see that so
all of these are again guzzle functions
and all of these functions here are to
do with headers so it's something like
heads set header get get header add
header that kind of things so we can
guess that guzzle is lowering all the
strings using that function when it's
setting the headers and again because
it's doing a lot of external requests
it's no wonder that it's doing you know
over 100 calls to that function so the
reason why I'm showing you this is that
you can really gain a lot of
understanding of what your code is doing
when you do something like that you can
click around here all of this is
clickable they're going just click on
these things and get an understanding
for you know what's what's exactly
calling this is this something that
should be worried worried about or is
this normal and unless can we see so we
can see that we have 9 calls to the F
open function and well we know that
our the cigar app is only opening a file
once it's got one config file that will
it will read the list of URLs from so
we'd expect more like one call to F open
and again looking at the colors list
here we can see that this is our get
file contents function which is actually
the one that ended the file that we the
config file that we are reading there is
also some guzzle things and again you
might be wondering what is guzzle open
doing with F open like is the opening
files no maybe it's some temporary files
that it writes down and again you can
look at the source code and you can see
here that is the PHP temp some writes to
PHP temp so then now you know that Gazoo
is actually writing some temporary files
as part of its work and again that kind
of visibility you can gain by by just
clicking around so now we can flip the
drop down here to memory and come back
to our get file contents function you
can search for it or you can just find
it in the list so we click on that and
you can see that the you know we do like
an F open F read an F close and that
seems to be taking quite a bit of memory
and I wonder because since we and this
is kind of the part that mostly just
comes with your experience or how
quickly the light bulb is gonna go off
in your head but when you think about it
we're only reading from the config file
we're not writing to it and there's a
different function in PHP for doing just
reading from file called file get
contents so again you might be wondering
oh is it gonna be faster if I use that
function instead or like is there gonna
be any difference at all and so we saw
we swapped that function and then sure
enough just file get constants here now
gives you instead of over 8,000 here in
the memory forget what the units are I
think it's bytes now it's like four
hundred and ninety-six and then overall
if you look at the colors list so the
parse function which then inside calls
they get file contents that was 512
before and now it's 496 now so again you
know now that using that function is
faster in your case so you should
probably go with it but again you've got
the hard proof you've got the numbers
but this is actually better and this is
so easy to play around with as well like
you can all you have to do is edit
code your ex debug is running in the
background you just run your app again
you get a new file you open it and cache
grind and you've got different results
so this is a really quick feedback loop
it's not we're not talking about minutes
to compiler anything so it's really easy
to play around with this if you want to
play around we're using different
functions see if it makes a difference
maybe it does maybe it doesn't and by
the way for this case xh prof wouldn't
show us any of this information so in
the UI you can click through things so
when i click on the get file contents
thing function from the first list this
is as far as it gets me clicking on that
link takes you nowhere further so this
is all you get and this is the call
graph and it just shows you that parse
function that then calls get file
contents but you don't know anything
more than that like f open doesn't show
here so you wouldn't get that
information from xh prof in this case
and this is why you should really use
all the tools i mean don't just stick to
one because sometimes it might help you
sometimes both might show you the same
results but sometimes one of them might
be much better than the other or it show
you more information so by all means go
ahead and use as many as you want or try
out new ones so what if you want to do
some general export like explorations I
mean those were things that we could
kind of spot as maybe potential problems
but what if you want to just know what's
inside inside your memory in your app
maybe there is something that could not
be there so you know and how do you
check that your program is not leaking
memory for sure you can inspect you can
you can look at the memory numbers index
debug or an or xh probe and kind of
guess on that you know roughly how much
memory or take your you're taking and
does it go up between the runs does it
not go up you could watch your
monitoring graphs your production
monitoring graphs obviously those are
good things and if you look at the GC
stats for example you know if you see
something like this so these are all the
GC phases that's okay because the
overall this is flat so as long as this
stays fats that that's fine this is just
GC doing its its stuff but it would be
nice to know what's in your in our
memory at the end of the run of your
program like of what what exactly what
objects are there when you finish
running your program so for that we can
use the PHP mmm info extension again
once you install it you just need to add
one
so at the end this basically just tells
to save the output to a file
it saves output in JSON files so you
can't actually open them and make sense
of them which is nice so this is all you
have to do you just do mem info-dump and
it will shove some information into the
file that you can then analyze and
Explorer it also comes with an analyzer
that is just a PHP app so comes bundle
up with everything you need so let's add
that to the end of the parser file and
the sorry not the parser file so this is
the entry whoops the entry file to
cigars so every PHP app is gonna start
with the procedural file so this is the
main binary file that you for cigar
so you just we just add it at the end of
the main file so we know that we're
gonna get the data at the end of the of
the whole app and then you use use the
analyzer so it just it's just a binary
that you run and you've got a summary
called for example which is a good one
to start with so just do your summary
and then the name of the file and it
gives you something like this and it
gives you the exact count of Alden um of
all the objects that are in the memory
when we dumped the output to the file so
we can see how many instances of
everything are there I mean there is
some output or and parser which is the
cigar code and there are strings array
integers there is URLs there's results
all sorts of things we've got 44 strings
for example this is how much memory they
are taking it's pretty useful and the
cool thing about it is that if there was
a memory leak you'd probably see an
object that you wouldn't expect to see
here like if there was an object that
you would you'd think like why is why is
it here and on top of that if there was
like a hundred and something instances
of it that might be a warning sign sign
so this is quite a good outfit like we
see nothing warning alarming here but if
you did see like a random object that
you'd think it should be long gone and
there's a hundred and twenty four of
those things and maybe you shouldn't be
that's a really good good tool for that
to spot any of this and by the way for
this demonstration I tried to create a
memory leak to show you like an actual
memory leak here but it's really really
hard to trick PHP seven into memory
leaks these days like I've all my tricks
I've known from PHP five don't work for
PHP seven so if
leave open file handles if you leave
circular references to objects none of
this work simply to be 7 anymore it's
gotten a lot clever more clever so let's
just for the sake of the demonstration
and see what you have here well we've
got our favorite parser object again but
then if you think about it when we look
at the source code we create the new
parser object and then we parse the file
to get the config so get the urls that
we are we're gonna call and then we do
the calling like we do we do this a
synchronously so we only read the file 1
so we only need the parts parser object
once and never again because we only
read the file information once so why
the hell is it still in the mem in
memory at the end of it it could be that
because overall your program it is not
taking a huge amount of memory the GC
just doesn't get to it like maybe if
there was a moment more memory used the
parser object would get cleanest as part
of it but maybe not so so why so so why
is GC is not cleaning it likewise why is
that object still there at the end of
the file when we we only use it here and
we don't really need it anymore
so we looks like we are creating a
variable here and we're using it here
and when you look at the when you look
at the query command in the analyzer you
can filter it by class as well so we can
zoom in to the parser function
specifically then it gives you all the
information about that particular object
in memory so gives you the ID of the
object tells you that it's an object of
this class there's two references to it
and it's a root so it's not a child
object and it's in the global execution
frame which is what we would expect
because we're in the main procedural
file so it's a global scope and then can
we dig deeper like well we can we can we
can use this ID in the next command
which is the ref ref ref command which
shows you all the references to that
object so we have two references here
one of them is the self reference here
which is the self reference from the
object to itself and every PHP object
will have it and then the other one is
from the global scope too
a parser object so that kind of gives
you an idea for for if you want to find
out if you've got lots of objects in
your in your memory and you want to know
what is the reference that is preventing
this object from being GCE then that's a
great tool to use because that will show
you exactly what is still referencing
that object like in this case this is
not alarming this is yourself in global
this is what we expect but if there was
something suspicious if like something
else was reference was referencing this
object or that we wouldn't expect you it
should show up here so that gives you a
good idea
so out of curiosity we can look at the
Global's ID as well so in the in the
previous one you can have the ID here
for the global scope and if you do that
you can see all the familiar PHP things
so this is get post cookie files request
server all of that stuff is here in
memory in the global scope so can we
make that parser object go away I mean
we don't really need we know we don't
need it so is there a way to do that
well PHP gives you the option of
creating that object on the fly and then
calling that function on the newly
created object but without really
keeping it variable attached to it
so does it change things if we do that
instead I mean we know we don't need
that purser variable anymore so then we
run the analyzer again after we have to
run the summary comment command again
and then it's gone it's no longer in
memory so again we've got the hard proof
that we've done it and it's no longer
here in memory and this is something
this is a good trick to keep in mind
that that sort of dynamic reference if
you've if you know if you're creating an
object just for a single use and you
might not need it anymore especially if
it's in the global scope and you want to
make sure that it doesn't necessarily
hog the memory that's a good trick to
keep in mind and again you can run your
analyzer didn't find out if it's
actually working or not so just to make
it clear I have to be clear none of
these things were in bronty's original
code he didn't make any of those
mistakes he's done his performance
homework I have made a lot of edits to
this code to make it to make it bad so
thank you much for letting me use this
so I hope it was useful to see the demo
like this and I hope it seems a bit less
scary now there are many many more tools
out there all of them have read me
so we can probably work out how to run
them it might seem a bit I mean this was
a small team demo and I already knew
where I was going with things normal
performance optimization might seem very
tedious at times they might seem a bit
daunting but it is so rewarding at the
end of the day it's really worth it I
mean you know the feeling that you get
when you get the final result and you go
yes you know I've got it down from like
three seconds to not 0.5 seconds
it's really worth it even though it
might seem a bit tedious some key
takeaways just to summarise um
prioritize what to focus on look at the
gains versus effort it would take to
optimize something and focus on the most
important things first I mean the very
reality of most of for most of us is
that we're given a specific time to
optimize a project and you're just never
gonna do everything that you want to do
so just focus on the most important
things and ignore it micro optimizations
unless you really really have a good
reason to worry about them design
changes sometimes redesigning your whole
app like actually changing how it works
is way more important than single code
changes or your flipping of your single
quotes or double quotes usually try to
focus on the hot paths I mean you can
use the exit probe as a guidance for for
what's the hot path but not always you
know sometimes the hot path is there
because that's the nature of the app so
definitely don't ignore the rest of the
tree you know don't sort of take it for
for a silver bullet always customize
your optimization for your needs I mean
there is usually more than one way to
optimize there's usually more than one
correct answer to make something better
and don't be afraid to break the rules
don't be afraid to break the rules if it
works for your use case so it's kind of
the same thing as denormalizing
databases I mean in theory you shouldn't
do that because your deed normalizing
things but actually if it works for your
particular use case then you should do
it and it's the same with performance I
mean you know maybe you're not doing
something textbook correct but if it
works for your case if it makes your app
faster don't be afraid to do that use
the data to prove your guesses measure
everything keep in mind to do this with
minimal impact on on performance
especially in production so try and
avoid profiling in production if you can
you can just do all of that stuff in
your web development but
always measure everything always have
the benchmarks to prove your your
guesses and remember that performance
optimization is an iterative process I
mean it's not enough to do it once you
usually have to come back to it over
time you need to know your trends over
time you need to observe how they change
over time so have monitoring in place
maybe have some other thing in place
based on the trends you could run your
automated load tests to prefer prevent
degrading performance so you know you
could run it after every commit even to
make sure that it doesn't make things
worse and for the VIP experience this is
something that C does and they have a
really good blog post about it they
actually have a graph which which shows
the memory usage and they've correlated
that with deployment so actually they
have vertical lines for every time they
deploy something and then you can easily
see that after this deployment the graph
suddenly spikes so you know exactly what
deployed which deployment made things
worse
which again just helps you narrow things
down a lot faster that is all for me
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>