<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NodeJS: What's Next? | Coder Coacher - Coaching Coders</title><meta content="NodeJS: What's Next? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NodeJS: What's Next?</b></h2><h5 class="post__date">2018-02-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gss9zu4Afz8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello so I'm just now I work for near
Forum I have the other distinct pleasure
of it you know that they pay me to work
on node full-time so every day I could
have my my hands in node core working on
the open source stuff just full-time
components one of the things that I like
to focus on within core is kind of
what's coming what's the new stuff you
know where you know where does the
platform need to go right so we're gonna
take a look at what's happening in core
what are the new things to expect over
the next year this is a very important
point there is no official roadmap for
coral what happens in core is whatever
is the priority of the contributors and
most the contributors are users so it's
whatever pain point they have well you
know what problem are they trying to
solve for themselves those are the
things that we're working on so we can
take a look at what those you know what
people are doing to see where the where
the platform itself is gone if you stop
to think about this the fact that there
is no technical roadmap you think about
the millions of developers that are
using this the businesses that are you
know basing their entire operations on
on top of node fact that we have no
official technical roadmap is actually
quite significant so let's see you know
we're gonna take a look at so it did
some of these things that are folks are
actually doing what are the priorities
that we've seen we know these are
priorities because these are things that
people are actually working on number
one by far the the most important thing
that we've seen and this has been
consistent as improved diagnostics and
instrumentation so understanding what is
happening in your node process what's
happening inside the event loop well you
know what's you know what's keeping it
alive what you know what are the you
know what what are the performance
bottlenecks improving this has
consistently been the number one thing
people about have asked for improve
standards support so we have HTTP to now
better URL parsing things like that
alignment with the web platform so
things like yes and the module
things like better support for web api's
greater platform diversity what this
means as nodes not just about v8 anymore
it's also about Chaka core it's also
potentially about other BM BM platforms
that could make it spin underneath so we
can talk about some of that improved
developer experience and some stronger
security process processes and kind of
touch on a little bit of that here as
well so let's start with the diagnostics
and instrumentation again this is the
number one thing that folks have been
asking for consistently a couple weeks
ago I just kind of did this informal
survey of folks just asking around
what's your number one problem with what
score every single person small
companies up to the large enterprises
came back with the exact same answer
their number one priority is figuring
out why the apps not working as well as
it needs to write the tooling is not
quite where it needs to be and needs to
continue to evolve core itself needs to
provide better primitives internally to
allow these tools to work work better so
we have a number of things that are
going on right now to improve those
internals and improve that
instrumentation some of this stuff you
know deals with tracking the context do
asynchronous operations so long stack
traces right profiling an event flow
understanding about the inspection
debugging there's a number of other
things in there as well but these are
the high points so let's talk about a
couple of specific things so let me go
through a lot so I'm just kind of
touching on the surface of a lot of
these things we can go into more detail
if you catch me out if any of these
things if you have any questions and we
can deep dive on specific things later
but I'm going to touch on just just the
high points the async oaks API has been
being worked had been worked on for a
while it's been in for things since
since version six it has gone through a
number of of evolutions but it's finally
starting to stabilize for those of you
that don't know what a sink cooks do is
essentially a low-level primitive that
allows you to peek at what's happening
in the event loop within core everything
is based on you know we have
or handles and requests handles are the
persistent resources the requests are
the asynchronous operations that are
that are happening on those right async
codes basically gives you the look at
the lifecycle it lets you know when
these things are being created what's
being created it lets you know when the
the actual callbacks are being triggered
so you can do things like measuring
latency between you know these various
events you can track your resource usage
there's a variety of things that you can
do there's a whole bunch of process
management tools that are being built on
top of these primitives right now one of
the very important things is being
looked at is a reimplementation of the
domains functionality that's in core on
top of this so that hopefully that
doesn't suck anymore so we have our
biggest going on there so async cooks is
one and I have to say out of everything
I'm gonna talk about is one of the most
important things that you need to be
aware of within core it is pretty low
level not everyone will you know what
abuse for it but if you're doing any
kind of diagnostics work in core async
hooks is the one you're gonna want to
pay attention to the most this is a
relatively new one we now have the same
an implementation of the same
performance API that it's implemented in
browsers so you can do mark measure and
performance observer this is really
intended just to give another option for
high resolution timing within things for
so if you use console time and time int
right now what you've probably noticed
is that just using those functions
introduces a certain amount of
additional overhead right they're not
quite as precise as you'd want them to
be using this API you get a higher
resolution timing than that and you
don't have to worry about the console
output so it gives you plenty more
options and it's the exact same API
that's that's implemented in the browser
one of the interesting additions that
that we added when doing this
performance API was time horrified this
is a function that will wrap any
function you give it in a
resolution timer so to record the the
start time when execution started for
that function it'll give you the end
time when it completed what are the uses
that I've had for this is measuring the
exact latency for a synchronous
operation so you know if you're creating
a promise right and you want to you know
measure exactly when that that is being
resolved you can wrap each of the
functions that are involved in a timer v
function execute that and you'll get it
for you know you ready sort of
performance observer and you'll see the
exact latency that's happening with
those with all those callbacks you can
do this with the traditional callbacks
as well so this one's particularly
useful and again you don't get the
overhead that you have with console time
ah trace events this is a big one so if
you've if you've used Chrome's
debugging tools to an extent you're
probably familiar with with with with
trace events and profiling there is an
experimental implementation in Cornell
where you can generate a trace events
file from cor visualize that in chrome
debugging tools it's still experimental
and we haven't fully instrumented core
yet with all of the necessary output but
we are working on expanding that in
whatever you know you know what you
should expect over the next year that
the instrumentation within core to
generate these things will continue to
expand one of the very important
examples of this is we are combining the
async hooks and Tracy bits so that you
can within chrome you can visualize the
all of the async operations that are
happening within a node process in this
particular example this is a look at the
HP at an HP 2 server which was serving
up I think about a thousand requests
with it you know along this cyclist is
kind of a zoomed in version but you can
visualize out and actually see all the
various handles that are created all the
requests and visualize that within
Chrome so this is a fantastic new
Diagnostics tool so you can just see
kind of peek into what's happening
inside your process
we have some other stand-alone
diagnostics tool so there's a
Diagnostics working group is a few
members here and Oh Michael Boston here
as a few others that can go into more
detail on these but these are standalone
tools that are some of them are being
done within the foundation other ones
like 0 X or outside the foundation but
are still very very powerful node report
and node heap dump in particular for
doing post-mortem diagnostics is that
they're extremely valuable tools in
there they can be installed standalone
we are working on getting them
inspirated into core there are
discussions about having to just be part
of core and of course ello node it's
been there for a while I think it needs
to be updated with the latest versions
of 8 but you know that they're still
work happening there
0x if you're not familiar is a flame
graph profiling tool written by Matteo
Kalina and he rose David a few other and
it's just a fantastic tool for just
visualizing what is happening within
your application this is the this is the
one I love
we now have HTTP to support in in in
node core it is still experimental it's
been a labor of love for mine probably
about the past two years
it spent a lot of time you know working
on on getting this right and just
because it's cool these slides are
actually running on an HP 2 server and
node so like pull up the these are in
the browser and I can refresh the slides
themselves rec to show you all the
images are using push in a server side
flush just for fun you know it's just I
love showing it off so this is good if
you're not familiar with the HP - it's
got it is a very different protocol than
HP one uses a binary framing so you're
not sending checks files back and forth
it actually and it's quite a bit more
complexity they're multiplex request and
response flows
so no head-of-line blocking issue you
can actually send multiple requests
multiple responses in flight at the
exact same time with that data being
jumped up and sent sentient packets you
have push streams header compression is
interesting you can actually say you
know if you look at your traffic for
most you're a plus especially with api's
or you mean like an arrest api's most of
your data transfer back and forth seems
to be wasted in headers with the header
compression you can get you know you can
I think some of the benchmarks I've seen
a 90% reduction in data being
transferred back and forth just from
headers we do support plain text and TLS
if your course if you're serving it in a
browser with browsers only support hb2
over TLS so of course in node we have
had that support for that but we also
can set up plaintext hb2 servers here's
an example of the server the the slide
this is actually a small variation of
the server that's running these slides I
just added a few few additional bits for
doing the actual file serving it was
designed to be as familiar as simple as
possible alright so in just suspending
you know line code you can set up an HP
2 server with TLS support ok one of the
really cool things here is we now have
basically sent file support where you
can respond with file or respond with FD
so instead of using a streams API for
writing data out you can give it an FD
and all of the data transfer will happen
all in you see later ok will happen all
on the sealer let's see so here's the
client side again very simple here the
API is not as familiar because some of
the requirements for HP 2 on the server
are on the client side are different
than HP 1 on the client side we're still
working out what the API needs to be so
still work in progress but you know it
it's functional it works
this is a really cool thing Express and
fast if I you know are both working with
HP to know I think Express is waiting on
an actual you know Express five to
release it but we you know it is working
faster by I think just added it here
within the past couple weeks you think
that that landed there so you can
actually start using these frameworks
you know on top of HP to in core so very
very cool es6 modules are in for it is
experimental you can use it there are
caveats there's a lot to be done the
goal is to try to get it done by node
ten you know but there's a lot of things
that need to be figured out between now
and then everyone loves this MJS
extension is this the feedback on this
has been wonderful it's it's yeah it's
definitely something that nobody
actually likes sitting in court you know
we get side it's not something we
actually is like either but for a number
of reasons we've had to introduce this
where the basic support for modules use
the mgs extension this has to do
completely with not breaking everybody
else though the way that modules work is
are fundamentally different than common
j/s in the common jay-z ecosystem and we
cannot just enable one you know the new
stuff you know and break everything else
alright so we have to do this in a way
that allows us to get get it in there
experiment with it and evolve it and MJS
was the way to do that there are other
things that are happening though we have
a full requests that are looking to you
know they're open right now to kind of
evolve this and make this easier we have
efforts that are going on to look at
this and see you know how we can evolve
this one of the tools there is this new
loader hooks where basically you can
customize how modules are loaded in
court and this will be something that
allows us to experiment with this even
further ok so you can use them there are
caveats one of the caveats
you can't do named imports yet on common
j/s modules so you can do them on es6
modules but if you're you know importing
something that's an existing node module
you won't be able to use a named import
errors so this gets into things like a
developer experience if you've ever had
to do any kind of problem determination
using nodes existing error messages you
you know that they suck
we know that Facebook they're very
inconsistent they don't provide enough
information even you know when type
checking is is is performed it's done in
a very inconsistent way different parts
of the code you know sometimes you know
the type checking is done in C so the
error stacktrace that you get is only
the JavaScript side you don't really
actually know what the extra there or
actually occurred so we're going through
a lot of effort to improve just errors
and for and one of these significant
changes is we're adding a static error
code to every error that node throws so
if it is a type validation error on
input it will always have this error in
Belliard type code that will actually be
printed out to the console you'll see it
you'll know exactly what the problem is
you won't actually have to parse the
error message anymore to find out what
is going on some error codes are very
generic like they're invalid archetype
other ones are very specific like the
server already listened right that's
telling you that the net server that
you're creating you already called
listen on right so it's some of them are
very very specific the nice thing about
this is we have to fill out the
documentation on the you know in the
docs more but you'll be able to take
these error codes and use them as an
anchor in the documentation as a hot-dog
me on the hash and look up the specific
place in the documentation about you
know information for this error so it'll
be make it very easy to find the
information about what's happened okay
when the other things that we're doing
is adding additional information to
Paris this is relatively new
it's you know if you look at some of our
errors some of them have additional
properties some of other ones don't all
almost all of our error messages are
parameterised so you know that their
message itself will tell you the details
all right but the idea here is to start
making it where you can programmatically
get it this information right so you
don't have to parse the the message to
get that get those details so in this
case what this is showing you this error
no message just called these are these
are more the low-level internal if
you're doing file system or net-net
calls other things you might expect here
like if it's a validation error you know
what was the type of property that you
passed in right you know did and why was
it invalid what was expected and said so
there's a number of things you're
looking at promise support is coming to
node quarry yeah everything's been
callback based up to this point there
was significant conversation about
whether we were going to do promises in
core API it's gotten to a point where we
just need to do it last year or earlier
this year util promise if I was at it if
you're not familiar with what that does
is it takes any call Arabic style call
back and function and will return a a
wrapper function that returns a promise
okay so when that call back is in it is
invoked with an error you'll get a
promise rejecting right or you know it's
a but if you get a good response to get
the the promise fulfilled right that's
there async await is supported by
default now finally I love this a single
is fantastic you're not using promises
you're using promises without async away
you're doing it wrong if you're not
using anything the way yet just sort
using it I mean it's it's it's fantastic
and soon we'll have core API so that
return promises these aren't wrappers
these are actual implementations of the
functions that are the return native
promises so there are some overhead
there's some overhead with promise of I
because what you're doing is actually
wrapping
the existing callback function all right
and that promise is is working with that
callback with the native support it's
you know instead of having used a
callback at all we're just going
straight to resolving the promises so
it's uh it ends up being much much
faster the place where we're starting
with this is the file system module so
there is a PR out there right now that
starts this process or it's kind of
experimenting with this what this API
will look like it'll essentially be a
clone of the existing FS API but instead
of being called back based everything
will return promises and all the
functions will be away double async
iteration is something that is coming as
soon as v8 turns these on by default we
will be able to start playing with these
more extensively in court it's going to
give us the ability you know some some
greater flexibility for things like
reading files streaming some of the
crypto api's or feeding data
asynchronously into those without
necessarily use having to use streams
API for doing that there it's it's
really interesting it's just too early
for us to actually do anything with yet
but I would expect I you know you should
definitely expect us to come within the
next year that you know we'll be doing a
lot more with async iteration a native
add-ons
so this is this is a cool and it's gets
to the platform diversity native add-ons
is a new way of writing native modules
for node so instead of using man or
writing directly to the v8 api's you can
write to this new n api which is
guaranteed
ABI stability even across node node
versions if we get you know if even if
we update the version of v8 or even if
you're using node onto chakracore you
should be able to write the module once
and and it'll still work across those
platforms okay there are demonstrations
I'm not sure if there's actually going
to be one
here that will show you know that we can
actually show building a module once on
a system and it works across multiple
versions of node all the way back to
four and on node chakracore just
building the module once so no more
NPM rebuild every time you install a new
version of nodes so very very exciting a
bit of work in the examples pretty
straightforward there's there's a number
of these that are in the documentation
you can look at the tests as well I
think I pulled this one out of one of
the tests it's it's very you know basics
you see seesaw API very very
approachable still considered to be
experimental beginning to stabilize and
again works in v8 and no shocker course
so lots of lots of room for playing
around on that this one's a fun one this
one's relatively new and I probably
shouldn't talk about it too much yet but
so the streams API and for it's critical
everybody uses it right but it the fact
that their streams one streams two
streams three and resolves complexity
there and it's a lot of overhead trying
to make these things work together all
this kind of stuff as I was going
through the hp2 implementation I
realized that most of the performance
bottleneck that I was seeing in that
implementation was coming from the
streams API there's nothing you know no
party arrests the implementation it was
just a streams API so that experience
kind of kicked off this this discussion
of well maybe if we took a step back and
did a new stream of new low-level
streams API in core that did not have
all the backwards compatibility Kroft
not touching the existing one two and
three streams all that the existing
streams API stuff would still be there
we wouldn't touch it we wouldn't yeah
and we would be able to do you know do
some integration between it's new thing
in that but this is looking at something
that is is much more low-level that
would be full based so I'm very familiar
with Dominic tarz full streams module
very very similar to that not based on
event emitter
the goal is to eliminate as much as
possible to need for her back pressure
we would be able to do the binding of
the data flow at C the C C++ level as
much as possible so if you have two of
these streams you know they might have a
jeaious interface you're working with
but if they're both backed by a Unicode
then we can do all the data transfer at
the native layer instead of bringing
that data up into the JavaScript so it'd
be much much faster this is basically
how we're doing the the send file with
HP - you know that using this same basic
idea and intentionally not backwards
compatible with the streams one two and
three that's in order to keep it good
fast this is still very very early we
have this initial PR to start discussing
it there's some initial working in Java
scripts that Jeremiah sang bill Fisher
locked in series it has been working on
we're just kind of starting the process
here so I would expect something over
the next year to start to emerge on this
there's there's a lot of really
interesting possibilities here security
so this is a this is an important one
this is not less on its actual side more
on the management side of the project
the project is looking to start managing
these units own CDs and you can go to
the security working group repository
and see this conversation basically
right now whenever a security
vulnerability and note comes up right
and we want to issue a CD we got to go
out and in request that number and wait
that's all process involved what we're
looking at right now is is being the
authority for note where we can just
issue those directly so it allow us to
get that information out much faster and
allow us to have more more direct
control over that information the other
thing we're looking at right now and
again this is also an inner discussion
in the security working group is
tracking vulnerabilities in ecosystem
modules so I think it was about a year
ago that the node security project
became a part of the node foundation in
terms of the data right they can
basically they contribute about
vulnerability data to the foundation
since then we've been talking about you
know
what process are we gonna have to
actually manage this vulnerability data
and that's actually starting to coalesce
now and so a you know you know what that
process is going to be so we will be
able to track vulnerabilities we'll be
able to do all the notifications will be
able to assign CBE's to those things if
necessary so not just in core but across
the ecosystem as well and we're also
looking at its early discussions of a
new earlier a responsible early
disability program for getting
information about these vulnerabilities
out early but in a way that it's very
responsible so it's not we're not you
know not zero dating anybody and you
know I like to in every talk I give with
we deal with this call nut core is an
open source project we thrive on the
users who you know who you know find a
bug and say okay I want to come I want
to help fix that right or even just you
know find a typo in the documentation
hell and fix them right you know we node
would not be where where is today
without you know the user community
that's contributing back to it yeah
there's there's folks like me that are
that do happen to be paid to work on it
but you know I can probably count on one
hand two people on the revolving for
that do that everyone else are users
that you know that are come and actually
you know just scratching in it kid
fixing fixing you know one small thing
here one small things there we do have a
code and learn workshop later on today
basically this is you know we take you
through the process of setting up your
dev environment all the way to opening
your first full request in in court
there's it's run by Anna and rich
they're here somewhere
they've done a fantastic job running
these when we did in Vancouver we had a
few hundred people show up and I think
there's like 200 50 some-odd pull
requests open with an I'm a couple hour
period which is fun to go through and
land them afterwards but it's you know
if you've never contributed to an
open-source project before it's a
fantastic opportunity
to kind of get your feet wet on
understanding what the process is and
even if you don't come back later and
contribute to note you know I hope you
do but if you don't it's still a
fantastic experience to kind of go
through and figure out you know what
that process is and it is definitely the
first step to figuring out exactly how
you know the whole note chord thing
works right so definitely I look at that
it's into a block I think it's at the
same time as the hardware workshop so I
might actually sneak over the hardware
workshop but you know we'll see that's
it thank you I am Jason l-3 much
everywhere</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>