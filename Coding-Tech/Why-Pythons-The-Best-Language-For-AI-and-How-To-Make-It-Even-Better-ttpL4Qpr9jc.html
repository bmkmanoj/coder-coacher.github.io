<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Why Python's The Best Language For AI (and How To Make It Even Better) | Coder Coacher - Coaching Coders</title><meta content="Why Python's The Best Language For AI (and How To Make It Even Better) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Why Python's The Best Language For AI (and How To Make It Even Better)</b></h2><h5 class="post__date">2018-04-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ttpL4Qpr9jc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so as Doran said I'm going to be talking
about the development of AI and data
science more generally in Python and the
sort of role that the language is taken
up in this nation how we can actually
extend its advantage in this type of
development because it really has become
sort of a dominant or obvious choice for
this important type of software and I
think that actually there are some
things that the community could be doing
more to maximize this advantage and to
make development of these things even
better so so first of all I'll start out
by telling you a little bit about me um
so my background actually was not in
computer science I started out in
linguistics and then I went straight
from an undergraduate in linguistics to
a PhD in computer science now in
Australia actually in PhD programs we
don't do any coursework so I've actually
never taken a programming course but
I've actually come to you know really
appreciate software engineering and you
know designing careful algorithms and
careful implementations and you know
through that of ended up developing this
library space E which is a natural
language processing library to develop
within a spontaneous a small two-person
company explosion AI so and our
experience developing that is really
informed what I'm going to be talking to
you about today
so give you a little bit about spacey if
you haven't heard of it
interestingly it's actually the fastest
natural language processing library of
any language so not just among like
Python languages there are no fastest T
plus plus so Java libraries to do this
and in natural language processing speed
is very important because we can't just
rely on computers getting faster because
the web actually gets bigger faster than
computers get faster so you know the
size of our job actually gets larger and
so the implementation algorithms that we
develop have to keep getting more
efficient otherwise the total running
time of the things that we'd like to do
with reading the web or reading all of
the information in Wikipedia or
something will actually get longer
rather than shorter so it's really an
application domain where efficiency is
very important and this sort of dynamic
actually plays out a lot in data science
in
where there's you know the size of the
datasets that we want to work with keeps
getting larger and so we have to think
about efficiency in order to really
achieve the aims that we've set for
ourselves and in order to develop good
solutions but at the same time
developing our fast software is not
always easy in pace and I think we've
come to some interesting lessons from
this so the main thing that I think sets
this apartment main thing that I think
has made this successful is that it was
designed from the start in cycling which
is a language used for writing C
extensions in Python it wasn't you know
I didn't sort of develop it in Python
and then retrofit the efficiency
afterwards and I I'm going to be arguing
that actually that doesn't work terribly
well and that it's both easier and
better to design for performance up
front
sedation's okay so oh I'll start by
giving you a quick outline of you know
the argument and I'm going to lay out
and you know sort of give you the whole
thing in breathe before going back and
justifying the individual assertions so
just quickly here's the sketch of what
I'm going to be talking about
so the first thing - the first point to
make is that you know Python is actually
really the dominant language in this
niche so I don't think that there are
actually any other programming niches
where Python is the number one obvious
choice it's a good all-rounder language
that has a good place and lots of other
nations but it's actually really in data
science and also scientific programming
which is a slightly different type of
nation but python is really the number
one obvious choice and I think this is a
type of programming that's getting more
and more popular and as of you know sort
of an important type of development and
so as a community I think Python should
think a little bit about how it has come
to this place to be the obvious choice
of development of this type of software
and what we can do to you know basically
extend that advantage and make sure that
you know it's it's as good as possible
to be developing this type of software
and pilot and one of the benefits of
having you know this sort of position of
- is a language of data science in a
language of machine learning is that
then when we go to do web development or
other types of development in Python
it's all of this great tooling available
and so I think that it's really at
a great benefit for the language that
it's come to this position so I think
it's sort of worth thinking about this I
also think that the lessons here about
writing high-performance code in this
domain probably do actually generalize
to lots of other types of development in
that there's more general to learn here
so the question had it you know Python
come to dominate this well I think in
general languages get to this sort of
position by prominence in other words
they win by being a good enough solution
that's in the right place at the right
time
so I think around 2004 when pythons
started really taking off in scientific
pro computing and in data science Java
and C++ really weren't productive enough
I think the languages have gotten a lot
better in this respect since but
certainly then they were you know it's
pretty hard going writing you know quick
and dirty solutions in this and writing
things that you can change quickly and
adapt um and at the same time I think
see extensions were just you know harder
and less obvious the Perl and Ruby so as
much as I think that Python you know
rightly prides itself for a lot of
cleanliness in the language a lot of
like nice developer experience I think
that it's not actually probably what's
most decisive I think that what was
really decisive was did it was easy to
write something in a lower level
language and link it in and have that
almost all of the performance that you
would get from that while still being
able to work in higher-level language so
this is I guess the you know slightly
controversial claim that I want to make
here and that's that despite a lot of
ambivalence in the Python community
about the role of C extensions and this
kind of long flirtation that the Python
community is been having with
just-in-time compilation and other
solutions and trying as hard as it can
to you know avoid doing C extensions and
avoid and do less of this I actually
think that this is an it has been an
important part of pythons edge and it
you know will continue to be an
important part of privatization and that
we can actually maximize these
advantages and do do more of them both
as a community and as individual
developers if we sort of understand
embrace and accept that you know writing
low-level performant code is actually
productive inefficient
use of time so to to sort of flesh this
out a little bit and explain
specifically about siphon which i think
is a good solution for this type of
thing okay so on the left here you have
really the sort of most obvious
immediate thing that you would think of
to do in order to apply this function
that you know which happened this sort
of slightly arbitrary data
transformation turns out to actually be
a very common operation in neural
networks and so it's essentially just a
low pass filter we clip that use data
unload in 0 to 0 so the first most
obvious thing that you would do is just
loop over the Guyton's in the list and
if they're loaded in 0 set m 0 now this
turns out to perform terribly because
and i think this is over a list of like
you know 100 million items or something
like that just to give you a sort of
scale of the things but this performs so
badly that even if you're doing a lot of
matrix algebra and you know a lot of
heavy lifting elsewhere in your
application if you've input if you've
implemented this trivial function in
this way this will noticeably slow down
what you're doing and so this is a trap
right so um people quickly come to learn
that alright if you're using numpy and
you have to be writing say one of these
two things and so you know is this one
faster this one well yeah thanks um you
just end up with crew
yeah so you end up accruing what a lot
of this sort of arbitrary wisdom about
alright I will use this maximum function
and oh is this yeah okay sorry thanks
yeah so um basically you end up learning
a lot of library Arcana I'm in order to
sort of use numpy well and take
advantage of its factorization but
instead of learning the slightly
arbitrary things if you simply use
siphon well you get to write it
basically in C and the code that you end
up writing for this actually ends up
looking a lot like the obvious solution
because you don't end up running into
this sort of arbitrary artifact of the
language where loops just happened to be
slow so this performs at the same speed
as it wouldn't see because it really
just compiles directly into C code so
it's sort of trivial to write obvious
solution i if you do it in siphon ends
up performing as well as you would want
and so you end up a lot less trapped
into having to use rely on B AB tree
api's of different libraries and so you
know it happens that there are good
solutions in numpy phase but hey you
have to know what they are and B if you
didn't have a problem way you need
slightly different and there isn't a
solution in the library well then you're
sort of stuck and also because the
capabilities that are exposed in the
library are sort of arbitrary you can
end up having to spend time figuring out
whether there's a fast way to do this in
numpy and what I want to suggest is
actually did this whole thing of like
alright now how do I do this in numpy
how do I like you know work with the
libraries to do this sort of thing if
it's really easy to express the logic as
a function then it's very actually very
handy to first just say well like what's
the problem I'll just write it in this
and I'll write it in siphon and you know
that'll be kind of like you know one of
the first things today go for the first
tool that I reach for and I actually
think that that's a sort of more
productive and extensible solute type of
solution for this type of problem rather
than you know having to work around the
limitations of the language and work
through these libraries
then okay so um so as I said this is
what we should do differently I do I
think that individual developers um it's
beneficial if they you know get
comfortable writing syphon and reach for
it sooner rather than um spending more
effort trying to learn work around this
in learn more library features and you
know these sort of back door tricks
about numpy um I think that you know in
general learning more Arkana about
library about individual libraries
doesn't pay you extra dividends and so
it's sort of it's better to be working
in domains where you can reason about um
your code and you know have everything
sort of makes sense but at the same
token I think that the community should
really invest more in making this type
of solution easy and obvious because at
the moment it really isn't and I think
that we can do a lot more to make to
really fix that and finally I think that
the general problem that this is
attacking performance is generally a big
problem in Python code and I actually
really don't think that we can fix this
as an afterthought I think that the
discussion that's around say releasing
the global interpreter lock or improving
the just-in-time compilation tools I
don't think that any of these were
really solve the problem well because I
think that in order to get our well
performing code a lot of it comes down
to making our programming decisions and
then expressing those decisions in your
program and just-in-time compilation and
things really don't give you a good
framework to do that um the decisions
need to be made they need to be made
early and then you need to write the
rest of the program consistently that
this means that you can't really can't
do this it's an afterthought it does
have to be a sort of upfront process so
to give you a sort of more complicated
example of their sin this is and this is
not a real example this is sort of still
arbitrary because I wanted to have less
code they actually think that this is a
little bit more code than I like having
but this is an example of some sort of a
more complicated thing that you can do
is siphon um and so this is really just
it really just is C++ that's just
written in Python extent acts but the
nice thing is that you have an easy
linkage into the Python library so if
they at any point of this you wanted to
say raise a Python error natively in a
way that was
useful today I'm program you wouldn't
think twice about doing that
whereas if you had this actually in a
C++ file suddenly you have your across
this language barrier and you're no
longer really developing a Python
solution and I think that that really
makes a difference so the free mixing
that you get a C++ logic and Python
logic I think is really distinct inside
and I think that's really something to
make sets this apart it makes it is a
useful strategy what this example is
doing is it's an example would say
finding the top three ratings of a long
list of things and so the type of
development process that I'm suggesting
is really sitting down and saying well
ok if I've got this long set of ratings
how am i what the minimum amount of
information that I need to actually
encode that so in this case we've
encoded it as a 64-bit integer that a
user ID a 64-bit integer for a product
ID and a floating-point number for a
score and so if we look at this it's
like okay this comes to 160 bits of
memory and this means that we can easily
see if we have 1 billion of these this
will take 20 gigabytes of memory and so
we say all right I've got a machine that
can do that now this is the type of sort
of simple analysis that really ends up
feeling cut off from you in Python um I
really don't know off the top of my head
how much memory one million integers a
list of 1 million integers takes in
Python it's just not something that I
ever really think about um whereas it's
very easy to remember well okay I'll
loop 1 million 32-bit things takes 4
megabytes of memory
oh ok like we can breathe you can really
start to reason about the size of
working sets that you can actually use
and what we can fit in one machine or
how you can exercise these calls and so
doing this type of sort of upfront
reasoning feels like oh god like you
know I just wanted to solve my problem
why do I have to like think about these
things but it actually doesn't take that
long in the scale of you know
development like you sort of sit down
and do this analysis and at the end of
it you end up with much much less sort
of experimental like poking and prodding
and like groping in the dark and I think
that the overall that's actually um it's
much more productive so for the rest of
the example I you know again
is sort of not real not a real example
but I thought well okay you know maybe
we've got this long list of structs and
we want to have say a priority queue to
find a top three and without sorting the
whole list and this type of thing is you
know it's very easy and natural to its
Restless logic and um you know
essentially with c++ data structures and
at the end of it we can very easily
output a Python list so this is sort of
natural um one of a neat feature in
siphon is that this will naturally
convert struct into a dictionary so we
can just get a little Python dictionary
or add items and so what do you put a
get practice in this this is becomes
known slower to right then and it
wouldn't pipe it um but I find a lot lot
faster to write then you would a fewer
sets him down and said well okay I'll
have a two-dimensional numpy array and
then and on another numpy array for the
score and just working with these
flatbuffers that you end up working with
in vampire is really a much more limited
type of programming than you would get
if you you know basically just get to
use structs and arbitrary data
structures and things like you know
working around the limitations of the
language um makes it very difficult
whereas if you just say well you know
here's my memory and this is what I'm
going this is the algorithm that I'm
going to express I think that it's much
much lower variance much more reliable
process once you get sort of you know
more practiced at it so so that's the
sort of vision that I had for like you
know what I'm that's the type of
solution that I'm going to add the Cape
for so first on Oh back up a little bit
in you know justify a little bit on its
assertion to pythons currently the best
language for AR so this is sort of a
little bit of a straw poll and that we
did and our survey that we put together
for users of spacing also users of
related things and you know basically
general AI developers and we found that
yes people are very dominantly using
pipe and so this was very biased because
you know it interacts with our developer
community and we are a Python library
but it does match up with a the sort of
like common wisdom in and that's around
and also to developers surveys that you
see in Stack Overflow
that's where I think very clearly comes
out as the number one on language that
people are talking about in the sort of
space and um so did as a sort of further
straw poll about you know why that might
be um so this was just a poorer thread
and you know somebody asked wise pipe in
the the leading language for this stuff
and really do um the answers that kept
coming back for the ecosystem so it's
you know basically did this more
libraries developed this and so would
develop it's working in it and then this
creates this virtuous feedback loop of
more you know more and more of the same
basically there's you know because it's
the obvious language people are working
in it's also the language it will
develop libraries for okay so the
question then is you know how did we get
to this point like why is the assistant
and want something that's notable about
all of the eco all of this ecosystem of
performing good um data science flawless
it they're all basically says and in
fact so they're pretty much all written
inside so Candice um it's basically
scikit-learn
a bunch of non players see because it
was written a long time ago but then
other bits are also in cycling it's
really the part that's kind of making
this whole thing tick so you know what
are the only exceptions is tensorflow
was bindings are in swig I and the core
library is in C++ and I actually think
that this you know is sort of gives this
notable different feel to tensorflow
where they're really cut off from the
internals um as a Python developer
whereas if you're using one of these
other libraries but he in Turtles are in
siphon it feels much more accessible
that you can basically go in and use the
lower level API and the lower level API
is sort of set up for you to use as well
okay so if you so how do people normally
do like yeah what's normal approach to
writing more performant Python code I
think that the following sort of process
is very common you start off with like
you know basically implementing the
solution and getting it to work and you
test it and you're like great write an
implementation we've got my project so
then you sort of start to fiddle and you
make it a bit faster so there's always
something that you've done with
you know your numpy raise or something
you know did some way you're using these
libraries that is my idea
and so you profile and you tune and you
make it a bit faster and then at the end
of it you say well okay if you're not
happy with the results at the end of um
went to then you start to look around
say well I hear that numbers a thing
like pi PI it you know and so basically
you start you know sort of more
desperately trying different things and
then you know you might say well okay I
need to paralyze this'll add more cause
then you know this may or may not work
I'm multi-processing doesn't is not
guaranteed to give good results because
I you may lose so much in the arm there
pickling and start up um and transfer
costs of the multi processing that you
actually can't easily benefit from it
and and once you're at this sort of
point on the track sort of set and
you're kind of in a local maximum here
and that's that's really the problem
that I think comes up a lot and I think
that it's you know sort of worth
avoiding and so I think it's you know
basically the path that the language
sets out for us and also that the
community sets out for us this is really
I think the recommended process and I
think very often it leads to an outcome
that is very difficult to fix and a lot
of time has been spent to get to this
point where we're not happy with the
performance and we spent a lot of time
developing this thing and we don't
really have a good way forward and I
think that's really the problems that
you know want to talk about it and see
whether and advocated solution for
petitions to weigh this is kind of a
metaphor of this problem and I call it
the parable of the tree kangaroo
now this noble Australian animal is as
you may notice a kangaroo that lives in
tree and this is sort of a strange
outcome if you think about it and
because you know Australia is being an
island continent was cut off from most
of the rest world for a long time and so
it kind of developed its own line of
kooky mammals so the ancestors of
kangaroos were sort of possum like
creatures that lived in trees then at
some point there was a job opening on
the ground and um kangaroos developed in
they're essentially kind of like
marsupial here they occupied it same
sort of ecological niches do you do in
other parts of the world but they're you
know they have a lot of inter
adaptations for that the grassland
living but then at some point to drop a
drop opening up back up in the trees in
the rainforest in Vidor and so then you
know the kangaroo said well you know
I'll take it and so you end up with this
animal that is actually by the scale of
evolved animals kind of quite ill suited
to the work that it's doing we're used
to thinking of evolution is producing
these exquisite adaptations and you know
animals perfectly adapted to their
nation but actually you know evolutions
a hill climbing process and so there's
no guarantee that that's going to happen
and you may end up with this sort of
weird path-dependent local maximum of a
kangaroo living in a tree
so and you know if you watch these
creatures you notice that actually they
really are you know quite ungainly and
you can say you know nice things like
well it's surprisingly good at climbing
for a kangaroo and they do have you know
a lot of adaptations of this they have
you know big balls and actually one of
their notable adaptations is that you
know their legs which are built for
jumping mean that they can cushion the
blow Falls quite well and so you know
they were surprisingly good at falling
out of trees and surviving but this
isn't a great outcome right like you
know once you're in this position you
like well it's hard to feel like there
wasn't a better solution if you started
off in a different part of the solution
space and so the parable of the tree
kangaroo is really about how the
incremental changes to a solution do not
necessarily get you the best solution
and you do have to like sort of make
sure that you're in a good part of the
solution space to start with and I think
that this really applies to optimizing
code and you can't expect that if you
just take an existing solution and sort
of incremental optimize it you'll end up
with a program that is good you may end
up having to rewrite the whole program
so as I said you can incremental
improvements just don't always lead to
the best solution you can make your
program you can reliably make your
Python program fast if you forgive but
eventually these bits get smaller and
the effort to make those optimizations
get harder and the changes that you have
to make your code make it less and less
readable and less and less maintainable
similarly kangaroos can indeed get
better at climbing or falling out of
trees better
by bit but you know this doesn't um this
doesn't actually lead to a satisfying
outcome so as it they then ultimately
you considers but you know the
incremental solution isn't always
competitive now just so happens that
there are no Apes or are in towns in
Australia you know we have I guess
important restriction but if you can see
that the solution here is on ideal by
very easily imagining how quickly they
would be out completed as soon as that
were no longer true like as soon as
there was an invasive species somewhere
then you know okay you know the tree
kangaroo would very quickly find that it
was like not competitive with our
different and something that came up
from the different part of the solution
space so what I suggest is a better sort
of approach to performing Python or a
better on the solution for this is that
we should you should actually get used
to planning your data structures upfront
and it feels like effort at first and
indeed you know it's not this sort of
greedy path but the fact that these
local maximum is exist you know it
should make you make your peace with
that and say that well actually if I
just do at each point what seems like
you know the step that takes me one
little bit closer to my solution you
won't necessarily end up with a better
or easier time overall and so there are
these situations where the upfront
analysis is actually very efficient and
then once you're doing this you're
really in a domain where you can reason
about things and that makes things more
reliable and so then you can write the
simple obvious and approximate optimal
solution but there's also there are
problems here and that's why I say that
there's we know we can make this even
better because unfortunately step three
is well now I have to chant strange
incantations and to set up tools because
I have some compile error and things
like I'm like why is this so hard
and why is the documentation not that
great and like wait isn't this is this
way I'm supposed to do it or am i doing
it wrong we're like you know why is this
so hard and so but eventually you do
benefit greatly so well you know my sort
of humble vision is that well okay I'd
like to suggest that this could be
better so I think that actually in order
to make this
better and it would be nice if just sort
of on a messaging level that this it was
sort of more obvious from people that
there wasn't sort of consensus that this
was the accepted answer to how to do
things and I think that that's really
not the case at the moment I think
actually the set up tool stops at the
moment reference something called
pirates which was you know the
predecessor of recycling and then
there's you know mixed messaging about
when you should use CF for fire CF fi or
when you should do this of that it's you
know it's very confusing and I've made a
lot of Python developers who've actually
never even heard of this even though it
really powers most of the libraries that
they're using and so you know I think we
should discuss some way of like you know
solving this in some way of making this
a more obvious they're excellent I don't
want to comment about what should be
done here because I don't know honestly
I don't know enough about that I'm not
asleep as a developer I don't know what
solutions are appropriate or something
but it does seem like there may be
something that could be done that makes
this sort of a more official obvious
choice and you know hopefully it is
something that but then there's also a
lot of improvements that we could get
from just sort of extending this
strategy so an AI at the moment um
pretty much everybody's writing CUDA
code which is an you know this dialect
of seed it can only be compiled by
Nvidia's compilers and and it you know
basically is how you get your thing to
run on the GPU now we write this as
strings in our Python code and like this
is obviously an idea we're just like
writing this chunk of programming
language in a string and then I can't
even compile it on my home machine I
have to like send it off to you know the
server in order to get my compiler you
know and in the meantime I'm happily
writing this language that compiles into
C and the semantics of CUDA are no more
difficult than the semantics the C 4
plus code did I'm compiling the cyclin I
shouldn't even actually be able to have
the same function in target different
backends of it but again I don't know
exactly the parameters in the solution
design that I want here but it really
feels like something could be improved
and so I'd love to see more investment
units
similarly I think that there's kind of a
two-tailed trap at the moment so when I
started designing space you knows a
happy
the music for a long time I imagined
having this elaborate well-documented
siphon API to library there would be
this kind of lower-level back-end that
people could hook into it but the truth
is that there was never like a scary
cook demand for this and and so it was
never really developed and so even
though I use the same API a lot it's
kind of like not really obvious to
people and I think that you know this is
because libraries don't tend to make
this available and so developers don't
aren't in the habit of asking it or
expecting an answer libraries don't make
it available um so I think if we kind of
get over that then I think that the
development process could be a lot
better because it could mean that
instead of people having to wonder well
which one of these ways of using this
thing in spacing is going to happen to
perform better if they need the more
performance then they can just write the
obvious thing that obviously is going to
be optimal because it you can actually
reason about this rather than having to
guess how its implemented internally and
which one's going to result in more
object allocations in Python which
there's just no way to guess you just
have to happen to know and I think that
having a if we can get to a point where
there's just fewer of things of you have
to happen to know I think that that's
going to be a lot better for the
community um similarly actually I think
that it could be a lot easier to develop
standalone libraries and applications so
at the moment there's this problem that
I'm sort of writing C++ level code but
if somebody actually wants to use that
from C++ there's a lot of song and dance
that they have to do and it's in theory
possible but this could really be a lot
easier and at the moment one of the real
disadvantages of writing siphon as
opposed to writing on C++ is that it's a
lot easier to write to link C++ into
other languages and I think that you
know if that continues to be the case we
will get more applications that are
written in native C++ and I think
that'll actually be worse for the Python
community because it will be harder to
use those things as from Python and
they'll feel less like white
applications
they'll feel much more like a C++
application with in fact kind of ugly -
into pets which is much less good okay
now to sort of head off a couple of
objections that I can get safe amuses
you know sometimes there's a sort of
narrow conception of the role that
people have as a data scientist if there
might be they say well oh god I really
need to worry about performance because
I'm you know basically just work
and data science and then I'm gonna hand
off my code to some engineer and they're
going to implement the production level
version and so I don't root so you know
the perception of this is that I don't
need to worry about performance somebody
else will worry about that
and you know my response to this come
across as latest Enzo personally if that
will make I wouldn't be so satisfied
with that because you know it really
means that you're paid painting yourself
into a corner where you've got kind of
an unstable situation and you know if
you're not interested in writing the
sort of production level version of this
I suggest that the people who are who
you know you're throwing your solution
of event the fence to is like the
implementation monkey I think that he's
going to be eyeing your job and saying
what well you know there's you know why
can't I designed a neural network well
actually I think I can and you know I
think that the this sort of you know
division of labor that I is in the mark
moment is you know I wouldn't keep
betting on that continuing and I also
think the demons from this you know
aside from that sort of call calculation
I think that in general in development
there's a sort of trend towards people
having t-shaped skills which is this
idea of having a deep specialization and
then also a broad knowledge of the other
roles that you are interacting with so I
think it's probably it's both unhealthy
and inefficient to have the attitude of
something else being not your job and
you don't need to know much about it and
I think that you get much better at any
one of these roles if you understand
well and the concerns of the other
people who are doing the other roles and
if you could sort of wear that hat if
you had to and maybe you're less
practice at it but I think that drawing
a boundary box around the things that
you know and a good at and saying well
this is these are my skills and I'm
going to work on them it's not very
helpful
I think the in general having the
attitude of like well you know I want to
know all about the whole process leads
people to develop better solutions and
get better at the things that you know
even if they care about a deep
particular speciality I think you'll be
better at it if you understand more
about the rest of the way that it's
interactive
so I would suggest that even if you are
currently in a role where and you do
hand off the production engineers I
think that you should be interested in
continuing to understand how those
production but the concerns to make the
production implementation faster though
you might do more to make that easier
and not have to rewrite importance of
solution after they're done so another
thing that comes up often is people say
well look this whole process of sort of
you know worrying about these low-level
details why can't I just write in a
high-level language and and have these
details sort of taken care of form you
know it seems like a simple
transformation to you know unbox these
integers and as I as it's iterating
through it and this is all very
mechanical the computer should do the
engineers work of rewriting these things
and I should just work in a high-level
language so the problem here is that a
lot of the benefits flow from making
decisions and actually it's the making
decisions part that people are sort of
requiring from them the part that feels
hard is this planning part but that's
also the part where the benefits come so
you know unless your program just
happens to have the these consistencies
that the just-in-time compiler can take
advantage of you really won't get much
benefit from this so and instead of just
sort of planning to have those in sort
of remembering to enforce them it's
actually really a lot easier and more
intuitive to sort of write them in at
the start so if you're going to decide
that this you know list of items is
going to be homogeneous by type and
which is really what you need in order
to take advantage of just-in-time
compilation you really may as well
specify that in the data structure that
you define rather than just having an is
to sort of loose constraint that you
follow so I I really think that rather
than having the just-in-time compilation
is kind of the first plan and having you
know this fallback strategy of our if we
get desperate we can write it and see I
actually think that we should flip that
and we're just in time compilation
really shines is in situations where we
can't do anything else
so when we've got a whole chunk of code
and we don't have any control over this
code base we you know it just comes to
us and we like well we want this to run
faster and we can't rewrite the whole
thing because that's too expensive so at
at least we can use a just-in-time
compiler and then we get this benefit
and that benefit can come for free and
that's like really awesome but if we are
in control of the situation we do get to
make decision so we haven't written the
code yet I mean the first point of
course should not be just-in-time
compilation at that point when we have
the decision to make I think that it's
actually better to plan out the
applications performance in you know
plan to have internals of it in a memory
managed language and plan out data okay
and similarly another thing that you
know may come up is well you know why do
I do many developers have to worry about
that why can't this be sort of a narrow
concern of library authors and then you
know we'll have it sort of bottlenecks
that are written in you know this fast
style and the rest of us can you know
not worry about this and sort of write
in higher-level semantics and the thing
is this is you know this is sort of
almost true this has been what makes
pythons successful and this strategy is
really working so this is kind of like
you know 90% like I wouldn't say that
people should you know write see too
much but the thing is if you really have
this is you're like only strategy and
you don't have any access to these
underlying fundamentals then you become
very dependent on these libraries and
you end up spending a lot of time sort
of trying to figure out how to like tune
the performance of library and how to
you know alright if I do it this way is
it slightly faster this is doing it this
way as a slightly faster or spending
more and more time hunting down other
libraries to do different things and you
know is this poorly documented chunk of
code better than this other Pali talk
about meaningful chunk of code and a lot
of the time when you're doing that the
logic that you're trying to express is
really simple and so rather than hunting
around for some existing solution you
can just write a few functions and I
think that that's a much more powerful
and you know ask attitude that pays much
more dividends overall because instead
of learning you know really arbitrary
stuff and you can you know basically
have more control of reasoning about
your programs and I think that that in a
long term is you know a much more
beneficial thing I just think that at
the moment we're in this situation where
the path to that sort of right a
long-term benefit sort of travels
through this like you know valley of you
know chanting incantations and set of
tools in my
being confused that stuff and that's you
know basically making that path to you
know getting to a halt sustainable point
I think you know what I think we can
improve and so that's what I wanted to
suggest
okay so the question is if we're going
to worry about you know divining low
level memory and stuff then you know why
use placing at all why not use a
language that's sort of more defiant
designed for that in a language which
actually does have a lot of advantages
for that type of development and so this
is true to some extent but the fact is
that um placement is a lot to give up
and a lot of the time you actually
really want to interact with the rest of
a Python code base and there's other
reasons why you do want to continue with
the language so if you are working
within a larger project that um has a
reason to be in Python then you may
still be developing a chunk of code that
by itself wants to be performant and so
imagine that your company overall is
using Python but you've got a task that
you know is you know some development
goal that's six months or something of
work you still may want to have that in
Python because you're having it as a
service is inconvenient and you want it
to be alive with you you want you want
to take advantage of other Python
tooling so you know there are lots of
reasons why you want to continue working
in piping and and is but you know doing
this is not so bad so if you sort of
make peace with the you know these
things which are still slightly on our
deal about siphon and it's still a good
way to do this and you know you can
still basically get this done and I
think that pretty common sort of use
case you're better off now managing the
memory rather than you know saying well
I'll give up entirely and rather than go
on so you know there are situations
where you want a performant library is
easy to call forth from Python so the
question is that I I seem to be favoring
rewriting over patching and I actually
think that whether whether this is
rewriting or not depends on whether
you've written it in the first place so
I'm actually suggesting that you don't
even necessarily need to rewrite and you
know I'm suggesting that at the start of
the project if you know that you'd want
to say process a bunch of you know these
product ratings you know rather than
thinking well that seems like something
that I'll need lots of machines for so
you know
actually sitting down and analyzing how
much memory something will take and
saying I'll actually note I don't fit in
memory um if I use this data structure
um that upfront analysis even before
you've written
um can save you from having to rewrite
and I think that that's actually
something that you know is can be very
beneficial um so the question is whether
I could and sort of talk about the
comparison no like you know it's a
dynamic people using numpy versus people
using syphon so first of all I would say
that actually I don't see it as two
communities at all like I would say two
numpy support is built very heavily in
society and almost everybody who's using
siphon is also using numpy and actually
I think vice versa there's a sort of
level of detail that which people who
are using numpy sort of end up reaching
for number and people who are using
siphon end up reaching for number soap
and this for instance is written largely
in siphon but it certainly has deep
linkages into numpy and the rest of the
PI data ecosystem so the way that I see
it is that the I think that the numpy
developer community would be the first
to sated the library itself has really
evolved a lot over time and there's a
lot of concern for backwards
compatibility and which means that
there's a lot of sort of arbitrary
details in your library that make it not
perfect and you know I remember there
was one a thread that I read on github
about you know making the random number
generator faster numpy and using a
faster algorithm but and the decision
was actually that we can't improve this
because we want stability in actual the
number the random numbers generated
because otherwise we'll break too much
scientific code and people will get like
a totally different analysis and so if
you think about that level of sort of
history anything it's a pretty troubling
position because I actually think that
that decision was correct that okay
they shouldn't improved around the
number generator but it also you know
makes me just made because I want to
fast fast around a number generator
right so I think that there's a lot of
things that you end up doing where the
of the sort of like best way of doing it
an umpire's a pretty approximate
solution and I you know rather than
having a lot of guesswork and writing
code that's
actually not very readable it's often a
better alternative to I'm just writing
in the memory manager way and sort of
think more carefully about the structure
of the thing rather than you know sort
of muddling along in numpy which
actually doesn't give me much support
for this type of development so I
definitely feel like it lets me manage
the low-level details yes so I do think
about cache performance um I find that
the seeded siphon generates is overall
very good and it's they're also very
easy to view to see that is being
generated by looking at the output and
if you use um but sort of one of the
tricks that they use to make that true
is I really do work with pointers a lot
and also with C++ data structures a lot
if you work with the umpire raising them
reviews then there's a lot more like of
an art to this because you've kind of
been working thirty like the Python
layout whereas I've sort of made peace
with well I've got this chunk of memory
and I won't use this so but once you're
doing that it's no harder to make sure
that your memory stays aligned the cache
boundaries and stuff then you know it
isn't other languages and then also in
terms of debugging um I find that
actually the syphon compiler is pretty
useful in catching errors and so I and I
get you know sort of nice errors out of
it then I would from like just writing
in say I have to say that I don't tend
to use a debugger very much tied into
the sort of you know print things
um and I found that actually also inside
them that works pretty well and I get to
use PI test and the rest of the Python
testing infrastructure very neck
naturally and easily which is something
that you know I've never quite gotten
comfy when I've tried to write just
strict C++ code base</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>