<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How Does Python Do Multiple Things At Once? (Best Intro Into Asynchronous Programming) | Coder Coacher - Coaching Coders</title><meta content="How Does Python Do Multiple Things At Once? (Best Intro Into Asynchronous Programming) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>How Does Python Do Multiple Things At Once? (Best Intro Into Asynchronous Programming)</b></h2><h5 class="post__date">2018-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8FdeJ2_LDuQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm gonna start with a question how
many of you have heard people say that a
sink makes your code go fast or really
very fast okay so out of those of you
that heard this but wanna know why or
don't understand how's that possible
so this this is the talk for you I'm
gonna try to explain it in very simple
terms at least I'm going to try so I'm
gonna start with a super simple
definition we're going to build on this
later but a sink I mean it is in a
generic term I'm not specifically
talking about a sink i oh that's not the
only way to do a sink but that is one
way to do concurrent programming which
means doing many things at once okay so
let's let's go through the you know the
few ways that we have in Python to do
multiple things at once so the most
obvious way is to use multiple processes
right you from the terminal you can
start your script two three four ten
times and then all the scripts we're
gonna run independently or at the same
time and the operating system that's
underneath will take care of sharing
your cpu resources among all those
instances when you're using C Python
right there the most popular Python
that's actually the only way you can get
to use more than one CPU at the same
time right this is the only way so the
next way to run multiple things at once
is to use threads and a thread is a line
of execution pretty much like process
but you can have multiple threads in the
context of one process so they all share
access to common resources right which
is a headache
that's why threads have such a such a
bad frame right it's difficult to write
threading code so the operating system
again is doing all the heavy lifting on
sharing the CPU you don't have to worry
about it when you write your Python code
and of course you know that the global
interpreter lock in Python this is a
special
and special to Python when you have
multiple threads running code the global
interpreter lock allows only one to run
Python code at a given time so basically
you're running in a single core even
though you may have two or four or more
so the third one is the topic of this
talk right asynchronous programming so
to make the mystery even bigger I'm
gonna tell you that the OS does not
participate here the OS you know as far
as the u.s. is concerned you are going
to have one process and there's going to
be a single thread within that process
but yet we we can get multiple things
done at once so what's the trick so to
try to explain this I'm gonna go you
know thinking completely out of the box
I'm gonna pull a real world scenario
from the world of chess so this is a
very old photo the the lady in this
photo is yudit polgár it's one of the
best chess players in the world and what
she's doing here it's it's called a
chess exhibition I'm not sure this is
still being done you know these days but
it was pretty popular before computers
killed the fun out of chess by not being
so good at it but you know what I was a
kid this were pretty exciting if you
know events if you if you were into
chess so basically she shows up at the
event and then she plays a game of chess
against lost lots of people everybody
normal people like you and I right and
she'll she usually wins all of them
right but it's the whole idea is to play
with a chess champion right so what I'm
gonna do imagine you need to run this
event right so I'm gonna just do back of
the envelope math here and I'm gonna
just pull some numbers out of nowhere so
let's say that there are 24 people
showing up for the event right so there
are 24 games and you know you did pole
bar
she's pretty good right so she's gonna
come up with a move on average in five
seconds and if the opponents are gonna
take 55 seconds so we get a round minute
for a pair of moves and let's say that
for the average game there are 30 moves
which is a short game but she's gonna
cream everyone so you know it's gonna be
a short game anyway for for most of em
are all so imagine you're gonna do this
the synchronous way so for each game is
gonna last 30 minutes right half an hour
right so she needs to play 24 of these
so she's gonna be there playing for 12
hours right which is pretty bad right
for her especially so in reality DC that
events don't run like that right they do
something else so what they do is they
use a synchronous mode and it works more
or less like this she walks to the first
game and makes her move
so five seconds give or take and then
she leaves the opponent on that table
thinking but she doesn't wait she's not
waiting there for the opponent to make a
move she immediately moves to the second
table and she makes a move on the second
table and she leaves that opponent also
thinking and moves to the third and the
fourth and so on right so she can go
around the room and make a move on all
24 games in two minutes right so by that
time sheets back at the first game and
the opponent at the first game had more
than enough time to make a move so she
can make it you know can her next move
on that game without waiting right so if
you do the math she can she can play you
know that they're all 24 games and win
them in one hour versus 12 on the
synchronous case right so when people
talk about asynchronous being really
fast it's this kind of fast right what
we're not putting an implant on you that
polgár to play chess faster right we'll
just optimizing her time so that she
doesn't waste time waiting right make
sense that's all that that's a secret by
the way that's the complete secret so
that's how it works so in this analogy
you did polgár the the chess champion
will be our cpu and the idea is that we
want to make sure that the CPU doesn't
wait all waits the least amount of time
possible and it's always finding
something to do
so now I can tell you a more complete
definition this is still mine and I'm
just you know inventing these
destinations I didn't take them from
anywhere but asynchronous programming is
it's a more in which the the tasks that
are running released the CPU when they
enter a waiting period and and then that
allows other tasks that need to CPU to
run while the the first task waits and
basically that's the secret but you
probably want to know a little bit more
right how how can you do that with one
process on one thread right so you need
two things basically the first thing
that you need which sounds awfully
difficult is to have a function that can
suspend and resume right we want that
the functions that are in our
asynchronous program to suspend when
they enter a wait and and and then when
when that condition that generated the
way it ends we we want to pursue those
functions from the point where they they
were suspended so uh sounds difficult
but they're actually I I counted four
ways in which you can do this in Python
without operating system help and those
ways are callback functions which are
gross I'm not going to even show an
example of that because they're pretty
gross but three ways that are a little
bit more decent are using generator
functions which is a Python fridge
feature from you know from years it's
been there for a long time in in more
recent pythons 3.5 an app there's a
async/await
keywords that you can use for that and
then finally there's a third-party
package called green LED that actually
implements this as a C extension to
Python and you can install that with tip
and gives you another way to suspend
under some functions so so that's the
first part right so so now we can
suspend and resume the next thing that
we need is we need a piece of code that
can decide how the CPU is shared how you
know which function gets a CPU next
right so we need a scheduler of sorts
and in asynchronous programming this is
called an event loop so we're going to
have an event loop
it will know all the tasks that are
running or that want to run and then
it'll select one it will give control to
it and then that task is going to
suspend when it needs to wait for
something and control will go back to
the loop and the loop will find another
one and that's it we'll keep going that
way until the script ends so this is
called a cooperative multitasking it's a
thing you know for from many years ago I
mean they did the very old versions of
Microsoft Windows for example or Mac OS
did this so it's an old idea so anyway
that's how it works
so I created a bunch of examples to show
you how this looks in practice I'm not
gonna have time to show all of them but
I if you go or say that link you can see
more examples that I created that I'm
not gonna have time to show here but I'm
not sure we feel here so this is a super
simple test that I created let's say we
want to write a little script that
prints hello waits 3 seconds and then
prints world ok so this is how we will
do it in normal Python right you will
print the first text then sleep for 3
seconds and then print the second one
right so if I were to put a for loop on
that hello at the bottom to run to call
hello 10 times for example this is gonna
run not for 3 seconds but for 30 seconds
right you know each function invocation
will run and they're gonna run
back-to-back so here are two examples
that use async IO and you can see you
know there's a little bit of boilerplate
at the top to create one of these event
loops and there's another little couple
of lines of boilerplate at the bottom to
run the asynchronous function but
ignoring that you can see that in the
function we have we have here two ways
to do this suspension suspending a
function and then resuming on the left
I'm using a generator function so
generators are these special functions
that typically you use in Python to
generate sequences of items
and the nice thing about them is that
you don't have to pre generate all the
entire sequence you can generate
elements of that sequence as you know
that the personal calling the generator
asks so you can repurpose that using
this yield or yield from keywords and
also use it for any synchronous function
and basically what we're saying on the
example on the left when we reach the
yield from or saying okay loop I'm done
for now so I'll give you back control
please run this function for me that the
one that follows the yield from so I
think I'll sleep for three seconds and
then when that's done I'm ready to
continue and the loop will keep you know
it'll take note of that and then manage
everything because it's a scheduler
that's what it does so if I were to call
this this hello function ten times
instead of running for 30 seconds you're
gonna see ten hellos and then you know a
pause of about three seconds and then
you're gonna see ten worlds because you
know during that three second wait the
loop will find you know all the other
nine right it'll run one first and then
the other nine eventually will get to
run okay so in recent pythons there's an
improvement
you get a much nicer syntax which you
can see on the right but you know
functionally these two are equivalent
and you have the async def declaration
that's what you use to define a a
synchronous function and then if you use
that syntax to declare the function then
you get to use a wait for for the
suspension and assuming so that's the
point where things are suspended and one
of the things that I think I oh I think
it's great for is that it makes very
explicit the points were what the code
suspends on resume so all those points
were we're at Lisa this magic of
multitasking can happen but I think is
not the only one there are there are a
bunch of others actually I don't have
time to tell you about all of them but I
wanted to mention the ones that are
based
on the greenlit package that I mentioned
early and they these two this this RG
event on the left and event LED on the
right you're probably gonna have trouble
finding where the loop is in this code
and actually you're probably gonna have
trouble finding what's the difference
between this and the synchronous Python
example right they look kind of the same
I don't know if you notice but the only
difference is that the sleep function
that I'm using on these two is it's not
the sleep function from the Python
library it's a different one that each
framework provides but that's the only
difference and the goal of these two
frameworks which are very much alike is
to make asynchronous programming
transparent sort of and that that could
be a blessing and it also to be a curse
it depends on how you look at it me as
an open source developer I find that a
lot of people get into this thinking
that it's all the same right I'm gonna
start doing whatever I do always and and
then things with weird things happen
because that they're not considering
that this underneath is running a loop
and you need to make sure that you never
block because if you go if you blog then
you're blocking the whole thing which
leads into the pitfalls this is this is
actually I'm interested here in saying
these things that I'm constantly
answering on my own the issues on my
github project because people always
trip on these things and people number
one is that what happens if you have you
know you probably have an asynchronous
program about maybe one task or a few of
the tasks need to do some heavy CPU
calculation right and the problem is if
you use the CPU in your function for say
one minute then during that minute
nothing else will happen because this is
a single thread right so all tasks need
to to be you know nice to the remaining
tasks and release the CPU often so if
you have an opportunity to wait right
and nothing to wait for what do you do
and what you do is to sleep basically
you have to be nice and
called sleep every once in a while in
your function that's often as you can
and if you're really greedy and you
don't want to really you know you don't
want to give up the time that you've got
the best you can do is you can sleep for
zero seconds which is basically telling
the loop I I'm gonna sleep because I
have to I don't want to but I have to
but please give me control back as soon
as possible because I wanna have used
the CPU so basically you sleep zero and
if your calculation has a loop which
which is pretty common
then you stick a slip zero inside that
loop so once per iteration you allow
other tasks to continue running so this
number one now the big one and this is
going to be a big surprise probably
there's a bunch of things in the Python
standard library that are designed as
blocking functions right so everything
that has to do with networking so
reading writing from network sockets
waiting on input or output from sockets
anything to do with processes with
threads the sleep function that we we've
seen before you cannot use them so this
is true for every async framework you
cannot use these functions if you use
these functions the thing is gonna hang
so don't use them okay it's very
unfortunate people it's like they they
they want me to tell them when when they
ask about this you know I want to use
them well you can't so you can't so all
a sync frameworks provide replacements
for these functions right and sometimes
that kind of sucks because you have to
learn a different way to do the things
that you know how to do right all these
very common things that you do with the
processes threads and networking
unfortunate but it's true for async ILO
true for Evan Leedy event twisted curio
you know all of them they all provide
alternative ways to do these blocking
things now you remember the sleep
function in a valid and G event that was
coded you know almost or actually it's
identical to the the Python one so the
the folks that Val
level eight on the event they went other
way to create all these alternative
versions very in a very compatible way
to the ones in the Python library and
they have above this option to monkey
patch the standard library so basically
they they swap out the blocking
functions from the Python library and
they put their own instead in their
place so then you can take any piece of
code that was designed to run
synchronously and somehow they inherit
this asynchronous behavior and for many
applications that that's enough to get
you know code that was assigned
synchronously to work but you have to
use have a letter G event now I'm gonna
save you guys time somebody who is going
to come later in the question period and
ask how do I do this for async i/o and
I'm gonna say no you can't you're not
gonna do this with async async is
designed as an async framework that
doesn't try to hide the asynchronously
you know under the rug it wants you to
design and write your code thinking
asynchronously which is a different goal
than these are these two even let them
fear that so I'm gonna summarize this
with a little table and this is probably
going to be surprising to some of you so
this compares processes threads and
async on a number of categories so maybe
based on what I said so far you you
think that these are super cool no not
non-blocking not you know doing
something while a task waits
it's exclusive to async and that is not
true
processes and threads can do that pretty
well too and it's actually not Python
doing it in that case it's the operating
system doing it so there's no winner
here right there's a slight difference
in the processes and threads case it's
the operating system doing it in the
async case you have you know your async
framework I think ilg event or so on
they're doing it so it's cooperative for
async but at the under
preemptive which is called when the
operating system Yanks the CPU out of
you without you knowing it but all of
them can do it so there's no winner in
this category
now I already told you that if you want
to maximize your multiple cores in your
computer then the only waste processes
right so that there's clear winner
processes is the only option that can do
that and many times people combine
processes with one of the other two so
you run a multi-threaded on an async
program and then they run it as as many
times as course you have which is
actually a pretty good idea but the
processes is the winner there so then we
come to scalability and this is an
interesting one because if you're
running multiple processes each process
will have a copy of the Python
interpreter but all and all the
resources that it uses plus a copy of
your code your application plus all the
resources that you use so all of that is
going to be duplicated so if you start
going crazy and start new instances you
can find that you know pretty soon
you're gonna reach you know you're gonna
be a probably out of memory you can
really run you cannot run a lot of
Python processes on a normal computer so
scalability is pretty low you know I
would say in the ones or the tens but no
more than that if you go to thread
threads a little bit more lightweight
the processes so you can you can
associate much more threads and
processes so that that's better you can
scale a little bit better I would say in
the hundreds if you go with async async
it's all done in Python space there's no
resources at the operating system level
that are used so these are extremely
lightweight so this is the clear winner
async can go into thousands or tens of
thousands even so this this would be a
good reason to go async now we have the
bad news of the using the blocking
functions in the Python standard library
which processes and threads can do no
problem because the operating system
knows how to deal with those but when we
lose the support of the operating system
in a
we cannot use those functions and we
need replacements and then last the the
global interpreter lock we know it
causes some trouble with threads in my
experience though it's not that bad when
you have the the types of applications
that are good for also for async which
are heavily i/o because unlike some
people think if you have threads that
are blocked on i/o that you don't hold
the global interpreter lock so if a
thread goes to weight then the operating
system will give will access will be
able to give access to another another
thread without any problems so really
it's not a great right I mean that there
aren't that many things are better for
for async it's that right that's it so
basically the the closing statement that
I would like to make is that really the
best argument to go async is when you
really need massive scaling right so
this would be servers that are going to
be very busy lots of clients want to
handle lots of clients without you know
going bankrupt in in buying a hosting
right so async can do that really well
it can go into thousands or the tens of
thousands of connections and it's like
nothing it's not a problem
which threads cannot get there and even
less processes any other or any other
categories it's not really you know
clear that you should go I think unless
you like it and then it's a totally
valid framework to develop your
applications right so if you like it you
like it right there's nothing to say
against that so this is pretty much all
I have it looks like I did good time
right so just going to be time for
questions looks like
Thank You Miguel are there any questions
yes so my question is is it possible to
schedule a synchronous operation from
multiple threads you can run a loop you
can have multiple loops right in
different threads all right they don't
go together in the same bucket and then
you have to use normal threading you
know synchronization mechanisms if you
need you know the tasks that are running
under one loop to somehow coordinate
with the other it gets pretty nasty to
be honest so pretty much you get
affiliated to that thread that's correct
yes
yes because most of the times you have
only one thread so yes thank you yep hi
Miguel
thank you for that talk I was hoping if
you can give me some help trying to
conceptualize this and like a stack
frame all this magic that happens not
necessarily just what they think but
it's generators and everything in
general well generators a Python feature
right they already support the you know
say in the context when when the
generator function calls the yield or
give from keyword it basically returns
it does sort of a partial return returns
the value and and control goes back to
the loop and then the loop can call that
again to you know to make that function
to do a little bit more work which is
exactly what you do when when you write
a generator function you basically you
have a function that returns partial
values every time you call it it that's
a little bit more work and returns
another you know another value and as a
result okay in architecture where you
spawned off multiple processes of the
async workers mm-hm
in say for a server how do you like the
socket binding how would that work
across the different processes ah it's
it's only one thread that that will have
a really large number of connections but
if I have the same port that has to go
through multiple processes
of them have a single thread of async
there are multiple ways to do it so for
example you can have a something like
nginx a reverse proxy in front so then
you or say you have four processes they
could be listening on different ports
right four ports say and then nginx you
know consolidates that and then reverse
proxies into all these back-end async
processes that will be one way
thank you that make sense how much more
imprecise is an async sleep command than
time dot sleep more could it be like
seconds more or so this is this is all
cooperative right so you really your
task depends on how the other tasks that
are running at the same time behave
right if you have a rogue task that you
know that that's a lot of computation
and doesn't return to the loop as often
as it should
that's gonna affect your timing so yes
and that that's actually the the problem
that I see most often is that you know
people forget that they're doing a sink
and there's some task that that's
something that blocks and that stops the
whole thing for everybody so yes
imprecise sure you need to make sure
that all the tasks are well designed for
a sink for one more short question so I
guess my question is related to the one
the gentleman asks the previously so
actually in in JavaScript one of the
issues is we used to be saying for 10
seconds it's actually at least a 10
second so I guess in Python they have
the same issue when I want to sleep a
certain callback for 10 seconds is still
at least a 10 second mm-hmm there right
it's it it depends on which it depends
on the other items so as I said before
the sleep function is going to be
implemented by the a sync frame boot
framework that you use right so async IO
implements sleep and then G event
implements sleep in a different way
right the wrong way
and you know every framework does it in
its own way and you can you know you're
gonna have to find the best async
framework if you are concerned about
that right you need to find the one that
it's more accurate but in the end it's
cooperative so it depends on all the
tasks being nice to each other if you
don't have that then this this doesn't
work well I guess in JavaScript at least
the guarantees there will be at least
yeah and you get a guarantee you know of
that sort but you know exact times are
you know heavily dependent on how the
tasks return to the loop it could be
continued out in the hallway mm-hmm many
thanks to MacLeod thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>