<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Developing For Mixed Reality With HoloLens And Unity | Coder Coacher - Coaching Coders</title><meta content="Developing For Mixed Reality With HoloLens And Unity - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Developing For Mixed Reality With HoloLens And Unity</b></h2><h5 class="post__date">2018-04-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pyQ6JpRFkcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for being here Frank you
organizers for having me at this
wonderful conference what I'm going to
talk about today is the technological
mixed reality and the device that runs
it which is called hololens and let me
first introduce myself I'm raffle
leggins you can find me on twitter at
traffic and i am a software engineer
working for a consultancy company called
solid brain is based in krakow poland
and what i do for last 6 months is i'm
focusing on this a our experiences
holographic experiences that you can get
with hololens and basically i'm
exploring the possibilities i'm talking
with different businesses and to see on
which fields can we employ this
technology also I am a compress
organizer I organize a deaf conf since
2011 in Krakow as well and I try to be
conferenced because so whenever I think
I have something interesting to say I
applied to conferences and hence I'm
here for example so Holland's how many
of you have heard about this device
that's what I think thought how many of
you actually tried the device quite a
few so I have the device with me so
after the session whatever whoever would
like to try it out I'm willing to to
help you out with this so let's do a
quick introduction to the device itself
it's as we can see everyone was raising
his or her hand because you know the
device already and that's true because
the device isn't like very new it was
announced in I guess it was late 2015
then it was released in early 2016 and
the first wave of devices was sent to
developers in June 2016 as far as I
remember so it's been a while since
since it's on the market and there are a
lot of companies already in developers
that are embracing this technology
creating lots of wonderful applications
but it's mainly targeted to business I
would say it's not like mainstream it's
not for consumer markets so that's why
it's not so that that much visible to
like regular users
say long story short it's it's a very
sophisticated AR device basically you
put it on your head head fire up the
application and all the sudden you can
see like a digital stuff around you and
the by the sophistic sophisticated
device i i meant that the digital
content that is being rendered by this
device is can really blend pretty
seamlessly and well with the user
environment which we'll see in a second
so you might have heard that like this
year and last year there's a lot of
stuff going on in the media or the
internet about AR VR that 2017 is the
Europe VR etc and you might be a little
bit confused with AR or VR or what kind
of devices we have on both feel both
feels how do they differ etc and where
the hololens is being placed in in this
group so having those two realities like
the physical one that one that we erect
are interacting with every single day on
our daily basis or at least I hope we're
interacting with physical reality all
the time and and the digital reality we
have in between whole spectrum of
different experiences that we can have
depending on the on the device and
depending on the software that runs on
those device so current AR devices lays
very near to that physical reality end
of the spectrum and that's because most
of the AR solutions right now or
basically run on smartphones or tablets
so the user hold it in his hand and
basically whatever the device can see
for the lenses it's being displayed on
the screen and then the digital content
is being overlaid on that screen so
basically there's no immersion effect
for the user the user is still fully
aware that he is in the physical
environment and it only looks at some
kind of screen with digital stuff on it
and it interacts with this stuff by
touching the screen
so no immersion evidence say some of the
devices
are little bit more sophisticated like
for like for example project tango from
Google where you have this special phone
like Android phone but the phone has
like special some special sensors in it
so so that this device can get a little
bit more understanding of the
environment so that it can deliver a
little bit more and of immersive
experience to the user because the stuff
that we can play with on that on that AR
device can blend with the environment
better than on the other devices but
it's still not the same as in Hollands
also we have those AR Solutions wearable
AR solutions like Google glasses for
example or absolute area those are smart
glasses that basically you put on your
hand ahead and have your hands-free but
the digital content that is being
rendered there on the other hand is
totally detached from the users
environment I mean it's basically some
text or images floating in front of the
user eyes so it's okay
ish but it's still not kind of
augmenting the real world it's basically
some digital content in front of the
eyes on the other hand it's worth
mentioning that most VR devices
experiences that we have right now in
the market and I mean like HTC vive
oculus rift psvr etc they live on the
other side of this spectrum and I don't
know how many of you try the regular VR
headset like oculus vive or so many of
you so you already know that those
experiences are like very massive I mean
whenever you have this cat sit down
you're basically out of the real world
and you're fully immersed in that
virtual environment and you have
basically no sense of whatever is
happening in the real world right and
you can also see all those funny VR
prank videos on YouTube where someone is
playing a bigger game and the other
person is poking that person and the the
person playing is freaking out because
something is going
that is not in the visual reality which
is funny and a little bit scary of
course but it's true I mean the VR
experiences that we have right now they
are totally like in this direction so
where is hollowness then Holland's as I
already mentioned is the sophisticated
AR device so obviously it lies on this
side of spectrum it's more sophisticated
because it's parked with all kind of
sensors it's also a head mounted display
so the user can go hands-free the lenses
are optical see-through so there is no
occlusion when it comes to the user
visions of the user can still experience
the real world but this real world is
enhanced with digital content which is
rendered here and there and blend pretty
seamlessly with the environment so it's
nothing more like whatever we have in
terms of AER on the market and in my
opinion there is no competition at the
given moment for Hollis and and when it
comes to VR it's worth mentioning also
what Microsoft is doing recently is that
they recently release the whole set of
new VR headsets they partnered with
companies like Asus Acer Samsung Lenovo
Dell etc and they released new headsets
which are basically like oculus and vive
the regular heads that you connect to a
PC and you can play games or run
applications on it and but the thing is
that they employ some technologies from
hololens to those VR headsets so for
example we revive and oculus the thing
is that you need external sensors to
track the users movement I don't know if
you remember when you were trying the
vipera cruise but you have to have those
external sensors 2 or 3 for artists and
2 satellites which are put above the
user with vive and this is and this is
something that makes the user play space
are we are really kind of small and not
that extensible I would say
but with those new head says the
inside-out tracking from hololens allows
the headset to track sees itself so
there's basically no need for external
external sensors you basically plug it
in to your computer do a quick setup and
that's it and the whole the whole
spectrum is being called mixed reality
and that's the term that Microsoft is
using a lot recently you can using hear
it a lot and but it's not the term that
is being made up by by Microsoft because
that terms appear appeared in some
papers like 30 years ago something that
because the whole spectrum is also known
as virtuality reality continuum and this
is something that scientists were
working on like for several years
already but the thing is I think that
what Microsoft is trying to do here is
they're trying to close this gap they're
trying to deliver a set of devices or
maybe one ultimate device that would be
able to eventually deliver all kinds of
VR or AR experiences to the user so we
those are really interesting times we
were living in so let's go quickly for
the specification or maybe technical
details of the name of the device and it
wouldn't we did it wouldn't be possible
to deliver this kind of experience to
the user without all kind of sensors and
hallways have them all I would say I
mean the most important ones in my
opinion are those two which are
environmental understanding cameras
basically those sensors are responsible
for gathering users surrounding data
they're scanning the the environment or
all the time whenever the whole lens is
turned down also it has HD camera
ambient license or def camera mixed
reality capture camera and an array of
four microphones so that it's possible
to issue voice commands to hololens and
as a developer as developers we can
handle that and operate in our
applications with voice commands and
other thing is the optics I already
mentioned that it's not it's a
optical sifu lenses there is no
occlusion effect when it comes to users
vision the thing every every eye is
being covered by an HD engine so that
means it's more or less 1,200 by 700
pixels per eye but when the cam cyka
hololens we've done we don't describe
those lenses in terms of resolution as
we might know from the regular screens
because we do not have to feel the whole
vision with pixels because that what
real word is doing we have all the
pixels render it right we have to only
render some extra pixels right the the
Holograms so when it comes to colors we
have something which is called
holographic resolution and that means
how many light points and by light
points and mean points that build up
Holograms how many light points can the
device render at the given moment and
that number is 2.3 million light points
also we have something similar to dpi
from regular screens which is called
holographic density here that means how
many light points per Radian can be
rendered and that number is 2.5 k also
we have the the holographic processing
uniq will in short HP HP has basically
the cast only designed chipset it was
done by Intel and as far as far as I
remember and this this unit is
responsible for processing all the
sensory data so whatever comes from the
sensor goes through goes through this
core processor and then after being
processed it's being used by the other
ones and also it processes user gestures
for example for example so all this
technology I'm not I'm not going into
details here how much gigabytes of RAM
or whatever Bluetooth it has because I
mean that's basically it's a mobile
phone I would say right it's not that
important here right now so given all
this technology and and in the software
and and the whole is actually run
Windows 10 on board so it's well known
Platt
I would say my developers already
created all sorts of all sorts of good
solutions for hololens so let's just
name a few the ones that I like the most
and actually for all of them you can
find a YouTube video explaining in
details on explaining in details on how
what are those project about and the
first one is from a company called city
it's backing company where the user can
have financial data rendered in front of
him and play around with this data dig
through render some holographic 3d
graphs based on some data the other one
is from Ford they recently announced
that their start they start using
hololens for the designing process so
that the it's the DES and process is
enhanced with Holograms and here we can
actually see that there are two persons
using whole advances and they're looking
at one piece of hologram and that's one
of the features one of the cool features
of Hollande's where basically we can
have one applications that is being run
on both whole lenses and they can share
the holographic space so that users can
actually work on kind of inside one
applications which is really cool full
collaboration also one of my favorite
favorite solution this is something I'm
focusing on right now as well nowadays
it's from Schneider Electric where
basically it's a maintenance
applications for Service Worker
so whenever the Service Worker is about
to do some work on a piece of machinery
whenever he has a whole hands-on he can
have some digital content overlaid over
that machine so that some steps can be
displayed or some extra information can
be displayed or this crew can be shown
or highlighted which which screw has to
be unscrewed for example so this is
pretty cool
for for maintenance work as well thyssen
krupp company the company that produces
elevators as well has this application
for service workers
whenever the worker has some job to do
at the elevator he can have all the
contacts information he wants just in
front of the eyes and for example you
can have service manuals some tutorial
videos can have Skype he can perform a
Skype call to someone else's showing
what he's saying he can have like a 3d
model of the thing that he's about the
thing that he's going to work on and can
explore it a little bit deeper but on
the 3d model so those are all cool
applications in my opinion and there are
lots of them of course and but those
applications we can see here they do not
use horns to fully extend and by full
extent I mean they do not use the the
coolest feature in my opinion basically
that means special mapping special
mapping is this is this feature of horns
where as developers we can make use of
all those scanned all those data that
comes from the scanning process of the
whole and so basically whenever the
Collinses holland's is scanning the
users location all the data is being
stored on Hollins in special buckets I
would say and then as developers we can
build up the whole mesh of the location
inside our applications so basically
here we can see like the mesh of the
room I know it you can't see like a lot
but basically it's a mesh of the room
where mesh mimics all the real surfaces
and here is the inunity here is the
material applied which is this white
wire frame so that we have the
visualization but what I mean is and
that we can have the real room inside
our application who can do all kinds of
cool stuff with it and the thing the
coolest thing lays under the hood that
means colliders those are regular Unity
colliders that means this is the those
are those are the pieces that makes all
the physics possible inside unity unity
engine and unity is the engine which we
used for whole as development so
basically wherever we have
regular real-word surfaces around us we
have pretty well aligned colliders
everywhere so if we had would have for
example a holographic ball inside our
application and if we would it would
like to bounce it on the floor then we
can detect that the ball is actually
hitting the collider
coleye de which is aligned window with
the floor and we can do all the same
stuff with walls or sofas or chairs etc
so based on that feature we can create
all sorts of even cooler scenarios like
those games that come from Microsoft and
asobo studio the one is a young conker
where we have this little guy that is
running on our floor jumping in our bed
chairs or table we have this game which
is called fragments that the best game
on Holland's in my opinion basically it
turned your interns your room into a
crime scene and you're a detective
trying to solve this some kind of
mystery and basically you have the clues
that are being hidden in your room so
you have to look for them like on the
walls in the corners behind the desk or
or your sofa this is pretty cool this is
the the best immersive effect AR effect
I've ever seen actually and you have all
those holographic persons as actually
walk into their room and they sit on
your sofa that's that's really cool
that's mind-blowing my opinion also we
have rubber right where there is this
alien invasion and actually the aliens
drill through your real walls and like
like like here and they attack you and
then you shoot them and when you miss
shoot them then you're making holes in
your real walls this is amazing as well
I mean totally awesome so how do we use
hololens how do we interact with it how
do we issue comments so we have this
this paradigm called GG V input
where GG V stands for gaze gesture and
voice so gaze is basically something
like this I would say right like if you
would have a laser
from our forehead and this is the main
way how we indicate what are we going to
interact with so basically is the same
as the cursor on the computer right we
first indicate something and then we
invoke some action like clicking so this
is the cursor basically in applications
where ever the the the our array from
from our forehead hits the surface
whether it is like a real surface or the
field the object we have a cursor that
is rendered on in that place the other
thing is gestures so the same as we can
do on computer like indicate something
with the cursor and then click here we
have also a click but this click we're
performing in air like air tapping it's
something like that and based on that
gesture we have some other gestures like
hold which is like just holding your
fingers together and based on holding we
have like manipulation and navigation
gestures where we can basically track
our a hand movement and there we can do
some some operations based on that and
there are there are no other gesture I
mean there's one other gesture which is
Blum but this is like operational system
level just certain which we can't use in
our applications so no other gestures we
can't define our own we have to live
with that but that's more than enough I
would say the other thing is voice so we
can basically issue voice commands and
as developers you can program for some
keywords detection and based on that
keywords we can perform some actions so
basically with this paradigm we can look
at something issue a voice command or
just our tab or manipulate stuff
whatever we like so that's the that's
how we interact with stuff so let's go
to tools the most common way to program
for whole lines is by using unity which
is well known
I would say and visual studio which I
probably don't have to introduce to you
so starting from version 5.5 as far as I
remember I'm going to introduce a full
support for hololens so we have this
namespace there called unity engine XR
WUSA where all the classes that are
helpful for all lenses live and we can
just use unity pure unity to unity and
c-sharp scripts for creating the whole
ins applications but community came to
the rescue and there has been there was
a lot of work put into one particular
library which is called mixed reality
toolkit which came from Microsoft and
the open source it it's a it's a
combination of scripts objects shaders
materials that you can use in in your
unity projects that help a lot while
starting with and producing colin's
applications and some of them are pretty
cool because as we've seen the games
earlier the fragments game and young
conquer so the the studio a substitute
that was working on those games they did
lots of work regarding spatial mapping
and detecting different surfaces in our
area and it all has been released as an
open source and it lives in this toolkit
so it's pretty cool we can use all of
that and I will actually we have some
time still so we'll actually go through
real quick on how to make use of the
things from a mixed reality toolkit in a
second the other thing is mixed reality
design labs is basically a set of it's
also open source it's a set of
applications by Microsoft well those are
different applications I mean it's like
lunar lander or something like that
but there are well documented and they
are on github it's open source and you
can make use of them or learn based on
them or reuse some components that there
using in those games so this is this set
of modules I would say is really helpful
when whenever you would like to do hole
and supplication so let's now switch to
to unity I think and let's do like a
really quick really quick hello world
application for hololens i don't know
how many of you are familiar with unity
does anyone okay so not not many people
okay so i will explain some bits but
will not go too much details with that
so that's basically unity is an engine
and also an ide because unity comes with
an editor where come on
okay let's just create some it's we're
creating a project and then the editor
will show up in few seconds I guess this
okay it might look a little bit scary
you have if you haven't ever did any job
in 3d programs or anything like that so
long story short just like we have a
scene view here where we put up our
scene we have an inspector here on the
on the on the right where basically is
the same as like properties pane in
Visual Studio so whenever we select some
we'll select some object we can have
properties of it here we have a
hierarchy here so it's like a hierarchy
of objects in our game or application
and we have a project pane where where
we have all the assets that we have
imported to our application so first
things first first we will import import
this mixed reality mixed reality toolkit
I've already downloaded it it's it comes
in the form of unity package so
basically we import that package into
unity editor and it's decompressing and
probably checking something and it will
show us what are the contents of of that
package so we have here all important
stuff like built built helpers some
cross-platform stuff helpers for import
etc etc we don't care right now
which which would like to import or not
or not let's just import everything
we'll just make use of several of them
I'm going to show you that we can create
like really really simple application
like a cube which we can click by
basically putting some pieces together
and writing like one one line of code or
something like that so it's like super
easy to start hold on
yes it's important so the very next step
would be to to set up all the properties
or the necessary properties inside unity
editor so that the unity knows that we
are creating applications for Hollande's
because that's not the default obviously
so I could go through all the menus and
and inspector panes and selecting all
the necessary details but that would
take some time but what my mixed reality
toolkit developers did they created some
scripts that can automate that process
so what I basically will do is I will
just select one option in the menu as
soon as the whole loan process will stop
we're almost done and done okay so we
have this toolkit imported here it was
called hollow toolkit not that long time
ago but they they renamed it into mixed
reality took it so we have all the
necessary stuff here but first let's
configure them let's first save the
scene a source gene that's important and
let's first configure our development
environment for hololens and we've whole
kit it's basically one click apply whole
as project settings and bomb we're done
I mean what it's doing is basically
enable VR it's setting the quality to
fastest it it sets the build target for
direct3d and setting the target also to
be the universal Windows platform
application so that's that's all it does
into the reboot and after it's done
we're almost don't need that one okay
then we can start putting together the
application we have main camera that
basically camera
3d engines it's basically the camera for
whatever the user will see we need to
delete that one and call a toolkit or
mixed rarity tool kit comes with its own
camera which is already set up for
Holland's development and what we did
what we do is basically we can drag and
drop the whole and camera here we can
see all the details in the inspector
pane I'm not going to go through all of
them or any of them because that will
just take out of time and would be that
necessary also we have something which
is called input manager that's basically
a set of scripts that are responsible
for for the user interactions that they
all wrap the scripting API from unity
and they makes they make a lot a lot of
things way easier which I will show you
in a second
also in the cursor which is somewhere
there as you can see I'm not writing a
single line of code and I have some kind
of application right now and then I will
create a simple cube right in the middle
and that cube by default is in the size
of one by one by one and that means one
meter by one meter by one meter so let's
change it like 20 centimeters H and let
me just do a quick setup here that we
are building for hall and and we can run
this application inside our unity unity
project and what we have here is I'm
using my keyboard to to to move in the
application and that's the actually
feature that comes for withholdings
camera so that we can move here like in
the games so that what we see here is
that we have this box we can look walk
around walk walk around it and wherever
we have our ray our gaze crossing with
the with the object we have this cursor
rendered and whenever we do not cross
anything we just have this blue
dot that indicates that we were not
hitting any surface so that's some kind
of a pattern I would say and well let's
do something that that would actually be
some kind of interaction so let's do
like like a click on that on that box
and let's see how easy it is to be done
so what we will do what we will do is
whenever we will click on that box I
will I will make the gravity being
applied to it so that it will just fall
down right so let's first add something
just called rigidbody to this come to
this object and rigid body is basically
component which whenever you add it to a
3d object it will start behaving like a
physical object so you can have all the
physical interactions with it and one of
which one of which is the gravity and I
will turn it off so that the gravity
wouldn't affect that object and also I
will add a script which will name cube
behavior bomb create an ADD and will
edit the script in visual studio and the
thing is that in unity like in any any
other game engine
we have scripts that are being run in a
game loop so in this case we have in
every script we have the update method
and that method is being run 60 times
per seconds and that's it so that's
that's something different that than
what we were doing for example in
regular enterprise applications so we
have this one script attached to this
script is going to be attached to our
cubes so whenever the cube is rendered
the update function which is here maybe
I'll make make it a little bit a little
bit bigger this update function is being
run 60 times per second so writing
applications here is a bit different
than what we're doing in enterprise
stuff for example but what we wanted to
do is handle the clicking so I could go
to scripting API from Unity
and look for all those evens that I have
to listen to and all the stuff and set
it up but what Microsoft what mixed
reality took it does they provide the
wrapped it up and they provide simple
interfaces that we can implement to
handle for example clicks so handle the
clicking would be as simple as
implementing the interface called I in
boot click handler let's import the
whole toolkit and implement that
interface so that's it so whenever we
whenever we click click that box I mean
I'll tap on that box this method will be
involved and what we would like to do
here is apply gravity so we are getting
this rigid body component from our
object and the basically rigid body use
gravity true bomb let's go back to to
our application and let's run it
we have a we have our box here let's
click on it
bomb and fell down and we can see it and
as we can see here it's like falling to
the void like all the way down all the
way down so yeah it so that's the
problem so we would like to have a floor
here in the in our in our unity project
so and this is the hole ins application
so the floor is actually being generated
like in there on time right we don't
have this floor here so there is this
one little trick that I really like so
that there is no need to have hole
answers all the time with you for
debugging because that will be tiring to
have a floor I mean that will be tiring
to put hole and so on just to have a
floor and test if the box is hitting the
floor so let's just start using special
mapping here inside unity and see how we
can emulate the some kind of room inside
hole inside unity project so it's as
easy as as the other things we did
basically we grabbed special mapping
prefab which is similar what we did
previously and the special mapping
prefab here the thing I just dragged and
drop is also something that wraps
whatever is in scripting API for special
mapping we can adjust for example
numbers of triangles for the mesh that
we are creating right for the spatial
mapping match but we're not going to
play with those with those values here
so this is a special special mapping the
other thing we need to do is go to
project settings and select the
capability of the application so that if
we would run it on hololens will let
user know that it requires a special
mapping capability that we are going to
use in our application a special data
that is being stored on hololens
so as simple as that we have the special
mapping capability but still we do not
have this room anywhere here I mean what
I just
just work but when I would run it on
Hollins because there I with this
special mapping module that I added all
the data that is being stored on Hollins
about the current location would be used
and there we would have this floor but
still in our unity editor we do not have
it but there is this fun trick and the
cool thing that was delivered in mixed
reality toolkit is that inside the
special mapping special mapping module
we have objects surface observer and
here we can provide a room model and
that basically means hold on for a
second that basically means you can have
room of room model in like in like a
separate file file and that file can be
created actually by hololens because we
can connect with hole answers and grab
the current scan currently scanned
location I mean the location we are in
at the moment and we can export it to
like a file with with the 3d model and
that model can be imported in unity
I'm gonna import it that's a regular or
obj object it's it's just a regular
object that you would create in blender
or 3d studio max as we can see here like
this the small thingy it's a it's a 3d
object for off some room that I scanned
and what I will do is basically I will
attach it to my room model and then I'll
run it again and bam we have the mesh of
our room down and we have all the
colliders here as I explained earlier so
basically where is that box okay so it's
outside of the room so we can so we can
tweak it a little bit and we'll just
move it a little bit inside the room
because well the the object is created
in in point zero zero zero in this space
and point zero zero zero is whatever we
fire the application Hall lands and
whatever the users head is that's where
the coordinate system will be zeroed I
would say well it's okay oh no not this
way that way
okay so here we have the box inside our
room and then we can tap on it and it's
on the floor right so right now we can
disable the mesh that the Dwight thingy
and we will still have that box no match
but as you can see the cursor appears
sometimes to be like the blue one so
that the surface is there but it's
invisible so if we would run it on
hololens the we will still have that
mesh but it's invisible and we can hit
the floor for example so we can tap on
the box and we it will be sitting on the
floor down so we have like two minutes
left
I don't know maybe questions and answers
I would say because I mean I can I can
show you how to deploy it to Cohens but
it's basically building and and pushing
it to a hole and for visuals to there is
nothing really fancy so let's just do
questions and answers and I can show you
call a some who to whoever likes it
afterwards yeah yeah yeah so for example
what I'm doing right now is I I was
given the cut cut project from one of
the cut designers which is like some
kind of machinery and I'm putting it in
I put it into a Collins app and I can
place that machine like in front of me I
can actually I think I can I don't know
if I have this video whatever yeah you
create the the objects in some kind of
other applications
again again direction we'll be looking
at yes yes SS yes it's a it's a gays
vector you can get it yeah yeah no no
it's like it's like regular vectors yeah
I mean I think yeah I think so yeah it's
Kay's direction it's called gays
direction it's it's a bacteria
animations you mean yeah yeah it's
simple isn't the object and you
basically that's that's a unity thing
it's not whole and think it's basically
can you can fire up the animation that
is blended with the with the object yes
yes yes or you can create your
animations inside unity as well so it
depends basically any other question yes
again what was the question which
framerate
oh the framework the default frame rate
is 60 frames per hours but it's but it's
per second sorry
aha that'll be bad frame rate yeah yeah
so 60 fps and well we have to keep that
I mean based on the performance of the
application it can drop of course but we
should keep it like 160 okay yeah it's
the whole assets of the development
version called version costs $3,000 and
the regular version like the enterprise
cost $5,000 so looking at prices we can
assume that it's not for consumer market
but the games the games were created at
the very beginning where the where the
whole lens was released and those were
basically for showing the capabilities
of the device so it's not like for
people to buy that those games are for
free and they're just showing the the
things that it's from Microsoft to show
you know how this thing works
but there are also lots of developers
that are just learning the platform and
there are creating games as well just
for fun and and learning
yeah I mean there is minecraft for this
yeah I mean yes I mean but all this is
basically I think for promotion I would
say it's not like you can it's too
expensive for to expect that the regular
user will just buy it like on the
consumer market yeah more or less like a
multiplier environment it's basically to
two instances of the same application
that one it runs on one on wholeness and
the other one runs on the other one and
the first one connects to like some kind
of service and when the other person
connects that service their coordinate
systems are being aligned and all the
all the Holograms they have they're also
being aligned with each other's so it's
and it's all about like exchanging data
on what happened in one environment to
the other one and it's all being aligned
so it's like a multiplayer game I would
say well it's it's a service on some
server that lives in it communicates
over Wi-Fi yeah yeah yeah and and and
and colons they have they have wife of
it Wi-Fi it because their horns the the
device is untethered so there's no wire
there but their life is about two to
three hours active viewers so it's not
like very very long but you would prefer
example you wouldn't like to use it like
for eight hours at all because it's it's
it's kind of too heavy so after one hour
it's like you need the rest basically
yeah yeah
I mean how far you have to be from the
wall to the wall being scanned or I well
it depends I mean if we would tweak the
number of triangles that we would like
to have in our special mesh it can get
pretty pretty decent but the main
purpose is for scanning like the
surfaces or bigger objects in the user
environment there is no way to scan for
example like a bottle or like smaller
objects and detect them with special
mapping it's not it's not the tool for
that you have to use something else
so basically walls chairs sofas like
bigger objects that define our
environment not yet not in applications
that I had but I can assume if you for
example import like well I had once when
I had an object from like blender which
had like way too many triangles and then
basically after importing it it killed
the application because we have to i had
to lower the number of triangles
basically
and if you guys okay so thank you if you
would like to try the whole line right
here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>