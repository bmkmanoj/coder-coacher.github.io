<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Loading on the Web | Coder Coacher - Coaching Coders</title><meta content="The Future of Loading on the Web - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Coding-Tech/">Coding Tech</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of Loading on the Web</b></h2><h5 class="post__date">2018-02-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eDjVDO2_O7A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is Sam ciccone
you may know me a little better like
this
this might seem more familiar but Here I
am it's a pleasure to see everyone and
hopefully it's alright seeing me so
today we're going to talk about the
future of performance on the web and a
look into performance patterns that will
be coming to the platform soon hopefully
I've never been so excited to be a web
developer in 2017 we have all these
amazing primitives at our fingertips
from WebGL from serviceworkers for
offline to web USB to interact with
physical devices that we can plug into
our computer we have so many ways that
we can express ourselves on the web like
never before but as Eric put so well
chrome chips
a lot of features in the past four years
it's shipped over a thousand features in
Chrome and if you're like me I get a
little overwhelmed all these new things
coming at me all these blog posts about
new things that I can do and I lose
track of what's coming up because I can
barely keep track of what's already
landed so before we go into talking
about performance I want to make sure we
have a common language that we can use
when talking about performance so let's
zoom out and think about performance in
three primary pillars we have our
network bound operations our parse and
execution bound operations and finally
our render bound operations you can
think of network bound as when you go to
a web page you have to download some
files and how those files get to you is
important because the faster they get to
your user the faster that you can
actually run them when we finally get
those files and run them we enter into
this phase where the files are being
evaluated and executed and how they are
run impacts our user experience and
impacts how fast we can get things to
the screen and finally when our files
have run we drop into a renderer phase
where the page takes all the
side-effects of our operations and
paints them onto the screen so to start
I want to talk about bundling
performance bundling perform
is bundling your files together and
getting them to your user over the
network and I want to take a look at
some future patterns which are going to
kind of question our common best
practices apps today kind of look like
this if you've shipped an app or looked
at the network profiler when you've
loaded an application you might see this
sort of shape you have an application
bundle a vendor bundle and a style is
that CSS and these are the combination
of all your individual files compiled
together if you've read any sort of
performance blog posts or books it will
always say you need to bundle you need
to be combining your assets together
before you ship them to your user
because it's going to get the assets to
your users faster because they're not
going to have to round-trip with the
server over and over again however this
approach has some performance downsides
that not too many people talk about
let's consider the following situation
our application bundle has page 1 j sfh
2 j s and a common JS file that's
required in both our vendor bundle and
our application bundle for these bundles
to be valid think of these like string
utilities something that's required in
both files to even run and in our Styles
file we have our individual CSS files
rolled up into one single bundle but we
have this common J's file that's shared
so this means that when we change a
single bundled file so comment is all
dependent bundles are invalidated
invalidated is a fancy way to say that
the browser needs to redownload them
because now when I load the page for the
second time the browser will say app
bundle has changed vendor bundle has
changed so I need to refresh them from
the network redownload them re-evaluate
them reparse them and finally execute
them so a small change like an update to
your strings that J's file and command J
S might cause all of your files to be
invalidated and this and the sorry
downloaded which will cause a negative
perf impact for your end users ideally
something that we want to avoid
so I postulate what if our applications
look like this some of you may already
be doing a form of this where you're
shipping
assets based on route or you're using
something like react router and web pack
to do route based splitting but I want
to push it a step further and say what
if we took our individual routes and
also our individual libraries and
started shipping them independent of
each other so page 1 page 2 modal
library framework and all of our CSS
individually as well
now when you would go and make a bug-fix
to page 2 dot Jas instead of your entire
bundle having to redownload you only
need to redownload one single file not
these entire bundles meaning that when
your user reloads the page they already
have the majority of the assets in their
cache and do not have to round-trip for
those assets now when we ship granular
assets there are some other interesting
winds that come along with that so let's
walk through what it looks like to load
a single javascript file when we load a
javascript file we first have to
download it from the network the
JavaScript file once we have it enters
into this parse phase where the
JavaScript engine has to take this
textual representation of your code and
turn it into a shape that the browser
can understand once it has that parse
phase done it drops into a compile phase
where it takes that parsed structure and
compiles it into a machine and
platform-specific binary format that
then can be run in v8 or in your
JavaScript engine of choice so we start
shipping granular assets this means that
our initial download gets saved on
repeat loads because we have that asset
locally and cached we then have to still
do our parse compile and execute phase
but we have a significant savings
already now wouldn't it be nice if there
was a way that we could get around this
parse and compile phase which is
non-trivial for large scripts well it
turns out that v8 is smart and does some
fancy optimizations when you reload a
script enough times v8 will say hey I've
seen this page one that Jas multiple
times now and I'm going to take the
parson
work that I've done before and reapply
it back to this file so it can cut down
the amount of time that your JavaScript
engine is spending in parse and compile
because it reuses the work that it's
done now on average this yields about a
40% reduction in parse and compile time
and this is across all sites now you can
think of this number as an
implementation detail in v8 this number
is only going to rise and I know the
team is actively working on driving this
down but by shipping granular assets we
opt into the savings whereas before we
were invalidating entire bundles we now
invalidate single files which means that
the engine can reuse the logic that it
has to reapply parse and compile on to
the same file so with all these
optimizations we end up saving a
non-trivial amount of time when
redelivery assets to the user on second
third fourth reload so the good news is
today it is possible with script type
module to load completely unbundled code
via es2015
imports script type module and you're
good to go chrome engineers recently
kind of put this to the test they asked
the question well what would it look
like if I went all in and loaded all my
code completely unbundled so they took
some popular libraries like moment Jas
and three Jas and tried to load them
without having any compiler phase and
what they found is that when you
unbundle everything it gets slower
unfortunately in the case of moment Jas
which this graph is from the perf gap
was over a hundred milliseconds of
loading moment Jas which is hundreds of
files using es2015 imports as compared
to bundling not minifying in this case
just bundling the files together so this
is kind of disappointing as a developer
right now and it kind of leads into the
fact that delivering granular assets and
ensuring good performance is tricky
slash not really possible to do today so
why are we talking about granular
acet living well it's because I want to
talk about where we're going and some of
the performance patterns that are going
to be unlocked on the platform soon in
the examples that we've talked about
we've sort of looked at loading all the
individual files upfront and paying that
cost and in that case bundling makes a
lot of sense however would it be nice if
in the browser we could have some
information about what the current state
of the client is before we send off
those requests so we can intelligently
choose what to request and when to
request it well this brings in this
feature that has landed in chrome for
dynamic imports dynamic imports is j/s
code loading on demand in the browser
this looks something like this we have a
import here that uses a familiar import
syntax that can load a file it returns a
promise one that promise is resolved we
have that module that has been loaded in
the browser inside of an if condition
here which is the interesting part and
then we execute run which is an exported
function from that model now dynamic
imports are cool but that demo didn't
really show their full potential so I'm
going to lean on another new API that's
the network information which you've
heard about a little bit already the
network information API allows you
inside of the client to determine the
runtime conditions so that you can then
choose how you're going to fetch your
assets so we can look at things like
type download round-trip time estimates
download max an effective type to figure
out what is the correct solution for
this specific client so using that
primitive plus dynamic imports we can
come up with a dynamic loader a bit of
code that can determine should I be
downloading a bundle for this client or
should I be downloading granular assets
and thus getting that repeat page load
performance game that I get from
granular assets so we're saying if the
round-trip transit time is over 500
milliseconds go ahead and download the
bundle because we don't want our users
to pay the cost in this case otherwise
drop into granular assets because we
want that repeat page load performance
so with client conditions and dynamic
imports we can start delivering optimal
performance across a multitude of client
conditions so one case or one one
solution won't have to fit every one of
your clients so we've talked about
loading now I want to talk about the
next phase that your browser drops into
and it's once you have these assets
getting to interactive faster so
painting what's important for your users
on the screen as fast as possible I
think that we are at sort of a loading
inflection point on the web we're moving
from a world where the client has been
initiating fetches to a world where the
server will be pushing us assets we are
moving from a world where the browser
discovered all of your assets to you as
a developer are able to declare your
assets upfront without your browser
heifer having to read all the files and
finally we're moving from a world where
assets have inferred priorities about
what's important and what's not too
explicit priorities that you as a
developer can say what's more important
than something else the first part of
this is cache digest with HTTP to push
now I've been a vocal critic of HTTP to
push and saying that it is a foot gun
that can get you into trouble
however this proposal sort of course
corrects and gives us a new primitive
which will allow us to get around one of
the major problems which is over pushing
so consider the following situation
imagine your client is repeating a page
load on a web page and for that page the
server says you're loading index.html
I'm going to need assets A through F I
know you are because I'm the server I
know exactly what I'm going to be
sending you but the client already has
assets a through D locally so the server
pushing assets a through D would result
in an over push recurring so wasting
network resources to send these assets
that the client doesn't really need so
in this case I call this over pushed
it's
unnecessary cash digest would enable a
client to tell the server exactly what
it has in its cache so it would be able
to say as soon as that h2 connection is
opened hello server it's nice to see you
here's what I have in my cache whatever
you do don't send these files to me
because I already have them and the
server would say okay cool I see that
you have a through D here ENF go on have
a great day so in this case we are no
longer over pushing and the user has a
faster load in experience and this is
one of several solutions this is just a
proposal but there's a lot of people
working on this which I'm excited about
so this brings us into the next phase
when it comes to delivering assets not
all assets should be treated with the
same priority what does this mean well
it'd be great if I as a developer was
able to hint to my browser exactly what
was important and what was not and we
can do this via a proposal for priority
hence explicit priorities versus
inferred priorities think of your
browser sort of like a gigantic
inference engine it loads an index.html
file it scans through the page it looks
at the position of your script tags of
your images of your CSS and it says this
is critical to the page this is not
critical to the page this seems medium
priority but because it's an inference
engine it doesn't always do the right
thing when you as a developer know
exactly what you want it to do so
priority hints give you as a developer
explicit control over what you load and
how you load it now before we had to do
some kind of silly things to hack around
priorities where we would use a link rel
preload tag to force an async script to
load as high priority or do something
even crazier like use an image tag to
load a javascript file that we were
dynamically important to the page on err
kind of strange stuff but hacks more or
less priority hints give us a path to
remove these hacks and opt into this
explicit performance path so let's take
one of my favorite sites my my fav
at site so the site has three images or
two images in a JavaScript file no I
want my users to always see my favorite
app first so what I'm going to use is
use resource priority hints to use a
syntax of group to say I want you to
download my favorite hat first and once
that's downloaded go ahead and download
cool hats gif in the background and hat
store dot J s in the background because
the most important thing for users to do
when they load this page is to see my
favorite hat I could care less right
away about my cool hats showing in my
store now this proposal goes a step
further and it's not just for image tags
and script tags but it's also for
fetches so this means with a fetch you
can set the priority of a fetch so that
it doesn't cause contention in your
network stack for low priority fetches
so consider you had a long pull
operation that paying the server every n
seconds wasn't really important didn't
need to happen right away you could set
the priority for that fetch as low and
offload that work from the critical user
story around your network next async
images asic images is a intent to ship
proposal from chrome that unlocks the
explicit control over image decoding and
allows you as a developer to move images
outside of your critical path what our
async image is why would I want this
okay well let's look at this example we
have a very large image and then we have
a javascript file so what can happen in
this case is our image starts
downloading on top our script starts
downloading on bottom our image download
finishes before our script the image
that goes into this phase of decode and
a decode of an image ties up the main
thread that means that it actually
blocks that script from dropping in to
parse compile an eval so it pushes out
when that script runs so I'm guessing
that your website maybe an image isn't
as important as delivering your
framework to actually show the page so
this seems undesirable with the async
proposal we'll
be able to work around this we'll be
able to free up the main thread from the
image decoding overhead so we would mark
this image as async and now our
waterfall looks like this we download
our script file we download our image
file the image says hey I have an async
attribute I'm going to defer the
decoding of this off the main thread off
the critical or it's still in the main
thread but it's off the critical path
and then the script is going to say I'm
ready I'm going to drop in to parse
compile eval and once my critical main
path story has been completed the image
is going to go into a decoding phase
which is going to unblock the rest of
the interaction on your page okay so
we've talked about bundling and
delivering assets and making sure those
assets are to our users when we want
them and things are executing in the
order we want but we still have the
entire runtime phase of our web app so
our assets are running our page is now
interactable but we want to optimize the
actual runtime of what's going on under
the hood so I want to talk to you about
how to move work out of the critical
path and how to do more work without
impacting the user experience this
brings in my friend web workers now web
workers are not service workers web
workers are a utility that you can think
of as friends that you can give
JavaScript tasks to that will run these
tasks and keep your main thread
responsive because your main thread is
concerned with doing other things so
imagine our browser here in the middle
and it has all these tasks that are
coming down react to user input download
this script file calculate pi - 10
digits okay doing them doing them great
but then our page starts to get
overloaded we ask the browser to do more
than it can keep up with and this
results in jank we've all had the
experience where we load a page and try
and interact with it and nothing happens
or tapping and nothing's loading and all
of a sudden everything snaps in this is
because your browser was overloaded and
trying to catch up but with web workers
we can take these tasks and hand them
off
- our web worker friends and the web
workers will execute these tasks for us
and then pass them back to the main
thread when they're done this leaves the
main thread open and available to react
to user input to take care of the
critical tasks that the browser needs to
do to make sure you user experience is
great
so I made a demo to illustrate exactly
what's happening here all this demo is
is I'm moving a rectangle across the
screen in canvas I'm doing it on the
main thread on the top and then a worker
thread on the bottom and I'm passing
just an array buffer for the screen or
for the canvas back to the main thread
to draw this we can see that the worker
thread goes quite a bit faster than the
main thread and why is that well it's
because the main thread has a lot of
stuff to do the main thread has to
render all this the main thread has to
react to user input the main thread has
to keep track of a whole bunch of stuff
but my work real thread all its
concerned with is move the box by one
pixel move the box by one pixel and
because it's focused on just one
specific task it's a lot it's able to do
that a lot faster but as web developers
we find ourselves working with the Dom
often and basically always working with
the DOM and if you've looked at web
workers at all you may have noticed that
web workers don't have access to the Dom
which is painful as a web developer and
makes it seem like it doesn't quite fit
but I'm excited because there are some
proposals in the works to lift this
restriction to make it possible to do
Dom manipulation in a web worker
Dom change list is one of these
proposals it enables the construction of
Dom operations in a web worker that can
be backed by an array buffer so you can
use that array buffer to transport the
Dom operations the Dom operations
in-between the web worker and your main
thread so what does this look like well
here's the API it looks familiar but new
we construct a Dom change list
we then batch up a bunch of mutated
operations and then we apply those chain
apply those changes from the Dom change
list you can think of this like a
transaction on a database where it can
be accepted or rejected
now this is really interesting in a
webworker because as I said this Dom
changeless can be backed by an array
buffer and array buffers are very
inexpensive to send in between the main
thread and the worker thread and back
and forth so imagine that you had a
library that had to do a lot of Dom
dipping well that Dom dipping could
actually take place in a web worker
freeing up your main thread to be still
responsive while calculating what it
needed to update and then finally post
messaging that new mutation set out and
applying that to the document on the
main thread now sharing messages as I
alluded to earlier between a worker and
the main thread is a little different
than you might be used to you have to
use message passing or post message but
post message has a slight overhead so
for applications that have chatty needs
meaning you have to go back and forth a
lot post message can actually get in the
way but there is a proposal that has
shipped in chrome and several other
browsers that sort of unlock this
limitation shared array buffers and this
is a scary thing to say in a room of
developers it's mutable shared memory
meaning multiple threads and multiple
processes can mess with this memory at
the exact same time and stop all over
each other
it's scary let's just avoid that for now
but let's talk about what this unlocks
well here's what it looks like if we
were to use it we can allocate a shared
array buffer we can post message that
shared array buffer into our web worker
and start acting on it but unlike
regular array buffers the shared array
buffer in this case refers to the same
thing it doesn't pass the whole array
buffer into the worker and then pass it
back out we're creating a direct link in
between our worker and our main thread
what does this let you do well I made a
silly demo where I count up from 0 to
10,000 on the top one I'm using post
message to post every single time that I
mutate my counter so I have one two
three post message post message post
message and the share to refer array
buffer case
don't have to use postmessage because I
have I have the data that's shared in
both places so I'm able to simply read
from that shared array buffer think of
it like my shared array buffer is a
model and my viewing this case just
reads from that model whenever I want to
so I'm able to work around the post
message overhead which roughly translate
to about 10 milliseconds per message now
normally post message is great it works
fine but in applications where you need
to be super fast and you need to make
sure that the data can go back and forth
really quick share very buffers might be
your answer now you may be thinking web
workers seem really great they seem
super powerful but I don't want to have
to write a framework that utilizes web
workers because it seems tricky and
difficult and I would agree with you
share array buffers and web workers are
very hard to grasp concepts and hard to
translate into normal web development
use cases but luckily for us frameworks
have already started taking these
low-level primitives and applying them
at a higher level in their frameworks
pre-act is one example pre-act actually
has a demo where they're able to do most
of the work inside of a web worker so
this is this works today it's pretty
amazing I recommend that you check it
out a library from the Google Chrome
team called commlink has a pretty
advanced idea where it allows you to
export a class via a worker to your main
thread so you can write our class in
this case app which is running on our
worker and then we can expose it via
comlink so on the left side we commlink
proxy the worker and then we're able to
call methods on the app class from our
main thread even though it's running in
a web worker so this is one of those
building block primitives that I think
has a lot of potential and people can
really latch on to and build some
interesting demos with finally angular
angular actually ships with the ability
today to run fully in a web worker you
have to opt into this mode but it
it works and it works great it's
surprising I didn't think it was this
easy and I asked someone on the angular
team they sent me this demo and it just
worked so angular is able to do the
majority of their work in a web worker
which means that your main threads stays
super responsive and able to react so
this is amazing because angular is a
very high-level framework and the fact
that it works like this is kind of
jaw-dropping
all right so where do we go from here
well I would encourage you to take a
look at these api's that we've talked
about today and experiment push the
limits see what breaks see what things
are missing share your demos with us
tweet at us post bugs and just in
general provide feedback so ideally with
your feedback and the things that we're
pushing on we'll be able to push the
overall web performance for our end
users to be a fast experience regardless
of what kind of device you're on and
regardless of what kind of network
condition they take your user finds
themself on thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>