<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Speech Recognition Lightning Talk - Google and AAAI 2011 | Coder Coacher - Coaching Coders</title><meta content="Speech Recognition Lightning Talk - Google and AAAI 2011 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Speech Recognition Lightning Talk - Google and AAAI 2011</b></h2><h5 class="post__date">2011-08-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g6iAOdRsDOM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks boss so my name is Vincent seven
oak it worked on the speech technology
King here ago and I thought I'd try to
share with you a single piece of insight
that we came from working on speech
technology at Google scale and that can
be summarized basically a touch and if
you want to get a shot at super human
performance machine and it may be the
first thing you should try and do is to
get rid of all humans and so you might
be questioned man my premise away you
may be wondering you know I'm talking
about super human speech records and you
know we all know that speech recognition
is not at human performance here the
problem is that is getting dangerously
close and let me just give you an
example imagine so one of our products
is voice search you can just speak to
search engine Google you can just talk
to it so imagine that you talk to your
firm we record that that that forms and
then we played back we played back
either to yourself or we'll play back to
the speech recognition engine
and we asked for the the transcription
there is no question at this point that
you will do a much better job than the
speech recognition engine at recognizing
your long speech the picture changes
when if you actually change this set up
and play the audio to a naive human and
by naive human I mean someone who
doesn't know you who doesn't necessarily
have the same cultural references as you
have who doesn't necessarily be able to
save neighborhoods doesn't have the same
context it actually becomes a toss-up
and if you just play it once to a user
and ask them to transcribe it and they
will do almost no better than the speech
recognition so why is that roughly
without going into details speech
recognition is two components there's an
acoustic model and a language model and
the acoustic model is what recognizes
the sounds and we're not really at human
performance yet in acoustic modeling but
the fidelity is not yet at the yellow we
def a ebony native female speaker we
have but we have this language model and
the language model is what feelings you
know which words you're saying and
before you break you say we train
similar to machine translation and huge
huge corpuses we train on 240 million
words for voice search and that gives us
an edge that a single user might not
have so if you're naive user you're
naive human isn't that from Canada he
might know not know how to spell
schedule and if a person is not from New
York you might know
know how to pronounce connected II New
York sure myself but this edge really
makes the difference so why is that a
problem course humans really get in the
way France just mentioned that the human
evaluation is huge problem in machine
translation it's the same thing in
speech recognition the ground truth the
standard the golden rule the golden
standard for speech recognition is human
performance we have humans transcribing
the speech recognition and that's what
we benchmark us ourselves against and if
the benchmark is very better than the
actual system then we who really have a
problem the other issue is that with the
kind of growth that we've seen in terms
of usage we're getting a lot of data
flowing throughout the system every day
now we get about two years worth of data
and you could even start thinking about
transplanting all of that and we also
have to support 27 languages
internationalization is a big big
emphasis for us and we're trying to
expand in all the languages of the world
so I'm joking here but Fred jellineck is
a very famous person in speech
recognition you used to say that every
time he fired a linguist the performance
would improve I want to fire all the
humans so the key inside forest has been
that speech recognition as i said is two
different components and those two
components trying to sort of compensate
for the
of each other alright so the realistic
model can compensate for deficiency in
language mole and vice versa so the
traditional way of doing it is you have
the truth that's set by a human
transcriber that's the gold standard and
you benchmark your system against the
truth you compare your best system
against the truth and trying to push it
and learn towards that goal if you
remove the truth you're out of luck you
don't have anything that you can compare
against it the trick here for us is that
we can actually cheat and we can
artificially make it harder for some
parts of our system to function we can
actually weaken parts of resistance so
for example if I week in my language
model then I suddenly have a system
that's actually less powerful and I can
compare against our best asset soup so
if you train our system and try to
improve our acoustic model based on that
going to get something better and then
we can basically do the same thing with
the language model using a weekend night
acoustic model and then improve our
language policy the result is that we
end up with a better system hopefully a
better combination of the true that can
be covered up gold standard and we can
enjoy it so the message there is there
are ways to do into a new movement
without having human support and well
unsupervised learning is not new and
that's been done for a very long time I
think it completely end-to-end pipeline
where we can do training evaluation
tuning entirely unsupervised without
involving any human at least in speech
recognition that's very human that's
very exciting that's really the kind of
things that we're
excited about because it really enables
us to scale levels of scaling that we
haven't been able to to reach before and
so while we're not yet at superhuman
performance it's possible that by
removing that ceiling of human
performance maybe that will enable us to
get to that faster and not asymptotes
towards the actual performance that we
sleep and so that was my bit of wisdom
that we've been working on recently and
in a very it's been a very exciting
development for us and we can there's a
little bit more in the paper that I put
it in the curious one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>