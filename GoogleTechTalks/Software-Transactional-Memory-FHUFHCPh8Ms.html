<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Software Transactional Memory | Coder Coacher - Coaching Coders</title><meta content="Software Transactional Memory - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Software Transactional Memory</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FHUFHCPh8Ms" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the latest in our series of
talks about program
languages I want to start out as I do
every week by making a pitch for anybody
who knows anything about programming
languages that they thought they think
that other people might be interested in
to come talk to me and give a talk cop
talk to me and we can set up a talk my
name is Jeremy Manson my email address
is Jeremy Manson at google com it's
really easy to find this week by popular
demand from people off site we are going
to be able to submit questions if you
are off site so for all of those of you
who are off site if you go to the
website qdb / questions / 878 you can
submit your questions today we have with
us a speaker Adam Langley who is another
Googler who was interested in giving a
talk he's going to talk about software
transactional memory which is a very
important topic now there are a lot of
important right so the implementation
for when you aren't using green threads
and you really do have real threats
coming around and stomping you and
initiatives from companies like Sun and
Microsoft and IBM and Intel about
getting transactional memory off the
ground it's part of a broader effort I
think in the whole programming languages
community to get a better story for
efficient and effective concurrent
programming and in the coming month or
so we're going to have a lot of talks on
concurrent programming including one by
myself so without further ado I'd like
to present Adam Langley and thank him
for giving the top right thank you I'm
not sure how well that video cameras
going to work because I have a tendency
to paste around when I give talks so
software in transactional memory I
understand this is going to be the first
of a few talks on this topic I can't
profess to be an expert in it but I do
use it in real code in google and it
works so let me start off by presenting
a dichotomy of concurrent programming on
the one hand we have shared state
programming where different actors
threads in the shared state world live
in the same address space they use the
same memory and they communicate by
mutating that memory now clearly they
need some mechanism to stop
Angela's toes and traditionally that
mechanism has been looks so shared
memory locks accounts for the vast
majority of concurrent programming at
the moment software does actual memory
is another method for making shared
state programming work now the other
side of the dichotomy is message passing
concurrency which at the moment has been
championed by languages like Erlang for
those who don't know Erlang is a
language developed by ericsson for
programming telecommunication switches
and their big headline the fact that
everybody comes up about with Erlang is
that these telecommunication switches
achieve something like 31 milliseconds
of downtime per year on average so
clearly message parts of concurrency has
something to go for it and recently on a
few programming language web blogs and
such and such people have been saying
that software transactional memory we
shouldn't we shouldn't approach it we
shouldn't use it because what we should
really be doing is shifting to message
passing concurrency and this is just
giving legs to know a dead idea she has
say concurrency is bad we should abandon
this because it's helping us a lot I
actually think this works really really
well so maybe in the long term message
passing concurrency is the correct thing
to do but for the moment this is pretty
awesome so let's have a look what so
everybody might want to take a moment to
remember a time when every single one of
these problems has bitten them so this
is the problems with locking you can
take to a few locks you can take to your
money locked you can take the wrong lock
you can take the locks but in the wrong
order you can leave the world in the
incorrect state when something odd
happens or you can lose wake up's and
your threads can hang around forever
waiting for an event which will never
come so if you haven't hit every one of
these at some point in your career you
either haven't done a lot of
multi-threaded programming all your Mike
burrows personally I am not competent to
do multi-threaded programming because I
have hit every one of these I don't hit
them terribly often but when they do
come up they take me sometimes days to
fix so I mean locking is clearly an
issue locks can even bite you when you
don't even have any locks in your
programs because somebody else is making
a call back
a different thread so what's the
alternative well the alternative I'm
presenting is transactional memory
transactional memory involves recording
the actions you're going to do and
committing them I mean it's a concept
that has been around in the database
world for years it's nothing new so how
do we do that in programs so obviously
if there's only one thread in the world
it's not a problem you can record your
actions you can perform at the end
nothing could have interrupted you
nothing can have gone wrong it's the
trivial case but what if somebody else
comes along and mutate something that
you're working on so let's say you read
a couple of values and you write a value
so another thread comes along and
updates one of the values after you've
read it but before you've committed the
transaction what can you do well the
only thing you can do is to abandon the
transaction and we try it which is a
little uncomfortable if you're a
programmer writes it means that the
block of code which consists of your
transactions can be executed an
arbitrary number of times just magically
you have no idea maybe it goes once
maybe goes a hundred times so obviously
you need to think about that io inside a
transaction is clearly problematic so if
if you printed something inside your
transaction and it retries you'll get
printed every single we tried a couple
of groups who I think will be presenting
have some solutions for this in which
they buffer the output or roll back the
input that you've read in transaction
but the transactional memory I'm going
to be talking about today is based on
the one in Haskell specifically ghds
implementation so Haskell is a pure
functional programming language and one
of the things about that is in a pure
functional programming language your i/o
is done using monads now I'm not going
to explain monads nor am I going to use
the Haskell syntax you in this talk
right because I know that that will take
some time I mean not that that wouldn't
be a wonderful talk it would be and it
should probably happen at some point but
it's not this one so I've made up of
syntax which is vaguely see like so
people know what's going on and monads
for this talk you can consider as a
taejun in the type system so normally
your getchar function will return a char
obviously but imagine for the moment
that any non deterministic or side
effects full function in fact returns
its value wrapped up in an i/o so an i/o
is a magic thing which says this
function depends on something other than
its arguments and if you call a function
which returns an i.o.u return an i/o and
so forth and so any non deterministic or
side effect full function contagious up
the call stack and the type system marks
everything is IO now this means that we
know what functions are going to do i oh
so we can exclude them from the middle
of our transactions this is why
transactional memory works so well in
haskell let's move on what am I saying
next okay so along with I oh I'm also
going to reduce another type system
contagion called STM so STM is the Monad
for things which do transactional memory
operations so you can compose STM
operations with other rescue operations
and you can compose them all the way up
you cannot have any i/o in an STM
operation and when you've finished
composing your transaction you've turn
it into an i/o operation and execute it
because if you're doing something which
can affect other threads that is IO it
may not be reading or writing to a
socket but it makes the function
nondeterministic in another thread can
come along and affects it so this is a
very simple example this is decrementing
a counter so if it's obvious right you
read the counter you write the counter
now that isn't the transaction that's
that's just a function that you can
compose together into other transactions
next one so sequential composition now
we can do atomic decrements with wait
three algorithms there's an atomic
decrement call in the Google 3 ko's
there's a lot of weight three algorithms
in the Java standard libraries do I need
to explain wait free lock free no okay
big
so wait free means that wavery means
that the system always makes progress it
can never deadlock and every single
actor in the system proceeds in a
bounded number of steps lock free is the
same thing except that actors can be
starved this software transactional
memory is only lock free I'll come back
to that when i talk about
implementations so there are there are
lock free hash tables in java and you
can use them and they work great but you
can't compose them you can't atomically
take an object out of a hash table and
put it into another just as in google 3
you can't atomically decrement two
numbers using just the atomic decrement
function but here we are we are
composing to documents and we are
wrapping it in a call to atomically so
atomically will take that transaction
and run it and it will happen atomically
and everything will just work doesn't
that depend on actually I'm that there
are no other threads that are accessing
higher or
which you're not using the aisle st an
affirmative sorry so if another thread
was accessing at the same time yeah so
what would happen would be that we would
have bought this transaction and we try
it so when it came to the end of the
transaction we would check everything
we've read we would make sure that we
saw a consistent state of the universe
and if we had then we atomically commit
this process or thread accessing
character words using google three and
not STM then you're screwed right yes
okay that's all I questions repeat
questions the everybody told me that's
what I came up I still forget these
barriers work as long as everybody in
the world uses the same primitive yes
absolutely so in high school this works
because anything which uses an STM
primitive gets wrapped up in that STM
monads and it's contagious up the type
system so you know but yes you're
absolutely correct this doesn't work if
other threads in your system are doing
wild crazy things so STM is you either
partition your concurrency internists
you have a non STM part or it's
everything but even so this is this is
clearly quite a bit better than locks
because in locking you would need to
find everywhere its uses counter
everywhere its uses counter to and
everywhere which might need to impose
some notice I'm ordering on accessing
between them and of course you need to
take there's lots in the right order so
that's quite neat but we can do better
so this is how STM handles events so in
locks you'd use condition variables or
if you're on google three you can use
the weight and lock when but in this
this will block if V equals zero and the
way it does this is when it hits retry
it will look at the list of every
variable gets read and wait on those
variables so all the STM variables have
wait queues hanging off them and when a
transaction completes it will wake up
all of the threads which are waiting on
the variables which we've just been
written so another transaction comes
through and it set that it sets v 2 1
if this has called retry this will get
woken up it will abort a transaction it
will retry and it will run through and
now it be able to complete because we
will be equal to 1 and this means that
you can't lose wake-up calls you can do
retries arbitrarily deep and this is a
fairly specific part of the GHC
implementation of software national
memory not all software just actual
memory support this but once again it's
just a very neat trick and we get better
so right I'm plea not explaining myself
correctly so so imagine that we were
writing lock based code and we wanted to
wait until this was non zero and then
decrement it so we would have clearly a
lock around counter we would have a
condition variable and everybody who use
counter would have to lock it and if
they've implemented it has a fire
condition variable and so on and so
forth and you'd have to wait in the wild
loop checking the condition very is non
non zero and then decrementing it when
it was correct so what this gets you is
that you don't have to bother any of
this stuff you can throw away your
conditional variables you don't have to
worry that maybe somebody isn't using
the condition variable elsewhere in the
code and so your your wake-up call will
never happen what it is
right so as I went through before we try
looks at all of the variables you've
read and it hangs the current thread on
a wait queue of all of them so at this
point we will have read counter and if
it's zero we hit retry and retry will
suspend the current thread until counter
in this case has been updated now it may
not have been updated such that it's
nonzero it may have got to minus one but
anyway this will be woken up when retry
happens so you can consider retry as
just a bought in the current transaction
in trying again and the fact that it's
waiting is just an optimization it could
busy wait right and the semantics would
be the same but as an optimization we
look at the things we've read there for
those are the those are the only things
we should affect us because we're
deterministic there's no I oh and when
they've changed it's worth considering
whether we can complete again here's
another way of bridging the same
question which which I forgot to repeat
when did no such as stars let's say you
give a tree tonight this is deeply
inside several functions yeah how
doesn't know where to rethread from so
it retries from the top of the
transaction your cookie right so that's
because if we made this a transaction we
wouldn't be able to compose it with any
other functions so the transaction a
transaction is made with the atomically
call so you can see their debt counter
are in STM bone add maybe I should have
explained moments but you make a
transaction by calling atomically on it
and so a retry no matter how deep it is
will run all the way back up to the
start of the atomically block
those are nested to it like if you had
an atomically thing which called another
one which an anatomically in it either
one Hector will retry it sounds like it
might be some sort of scoping it would
retry to the top of the transaction
that's on the top of the nested stack so
in this particular case you can't nest
atomic please so if you if you have an
atomically you'll notice debt counters
returns an IO type whereas you can't
have an IO inside a transaction so if
you had an atomically inside one of this
debt counter then you won't be a zanessa
because the type system wouldn't let you
but in other STM certain you can either
SVM's don't enforce that and you're
right they have their own semantics for
nesting let's say I want to use this
kind of hash table which thus bill
locking on its own and I would be make a
transaction which involves reading and
reading the hashtag was repeated baffled
so if the hash table hit it sports a
function which has a transaction decided
yes you cannot compose them in Haskell
so what it needs to export is rather
than something trapped with atomically
it needs to just export it without the
atomic fee around it and then you can
compose it together and you can put your
own atomically around it when you're
done repeat the questions please so I
didn't repeat that one because I thought
my answer explained everything right yes
there is actually a lot a lot of
research on how to nest
come across incorrect that's exactly
right
so yes Jeremy was just saying there's a
lot of research into how to do this in
this particular case in high school you
can't do it you have to compose
everything before you caught atomically
so right once again this isn't a
transaction you'll notice this returns
in STM type so this can be this can be
composed now what this is doing this is
a kind of nested transaction so I've
made up some syntax here it's called or
else what this will do is this will try
the first debt counter all wait and if
it calls retry it will try the second
one if that calls retry then it will
wait on the union of all the variables
which they have read so this allows us
to compose blocking actions now consider
for a moment what this would look like
if we were using locks so if we were
using locks we'd have a function which
can block and we'd have another function
which can block so how would we do this
we would have to spawn off I think
unless someone has a better design we'd
have to spawn off a thread to wait on
each of these which we then share a
condition variable with and then each of
these threads can tell us when one of
the other has completed except they
could both complete at the same time so
the two threads would need to share a
lock to make sure that only one of them
signaled the condition variable I mean
it is certainly doable but in C++ it's
going to be 100 lines of code perhaps so
they are this is this is composing
blocking actions and basically I'm just
going through like the sparkly shiny
jewels of softener electrical memory and
this is one of them any questions on
what that means
so the or else happens if the first part
calls retry so retry would normally
block a transaction for something to be
ready but if it if it blocks then it
will try the second one if that blocks
as well then the whole thing blocks and
it waits on the union of all the
variables that have been read so if
either these counters are then updated
the whole transaction starts again and
it will try the first one and then the
second one if they both block it or wait
again and so forth and I just like to
point out that I've just made up this
syntax clearly if you wanted to test
three or four counters you would start
indenting across the page the actual
Haskell syntax for that would be
something along the lines of that so I'm
just saying ignore my syntax just think
of the semantics sure if two threads
we're executing that same atomically
example very
to count because the way it's written
the order in which either one of these
threads might acquire one of the
counters is random because of the or
else so doesn't that mean to a potential
deadlock between the two threads because
seems like one of them to get counter
one the other one can get counter to now
you're dead right so the question was
isn't there a possibility of deadlock if
the if two transactions are going
through the previous function and they
acquire the counters in a different
order so the answer is no because
semantically the software's actual
memory says the deadlock can't happen
and the reason it does that is because
when the transaction comes to committing
it acquires the locks in some global
total order which is usually defined to
be the address of the locks so when the
transaction came to commit it would look
at all the things that's read and you'll
go I need to lock this this and this and
it would lock them in the order of
memory and if another thread is coming
along at the same time then you need
codes a handle that I'll go into that at
the end so yes as I said before this
software national memory is defined to
be lock free which means the system as a
whole always makes progress even though
one particular actor may be starved how
am i doing for time I'm good okay so as
I said I'm just going through sparkly
jewels of things you can do with
transactional memory and this is another
one this I think is is unique to the ghd
implementation but what it allows you to
do is it allows you to enforce
invariance on your transactional
variables so here we make a
transactional variable and we initialize
it with zero and we have a check block
which is a transaction and this check
block is evaluated every time any of the
transactional variables it reads is
changed so in this case this function
makes transactional verbal and returns
it it also puts into the global world
this check function which every time any
transaction modifies this transactional
variable will make sure it's less than
some limits and so this will allow you
to catch as soon as your transaction
completes anybuggy transaction which is
breaking your invariants
once again I mean it's not fundamental
it's just very nice so the question was
what happens if the environment is
broken I mean that's up to the
implantation clearly but it's all I
believed you actually will throw an
exception at the point of the
transaction which broke it yes it's a
debugging aid and so it will it will
shout and scream in some way that this
transaction is buggy you've broken you
invariants these environments can also
be defined based on the difference of
the old value and the new value so here
we can check that the transactional
variable we're returning is always
monotonically increasing in fact
strictly monotonically increasing yes
it's greater than once again as I said
just a nice trick right drafts as ever
so these graphs are from the Haskell
implementation and what was it yeah it
was the array blocking q example which
I'll come to but the actual values in
these graphs aren't important all I want
you to take away from this is soft when
transactional memory doesn't suck hugely
so on a uniprocessor it's kind of
roughly the same ish sure when we give
it four processes it happens in this
example that so this is increasing time
increasing time it's bad this here is
locking and this is transactional memory
so this graph shows that transactional
memory is actually beating locks in this
particular example but I don't want you
to think that transactional memory is
faster than locks because you can
equally come up with another example
where the graph is inverted the only
thing I want you to take away from this
is transactional memory doesn't suck
hugely in that it's perfectly reasonable
to want to use it and you shouldn't
expect your performance to go through
the floor
okay in fact I'm going to go back that
slider I don't was gone to that example
yes so I'm just going to discuss ghd's
implementation a little of transactional
memory so in GHC 6.4 they there 66 now
which is fully multi-threaded but in 6.4
they were in fact only green threaded
which means the kernel thought the
process was only one thread and the
thread did the scheduling inside of
itself so this may transactional memory
kind of easy right because whenever
you're in the sea runtime there is only
one thread executing so the way GHC
works and i'll come to another
implementation later on is whenever a
thread starts an atomic block it makes
up a transaction descriptor which
contains a list of all the variables
which have been read and all the
variables which should be written and as
the transaction progresses obviously
things are added to these descriptors if
you hit an or else block then it nests
the transaction because if an or else
switches to us alternative path then you
want all the things which the first path
is done to be reversed and there are a
couple of little niggles in its
implementation one thing is that any
given transaction may see an
inconsistent view of memory and so this
can cause it's either the throw an
exception or it can cause it's a non
terminate so you mean you can imagine a
for loop which starts off perfectly
validly and then its condition is
decremented before its initial value at
some point you in the transaction it
will never terminate so one thing ghd
does is every time it's schedules or
thread which is in a transaction it
verifies the transaction is still valid
valid means that all of the values it's
red still have the same value as when it
read them and so if a thread is non
terminating because it's seen an
inconsistent view of memory it will
abort and try again likewise if a thread
throws an exception then GHC also checks
whether the transaction is still valid
because the exception may have been
thrown because it's all random contents
of memory if that's the case the
exception is squashed and it starts a
transaction again
my notes what else they have to say
about this I think that's it other
things that just point out is that the
system must proceed globally because the
only way a transaction can be aborted is
if another transaction has completed and
stomped its variables therefore
something is proceeding right because
something is finishing transactions
however a big transaction which runs for
a long time may be constantly stomped by
lots of little transactions coming
through and breaking one of its
variables and the big transaction may
retry it in a loop so we can starve big
transactions but the system as a whole
must proceed because the only way to
cause a retry it is for a transaction to
have completed so now I'm just going to
quickly go through a less nadie example
this is an array blocking q it's used in
Java Java programmers should know what
it is it's basically a circular buffer
of constant length and it blocks when
you want to add in its full and it
blocks when you want to take an element
and it's empty so first off we're going
to define a fairly generic function
which will be used to implement a couple
of Tanks it will be used to implement
taking it we use to implement peak so
this function first off if you look at
the way top left it's an STM is so it's
not a transaction in itself it can be
composed with other transactions you
want a you want to not make things
transactions as much as possible because
otherwise no you can't compose it with a
high level but it returns an STM maybe
int which is either went into it's a
failure value so what we're going to do
we read the number of used values in
this array if it's zero then were empty
and we have a couple of flags which tell
us how we're acting we have a flexible
move and a flag will block
if we're empty and we're blocking them
we retry which will suspend this thread
the only variable we've read so far has
been used so this thread will be woken
up whenever the used variable is changed
in any way and if it's changed in its 0
then we certainly hope it goes to 1 and
so then we'll be woken up and we get to
reach for I again if we're not blocking
then we return a special value which
says there is nothing in here if it
isn't empty then we read the head we
take the value from this array which
which the head tells us to take if we
were moving it then we update the
structure with a couple of rights no
obviously you increment the hedge you
say there's one less used and we return
it so if we imagine we just wrap this in
an atomically block imagine this is the
transaction if we get to here and
another thread has come through and it's
stomped either are used or its stomped
if we're updating the head and used then
we will abort we will throw away
everything we've done and we will do it
again which as I started at the
beginning is fine because there's no I 0
in this so this function can magically
be executed ten a hundred times
eventually we hope that we will be able
to make a complete run and no other
threads would have stomped any of our
values and we finish I haven't got the
version with locks in here but suffice
it to say it's quite a bit longer and
not nearly as clearly correct and so
from that more generic function we very
quickly define take and peak take a
simple e the case where we remove the
element and we block peak is simply the
case where we don't remove the owners
and we don't block
what's next okay this is a more
interesting example this is taking from
the queue with a timeout so first note
this is I oh we have a timeout we're
dependent on the real world this can't
be composed with other STM actions and
that's why you see the atomically call
in there so we start off by making a
timer which is of a type which I've just
made up called teach an but you can
imagine teach an is a transactional
channel you know how channels work they
block if you try to take it and it's
empty in it so forth it's very much like
the array blocking Q so we start this
timer and then we have an or else so
initially we try to read from the
transactional channel that will block
until that time that has happened so we
will go through reader transactional
channel that calls retry to block and so
then we switch to the or else which says
that we try to read from this array
blocking q true true means blocking Emma
move and if it's empty that will block
as well so both paths of are also block
to the whole thing blocks and it blocks
on the union of the variables they've
read that union is the array blocking q
and this transactional channel connected
to the timeout so when either those
triggers this transaction starts again
and depending on which one has triggered
one of these paths will work and so
that's timeouts in I don't know what is
it about 10 lines of code maybe less and
it's timeouts which are clearly correct
and which you can't get your locks in
the rewarding you can't lose stuff so
now I'm going to go on to another
implementation this is an implementation
from the lock free group at Cambridge at
the original Cambridge not this American
upstart and so has anybody got any
questions on transactions at in the
high-level view which I've gone through
before I dive into this
maybe escondida vomit since you can't
let things as you protection
right and same time you have a lot of
big number of sweats appears to me that
chant that I need to interact interferes
pretty high okay so some kind of how
well does this feel this big protection
of it so the the question was because
transactions don't nest your
transactions are going to end up being
fairly large and doesn't that mean that
they'll retry many times and thus
progress will be slow so transactions so
transactions do kind of nests right or
else is a nesting of transactions in
some sense in that if one branch of an
or else blocks then it's undone and the
system the transaction carries on on the
other branch as if it never happened so
they do nests in some sense in Haskell
also in other sm implementations they
may nest as much as you like but the
question of dozens it some don't large
transaction to stomp each other and
cause the whole system to proceed slowly
possibly as I said I showed you that
graph where sgm beat locks you can come
up with other examples where lots be
STM's in practice what I've seen is that
it works very well Jeremy
right so Jeremy saying you never have to
have a transaction longer than you would
otherwise lock which is true but
yeah and if your transactions do end up
very large you should probably question
your design maybe a bit same way if your
locks end up spending a long time okay
any more questions before I dive into
the crazy implementing this is a linked
list and so you can see the cons cells
in this linked list rather than point to
each other in fact point to these hidden
structures under the water these hidden
structures under the water are managed
by the transactional memory and this is
a completely different transactional
memory design and I've been speaking up
before and so let's just look at some
code for how you would manipulate this
right isn't this fun so you can see sgm
object is the type of an object which is
protected by the transactional memory
and so the do here is the transactional
memory loop and its explicit is so your
code doesn't magically restart the
restart happens here and so in this
particular implementation you have to do
it all yourself I'm not going to go
through this in great detail but you can
see that I got the laser pointer you can
see that the code pulls it pulls from
the transactional values it pulls the
real values out by calling open for
reading and there's a similar open for
writing down here so this is how you add
transactional variables to your list of
red objects and your list of written
objects and this happens to be a list
insert and this is fairly standard
you're walking along the lists to find
the position where you should insert it
to keep it ordered and then this done
here commit transaction if it turns
false then the transaction is a boss you
need to restart
so this is this is when the transaction
is committing so what we do we have a
read list and we keep an idea of what
we've read in this read list and we have
a right list and so when we open an
object for writing we make a shallow
copy of it when we actually write to the
object we write to this shallow copy and
other transactions can go through and
they see the old values when we come to
finally commit we walk through and we
this pointer here this is an STM object
normally this point here points to the
real object but when we come through to
transact we use an operation called
compare-and-swap compare-and-swap is
implemented in the processor it takes
three arguments it takes a memory
address and old value and a new value
and it's atomically they're using bus
locking says if what's in the memory
address is the old value replace it with
the new value and tell me what ended up
in the memory address so this point here
we can atomically update when we commit
to point to our transaction and this is
called the acquire phase we go through
and we update all the things we've
opened for writing to point to our
transaction now if another transaction
comes through and it wants to do the
same thing it finds this thing at the
end of the acquire phase rather than
finding that it finds our transaction
and it can look up in our transaction
the actual value of why it should be
using so another transaction comes
through finds that points there and it
finds our value of wine starts using
that sure
does it restrict itself to a single
compare-and-swap or can they can you
happens and pins action something that
will require some a series of
compare-and-swap so the question is can
you only have can you have one object
open for writing no you can have many
objects open for writing and when the
transaction starts to commit it will go
through in a global total order which
again is generally the order of the
memory addresses and it will try to
acquire all of them if it finds that if
the compare-and-swap tells me that the
value there wasn't what I expected then
the transaction is aborted so we go
through in this case we only have one
right object but we go through all of
our right objects and we point them at
our transaction this means we now owe
them we then go through all of our read
objects and we use compare-and-swap to
make sure that the value in them is what
we read when we first read them if not
then another transaction has completed
and we need to abort once we've done
once we've checked all of once we've
owned all of our rights and we've
checked all of our reads we're ready to
go and we go through and we compare and
swap and get rid of our transaction
objects and point this to our what was
our shallow copy but is now the original
version and what we haven't done in this
case is we've removed an element from
the end of the list if another thread
comes through and it notices that it has
been tripped up by our transaction
committing them rather than the boss
itself immediately what it will actually
do is the other threads will call our
commit function so you can have multiple
threads all committing the same
transaction at the same time but because
they are using compare-and-swap and
because they're working in a global
total order what it will actually do is
it will help one of them will always get
there first and that's what makes us
that's what make sure that we always
have progress in the system as a whole
so another's where it gets tripped up it
will help the first thread completed
transaction and then it will abort
itself now every time I look through the
pseudo cope with this I have to convince
myself that it actually
correct and I did it again this morning
and by this afternoon I won't remember
so any questions on this are entirely
welcome and completely reasonable to
point it looks to me as if this system
which I rather like quickly transformed
into a proven system if you replaced
every open for right by a lie and then
when they call back to the transaction
commits happen you release the locks in
case you didn't have all the speaking
thing is I can't do one at a time so the
question was isn't can't this system be
transformed into another where every
open for right is converted into taking
a lock for that variable well let's
think trivially you can convert any
software does actual memory system into
a big lock and that's obviously correct
it's inefficient but it's correct but
your transactions can still get stomped
if somebody else has written one of the
variables you've read or do you want to
lock the read variables as well as the
right robles yes I so I can't answer
right now whether it works it possibly
would it's possibly another reason
implementation I'm not sure second
thoughts
yes the order could be different us a
very good point well yeah I understand
but what remember what I said is that
it's a it's a locking system where you
have a call back if somebody else it's
got some of our lives that you would
like then you release your locks so
that's how you make progress and that's
that's actually equivalent from what I
think I understand you're playing so
you're saying just for the people
watching that it's a callback system
where lots can be released if they're
contended on and taken in the world
order it sounds like you might have a
reasonable implementation because what
you're really doing you say I pretend to
take a look I pretend to take a lock
down on my luck so now I'll commit you
could say I take a lock I take a lot of
Hoops I can't get this one so I'll
release all my other ones that's
actually having done the nao or anything
object right so it sounds like you want
to impress often is actually member no i
don't i'm using my second comment is
that i've observed in systems like this
systems like this can be unfair unless
all of the players have people owe a
legacy to the compare-and-swap or
whatever you're using for the underlying
mechanism if the system is bigger than
for right you will usually have hot
spots and cold spots and processes can
get frozen out and not made progress
because the other guys are getting
faster access to the underlying
mechanism whether it's a longer not so
the second boss the question was this
system can be unfair if there's like
latencies between different transactions
yes absolutely can starvation can occur
this is only lock-free the system as a
whole makes progress but large
transactions can be consistently kicked
out by smaller ones yes one the batter
the rights you would have to introduce
yourself you would have breakfast you
will max right word place the values of
the old on his prior tier changes yes
actually that's the magic that's inside
to commit his commit transaction
function your retro can commit
transaction function that has to have
everything like that you just said
opening should this is the hard part by
blocking blocking is easier except for
separate deadlock which is the other
part this simply going to handle the
hard part is doing all of the
compensating essentially compensating
work and to back out difference like
this the big win in the system is doing
all the beasts that's a database gives
your terms and roll back
right why not I let you to comment on
that Padma what does the memory model
for this to look like forever working a
locative doesn't require barrier unlock
as a release barrier where are the
barriers here so the question is what is
the memory model look like the memory
model of course is defined by the
implementation I couldn't give you exact
details on this but in general the
memory model is it works right it will
be handled by the transaction system you
don't need to worry about it software
transactional memory cell per
transaction memories of how far along
enough to be able to decide something
really really solid with respect to
women model in general it's got the same
to give a transaction that's that make a
transaction sex again property but
real details they haven't quite worked
out what the semantics should be enough
to actually work out what the actual
Joey was just saying that they don't
really have one or not far enough along
in the research any more questions so
you always should call it roll your own
and Zach channel data structures rather
than the transactional memory because
this is all about data structures and
how to lock up yep they're also there
are people in flaming felon Sun or
actually working on hardware combination
that's been tried before the rope so if
you're watching the place to go online
is qdb / questions / 878 someone right
at the back there right can I say
something about one commentators are
available so the the third of these is
locked for grouper Cambridge they have
an implementation which I just discuss
at the end in see the Haskell one is
beautiful and documented at well the
second one mostly and there are
certainly lots and lots of
implementations and some of these people
might be coming here to talk about them
there is certainly a Java one which I've
seen IBM have a group right Jamie 14 c
sharp sxm is that yes so I I think it'd
be a google search tim harris is yeah
that's he's cambridge right yeah so
these are just the ones these are just
the ones i've been talking about there
are lots
okay right to the no more questions
thank you all for listening
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>