<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Nurturing Tagging Communities | Coder Coacher - Coaching Coders</title><meta content="Nurturing Tagging Communities - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Nurturing Tagging Communities</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/49Lu0a3QAc8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Shalon sin and I'm a PhD
candidate at the University of Minnesota
I'm doing research with the group lens
research group and my advisor is John
readdle so I'm going to be talking today
about some research that I conducted for
my PhD dissertation that I'm working on
and I did this research with a bunch of
collaborative collaborators and one
actually happens to be in the room now
so I'd like to recognize him dan
frankowski he's with google groups and
he also used to work with me at group
lines research and I also happen to be
an intern with Google Checkout for the
summer so I titled this talk nurturing
tagging communities and one of the big
questions i had when i started doing
this line of research was can we as
system designers of tagging communities
actually influence the tags people
create in positive ways can we encourage
them in a way that really is meaningful
to create tags that are better for the
community and I think my title probably
will tip my hat as to what is what I
believe now but well that'll be a
central topic of this talk so if you're
here you probably know what taking
systems are all about just but just for
the sake of being thorough here's an
example this is a photo from Flickr it's
a photo of a brick wall with some
graffiti on it and it was taken by fire
monkey fish and fire monkey fish the
skits decided to describe this entity
this this photo with some free form
words and phrases that we call tags and
he used tags like Los Angeles guess
where la tagging which is how i found
this particular photo i did a search on
flickr for tagging and at the time i
created this talk this was one of the
highest the highest return search
results i don't think it is right now
but so this is an example of an entity
being tagged and taking has become very
popular in the last five or so years and
it's good to talk about why it's popular
why do why do people care about it
well there's a bunch of reasons and
here's an example that should illustrate
some of them this is a very cool website
called library thing com librarything
com allows users to catalog their
personal collections of books so Library
Thing com has a database users can go
and say I have these particular books
and then there'll be lots of information
that's automatically stored about those
books when they cross cross reference to
library things database so librarything
also allows users to tag the books in
their library and if I'm looking for a
book for example a book on cooking I can
go to library thing calm and do a tag
search for cooking and here you can see
what the search results page looks like
for a tag search for cooking there's a
quintessential tag cloud on the right
that shows the popularity of various
related tags and you can see I could
drill down into some more refined
searches besides just cooking and then
most importantly there's a list of the
books that were tagged most often with
the word cooking and you can see the
number one result joy of cooking
rightfully so was tagged by 407 p70
people with the with the word cooking so
this gives us a lot of examples of why
tagging has become powerful to tool
first of all take scale very well this
website which you may not even have even
heard of has 17 million books that are
tagged with over 20 million tags and
that has been done in just the two years
since library thing has been around and
you can compare that with the Library of
Congress who has been around for 200
years and has tagged sorry classified 20
million books and the time they've been
around so the other thing we can see in
this example is that taking system draw
relevance based on the wisdom of crowds
so while web web pages for example use
something like PageRank to draw on
webpage row relevant something that's
very opaque for the end users tagging
systems use words that users apply to
entities so you get both relevance
and popularity out of this single with
single annotation and it's also very
transparent to the user right when I see
470 I know 470 people have tagged that
particular book so that's another
advantage of taking systems and thirdly
tagging systems help encourage social
awareness and this is a facet of tagging
systems that's often looked overlooked
by industry and the idea here is I want
to know that the pictures I'm looking at
the books i'm reading the web pages i'm
pages i'm searching for our popular i
want to know that other people are
looking at these same web pages i want
to feel like I'm part of a group and
tags help create the social awareness
that makes this possible so before I
jump oh yes so this skeptics of tags
often cite reasons for not liking them
and their reasons such as tags can be
non informational that we can can be
nonsensical or they can even be
malicious they could be spam tags so
here's an example of amazon.com stags
for this particular album by Paris
Hilton and you can see although we get a
sense for the fact that this album is
bad we don't get a lot of extra value
right from these pegs so we could
probably get all this information maybe
not the entertainment value but we can
get all this information from that star
rating up there so here's an example of
why people don't like takes and before I
jump into the rest of my talk I want to
take a second to talk about the design
dimensions we might think about when we
when talking about or designing tagging
systems the first one that probably is
most popular is whether tags themselves
are kept public or private so here's a
website Flickr which you've seen an
example of already and here's a tag
search for the tag tiger and this is
actually kind of a cool result page
flickr groups together senses different
senses of the same word tiger so you can
see results that have to do with tiger
the animal results that have to do with
tiger the operating system results that
have to do with tiger the flower so it's
kind of a cool example on the other end
of the spectrum gmail has entirely
private tags because
your emails are private so that's the
other side another very important
dimension of tagging systems are whether
the items that are tagged are shared by
users in the system or whether they're
they belong to particular users on the
shared side a website like last.fm is a
website that presents information about
music it's kind of a social networking
site built around music so here's a
particular track it happened to be the
most popular track when I looked at last
FFM a few days ago and it's a track
called farewell by the band Anastasia
and you can see it's been tagged with a
lot of words like metal and progressive
metal and this track doesn't belong in
to anyone in the in the community right
it's shared by all the members of the
community and you can contrast that with
YouTube where a particular user uploads
a video and kind of owns that video so
another dimension that goes closely
along with these two are whether the
individual tags that people create are
maintained separately for every person
such as in the last FM site if I tag
this particular track metal you can also
take it metal and our tags are stored
separately they might be aggregated
together there might be built public but
the system itself stores them separately
so they can maintain statistics about
them on the other hand a video on
YouTube really only has one set of tags
so why am i interested in studying
tagging there's a couple reasons first
of all it's very popular it's kind of a
ubiquitous web two point O feature but I
think more importantly tags are a form
of community contribution in fact
they're probably the simplest form of
community contribution you can think of
when you think of community contribution
sites their site such as Wikipedia
Flickr YouTube these are some of the
most popular sites on the internet these
days and tags kept capture a couple very
important aspects of these community
contributions first of all they're
tremendously expressive second they're
very simple so they're a very
interesting vehicle for study
studying this community contributions
and with that in mind there's a
particular type of tagging systems that
I'm interested in focusing on I'm
interested in focusing on tagging
systems that have public tags because we
want to see the interaction between
users and I'm interested in focusing on
systems that maintain individual sets of
tags right and the reason that I'm
interested in those type of systems is
we can get some idea for approval in
these tags we can get from the aggregate
statistics about multiple users tagging
items we can get information about
agreements in the community all right so
now I'm ready to jump into my talk and
here I'm going to just give you a brief
overview for how it's going to be
structured so individual tigers in a
system in a tagging system tagged items
and those tags all come together to form
a tagging vocabulary for the entire
system in the first half of the talk
we're going to look at how these
vocabularies emerge what are the things
that make people tag the way that they
do and then if we understand what those
things are can we assist them designers
influence the tags taking vocabulary in
ways that are meaningful and finally if
we know that we can influence the
vocabulary in ways that are meaningful
can we make the vocabulary vocabulary
better do we understand what types of
vocabularies have more or less value for
the community so those are the three
questions in the first part of the talk
and in the second part of the talk will
look at one particular input the tags
that users see that actually turns out
to be an important factor in the tags
they themself create and if you believe
that that is true then it's an
assistance best interest to display good
tags right they want to display tags
that are good to encourage the user in
turn to use tags that are good so in the
second half of the talk will look at tag
selection methods that can differentiate
between good and bad tags
so the first part of this talk is based
on a paper i presented at cscw 2006 you
can find it online if you're interested
in more of the details I'm going to
start by talking about three example
vocabularies from three different
tagging systems this is the website
delicious it allows users to tag web
pages and here you can see a particular
user's vocabulary sub stuff sub stuff
has used generally informational tags
that are kind of keyword type tags I
think most of us would consider these
tags to be good tags and I'm going to
tal call this type of vocabulary a
factual vocabulary alright the second
type of vocabulary will look at is from
Amazon here's a user john d collins from
amazon here's the tags john has created
and you can see John likes to describe
how much he likes the books that he's
read and so this is an entirely
different type of vocabulary I'm going
to call it a subjective to vocabulary
it's based on John's opinions and you
might want to think about how valuable
this is for the community as opposed to
factual vocabulary and how value
valuable it might be to the user that
who created the tags and the last type
of vocabulary is an example from a
website that my research group maintains
called movie lens and here you can see
this user has tagged movies with dates
and it turns out those dates are the
dates that user saw the movie so these
tags are intended just for the user who
created them they aren't really intended
for the community as a whole so I'm
going to call this type of vocabulary a
personal vocabulary and again think
about how valuable this is to the
community and how valuable it is to the
user who created those tags okay so I
said we're going to talk about three
questions first how do taking
vocabularies evolve what makes people
tag the way they do second can we assist
them designers control vocabulary
evolution and third other specific types
of vocabularies that are more or less
valuable to the community so in order to
study vocabulary evolution we introduced
tagging to a website that we maintain
called movie lines
movie lens is a movie recommendation
website here you can see this users
number one recommendation is 2001 a
Space Odyssey so users on movie lines
rate movies and they receive movie
recommendations there's forums so users
have some form of social interaction and
we introduce tagging about a year and a
half ago so tags show up on the search
results page here you can see Forrest
Gump has been tagged but tagged with Tom
Hanks users can steal we call it steal a
tag as their own by clicking the little
plus next to it and we also suggest tags
via Ajax autocomplete widget as users
are entering takes for their own so in
order to study vocabulary evolution we
collected data when we first introduced
tagging into the movie line system for
about a month and during that month
users created 3,600 unique tags unique
sort words or phrases and those tags
were used in over 11,000 tag
applications so that the distinction
between tag phrases and tag applications
is important a tag application is a tag
phrase applied to a movie by a user okay
and I'm going to return to those three
classes of tags that I introduced in the
beginning we coded all the tags that
showed up in movie lines during that
first month and here you can see a list
of the top factual tags and those
accounted for about sixty four percent
of all the tag applications and the
subjective tags here the list of the top
subjective tags accounted for twenty-two
percent and finally the personal tags
were the smallest portion eleven percent
of all take applications
alright so what makes people tag the way
they do well there's a lot of things you
can imagine there's properties of the
object being tagged you know if if a car
is fast people might take it with the
word fast but as a system designer we
can't really control the properties of
the objects being tagged maybe we can
control a couple other factors though
and two factors we consider consider in
in our paper our investment inhabit the
idea here is that users tag in ways that
are similar to ways they tagged in the
past and community influence users
tagged in ways that are similar to the
ways they see other people tags and here
is a graph comparing these different
types of factors and I'm going to talk
you through the graph so the idea here
is to look at the similarity between a
particular tag that a user has applied
and another group of tags and when we
talk about similarity we're talking
about similarity of tag classes so if
this is a factual tag that the user is
applied we look at the number of the
proportion of factual tags that this
this other group of tags has had in the
past so the very first line here the
blue line is the similarity of a user's
tag a user's enth tag so example for
example their fifth tag to all the tags
in the community as a whole up to that
point in time so if they apply to
factual tag we see the proportion of
factual tags a community has had in the
past the light green line is the
similarity of tag users end tag to the
tags the user has seen in the past so
this is a pretty interesting difference
here it shows us that the tags a user
creates are more similar to the tags
they have viewed than the tags in the
community as a whole right so clearly
community influence does play some role
in in the use in the tags a user creates
and finally the top red line the the
strongest correlation is the tech the
similarity between a teggy user has
applied and
tags they've applied in the past so
users seem to tag similarly to how they
checked in the past alright so we've
seen that users care about the tags they
see in the community that they're
influenced by what they see now can we
use this to this community influence to
control vocabulary evolution and to
study this when we introduced tagging
features into movie lens we split users
into four groups and each group stag
tags were maintained separately and we
use different tags selection algorithms
for each of the these groups and it
takes selection algorithms decided which
tags each group was shown which
community tags so this take selection
algorithm showed itself in a couple
places in the interface in the search
results it shows that community tags
that were displayed and in the movie
details page it shows shows that
community tags that were displayed and
it also shows the tags that were
displayed in the autocomplete drop-down
so let me describe the four different
groups the first group we called
unshared and in this group users did not
see other users tags so three different
users these are these are actual real
examples from our website applied three
different tags to the movie Pulp Fiction
and none of the users saw each other's
tags the second group is called the
shared group and in the shared group all
the tags by all the all users in the
group for the movie Pulp Fiction get
grouped together and then we randomly
pick a selection of tags to show the
user and the third group is a shared pop
group now this is just like the shared
group but instead of randomly picking
tags we picked the most popular tags in
the group and finally the most radical
of the four groups was the shared rec
group and this was an idea to try to
bootstrap tags so we looked at movies
that had been rated similarly here Pulp
Fiction Fight Club reservoir dogs and
the Godfather had all been rated
similarly similarly by movie lens users
we grouped the tags together for all
those movies and return the
we return the most popular tags from the
whole set so what did we find well we
found that the vocabularies that emerged
were very different and the way we talk
we measure different was we we looked at
the tag class distributions over time
for each of the groups all right so we
can see in the unshared group the tag
class proportions are relatively similar
the shared group is dominated by
subjective tags and the shared pop and
shared rec group are dominated by
factual tags so this is a pretty
surprising result we have four groups
they have very similar tagging
interfaces and the vocabularies that
evolved in each of those four groups are
entirely different we weren't able to
run this experiment many times we don't
have a large enough user base so we
can't be sure that these results are
deterministic we can't be sure that if
that it's actually the different
interfaces that are responsible for the
differences but but anecdotally we
believe there's evidence for this and
the reason is as follows the shared pop
and shared wrecked group preferred to
show users tags that were popular now it
turns out that factual tags are
generally applied by more users and more
times than other types of tags so it's
very likely that the shared pop and
shared rec group showed more factual
tags and in turn users decide decided to
tag in more in more factual ways and
similarly the unshared group didn't show
any community tags so if I'm a tagger
and i'm creating tags that I don't think
are going to be shown to the rest of the
community I'm probably only interested
in taking for my myself and so the
number of personal tags is much higher
in the unshared group so this is pretty
strong anecdotal evidence for these
different tag interfaces affecting the
different vocabularies the XX is the
number of tags in total so there is
different there was different overall
different number of tags / for each
group we didn't actually find that that
difference was statistically significant
so for example there's a few users who
might
apply a lot of tags one thing we did do
was we retake this graph with the
normalizing each user so enforcing that
power users and a normal user who has
just applied five tags have the same
amount of of influence over this graph
and we found the same result so it's not
just a few users who are skewing the
sole distribution this is really a broad
robust difference between groups alright
so we've seen that users are influenced
by the tags they've see we've seen that
different types of vocabularies can
evolve and now we want to know whether
different types of vocabularies have
different values so the way we did this
but was by asking users a survey about
particular tag applications so we asked
them a bunch of questions about the tag
phone booth for the matrix for example
and I'm going to summarize the results
for each of our oh I skipped one did
they miss a slide there it is right I'm
going to summarize the results for each
of our three tag classes and here's the
results for fact for the factual tag
class I'll let you read this quote
so most users agreed factual tags were
generally liked fifty-six percent of
factual tags were deemed displayable by
users and users found them useful for
learning about movies and for finding
movies so the second group is subjective
tags and here are two different quotes
about the tags surreal for eternal
sunshine of the spotless mind let you
read them so the funny thing about
subjective tags its users agreed our
users like subjective tags if they
agreed with them they didn't like
subjective tags if they didn't agree
with them and that's kind of reflected
in these two quotations subjective tags
were in general less useful but users
who created the subjective tags found
them very useful for expressing their
own opinion so they liked applying
subjective tags even if the other people
in the community didn't get as much
value from them alright here's the last
class of tags personal tags I'll let you
read this quote
how does it help a singer single other
person on the planet I mean this user
really didn't like this particular tag
and he wasn't alone this sentiment was
shared by many other users only
seventeen percent of users thought
personal tags were were helpful but
again we see this cut this imbalance
between the value to the community and
the value to the tag creator users
thought that personal tags were very
valuable in organizing their own lists
so this hints at a design recommendation
tagging systems should have optional
private tags so that users who want to
create personal tags can do so because
it's valuable to them but they can be
hidden from the rest of the community
okay so now I'm going to move on to the
second half of my talk so in the first
half of the talk we looked at how
different tagging vocabularies emerged
we saw users are influenced by the tags
they see and we saw that different types
of vocabularies can have a different
value value so it makes sense that in
order to can encourage users to tag in
ways that are good we want to show them
tags that are good right there
influenced by what they see so in this
half of the talk I'm going to talk about
a paper that i'll be presenting at group
2007 so how can a system determine what
tags are good well there's tons of ways
but we focus on a few very simple ones
in this paper we just talked about how
different tag classes have different tag
value I sorry have different value to
the community so we could use that
unfortunately we found it fairly
difficult to infer what class a
particular tag is and even for the most
well-liked Ted classf actual tags only
fifty six percent of those tags were
deemed viewable so we hope that we can
have a better signal so we looked at two
other types of signals for determining
tag quality and that's implicit
behavioral data things like clicks
searches the number of applications atag
has an explicit rating
data in the form of thumbs up and down
widgets and in order to evaluate take
tag quality we collected some survey
data we collected 75,000 survey
responses about tag applications where
we asked users to rate tags on a
one-to-five scale we told them tags
rated three four or five would be
displayed in movie lens so that's kind
of three is kind of a threshold for
displayable and one thing we found in
movie lens that may not be true in other
communities are most of the tags and
movie lines are actually not very good
only thirty-eight percent of the tags in
movie lens were displayable and the mean
rating was only two so let's look at how
some of the implicit measures fared the
first implicit measure is that we might
want to consider are the number of
applications the tag has had it makes
sense that if that users apply good tags
more often that seems reasonable so it
turns out that isn't the case only 39 so
if you rank all the all the tags in the
survey by the number of applications
they've had so the most the most applied
tags are over here on the left and you
take the top 25% the top quartile and
you look at the number of the percent of
the survey responses in that top top
quartile that users actually wanted to
see we're going to call that the
precision of the top quartile so the
precision of the top quartile was only
39 cent percent I mean and that's barely
above the average across all survey
responses of thirty-eight percent so not
very good and it turns out the reason
that is happening is because the most
applied tags are generally personal so
four of the five top most applied tags
are DVD own seen at the cinema Eric DVDs
so users apply these personal tags a few
users apply these two personal
many many times so how can we combat
these personal tags well one thing we
can do is normalize each user's
influence and the easiest way to
normalize each user's influences to look
at the number of users who have applied
each of these tags and actually that
does much better so again if you take if
you rank all the survey responses by the
number of users who have applied a tag
you take the top quartile fifty-two
percent of those tags in the top
quartile were deemed displayable so not
great but but a lot better than number
of applications another thing we looked
at was the number of searches for tag
turns out that if you just look at the
broad number of searches it has the same
problem a few very power users skew the
results but if you normalize by user and
you look at the number of users who
search for a tag it does much better it
does particularly well on the high end
at the hut and for the top one or two
percent i think it was up at eighty
percent precision so what can we take
from these implicit measures well one
thing is that you should select implicit
measures that normalize the ability of
particular users to influence your
metrics so we don't want a few power
users skewing the results for for all
the rest of the users so we also looked
at explicit explicit measures based on
tagged ratings for determining tag
quality and here you can see the
interface we use we just stuck a little
thumbs up thumbs down widget near each
of the tags if the user would rate a tag
thumb thumbs up it would slide to the
front of their list of it they rated a
thumb down thumbs down it would fall off
their list skip this slide so here's
what we found about what we can infer
from a user's rate own ratings for a
particular tag so if we take the most
naive reading of a tag rating that so if
I rate the tag phone booth for the
matrix if we just take that as meaning
that i don't like that particular
application of that tag we get a very
high precision rate eighty-one percent
unfortunately any particular user
has not rated very many tags so the
coverage of that algorithm is very low
only 0.5% of the survey responses or
associated with a particular tag rating
on the other hand we could take a little
bit broader reading of at a grating we
could say if I rate the tag phone booth
for the movie The Matrix that might tell
me something about how I like the tag
phone booth in general so that had a
relatively similar precision 75% so just
slightly lower but it had four times
higher coverage still not very good but
much better than user rating so we have
to design recommendations that will come
from this first systems should assume
that users are going to rate tags
consistently because that's generally
what we found there we found that users
overall rate rated tags very
consistently but they don't always rate
them consistently so you should make it
you should make have some way for users
to rate tags different applications of
the same tag differently all right so we
can probably be smarter about the way we
interpret tag ratings we could look at
how the community as a whole feels about
particular tags so to do that we'll look
at the global average for different tag
ratings and here's a graph that compares
global average with the other tags
selection algorithms we've seen so on
the y axis we have the precision of the
survey results the percent of the survey
results that users said they wanted to
see on the x-axis again we ranked all
the tags using each tag selection
algorithm and we cut off at various
points the top twelve percent the top
25% the top thirty-seven percent so here
you can see first of all that user
average and user rating do very well but
have very low coverage so they they
can't even handle the top twelve percent
but more interestingly global average
barely does as well as the best implicit
measure so the number of users who have
applied of tag is as powerful a
predictor as global average so this is
pretty surprising to me I actually
expect expected explicit tagged raining
feedback to be much stronger than this
so why aren't ratings more powerful yes
yeah so this is looking at how well
thumbs up thumbs down ratings predicted
survey results so we have yeah right and
so I think the way we phrase that
question was would you want to see this
tag on this movie so and I don't think
we differentiated between tag creators
and the community as a whole all right
so why aren't average user ratings more
powerful as a selection method well it
turns out users don't agree about how
how good tags are but they don't agree
in kind of interesting ways they greet
they agree about bad tags so if the
first time three times a tag has been
rated are all are all negative ratings
if the first 3 ratings are all negative
ratings the ninety percent of the
resulting ratings for that tag you're
going to be neg negative so this is a
pretty easy metric that systems can
implement and it seems a fairly accurate
and you can slide the knob up I think if
you go and look at the first 5 ratings
you know it goes up to ninety nine
percent or something like that so on the
other hand users don't agree about good
tags so if you look at the first three
users who rated particular tag and
they're all positive only
fifty percent of the remaining ratings
will be proud positive so users really
didn't agree about what tags were good
if they just agreed about what tag for
bad and as an example here's the tag
based on a book the first nine users who
rated this tag all rated it positively
in fact many of those users rated at
several times so 16 positive ratings for
this tag right we have a lot of data
about it so we should assume that this
tag is good well it turns out that not
everyone agreed the only sixty-five
percent of the remaining 37 ratings were
positive so this might be domain
specific you know movie lens has fairly
poor tags overall only thirty-eight
percent of our tags were were deemed
displayable so it might be
domain-specific but still it's a
interesting result here's an example
another example about how users don't
agree so here's a list of the most
controversial tags in movie lens and
controversial is measured by kind of a
beige inform of entropy that waits tags
with very few ratings lower so we look
with tags with a relative even up and
down braiding and you can see the tags
on this list fall into a few categories
first many of them are subjective tags
like stylized quirky classic these are
subjective tags some of them are
redundant so movie lines dissipate
displays information about a movie and
tags like animation steel Steven
Spielberg and sci-fi already appear in
the interface and the third class of
tags are tags that are inherently
controversial and this is a tag like the
nudity tag nudie full frontal and so I'm
going to use this as a launching off
point for a very interesting story and
this is to look at the evolution of
nudity tags and movie lines so movie
lines doesn't have any adult movies
first of all just to prefer preserve
movie lenses integrity
so here's a graph it shows the number of
times nudity tags were applied on the
left and the number of users who applied
them on the right and the x-axis is the
number of days since the first nudity
tag was introduced so these are all the
tags that have the word nudity or nude
in them and I'm going to tell kind of
just tell the story of about how this
vocabulary evolved so the first nudity
tag was the tag nudity right that's a
natural tag for a movie with nudity and
it's for this movie havoc which I don't
know so about a month later oops a month
later there is the second nudity tag
which is my favorite of all the nudity
tags when you're stressed out nudity
works wonders for your nerves so this is
not a lot of informational continent
content with some entertainment content
that was a tag yeah amazing I don't
think they had the comma in there
because that would be shown as two tags
but and then another month later or so
we really see to start to see the real
nudity vocabulary emerging so a single
user applies the tag notable nudity and
three other users use that same tag and
three different in three days now that's
an interesting choice of vocabulary
right if you're going to describe a
movie with new tube nudity and you ask
to random strangers they and they don't
have any communication they probably
won't both say oh no notable nudity so
clearly there's some community influence
going on in fact that tag notable nudity
was used by 20 different users over the
next three months so now we're going to
jump to this big spike in the graph one
particular power adult annotator a few
months later at one in the morning
decided to take 300 different times with
different versions of nudity tags and
this particular user was not
satisfied with notable nudity right he
or she wanted a much more refined set of
categories for nudity so here you can
see what their categories were and they
ended up creating 800 tags nearly 800
nudity takes over a span of a bottom a
few weeks I think so this is all
interesting immune to the very good it
seems like a reasonable classification
for nudity well the movie lines
community also thought so so if you
remember there was about 30 applications
of notable nudity down here but after
the adult annotators vocabulary the
movie lines community entirely switched
so that tag notable nudity was only used
three times during the whole rest of the
new details evolution and on the other
hand the adult annotators vocabulary was
used all woods used very very frequently
it was used by 71 users 173 different
times so that the movie lines community
really grabbed on to this vocabulary so
it's interesting you know the vocabulary
came along here and it changed midstream
right so it really shows the power of
community influence in a vocabulary so
what another site interesting side note
is nudity tags are very popular in movie
lines in fact four of the top 10 most
popular tags searches are are these
eight nudity tags alright so we talked
about ratings and how users don't agree
on ratings so the last thing I want to
look at is whether ratings are helpful
so it didn't look like it right num user
is this implicit metric did just as well
as global average but if the type of
tags that num users and global average
are good at predicting are different
then we can get value from combining
them so what we did is we formed a
hybrid
method that basically averaged the
responses from all the different tag
selection methods both explicit and
implicit and what we found is that the
overall precision was five percent
higher so tags is so rating tags
actually did add extra value in terms of
precision so five percent right what
does that matter is that worth the extra
effort that users have to expend to get
get five percent well the answer is yes
because even if it was zero percent
people would still do it people like to
rate tags they really enjoyed it so
there's not it shouldn't be considered
work at least in movie lens and lastly
there's a few open questions related to
determining tag quality first of all if
you have a high traffic site it could be
that implicit measures could do a lot
better if your ratio of good to bad tags
is different than it is in movie lines
you might be able to do better and
lastly the the tag selection algorithms
we focused on we're really intuitive
easy to implement algorithms and you can
imagine doing much more complex machine
learning techniques okay so that's my
talk I'm going to just summarize what
what we talked about we talked about
vocabulary evolution we saw that users
are influenced by the tags they see we
saw that vocabulary evolution is pretty
volatile quite different vocabularies
can emerge and we saw that vocabularies
have different value value so it's
important for designers to be careful
about vocabulary evolution and then in
the second hack half of the talk we
looked at how systems can choose good
tags to show users we looked at some
implicit measures of tag selection and
we looked at measures that were fairly
successful that normalized the influence
of power users so that particular users
can't skew results and finally we saw
that if we if we use hybrid schemes that
are based on ratings and implicit
information they do better than any one
particular tag selection algorithm could
do
so thanks to my advisor John riedl
co-authors including Dan the rest of
group lens and it's tough for paying me
and Google for hosting the talk thanks
and I'll take questions so let's start
out there in the back I have a
microphone but maybe I'll just let you
talk and I'll repeat repeat your
question
there you go
so I assume people who tagged know
something about the information they're
looking at so that they can tag so they
know that a movie is this fictional and
so they tag fictional so if they already
know the information about about what
you're tagging what's the impetus what
drives them to tag that's a great
question and we ask that question in our
first survey that we asked movie lens
users so it turns out that the people
who tagged were kind of evened a lot
evenly divided in the reasons they
tagged I think a lot of people tag to
express themselves just because they
like to express their opinions about the
movie those probably resulted in
subjective tags a lot of people tagged
because they felt like they were part of
the movie lens community and they just
wanted to give back and then some people
tagged to organize their movies so those
were the top three separate responses
and if I remember correctly they were
kind of evenly divided buck so on your
entropy slide ah it a lot of the tags he
showed with a lot of entropy were very
subjective yeah and I find it very
surprising that you also had quite a lot
of entropy on somewhat factual stuff
including nudity sci-fi animation Steven
Spielberg is there any wait were you
guys able to find any way to separate
the difference between I showing just a
quality of a tag in its application
versus whether or not the user cared to
see it be redundant or they just don't
want the word nudity showing up all over
the web site right so we didn't we don't
have any data on why users don't like
the tags that they don't like except
that we have some anecdotal information
based on survey responses it would be
interesting at least to run an
experiment you know where you had
different ways of pan
at a you can pan it because it's good
i've started panic because it's
subjective or because it's redundant or
something like that sorry like slash dot
right right different different reasons
for moderation because I mean maybe
you're right maybe maybe you can do a
better job of detecting specific cases
of bad tags than trying to detect the
umbrella of bad tags other questions
so the question was what percentage of
the community used tagging and do people
like it in general did it encouraged
overall usage i believe so you're
talking about tag ratings are taking in
general so i think about 12% in I think
so there's a portion of my paper I
didn't talk about here there's different
experimental groups with different
rating interfaces in the most active
rating interface twelve percent i
believe of the people in the community
rated a tag and I think the percentage
of taggers overall is something like
seven percent so one interesting thing
we found so these tags actually take up
a lot of real estate on movie lines so
we found that people who had been using
the system for a long time before tags
were introduced often didn't like tags
they thought they just didn't want
things to change they wanted them to
stay the way they were so we actually
had to introduce a hide all all tags
button and I think that was probably
used by you know like a quarter of a
percent of the total you users but I
don't know if we saw any overall changes
in usage behavior I'm not sure about the
data on net more questions
could you tell us a bit about where the
decision to use movie land came from as
opposed to using this has been hosted
entirely by your research project I
guess so was it much easier to do that
and have some something of an artificial
maybe I'm site or is it as it apparent
he uses that that the research is going
on behind the site as opposed to using
some satellite delicious and getting
data from that is that difficult thing
to do it was difficult for us because we
wanted to do experimental manipulations
so we would have to make changes to
delicious which is not easy for a
research group to do the movie lens
users so movie lines is actually a site
that exists outside of these experiments
being run I guess but users do know that
their ongoing so in the discussion
forums they often talk about being
guinea pigs but they are they seem happy
to be guinea pigs so any more questions
does New York have a question well I'm
trying to think of one because I do have
a couple kind of almost questions um you
talked about the display of the tags
influencing the tags that get plot did
you did you try out different ways to
display the times yeah so we didn't
change the fundamental the tag display
widget between groups so that's another
area of research that could be really
interesting we didn't look at things
like differences between tag clouds and
other ways of navigating the tag space
we did look at like I said we did look
at how choosing different tags to
display matters hmm yeah I couldn't see
the screen so okay yeah so the
differences are mostly in the tags that
were showing to users not in the widget
that displayed the time how they was yep
did you have another question oh no no
no okay okay there's a question over
here q so you mentioned that only about
seven percent of the community we
actively tag in and I think you also
mentioned that tag application didn't
really seem to change how people used
the site so in your opinion what do you
think is a value tagging then right so I
think users get informational value from
tagging they get search value from
taking so tag searches are next to title
search is the most popular search in
movie lines so they're actually I mean
so would be lines has a small support
staff we can't enter all this
information in movies that users what
and tags are a way for the community to
do that in a way that's scalable so it
turns out that these tag searches are
actually valuable to the community and I
think
the other reasons that tags are valuable
valuable either just fun people like to
do them their way of X for community
members to express themselves all right
we have a whole bunch of questions how
about over here Lily so you're talking
about um during the talk I kind of got
the sense that objective tags seem like
the ones that we were the most helpful
to the community um but you also say a
reason to do tagging is because people
find it fun and those people are tend to
be the ones who do subjective tagging
how do you think about that in the
design of these sorts of systems yeah
you know that's a really good question I
can imagine so I think that's a
contradiction that you'll always have I
can also imagine that if you had
selection algorithms that were smart
enough you know maybe they could look at
so one of the things I said its users
like to see subjective tags they agree
with and you can imagine trying to
decide what subjective tags a user would
agree with and trying to show them those
particular tags right right so that
would be that would be a cool
application on the other hand I think
you're right it's it's a tough it's a
tough balance
alright i think i heard recently that
there was a news search website based on
tagging that was started by the one of
the people involved in wikipedia like
just for a sort of chat trying to tag
the internet of the whole oh so i was
wondering if you saw it like tagging
could be like scale to being able to
actually successfully tagged in and out
of the hole and how you think the search
quality of that tagging based search
engine would compare to say google right
so I any example of such a site would be
delicious right delicious tags web pages
it scales it doesn't look like delicious
is motivates users to tag as much as a
site like Flickr or our Wikipedia or
even like library thing for that for
that matter but the one thing that
delicious does give you is the wisdom of
crowds measure of relevance so if I get
search results on delicious I know those
search results are there because users
found that word relevant to that site
right and that's very very opaque sorry
very transparent it's very clear why
they did that so I think that's a very
powerful feature of tag search that page
rank for example doesn't give you now
whether or not a site like delicious can
scale to the entire Internet I don't
know that's that's a big question
any more questions yeah I want another
one um did you think about tagging
objects based on user behavior rather
than on exclusive like I want to tag
this I mean did you ever consider sort
of you know interpreting user behavior
and tagging things alone so like if I
search for a particular item and click
on it than in further the tag would know
we didn't do that we did the one we did
try to bootstrap the one tagging metric
that was based on similarly rated movies
so we looked at movies with similar
ratings and we grouped together tags it
turns out users really really didn't
like that particular approach so you
would get all these really nonsensical
tags I suppose if you know like the
example I gave about searching for a tag
and then clicking on something that
might be a reasonable approach to try I
think you'd have to be pretty accurate
with your with your with your implicit
metrics yeah something that's the main
problem with tagging is that you have to
make tags and then apply tags if there
was if there if you can figure out a
good way to sort of tag things in as a
side effect of doing what you want to do
huh you know I mean how oh it just
happened to tag it that way because I
did I wanted to do right on it seems
like the ideal situations there'd be no
extra Africa music right I don't know
how to do that so a lot of applications
actually try to do a little bit of what
you're saying right delicious for
example it's a bookmark management tool
and I just happen to have tags fall out
of bookmark management so users tag
things because they want to be able to
find them later presumably right not
because they want to share their tags
with other users as much I don't
actually don't think that's entirely the
case but but what you're saying i think
is as good
any more questions all right thank you
very much
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>