<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Seattle Conference on Scalability: Scaling Google for... | Coder Coacher - Coaching Coders</title><meta content="Seattle Conference on Scalability: Scaling Google for... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Seattle Conference on Scalability: Scaling Google for...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LT1UFZSbcxE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's my pleasure to introduce Marissa
Meyer who's a vice president of product
management and she's been at Google for
about eight years now and she was our
first female engineer to be hired into
the company so she's responsible for all
product management related activities
for Google search as well as a variety
of other search related products before
joining Google Marissa was did her
bachelor's and her master's at Stanford
and specialized in AI so welcome Marissa
hi today is actually my eighth
anniversary to the day at Google and I
guess it's fitting given that I remember
working every Saturday of that first
summer but I'm here on a Saturday but I
really appreciate all of you being here
and spending your weekend learning a
little bit more about Google and our
scale and how we approach some of the
technical problems so my talk today is
about scaling Google for every user and
trying to give you some insights into
how do we approach the user experience
and how do we think about how we want to
advance search and the first sort of
piece of the framework that you need to
understand is who the average Google
searcher is and one problem is that all
Google searchers are different they vary
by age gender location profession
they're all very different and they have
very different types of tasks and so
scaling the user experience and trying
to understand all of these different
types of people it's really complicated
because we have lots of users and then
we also have lots of web pages lots of
data that we need to organize and so
when we think about the overall design
principles that we approach the search
experience with there's a couple of core
ideas that we try and work with given
that there's such a variety of people
and given that there's such a variety of
information and one of those design
principles has to do with novice to
expert should we look at each of these
people based on the demographics of
gender or age or location the answer is
a little bit location in particular is
very sensitive to search the other
elements don't matter as much and
one thing that we see is searches
incredibly tasks and actually search
specific the best experience for a
particular search usually has to do with
that search and the other interesting
phenomenon that we see that's related to
this is how quickly people advanced from
being a novice to being an expert
because what happens is when we see
people use search for the first time I'm
sort of a more naive searcher though who
saw something like why doesn't anyone
carry an umbrella in Seattle and if you
type a query like this into Google you
get kind of irrelevant results about
technical careers at Microsoft so it
turns out but actually what you really
wanted to type in is something like you
know weather Seattle Washington and
you'll ultimately get the weather and
people ultimately are able to refine
their search techniques really really
quickly so we see people make this move
from novice to much more expert
searching able to get exactly what they
want in a really short period of time
usually like a month so there's certain
skills like driving or you know flying
an airplane that can take years to hone
searching goes really fast it's a fast
process which means they can iterate and
actually change their strategies quickly
and so we see people being able to do
that they're able to do much more
sophisticated searches much sooner so
similar example where can I hike in the
Seattle area about a year later you'll
see about a month later you'll see
people type something like hike Seattle
area and get much better results so the
learning curve looks like that their
skill level goes way up in a very short
period of time so what does this mean
for design it ultimately means that we
aim to design for the expert so yes we
could make those that first month of
search more comfortable or more friendly
for that searcher but the truth is
they're gonna move out of that phase so
quickly that we should be we should be
targeting our user experience such that
it's really easy to use and not annoying
and so on and so forth for that expert
searcher because everyone's going to
become an expert really really quickly
and so that means doing things like not
having a lot of repetitive text not
necessarily having a lot of help text in
the way of the
experience and when you're doing your
search try not to give people too much
guidance so aim for the expert but don't
intimidate the novice what you want when
you want it so how do we actually think
about new features because over the past
eight years we've actually taken the
search experience and added a lot of
different things to it and so when we
think about our philosophy you could be
sort of the portal of the portal efforts
of 1999 where you try and be everything
to all people and you could just put all
the things that you do right on the
homepage so everyone can see the whole
product line the whole set of features
and when our approach is somewhat
different we want to focus on search and
be what you want when you want it so a
few observations so in the PC world if
you sort of think of it as a graph of
features and user experience the more
things you can do with your computer the
better your user experience ultimately
is and so the graph here in the PC world
looks something like this the more stuff
you add and the more things that you can
do the better the user experience gets
then there's things that happen like in
the handheld world where you start to
see more of a parabolic curve as you
increase features the experience it gets
slightly but you get gets better and
better but there comes a point when
because the device is so small you're
such a constrained on sort of a
constraining piece of hardware if you
get to the point where you add too many
features it ultimately hurts the user
experience this is sort of analysis that
palmed it around what happens in the in
the handheld world what they really
found was that there was sort of a sweet
spot in terms of features and what you
could do with your handheld and what we
find at Google is that there's two
pieces both of those pieces actually
apply one is that we need to increase
features and the more things you can do
with a search engine and with Google's
products the better off you are so it
looks like the first curve but the other
part of this is that as we try and stay
more singularly focused on search and
ultimately give people what they want
when they want it that other curve comes
into a plot into into play so the
apparent features those features that
grab you right when you first come to
the site or you know offer you something
to do we want those features to appear
when they're when they're relevant in
context so for example
rather than telling you we do
translation right on the homepage
ultimately we put the translation
features in context so when you get a
search result that isn't in your native
language there's a translate this page
link right there I called this sort of
the Swiss Army knife thought hmmm where
you can have a Swiss Army knife and the
portal approach is all the functions
open right so you can actually see all
70 things that can do but you might
actually you know lose a finger or cut
yourself if you tried to approach it
that way so that Google's the Swiss Army
knife closed so all the lovely doodads
are there you have the screwdriver you
have the bottle opener you have all of
those things but they're there when you
need them and they can be sort of pulled
out at a moment's notice and we try and
structure the features such that they
appear when they're useful I want to
spend a little bit of time talking about
one of the nice things that we can do at
Google scale which has to do with the
way we evolve the user experience and
the way we do user experiments which is
my background as you heard isn't in user
interfaces or user experience at all
it's actually an artificial intelligence
and so when I was approached you know
some number of years ago and asked to
spend some time thinking about what our
user experience should be like you know
I didn't know very much about it so my
approach ended up actually being
mathematical mostly because I just
didn't trust myself right I didn't know
which font we should use I didn't know
if we should make it gray or make it
black so I tried to go out was er away
we could mathematically figure out what
we should do on the site and the beauty
was that because we had so much traffic
we actually could use Google's scale so
we do what's now known we did it but
then and now is more famous than in the
industry actually Amazon was the other
company that kind of pioneered this
technique is split a B testing where you
take a small percentage of the users and
you give them a new experience or you
change their experience and then you
watch that population so every time they
come to the site they get that new
experience and you watch that population
to see what happens with key metrics
over time do they search more or less
often do they use this product more or
less often than say a control group and
it's nice because you can actually find
statistically significant differences
even in things as small as color
let alone layout and flute and user
flows and by doing these kinds of user
experiments you can actually figure out
mathematically what the right user
experience is there's no more fighting
on the design team so should it be this
green or that green there should to be
laid out like this or that we can just
put both of them on this on the site run
them both in an experiment on a small
percentage of users and then ultimately
decide which way we should expand it to
100% so from that basis I wanted to show
you one of the more interesting
experiments that we did which was one
the first ones I had to do with the
number of the number of results so when
we first went to putting together Google
and this is sort of a shortened and
abbreviated result page we just picked
ten results because that's what
AltaVista did right when you're a
startup you just sort of have to do the
expedient thing and ultimately just you
know go with something as sort of a
starting point so we picked 10 results
but at the time Yahoo was doing 20
results and I remember Sergey and Larry
came to us and they said you know what
should we be running 20 results by
default
should we give people 25 or 30 and so we
do two different types of techniques to
answer these questions we do the user
studies where we actually talk to users
probably the numbers of like 5 or 10
then we also can do percentage
experiments so when you go into the user
studies and ask users should we give you
20 results by default they say sure 25
great 30 even better best of all and so
we thought ok well it's clear we
probably should give users more results
because they'll be able to find what
they're looking for more easily if we
actually give them more so we went ahead
and we gave them more results we ran
three different experiments one with 20
as the default number of results one
with 25 and one with 30 and so he sort
of lengthened the result page and with
these sort of more is better philosophy
right like the more results we give them
the better chance they have a finding
what they're looking for the better off
we are and in terms of Google searches
over time we saw things plummet it was
actually the worst experiment we've done
to date within six weeks we had lost 25%
of our searches on the 30 results group
and actually and for the for the median
the 20 the 20 results we had actually
lost 20% of searches so we ultimately
saw this huge drop in searches which
makes you wonder you know why why would
we lose all of these searches because is
it the idea that you know are they so
much more overwhelmed with all this
additional information that they don't
know what to do and they're ultimately
driven to search less as I thought this
is sort of the paradox of choice but
that doesn't explain why people would
start doing like you know one out of
four searches last in a six week period
and so then we considered other things
like well maybe it's because we actually
count the next button as a search and so
people are pressing next class right so
ultimately they they have to do less
searches because they have to go to the
next page less it turns out you know
almost no one actually presses the next
button on Google so and we did the
analysis of first page searches
alone well the drop was slightly smaller
it still was really significant and when
you actually when I said we were sitting
there puzzling and puzzling over this
and we finally ran a regression test
over the logs we have sort of 15 fields
you know the cookies the IP addresses
all these different things to try and
figure out was there some field there
that very dramatically meaning it wasn't
a valid control there was something
changing outside of the number of
results and there was the issue is that
in our control 10 results it takes us
about 0.4 seconds to find those and
return those to the user and obviously
when we went to get more results took a
lot longer and the canoe average
experimental group it was taking about
0.9 seconds so it really came down to
latency it's one of these things where
they say the perceived behavior is
different than observed behavior in
psychology so what the people perceived
about themselves the fact that they
would be happier getting more results
was different than their actual behavior
and their observed behavior which is
that they were leaving the site and
drove and the difference was that while
they wanted more results the fact that
they had to wait an additional half a
second to get those results really
wasn't worth the trade-off and what we
learned here is that latency and
improving our latency is really really
important so this shows you sort of how
we've evolved the user experience and
the type of tests we do to try and
understand everything from number of
results to the structure of the result
page
and so on and so forth in fact we what
we've now done on these percentage based
experiments is we rolled out Google
experimental where you can actually if
you're wondering what we're what we're
running on the site in any given time
you can go to Google experimental you
can actually sign up and log in and
become part of the experiment for the
people who elect to be part of the
experiment there's obviously a big self
selection bias so we don't factor that
in to the ultimate experimental results
but this is a place where you can go and
we can actually get feedback explicitly
from our users in terms of what they do
and don't like about these new looks and
feels that they're seeing in the
experimental part of Google I also
wanted to spend a little bit of time
talking about improving Google search
why it's hard and also why it's
interesting and so do you think about
the overall search experience and how
you evaluate it there's all kinds of
different elements that go into it we
think of them as just searches and
queries but ultimately you start with
the sort of the query or the search
itself you should factor in the user who
is sending in that search their tasks
the context around what it is they're
doing at this moment and also their
location and the way that they look at
the search experience when you're done
is actually not only about the relevance
of results but actually the underlying
information in the results what
additional information do we provide how
good are those results when they click
through to them and if you think about
things there's all kinds of interesting
problems here inside a search so for
example we know that GM means
General Motors the cars of course unless
you say GM foods which means genetically
modified foods and I think one of the
the really exciting things that's
happening at Google is because we have
so much data from the web and so much
data from queries people revising what
they're doing saying you know GM and
then typing in GM foods so we understand
that there's another context than that
what GM means it ultimately means that
we can do things that almost sort of
mirror intelligence the idea that GM
means this when followed by cars and GM
means something else when followed by
food it's something that because of the
amount of data that we have we're well
positioned to do so if you look at
things like this I thought was a really
fast
needing examples so if you type in B&amp;amp;B
for bed-and-breakfast a B we basically
we don't know it not in the semantic
sense but because of the amount of data
what we're finding is that when people
say bed-and-breakfast followed by
something they usually mean a place so
it ultimately figures out that a B must
refer to Alberta Canada and if you
search for something like Ramstein a B
we know that in that case it must mean
airbase so trying to you know because
there's so much data out on the web and
because all these words are used in so
many different contexts we can actually
change it basically looks as if we're
changing how that word is we understand
the semantic change even though it's
really just based on the raw data and
search is really hard we still can't
find all the answers and there's in
terms of user intent that's the
ever-elusive thing that makes search
really interesting and also really
compelling so when you think about sort
of the span from easy to hard and think
about user queries what you know given a
user query what Google should also try
there's some things that are simple that
we do right now so if you look for
unchanged lyrics van Halen Halen even
though unchanged is an actual word in
the English language because of the
context we have in terms of all the data
we actually will suggest the lyrics to
Unchained by Van Halen right because we
know from different revisions that
ultimately Unchained is what the person
is looking for but things get that much
harder when you start thinking about you
know freeform questions how much does it
cost for an exhaust system and we
ultimately should really be doing a
query like query cost of an exhaust
system and and then of course as we go
down the spectrum to harder there's
things like overhead view of villagio
pool how will we ultimately build the
understanding this is some of these
uncharted territories that overhead view
really means a picture that which you
should really search for as bellagio
pool pictures and again you'll get the
right result and then f15 launched from
a submarine you actually are looking for
a submarine launch and then things where
that are even more complicated where the
piece of information exists
but it's not obvious what the chain of
logic should be defined something from
distance like distance from Zurich
Switzerland to Lake Como Italy the
easiest way to find that is actually to
look up the trains from one place to the
other ends in in Europe and I'll and
find the time there so these are the
types of things where if we had the
perfect search engine all those types of
queries on the Left would be you know
interpreted and executed like those
queries on the right but building that
level of intelligence is really
challenging and I think that's one thing
that makes search a really interesting
problem it's very large-scale it's
highly multi-dimensional and it's not
well-defined problem so I also wanted to
spend a little bit of time talking about
some of the things that we think are
going to advanced search a lot in the
future as well as some of the exciting
technical problems around it and one of
those things is scaling internationally
we have a demo that we released last
month that is shows sort of the cusp of
a new piece of technology that I think
is a really non-intuitive way to improve
search but does really work
it's called CLI R cross language
information retrieval and we're
attempting to do is use the automated
translation engines that we've developed
to take people's queries translate them
into different languages and then search
the web for documents that match all of
those translated queries bring those
results back and translate them into the
native language and so right now what we
have up in terms of a demo is something
that works like this I apologize for you
in the back I'll just ordinary three
this looks so what you can do here is
this is Arabic to English so right now
we're doing single language pairs but
you can type your query in Arabic there
in the search box and it gets translated
into English so this is restaurants in
New York and then you say you're in
current language is Arabic and you want
to find results in English so we take
that query translate it using our
automated translation engine to
restaurants in New York search English
pages for restaurants in New York get
those results back and then use the
automated translation engine to
translate them back into Arabic so for
the end user they typed their query in
Arabic and they got their results in
Arabic
and so it's a seamless language
experience for them and right now we're
doing these pairwise and obviously
automated translation even as good as it
is and as much as we've invested and it
still has a ways to go but when you
think about what this could do for
search it ultimately means if your
answer is out there if it's written in
any language you can still find it and
it's really compelling and for English
may end up not being as important
because so much of the web is written in
English but for a country in a language
like Arabic which you ultimately see
you're just a a language like Arabic
what you see is that only 1% of the web
is written in Arabic so when they do a
search there's just not nearly as much
information to answer their query with
so by having a technology like this we
can really unlock all the great answers
and all the great search results that
are on the web and bring them back to
them in the flame in in their native
language and then of course when you
click on those results you ultimately
get driven to pages where we can again
use our automated translation engine and
translate the full page this is another
example about typing text words per
minute because it turns out there's no
typing tests on the web for for people
who want to try out their typing speed
for air for Arabic users so there's lots
in English and it turns out you don't
really need to understand the
instructions all that well to get a
count so this is a way where you could
actually find something that doesn't
exist on the web in Arabic by using this
type of translation tool and so as I
said I think the real power is using
this across multiple languages finding
the best answer bringing them back and
making it a seamless language experience
then there's universal search so in the
middle of May how many people heard
about Google's Universal Search
announcement so in the middle of May we
retooled the search engine to try and
expand from our classic 10 text-based
URLs to introducing much more rich types
of information into the result page
things like books videos images news and
local results all onto the search result
page and Universal Search has a couple
of interesting problems around scale
this is an example of what we're trying
to do so it turns out not for a tube as
was the original monster-movie it to
find the whole sort of drag
a scary movie genre it was made in 1922
so up until we released Universal search
when you search for it you had a great
result from the IMDB as your first
result and had lots of good meta
information things like the director the
actor the running length so and so forth
but what we see here now is that with
the power of universal search we
actually have a video of it right on
page and not just any video it's not a
video clip this is the 84 full 84 minute
movie that was uploaded to Google Video
so you don't just have to learn about
Nosferatu on the meta level you can
actually just watch the whole movie
right here in page and as these kinds of
much richer better answers that we're
trying to provide with Universal Search
sometimes the right answer isn't just a
URL or a text link sometimes it will be
something that's much more rich and
experiential like this video
Universal Search has a couple of key
scaling problems that make it
interesting one is if we actually want
to bring in results from all of those
different corporate RAAA what we have to
do is run the search on all of those
different corpora which means that right
now you know we get a lot of search on
main web search hundreds of millions of
queries a day but something like Google
News or Google Book Search may only get
you know single-digit millions or tens
of millions of searches a day and so if
we want to scale it up such that every
query Google's given has been we can
actually go and search those corpora we
add to think about how to totally change
the representation the data
representation how do you change the way
that you store the index how do you make
it computationally feasible without
multiplying up our entire infrastructure
by you know tens of thousands if not
hundreds of thousands of machines so the
infrastructure problem here is something
that we ultimately had to address and
some of the people that you've heard
from today like Jeff and others are some
of the people who thought about how we
should roll out a new infrastructure so
Universal Search represented bringing
out a new infrastructure to run these
kinds of queries and make this
computationally feasible the next big
problem that we had was once you have
different types of content the
equivalent of apples and oranges how do
you rank it which one should go first
apples or orange
right how do you decide should a book go
first and a video go first and an image
go first how do you decide once you get
all those results back from all those
different indices how to mix them
together and ultimately understand the
relevance and so and the other problem
is that when we're looking at all this
each type of index has a different type
of signal right so in books do we know
the page number that the word appeared
on on the web we have much richer things
like link structure the you know the
bolding that italics there's all kinds
of different signals and so when you try
and sort this out total the scoring
functions aren't that interesting it's
as if you were going to say which should
we put first apples or oranges in terms
of u.s. consumption turns out you'd want
to put oranges first so what 80 pounds
of oranges per person versus what 50
pounds of oranges get consumed per
person per year but if you look at
something like fresh which how much
fresh stuff gets consumed it turns out
many more fresh apples get consumed than
fresh oranges and then of course the
most valuable crop in the u.s. is
actually grapes so you get the idea that
with all these different types of items
how do you blend them all together and
that's one of the things that you team
and I are in our search quality team
looked at how can we roll out a ranking
function that does a good job
normalizing across all of those
different indices and then finally
there's the user experience problem
which is what I worked on with my team
of once you have something that's
totally different and really disruptive
where do you put it in the search page
and how do you actually get to the point
where users can find it but they you
don't have something like presentation
bias where someone ultimately notices
something to a larger degree than they
should
relative to relevance and so on and so
forth so should images always go on the
top you know should news always go on
the top because of its urgency should be
interleaved
into the results how should we you know
represent these different entities these
are all the types of questions that we
asked we sort of talked about segmented
versus blended view should we show each
type of result in a segment of the page
should we blend them all together and
should you have fixed placement or
variable placement should where the
results show up always be fixed in the
same order so it's easy to find and
navigate or should you actually vary
where they show up and our first attempt
what we did is we just took the
normalization function ultimately gave
good
textual clues as to mediums like a
thumbnail if we're if we have a video
there pictures for images news headlines
and dates and times associated with them
to give the users some insight into the
medium but in terms of the ranking and
segmentation when we ultimately decided
to start with was just an ordered list
which is what people are used to with
search just put it on the page and rank
order give some clue that this is a
different type of result visually in
terms of the layout of that result but
lay it out that way and that's just a
first attempt I think that there's going
to be on there's clearly going to be
ongoing research in terms of the right
way to deal with all of these
heterogeneous types of results and then
finally there is how to make google
personal at scale and a few years ago
there was a big announcement which some
of you might remember about Stanford
University students who found out a way
to make Google faster do people remember
this it was sort of interesting because
it's sort of a case of computer science
and journalism gone wrong because
because return notice there was a team
stopped can bar Taher Glen over at
Stanford who had found something really
interesting they had found a faster way
to compute PageRank and of course people
the the journalists understood that
PageRank was part of Google and then
ultimately thought well this means that
Google will be faster because we can now
compute PageRank faster so all these
headlines you know blanketed the didn't
do the news the next day that now
they're you know someone could come up
with a faster Google of course this
doesn't totally make sense because
PageRank is computed offline long before
your query actually gets issued as
opposed to in real time but there was
something interesting here we ultimately
ended up acquire they formed a small
company we ended up acquiring them the
idea was that what they had found is if
you component if you made a component to
a component structure of the web where
you group things and sorted them by host
by looking at just the connections
between the components you could
actually do a computation of PageRank
looking at the link structures across
those components that was far more more
efficient and you know frankly we hadn't
been worried that much about making
PageRank very efficient it runs across
hundreds of compute
it takes about a day to converge using
different mathematical approximation
methods but it was interesting to think
about making PageRank much faster to
compute because well PageRank would
still be computed offline it could for
example allow us to compute multiple
page ranks so it turns out the PageRank
function itself our measure of
importance is very sensitive to the
seeds in the equation so depending on
how you start the PageRank the this you
know you see the PageRank algorithm you
also may get very different types of
answers in terms of importance so what
this would allow us to do is do
something like compute a PageRank per
country so for example we could seed
PageRank with all kinds of different
URLs from say the UK and compute a UK
specific page rank which might help us
get more relevance there but even more
intriguing we could actually look at
pages people visit and use and click on
on the web and compute a personal page
rank for each person so we could
actually create a personalized search
engine and ultimately that's really the
advance of whatsapp and Taher and Glen
were working towards and so we brought
them on board at Google and they
developed our personalized search engine
where you can sign up for it it keeps
track of and a search history it keeps
track of your overall queries and where
you click and the results and then using
that they ultimately compute a vector
over the web wherever I wish we re
ranked your results in line with this
type of PageRank computation so you
actually end up with sort of a
personalized a sense of what's important
to you and when you use the results
other interesting things that we're
doing in personalization that sort of
veer far from search but are still are
still related are things like our
iGoogle page so this is our personalized
home page that we offer on Google and I
think there's a couple of interesting
technical things here in terms of what's
happening both technically and in terms
of strategy one is that this is an open
platform so these little modules down
here on the bottom are called gadgets
and we have developers all over the
world working with our API and now a
wizard called the gadget maker to create
these gadgets and it's really
interesting to see what people create
people will create slideshows
new games weather news and this has been
our fastest-growing product it sits on a
relative basis it's it's scale and
growth is comparable to YouTube's people
are really responding to having this
kind of personalized content on their
home page in this type of rich
functionality but from a developer
standpoint there's all kinds of
interesting things happening here so for
example there's one teenager who's 17 in
Arkansas named Caleb who's our number
one gadget developer and he basically
made a bunch of gadgets that are super
useful for high school students like
periodic tables so if you're a high
school student would you really want on
your homepage as a periodic table and it
turns out that Caleb an aggregate across
the 10 or 12 different gadgets he's
created actually gets 30 million page
views a month so he gets a huge amount
of distribution of these gadgets so for
website developers for companies
building a gadgets a great thing to do
because it ultimately means is well
someone might not make their full
homepage a periodic table just like on
my home page I have my Netflix queue I
would never make Netflix my home page
but now Netflix can participate on my
home page by having a gadget and we're
sort of seeing a lot of interesting
growth and gadgets and it ultimately
means a few things for us one is there's
this personalized experience that gets
people to come back ultimately causes
them to search more and it's part of
searching more that helps us improve our
algorithms but it also helps us learn a
little bit more about them and then when
you look at taking things like their
search history their activities on
personalized search and iGoogle together
well we ultimately are hoping to build
is something where the search engine
really understands who you are and what
it is that you want so sort of you Plus
Google hmm being a sort of home joint
search engine hmm
so personalized searches I think one of
the most interesting things that we're
going to advanced and because and I
think about the future what I really
think about is you know what will the
lead search engine be like in 10 years
right because six months out is really
well kind of easy right because whatever
we're going to release in the next six
months is probably in production and
being built right now
two years out is really hard because
there's sort of weird stochastic changes
that can happen in the environment in
terms of what might get built or what
might advance technology but do you
think ten years out there's just some
things that have to be true like the
search engine ten years from now has to
be better than Google today right Google
today is better than it was a month ago
or two months ago so there will be a
search in in ten years from now and it
will be better than Google is today and
if we think about why will it be better
I think part of that answer has to be
that it will understand more about the
user which will help us get closer to
that sense of user intent that we
ultimately saw earlier maybe it will
just be that it understands where the
user is or a little bit about their
overall preferences and the types of
searches and what they've already read
on the web so we can produce new and
unique results but there's those types
of elements of personalization that I
think are going to be part of the
surgeons in the future maybe not the
exclusive reason they were better but a
big part of one reason rather better so
with that that's the end of my my formal
presentation and I have some time for
questions
not necessary well I think you could
sort of say well it to the extent that
novice users often type I'm sorry it's
already I need repeat questions so the
question was does our focus on the
expert ultimately caused us to devalue
natural language processing I don't
think it necessarily does there
certainly is a lot of interest in work
at Google thinking about natural
language though I would say it's
probably more and things like
voice-to-text and other elements there
because for example we rolled out our
new service 1-800 for one one where you
can actually call and speak queries and
there's all kinds of reasons boys to
text would be really useful I do think
that what we see is a lot of times when
users start out they end up doing more
natural language questions and as they
evolve they start to understand the
concept of keywords I don't necessarily
think that's good that's one thing that
maybe also makes the search better but
you know my view is that searchers
should be able to express themselves the
way they feel comfortable as opposed to
conforming to our approach so the fact
that our approach is so keyword based
that they ultimately lead their need to
learn to be keyword-based it's sort of a
- right it would be better if we
actually got smart and learn to do
natural language - it says that natural
language as you know is really hard
other questions
sure so the question was how do we when
we when we - OCA shion's and we mine
refinements and things like that how
does it work in terms of folding those
observations and those findings back in
and the answer is we have as you can
imagine a lot of data coming in to
Google at any given time from the crawl
to queries so on and so forth so there's
all kinds of ways that we process that
data most of it happens offline and then
gets uploaded in either nightly or you
know hourly builds of data so for things
like personalized search we do a
commutation that I think runs about
twice daily that folds in the latest
elements of your search history into
your personal profile so there are
things like that so there's constantly
off-line processing running and they
happen in different periodicity
depending on the product yep well sure
so the nice thing what Universal Search
does we actually replaced the main
engine searches going as well as Google
searches going and so things are going
pretty well we always see a little we
always um we also we always see a little
a little bit of a slump in the summer
but in general traffic is is up and
we're pretty happy with it and users are
responding really well to it so we're
starting to see the overall benefits of
people finding a video or finding a book
and the increased traffic to those
properties also seems to indicate that
Universal Search has been a net win I
think that there's a lot of immediate
challenges right in terms of like once
you roll out a big infrastructure change
like that there's always lots of things
to fix and lots of new problems to
consider so for the first time this year
I look a lot at our traffic graphs to
try and understand what's growing and we
really should allocate resources and how
to prioritize for the first time this
year I saw something really interesting
happen which is as our sort of traffic
slope down a little bit over a Memorial
Day which it always does interestingly
our mobile traffic went up in this nice
little growth curve that almost
perfectly correspondent on a percentage
level to our to our traffic slope off so
as almost as a people you could actually
watch our traffic and see people
shutting off their computers and going
outside and doing searches from their
phone
so I thought that was really interesting
but that also made it made it much more
clear to me that the advances of what
we're doing as part of web search that
you do from your laptop have to be
reflected in the phone so of course the
universal search has lots lots of
interesting problems
is it a follow up question okay sure so
the question was what is our primary
metric is traffic our primary metric and
the answer is usually what we do to make
sure with let's say one of the split AV
experiments that we actually have a
definitive an actionable answer as well
usually define a primary metric so for
example if we're changing the appearance
of the ads we'll have the primary metric
be rpm revenue per thousand pages and so
if that goes up that ultimately means
these ads are more effective than the
way we previously were just playing the
ads if there's something with like
Universal Search which should we do it
which we do experiments on and we
actually did experiments leading up to
the big launch in May we look at things
like overall traffic traffic to the
specific properties that are linked to
off of Universal search and how we drive
traffic there and then also things like
normalized traffic because it turns out
looking at traffic overall especially on
a global scale it's incredibly sensitive
to world events someone has a holiday in
this country and you can see it right
that you know the Olympics happen or
there's a big news story and it really
causes traffic to fluctuate a lot so you
need to look at more normalized metrics
like searches per user things like that
yep
sure so the question is in in less
sophisticated environments of split
maybe testing you know and also probably
Google as it's grown over time have we
seen resistance to new you know new
things that we put in the split maybe
testing and the interesting part is that
for end-users not so much it's
interesting my mother is very
detail-oriented and she's an art major I
mean I was an art teacher and like I'll
show her two different designs and she
can't tell the difference because I got
a changes that we make our very subtle
room usually measuring really small
things interestingly the most resistance
we got is from inside of Google of
course is the employee values has grown
that means that the resistance gets
larger and larger right so you change
something small like the color of the
bar on top and they're like it's ugly or
like actually I had the same reaction
last fall we changed the top line of our
ads to be in the standard font size
rather than font size minus one and
right I did the search the first day I
looked at all the experiment results it
seemed like a good change we changed it
on the site the first time I saw it I
was like I'm blinded the odds are
screaming at me look at they're so big
but I you know you get I think it's
because we used Google so much that that
you know you get really sensitive to any
small change because I three four or
five days later I was over it and I
didn't even notice anymore so that's I
find that the most resistance is
actually internal yeah
sure well so bias and also the flipside
there which is user trust is a really
important issue for us because search is
ultimately a learning mechanism right so
if you think in some ways of like how do
you learn something from a teacher you
need to trust the teacher you need to
know that when you go and ask a question
you're getting the best answer not the
best answer that that person was paid to
give or that best answer that person was
you know predisposed to give and so it's
one reason we've ultimately tried to be
very clear on our ad so you always put a
pastel background on them or put on a
special part of the page labeled and
very clearly sponsored links so people
understand when our answers have bias
that said with universal search we you
know that's our objective search results
and so we're introducing things that
they are very agnostic in terms of which
you know very agnostic Lee in terms of
which corpora they come from this is
also one reason why Google has been
hesitant to be a Content hoster or a
content creator because the degree that
we host content we ultimately have a
monetary incentive to drive people to
those pages if those pages have ads on
it so while there are some times when
we've had to almost Rinna sassa tea so
for example we host videos on google
video and on YouTube but that was just
because the video experience was so
broken across the whole web that if we
did video search and let people click
and go to a page where they actually
couldn't see the video we thought that
was worse but we've been very clear
about our monetization and eBooks was a
similar item where a lot of the
publishers didn't have the capacity to
host their books so we've posted them
we've been very clear about our policies
they're about monetizing in terms of the
way they were introduced into Universal
search we've tried to be agnostic and in
fact for videos we not only include
things from Google Video and YouTube in
Universal Search but we include all
major video hosting sites all over the
web including Metacafe and others yeah
so the question was on our stock quotes
when you type in different tickers you
see little charts up here on the top of
the page and we used to have Yahoo first
and now Google is first and I think the
answer was that I mean if I recall
history correctly we didn't actually
have Google Finance until about a year
ago so up until then we were actually
ordering the links based on various
published metrics like comScore and
media metrics so we had the five top
finance sites in their order of
popularity listed there so when we
rolled up Google Finance we did put the
Google link first so see it's only fair
all right we do all the work for the
search page all these other things so we
do put it first hmm but and that's
actually been a policy then because of
Finance we influence in other places so
for Google Maps again it's the first
link so on so forth and after data
string it's usually by popularity yeah
so let me make sure I may understand the
the question properly so you're looking
at information processing errors so a
query coming through the system if it
gets routed to the wrong indices or even
or just returned results that just
weren't as relevant so it's an
interesting question it's an interesting
problem and it's one that has you know I
remember thinking like you know when I
first joined Google that it was really
hard for us to figure out where we
actually producing the best results on
the web because the other thing is like
you know Universal search makes this
even more complicated because we're
hitting different content types but as
you can imagine we can't fit the whole
web or you know our entire postings list
on one computer so you ultimately hit
you know 40 different computers and then
Stitch the results back together and
like what if one of them is down or just
kind of concept in the middle of what
it's doing and we have all kinds of
sophisticated systems that watch this so
in terms of the actual operations of our
systems we actually literally have what
we call baby sitters that are constantly
checking the health of all of our
machines right you know are all these
index servers the dark servers the web
servers are they up are they answering
how overloaded or you know unloaded do
they seem we're constantly checking
things like that in terms of quality
assurance we actually have a bunch of
different ways of looking at this one is
we in terms of advancing our quality as
we try and change the signals and our
ranking behavior we have evaluators all
over the world literally several tens of
thousands of them that log onto consoles
and rank is this query and this is this
URL a good answer for this query so
they're constantly helping us understand
and get it and get a good benchmark
around what is a good result for this so
we know when we roll out a new
evaluation function does it seem better
by those hand evaluations and then of
course the real-time text that we have
have to do with monitoring the system
and the way users are responding to it
so for example we've given the large
number of query
it turns out that the percentage of time
the first result or the first admins
clicked on is pretty stable right
because we're just averaging over such a
large base and so if that starts to
swing dramatically and we're seeing
either less click activity per page or a
different distribution that usually
that's us know that something's going
wrong so we have all of those different
systems monitored so those are the types
of things that we do to make sure the
machines are healthy
make sure any advances that we turn out
are actually advances and aggregate
based on a benchmark and then monitoring
the systems in real time yeah so I'm not
aware of hand tuning we did with Google
BOMs I know that we have actually looked
at automated processes to try and find
Google BOMs it's very goo Gabbana's are
very are hard to find so how many are
you all familiar with Google bombs and
how they work
no okay so what happens with Google
bombs is someone basically tries to own
and/or embarrass a particular query or
her entity so for example if you take
two common words that don't occur
frequently together on the web like the
word miserable and the world failure
they so they occur they occur but they
both occur a lot on the web they don't
occur together a lot and so it's
something to do as I'll say hey let's
make miserable failure mean something on
Google and they put up a big blog post
and say why don't we all link to this
page about george w bush and so
everybody put a link on your page and
link to this page and then it'll be
really funny because on google you'll
type in miserable failure and this page
will come up and so that's sort of the
spirit behind i'm behind google bombs
and that's how they work and it's
actually really hard to catch because
that linking behavior of a new set of
terms appearing on the web and all
linking some new place is also the same
linking behavior that you see on blogs
right so you know the
okaygo treadmills video appears on
YouTube you guys all seen the treadmills
they're great anyway so like they're
really popular they got like millions of
views everyone's watching these guys
dance around on treadmills - a
choreographed dance to the music and so
the same thing happens right like
everyone says okay go treadmills and
links to that video on YouTube and right
that's ultimately that what drives the
link structure and PageRank a bunch of
other things that make Google work but
the same thing is happening now with
miserable failure in a way that really
wasn't intended so it's hard to find and
let you know even when you're looking at
snapshots right because one thing you
thought was maybe it's temporal maybe
you can see because all those miserable
failure links appear so quickly that
that's that's a sign but it turns out
you know the blogosphere ultimately
means that even finding a temporarily is
hard so it's something that we've looked
at a lot we found some techniques that
work we have some techniques that have
false positives and I know we've we've
rolled out some changes to it Larry Page
our founder actually makes a very
interesting observation about this
though which is there one of the
problems with Google bonds and there's
been about four or five very famous ones
over time is that they become famous and
they become and talked about right so
everyone's running on talking about
miserable failure so then when you
search for miserable failure actually
being able to see the Google bomb or our
explanation of it because we'll put an
explanation of it up on our blog that's
actually the right answer because the
people who are typing that are actually
looking for evidence around what happens
with a so it becomes a sign of
self-fulfilling prophecy or
self-reference or prophecy that like
that's really quite strange but
ultimately kind of ends up working out
so yeah
sure so the question was what percentage
of the web do we crawl and what is the
limiting factor in terms of growth and
so let's see there's a couple of
different answers to that we try and
crawl almost everything there's
certainly some types of content that we
don't do as well on things behind you
know sign ins various databases where
are we trying to what we're doing now
with databases is actually allowing
people to send us feeds of data to
Google base so they can actually just
give us all that attribute data in one
sensible way rather than us crawling and
infinite looping and getting the same
data again and again so there's some you
know places where we can't do as well
but we try to get as much to the web as
we possibly can
the one issue that we have or that I see
is that to reduce the kind of really
precise and relevant results that we
have we have very detailed postings
lists right we needed not only to know
that this word occurs on this page but
we need to know where it occurs on the
page was it in bold was it in italics
what was the exact position so later we
can do proximity text for the words and
the postings lists are super detailed
and they actually go into you know 100
maybe even 150 different facets of a
particular of a particular postings item
and so as you start going towards tens
of billions of pages what you want to
have really deep information like that
on the on the top few billion pages the
rest of them you don't want to expend
quite as much sort of linear energy on
them and so how can you have an index
that's smaller in terms of you know the
postings list and the amount of data
that's stored but still allows you to
accurately find results so if someone
type something really obscure and it's
not sort of in that top chunk of the web
you kind of fall through to this index
that doesn't have quite as much data
still allows you to do the basic search
and produce relevant results but you
know so those are the types of
techniques that we've ultimately worked
on in terms of can we have different
amounts of information in different
indices such that as we scale and get
larger we you still have a way of
producing a good result but it may not
have the same precision at the top part
of the web has in the back
sure there's a lot of it and there's a
lot of interesting problems there so the
question was for we you know we're very
text-based and keyword based still so
how long until you can search for a face
or search for a tune you know so things
like you know a visual search or an
aural search where rather than yeah in
turn you know you rather than entering
in text you ultimately enter in a
picture or enter in a few hummed notes
and I think a lot of these techniques
are having great brown ground
groundbreaking efforts published and if
you look at some of the interesting
papers are happening in academia on
visual search they are showing real
advance but they're still at a place
where they're 50 percent accurate 60
percent accurate when you're searching
for faces and well that's very
interesting from an academic standpoint
and it is something it shows that the
science is advancing and may someday get
where we're going in terms of end lay
people users they just don't understand
when a search is wrong half the time mmm
right or maybe some mistake half the
time and of course when you're wrong on
half of the results on the 10:00 on a
tenth I don't know page of ten images
it's just sort of beyond what they can
comprehend so we're all t'me but i think
is actually much more likely to happen
as an advance instead is for example an
image search we look a lot at the
associativity of the text around the
image
so what around that image can tell us
what's there so it's still a very
text-based
approach but it's sort of more
sophisticated and trying to understand
what words associate with this picture
what words describe this picture can we
you know understand you know that it
says you know Eric is on the left and
Serge's on the right can we you know do
that kind of understanding and on video
search I think again while the those
visual means are still coming along I
think it's much more likely that early
advances in video search will come from
voice to do to text technology which in
my opinion is much further along and
being able to extract voice out of the
video build a text transcript and then
search over
so those are just my own personal
speculations but I would guess that the
advances in image search and video
search over the next two to three years
on a consumer and what's available to
consumers are much more likely to come
from Texas OSHA tivity and and
voice-to-text advances yeah sure so the
question was you know for something
where you actually embed the information
in the page so for a ticker symbol where
we give the stock price rate on the page
or for a map where the map is right on
the page how do we measure success and
it is so frustrating dynamic actually
sometimes with teams because we're so
used to everything being so measurable
on the web you can say you know my
product is useful to people 17% of the
time and it's really great to actually
be able to know that number but what we
try and avoid is actually people hiding
information away for the sake of
achieving measurability right the idea
that you know don't take information
that could just be embedded in the page
and put it on a separate page behind a
link just some people have to click so
you can measure it and I might be
frustrating because you ultimately lose
measure ability it's actually better for
the users because they're one step
closer to the information so what we do
there is we do a lot more of the hand
evaluations that I talked about with
those tens of thousands of people
logging in we also look at queries of
say the case where like a stock ticker
shows up first or a map shows up first
where there was no further click
activity on the page there you know it's
a loose approximation it's not the
precisely measurable hey they clicked on
it they most liked it but because
because for example they could have just
decided to go search somewhere else or
walked away from their computer unhappy
but the idea that they got that page and
didn't do anything further with it
usually means that they were happy we
can also look at for those users who got
the piece of information how what
percentage of them clicked elsewhere on
the page because that usually is an
indication that they weren't satisfied
with that and with that information we
embedded and so those things ultimately
helped us approximate so we'll
we lose full measurability there still
is a concept of of you know overall
sense of successes habit and user
satisfaction so I think I have time for
just one more question or yeah how did
it be what so the question is how do we
deal with spam and I realized a while
ago that like spam means so many
different things at Google because we
have spam in the search results people
who are trying to trick us into thinking
that a result is good for a query it's
not good for we have query spam people
who send us lots of nuisance queries
just to measure things or just to try
and overload the service and then we of
course now with our Gmail product we
also have mail spam to do so we have
lots of people all over the company who
are working on spam how to find it and
route it out and how to get rid of it
and I think the most notable form of
spam that relates to search is the spam
in the results so again there we try and
have a very clean technical objective
automated approach which means trying to
understand what are the link patterns
around spam so sometimes for example you
can look at link structures on the web
and you can say well look if this page
really was authoritative on this topic
how come only pages on this domain we're
only pages on these five domains just
point to that page that's really funny
because if it was globally authoritative
you'd see more links so you can kind of
look at you can do a local connectivity
analysis and try and understand
something strange is happening there
there's also other memes so you know for
example one of the most popular forms of
cloak spam is called cloaking where you
know when our crawler comes through we
declare it as Googlebot so website knows
when Google's visiting and so what
they'll do is they'll serve a different
page to us as Googlebot then they'll
serve to a user later so for those types
of things I mean that ultimately we feel
hurts our users because we served up
that result
thinking it's that that page said this
and was relevant to that query so if
you're gonna serve them something else
we don't know if that page is relevant
anymore
but it also needs again this is you can
imagine there's an easy way to check for
this but so when we up we'll all
sometimes have the crawler come through
with the Googlebot user agent and we can
have other tests go through using an
classic end-user agent like ie right
this is that and actually see you know
aside from ads and other sort of
cosmetic changes are we still
fundamentally getting the same page in
the same context or so we have we have
automated ways of checking on things
like cloaking checking on things like
strange link patterns on the web that
might mean this isn't really
authoritative on this topic so those are
the types of ways that we adjust results
spam in particular well so with that I
want to thank all of you for your time
and attention and I hope you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>