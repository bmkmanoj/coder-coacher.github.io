<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PhotoTechEDU Day 30: Imaging optics for the next decade | Coder Coacher - Coaching Coders</title><meta content="PhotoTechEDU Day 30: Imaging optics for the next decade - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PhotoTechEDU Day 30: Imaging optics for the next decade</b></h2><h5 class="post__date">2007-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6VTrb2gl-14" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">morning everybody time to get started
welcome to photo tech lecture number 30
that's some kind of milestone today
we're really super pleased to have with
us Bob Fisher he's the founder and CEO
of optics one in Westlake Village
California
I've got his optics training at the
University of Rochester and has had all
kinds of honors awards and positions
over the years including the president
of the spie
which is the organization formerly known
as the Society of photo optical
instrumentation engineers okay they gave
that up now they're just the SPIE
Bob looking forward to a great time take
it away okay thank you very much for the
intro appreciate it I'm gonna start out
slow but I'm going to accelerate very
rapidly I have about two hours worth of
material to present to the next hour so
if you can listen as fast as I talk
we're gonna get along terrific I always
like to start out with this one which is
my favorite visual illusion it's sort of
your relevant relative to the rest of
the top but it's so neat that I have to
show you basically if you stare at
either one of the crosses I think you'll
see eventually well pretty quickly
actually that all the pink ones go away
and all you see is a green one there is
no green spot it doesn't exist it simply
doesn't exist and if you stare at it
long enough you'll just see the green
one go around and the Pink's of the
purple book completely disappear the
purple I'm sorry the green is after
image on your retina is what it is and
purple I commit you may have may
remember as a kid getting a picture in a
little coloring book with a marking flag
and they tell you to stare at it under a
bright light and then five minutes later
or two minutes later look away and you
see the inverse colors the reverse
colors that's effectively what this is
so anyway that's kind of neat I just
wanted to shift share it with you now
arrow down
I think yeah I just want to cover a
little bit of this this is also a lot of
fun late invention of telescopes is so
exercised most of the geometries that
they leave they seem to have left
nothing unattempted in optics no room
for further improvement that was in 1669
from Isaac Newton he turned over his
grave with you so we're doing an optics
these days and of course Bill Gates
thought 640 K of memory ought to be
enough for anybody
so this is kind of neat things there the
world is moving ahead very rapidly okay
they actually let me go back to the
other one from real quick here
everything that can be invented has been
invented well that's a misstatement as
it turns out if you do enough searching
on Google and that's where I do all my
searching you'll find out that that is a
false statement and it's a myth and the
next slide which I'm not gonna stop on
okay today's presentation imaging optics
for the next decade we're going to see
in our lens systems and other imaging
systems we're gonna see nonce more
increased use of non spherical or
aspheric surfaces and I'll show you why
in a little while any of you are who are
into digital photography this should
feel very you'll feel right at home with
all this compression molded glass lenses
and injection molded plastic lenses
often with a suruc surfaces again are
going to be very prevalent diffractive
optics where we use basically the the
the physics of a diffraction grating to
bend light can have some remarkable
advantages over conventional surfaces
improved image quality as sensors become
smaller pixels become smaller the the
task focuses right on the optics as one
of the weak links in the chain unless we
unless we come up with better designs
more compact zoom lenses you'd love to
put it in your shirt pocket and have a
12 X or a 15 X zoom well you don't have
that yet but and I'm not sure you ever
will quite to that extent but they will
get smaller they'll get lighter in
weight and they'll get cheaper cheaper
as well more efficient straight light
control that's something that comes with
the territory any lens system if you aim
it close to the Sun even if it's outside
the field of view you'll get some flare
and glare and other problems
more robust lens assemblies now a lot of
cameras are underwater for example and
things like that and lower-cost optics a
few words about basic optics let me push
this twice I didn't do that in the first
place okay look the goal of virtually
any image forming system is to create it
is to be of sufficient quality to
resolve the minimum sized object namely
each one of these what I like to call
resolution elements you could call in
pixels if you'd like and the image blur
must be matched or should be matched to
your smallest detector size namely that
of a pixel that's a good rule of thumb
it's a handy-dandy rule of thumb in
addition the clear aperture and the
transmittance has to be sufficient for
the desired sensitivity your image your
imagery is no good if it's if the sensor
can't pick it up and have sufficient
signal-to-noise to to be able to give
you an image to look at so that's the
purpose of the performance of our optics
the design form must be capable of
meeting that performance you're not
going to be able to use a magnifying
glass as a front objective lens for a
long telephoto or for an astronomical
application or anything like that a
magnifying glass is one lens element and
the image will be exceedingly blurry and
just it won't perform well special
requirements we may have in the infrared
and other wavelengths must be met and
then of my size cost weight
environmental effects and there's a
whole list that probably would add on to
that as well if I take a PT Cruiser make
it monochrome and then split it up into
five by eleven and these various other
numbers clearly you can see the car here
here and you can barely see it here but
I I speculate and I've some experts and
image processing have can concurred with
me that motion is a cue that's extremely
important and you probably would be able
to tell what it is if you saw the car
driving across in the 8 by 16 I just
added this slide to my show to my
lecture recently if you have a tank or a
cannon or a person these are the number
of bars or resolution elements that you
need in order to resolve to detect
oriented NIH's and ultimately
identification you're going to need six
bars across the object in most cases so
that's what we're dealing with them
we're talking about pixels now how does
a lens work I I meant to bring this
along but in the hustle-and-bustle last
night I didn't pack it but this I call
this a wire lens I have a I have an
optical axis here where there's a piece
of piano wire it does kind of a loop
here so it pivots about this point and
it continues on up at the top I have
another piece of piano wire it comes to
here it loops around there's a screw
going into the wood and it comes down
this way to here and then this one and
this one and this one so I have parallel
what I'll call wire arrays or whatever
you want to call it and each one is a
zipper gets progressively further from
the optical axis bends the light or the
Ray is more severely so that they
ultimately all go through the focus at
the letter F and that's how a lens works
if I take this bungle of rays here or
wires and I send them in at an angle
going uphill to the right indeed the
image is out here of both the optical
axis but still forms an image if I
gather the the wires here I come out
collimated which would be meaning it
focuses effectively at infinity if I put
my wires together at two times the focal
length from the lens this being the lens
position it a pre-image --is 2 2 F on
the other side and then this one simply
shows if I have converging light it
focuses closer than the focal length so
you can look at this and you don't have
to know anything about optics or physics
this is how a lens works and this is the
function of a lens
I'm gonna skip over this pretty quickly
because we don't get for the sake of
time but basically these are the
specifications that an optical design
person would work to this has most of
the specs in it that are important
perhaps the most important tied together
the focal length which is this distance
here and if I put a single lens here and
I eliminated these and the light came in
from infinity and came to a focus right
here that would be the focal length it's
taking this black ray and extending it
forward as if it was not bent by the
lenses and it meets the entering ray at
the very edge of the aperture here
that's the focal length clear aperture
diameter let's call it self-explanatory
and the f-number is focal length divided
by clear aperture now years ago maybe 10
or 15 years before digital cameras came
along anybody who was into photography
knew what an F number was now I hasten
to say nobody does so we have to keep
the spirit alive a little bit and we
actually have to work with that in doing
our design work one of the only other
point I want to make here is that the
specification for a field of view has to
be the full field of view it cannot be
just vertical or horizontal because in
this particular case the diagonal is
significantly larger than the horizontal
or vertical and I have seen almost
million-dollar programs fail in
aerospace companies because they
designed their optics to go from here to
here and ignore it anything out in the
corners so that's called a word to the
wise aberrations diffraction image
quality and optical path difference some
very key metrics that we work with first
of all geometrical aberrations a lens if
it could form a perfect perfect point
here at the image then you would get it
what's called an airy disc which is like
a little Gaussian with a ring pattern
around it however these are geometrical
aberrations predictable to many decimal
places this is called spherical
aberration the edge ray focuses or
crosses the axis here and as we proceed
towards the optical axis the crossing
point extends outward to the right and
this is what's called paraxial focus
that's where rays infinitely close to
the optical axis will focus
if I had a perfect image here as I said
I'd get a diffraction blur if I had a
very blurry image here I would not see
the effect of diffraction at all I see
as the effect of the Rays not coming to
focus so it's one or the other or some
combination of the two now when I first
started teaching my course I wanted to
explain diffraction without any Bessel
functions or integral signs or anything
like that which to me is sometimes
intimidating so think of it this way we
have a swimming pool at 3 o'clock in the
morning and the water is like a sheet of
glass or ice it's perfectly flat and
straight we throw a rock into one end of
the pool and the wave fronts emanate out
in a concentric fashion from where the
rock entered the pole well there's an
exact correlation between
electromagnetic theory in terms of
diffraction and also the way that water
waves behave using the exact same
derivations and vessel functions so if
at the other end of the pool I have a
very long radius to the way of the rock
went into the pool way out here
somewhere so they're almost straight so
let's consider them straight I then put
up like a part of a 4x8 piece of plywood
immersed it partway into the water
these waves continue to propagate
there's nothing evident here and then we
get little curls occurring here there's
no such thing as a step function in the
water so that is the fraction of water
waves and if we substitute a light for
that we would get a gradient with little
intensity variations up here and if we
get diffraction around the lens that
goes in and out of the screen if you
will we get our symmetrical airy disc
which you can see is sort of an
extrapolation if you want to think of it
that way of this pattern here from just
an edge so that's where diffraction
comes comes from the airy disc which is
this Gaussian like image the physical
diameter is two point four four times
the wavelength times the f-number and
let me just say is a quick rule of thumb
and the visible that diameter is the
f-number in microns so if I had a
sophisticated or a simple camera lens
and it had
f-1 I would have a 1 micron diffraction
blur if it was f10 it would be 10 after
100 it would be F 100
I mean it'll be 100 microns the angular
diameter is 2 point 4 4 times the
wavelength divided by the clear aperture
so if I have in this case three
different F number of lenses actually
located here the first one images here
the second one on the third the image
gets progressively larger based on this
equation here and I will not bore you
with too many equations today I promise
you if I have three lenses here of
diameter D 2d and 3d and they have the
same f-number the airy disk diameter is
identical and it's clear that this will
September that achill angle alpha this
will be half alpha because it's a longer
distance here and this will be alpha
over 3 so it's the same size blur but a
longer distance means that the angle it
subtends is smaller so if you're doing
anything relative to high-resolution
optics this helps quite a lot I think
I'm going to pass by this one well how
am i doing in time right okay I don't
want to get too crunched at the end
generally in optical fabrication we use
this kind of process where we have
what's called a block we rotate it about
this vertical axis here and these are
lens elements whose upper or outer
radius is effectively the goal is to
make it spherical and then on top we
have a tool of the particular radius
we're interested in and this this part
here rotates that whole tool assembly
back and forth according to where those
arrows show now as this rotates about
the vertical axis and this swings back
and forth we get a near random situation
it's not completely random
there's overhang on this side and then
this side and the center elements don't
overhang at all but it's it's so close
to random that if the optician if the
person in the shop varies the length of
this and the speeds and so forth they
can create essentially a spherical
surface very quickly one of the beauties
of a spherical surface is that the rate
of change of slope everywhere on a
sphere is absolutely identical so if I
took a tangent to a sphere and moved it
somewhere else and then moved in another
similar increment the angle
of the tangent is gonna be identical at
each position this is one of my favorite
slides of the past actually many years
wit aberrations come from anyway you
don't have to know anything about optics
and you're gonna believe what I say
because it's very simple
once you look at it this way aberrations
are the failure of the race from a
common object point to come to a single
or common image point and you saw how we
had the blur before real rays of base
Snell's law we all learned Snell's law
in high school at least I remember
learning it in high school and sine
theta equals n prime sine theta prime
that looks the prime got stuck down here
somewhere her axial rays which is the
small angle approximation the sines and
tangents and the equations become the
angle in radians so n theta equals n
prime theta Prime and that's the small
angle approximation so if we and
paraxial optics has zero aberrations
it's absolutely perfect in the
geometrical sense so if I take a ray in
coming in here the paraxial ray goes
down according to the blue arrow and the
real ray refracts more severely because
it's obeying Snell's law which is a
nonlinear equation this is a linear
equation and the difference between the
two is what the aberration in effect
really is so if I had theta is one
degree the real is 0.5 double are one
axial meaning the small angle
approximation is one half the difference
is almost zero is a little tiny number
three zeroes one if I go right to forty
degrees for example I find that the real
ray descending angle is thirty four
point six degrees the paraxial is twenty
degrees so the paraxial is here and the
real one is here and the difference is
about fifteen degrees that's pretty much
close to what I show here and that's
where aberrations come from that's the
root of any aberration for any lens
system you'll ever work with this shows
the real rays in green after they enter
the lens here it's basically a flat
surface and then a curved surface and
this is the paraxial lens where the red
rays are and the red rays come to
perfect focus the real ones will base
Nell's law and they
come down an image here from the very
edge of the aperture and this angle from
the green up to the red is also about 15
degrees give or take a degree or two
now here's another lens with spherical
aberration and these are bad things
either these are things that we have to
get rid of if we take a single element
and curve it around this way the
aberration is so large it's bigger than
the lens itself I mean that imagery
would be absolutely positively awful if
we take an equal radius on both sides
equal and opposite we still have a
residual and then bending it this way
gives us something not quite as bad as
this if I bent for minimum of spherical
aberration the lens I can get down to a
fairly small blur but it's still nowhere
near as good as you're gonna need for
many applications one way that we can
overcome the problem is to eliminate the
very steep angles of incidence that
surfaces like here or up here and we can
do that by splitting the lens into two
three four and multiple components and
you'll see evidence of that in just a
few minutes there's a term which I want
to develop called optical path
difference and basically what I'm
referring to here is that if we think of
this rock into the swimming pool in
Reverse we have the wave fronts and the
water coming to a focus point where the
rock entered the pool and that's just -
that's exactly the same of light coming
down with a - a perfect focus somewhere
over here that would be the the
wavefront would be the blue spherical
reference wavefront if the lens has
aberrations then you will see the wave
front will be perturbed it could be this
red curve it could be something very
much different than that but that the
difference between the two is called
optical path difference if that number
that OPD optical path difference is less
than or equal to 1/4 the wavelength that
you're working with namely a half a
micron and the visible then your system
will be almost a fraction limited and
you'll see that every disc pattern the
wavelength and the visible is 25
millionths of an inch so we're talking
about this number being 6 millionths of
an inch or less so whenever I talk to
mechanical designers they go into lala
land when I say
six millionths of an inch they have no
comprehension of what I'm talking about
and I'm sort of joking here of course
but it is a very very very small number
and if the if a topi D is less than or
equal to 1/4 the wavelengths of light
then you will get an almost perfect
image I'm getting a little bit deeper
than perhaps I should here this is more
or less the same thing I showed before
the OPD the what's called peak to Valley
that means the maximum to the minimum
the leading to the trailing extent what
if I have a wavefront that is perfect
from here to here and then it just has a
very sharp hook in it well that's going
to have a peak to Valley that's the same
as this because it's the leading to
trailing but most of the wavefront is
perfect so for that kind of application
or a result we use what's called RMS
which is this equation here which does
more averaging over the surface so if I
were to make a telescope mirror as big
as this room here and I had a little
dimple or a little raised area the size
of a pencil eraser that was one way one
visible wave it would not meet this
criteria of being quarter wave in terms
of quality but the area is so small that
it would have a negligible effect and
this equation is a better one to work
with so I hope it's clear this shows
what happens if we have zero waves that
is a perfect image a quarter wave a half
wave and one wave and you can see that
we wave which is this so called Rayleigh
criteria that's the OPD being a quarter
wave if we have a pattern that is a
little bit degraded from this one but we
still see the first bright ring as
continuous as soon as we get down here
and here we lose our first ring almost
completely lens configurations it turns
out that the proper configuration is one
of the keys to the art and science of
lens design and I do call it an art and
a science it provides the basis on the
starting point for what your design
effort and the programs the software
that you that we all have access to I
put quotes around the word automatic but
they're rarely capable of changing
configurations if you go in with a
certain configuration and I'll show
a grouping of them in just a minute the
program usually reaches an optimum for
that same starting configuration but it
changes the radii and the shapes of the
lenses and so forth that's called the
local minimum and the error function the
configuration can be driven by any one
of the specs that I showed before or
some of these as well a simple lens
magnifying glass quality small field of
view light bucket however they may not
be that bad and I'll get back to that
point a little bit later a landscape
lens is the old Eastman Kodak cameras
from the 20s and the 30s where they just
simply have a curled lens around what's
called the aperture stop where all the
Rays pivot about here up to 30 degrees
field of view but you have color
aberrations and the quality is not that
good and a chromatic doublet is the
first lens where we can now bring the
color under control and we can bring the
red blue and green to a common focus or
almost a common focus that's called an
achromatic doublet a rook triplet is a
kind of a milestone in a way because
this is the first time we have enough
individual things to vary so that we can
bring the performance to a rational
state of perfection we have six radii
one two three four five six and the two
air spaces the thickness of the elements
are not that helpful sometimes they are
but in general they're not and we can
control circle aberration Combe
astigmatism axial color lateral color
distortion and I always forget which the
last one is 104 the focal length of
course as ice tests are for example is
an extrapolation of a cook triplet where
the last element is using two different
materials to help with the color
correction so you can see sort of a
logical trend as you go down these a
double Gauss lens is what you would have
in a low f-number film camera or digital
camera with a fairly sizable sensor low
F number perhaps even F 1.4 or even F 1
in some cases I want to go through each
one of these with pests of all ends of
telephoto a wide-angle I'll show you on
the next slide
exactly how that works and an IPS which
would be a viewer for a display or other
IPS application like a telescope a
wide-angle lens this one particular lens
covers plus or minus 90 degrees so it's
180 degrees field of view now if I if
you think of it like coming in this way
it has to be Horst around rather
significantly and eventually it comes
out of this front group of three
elements with an angle of about that
angle relative to the optical axis and
then I take this group to basically re
image the position here where the is
raisa P R to come from and it reaches on
to the sensor or the final image plane
so this effort here going from a prime
and B prime to a and B is taking us from
some position out here to the final
image we take that as a unit we marry it
to these three elements and we have a
hundred eighty degrees of field of view
lens now I don't expect that you'll be
able to go back to your office and do
all that in the next twenty minutes it
takes a little a little bit of expertise
to get there but this shows that it is
rational it's not voodoo it's not rocket
science it's it's challenging however I
will say that how can we continue to
improve aberrations as I said before as
pixels get smaller and sensors get
smaller we're gonna have increased needs
on our optics well one thing I haven't
talked about yet is refractive index
that's how basically how much the light
slows down as it goes into the denser
medium namely the glass and from Snell's
law that also defines how the light
bends or refracted each one of the
surfaces and let us suffice to say that
if I take three elements with an
ordinary glass type and I'm not going to
bore you with any greater details than
this
of an index of 1.5 that means that
that's the ratio that the light slows
down in the denser material and then I
go to higher and higher refractive index
denser material denser glass heavier
glass the optical path difference goes
from about two waves to five a to I'm
sorry about one maybe one and a half
waves to a quarter wave and if I go even
further
condenser glass than that I ultimately
I'm planning on a scale of two
thousandths of a wave so this is far
less than a thousand and that's one
method of making aberrations go away
another method is the configuration it
turns out that this I call the classical
configuration but if we curve this lens
element in the front in the opposite
direction so it's curved this way this
was two waves here this is 7 thousandths
of a wave and that's because we're
getting balancing of the three elements
so there's there's a lot of tricks to
the trade in this business this I only
made up a few days ago actually what
this shows is that if I go from actually
I should have started at index 1 and 1/2
way up here I then come down basically
with the other glasses I come down about
5 orders of magnitude of the spherical
aberration and that's a lot by orders of
magnitude
just by using a slightly different
glasses rather remarkable current state
of the art and digital cell phone
cameras I have an iPhone which I dearly
love I don't really know what's in it
but I do know a lot of things about it
that I want to say searchable on Google
is how I got there obviously typical
iPhone specs are 1/4 inch CCD measuring
this dimensions here the pixel size the
individual pixels are about 2.2 microns
on a side that's getting pretty small it
is said in the literature that in about
2 or 3 years we may be down at 1.2
microns pixel size and that would be
compatible or that would be indicative
of a 6 megapixel pixel sensor right now
the current iPhone is about 2 megapixels
and it's not bad
this is a lens which although it is
bigger than we like in terms of scale
the focal length is only this distance
here so in theory I could put one
element here but I would have lots of
the aberrations that I talked about in
any case this lens gives performance
that is actually quite good I'll show
you on the next slide how the image blur
mat compares to a pixel this is an airy
disc and that's a pretty good rendition
but these are the various specifications
which 1.92 which is close to two
megapixels so that would be compatible
with the iPhone except that it's too big
I think I'm going to skip the
spreadsheet this is a similar design I
believe I'm not going to compare the two
the pixel size is again 2.2 microns I
here this total length here is 17
millimeters this one is 9 millimeters
this one is four point six millimeters
this is what we will ultimately be
driving towards for the super super
compactness and the performance is not
quite as good as this one but there's
definitely hope and promise that it can
be brought to that level so that's kind
of at least close to the state of the
art that you would see in these cameras
the squares are 2 bytes 2.2 by 2.2
microns the airy disk is 2.4 microns in
diameter so this is taking a whole grid
of rays and sending them into the lens
at different positions from the center
of the field of view to the outer
periphery of the diagonal and most of
the energy does fall within a pixel I'm
not going to spend too much time on this
this is probably the most common metric
in terms of optical performance in
digital cameras and we see what's on
okay I'm doing fine and it's called the
MTF or modulation transfer function and
basically that is contrast I'm going to
call it here just think of the word
contrast versus line pairs per
millimeter and the higher the curve the
higher the contrast and basically if you
think of let's say I were to take a
white board up here and I would to take
black tape
one inch wide or to it let's say two
inches wide and I'll put a piece of tape
and then a space two inches and another
piece of tape everybody in the room
would be able to resolve those big
pieces of tape that are adjacent to no
tape and the white so it's black and
white and the contrast to your eyes is
going to be very high now let's see
who's had a good shirt for me to point
out I don't see any good shirts so let
me just say we instead of the two inch
white tape we take tape of a quarter of
an inch wide and then a space a quarter
of an
in a tape in a space eventually it's
going to get so small that the
aberrations are going to begin to
predominate and you'll begin to see
blurriness even from your eyes as a
matter of fact and that is the contrast
as the number of pieces of tape or the
number of line pairs per millimeter
increases so that's what that curve
means there's a circle energy which tell
us how much energy falls within a pixel
I'm not going to stay here very long
because I think the graphic is better to
see here's a very important point
I'm not never sure where to put this
slide but a word to the wise this is
another handy dandy tip to keep in your
mind if you have a lens here you'll say
it's it could be a camera lens it could
be anything but let's say you bought it
as a unit to look at infinity like a
camera lenses typically are used to do
and now you decide well what I really
want to do next Saturday morning is I
want to take my postage stamp collection
and I want to take close-up pictures of
my postage stamps where I put the stamp
here I move the image outward which is
from first-order optics what you need to
do and then I start taking pictures well
from infinity that's a pin point at
infinity a point source like a star
would be plotted the blur would be
plotted on a 25 micron scale of the
image plane or the sensor if I change if
I keep the lens exactly the same but
move the object to here the scale
increases here to 500 microns very very
significant difference so if your lens
was not designed for close-up
photography don't use it to that they
make what they call macro lenses which
are finite conjugate which means close
object close image but you could get
into a heap of trouble with that one
now well these are just to give you a
flavor for the most sophisticated form
of optical systems that you'll probably
ever come across its lenses for micro
lithography for doing the
step-and-repeat imaging and then there's
edging that takes place on the wafer and
so forth and so on and this is from a
paper given some years ago I'm not going
to go into the details of it but this is
about 17 lens elements and you can see
that each one bends the light a little
bit
or so the angles of incidence of being
minimized and that's how the aberrations
are gotten rid of I would like to show
with this slide this element here looks
like it can go away because it's not
really doing much of anything the light
comes in keeps going pretty straight and
comes out pretty well parallel to the
way it went in and if dr. glottal were
here with us this morning and I would
ask him why that lens is there he'd
refused to answer the question that's
because he doesn't speak any English
actually passed away three years ago so
that's another probably more pertinent
reason but all jokes aside this lens
probably could be gotten rid of so if
you ever deal in lens systems the
computer drove in this direction and the
mechanical design was probably finished
so they said hey leave the lens in there
this is a 30 element lens it's from a US
patent there's the patent number you can
see the very small incremental
redirection or bending if you will at
each one of the surfaces and therefore
the angles of incidence are small and
the aberrations are very very very low
this lens is probably capable of taking
a getting a five to one reduction
probably giving you submicron maybe 1/2
micron third of a micron spot diameter
for an excimer laser in the deep UV at
the final image this particular one is
the one from the previous slide just to
show that that was actually a hardware
design one of the aberrations that we
sometimes get into is distortion and the
thing to be careful of here is
distortion does not change your image
quality your resolution the MTF will be
virtually identical it's a Miss mapping
from your object grid which might be a
square grid like this so the image in
this case it's called pincushion
distortion this is called Beryl and it's
it's you can predict it to many decimal
points places it's a mapping error now
the eye doesn't like to see imagery that
looks like this that has that and I
think the next one shows different
amounts of distortion about two percent
is what we usually say that is the
maximum tolerable for a visual system if
the user
if it's designed such that the user will
barely barely notice it and of course we
can take a single element with with
polychromatic light and we'll find that
the blue light refracts more severely
than the green or the red and we get a
spreading of color here and that's what
we use the a chromatic doublet for it to
bring the red and the blue to a common
focus with a green D focused over to
their color fringing is prevalent in
binoculars and a lot of other visual
systems don't go home and throw your
binoculars away you've never noticed it
yet and today you're gonna look through
it when you get home you're gonna say oh
this the imagery is awful but just
remember you never noticed it before so
don't throw your binoculars away and
actually in all seriousness this is it
towards towards the outer periphery of
the field of view generally you take the
the quarterback of the football game and
you put put them at the center of the
field of view so you really don't notice
the color fringing at all in many cases
this is an important one it's a little
tough to explain but let me give it a
quick go here let me take a look at my
watch first okay if I take three
different image positions here and the
red blue and green have nothing to do
with wavelength they're just to
differentiate the different positions
and I put a compass point at the green
crossing the axis right there and I draw
a circle here and then I move to the
blue and I draw a circle here and the
red which is the space to the right of
course
I drew a shallower radius out here if I
do that in this distance between each
pair is 1/4 wavelength that says that
the imagery will be diffraction limited
or nearly so so this is taking this
quarter wave criteria and extending it
to what's called depth of focus so if I
move the image in or out from the green
to the blue to the red positions the the
light stays comes down at exactly the
same same way it did beforehand but it
will be almost indistinguishable from
diffraction limited because it's less
than a quarter wave the lens design
challenge is to leave these local minima
if this is what's called the error
function
the merit function this is the goodness
if you will of performance the lower the
curve the better the performance the
higher the worse the more image blur
there is and a computer program will
take you here and then you were varying
certain radii and air spaces and
thicknesses perhaps and then the
computer will bottom out here and will
say ok say figuratively ok what do you
want me to do next I've done everything
I can for you
well what you'd like to do is to jump
over this hump here and come out to a
better solution here and maybe even a
global minimum or where the performance
is the best possible well there's one
very important point that's missing here
this is what I've said so far has
nothing to do with manufacturability so
you might have a computer program that
will bring this to identically zero but
it may be very sensitive to
manufacturing tolerances which means so
what what good what have I bought and
that's a very very important ingredient
that the designer has to factor into the
design as the lens is being designed not
after the fact I like this one Wyeth
lens design fun this is sort of my
little commercial here we watch the
merit function which is the measure of
performance and that's equivalent to the
line of wheels here and if you think of
the watching the merit function proceed
just like playing a slot machine you
yourself will experience an
indescribable adrenaline rush and
satisfaction that lens designers have
experienced for many years and there is
some truth in that it's that you don't
know where the next iteration is going
to take you if I had more time I'd
expand on that a little bit more I'm
gonna skip that one
this shows a double Gauss lens for a
35-millimeter application it was in 1980
so the digital wasn't quite here yet
f2 30-degrees full field of view and one
of the problems that was sent around the
community of designers was to change it
to f5 for the bigger field of view and
we what the committee did that took this
on was to put together a report or a
paper that was published in the
Proceedings and here are 3 designs that
evolved let me look at the middle one
first this is contrast versus line pairs
per mil
I call this a happy lens what's a happy
lens a happy lens is where the bending
of the surfaces is fairly mundane angles
of incidents are not extreme aberrations
are relatively under control Packaging
is good it fits in your shirt pocket etc
this lens meeting the same specs has
worse contrast look at the angle of
incidence here in almost 90 degrees
awful absolutely unproduced to be
unproduced will not to mention the fact
that it's bigger in size and it has
other problems this one is almost a
combination sort of a hybrid between
these two and probably has the best
performance as well so if someone comes
comes up and says gee I got a beautiful
design for you and they show you this
drawing now you'll know enough to say no
well hack it the US patent system when
it comes to lenses is in a state of
confusion is what I would call it I'm
not sure what to call it I've taught my
course twice at the US Patent Office and
I had a wonderful audience to to speak
to at that point but basically these are
nine Cooke triplet patents each one is
different and they're all US patents and
I hasten to say the difference between
most of them is negligible 1924 1965
this is nineteen ninety two or three
it's right up here somewhere and I'm not
going to read through this but you'll
find a lot of patents if you do any
searching on Linde systems they give you
all kinds of inequalities that for me a
lot of its gobbledygook they're just
trying to whether Co barrier to entry is
what the term that's used point one
times the focal length is less than the
refractive index plus the focal length
of the second element which is less than
two times the focal length or something
like that mumbo-jumbo
last selection class is generally
characterized and I'm going to try to
speed up a little bit because I want to
finish on time let me just take a look
okay refractive index this way what's
called Ave number or dispersion this way
it's a reciprocal type of relationship
so the smaller
number the bigger the dispersion like a
prism would spread lights from across
the spectrum Aleister of one of my
colleagues Aleister wave at everybody
and I did some work for one of the
largest glass manufacturers to help them
learn how to use different glasses for
better performance and we basically
divided into six different categories we
call them balloons and one would be the
positive element in a multi element lens
low average dispersion very common glass
and then as we get to higher and higher
indices the aberrations decrease and
that says of lower amount of chromatic
aberration now very much of an aside I
just saw last week in one of the
journals that Cassio has introduced the
lens using a clear optical ceramic which
they claim has a very high index which
it probably does we can work we've had
sink sulphide that's clear for years and
years and it's probably as good or
better than what they're using so it's
it's a it might be just PR until I see
more about more about the material and
then some of the plastics are here Co
see acrylic polystyrene and
polycarbonate I'm not going to bore you
I don't think with this one all this
silver is a very important one but let
me keep going for the sake of time
digital camera is a case study this is
to me very interesting Nyquist frequency
is the maximum spatial frequency that
you can resolve without aliasing and
it's basically the frequency of the
non-ionic a bar the rows or columns of
these this pixelated sensor so this is a
pattern which matches exactly to the
Nyquist frequency bright dark bright
dark bright dark in synchronism with the
actual geometry this is under sampled
which means I have more spatial
frequency within a pixel so I can't
really resolve these things and this is
over sampled which is a much bigger
pattern
now here's the crux of it all this is
this is actually a true story all my
stories are true assume we require a new
lens for digital camera with a 30-inch
CCD now this is actually a stated after
my very first digital camera from Sony
this is the size that the sensor six
millimeters diagonal the focal length
was comparable to a 35-millimeter camera
with a 35 millimeter focal length and
the focal length here should be four
point eight millimeters to meet that
requirement f2 for low for adequate
sensitivity at low light levels I simply
picked that out of the air if I had 640
by 480 pixels be seven and a half micron
pixel pitch that's between adjacent
pixels and that's the necklace frequency
of sixty six point six I should have
changed that to symbol
line pairs per millimeter the
diffraction blur is 2.8 microns but the
pixel pitch is seven point five so we
have a mismatch here the Rayleigh
criteria says we have customized eight
point six microns depth of focus okay
now here's here's where the magic begins
this is a single element with a focal
length of about four point eight
millimeters very very small I can I call
it an aspirin tablet lens now when I
first bought the camera I looked at the
manual the manual said everything from
21 inches to infinity will be in focus I
said wait a minute that can't possibly
be with my ordinary lenses I focus on
the tip of somebody's nose and their
earlobe was fuzzy focus on their love
and their nose is fuzzy so what's going
on here what do they know that I don't
know well this is a relationship for
calculating how much the image moves or
it should be refocused as a function of
object distance which is where these red
dash rays would come be emanating from
position way out here somewhere so if I
so if I look at focusing the sensor
right at infinity that is to say the
black rays here focus right on the
sensor and then I move the object to 3
meters 2 meters one and a half a meter
the image distance will D focus by this
much
and if I leave the sensor where it is it
will create a disc of light zero because
that's where I start from from infinity
three point eight and so forth down to
eleven point five for one meter and at
21 inches which is approximately this
this distance here 23 microns well 23
microns is much bigger than a pixel so
the that's not acceptable in my book so
what I did is I said to myself ah I
think I figured it out and it worked out
perfectly
I nominally focused the lens at one
meter so one meter would be where the
black rays come to focus then I went I
went negative I gotta make sure I say
this right I go okay that's a 1 meter I
then go to infinity and 1/2 meter at
these two points and I get 23 microns
focus shift that creates a disc here
eleven and a half microns at 21 inches
at infinity now 21 microns
I'm sorry 11 and a half micron blur
diameter that's what I meant to say it's
about one and a half pixels that says in
my book the Sony camera with a VGA
sensor and a pixel pitch of
seven-and-a-half microns will focus
adequately from 21 inches to infinity
which was what I was hoping I'd prove
but that's why it's it's true and it's
true because of as the focal length gets
shorter and shorter and shorter the
amount of refocusing as a function of
object distance decreases with the
square of the distance or the focal
length of it very significant now if we
follow that some of the trail of digital
cameras we had quarter-inch chips
half-inch chips I'm not sure which
designation these are but they're
progressively larger and you can see the
size on some of them if I took this as
being the benchmark that is my Sony
camera lens the total length is about 14
millimeters focal length of 6.4 I put
the other 4.8 but anyway it's pretty
close to that if then I scaled up and in
order to go to the blue sensor instead
of the red one this was for the red this
is the blue I had to scale the lens up
three and a half times so before I had a
lens that was a little tiny little thing
sticking out the front of the camera now
I've got a bigger lens because my sensor
is bigger and if my sensor goes up to
this which is almost it's about 24 by 36
millimeters which is 35 millimeter film
dimensions
then I have a lens where I have to scale
it up five and a half times the focal
length 35 millimeters the whole lens is
a big hunker just like we were used to
in the latter days of film photography
so you have to be really cautious how
you design the lenses make them suitably
compact and so forth the market places
increased five times since 2000 the year
2000 for digital cameras sales in 2004
were 53 million cameras for the revenues
of 24 billion dollars in 2008 100
million cameras will be made and each
each one of them will probably have one
two or three aspheric surfaces I'm gonna
skip a few of these things testing I
really I just felt I should talk about
it I have already so I'm gonna skip that
this shows that for a perfect system and
a quarter wave this criteria for
diffraction limited performance and then
a half in one wave this is lower
intensity than this but the character of
the of the image of a point source is
very much the same and here we begin to
lose image quality rather rapidly now
I'm not gonna read all this but I'll
read just one or two points here in 2003
this was predicted I could should
probably car like that and see what it
really was but about 250 million glass a
spheres were manufactured and this is
largely in Japan for the Japanese camera
industry compression molding can go from
one millimeter diameter to 80
millimeters with typical diameters of
about an inch or a little bit less the
residual surfaces are good enough in
most cases so that you will maintain
your diffraction limited performance now
this is the aberration the spherical
aberration or check my oh I'm getting
real close here if I were to make this
curve flatter at the edge it would push
this rate to meet the paraxial ray and
all the Rays would meet there and that's
exactly what I'm going to show you in
the next slide this is lots of spherical
aberration the
shallower curve which is what's over
here also is such that all the light
focuses right to a point here so that's
by taking this steep spherical surface
and making it gradually flatter and
flatter and it's a hyperbolic shape this
is for correcting what's called the
stigmatism by putting a little rolled-up
edge towards the outer periphery of the
lens making it non spherical gets rid of
the astigmatism if I take a three
element cook triplet and I make all
spherical no contrast whatsoever down in
this region here one aspheric two ace
works three aspheric sand all aspheric
you can see the progression of the
performance getting better and better
this is the polaroid sx-70 camera it's a
beautiful device I just don't have time
to go into it here if anyone's
interested later I can discuss it with
you
that's a reflective system injection
molded lenses we had a project many
years ago where we had acrylic to
acrylic elements and this shows the
progression of the this is called it
into Farah gram and this shows the
departure from perfect shape more or
less like a topographical map and this
enables us to determine whether the
performance is adequate and I'm just
going to go through these pretty quickly
one of the elements was 28 millimeters
in diameter and an exaggerated profile
of the ACE ferocity is shown in red and
then we predicted MTF we predicted all
kinds of things and eventually the
system worked very well unfortunately
the project was cancelled and if you
look at some of these predictions here
and then I'm going to skip these but I'm
going to settle into one of these you
can see almost an exact duplication of
what we were predicting based on
measurements of the surface let's see
what else we can do here okay
well that was a pretty big study let me
tell you tolerances don't lie if a
quarter wave represents you you're
standing on the edge of the Grand Canyon
and someone gives you a little push
they're gonna introduce a quarter wave
figuratively to your position if they
push you much harder you're gonna fall
in and you'd be up to half wave in a
wave then you'll fall down you'll have
lots of aberration and the performance
will get bad very very fast so you've
got a little bit of margin built into
most good designs but not a lot this is
from a study Alistair did on 70 separate
lens elements comparing measured values
with what the specification was in the
spec was right along here at a hundred
percent of the tolerance level and then
what we found is that there was
something like 82 percent were within
their thickness specification that says
18 percent were out of spec now that's a
good optical shop good reputation and so
forth so one has to watch these
suppliers and vendors like a hawk this
is another cell phone application
diffractive optics should I keep going
or where am i two minutes okay can you
tell me what I have one minute okay
diffraction gratings are basically
rulings on a piece of substrate material
and we use diffraction let's say with my
favorite slide there it is an ordinary
lens the blue focus is here the green
and the red if this were a diffraction
grating the red because the wavelength
is longer focus is here that's out of
the grating equation than the green and
then the blue so basically you can have
with one material with a diffractive and
a spherical surface you can bring the
red and blue to a common focus and that
will be present in future designs that's
an IPS we have a patent on I'm not going
to worry about this is just fabrication
types of pictures as I said if you can
oh I'd love to tell you about it if
anybody is interested this is called
magnetorheological finishing one of the
more significant advances in
manufacturing probably in this century
or the last century stray light
suppression this is a true story I won't
tell you the whole story but I will say
that it's a friend of mine who had a
machine vision company
and basically he made a new camera and
he got stray reflections from the inside
walls which were anodized machined and
anodized and ultimately what we did is
we put low reflectance paper like flock
they call it inside of this and then in
addition we illuminated only what he was
interested in not holes half-acre down
here which was bare aluminum and his
performance got not only good but it got
better than it ever was more straight
light suppression for telescopes this is
the Cassini mission of my up to my
minute yes off the shelf optics I'm not
going to talk about this of time I think
that's actually the last one believe it
or not
now I'm gonna simply say here that
today's talk is the ever increasing
performance of digital imaging
specifically cameras and the
requirements must will continue to
improve of the optics it has to smaller
pixels smaller image blurs lower F
numbers more compact higher MTF and
contrast new lens technologies compact
zooms new lens materials like the Casio
more use of precision a spheres
diffractive and spherical surfaces
improves stray light control and lower
quest optics will all be required and
that's rather complex so fasten your
seatbelt hold on to the safety bar it's
going to be a very fantastic right into
the future of imaging optics</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>