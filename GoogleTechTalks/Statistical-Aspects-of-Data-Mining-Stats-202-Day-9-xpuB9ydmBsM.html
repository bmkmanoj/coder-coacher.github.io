<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Statistical Aspects of Data Mining (Stats 202) Day 9 | Coder Coacher - Coaching Coders</title><meta content="Statistical Aspects of Data Mining (Stats 202) Day 9 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Statistical Aspects of Data Mining (Stats 202) Day 9</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xpuB9ydmBsM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so today is lecture 9 for data
mining at Google there is a midterm exam
for the Stanford students this Friday's
are sorry this Thursday so we're not
gonna have class Friday and I'll send a
bound email reminding you about that
it's just so we stay in sync with them I
started to talk about Simpsons paradox
last time so we're going to review that
today I gave you a sort of a toy
textbook example last time I'm going to
give you the same numbers in a real
example this time and get you to think
about the implications of that I have
the homework solutions I'll just show
you the link to that I don't think we'll
go over any of those specifically and
this was a few that you want to see so
we'll probably get done pretty early
today if you're curious to see what's
what's on the midterm I can also send
around the midterm exam after the
students take it to the email list if
you want to take a look at the types of
questions and see how much you've
learned but basically I want to go over
some since paradox today which shouldn't
take too long so that's about the
midterm ok so chapter 6 on Association
analysis the mid to the Simpsons paradox
has talked about in section 6.7 I
believe and this was the example I gave
you last time where there's a third
possibly hidden variable right so the
variable could be something that's in
your data but you haven't thought about
it could be something that you could
measure but have chosen not to or it
could be something that you're
completely unaware of that's that's
causing the the paradox to occur and so
it occurs when this third possibly
hidden variable causes the observed
relationship between a pair of variables
to disappear reverse directions so for
an example here I'm looking at the
relationship between who is taking the
shots and how many are made or missed so
those are the two variables that I'm
looking at make or miss versus me and my
friend and from the aggregate data I see
that I'm making 50% of shots and my
friend is making 40% of shots which
leads me to believe that I am the better
shooter okay because I've made a higher
fraction of my shots than he has and for
some applications that would be of
interest right if I had to say
okay I need to pick one person to go
into the game to shoot a shot well if
they have to create their own shot and
they have to play in a similar style to
what they played when my friend and I
played then maybe I should go into the
game because I'm gonna have a higher
percentage of made shots however if I'm
putting a person to go into the game
to take a specific shot if that's the
question of who is the better shooter
means who is a better shooter for
shooting a specific shot then really I
should control the data for the type of
shot and the type of shot in this data
was was whether the shot was far and
close and what you see is that sort of
an aggregate remember in aggregate I'm a
50% shooter and my friend was a 40%
shooter so in aggregate when we're left
to our own devices to pick our own shot
and shoot our own shot I make a higher
percentage but when you control for the
distance that's when things get
different right so me from far remember
I was one out of four from far so I was
25% from far and my friend from far let
me go down here to my friend just split
these between me and my friend my friend
from far he shot 5 out of 15 so he is a
33% shooter from far-right 33.3 so he's
a better shooter than me from far away
and then you look at close and I from
close am 9 out of 16 so 9 out of 16 from
close that was 50 was that 54% 9/16 56%
56% from close and my friend from close
he is a 3 out of 5 so he's 60% from
close ok so what's happening my friend
is a better shooter than me from close
up and he's a better shooter than me
from far away right 60 versus 56 33
verse 25 so he shoots better than me
from close up and he shoots better than
me from far away but I wind up having a
higher overall percentage why because
I'm shooting more shots from close up
and he's shooting more shots from far
away and the far away shots are her to
make so obviously if you fix these two
ratios to be the same this thing
couldn't happen but as long as I'm
allowed to shoot more close shots which
are harder to make which are easier to
make sorry and he's shooting more far
shots which are harder to make then I
can wind up doing better and aggregate
when in fact he does better from every
from each specific distance and again
it's not so much a paradox as it comes
back to really what is your question you
know ones you just say who is the better
shooter it sounds like a simple enough
question
really what you have to do is ask the
person who's asking you this question
why do you want to know all right it
sounds like you're being defensive is
very shooter why do you want to know but
it's important because you say if you
want to know because you're gonna pick
one player to go into the game and
create their own shot then I'm the
better shooter but if you want to have
one player going the game to shoot a
specific shot from a specific distance
which may still be undetermined then my
friend would be the better shooter so it
really depends on the cluster now again
this is just the toy textbook example
what I wanted to use the same numbers
and show you sort of a more realistic
example so let me see if I can tell you
this story without sort of saying
anything that I can't say so a search
engine labels web pages as good or bad
okay so this you look at the web page
you say that's a good page it's a bad
page some measurement of quality okay
researcher is interested in studying the
relationship between the duration of the
time a user spends on the page so if you
were able to measure how long someone
spent on the page maybe you can think
about putting people in a lab and
looking how much time they spend on the
page and so you can record that as long
or short and then you know the good or
bad attribute so we have two variables
right how long they spend on the page
long or short and then what's the page
good or what's the page bad and so me
and my friend are taking the place here
of good and bad okay so let me here
actually know what I'm gonna leave up
I'm gonna leave this example up and then
just sort of redraw everything down here
so let's see the good pages alright if I
start with good the good pages are 50%
long right on a good page people stay
long 50% of time and on the bad pages
those are only 40% long right so in
aggregate it looks like what you want
people to do is to say for a long time
and this is sort of an open question
right because you can argue it both ways
you can say well if the page is good
they'll be happy with it and they'll
stay a long time but you can argue the
other way you can say if the page is is
good then they'll find what they want
right away and they don't need to stay a
long time right so reasonable people can
differ on their intuition in terms of
which way this should go but looking at
this aggregate data it suggests that the
good pages are long for
be personal in time whereas the bad
pages are long only 40% of time so it
argues for this case that if it's a good
page they're gonna stay a long time it
argues for the positive association
between duration and quality okay so you
say sort of you know period under the
end of the story problem solved and so
you say okay great now how are you going
to use this information okay what what
information relationship between quality
and duration going to influence you
well they'll say well now that you've
done all this great work and you've
showed us that there's a positive
association between quality and duration
because before we didn't know you know
we thought it could go either way we
thought if they're staying a long time
it could because they can't find what
they want or because they're happy now
we think it's because they're happy so
now what we're going to do is we're
gonna track our quality knowing that our
quality has a positive relationship with
duration so we're just gonna plot here
duration on the y-axis and on the x-axis
we're going to put this could be time
right so day 1 day 2 day 3 and we're
gonna track the duration over time and
so how am i measuring duration you know
sort of maybe that the total number of
seconds people stay on all pages okay
some some aggregate measure of duration
and then when I see something happen
right so right here some time points
something happens what happens what am I
looking for well someone has changed the
search results that are being served
right someone has sort of changed the
magic formula and now we're gonna serve
different search results so what I want
to know is what's going to happen to the
average duration well suppose that it
goes up okay so right here there's been
a change okay they changed from using
sort of one algorithm to serve the
search results to another algorithm and
they say great now we know that this
change was positive because it resulted
in people staying on the pages for a
longer time okay the problem is right
the original question which just said
what's the relationship in aggregate
right between duration and goodness
you know they never really told me that
this was going to be the specific
application and one thing now when I see
the specific application and I realize
what they're changing okay has to do
with the quality of the results I know
that in particular there's one thing
they're not changing that I should
probably
control4 and one of the biggest
influences on whether a webpage is good
or bad depends on what the query right
so if I type in that query amazon.com
there's a lot of good webpages for that
if I type in the query you know what is
the biggest country in Texas
well the cut Texas doesn't have country
isn't it right so there's probably not a
good lot of good webpages for that if I
type in a a b b b c CC d DF right
there's probably not a lot of good
webpages for that so the query arguably
is very important furthermore when you
see this right you see this change I'm
affecting the quality of the web results
I'm not affecting the queries that are
being issued okay so the query stream
isn't the changes in the query stream
are not something I'm interested in
picking up I'm interested in picking up
for the same query what is that what is
the quality of the web results for the
same query so arguably in this analysis
I should not be looking at aggregate
data I should be controlling for query
why because one I know it's a huge
source of variation and - I'm not
looking in I'm not looking to measure
changes as a result of the query stream
change and I'm looking at measuring
changes as a result of changing results
for the same query so arguably I know
already I should be controlling for
query so then when you look at the data
right of course again it's the same
numbers but we'll tell the story here
right so break down the good pages and
the bad pages into the type of query now
there's millions of types of queries the
one thing about whether this variable is
even measurable right I mean queries
don't come with their own labels you
would have to do some sort of labeling
in fact you could treat each query as
its own category if you want here I sort
of did an obvious split between adult
queries and non adult queries but you
know this could be any sort of
distinction you want but the problem of
you know thinking back to Simpsons
paradox talking about sorry talking
about a possibly hidden variable well
you know it's not really hidden but you
would have to do some work to do this
classification in two different types of
queries so here I just made a
classification into adult and not adult
and what we're going to do is we're
going to look at each one separately
right so the good queries which are 50%
long if you break these down into adult
and non adult
so adult and non adult okay so the dolt
queries are one out of four twenty five
percent long right these are 25 percent
long okay and sorry so I'm thinking
about what percent along with their
twenty five percent for the adult
queries here okay yeah they're 25% long
that's what I wanted to say and then the
non adult queries if I look at the non
adult Chris for the good these are 9 out
of 16 which is the 56% long okay and
then let me do the same thing for the
bad web pages so the adult ones here are
5 out of 15 percent long 5 out of 15 so
that's 33% long for the adult and then
the non adult of course these guys are
gonna be 3 out of 5 or 60% long ok so
what's the story the story is that if
you look at the adult queries the good
ones are 25% long and the bad ones are
33% long so on the adult queries it
seems like you don't want them to stay a
long time it seems like the quality in
the duration have a negative
relationship right on the adult queries
the good ones are 25% long the bad ones
are 33% long so I'd rather have people
not staying a long time to me that would
indicate that I'm giving them good pages
same same things for the non adult yeah
right the good pages are 56% long and
the bad pages are 60% long so also on
the non adult I don't want people to
stay a long time if they're not staying
a long time that's positive association
with good right so there's a negative
relationship again between duration and
quality which is arguing that if the
page is good they're not they're not
going to stay a long time okay so it's
the same stories with the basketball
right remember the story with the
basketball was that my friend shoots a
lot more further shots which are harder
to make with this one the bad queries
are much more often adult which are much
more often short so this relationship
I'm seeing the
twing twing bad and short isn't really
that direct it's really like bad implies
adult which implies short okay
so then once you control for the query
type and you look at adult and non adult
by themselves you realize that the
relationship completely it reverses so
then when you go back to this graph and
you see an uptick in the graph in
duration you say well either you know
for adult or not adult in either case
this is a bad thing
you don't want a long duration so it
completely changes your analysis right
whether or not you control for query or
don't control for queries so the
question of whether you should be
controlling for query really depends on
their way in which the data is going to
be used if you're looking at this to
sort of measure whether people are you
know sort of happier as a result of
changes in the query stream then you
shouldn't control the query but if
you're trying to see if people are
happier for the same queries which is
what we're trying to do then you should
control for the query you know
controlling for the query isn't that
simple right as I mentioned to you first
of all adult and non adult queries don't
come pre labeled you would have to do
some labeling maybe this isn't enough
categories okay maybe you want a
separate category for every query well
you know if you're using software
packages you know some of them only
handles so many categories if you want a
separate category for every query you
might sort of things may not work
furthermore even though you had a lot of
data for some queries you may not have a
lot of data so what looks starts out as
a lot of data if you can't if you're not
really allowed to aggregate then it
becomes you know not much data and then
what do you do
you know if in this case you know long
is always bad but what if in some of the
queries long is bad and some of the
other queries long is good then sort of
this sort of analysis really depends on
which type of queries are affecting some
queries you want them to become longer
some queries you don't want them to
become longer so maybe it's not really
even a good metric in the first place
because it would depend on sort of
whether this change is affecting one
type of query or another type of query
so you really you know the whole thing
of Simpsons paradox again I think it
trivializes it to call it a paradox and
to make these sort of cute textbook
examples it really comes down to
formulating the question very
specifically and you look at this
question to me this is an example of a
poorly formulated question whenever
someone says I want to study the
relationship between something right
like you know you can say the
relationship in a lot of different way
the question is once you have the
knowledge of that relationship how are
you going to use that information if I'm
going to be using it to track quality as
a you know by using duration as a
surrogate for quality well the first
thing I know is I should be controlling
for things like query and you know all
these other things come up so you really
need to you know when someone says hey
analyze this data because I'm trying to
find out this relationship or analyze
this data you know because I want to
know this but why do you want to know
that you know is it because you want to
know it because who should you put in
the game to create their own shot who
should you put in the game to shoot a
specific shot you know should duration
be thought of as a surrogate for quality
when I make changes that don't affect
the query stream would do affect the
result so it really comes down to sort
of knowing what you should control for
knowing what you should put in your
model knowing what you should be able to
aggregate over knowing what you
shouldn't be able to agree over the
other thing of course that people have
mentioned I think mentioned last time is
the only way this can happen is if these
proportions are different right and so
in an experiment from experimental data
this generally wouldn't be a problem
because you could control or randomize
for such things in an experiment and you
wouldn't let these marginal totals
differ by so much however data mining is
you know rarely based on experimental
data so this is often always a problem
if you want to know sort of how these
ratios have to differ this is one
example I'll show you the homework let
me just sort of mention this to you I
don't even know if I have an internet
connection so well that's the first
thing I'll try I probably don't know
okay so let me just show you the
homework then on this one so let's see
homework is here and one of the homework
problems I asked so this resulting from
stats 202 calm so you can see here let's
see here's a question about this my
friend or not number nine here my friend
and I play basketball I make 70% of my
long long non long shots and 40% of my
long shots he makes 60% of his non long
shots 20% of long shots letting pf2 note
the percent of my friend shots which are
long and PM denoted the percent of my
shots which are long what relationship
must hold an order between p.m. and PF
in order for my friend to make a higher
overall percentage so if my friend is
gonna make a higher overall percentage
you know you know that he needs to shoot
fewer long shots than I do right because
the long shots are hard to make and he's
worse at them than I am and he's worse
he's worse today
right he's he's 60 versus 70 and he's 20
versus 40 he's worse than I am but the
only way he's gonna beat me is if he
shoots fewer fewer long shots right so
his his PF his ratio of long shots his
percentage of long shots must be less
than my rate my percentage of long shots
p.m. so you know PF has to be less than
p.m. if you want to figure out exactly
what the relationship is how much less
that needs to be you can sort of go
through the math and it becomes a linear
relationship and again if they're equal
there's no way it could happen so he has
to shoot a higher fraction of long shots
so I lower fraction of long shots than I
do and in particular here's the math
right so you start out basically this is
how many shots I make right to make 40
percent of my long shots and 70 percent
of mine on long shots 1 minus p.m. would
be my long shots he makes 20% of his
long shots and 60% of his non long shots
so 1 minus PF would be the percent of
his long shots so you simply go through
you know the algebra and you see that
the proportion of my friends shots which
are long has to be less than mine times
0.75 minus 0.25 that's sort of what the
math gives you and you could work this
out in general by replacing you know
this these numbers with just arbitrary
constants and so you see right away he
has to shoot a lower fraction of long
shots if he's going to beat me and it
has to be you know lower by this
relationship so in particular right if
this were 0 this would say it has to be
negative so it can't happen right if I
don't shoot any long shots he's never
gonna beat me in fact even if this was
um you know like 0.25 then this would be
still negative so I I myself have to
shoot a sufficiently high fraction of
long shots for him to even have a chance
to sort of sneak in there under me and
beat me so that's sort of one of the
homework problems and if you look on the
stats to a to.com web page you can click
on although you can see all the homework
problems up there and I also have all
the solutions links so you're welcome to
go through some of those if you want to
practice sort of other problems like
this and see the type of horn problems
that the students on the class do and
that's sort of the one I asked them to
sort of investigate this relationship
and appreciate what's going on here so I
think this is all I wanted to say about
this one example I have one more short
example of Simpsons paradox
but let me pause and ask if anyone wants
to say anything about this example which
before you asked it's not real okay okay
so that's sort of the story there so the
last one I want to say is in the two
examples I've given you for Simpsons
paradox all three variables right the
two variables that you that you know
about right away right good versus bad
long versus short as well as the third
variable type of query they've all been
categorical right so we've looked at the
relationship between two categorical
variables being influenced by a third
categorical variable now of course any
of these could also be numerical now all
of chapter six tends to deal with
categorical variables but you can
imagine what the story is when this when
these variables are numerical and when
things are numerical we're measuring
association with correlation right the
coefficient of correlation so I already
sort of warned you about some things
with that but this would be sort of the
classic textbook example involving
numeric variables and Simpsons paradox
right so you look at this and you say
you hear people say things like this
right all the time right height and
reading ability are strongly correlated
in grade schools right so if you know if
I if I get if my child is tall he's
gonna read better something like that
right and it gets even sort of more
absurd like neither of these are two
things you know I can really control but
if this was something like you know
income or something you know maybe I
should go out and earn more money so my
kid will read better or something like
that right it gets even more more funny
when there are things that you can
control but high in reading ability I
can't control but they have a positive
correlation in grade school why well so
you know there's probably some third
variable but you look at this and you
say well in grade school first of all
you know the biggest source of variation
is not the height or the reading ability
the main source well
sorry the biggest source of variation
influencing the reading ability is not
the height but rather the age right of
course the younger students don't know
how to read as well as the older
students so assuming this is a test that
doesn't control for age then you say
well like here's all the first graders
right and they're all very short right
and they're all very they can't read
very well right so this is how well they
read and so now both of these I'm
measuring the both of these are numeric
variables right before I had categorical
variables but now they're numeric so
here's all the first graders and then
here's all the sixth graders
and so you say okay there's a positive
association right and so you say really
what you should be doing is controlling
for age this is young and this is old
but you haven't controlled for it so it
looks like there's a positive
relationship
in fact what can even happen just to go
further right height and reading ability
you could actually have variables well
let's not let's not call them height a
meeting a building anymore because they
these these are unrelated truly probably
right but you could have two variables
that actually do have a relationship and
it could be a negative relationship
right so this is a negative relationship
and then in the other group it could
also have a negative relationship right
so here's the first graders whatever
these two variables are also has a
negative relationship for the first
graders but if you just analyze this
data in aggregate and you say give me
the least squares line that fits all the
data best compute the correlation
coefficient for all this data that's
going to be the line right it's gonna
look like it has a positive relationship
so it's the same thing as Simpsons
paradox there's a negative relationship
or in this case no relationship if you
control for the age but if you don't
control for the age there's a positive
relationship now you say okay this is a
trivial example I would never make such
a stupid mistake but the other thing
that happens is like you don't just have
one two three variables you have a
thousand variables and depending on
which ones you put in there the
relationships can reverse or not reverse
could become positive become negative so
you really have to think what variable
should you be controlling for and what
variables is okay to aggregate over okay
I mean the solution isn't to control for
everything but in this case obviously
you should be controlling for age if
you're really trying to build a model
that can predict you know reading
ability within a class now if if the
other question though if the question is
like you're gonna give me a person I'm
gonna close my eyes and the only thing I
get to know is how tall they are and I
have to sort of play a prediction game
predicted or reading ability based on
only knowing how tall they are then I
would like to use this model if that's
really what the game is predict how well
someone reads predict how well a grade
school kid reads based on how tall he is
okay you know if you have two kids right
and one is you know an 8th grader and
the other is a first grader and you have
to differentiate which one of your kids
is reading the story to you if you knew
how tall they were then you you
it'd be good right but if the real story
is sort of study the relationship
between height and reading ability you
know argue levy argued arguably you want
to control for age so it's it really
depends on you know how descriptive is
the model supposed to be versus how
predictive is it is also an issue to and
if the only thing you get to know is the
height the positive relationship is
meaningful but if you have the age
around you probably want to control for
it and learn what the relationship is
conditional on the age so this is my
example of Simpsons paradox with numeric
variables any any comments on that again
that the textbook problems seem trivial
and you think I would never make such a
stupid stupid mistake but when you get a
real data set with hundreds of
predictors and you're looking at the
relationship between two variables
knowing which other variables you want
to control for is important and knowing
that really depends on sort of the
problem of formulation and exactly what
you hope to use the relationship for so
I didn't give you sort of a real example
to go with this one but I gave you that
so let's see um link I said in class in
in the campus today I went over the
homework problems and all the solutions
are posted up online you can follow a
link that takes you to a page that looks
like see if I can show you this a page
that looks like this and so I have a PDF
document with each one of the homework
solutions and so if you go to stats to
atour comm you can go through those
homework problems and read those
solutions I'm not going to take time to
go through any of these unless there's
any that you happen to see online that
you want to see so we'll probably get
done pretty quickly today the only other
thing I wanted to mention is that I have
a few sample midterm questions if you're
just curious sort of what questions are
on the midterm and I can if you remind
me I can email you around the midterm
and also the solutions if you want to go
through and test yourself on what you've
learned this you know chapter one just
by way of review we basically talked
about what data mining is and this a
here is the question the answer that was
in your textbook for the definition of
data mining the process of automatically
discovering useful information large
data repositories these are also viable
definitions but we just sort of got them
all online we talked about this nominal
versus ordinal interval ratio so your
height measured as short meaning we're
tall this would be example of ordinal
right it's not nominal because if I
permute the labels i've lost information
however it's not interval because I have
no reason to think that the spacing
between short medium and tall is equally
spacing in fact if you've ever sort of
thought about this problem there's sort
of an interesting optimization problem
if you look at like so suppose this is
the distribution of the lengths of
people's feet right so most people you
know their feet are this long but some
people have really long feet and some
people have really short feet okay so
assume these are all like adult males or
something okay so now you say okay shoe
sizes have to be you know one no there's
no one right two three four five six
seven eight up through you know some
sixteen or something like that right
that these are the shoe sizes I can
stock in my store I'm not going to stock
an infinite number of shoe size I'm
gonna stock a finite number of shoe
sizes so now I have to split these up
well you can see it would be suboptimal
to split this up equally spaced right
really what you want to do is near the
mode you want to have a finer
partitioning then you have near the
tails right because what are you trying
to do if you're trying to minimize some
loss function that looks like you know
the let's just say like the expected
value of you know your true length of
your foot - the shoe size the length of
the shoe size I give you you know like
you could look like squared error loss
you're gonna do much better if you have
a finer partitioning here and the
coarser partitioning in the tails
because you can make most people really
happy and a minority the people really
upset is going to be better than sort of
making everyone equally happy okay so
this becomes sort of like an
optimization problem it's actually
equivalent if you were doing
quantization right so you know you can
imagine then if I call you know if you
say very short short medium tall very
tall super tall you can imagine that
there's no reason to think that the
distances between these would be the
same and so you get yourself in trouble
when people say well I'm just going to
code this as one two three and then
compute a mean because you you're the
mean is sort of assuming that this is
linear right and in fact it's not and so
that's why we call this thing ordinal
and not interval if the distances are
all the same we're corresponding to
something where the distances were all
the same then we could call it interval
but it's not so it falls right here into
ordinal although you'll see people
abused this and
ten times just sort of numerically code
it and compute means don't assume that
it's interval but truly it's not okay so
that's that problem here is a question I
put on just to you know knock all the
people that are sort of zero based I
guess right so I want the third column
in our and so in our our is one base so
the third column would be data
nothing comma three that would give me
the third column and of course square
brackets are the right thing to use not
not round brackets so there's just sort
of a question about how to do things in
our that I put up there this one I think
we did this one in class compute the
confidence for the Association role BD
implies a so the numerator would be
everything that has the triple right how
many have a B and D one two just count
up all the ones that have a B and D and
the denominator would be the B and D
count up all the ones that have B and D
and that would give you a fraction which
is called the confidence and then what
does this value mean well that means
that whatever that number is of all the
people that bought B and D that person
that people also bought a so I've put
questions like this on the midterm just
to test support and confidence here's
sort of a question about you know if you
have data that's space delimited what
should be done to allow for a text
string that includes a space so the our
Excel will not split on that space well
of course you should escape it and you
remember we talked a little bit about
that and I showed the Wikipedia article
for that and then this question here is
the trivial example where I asked people
if I give you some numbers compute the
standard deviation so I give people
three numbers which is sort of the
simplest example you can have and ask
them to compute the standard deviation
by hand so there's a few questions that
aren't multiple-choice on it that exam
but you see they're all pretty
straightforward so that's really all I
was going to say today just in terms of
talking about how the class goes from
here on out so I told you we're not
going to have Friday what we will do
though starting next week is the
following so we've gone through the
introduction the data exploring data and
then we did a little bit of Association
analysis just to sort of give you an
introduction to that so arguably
chapters 1 2 &amp;amp; 3 you could have learned
all this in the basic stat class
Association analysis would be you know
not in a basic stat class but we didn't
do anything there that was that involved
I basically wanted to show you one
formulation of the problem and the type
of data that people get and give you an
introduction to that most of the
textbook really talks about algorithms
for solving the problem so it's not
really that interesting either but we
had a brief introduction to that ok so
then we have the midterm which is why we
don't have class on Friday then chapter
is four or five and eight deal with
classification so classification is
pretty much you know my favorite topic
arguably after sort of the graphing so
we'll spend a lot of time on
classification chapter 4 will basically
do decision trees and then we'll talk
about ROC curve training error test
error overfitting basic concepts for
classification and we'll use decision
trees as our example and talk about how
our decision tree is grown and sort of
the greedy approach to drawing decision
trees and compute the Gini index and and
then prune based on classification and
things like that then chapter 5 talks
about alternative techniques that's
where we'll really get into some of the
real classification techniques we use
we'll probably talk about nearest
neighbors as a simple example
we'll talk hopefully about some of the
methods like bagging and boosting
probably a few comments about support
vector machines I'm not sure how many of
these topics we'll have time to get into
but if we've laid a good foundation
chapter four then hopefully we can get
through these at least enough to show
you
oh here's the R function that calls it
and you know here's how its performance
and here are the pluses and minuses of
it and here's basically what it's trying
to do and then that'll leave chapter
eight with some cluster analysis which
will do sort of the last lecture or
lecture and a half maybe to talk about
cluster analysis which I'm not as big
into clustering as I am in
classification so we'll spend more time
on classification but these are
basically the two topics that are less
so so no class on Friday but then on
chapter on Tuesday we'll start on
classification in Chapter four if you
want to look at that okay that's it any
questions before we take off okay so
I'll see you on Tuesday and we'll start
classification then</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>