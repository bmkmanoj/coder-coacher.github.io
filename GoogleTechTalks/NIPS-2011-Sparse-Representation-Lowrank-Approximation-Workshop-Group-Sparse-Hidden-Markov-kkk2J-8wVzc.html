<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Group Sparse Hidden Markov... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Group Sparse Hidden Markov... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Group Sparse Hidden Markov...</b></h2><h5 class="post__date">2012-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kkk2J-8wVzc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is my student this is owner of this
presentation in carrozza introduction
speech opposition and then I don't
experiment and computer controls as we
know I the bottom others have been
successfully developed for speech
recognition and many other equations are
people usually I use a rest man i'd
estimate is to mention to estimate and
culture mental models but this it is
easy to get over the department
especially us each day night during
unconnected Virginia's environment with
no it'll impress always his favorite
problem is puzzling a problem so model
regulation sir information across
distribution is Pedro gaming system are
our instruments which features from
speech signal are you Junior Richard a
baleful frequency and control division
to the container of nature of human body
11 I use our artists model based on
tomorrow models to perform a syllable
biometric and then we obtain a syllable
latest that we perform our Seles
mention place and language model then
finally we are china recognize sentence
and then we usually are user Lisa left
to right without skipping a local
topology to to model the behavior of
speech utterance when you use a poor
natives up our check a tradition
probability to to mother the transition
from one frame to the other friend and
this is at a very a special process in
the way we usually I use alyssa polymer
to to calculate left block library
function are we here x is a bunch of a
speech sentences a baby brother each
caucus and then we calculate our likely
body habitual speech friends and the
connecting mother transition probability
a and for each observation in a pit the
bottom of the state i'll reduce
culturally two models with me a mature
way and we can be few and the piece to
match up in the way are the matter
validation of this study are given below
we are challenger power these are
existing hit a macro models are good
enough for four hours Mallory and is
which features corresponding to it in
another state and can we change the
matter structure and we are wondering
how can we share the model parameters
for different lots of models and the
whole family in hand in his individual
state information on 441 state in the
limo we are we are question about how
can we be a very large model for for
speech recognition so a recent arena I
and my colleague IBM physical self are
we presented a very high-performance
model code and patiences in the
automatics and this model we represent
update half by a bunch of basis vectors
we don't use an acyl optimization we
follow up relevance vector machine our
Medusa Gaussian distribution to
represent a weight sensing weight and in
this book are we we estimate a state are
dependent compact dictionary and the we
are representing our reconstruction era
but train observe engine and the places
representation using a Gaussian
distribution with zero mean and the
precision eyes and there are and this a
Gaussian distribution is easy to be
sparse because we have a gamma
distribution for the precision our
parameter and this other parameter is
the kind of chaotic or fermented
government's determination and in the
patience and hit the macro models we
have stained dependent dictionary we has
the defendant our procedure matrix in
the modern era we have state dependent
ard so that the older model of design
for the cheetah mathematics and the list
is the this is almost the best
speech recognition sofa is very state of
art and in this work are we we are we
are seeking a different way are we are
we are thinking of more specific I
yamaha models and the way we will try to
guess i will try to represent a speech
feature by groups of basis vectors and
then we use actually ha estas right we
deserve our passion as curvature
distribution and only use patient
approach in Decemeber estimation an amex
plus introducer visceral emotional
sparse coding which just a person less
honest I using this as the skirting are
our passion our scrimmage of education
is used this distribution is obtained by
our ETA inverse tan skin I think as a
comedy solution Thank You mr. la Russian
intervention and because of our national
karma are conjugated so the marginal
distribution marginalizing our x
approaches there with your distribution
is this this form and the list tradition
is even as faster than prostitution so
when we use a list solution for sparse
coding we we represent a syncopation the
single simple so we estimate parameters
we miss them since equate we are
minimizing adam of negative are not
posterior distribution and because of
the other hand very very kind of
destinations of young up we should be of
prime instead we estimate based
aboriginal
and the day we find a weight in the
weekend our formula this optimization is
weighted error one recognized objective
function I anissa waited every one
recommendation objective function this
is on Sam Sparro modern and this is a
kind so far ELISA oh wait so so here is
a weighted la so the Cowichan are so is
the varsity control parameter heka at
which can be calculated in confirmed by
this way another are the grouping of the
the basics representation can be done
for the non overlapping group case can
we also done by a for the top of the
wrinkles and in the mist our first
coating life is designed for the
representation of syncopation Papa him
in his speech recognition of the many
other applications with do is not only
simple week video is a pawn shop or
speech covers a large corpus we can
learn a lot de how we want to hit among
model to organize that the state our
information and individual settlement is
a kind of segmentation and labor in the
water and then it is idea in this data
we we just simply are used two groups of
basis vectors to represent our speech
features when is koda common basis the
other is called individual basis a
common basis are used to represent a
speech features are over different
actual states and the individual basis
here I are used to represent each
features within
stated so we want to use a some are
common are common muttering and
individual bothering to enhance the
hidden love bubble for speech
recognition and this is the the mother
is quite similar to cruise our feet are
theses common our bases psi star
individual basis and their theory we
introduce our limoges damage of the
tribution to to force them as positive
vision in the arm we have our 26 area it
so we have four sets of parameters in
the proofs fast with amon amarth a wine
is a wait wait for the common basis are
wait for the individual basis and also
common basis and individual basis we
have four sets of parameters to be
estimated and we could use a man and we
mix max r minus h 0 ER we minimize minus
blog post earring is our maximum across
Europe incentive and here are we
introduce a prime folder for the deaf
for the problem wait to be the flashes
curvature and then we use caution to the
presenter dictionary for trooper
optician airy and then we yeah we use a
human region and we will reuse in the
east end we kill t-they're oxidative
function in the oxygen from here up I is
a calculation over order all the singles
all the data corresponding to the Hastur
see so are we very optimal is our oxygen
function and to perform
stick in differentiation with respect to
down and we fly this solution and this
is solution of went for the comma wait
this is solution for the individual way
to and and then we can see our follow
wait for the common are common basis are
we have a see index here is a easy easy
is a count of all the tempo
corresponding to the cluster C by name
individual session with dr. pc index you
in the when we estimate basis vectors
for for common are common hour basis we
do the same thing but here we only
concern a common basis and here are the
calculation of auxiliary function is
also done for all samples of responding
to the cranston see here the the key
difference in hit a macro models and we
have this a posterior probability and
this is a occupation popular means are
the probability of the same for a given
the current estimate so is this
probability read we can Alec we can
estimate are hittable model parameters
and the in calculation of this our
campuses we take differentiation and the
city from zero and then we find on this
is our correspondent dictionary a
solution also here we can notice an in
calculation of common
basically the cementing here is all a
tempura corresponding to constancy and
the father individual basis are we don't
have this is tent but we have similar
form of the resolution and here are when
we can see our basis vectors are upon a
common group and a basic founders
individual group I used to spend the
subspaces could represent that we say
our interstate relations and the
intrastate variation respectively in the
implementation of a traditional need to
use a vital region to perform dynamic
programming to find the best state
sequence for the input our stitch
entrance in the here is a powerful
mother our voyage a simple XTS Maxwell's
difference what we have our kilometres
stab you find of vc is a comma of
Philistines our state in entered and the
way other state is transition time I
time and the entire control parameter
for the sparsity of that this is a
flowchart a liquid imprint I used to
implement a across vastly the macro
model for speech recognition this is
training pass mrs. test pass in turn
passed away of elimination and the we
estimated parameters basil neck and the
Richard conversions finally we estimate
postbus economic models for fall asleep
exactly and then I statement we perform
our a noisy speech recognition to
evaluate our course basket about others
Toronto is a very standard pissed at ask
for for speech recognition it's a is an
English community to be different noise
environments we have two cases of 20 why
is a mighty condition training including
and now we stayed high in in the in the
training they hug when you train the
models and the other case is a we don't
have no is Dana just use creator to
Trinity remodel but but the piston how
we have noise the data to be cast in the
we treat a certain level so that the
dimension is 39 mfcc paste feature
vectors this is quiet in during the
speech recognition I'm including our 12
RM FCC and Allah contention that there's
a free soda the second order derivatives
and they tested how we recover different
enormous type and click Ferguson up and
evolved into our for each nice condition
we have 1000 speech sentences in the
Reno experimental setup an inspector and
the motto motto each world each each
digit is represented by 16 states and
the three cultures and shadow can meet
us here we select rounded edge antenna
and there are we are we we compare our
apples
ramada understand I need a macro model
with a comparable model complexity and
there are the recognition rates are
averaged over different noise tax and I
people with us here this is a a
different accuracy in different and snr
about using current training and the
market condition training in Caen
internet marketing we have a snack hmm
Postmaster General and we can see are
here we don't perform any speaker at the
paging or any other noise robust
technique we just performed a very base
our best night the macro model and goes
fast enough mud and we can see in my
condition training we are we can see
Louis de knives including the training
zone performanc higher than French any
and that we can see are the the higher
and higher accuracy Emily the most
important thing we we got our tennis
promised land best line in the Mahamaya
movement so this is a conclusion the
future work in this book we present
course bus it apart from others for
sequential pattern recognition not just
only for one what my simple coding not
just only four
for the Commission and I will be a two
groups of basis vectors for former
presenter as each features later than
base map and there are la plage
spiritually tribution was introduced for
sparse representation and in the future
are we we are thinking how to determine
number of bases in different words
invested yet and the other Louis robust
lesser can be combined to improve the
whole performance and then in the future
we are conducting more larger scale
speech recognition task so they're like
some other our nation
did not approach using pizza so
estimating the parameters of amar Kabal
find observations it was an expectation
maximization as a lot of so there is a
modern algorithm how you find the H
naught prime opportunity we have been
invested in this direction but I a guide
Alyssa this is in his speech recognition
society and people are using an air
bubble tea I've done maybe nothing too
much under other issues in the
optimization problem we don't think we
don't investigate on this message maybe
I just curious how is your other tools
to work with speech recognition pass
well means well all the PM is good it
has limitations the question
so in your model you use a basic but
eventually if I understand well your
algorithm is your own privacy in the
States but you are solving each of the
position on the dictionaries so you
don't both model the latent variable
little de cristian coefficients focus
that's right and possible to do the same
thing goodbye I think the Lincoln
variables here at each sake got a
dictionary fee right we've got the
questions w right right right now in the
first operational presented w was always
way here isn't that you're maximizing
your shopping
yeah yeah I don't think too much on
state we have major component in mother
sometimes we can say under control
parameter is also learning so they have
variable can be stopped in different way
actually I uniform akita motto motto
contain different latent variables yeah
not just a the Clayton variable for
sparse coding but also get a miracle for
Mitchell components of states they are
but I don't think too much on how this
variable</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>