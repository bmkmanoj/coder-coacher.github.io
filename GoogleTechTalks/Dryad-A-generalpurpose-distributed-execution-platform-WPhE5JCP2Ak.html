<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dryad: A general-purpose distributed execution platform | Coder Coacher - Coaching Coders</title><meta content="Dryad: A general-purpose distributed execution platform - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dryad: A general-purpose distributed execution platform</b></h2><h5 class="post__date">2007-11-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WPhE5JCP2Ak" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Chris Callahan and I work on
the indexing team and I just wanted to
actually quickly introduce our
distinguished visitor today
today we have with us Michael lizard and
he's brought along with us in the front
row here a large contingent of the Dryad
team from Microsoft and so he's gonna be
talking about the Dryad distributed
computation system which is Microsoft's
superset you could argue of MapReduce
it's a more flexible version of
MapReduce and he'll tell you all about
it and it's very interesting research
and I believe they also use it for real
production systems Michael is a
distinguished researcher from Microsoft
he's worked for Dec and Compaq in the
past and I guess I'll just let him take
it from here I'm also a quick reminder
from the AV folks this talk is being
video conference two other sites and
they can't hear you asking questions so
if you have questions at the end please
go up to the microphone also this talk
is being recorded to be put externally
on YouTube after the talks so if you
want to talk about your ultra secret
confidential projects and share them
with Microsoft please do so away from
the microphone after the talk
thank you yes I'm going to talk about
the Dryad project which is research
mostly done a year or two ago with these
co-authors some of whom are here behind
you honor here you can talk to them
afterwards so I've given a bunch of
dried talks now almost certainly none to
an audience this specialized so I'm
gonna skip very quickly over the
motivation of why anybody might care
about distributed execution but I just
want to get a couple of you know basic
ground rules out of the way the idea of
the project was to make a
general-purpose execution environment
for distributed data parallel
applications and overall in the design I
mean you have to make design trade-offs
when you're building a system and we
chose to concentrate on throughput of
the whole cluster rather than later
any particular job particularly if there
are failures you know you can wait for
timeouts and stuff this isn't for for
real-time response and we're ignoring a
lot of security issues and stuff by
assuming you have a private data center
with single administrative domain that
all that kind of stuff and of course the
goal is that the program are just rights
the program runs it as they want to by
fault-tolerant single computer and the
system should be in charge of of doing
all the distributing the data and the
resources and scheduling and all that
good stuff that you used to so I'm going
to describe in some detail the
computational model of programs that dry
it supports but just to give you some
idea of where the thing I'm going to be
describing fits in the stack I've been
argue lots of programs and lots of
programming models can be represented as
the kind of graph that dryer understands
and dryer is really an the middleware
layer of the thing that will run those
for you
so dryer itself doesn't know anything
about the semantics of the program or
the programming model so in that sense
it's it's more general than MapReduce we
don't have the those specific operations
built into it and so it's an abstraction
layer between the program model on the
top that now just has to manipulate
graphs and Dryad below that just takes
any old graph that it's given and
executes it and the advantage of that
that we thought was that you can have a
nice simple regular scheduler that
doesn't know anything about semantics
just knows about graphs and that's where
you build in all of the stuff to do the
fault tolerance and the scheduling
policy and stuff and then that becomes
independent of which particular
semantics of the program model you have
on top of it so as I said this is kind
of middleware so you can write programs
directly on top of Dryad and people do
and you should think about the people
that do that as needing to be able to
write good sequential C++ code it's
useful to do that if you want a lot of
generality and if you really want to
tune it for a particular performance and
you can also do interesting things which
I'll talk about a bit later
customizing for example the dynamic
optimation optimizations that you want
to put in there so there's a lot of
flexibility writing directly to the
Dryad lair but almost everybody that
uses the system is actually writing to
some higher level programming model
that's layered on top of it and I'm
going to say very little about those
things like this talk is really about
that middleware layer not about the
typical user experience of the high
level programming and so before I get
onto to any technical details I just
want to have a couple of slides about
how this came to be so the dried project
started out as a pure research project I
just come off working with the search
team on the v1 of the MSN search that
launched in beginning of 2005 so I was
definitely motivated by some of the
experience I had at search and some of
their applications but but also by just
the general research question of how to
make it easier for programmers to
express parallel and distributed
programs and also my background is
actually in computer vision and computer
vision machine learning are fields where
that can consume a lot of cycles but
where the developers are typically not
systems programmers and and maybe don't
exploit as many cycles as they could so
that was another motivation so there was
an obvious technology transfer path for
this to search and search do use it but
you know remember that Microsoft is has
got a lot of other things beyond search
and so you know Dryad is is designed to
support some of that as well so it's
it's used as a research platform inside
MSR for things like scheduling
distributed database execution that kind
of thing and also there's a bunch of
people who just have a few machines
lying around they want to do some data
processing that doesn't really fit into
sequel server or whatever and they can
just fire them up and run Dryad programs
on them and so some of the flexibility
is paying off there that we're not just
using it on giant clusters for for big
search applications and then I just want
to do a bit of a plug for for MSR and
because I think it was a good place to
be able to do this research that the
project's just start out bottom-up so
essentially this project started because
I thought it would be fun and I was able
Khanh some of my colleagues into
agreeing that but then we have the
collaboration across the company that
means that we can actually get other
people using it and then leverage their
research and the fact that we have a
flat structure particularly in the lab
at Mountain View meant that I can have
all these diverse interests in learning
and also systems and get to work on them
all and then of course I get to come and
give you the talk because it it's open
to all right so I'm going to talk very
briefly about the runtime and how the
clusters set up and then I'll go for
most of the talk into what kind of
programs Dryad can run and then I'll
give a couple of case studies to sort of
illustrate that so this is probably a
pretty familiar picture this is the
cluster that dryads assumes so when a
dryad program runs there's a single
centralized coordinating process which
we call the job manager that holds the
graph in its mind and makes all of the
scheduling decisions and that's some
libraries that get linked in with the
user application that constructs the
graph and and then on the cluster there
are just a few services that this needs
to get bootstrap there's a name service
so it can find out what the cluster
resources are and then every machine in
the cluster has a daemon that will four
processes on its behalf and they can
talk to a distributed file systems and
their network and all the usual stuff
and then Dryad also supplies some
libraries at the vertex executable which
communicate through this fabric back
with the job manager so it can get
updates on what's going on so you know
pretty much what you'd expect so
a dryad job the restriction on a dryad
job is that it has to be representable
as a directed acyclic graph and as you
can see it's a multi graph you can have
multiple edges between vertices so so
the graph each of the circles is a is a
program that processes some number of
inputs and generates some number of
outputs the edges are channels which are
sending data items along them and then
there are some
virtual vertices which are inputs for
example in the distributed file system
and outputs in the distributed file
system and the channels can be of
various types so a channel can be
persisted to a temporary file where this
just writes it out to the disk and this
guy is going to read it in later or we
have TCP pipes and also shared memory
channels within a process which I'll
talk a bit about in a bit so as I said
the inputs and outputs are just virtual
vertices in the graphs that keeps the
whole structured structure regular and
this is extensible so we can support
different types of file system and you
know when you have a distributed file
system with a partitioned file then
obviously you know a single named object
there can expand it to a whole bunch of
virtual vertices so that you can do
reading in parallel and similarly at the
output a bunch of them can write out to
individual vertices which at the end get
coalesced into a single file at the end
so the channel abstraction we made the
choice to make this a sequence of
structured items which are C++ objects
and the point of that was that so we
could get this implementation
flexibility so for the temporary file
and TCP pipe channels the series ation
code that gets called and puts this into
buffers but when you are doing it down
shared memory the the pointers to these
can get passed directly so you can have
a whole bunch of vertices in the same
process connected by these shared memory
pipes and have very low overhead because
they're just passing pointers around you
don't have to worry about zeros ation
overhead there and in keeping with the
idea that this is this is middleware
that should be flexible we basically
have no restrictions on this data model
um the application designer can can pass
any it can just derive anything from the
base type and put any data in there that
they want so so then the main design
question is why a directed acyclic graph
instead of something else so we came to
the conclusion that this is
the natural most general design point
and I'll go in for a couple of slides
about why I think that but basically if
you had cycles it gets too hard and it's
probably a mistake to be simpler and so
I mean the reason for that is is partly
DAGs support the the full relational
algebra and you can do other things as
well I mean in particular it's nice to
be able to have multiple inputs of
different types coming into a vertex and
multiple outputs of different types
coming out of the vertex that gets used
a lot of the seafood for example for
joins in the input but also if you're
taking in some data type and splitting
it out into two completely separate
streams for other processing it's nice
to be able to do that naturally at the
vertex instead of having to work around
it which is I guess I mean you can
always work around this kind of thing
but also sort of from software
engineering as the idea of this layer
design I was talking about at the
beginning where we didn't want to bake
any semantics into the scheduler so we
could keep it nice and simple and just
have it deal with graphs so going in a
bit more detail some of the reasons why
you want a general dag and not just put
the semantics of particular stages in
there so one is that if you go and look
at a lot of applications they look I
mean a lot of them look a bit like
sequel queries that they look like these
very uniform stages happening one at a
time but of course in practice once
you've done some dynamic optimizations
these the actual things that get
executed in the data that flows gets a
lot more irregular so you could be doing
some kind of merge tree so that these
are on the same machine and these are in
the same switch and maybe some of them
don't generate any output so you just
wire them into some virtual vertex that
throws it away and you don't actually
bother you know sending the data and
discovering that this is empty and also
of course there are lots of non trees
that are useful so this is an example of
of distributing into equal size ranges
for example if you want to do a sort of
some key that you don't know the
distribution of you start out with your
randomly partitioned inputs you can
just tap off some small sample of that
data compute some histograms send it
back here and repartition it and you end
up with this thing that's not a tree and
when you combine that with the fact that
now this thing that looks regular isn't
really regular because you're doing all
those those merger optimizations you've
really ended up with a general graph
anyway so your schedule is probably
going to need to handle that so you
might as well just put it in as a first
class part of the scheduler why do you
not want to add cycles well I mean I
guess you guys are probably familiar
with this but two reasons mainly
scheduling is easy because you can just
run a vertex anywhere once all of its
inputs already and because it's a dag
there's a topological sort of the graph
which means you can always get from the
beginning to the end assuming of course
that the channels are finite length
which is something that we assume that
our programmers will respect so you know
once all the the inputs arrive the thing
could start running then once it
finishes running it can market its
output as as ready this is the picture
for the the files obviously if you have
pipes or shared memory the things that
the channel is marked as ready as soon
as the producer starts running and then
the other thing that it makes much
simpler than an alternative is fault
tolerance especially if you assume that
the vertices are deterministic or at
least that the program is willing to put
up with anything weird that happens to
the extent that they're not
deterministic because of course if a
vertex is running and it fails then you
just run it again and nobody knows the
difference and if one of its inputs
disappears you just Traverse up the
graph and rerun that and it's also as
you are no doubt familiar if one of
these guys is running slow you can just
run other copies elsewhere and because
everything is deterministic and there
are no cycles
by induction you can see that the output
is going to be the same from all of them
so you can just use the output
interchangeably from whoever finishes
first and not have to worry about a lot
of bookkeeping so the final sort of part
of the design space is that we wanted to
make sure that the graph was going to be
modifiable at runtime
and I'll give a bit more detail about
the actual mechanisms we use for that
but basically the application passes a
graph in and says run and then as the
graph executes the application can
register objects that get callbacks at
various interesting times and at the
when it sees those callbacks it can
decide to modify the graph and so you
can do a lot of optimizations that way
and you can you can basically modify
anything downstream that hasn't run yet
it's the way to look at it so once a
vertex is executed you can't delete it
and you can't change the number of
inputs or outputs that it has but before
it's executing do whatever we want this
question right so the question is who
does the modifications as the scheduler
do it or does the application do it so
in terms of the abstraction layer the
scheduler doesn't do the modification is
the scheduler calls back into the
application of course there are some
very common dynamic optimizers which
sort of come with the libraries that you
can plug in but in terms of the
abstraction layer they're above the
level of the their extensions to dry
they're not part of the scheduler that's
interesting
okay so so the another way that we think
about organizing these these graphs is a
lot of times many programs them you get
a bunch of vertices which are
essentially all the same there are just
partitions of some larger logical
operation and so we have a concept
called stages that allows you to group
these together and so the way that works
is that there are these stage manager
objects each vertex in the graph has a
single stage manager as its parent and
by convention a stage manager is going
to be managing a bunch of vertices which
are essentially of the same type
although that's just a convention you
can actually do anything you want there
and so the stage managers are useful for
for reporting because you get all the
statistics about the running of the
thing aggregated by stage manager but
it's also the sort of locus for where
these the callbacks come in on the the
events as the as the vertices are
running and as they complete and fail
and so the stage managers are in charge
of gathering specific statistics for a
particular type of vertex in the graph
and so that you could you know if you're
trying to to do estimates of how long
something is supposed to take you know
that stage manager sees all of the peers
and so that's that's the natural place
to build the model of the running
statistics and also that's where you put
the D algorithm to decide when to start
running there when when to tell the
scheduler to start running duplicates
that kind of thing and so again as in
the previous question these in the in
the design these are all extensions but
there are standard default stage
managers that basically most people use
that that do the obvious statistics
collection and duplicate execution
algorithm and then one other layer
beyond that is that so now you can lift
above the real graph there's this stage
manager graph which is implicit and
between two pairs of stages you can have
one of these dynamic connection managers
and that's how the
dynamic optimizations happen so you can
put a link of these between any pair of
stages and then that gets callbacks when
there are interesting events basically
in the upstream stage when vertices in
the upstream stage finish or when
vertices get added or removed from the
the upstream stage and this is where
most of the dynamic modifications happen
so so you know if you're doing some kind
of merge tree it'll get a callback every
time some vertex finishes you know what
the size of its output was where it ran
and then that lets you build build merge
trees that are optimized for data
locality and that kind of thing and also
because you're getting callbacks
when vertices complete and when they're
added to a stage you can get these
pipeline stages where you know that you
originally pass in just a single strand
of a pipeline but every time this the
the upstream the guy at the bottom of
the pipeline gets a new vertex added by
some dynamic optimizer that just ripples
up and so you end up with the whole
pipeline being filled in and so finally
I just want to to go back again to the
point about the the channel abstraction
and what actually happens in the
vertices so when you're writing a vertex
for dried program you know you're
writing this this program that has some
some abstract channels coming in and
some abstract channels coming out but
inside the process that's actually
running of course there may be some
whole graph of these where they work
together using these shared memory
photos and this sub graph is itself just
a vertex program that accepts a
serialization of of what graph is
supposed to be built here so it's all
just layered on on top of the basic API
is there's no specific support needed to
do things like sub graphs so now I'll
just go into a couple of case studies of
actual applications and I'll start with
with a small application and then and
then a larger one and this will pull out
some of the differences that we found
between using small private clusters and
large
shared clusters the first example is
this database query so this comes from
the disguise server database which was
that's something that Jim Gray worked
with astronomers on and it's a published
set of database queries about
astronomical objects and this was the
the longest-running one on on sequel
server and it's basically doing a
three-way join on some tables to find a
gravitational lens effect and I'm afraid
I don't can't tell you more than that
about what that means or how this finds
it but essentially you're starting off
with a two tables one has a whole bunch
of stars in and for our purposes each
row in the table is just an idea of a
star and its color and then you've got a
neighbor table which just says these two
stars are close to each other physically
and so that just takes two two star IDs
and says that they're close together and
the task is to find neighboring stars
that also have similar colors and so the
way they chose to do this was by a
three-way join so first of all you just
join the color table with the neighbor
table to find and and you output this
temp table which has the color of the
original star on the idea of the
neighbor and then you just join that
temp table with the original table a
second time and to pick up all the ones
that match then now you've got the Stars
ID and its neighbors ID so essentially
the plan that sequel generated looks a
lot like this and for this task this was
done a while ago before we had any
sequel like front end so we just
manually coded this up in Dryad and we
manually partitioned these tables by
range so that so that the same range of
primary Keys lives in each of these
partitions so what's going on here is we
start out with these partition tables
partitioned by object ID and then the
first stage is just doing the first join
so you're just pulling out the the color
and the neighbor ID and then the bulk of
the work happens here
which is really just repartition this
temporary table in order to make it
ready to do the the second join so
coming out of here we had these things
which were in some random order because
we were keyed on the neighbor ID and now
we want to just
repartition it so it'll be keyed on the
object ID and we can do the final join
so we do that by first doing a
distribute into hash brackets then we
take the merge of all of these inputs so
each of these hash brackets gets inputs
from all these it doesn't
non-deterministic merge and then it does
a an in-memory sort and then finally you
can do the second join because now these
are all sorted and partitioned correctly
again you can just do another streaming
merge join and get the answer out the
back so what I want to talk about a
little bit here is how we actually
optimize this so you can just write this
in draw it and each of these arrows can
be a temporary file and it'll write them
all to disk and it'll take a while but
the first thing you can see that you can
do is you can pull these two together
all of these pairs of things together
into the same process because you know
there's there's no reason to to have
this data escape so you just replace
that by a shared memory FIFO instead of
a file and then similarly up here we're
going to pull four of these merge
sorters and four of these in memory
sorts into the same process and also put
them in the same processes second join
and the reason that we chose four here
is because the machines that we were
running it on happened to have four CPUs
so this way we get the the in memory
sorts to be all paralyzed and so this is
sort of a typical thing you know we
didn't have to write a parallel sort
because we could just put more
partitions in and put one on each CPU
obviously this was done by hand but you
know that's the idea but then an
interesting thing happens so so the key
here is that these are all in memory
sorts and so you have to design the
partitioning such that you won't exhaust
the memory of the machine
by this much data and as I said at the
beginning we did a manual partitioning
so we just picked the right number there
so that we wouldn't exhaust the memory
of the machine but if you happen to know
that the entire data set all at once
fits in memory then you can actually
replace all of these additional edges by
TCP pipes because you can afford to hold
the whole working set in memory of the
whole across the cluster all at once and
you don't have to ever persist this to
disk because you know the important
thing is that is that all of these
processes can be in memory and then you
get to put all of these in the same
process because now you can put these as
fire photos put these as TC pipe TCP
pipes and run the whole thing at once
and that's where you you start to get an
even better performance so this is just
the performance graph this is the
original sequel server which is
obviously doing a lot more than we're
doing but just for comparison that we
don't have really terrible performance
and this is the scaling graph where we
were doing that the two paths or so
that's this one where we were persisting
the output of this distribute onto the
disk and so what this graph shows is we
did a partitioning into 40 partitions
and we just ran the same program on
between 1 and 9 machines so we had a
nine machine cluster and we get a pretty
linear speed-up as you'd expect and we
haven't tried that on much huger things
but you know that's what you want but
here when you are at six machines now
the working set will fit in memory of
aggregate across all the machines and
now you can go from six to nine and now
you're getting this linear speed-up at
least for four data points but basically
it doubles just by eliminating that
extra that extra right out to disk and
you know the important thing to notice
there is that we didn't actually change
the code of any of that was running in
any of the vertices all we're doing is
manipulating the graph at the graph
level in order to do those optimizations
so now I'll move on to a larger scale
example
so this is a fairly standard query
histogram computation so you start off
with some log file that's been
partitioned into n partitions it's going
to extract queries from those logs so
the queries are going to be much shorter
than the entire log entry every
partition by the hash of the query into
K buckets and then compute a histogram
with each in each bucket so I'm not
showing you a full sort of histogram out
the back we're going to end up with each
each of the K buckets having a histogram
computed so the first way that we
thought of doing this was was this
topology so this is sort of the the
gross structure of it the queues are
going to read in the log files and
distribute them they are going to reduce
them basically and within each of these
queues we actually have a bunch of more
primitive vertices connected together by
these these shared memory channels so
the first guy just parses out these log
lines and throws away everything except
the query the next guy does the hash
distribute and then we do a little in
memory sort of each of those do a
partial reduction while we're here
because you might as well now that
they're sorted and then when you get to
the are you do a merge sort because
these were all the outputs of these had
already been output in sorted order so
you can just do a merge sort here then
do the final reduction and you know we
thought this seemed like a reasonable
topology for doing this problem but it
turns out that this was quite
inefficient for a couple of reasons
one is that the actual partitions that
were stored on the disk are much smaller
than the memory of the machines that we
were using so essentially the queues
didn't have enough data they were you
know there's some overhead in running
each vertex so that was a waste to have
n be so large and then it turns out to
be inconvenient to get one of these guys
to read from so many inputs so if n is a
hundred thousand having this guy read a
hundred thousand inputs
put some strain on the infrastructure
which wasn't necessary so this is what
we eventually ended up with and it looks
a bit weird as a topology but I will
show you in a minute what actually
happens but this is the basic topology
that the application hands in at the
beginning of running the job so now we
changed Q prime to start off with a
non-deterministic merge so you can have
more than one input coming into it then
it does the parsing as before and then
it does its in-memory sort and then the
partial reduction but notice it didn't
do any distribution here and then it
writes that out to this T which is doing
a merge sort of its inputs even though
there's only one input here you'll see
in a moment then it does another partial
reduction then it does the distribute
and then the R is as before so we split
the queue into two stages and we've
allowed each queue to take multiple
inputs so then what actually runs we run
a we we put dynamic optimizers on there
so as I said the application hands this
in to start with but the first thing
that the dynamic connection manager on
this set of edges does is to group these
by the location the machines that
they're running on and modify the graph
to expand this out so that each queue
has up to some amount of data coming
into it so you specify some maximum
amount of data that you want to have
because you're doing an in-memory sort
there and then this dynamic optimizer
just does the grouping for you and so
then as these start running and as they
generate outputs we have another dynamic
optimizer here that is looking at the
size and location of the outputs that
are being generated and when you get
enough of these it splits off a new T
from here modifies the graph again and
starts running mad and so eventually
once all of these have completed each
them gets their own T then once all of
these outputs are ready you can start
running the final reduce
and so the statistics that this actually
ended up doing on some particular run
was we started out with a hundred
thousand partitions about ten terabytes
in the original grouping per machine got
this down to about ten thousand queues
so it was using about a gigabyte per
queue but then as I said there's a big
data reduction when you pull out this
queries from the logs so the output of
this is now very small and so we only
end up having a couple of hundred of the
T's being generated and now when they do
their distribution these guys only
reading a couple of hundred inputs
instead of tens of thousands of inputs
or hundreds of thousands of inputs down
here and so it did the statistics of
what had ended up being at the time that
we ran out on the particular cluster so
in both cases I want to pull out what
was going on here when we who are
optimizing these was in both cases we
didn't change any of the code that
actually ran inside one of those vertex
circles what we were doing was graph
manipulations we were rearranging the
computations pushing them up up and down
the graph and we were changing the type
of the channels and you know what you
should be thinking here is that this
kind of graph refinement is much easier
for a system to understand automatically
than looking into the code that you
wrote inside that circle and trying to
do parallelization there so we tried to
split out you know get the user to
supply the sort of atomic bits of code
in these circles and then let the system
have at it on these graphs to to try and
do the best it can using some
rearrangement rules and of course once
you start bolting on higher level front
ends the user doesn't actually have to
see any of this stuff the user just
writes something for example that looks
a bit like a sequel query and then you
can build something that looks a bit
like a sequel query planner that does
all of that work both statically to come
up with an original good one and then
dynamically to try and refine it once
you know where the data actually lived
and how big it is
so I'll say a little bit about what we
found when we've been doing this on the
difference between small and large
clusters so we have a bunch of people
that are using you know very small cast
of tens of machines and and there's
essentially no failures when you hardly
have any machines and you know exactly
what the resources are and you know if
you buy a new machine so the incentive
for the people that use it that way is
they they want to get as much
performance as they can because you know
there's trying to solve some specific
problem as fast as they can and so you
know things like the their pipes as I
showed in the sky server database
example
become really useful because you're
really you know that extra right to disk
could be could double the speed as you
saw and you're willing to spend a little
bit of time on the particular program
that you wrote to work out how much RAM
it's using how much CPU is using maybe
try and shoehorn as much onto each box
as you can knowing the number of
processors is in the sky so have a
database example and so you use a bunch
of features in Dryad in order to do that
but then when you go to these large
public clusters where you have to assume
that the resources are completely
unknown because the person that manages
the cluster might just take half of them
away or whatever and there's you know
always some unknown number of failures
etc you really end up trying to to go
for best effort across the population of
jobs sacrificing the particular
performance for any particular job and
then you don't end up using some of
these more sophisticated features
because it's just too hard to predict
exactly what's going to happen you'd
rather have the isolation you'd rather
just say you know I'm going to devote
this machine to this process because I
don't know what that process is going to
do and it's it's better not to to mix
them up so
the fact that we have this generality in
Dryad makes it suitable for both of
these both of these worlds but if we
were really only ever dealing with this
then we wouldn't necessarily be using
all of the features that we have so
finally I'll just say a little bit about
the higher level programming models that
we have on top of this that most people
are actually using so there's something
called SSIS which is built into the
sequel server product it used to be
called DTS I don't know if any of their
sequel server experts here but
essentially this is something that the
product already ships with which lets
you draw a graph a little bit like a
dryad graph and and put arrows between
boxes and put sequel queries in the
boxes and it all runs on a single sequel
server instance so a team in adcentre
Microsoft that we're already using these
they just wrote themselves a dryad
application that takes one of these
workflows on a single sequel server box
and splits it up and then uses Dreyer to
run the spread out partition thing I
don't have any any pictures to show you
but that's kind of nice because you have
the whole sequel server toolchain for
all the debugging and everything and
then at the end you just press GO and
this thing goes and runs on the cluster
and they've been using that for for some
of their ad billing pipelines for over a
year now then there's a sort of quite
simplified front-end that got put on by
some people in the search team which
essentially looks a bit like Perl with a
few secret like operators and this has
extremely low barrier to entry and it's
sort of like a turbo UNIX pipes
distributed and it's very easy to use
and people use it for all sorts of
things but it doesn't have amazing
performance and then you are who's in
the front row here for a while has been
leading development on dry
Lync which I'll say a little bit more
about so I don't know how many of you
are familiar with link but you can go
read all about it here it's coming out
in Visual Studio 2008 but you've been
able to download it and use it for since
last summer I think and it's a way to
integrate sequel like queries into
c-sharp or visual basic or maybe some
other dotnet languages and you end up
with programs that look a bit like this
so this is now a c-sharp program but
it's building an expression tree that
looks a bit like sequel you've got
select clauses and group fires and order
bys but each of the things that lives in
here is just any old c-sharp function
that that you wrote or as using whatever
dotnet libraries you want and this turns
out to be a really nice way of
expressing parallel and distributed
programmers you've got this generalized
relational queries so you can act you
can put in any any application operators
you want you don't have to just use the
sequel ones and you can use any
structured data type that you want you
don't have to just use the base types
from sequel but what the developer sees
when they write it is essentially the
sequential imperative program that's you
know doing whatever they want and then
building one of these these query trees
and the way that the link is designed it
does lazy evaluation so that by the time
the user actually tries to retrieve any
of these the system gets to see the
whole expression tree and then it can go
off and do whatever it wants with that
expression tree and in particular you
can go and run out on the cluster and so
this is nice because simple Superlite
queries continue to look extremely
simple and are very accessible and
approachable and you can hide all the
details of you know sort of vertical
specific stuff in libraries so that you
know you end up writing this
you know you're less technical developer
doesn't have to understand any of the
details they just get to write something
that looks like a sequel query it's all
using these seizures sharp objects but
they're hidden off in a library
somewhere but the hope is that it makes
big programs a lot more manageable than
any of these more toy scripting
languages you can use all of the
libraries that you already have and you
have a real-time system under there and
so we have programs of thousands of
lines we don't have hundreds of
thousands of lines yet but you really
start to see the advantage of a type
system over for example something in
peril when you start to have large you
know we ported programs and certainly
found bugs where the the untyped nature
of perl was masking some bug and you
know it's all built into into the tool
chain for debugging which is nice so we
don't have to write new tools for a new
language and so this is a great
front-end for writing moderately
complicated programs on top of Dryad and
I guess I'm finishing kind of early not
as many questions as I had prepared for
I guess so but in summary as I said we
have this general purpose platform -
designed as middleware for the
distributed data processing and as I
said a few times it's very flexible and
for our use that has been quite
important because is used in lots of
places on small clusters for research
etc but it does actually scale up
properly to larger clusters with
thousands of machines and very large
data sets and because we have this
flexibility people have been able to
experiment with different programming
models and have found different things
as suitable for different needs but
that's it
questions yep okay
could you go back to the slides where
you discussed the speed up when using
email more sorting when this way this
one yes so I am wondering the following
so you motivated the development of
Dryad by high throughput computing
rather die low latency could you discuss
to the extent to which this was the
bottom here for example did you did you
measure the number of six per megabytes
read I was wondering
this is all sequential access so we
didn't measure the number of six
anywhere
I mean sequel server is obviously not
necessarily doing that but by the time
we done the manual partitioning we set
up this problem so that everything was
just sequential I think so
in this specific example data was not
rid of buffer cache correct so this is
basically running at this speed I mean
we have I guess I guess we had four
disks on each of those machines and I
think we just had them striped I think
it's in the paper I don't remember it
was awhile ago I think I think that's
just for this striped into a single
volume and so as I recall
the first stage is is purely i/o bound
this stage obviously has got two parts
first of all it has to read it in and
then it has to sort it and that's
serialized so the different phases are
bound by that and then the amount of
output is is trivial so there is there's
no there's no he's like five thousand
bytes come out at the end yeah I could
you compare this product to IBM's stream
processing core no I'm afraid I can't
release okay thanks what's the what name
should I use to look it up
I think this IBM SBC they say okay I was
wondering if you could say something
about the ability to recover from
failure and the fault tolerance ability
of the system ah particularly with
respect to large clusters she mentioned
there was it is a big issue with large
clusters where rice fields etc so I mean
I I just put the simple to light up
there right we're assuming everything's
deterministic and we're assuming that
there are immutable inputs and finite
length channels so you know by induction
the data on each channel is
deterministic
and so it really is you know more or
less as simple as this that the vertex
vertices remember are linked with
libraries that let you communicate let
them communicate back to the job manager
so the job manager can distinguish
between the failure case where the
vertex itself failed and where one of
the inputs had a read error and so
basically just if it got to if it got a
read error um it goes recursively back
and tries to regenerate the input and if
it got a failure it just runs it again
which could mean that you had to
basically replay everything from the
resource unless you have some
persistency along there along the line
yes you also have a single job manager
right that's right which is a single
point of failure is incorrect and so the
job manager is running a deterministic
state machine so you can log out what
the job manager is doing and you can do
suspend and resume that way but we we
haven't done a I mean it's a state
machine right you could do it as a
replicated state machine if you want to
do but that didn't seem worth worth
doing for the number of you know
proportionally the failure is much less
likely on the job man you can always
restart the job from scratch yeah and I
assume you could also use some
persistency on the job management right
you can log and do suspend resume that's
right I mean they that's because we're
not too focused on the latency it's
easier to do that than to keep a
reliable state machine going
what fraction of uses and end up using
dried link as opposed to manually coding
the graph and the application almost all
of the users use some high-level
front-end very few people are writing it
directly
so you mentioned one of the I guess the
main design ideas was to have the
optimizer only care about the graph and
so it seems like lots of the
optimizations will be like running more
instances of the vertices that do the
same thing based on the data that you're
saying have you given any thought to
maybe if you had some traits associated
with the vertices then you could make
some like larger scale optimizations
like the one that you are you presented
with the the T right I mean as I was
saying it's really the it's really the
scheduler that knows about the graph and
the optimizations all happen above the
fold so like in these stage managers so
certainly you can both at the beginning
when you're constructing the initial
static plan the application level thing
you know dry add link or whatever may
know something about the semantics of
each of those operations and it may be
able to do whatever optimizations you go
off and read up from the literature if
you want to be able to do dynamic
modifications that that are depending on
the semantics the way that you do that
is by implementing a custom stage
manager and putting all the vertices in
that stage into that stage manager so
again it's it's sort of above the fold
but we we just supply callbacks and then
you can do whatever you want there
please comment on mechanisms to deal
with unpredictable execution times of
nodes in the graph as I said the stage
manager can collect statistics on you
know if you have a whole bunch of things
which are notionally the same the stage
manager sees the input size the machine
and the running time of everything that
runs and so you can do more or less
conservative things to decide when you
think's some vertex is running slowly
with respect to its peers and I mean
that's where of course you always have a
trade-off between if your job is the
only job running on the cluster and you
had infinite network then obviously you
would always run as many copies as you
could of everything until the whole job
finished because there'd be no downside
to doing that and when you have multiple
things on the classroom when they might
be coming up the network then there's
some policy you have to decide on
between you know the latency for this
guy running more copies of things that
might be slow and the throughput of
everybody else and that's really a
policy decision did you consider
duplicating work more than twice sure
what were the results
I don't have a I I don't have an
analysis of that list when we're
hopefully going to have a paper on
analyzing a whole lot of this kind of
stuff
but I can't really tell you anymore at
the moment I mean we do that but I can't
I haven't got a measurement that tells
did you have any upper limit in mind
either for the number of vertices or for
the fan Yin or fan out of any up one
vertex well with the current design the
job manager holds the whole graph in
memory so that limits to you know
millions of vertices if we started
running into that then it would be easy
enough to get it to paged off in and out
so I mean there is some overhead to
having a vertex run and so you know
ideally everybody would write code such
as their vertex took sort of one to ten
minutes I think and then going over
millions of vertices will require either
a very very large cluster or a very very
long job and we haven't really been
working in that space yet but the in
terms of the fan in
no I mean we when we started we were
restricted on the number of things that
we could have as a fan in because we
were using SMB to to read the files and
SMB doesn't work very well if you have a
lot of files open at once but in more
general terms no I don't really have
much intelligent to say about what the
maximum should be obviously having a
large fan out is generally easier so I
think we're actually running short on
time because we've got another speaker
coming right now but thank you very much
for the talk is very interesting</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>