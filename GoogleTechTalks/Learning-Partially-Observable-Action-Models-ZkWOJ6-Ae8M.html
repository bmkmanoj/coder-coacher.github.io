<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning Partially Observable Action Models | Coder Coacher - Coaching Coders</title><meta content="Learning Partially Observable Action Models - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning Partially Observable Action Models</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZkWOJ6-Ae8M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">on the ellimere and is this on
I'm right now professor at the
University of Illinois door banner
champagne and i'm going to give you talk
about some of my work and of course some
of my students were and megan here has
done some of the stuff that you will see
as well so i'm going to talk about how
to learn oh I assume that I'm given a
sequence of actions and observations I
see somebody say behind somebody's back
I'm looking at what the user types and I
see what action the user makes on say a
web page I click a button and I see what
happens so I see the user took an action
and then I see that some effect happened
and what I want is to estimate how the
actions of the user is doing how they
affect the world so for example I want
something like a is executable if the
state satisfies some property and I want
to find out if under some condition this
action a causes some effect so I'll give
you an example this is a small demo and
I'll explain here a little bit what what
I mean by this learning problem so what
you see here this is a there is an
adventure game here that is kind of in
the background it's a simulation really
here there are secret there is a
sequence of actions taken from kind of
the higher the action the more recent it
is so for example here is an action
number 11 get mouse in room 3 and then
action 31 which is the current one go
south from room one okay these are
actions that our agent is performing and
what you see on the right you see a
table unfortunately me it's cut a little
bit here by the
here by the architecture of the the room
but let me show you a little bit here I
think you can now see the fraction of
the table so on this column you see a
set of actions so such as get go north
from room two and on the columns you see
the features that the agencies in the
world so for example the agent is in
room 0 we have a kind of it's just an
adventure game where an agent performs
different actions like picking up keys
with flipping light switches and so
forth and the agencies all kinds of
things in this world and decides how its
actions affect the world so what you see
in this table an empty kind of a black
rubric is a place where we don't know
the agent doesn't know anything about
the world a block where it says causes
not say go east from room 0 causes the
agent not to be in room 0 so the edge of
knows for sure that this is the effect
of this action on this feature for
example another thing that say go north
from room to the agent knows something
but it doesn't know for sure what the
action is doing it knows that the action
either causes the agent to be in room 0
or it keeps the value of being in room 0
okay so by the way you can stop me at
any point I can kind of make the
presentation shorter or longer as you as
you wish so if at any point you kind of
lose what I'm saying just interrupt okay
any of the current state or only of the
results the current state the entire I
see I don't even have a real expectation
and what I will see the observation
model is whatever you see is correct but
you you can predict what you will see is
the result that's right that's right oh
ok so if the sorry so the question was
that it's odd that I have all the
parameters here specified in the action
as I'm doing the action and it is
correct we have this is kind of where in
progress of research and what we're
doing there are some I can talk a little
bit more about how to enlarge they lurk
and expand this to cases where you don't
know those parameters what we currently
do and this is actually something that
Megan is also working on is introducing
new variables as if about what we don't
know okay so so yeah so you can you can
make this a little more more general
okay in the more the most general in
some senses we would like to know
something about how what going east from
room X causes us and maybe we'll
generalize that and I will show also
some experiments on that at the end okay
so this is this is the kind of this is
the kind of stuff that i would like to
handle and really so what what you've
seen is really an instance of this kind
of sequence of events so we see some the
agent entering a certain room the engine
is performing some actions like flipping
a switch go in west we get some text
back and going east is the next action
that the agent is performing and we see
some text in return as well
so those are the kinds of things that I
will receive in the simulation that
you've seen I didn't have any natural
language text and I'm not going to talk
about text and the rest of this talk
okay why is this important there are
many applications for this kind of for
solving this kind of problem we have an
agent acting in the world say it could
be the world wide web it could be a
mobile robot it could be some game
playing agent it could be that we had
software that wants to interface to a
new version of an old software so we
want this software to adapt by
experimenting so it can perform an
action it doesn't see really how its
actions affect the world but it sees
some observations and we want the agent
to try to figure out from those
observations what the what the actions
are doing so and the difficulties are
really that we don't have a knowledge of
how the actions affect the world a
priori there are many features in the
world and the domain is partially
observable so in the rest of the talk
I'm going to tell you more formally what
it means for actions to change the world
in a partial observable domain how we
will present this change and update
their representation that we have in an
efficient way and then I'm going to talk
about some related work and conclude so
here is a picture of how the of the
problem it can be seen what you see here
is the state of the world although this
is the same globe and I actually mean a
different world state so the world
progresses in response to our actions
and we make some observations those are
the so those errors that go up what you
see here if denoted as k1 k2 k3 and so
forth this is some sort of a knowledge
that the agent has that particular time
so after the agent
forms in action it knows that it
performed that action and it makes some
observations and we now have to update
the its knowledge state now what
complicates this matter is that this
transition relation at the top that is
also not known and the agent needs to
kind of have a state estimator for the
combines both the transition relation
the lack of knowledge of the transition
relation and the state of the world okay
so what our task is here is to be able
to update our knowledge about the
transition relation and the state of the
world at the same time and this is what
we're going to do so we're going to try
to do this update in an efficient way so
that at the end we have the most correct
picture that we can have okay so here is
a very very very simple example that I
will use in the in the rest of a talk
it's from this adventure game world what
we have our two rooms here and really
three features in this world whether
they agent is in room e storeroom west
whether the switch is up or not up here
this tilde here means not ok so the
switch is not up and here the light is
not on so the switch is in the East Room
the light is in the West room and our
agent is in the east room so it doesn't
really see the state of the light it can
see the switch it knows that it's in the
east room but it doesn't see the state
of the light let's say that now the
agent is performing a very simple action
of of flipping the switch so now it sees
that the light that he's in the still in
the east room and the switches up but it
can't see what the state of the light
this is what happens in the real world
but the agent doesn't know that this is
the real world so what should the agent
do the agent really represents its could
represent its state of knowledge with
this set of pairs each pair has a
transition relation in a possible state
okay and we have a set of those when the
agent performs an action it no
was that as a result of the action if it
was if this transition 3 this is the
model of the change in the world if that
was indeed the transition model that
governs the world then in the result of
the action the agent will be here the
ages will be in this particular state
and still will have the same transition
relation and the same goes with the
other transitions if this is a
non-deterministic transition say t3 then
world to will split in two there are
many possible outcomes for this action
that the agent is doing with the agent
makes out observation it can cross off a
few of those pairs and this is really
the process by which the agent decides
what are the possible transitions in the
world ok only t2 and t3 are those that
are possible right now the problem with
this kind of representation is that if
we are talking about n world features
then the number of the size of those
sets could be very very large and
especially if we want to scale this two
ends that are in the thousands or
Millions this is completely useless so
for example even in our simple in our
simple example here when we had the
light switch and being in the east west
and so forth we start with a very large
belief state ok these are the two
possible States on the left here and on
the right we have all the possible
transition relations after we apply this
action of say going west we will have
this kind of very long list of possible
combinations of world state and say
transitions that map of the state to the
same positive same state transitions
that change the state in a particular
form and so forth after we make an
observation say we observe that the
agent is no longer in the Eastern room
and the light is not on we will cross
out a few of those but we will still
have this very large
that that we need to represent okay so
that was the problem really doing being
able to do this update but without
representing those states explicitly and
what I'm going to do now is I'm going to
use formal language to represent the
possible states the possible states of
possible transition relations and and I
will show you how to update in that
formal language yes so trying to
understand what is what word uncertainty
is ending this model so for example when
they take an action is it if you had
perfect knowledge with I know the state
of the world there is it some non
determinism in the underlying results of
the action there sorry the question was
whether the lack of knowledge here is in
the state of the world or the possible
effects of actions in non determinism or
is it we've had perfect knowledge with
everything becomes everything okay so
the question again just I repeat it for
the viewers so the question is is it
that the is there a fundamental
non-determinism here or if I knew the
transition relation would all of those
transitions be deterministic yes so for
the rest of the talk I do assume that
all the transitions are deterministic so
if you knew how the actions affect the
world then everything would be
deterministic that's right
okay so so my foot the way that I'm
going to represent those sets I'm going
to devote for this like a few minutes
the way I'm going to represent the sets
is just biological formula in this very
simple case I'm going to use a simple
propositional language where I have
propositions that talk about world
features and propositions that talk
about how actions affect the world so
for example I will have a proposition
that says that switching a flipping and
switch up causes us causes they like to
go on the flip they switch to be up and
the state of the if this the agent is in
the East Room okay so i will have a
proposition that says that i will also
have a proposition that says that going
west caught keeps the value of the
switch the position of the switch okay
and i will have some propositional
symbols that i denote like this so
switching up causes the light switch to
be up if we are in the east room that
could be a proposition in my language
okay so for example if i had this light
switch example from before where i had
this set of possible pairs okay all the
states and all possible transitions then
right now I can just write it with this
very simple logical formula that says
I'm in the East Room and the light
switch is not up and this is all I know
about the world and this will represent
for me the state of my knowledge ok so
now the question is really how do we
update this new representation and who
tells us that this new representation
will not explode into the large set
large size that we that we had before so
let me first tell you how I'm going to
update this representation and i'm going
to give you two slides of the
then I'm going to go into algorithms
that are more efficient the theory is
this we have a logical representation
that tells us what we know we also have
piece of knowledge that tells us how the
world is updated if some conditions are
met by our transition relation so for
example i can say i have a so i have a
logical formula that tells me this kind
of how the actions will react if they
have certain properties and from that I
want to conclude things like if after
the action i'm in the east room then it
must be that flipping the switch up
either caused me to be in the east room
sorry either it keeps the value of being
in east room or it causes the need to be
in the east room if i have observed if I
will now observe that really i'm in the
east room after doing this action then
either it was true before that I was in
the east room and the action just didn't
change it or the action actually changes
it in a certain way and that is the way
so I'm going to make the agent being the
east room and so these are the kinds of
things that I would like to conclude
from my logical formula here and I'm not
going deep into what that logical
formulas but if you're interested I can
yeah
and I go east then I end up in this room
but if it's off tonight at supper oh yes
yeah so the question I'm sorry the
question is can i represent conditional
effects or effects like if this is the
state of the world if the main switch is
on then the light will go on but if the
power company does not supply any power
then I will not have the light go on
yeah i'm not i'm not showing this here
in this talk but not not in the examples
that I have but the implementations that
we have right now and I will maybe I
will show it a little bit in a few
minutes it will be something closer to
what you what you're thinking about but
yeah it just what did what you need to
do that is just to have more
propositions really that's that's really
the effect that you have the more
conditional effects that you allow their
kind of the larger the more complex the
conditions are the more complex your
algorithm will be in terms of time so
the question is do I expect the if they
in input to my program that says how
complex the conditions are and the
answer is right now we do it is
relatively easy to change it to
something that adjusts automatically you
can kind of say well you know if I don't
have any models that say that this is
this with with this k preconditions I
don't have a solution then I can just
expand it to k plus 1 automatically okay
so so let me come back to just a kind of
the main theoretical story the main
theoretical story is we have our
presentation in some logical formula
propositional logical formula in this
case that
represents what I know about the state
of the world and the what I know about
the effects of actions and I am doing
some sort of update of that formula by
knowing that the action has occurred and
then by knowing that the observation is
seen okay so before I move forward just
so that you know it's very easy to show
that these are this is really equivalent
to representing the exact set of pairs
that's the important thing that we have
to keep in mind we're not losing any
information here by moving into this new
representation okay so now i'm going to
give you two algorithms i'm going to
focus on the first one where we
represent the knowledge as a directed
acyclic graph and if according to time I
will also tell you about a second one by
the way how much time should i when when
should I conclude at 12 okay so with
with questions it'll be so okay so we
with questions where will be a 12 okay
so i have about 20 minutes okay so let
me tell you how i'm going to do this
update of the formula efficiently and
the way that I'm going to do that is I'm
going to represent what I know as a dag
directed acyclic graph and this is how
it's going to evolve let me just show
you kind of the animation a little bit
but what happens is this assume that at
time 0 I have some these transition
rules here so nodes that tell me that
pressing a button causes say a door to
be locked if it was not locked before
and another possible transition rule is
pressing a button causes of it or not to
be locked if it was locked before I
don't know which of those is true these
are just propositions and a half
actually have many of them in my in my
er presentation here
this note here in the middle will be an
explanation if I have any for having the
door for observing the door locked so if
I now knew if I somehow observe that the
doors lock then this would be the
explanation for me it's just a node here
and after a few assu believe me that
after a few steps say after tea time
steps we have this dag here that
represents what I know about the state
of the world and the and the transition
rules I know which one of them is true
this is you can think about it as a an
NN f or be DD if you're familiar with
those is just a graph representation
that says this feature is true if when I
go down if when I evaluate this logical
formula I will actually get true or in
some sense it is possible if there is a
satisfying assignment for those features
here that ends up with the with the top
node being true now what happens when I
do the one step this is the algorithm
really we transition from time step T to
time step T plus 1 this is an
explanation for whether the doors locked
if for the door being locked ok now the
explanation the time T plus 1 would be
either it's 11 of the to the door could
be locked if either lock lock was caused
by my action ok so this is that birth
this branch there are many possible
causes and here is one of them this
transition rule is true and it is not
necessary not true that this feature
held at time T
now on the other branch this is the
other possibility for the explanation
the door could be locked now because it
was locked before and I didn't change
the value of this locked so what happens
here is that this is and of this node
the explanation that I had before
together with it's not true that both
this explanation holds and this feature
is true now of course if you if you look
at this little carefully I can do some
simplifications but my step here the
update step is just adding those
connective those no connective nodes so
this is an and this is not an and I
added about seven nodes here now notice
that I didn't really add any new
variables I didn't really change any
variables and I didn't touch anything
inside here inside this cloud here that
represented the dad from previous states
okay this is really the main the main
thing that main technical thing of this
algorithm so if you have any questions
now is the time it's a very simple step
what's interesting about this step well
what why is this it well actually let me
first kind of go over the entire
algorithm what you do is you do this
step iteratively you take the knowledge
that you have you're given an action in
observation and you can join your
knowledge base with the knowledge that
this action is executable you add there
is a formula that will say that this
action is executable and then I will
update the explanation of every feature
so I'm given the previous explanation
and maybe explanations for other formula
for other features and I will
update the new explanation maybe with
some connections to other features and
I'm going to replace the previous
features with links to their
explanations so if i had the
precondition of locking the door or
pressing a button was that i will also
be in the room then i will have a
condition that i'm in that room but i'm
not going to keep track of what was true
in the previous time step so i need to
update that and i'm just replacing it
with this new explanation I'm telling
okay this precondition if it was true
then it had an explanation and I will
link to that explanation okay so this is
my one step update and I will also then
conjoin my formula with observations so
this is a the algorithm and the
interesting features of it are that it
takes constant time to do the update
assuming that I use a hash table and
assuming that really the constant time
really is that I should say really the
constant time is constant times the
number of features that you need to
update with your with your action the
algorithm is exact that is we are not
losing any models in this representation
and the dag size is at the end of T
steps is just T times some n to the K
plus v0 where this k is the number of
features in my action precondition so
that comes back to your question from
before if I have more pre-k more
features in my preconditions really this
representation will be larger okay the
where do we win why why did we do all
this complex or kind of why did we go
through all this analysis the algorithm
is actually very simple but why should
we use it the reason is that we really
still have only in world features and
those are the features at times
t or time t plus one or after we did all
of these the sequence of steps so we
went through some convened to really
kind of a convenient oriole process that
at the end really we have a
representation of what is true at time T
together with what we know about the
transitional relations what do we do
with that representation we can use some
stats over to tell us to give us a model
or to verify a query for us and that's
what we did in that demo that I showed
at the beginning so I can use a Sat
solver to just tell me okay what is now
what can I know now about the the world
why is it better than to just use SAT
solver on the entire representation just
because that would be would take you
time that is exponential in your number
of steps that you performed in the world
you will have T times n variables that
you will have to look at
okay here are some example example
experiments that we did what you see is
here this is a graph that shows you how
the algorithm updates the there were
presentation there are three different
lines for three different domain sizes
the green is with 19 features 55
features and 109 features what you see
here at every time point is the time
that it take to do an update of the of
the formula for one step okay so we see
that this is a over about 5,000 steps
where each step is another piece of data
another action got executed another
observation was seen and what I want you
to get from this slide is that really
the time to do the update doesn't grow
so we maintain the same time to do the
update if we are going to go for a
million steps or for a billion steps it
will always be the same time now the
formula size does increase but increases
linearly because at every point in time
we add this fixed number of new
connectives if we still have the same
number of variables the formula size
increases with the number of connectives
that we add and again what I want you to
get from this is that this is linear so
if we go for a billion steps then the
size of the formula will be a billion or
a billion times three maybe
and now we can ask okay well we did all
this we did all this update now maybe
you in the process you really made this
formula useless but what we did is we
created a Sat solver we mean one of my
students Daphna shakhov she is created a
Sat solver that runs on this these kinds
of dags and what you can see from this
this is the time that it takes to do to
do different inferences so we ask
different queries from that dag after
many steps so this is up to 4,000 steps
so 4000 steps into the future we ask a
question and if we want to find a model
kind of in general you will see the
they're kind of the black the black
circles here are they the times in
milliseconds that we it takes us to
answer a query and the what you see in
kind of the triangles is what happens
when we're asking a query about a rule
in that an action rule and that turns
out to be true what happens this is when
we ask a question about rules and it
turns out that the query is false and
what you see here in the yellow circles
and the here the diamond the green
diamonds those are the questions that we
ask about the state of the world so why
is this why is this important and and
interesting the important thing about
this is that while this you know it does
grow it grows linearly what that tells
us is that the formula is not becoming
more complex whatever our presentation
is of the possible transition models
this is not a complex formula and we can
do so perhaps it takes us more time to
do the checking but it's really time
that is linear the growth is really
linear with the number of steps that I
need to
then I need to process so that makes it
feasible for us to run 10,000 steps
because well in 10,000 steps that will
maybe take me 10 seconds to run a query
on on the on the result okay um I have a
quick so I want to conclude with the
first algorithm so what I showed you is
just one algorithm to update a logical
formula that represents possible
transition models and states of the
world I'm going to briefly show you how
we can update flat representation in
some cases i want to emphasize though
that this dag representation that i
showed it assuming that your actions are
deterministic you can solve the problem
with this dag algorithm completely I
didn't make any other assumptions
besides the assumption of determinism of
the actions here the second algorithm I
will make some new assumptions and under
those assumptions i will also be able to
show that the update is correct and the
representation is is compact so here is
the algorithm it's a very simple
algorithm you take a logical formula
that represents the possible states of
the world and the transition models and
you break it into its literals it's
different propositional symbols each one
of the propositional symbols we're going
to update separately by some table that
we're going to generate beforehand and
that the result representation is just
the combination of those updates for
again an update for each one of the
pieces separately okay this new formula
is our new belief state
okay so here's a couple of interesting
things about this algorithm this
algorithm takes time that is linear in
their representation size that we have
it is exact when the actions map States
one to one so for example if I press a
button that transfers money from my bank
account in to paypal's my paypal account
then if I transfer fifty dollars then
fifty dollars whatever my account was
before the action it will now be fifty
dollars less and whatever my paypal
account was before the action it will
now be fifty dollars more okay so that's
a one to one action on the world and so
if this if this holds then this
algorithm is correct and I will explain
in a second why and also if I had an
actions that are not one-to-one they but
if they had no conditional effects then
I could also do a similar update
otherwise i will get just an approximate
result so here is an explanation let me
explain to you why mapping States is one
to one this is the last technical part
of the talk so what you're going to see
if you this process of breaking the
formula into its pieces really is what
we do is we take a formula we say ok if
this formula is built of a conjunction
of say different two formulas and we
update each one of them separately what
happens when we have non one two one
action so look at the example here at
the bottom we have two formulas vmc they
correspond to two sets okay so let's say
that these two sets don't have any
intersection the intersection is empty
and so the update should you know if I
had no models before I shouldn't have
any models after the action and that
didn't change what I know but if we
update each one
separately and then can join the result
what we have is maybe we will have a
model that is now in the conjunction
because the actions didn't map States
one to one when we have an action that
mop States one to one then it cannot be
that the two sets will intersect after
the action if they didn't intersect
before the action okay so this kind of
insight allows us to say well if the
actions are map states one to one then I
can break this update of a formula into
an update of its of its smallest pieces
and since I have only n features in the
world and say I have em possible action
rules than this set of this I can create
a table of a relatively small size that
will just tell me how to update each one
of them separately and that's what we do
sorry about that okay so so this is it
so we have an algorithm that is exact
and has some guarantees on the
compactness of a presentation after the
action I don't want to tell you too many
things too many details here but just
assume that I want to turn your
attention to things first is we know
that if we can observe every feature
every say K times then there were
presentation we can keep the
representation compact so compact in the
sense that the representation will be
order of n to the power of k plus 1 so
say if i want to check how my web page
what is the effect of transferring money
by pressing a certain button then i can
go into some webpages and check that
every say K steps and I am sure that the
representation of what I know is compact
that guarantees that the overall
algorithm is tractable
okay so here's a bigger picture of what
what I showed you the bigger picture is
this we have an agent that really
explores the world what I talked about
today is this learning module here that
is joint with kind of filtering the
state of the world we interact with a
knowledge base and sometimes we will
also include some common-sense
information together with the knowledge
that we now acquired in the world we
make we use that to make decisions about
what actions to take in the world I
didn't talk about how we decide what
actions to take it's a completely
different talk but we are going to make
those decisions and we're going to
interface with the world model that will
give us the information that that we
need for the algorithm okay so let me
summarize what i showed is how to learn
the effect / conditions of actions and
partially observable domains i showed
that we have an exact update algorithm
for directed acyclic graphs we also have
a CNF update algorithm kind of a flat
representation of logical formulas that
works if some conditions about the
domain hold and the important things
about these algorithms is that we first
I mean the first one is exact for every
action we can update them efficiently
the models of those transitions are the
set of transition models and and world
states and the result representation is
compact and that's most important
because we want to actually be able to
continue this into the future and also
to use the model you may ask what of
this here is is the work that my group
is done and the main contribution that
we have done a
is to present the first tractable
learning algorithm for partial
observable dynamic domains now we assume
determinism here which is a very strong
assumption this determinism assumption
does hold in some domains in particular
the world wide web at least in most
cases that you that we were interested
in in looking at we haven't really
experimented with an agent that works on
the world wide web what we did was just
in this simulated environment that I
showed you the beginning but this is
kind of the direction that we're going
the what I want you to remember from
this is really that the algorithm is
always exact an optimal and that it
takes a constant update on these are
things that allow us to solve problems
that have very large number of features
and we have generalized this to to
relational for presentation and a few
other generalizations like Peter
mentioned the beginning what happens
when you don't know what were the
parameters for your actions we were we
have done something along those lines we
didn't finish this yet this relates to
many things that you've you probably
familiar with reinforcement learning and
hidden Markov models and also learning
AI planning operators just for to give
you an idea why what would happen if i
use a hidden Markov model to represent
this or a DB n to represent this what
would happen is that i will need to
update the structure of the DB n or i
will have in this kind of using an e/m
like hill climbing approach and not the
size of the domains that i will be able
to deal with in the at least this is I
we didn't try it
all the most kind of up-to-date things
we just looked at the papers the number
of features that people were able to
deal with were usually at the order of
tens so say 10 15 20 features that
govern your domain and these were kind
of the state-of-the-art approaches for
learning the structure of dbms so it's
true that their problem is much more
difficult they're looking at general
stochastic processes but if we want to
solve problems that are large enough
then we have to make some assumptions
and examine them and perhaps from this
we can build and extend this to
stochastic processes and this is one of
the things that we're looking at so
there are many interesting open problems
particularly the how do we do efficient
inference with the learn formula what to
do how to do the same thing for
stochastic domains and also how to use
dynamic observation models so if i had
an observation model that would tell me
what i should expect after i do a
certain action that should be included
in this process so I I'm done you can
find some of the software on my website
and you can also ask me of course for
the software now we'll be happy to send
it so I'll be taking questions now
thanks
if you have any more questions what is
the software so we have the question was
what is the software that i have in the
on the website we have a software for
updating the currently what we have is
just the software for updating the
representation of the possible
transition models and the and the world
state so we have the second algorithm
that i showed that's available on the
web page it's just implemented by you
give it some input that could be
whatever you know about the state of the
world as the logical formula it could be
could be an empty input so i don't know
anything about the current state and you
can just run it on its in batch mode so
you give it a sequence of actions and a
sequence of observations then it will
output the formula that represents how
your state's affect how your actions
affect the world the other the dag
algorithm that i presented we should put
it on the web very soon like in a week
or two and i can also if you're
interested I can send you the decision
making software to we have a paper and I
caps this year alan cheng and myself
he's a student of mine
No</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>