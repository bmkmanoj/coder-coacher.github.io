<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HDR and Color Constancy--New Psychophysical Results | Coder Coacher - Coaching Coders</title><meta content="HDR and Color Constancy--New Psychophysical Results - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HDR and Color Constancy--New Psychophysical Results</b></h2><h5 class="post__date">2009-01-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OmlaLSxj27k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming everybody we've got
two great talks today we'll start with
John McCain came and spoke to you about
a year ago on some high dynamic range
rendering stuff cause you got some
interesting new experiments to report
and looking forward to a update on that
work don't know if I need to say
anything else about each other okay well
thank you very much I brought along as
one sure I could arrange it but I was
able to bring along my co-authors on
this and I'll talk for a while and we're
we're trying to organize a tag team
presentation last year we talked about
high dynamic range imaging and this year
we're talking about a still older topic
for for me and that is color constancy
and a combination that kareena and Ally
suggested as a part of a wonderful
program called create which is color
research for European advanced
technology employment it's sponsored by
the EU and the coroner is the director
of that and Ally is one of the principal
scientists helping to organize it it's a
session they'll tell you about it huh
I'll just described it wrong have to be
careful my I'm looking at the wrong side
so anyway you hear more about that as we
go along but they proposed this
experiment which is the I think the
first real advance in in Mondrian's
since nineteen sixty eight on land first
showed this pair of color Mondrian we
all know that we are fairly insensitive
to the color of the light that we live
in we can go from tungsten light outside
to leave the yellow light of tungsten
and go out to the bluish light of a
cloudy day and not much changes lens
experiment shown on the slide behind me
where we have two identical sets of
reflectances two sets banks of
illuminance there's red green and blue
light on each side
you can adjust the amount of red green
and blue light to control the light
coming from any paper to your eye the
way you do that is you've got a light
meter and there's a projector overhead
that projected the meter so you could
for example go and find a green area
here you're not seeing okay all right
well I probably can't fix that in turn
alive so you can go to a green area on
the left and a pink area on the right
and you can adjust the red green blue
here and the red green blue there in the
illumination so that in fact the two
areas are sending the same amount of
light to your eye yet one looks green
and one looks pink and so the purpose of
this experiment was to demonstrate that
any color can be caused by one on the
same stimulus and you can just go
through the mondrian one after the other
and produce a white or black or red a
green or blue with exactly the same
triplet of red green and blue lights now
there are other experiments such as you
can do this in black and white with
gradients you can find outdoor scenes
you can find a shadow the first shadow
that I thought was interesting was up at
Yosemite but the picture you see on the
right is actually in my backyard in
Belmont Massachusetts on a clear clear
fall day the shadow came from the roof
of my house that's my picnic table two
identical charts gave you the same light
meter reading from the hike card in the
shade as the black
okay I'm not sure I understand that now
lands Mondrian used a hundred different
reflectance papers it used uniform
illumination and the object the
experimenter varied the amount of
illumination falling everywhere in the
scene but when they change the
illumination they change everywhere the
same amount that would allow you to
prove that all colors are can come from
the same LMS quanta catch or the same
stimulus on the retina issues there in
universe in uniform illumination you can
have a variety of hypotheses to explain
this one of the popular ideas is the
gray world hypothesis and it seems that
if you all scenes have the same average
that's the gray world if you know that
average value of the scene or you guess
that average value of the scene and you
take the light everywhere in the image
you can divide the total quantity H by
the assumed illuminant because you use
the average reflectance to guess what
the illuminant is if you divide the
total light coming from the scene by
your guests for the illuminant that will
tell you the reflectance at each pixel
on the scene and so the gray world
algorithm seeks to find objects
reflectances using this estimate of what
the illumination is and so this really
tells you this two different ways you
can look to explain color constancy one
way it goes back all the way to
Helmholtz we're impressed by the
psychologist for explaining color
constancy he said while you need to
discount the aluminum and so far I've
only found one or two sentences on
discounting the
in all the volumes of Helmholtz so they
he's very invested in the quanta catch
side but he didn't really explain how we
should do the discounting yet
particularly among computer scientists
the idea of discounting the illuminant
is a great stimulus and people love to
experiment with it and in that domain
it's all about separating reflectances
from illuminations the land proposed a
slightly different way or totally
different way namely you don't care what
the reflectance is you don't care what
the illumination is what you want to do
is to use the use the spatial
information you want to look at the
edges and the gradients to calculate
what it is you see but finding the
illumination is unnecessary and in
irrelevant so the new experiments that
kyrenia suggested get at the heart of
the matter do we see an object's
reflectance disappearance really
correlate with reflectance obviously it
did in lands experiment but does it do
that in the world or another way of
saying the same thing is our appearance
is constant for all illumination now
it's very important here that we talked
a bit about the questions you ask the
observer over the years I've had many
arguments with Alan Gilchrist and it
goes right back to the definition of
what's the question Helen and I were to
do the same experiment we would get
totally different results and the reason
is because Alan would ask the observe a
different question than I would ask them
and that always bothered me for a long
time until finally I came back and read
something in the old OSA optical science
of science of color and they have this
definition of sensation and perception I
recall vividly when I was a freshman in
college and working a Polaroid in the
summer i read this definition of
sation and perception and I said to my
my roommate what are these guys smokin
why in the world would you get into
these really weird definitions because
sensation is a bottom-up definition that
says the mode of mental functioning is
directly associated with a simulation of
the organism however perception is a
top-down thing it's a mode of mental
functioning that includes the
combination of different sensations and
utilizes utilization of past experiments
in recognizing the objects and the facts
from which the present stimulus arises
well that never really connected me till
I was on vacation in New Hampshire and
looking at this raft in the early
morning light because that raft suddenly
made me connect with this OSA definition
and so the warning here is the question
you asked the observer will affect the
answer if you measure the radiance and I
never did that because I didn't have a
photo below radiometric equipment but if
you measure the light coming from the
two sides of the raft they are about ten
to one difference in in radiance and the
color temperature shifts from about
20,000 degrees Kelvin to 4,000 degrees
go so you can say radiometric Lee the
two sides of this float are very
different if you ask the sensation
question that's asked a fine arts
painter what would they do to paint an
image and paint the two sides of the
raft the painter presumably would want
to use a bright yellowish white on the
sunlit side and a little bit grayer a
little bit bluer paint on the other side
it would be similar but they would be
different and so that's that's at least
what I see what if I say if I were a
painter if I could think that
the perception question is different
what paint is on the raft you hire a
heist planer in town go paint the raft
and he doesn't go out with the meter he
doesn't take his chips out there he goes
to the paint store and buys weight paid
for both sides so I would urge that this
is the question that Alan Gilchrist
austins observers what do you perceive
the object to be whereas the experiments
that I would be asking observers is what
what paint would you select to render
this as a part of a complex image so
colors depend now and in the rest of
this talk will be talking about the
sensation even the sensation sort of out
of popularity almost everybody uses
perception for everything and doesn't
don't use it in the context that the
optical society required cognitive
processing but anyway we'll be talking
about what things what the appearances
are what the sensations are now the new
Mondrian proposed by ollie and Corinna
was a 3d Mondrian will restrict the
reflectances to 11 separate paints we
will have both high and low dynamic
range and illumination we will put them
in the same room at the same time close
to each other as we can and we will
measure the range of appearances from
constant reflectances if you want to
know our reflectance is constant in
different illumination swellview hold
the count reflectance constant in order
to make complex scene we need more than
one reflectance and here we have 11 mode
so here is the 3d Mondrian it is a
complex arrangement of wooden blocks
that are painted with only 11 paints
including the debt circle in the back on
the left yes that circle in the back
is paper painted with the same paint we
also will use a second non uniform
illumination well we have very sharp
contrast e light coming from the side in
fact this two lights there's a tungsten
light that's coming from the lower right
and there's a bluish white light LED
coming from the left side of the picture
so to repeat the questions are two
objects appear do objects appearance
equal the reflectance and other
appearance is constant for all
illuminants weird about reflectance it's
a very simple concept we're all familiar
with it the definition is that it's the
ratio of incident flux on a sample to
the reflected lux from the sample and so
it is in the 1k and in the incident
light is here on the left the reflected
light is on the right in practical terms
however nobody ever measures reflectance
for a fairly simple reason is that it's
easy to put a meter here and illuminance
meter that measures watts per square
centimeter falling on the device you get
into trouble over here because you have
to put the meter between the light
source and the object and as soon as you
do that you have filed up the
measurement and that's why no one in
fact except in integrating spheres use
that kind of a means to measure an
object's reflectance what they do is
that you have some illumination here the
yellow source up high you have some
object you usually take a lens collects
and light put it on the photo she'll
make a measurement then you place on top
of the object to standard something that
is assumed to be one hundred percent or
a known value of reflectance make the
second measurement and the value of
reflectance is this ratio between
the sample in that illuminant and the
standard in the same aluminum to make a
long story short the rednecks idea
proposed in the 60s was that well
instead of doing them time sequentially
we all we need to do is do it spatially
it's easy if you have a whites around an
object you just need to look at these
ratios to determine the relative
reflectance if you don't have a white
surround directly around it well if you
integrate things across the entire field
of view you can use the sum of all these
ratios of the product of all these
ratios to to tell you what the relative
reflectance of the image is simply said
if we have an array of edges and that we
can establish the relationship of the
entire image by combining the set if you
do that in separate channels you get two
sets of information and color constancy
and the rednecks way of thinking simply
stated is these two sets of information
tell you the color well let's get to the
experiment a hand here we have two
images the low dynamic range where we
try to get these blocks illuminated as
best we can perfectly uniformly the HDR
case is we try to do the opposite we
tried to get the worst possible non
uniform illumination but on the same
subject 11 blocks two identical sets of
blocks over 200 facets the illumination
was we used one of these illumination
cubes that google and ebay have played a
big part in developing this technology
if you want to sell you use sneakers on
the internet you'll get a better price
if you buy one of these nice integrating
spheres that you set up on the table you
put your sneakers in it you put the
lights around it and you get nice
uniform illumination
you take away the integrating sphere you
turn on a light this is a out to a
spotlight just a tungsten lamp and it's
a little hard to see but there's a
fluorescent stick that are not
fluorescent it's a stick that has in it
about 20 white light leds and so that
that's a white light but it's a bluer
light and you can see that alley a
little bit later we'll talk about the
HDR component of this is that we
documented this and made a lot of
different exposures to capture all this
information for subsequent image
processing but this will just so it'll
give you a chance of looking at some of
the details of this both of particular
interest is the in the high dynamic
range you can see the back in this case
that circle is on the back wall here
there's a hole in the black wall and
there's a little chamber behind it none
of the light coming from the side can
get on to the target but it can get into
the chamber so that's how we got a
really high dynamic range seen is by
having very low illumination on that
target in the back we had a number of
observers this was part of the create
workshop that will be described as a
little bit later but you can see that
the two displays were in the rest same
room at the same time people could go
back and forth look at each but
basically sit down and and study you'll
see here in front of the observer was
this painted sample that we call ground
truth this is just a piece of paper with
the 11 paints on it and the question we
asked observer was to go through and
look at different patches and say how
close is the appearance of these facets
in the
image to ground truth that's kind of a
no-brainer in this case and we would
tell the observer which faces they
should evaluate in this case gets to be
much more difficult much more
interesting because you see you have a
red that's in the deep shadow you have
one on the Left that's a little bit
bluish because of the blue look at the
scene oh yes this is all real yeah now
then given a few moments we could we
could do a little better with the with
the projector that be a little bit more
time but I won't interrupt us to try to
do that because corinna is going to show
us some paintings of the scene which
will tell us a lot more information so
let me go back a bit so basically the
observers task is to say well now if
this red on the left is bluer and darker
give us an estimate of how bluer much
bluer and darker it is we know the
Munsell value of each one of these
paints we know the XYZ of these paints
we tell the observer well the white is a
10 and the black is a 1 tell us the
number that it looks like from white to
black if it doesn't match the hue well
tell us how far it is to the next you
orange would be halfway between red and
yellow if it's more saturated or less
saturated think of it it is that round
truth sample is at a hundred percent if
it's more saturated give us a number of
how much more so we can proceed we can
have about four or five different
patches for each color and for each
aluminum now
just to quickly summarize some of the
data if observers saw that the
appearance equalled reflectance then all
of this data should fall onto the bottom
plane because the vertical axis in this
is distance in a uniform color space and
that's the distance between ground truth
and what the observer told her told it
was going to be I won't get into much of
the details but to just give you an idea
we start off with these estimates that
the observer gave us we know the
starting month self value we can
estimate the new munsell value of what
they would call a match and then we can
use a em lab lookup table to put that
into distance in munsell space and
that's why I say it's a uniform color
space them I without be laboring the
points we call an M lab and so as
vertical axis in this is simply the
distance between ground truth and what
the observers saw now what it says in
uniform illumination many now these are
just five different red samples and the
arrangement is just we tended to put the
bigger values in the back so you could
see the graph better so the arrangement
has no specific meet in Netherland the
size of the air so many of the pieces
and uniform illumination look like
reflectance but there's a few where we
didn't get the illumination quite right
and they look slightly different in the
other case in the HDR there also are a
number of patches that look like
reflectance but there are others that
look very different for calibration a
hundred to one is the difference between
white and black and a munsell chip so
some of them are up to sixty-five
percent of the difference between white
and black quite a substantial departure
I went the wrong way same results for a
separate observer we have 35 to 40
observers we're going through them all I
don't think there's much sense in
averaging all the observer data what
you're interested in is the variance
between estimates for a red paper yes
well the goal was in the L the low
dynamic range scene to make it as
uniform as possible and the other was to
make it as different as possible some of
these patches will be because the white
light LED is bluer some of these
differences will be because it's in the
back room English in the shadow we're
not separating those in these data we
could go into the data and identify each
of them but this plot it's just the
simple distant so does the parents equal
reflectance only in perfectly uniform
illumination even when we try to make
perfectly the illumination we didn't
quite succeed and if we try to make the
illumination very different we see very
large changes and do objects appear the
same in all the luminance the answer is
no and that we can see some very large
changes in the changes or you can find
in hue chroma and and like this so let's
take a look at this area right here in
both of these there
it these are in fact the same gray paint
and this is a darker paint there's very
little light on the top of that the
light that's coming is from the blue
light on that side so here we have the
case where the illumination is in fact
making a pretty good edge here's the
each time I may be out of order here so
let me get this
let me just go to this image my slides
are out of order I apologize but you can
see in the in the low dynamic range
scene it's much lighter on the top and
the high dynamic range scene it's dr. on
the top you can see the reflectances you
can see the illumination so this is a
case presumably because the illumination
has created a nice sharp edge where we
have a marked change in appearance from
two areas with the same reflectance
here's a similar area where we have this
entire block is white in reflectance but
you can see with the shadows and the
inter reflection the pink surface has
reflected pink light and the yellow
surfaces reflected yellow light so in
the formal definition of what's
illumination and what's reflectance
that's all a white paint but the inter
reflections between objects has created
different colors of illumination we have
tungsten light plus the reflection from
the pink to give us a big shift in in
color appearance so this is an example
where we have a white reflectance but
the top looks white it looks a cool grey
below that it looks magenta below that
and looks yellow below that now so to
sum all this up question is does
appearance look like reflectance and the
color Mondrian of land yes it did
because we used uniform illumination
when we tried to get it uniform in the
light box
in the illumination cube it worked most
of the time but some of the time we
didn't succeed in getting it utiful and
the answer for the highly district
angular highly here non uniform
illumination is that it really works but
there are some areas that are perfectly
good Carl show perfectly good
correlation with reflectance there are
others that show substantial errors
there's a second part of the experiment
that where we I would wear Corina will
Perriman from the University of from the
University of East of England easton
Western are you she said she's going to
describe the second part of this where
we used a different technique for
measuring the appearances on this
display so search ok so rather than
relying on cameras to to capture the
scene which is what we also did the idea
was to actually represent the scene
through colored pigments and then it's
in this case i was using watercolor and
so this is the the first one that i did
of the the high dynamic range i chose
that because basically it was more
visually interesting for me and but what
i found was during the the course of
making the the painting and sitting in
the dark and making the painting there
that was fine but as soon as I I left
the room
in bright sunshine and then went back
into the room all the colors looked
wrong and so I had to wait a while to
for me to be able to sort of go back and
see the same colors again so this was a
kind of kind of interesting process and
obviously trying to match the colors
what I was what i was looking at and
sort of the iterative process of putting
down a color on paper and then looking
at the different facets and comparing
one facet to another and so the second
ID and you can see that the brushstrokes
in the center and that's for the sort of
the the trying to get the sort of the
the range of colors in order to to try
and depict the sort of the the whole
range of colors that I was able to able
to see and so on the left you have the
low dynamic range and on the right you
have the high dynamic range and as John
described you can begin to see the the
shadows that have been cast by the light
on the on the right-hand side and as you
move on to the the gray block again you
can begin to see the the differences in
the different facets so the the front
facing face when as shown in the the
measurements that the front facing face
is lighter than the one on the low
dynamic range and the tops of the of the
box is there is also different and here
you can see there are those curves we
were using measurements of relating
to describe the changes in appearance so
those are spectrally no measurements of
a watercolor you can see the reversal in
the yellow pot so that's those are the
paints the reflectances of the paint
occurring the chose to match depends
which pass over the community one is the
top to the left face three is the right
oh this is the practices yep just
diagrams
and in the the color reflected areas you
can see a more uniform facet on me in
the low dynamic range and then much more
color interfaces in the high dynamic
range and again in the the reflected
light like white area there's a the
lilac a pink and this sort of dark dark
yellow and these are the measurements
which are taken from the different
reflected areas from the paint and you
can see the differences in the in the
measured samples so and I've got the
paintings here if you wanted to have a
look at them the obviously the colors
are quite different to what you're
seeing in the so that was the first
painting
and then this is the second nature yes
sir show them picking alone sofa in jail
so good morning i am alexander 8c and
just to conclude briefly the torque and
to make some comment on the results
sorry about the cove so what came out
strongly is that appearance and
reflectance are kind unrelated and they
strongly depends on both the light
distribution in the scene and special
effects our vision system and so on so
we can say that then two different
things and of course changing the
illuminant a big change in an appearance
can take place what we did is to we
spend some time basically John spent a
lot of time in measuring or the older
patches and we have a lot of data from
all the observers and so we have this
kind of possible set of experiments that
is there if you want to try to test and
that is that is there any way to measure
appearance automatically is is there any
model that can predict appearance or in
other words can we go and put the data
of the the distribution of the light
field in the scene into a sort of
computational black box and get out what
a a synthetic observer should perceive
and in terms of appearance and that's
the challenge so this order's data are
available I'm sorry all this data are
available and and can be used and
basically what what's interesting is
that we can get rid of the the idea of
that color is belongs to the object and
what we perceive is always a combination
between the light that hits the object
and the object itself and so this
ambiguity will be always present and and
that's why basically our vision system
adapted in this way developed in this
way to deal with this
beauty and this can be an interesting
point of view of the of the experiment
and if you go to black and white you
just get a rough estimate of the light
distribution in the scene and you can
imagine the reflectance going underneath
this right field we painted them all the
same pain and the uniform illumination
they pretty much look the same but
uniform gray mat surface gray box in my
uniform illumination don't look great
they look white and gray and black and
everything in between yeah after the
comment because we join me always
discuss about this but it's true that
also the average can be in some sense we
conducted two great but the I mean of
course gray gray war doesn't help you in
explaining the basic mechanism of the of
the underlying vision so just just
taking the summary sort of summary we
it's quite hard to explain the final
appearance of the scene just in terms of
reflectance and what our vision system
does probably and probably not probably
is in this comes quite evident in this
experiments that we do not discount the
illuminant but the idea is that we built
the image the final appearance
especially taking the comparison a
special comparison in Sun inside our
vision system that mainly our brain and
we build appearance from from this and
so what can be interesting to do is to
try to challenge the idea of computing
this appearance in advance and so try to
develop a model of a set of models and
this can be a test and grant asked for
try to test if the the final appearance
computed can really match with the real
appearance that is exactly what kareena
did in painting
because when when you need to reproduce
what you perceive what you what is your
sensation you have to choose the right
weather color that is exactly the
matching of your appearance so what what
a good mother should do is should just
basically to fit this data just include
since everything is has been held within
the create the great program these are
the schedule of the next two events and
everybody of you is welcome to
participate if you want and for sure
they all the sets and the experiments
about this experiment that we will will
continue within those two dates and
let's conclude the whole idea and thank
you for being here you mentioned him in
a section about the perception of
appearance and John talked mostly about
the sensation of appearance how do you
how do you reconcile these things which
one was playing talking this one I mean
we're talking about sensation because
perception all exist and take place but
it's too complex to compute that's not I
mean this is my opinion sorry yeah what
it was absolutely wondering if you get
it until he was talking about the
sensation
the perception that's why we continue to
argue for 50 years yeah so in the in the
photographic rendering business that the
problem is to to create an appearance on
a photographic reproduction that gives
the viewer a perception that's close to
what he would have had in the original
scene right sandy well they kept it's
complicated we became that my favorite
image of my info man survivals of
self-portraits he was actually
photographing the Grand Canyon to Kodak
to put the Grand Canyon around Grand
Central Station in New York City and
some clouds came by so he had a lot of
time to waste he took this wonderful
self portrait in which it was his camera
his hat shading the lens and the camera
but the whole picture was just a shadow
and so there are various people have
written algorithms to completely remove
shadows to get at the surface
reflectance of the image and I always
show them this if you took out the
shadows perfectly you would remove Ansel
Adams frontier self-portrait but that I
think is that
the perception is of the object there
was no Ansel Adams it was the dirt all
right that's a good illustration but
most people wouldn't it's a it's hard
because 30 40 years ago everybody used
sensation now we're going to use
perception or everything feel a little
bit like an antiquarian but by harping
on this but I've written so much I have
any other questions I'm sorry I came in
late mrs. hospital my area of expertise
and the one thing I get was that we
don't discount the aluminum but if you
think of the original system is working
on aesthetic you really confounded three
different factors in making this a
difficult scene to to separate those
things there's behind endemic rage just
in terms of the brightness there's the
color of the light and then some of the
objects were were shaded in a tricky way
you know when you have a bluff where
your visual system might you know your
perception might assume from the top
level that it is usually equally painted
but it wasn't in this case and so that
might add tubes for the top level
top-down perception that it's not you
know but the colors are often what
they're actually so I i wonder if and I
wonder if two of these things namely the
color of the light and tricky painting
of the objects are especially hard to
the human visual systems
I'll heuristic alee and maybe just the
high dynamic range and the contrast is
easier so I I feel like these things are
like separating things apart and making
several conclusions for each of them
would be more instructive putting them
all together making a blanket assumption
that illumines isn't high separated if I
can take your question I mean you talk
about three separate points but they did
amazing things and if you can recompute
your image starting from the
relationship they they go and they are
set perfectly in terms of appearance
that means that it just in thinking that
we do not perceive the value itself but
we perceive the relationship of the
values in the scene automatically go and
discount illuminant and not not a scant
alumina in terms of the geometry but
takes if you have a big color cast you
partially remove it and you readjust in
the value and you'll give what the
appearance the funny appears and in
terms of a dynamic range you real just
locally also the the distribution of the
light in the same just taking the
relationship
no injustice it just kind of amazing
there's they want one of the this bunch
of algorithm that we call it special
color algorithms that if you go from the
space of the input data that is roughly
the physical color and you try to
recompute the relationship among colors
distribution in the scene there's a very
positive side effects that exactly the
solution to the three points that you
addressed of course the speaking about
computational promise they're very heavy
because you have 20 n square and so this
kind of things but the humans do we do
we do it has a purpose it with the Allen
Childress framework is it should be
talked down you have a framework and the
framework is you've gotta find what's
reflection supports information so
that's this whole cognitive you've got
to figure out this whole thing come back
and modify modify the appearance of this
and this based upon what you top down
work that we've done I've been
associated with above and bottom up do
you really have to do this top-down
stuff because computationally top-down
is much more intensive than bottom up
because you've got allies the whole
picture from the image from the pixels
on the scene to get the right answer to
come back and modify the insolence very
difficult if not impossible I see your
point yes we have pushed everything we
can in to the 3d Mondrian we made it as
extreme as possible however along the
way like these pictures in my backyard
those are slightly different illuminants
because it's unlikely skylight but the
there is a large litany of experiments
along the way that break it down a step
at a time when I think build up this
consistent idea what humans do is
spatial processing show you that picture
moment
okay okay thanks guess one more out one
more yeah so are you attempting the
model any of the effects shown in your
presentation and if so what's the status
yes so are you trying to model any of
the effects shown in your presentation
so what is the status of that you be
asking about the compositional model
available around oh that's many of them
and that's why we did this what one of
the reason we did this is that was very
useful to have some data to try to just
for instance a model all this mode of
this family of models as parameters and
so this data can be very useful in in
order to tune parameters as well but
there's a bunch of them I we our group
just developed three four of them but of
course every the basic idea comes from
rednecks that is the original idea of
land and the camera my batteries plug it
in the next week I haven't my machine to
preliminary start up one of the titans
as an HP family
processing they both show significant
improvement in the HDR image and
particularly on the HP camera is because
there is no change in the hell do I can
show you that we just started but
there's
the question is not whether it will work
its question which is the best way okay
thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>