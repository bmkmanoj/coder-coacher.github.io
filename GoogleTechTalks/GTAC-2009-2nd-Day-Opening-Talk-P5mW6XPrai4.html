<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2009 - 2nd Day Opening Talk | Coder Coacher - Coaching Coders</title><meta content="GTAC 2009 - 2nd Day Opening Talk - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2009 - 2nd Day Opening Talk</b></h2><h5 class="post__date">2009-11-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/P5mW6XPrai4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">but happy to welcome Alberto from CERN
he will talk out to us about the
infrastructure project that he is
leading for the last four plus years a
tix now ethics to which is the second
iteration of this and I'm looking
forward to interesting insights into a
true grit offering have fun thank you
yoga good morning everybody I hope you
can hear me hey we have voice this
morning i hope it will hold until the
very end so first of all i would like to
say that it is a real pleasure to be
here the passion and enthusiasm I can
feel around me I'm really great and the
quality of the people of the
presentation so far have been really
impressive so far so let's move to my
own presentation so in the next 45
minutes or so i will talk about ethics
ethics is a project which has been
established to become a sort of software
engineering infrastructure for a
research project in europe japan
european project sponsored by european
commission so first of all i will give
you some background about what the
reasons behind ethics starting from CERN
and cg NDG project then i will go more
in detail into ethics as a build and
test system and end with the some of the
challenges that we have to to confront
with the next steps and conclusions i
put here a small grocery i'm going to
mention a number of acronyms in case
your doubts or get lost you can refer to
this one or ask me so let's start with
the CERN and cg and the EG as you can
said and i come from from CERN and as
you may know summer is the European
Center for nuclear research
and is you can say one is the biggest
european 11 of the world because the
research laboratories for nuclear
physics for particle physics it was
founded 55 years ago and has currently
20 almost 21 members namely from Europe
but with many other participants
observer or a saucy associate from all
over the world and it is also known as
the place where the world wide web was
invented it may recognize a tim
berners-lee from this picture working at
CERN when he invented the HTTP protocol
so one of the major current major
endeavors of CERN is the LHC the Large
Hadron Collider which is a machine is a
tool is a big ring running England in
the underground beneath the border
between france and switzerland where
physicist will try to accelerate hadrons
it is a large heavy particles I'd like
Newton neutrons and protons and smash
then one against the other of the high
speed and very high energies to see what
happens see what what are the effects of
this collision what comes out of this
and try to identify particles different
particles especially particles that are
known by in theoretical models that have
never been observed in practice validate
a theoretical model you need to have a
practical experimental observation list
and one of the major expected results is
the discovery of the mythic Higgs boson
which is the last missing pieces in the
unified theory which will actually sort
of prove that the current that he or
they are correct if it is not found be a
lot of fun for physicists to try to find
another unified theory now this is a
major endeavor and requires supporting
major computing and data infrastructure
to do
so this is the LCG LHC computing grid is
a collaboration between various parties
so the physics is the scientist doing
science we use all these these tools the
infrastructure and middleware a projects
are developing the actual distributed
computing and data infrastructure where
all the data can be collected analyzed
they were constructed the hope of
finding new interesting evidence and the
actual service providers for the
underlying network services and
everything that is needed to keep this
big huge machine running it is a
worldwide collaboration you can see the
yellow dots are different sites
participating to this effort is made of
almost 150 different Institute's all
over the world certify the countries
with thousands of users and growing in
parallel to that and a bit overlapping
if you want is another project called eg
which is enabling grids for e signs
which is a project started about six
years ago by by the European Commission
to extend and enlarge this distributed
data and computing infrastructure to
other sciences not just high energy
physics about any other science that may
require this kind of computational and
data management capabilities from life
sciences biology biomedical sciences and
research Shannon graffia astronomy or
humanities like archaeology or other
science it is a very large scale is
Ernest probably the largest scale
collaborative endeavor in Europe and
probably one of the among the biggest
thing in the world so this is the
background and ethics is born out of
this experience so in this kind of the
extremely distributed infrastructures
you have a hundreds of Institute's
thousands of people people working
together not only for the
physics but to provide infrastructure
the middleware and applications you on
this infrastructure it becomes difficult
to to find the common way of working
together especially in software
development you have to take into
account that is very difficult in this
environment to actually force anything
people come from different is due to the
different cultural and technological
background they are used to use
different operating systems different
different languages the different ways
of developing software they are the
different skills from very young
graduates to very experienced the senior
architect now since it is very difficult
to to force any particular architecture
in particular language the decision was
taken to try to find a way of the hiding
the complexity and provide the
collaborative tools where people can
efficiently collaborate bringing their
own experience and their own skills but
with the common interface is that
everybody can can efficiently use in
addition to the actual software
development here you have a pictorial
representation of the various complexity
operating systems different languages
there are different types of
dependencies among different products is
not just dependence in the sense of
libraries what functional dependencies
services needing each other in order to
provide other services and the top of
that you have the emerging standards at
least in this particular grid world for
web services for particular data
management standards computing standards
that the different services have to try
and comply with and since these are
emerging standards of course as in all
emerging standards there are four or
five versions of the standard which
defeats a bit the purpose of being a
standard but it is a natural process and
it is necessary to do converging try to
collaborate together and on top of that
you need to do some testing teaser of
course very difficult to believe that
all the different pieces are developed
in different institutes and put together
and they magically work so hard to do
this the ethics project was actually
started to
try and create this collaborative
environment software engineering testing
and quality assurance for for these
these projects and the moment ethics has
about 45 different registered projects
not all of them are particularly active
about 10 very active using all the
different features but they cover about
sixty percent sixty sixty-five percent
of the other total development in Europe
it stands for infrastructure for testing
integration and configuration of
software you can happily forget kinetics
and if restriction is a important apart
from the year when they they e was
mandatory wants a mini proposal because
everybody had to be called a something
for me for showing their commitment to
the new evolution but let's say it's an
infrastructure in the sense that is not
just a tool it's really an
infrastructure made of tools processes
resources machine people to provide on
this sort of collaborative environment
for everybody to use and it's its goal
its purpose is really to try to do very
distributed testing integration and
configuration of the different soft
middleware and applications produced for
this computing and data grid it was
funded partially by the Commission the
European Commission and partially by the
participating Institute in 2006 and now
it is ending is a second phase which
will end in highbury 2010 next year next
year and after that all the software it
is open source will be released as open
source completely open source some
mechanism to be decide then possibly
hopefully used by the taken by the
community or integrated in other ongoing
projects these are consortium among the
eight different partners CERN is the
coordinator and then you have the
Italian nuclear physics Center to
commercial companies are experts in
testing and quality assurance the other
other University of Wisconsin
research centers in Hungary in German
and Vega commercial company developing
software for the European Space Agency
all them bring different perspectives
and different expertise within the
project in a nutshell very quickly
ethics is essentially a continuous
software build test and quality
assurance verification system it is
designed to be as a flexible as
extensible as possible exactly to give
people possibility to contribute and
modified to get the best out of it can
be used for doing scheduled bills or
tests or on-demand build and test by
individual developers and users and it
can be used either locally on your own
computer or remotely by using the grid
itself so the main objective behind this
project is to use the grid the grid
resources to test the gate in order to
be able to provide the realistic
environments where the grid can be
tested because trying to to test the
grid they're a real grid the distributed
grid at least the type of data we are
working in a control laboratory
environment is completely mismatched
because what happens outside that is
almost unknown in terms of interaction
between the different services the
people would lead to our concern so we
try to provide realistic test beds which
are part themselves of the grid as
connectors to to be able to push these
didn't test jobs down into the grid
using values and technologies and we
show some of these technologies as a
repository where everything that is
produced by the system is stored of
public access packages test build
reports test reports and compliance
matrix or anything that is produced and
can be accessed using a standard package
managers management system look like ya
know which is a standard for the money
on some versions of Linux and it is a
multi-platform an independent from
specific language or build tools is not
done for java on 46 plus of python or
for linux or windows if it tries to be
as abstract as possible and to exploit
the functionality of different operating
systems in different ways
this is a pictorial vision view of the
architecture so it has a web portal
where people can the people can access
to to get access to the different
functionality of the system from
configuration repository jobs amnesia
and so on clients written in Python to
be as portable as possible for the
values as many platforms as possible and
a configuration web service and database
where all the meta data is collected so
all information about the different
projects the packages of the test
everything is stored in a common place
in order to be able to create
relationships among the different pieces
the repository service which stores the
output of the processes and the
execution engines which take requests
from the user and distribute them to the
grid before for execution and the actual
place where the bills intestinal are
done are called worker nodes which can
be physical or virtual or a combination
of them and we'll tell you more about
this later authentication authorization
and accounting is done using a client
and server certificates this is very
typical of the research grids almost
everybody in research if it has a
certificate issued by some high level
certification authority either national
level or from very big Institute for
example sirnas its own certification
Authority but France or Germany or UK
have their own certification Authority
and they create certificates for drift
values research infrastructure so you
can access the system by using your
certificate and must come from one of
these accredited certification Authority
now we are trying to change this because
this is limiting is a bit limiting in
terms of access many users are
complaining at using certificate is too
complex and they would like to use a
user standard user name and password or
she bullet or Kerberos tokens methods
used in various domains and try to
integrate them a single interface you
can access even without certificate or
password which case you are guest and
you can look at the data but not
modified and it provides a flexible
authorization mechanism on individual
objects or
or different parts of the system the
current system is installed at CERN and
this is the address ethics about sound
och when you login with a certificate
you of course are identified yourself
and depending who you are you may see a
different part of the system are an
administrator you see also the
administrative tools are you see
different paths the of the entire system
and from the web you can see in
different parts of the informations or
list of projects and all the
configurations of different packages and
for each configuration you can see on or
edit if you have the permissions all the
different properties the bill commands
the test commands environment variables
properties specifically and this can be
either global or per each specific
platform where you want to work with and
you define the entire build or test the
structure in this way with a common line
client you can do essentially the same
the same things as the web portal but
these are more designed to to do
building tests on your local computer or
to integrate the system inside existing
software engineering activities if you
already have a process ongoing you can
use the Python API so to take part or
all of the system depending on your
needs the repository they said the
contains everything that is produced by
using the system in terms of Delta s to
Quality Assurance web portal and matrix
and dynamically generate these yum
repositories so whenever you do a build
or a test everything is or is
immediately available for for chaining
action you build the produce packages
and these packages can be used for
deploying and doing configuration test
or or functional tests and it can be
easily browser queried with values
mechanism there is a rest interface can
be queried using XML or expert syntax
and there are mirrors that there is a
client and there are mirrors on shared
file systems like AFS for for accessing
them from other programs this is how the
depository web application will look
like the other list of all packages and
all the other shoes and there are links
between the packages and the jobs that
are
created those packages and vice versa so
you can see which packages been created
by a job or which job and who which
person has creating the center created a
certain package and for each package you
can instruct all possible information
and metadata to see what in contains
over how it works execution engines is
an important part of the system to
distribute the the various tasks and to
prosecution to the grid at the moment
there are values ways of using these
ethics ur can can work with the existing
the summation engines it uses existing a
batch system or grid summation engines
it started with condo which is a been
developed in the United States but
University of Wisconsin 10 years or more
ago which is one of the first very the
systems of our high-throughput computing
for parallelizing execution and multiple
individual machines not super computers
then unicore which is actually the
middleware on the contrary the middle
were done for accessing supercomputers
amazon web services so we are
experimenting a bit with clouds this is
a really very experimental at the moment
july which is the middleware used by EG
so this is really delight can test
itself on the grid using itself and we
are adding a less grid oriented more
batch system oriented the possibilities
like as ssf4 PBS for non reducers or
more conventional application building
with ethics just a quick overview how
does it work so in principle building
with that if some means using 3 comments
ethics get project this and you specify
the name of the project this gets all
the information about a specific project
for example ethics or july projects once
you have the information about a project
you can call ethics check out to extract
the actual code or packages for that
project and with it a check out you can
specify if you want to do full source
build everything from source or a
combination of source and binary for
example you want to be from source only
a portion of the system but you are
happy to take from binary whatever it
comes from another project or all the
dependencies and this can be taken from
any any source can be version control
systems like CVS or svn can be HTTP
enable repositories can be any any other
any other repository of your choice by
using a plug-in supply cable the
pluggable connectors once you have
extracted this the system builder the
all the dependencies among all the
different packages and you can call
ethics builder to build the whole lot
and you can build the firm from a single
package to an entire project of two min
of lines of code exactly with the same
three comments and each individual
package is built with its own commands
so this is a important part from the
ethics and the social point of view a
project as i said is made on 10
different languages or five different
computational systems and all of that
has to be accessed with the same comment
so using ethics builder in starts a tick
so to query to user information for each
package and then activate the individual
build commands and individual tools for
each package collect all the all the
information of the packages and then
create all the necessary links longer
order of the products and as part of the
builder it is rancer various types of
tests and validation problems static and
I aunt Esther you runs you test coverage
standard compliance testing creates
packages or reports and hold up so all
the matrix are collected by using
plugins this is now is quite typical
meaning to think this was started almost
eight years ago now it's much more
conventional so it is a plugin based
plugins are rappers are under existing
tools open source tools or commercial
tools or custom tools and created by the
users to do values to add values types
of functionality to go to the system and
they can be activated by user choice so
user may set profiles which package from
high-level profi saying this packages
Java which means activate whole set of
plugins and suitable for Jana
or you can specify individual tools that
you want to run or you can ask the
system to detect what is the best option
using the auto profile option in which
case ethics will try to understand what
is the optimal set of plugins to run for
your package and which matrix have to be
connected and everything is then pushed
in the repository for later analysis
trend analysis Quality Assurance
verification reporting and so on these
are just examples these are very common
open source tools for various languages
at the moment we we try to cover as much
as possible of java python and c c++
which have the three most used languages
that we cover about seventy percent of
the total few screenshots this is a
typical example of this this is an
overview this is the matrix overview
page of the bill and for each pay for
each metric you have an overview page
again from the specific matrices account
and if if a tool produces HTML reports
we just use them otherwise the data is
digested and formatted for for the web
this is the output ck GM and i believe
or a check node checkstyle chest i and
this is the output of the ipv6 code
compliance a checker which analyzes code
to see if there are illegal commands
illegal er functions from the point of
view of ipv6 compatibility now there is
also a possibility of creating
dashboards for users this is a user
configurable so you can users can give
us a an xml file containing which of the
matrix they want to see display the
which information like the list of beans
or platform compliance and so on and we
can generate specific reports for and
for each project and another feature is
the ethics packager so we try to isolate
the developers from packaging which is
not always successful and not everybody
likes it but is very convenient so in
principle we use the metadata
information to create the packages of
the most usable packages for each
platform so you can create your code and
athletics who deploy to her to be
is called on five of flavors of linux or
windows on my class solaris and and
ethics we create the appropriate
packages for her for this from this
platinum it covers about eighty percent
of the packages from functionality and
if this is not enough we can overwrite
it and do your own packaging the
developers in this case the developers
focus on the code and not on the
packaging and it allows to enforce
strict packaging guidelines with a bit
at the beginning was a very was a big
problem because for example setting the
right dependencies in the packages was a
problem if you were working in Korea and
using something developed parties and
like this everything is centralized and
the information is much easier to
identify and see what what happens if
you change something in the system and
finally the the matrix can be used to to
enforce something that we have created
called the aq cm in automated quality
certification model which is a an
implementation of values are iso
standards and particularized or 9126 for
confession which adds to the the normal
standard two aspects one practical
implementation the guidance don't don't
do them don't say anything about how you
should do like this they tell you what
you should do we try to tell the users
how they should do it and put the strong
focus on the automation of the process
and use it the metrics to measure the
quality I mean I could measure with any
quotes because this is very subjective
it depends what what incident in each
individual project consider as quality
and it has been recently presented in
rome's with one of the ISO
standardization working groups and this
was last Tuesday and I have been told
yesterday that it has been received
weather with interest which is a much
more than a very respected and it is a
important circle
testing let's go to into testing part so
you can test on ethics in exactly the
same way as you build with the three
commands get project to check out test
the difference is that instead of
getting things to build the software to
build you get tests to run but the
mechanism is the same and you can also
have dependencies between tests and Rama
different testing in different
sequencing the but this this is for
single no test so you can run a test a
single computer either your computer or
the grid but is still a single computer
which is interesting not not so excited
the important part is the multi no
testing this is our presentation over
for example of the July to stack which
is made of many different services and
again you see this is complete but again
in that inside that picture you can see
already probably six different languages
and different technologies in terms of
web service containers security and so
on so what we are trying to do is find a
way of actually deploying all that
completely automatically when if I want
to test an application on a particular
version of the grid which is not used in
production something new an individual
user are as absolutely no way of
installing a grid first test its
application so what we are going to say
is please tell us important from your
application point of view which services
you need to work with up to the point of
saying I need the grid as the bunch of
the whole lot and then the system will
deploy the grid for you and run your
application a new test for you and then
clean up everything and give you give
you the results and you can mix and
match different versions of the
different services but you don't have to
know as an application provider how to
do now there are several challenges in
this are you can expect so first there
is a service synchronization so you have
a combined multi-node test made of ten
services and they also have to be
deployed on 10 different worker nodes so
that the worker node the different
services has to have to synchronize
among each other so the
they start they maybe have to stop
waiting for another service to do sams
and then restart and could publish some
information and there is a need for a
shape exchanging information some task
on one node may require input from
another task on another note and they
don't know each other because like it's
being agreed that we with ourselves
absolutely no idea where the individual
tasks are going to be to be run which
machine which house name which IP
address even which part of the of the
world this is going to happen so the
nodes have to be able to communicate to
each other across all the layers of
securities and firewall and barriers we
may have in between and then flow
monitoring well where to go home when to
go home when everybody is finished
everybody has to go home and went to a
party if you ever protested the trans I
supposed to run for two days and it
fails after ten minutes then you don't
want to wait for two days until the
timeout is reached probably the results
so there must be a way of communicating
to all the waiting nodes to some singles
other so this is done it's a very basic
approach very simple approach this point
we are not trying to do invent anything
particularly clever but this is made on
a simple set of api's get it its get set
in for executing this message so Gator
gets a key value pair from the internal
information system and set sets a key
value pair on under the system these are
all the webservice place the port and
there are metals for setting up or
logging at exactly allows with an
instrumentation plantation method it
allows to run commands on another note
but not arbitrary comments so you can
run the high level comments that the
service is exporting to you so you can
start stop load or not configure and so
on so let me show you a very simple
example this is a hello world type of
example being so we have a client and
the server and the client has to pin
this ever done but it is to prove the
concept and the client has of course
have no idea or where the server is what
is his name I can
or when is it is going to be available
in they are submitted and they mainland
in completely different parts of the
world so these are the two parts you
have the first part in the server which
does an etic set of its own IP address
and on the other hand the other the
client which as part of these comments
there's an ethics get of the server on
the same available with a timeout minus
B means timeout it says I need this and
I will wait for a certain amount of time
and until it becomes available this is
how you submitted you submit the entire
multi-node test with a single command
you don't submit engine with your test
you submit the multi no test and you can
specify if you want I hope it's readable
you in you can specify if you want to
submit the entire test on the same
platform and or multiple fountain so you
can submit to the same multi-node tester
on right after four on scientific Linux
five on Windows and Mac OS on sun and
all the different nodes will build on
the same plot or you can mix and match
so you can say I want to run the client
on Mac OS and the server a win and then
internally the system will allocate as
many notes as a necessary and distribute
to the different tasks to the values the
values nodes so this is what happens
during the execution the client execute
is a ethics get command and then wait
until the server is able to to give the
result back or there is a time of the
server at the same time some somewhere
else in the world doesn't accept that IP
address and when this happens the client
isn't notified and then uses the
information to continue and then
everybody goes home now there is there
is a huge problem with this which is a
resource allocations so what what
happens the first implementation the
composition of the resources were fixed
in the sense that all the different
participating sites had a number of
physical machines installed somewhere
with the specific platforms now let's
assume you neither
sl5 which is x5 is a clone over right at
five and used for scientific
applications and typically looks right
you need a Cell 5 64 bit but all sl5
64-bit platforms are taken so ever you
have a mountain of jobs requiring 10 15
20 SMS and five and after the first the
first ten I've gone through the other
ten have no place to go and they have to
wait so at the end the test may never be
executed because by the time I knew the
platform becomes available the first one
may have ever reach this time out and
the test is about so issue one of the
job are cute and at the same time many
other many other computers are either
not doing anything simply because they
don't have the right platform for this
job second problem is what happens if
there are obsolete or rarely use
platforms nobody except one small
project user read of seven anymore but
we need to support this project this
means that there is a there is a
platform computer with right at seven I
don't four ninety-five percent of the
time while every other platform is
struggling for resource so of course we
want these to be dynamic now consider
this like poor man clouds mouse is our
first attempt for doing this wasn't
doing this so in principle we assume
that the all the machines are whatever
they want to be doesn't matter which
part from the run as long as they can
support visualizations only they have to
be some type of hyper visor in stone and
the moment we support VMware kvn or an
exam and when a job is submitted it
contains its platform requirements and
the appropriate virtual machine is
instantiated so whatever is needed at
the given time is instantiated and all
resources are always used to the maximum
of their capacity now this is not as
simple as it may look because we cannot
just visualize the worker nodes so there
are several problems with this first of
all
in the virtual that the worker nodes are
attached to this emission not and the
job submission engines normally have a
server in the client part the client
part has to be installed on the worker
node so in order to make a virtual
machine look like a worker node we need
we would need to install the client part
of the summation engine on each virtual
machine for each platform so this
problem makes the number of images that
we have to support explode because we
have to have an image for each type of
worker node original type of platform
for each type of submission system now
even in this is a huge maintenance issue
of course because they have to be
modified every country the change in the
operating system or the workable the the
submission engine client even if we
could do that in terms of maintenance
the problem the second problem is that
most of these emission engines are not
very elastic in the sense they they are
not dynamic you cannot say hey I'm a new
worker node I've been just instantiated
please use me they must be a link
between the summation node and the
worker node established with
configuration on the server so even if
we instantiate a worker note that the
server will never realize that is a
worker node and another issue is that
not all the type of job summation
engines support all platforms so in any
case we for certain jobs emission
engines we would have to limit the
number of support department so we did
in a different way as far as the job
submission engine is concerned there is
no modification to the actual work and
so the worker node client is still a
physical work around client but then
instead of shipping a see a normality
job dated job comes with a program
called the bootstrapper that downloads
the property in Ajuri me in the worker
node the bootstrapper downloads the
image it interacts with the hypervisor
software to instantiate the image and
boot it up then transfers to the virtual
image that the actual task to be
executed and at the end brings back the
result so as far as the submission or
disconfirm there has been no
virtualization they still a worker node
but the actual task
security inside worker node of a
completely possibly completely different
operating system so challenging
conclusions the challenges in all that
since the beginning and talking about
the war he started about eight six six
seven years ago so the first one is a
techno cultural challenges so the
academic research environment has a
limited focus hard at least this is
changing lucky limited focus on software
processes and quality assurance it is a
hope there are no scientists here apart
from computer scientist but there is a
completely different approach in how
software is developed in many scientists
have a need for a tool that works now
and they are not really interested for
understandable reason to to maintain
this tool or two to make sure that
someone else can maintain it or can use
it in two years time so the it's more
based on discardable prototypes not the
sense of a giant but really prototypes
that become a permanent installed them
some in some server and not touched
anymore and as the research
infrastructure grow this of course is
not maintainable cause that a piece of
software that nobody knows how to
maintain anymore and the intention is
very limited or the software is being
written with we're very poor computer
science skills but this requires a
perform the change in the way software
is developed for these are activities
and change especially in the training of
the developers and how the software
development activities are performed
which is a change or not not really in
the developers but in the management
ourselves of myself do to make sure that
they they they are properly trained and
properly informed about what has to be
done security is another challenge so at
least originally in science that were
very little not attention but very
little need for security all the
information is sort of public
no confidentiality issue more or less
but this is changing as the activities
scientific communities are being
enlarged if you start working on
biomedical applications then you have a
confidentiality of the data the patient
and information cannot be simply put on
a web web server it has to be anonymised
of pseudo naanum eyes it has to be
transferred there are international law
regulations for the privacy that to be
taken into account so all this has to be
considered now and this changes also the
way the software is designed there must
be this might be taken into account at
the design lab and not just adding
moving from HTTP to HTTPS on a web
server is not super imposing security
that is what and the third challenge is
sustainability so how to move this there
is research infrastructure for something
that is at the moment largely sponsored
by European Commission for creating it
but should be come sooner or later
commodity for scientists and
sustainability also know in terms of of
becoming our commodity but becoming also
self-supporting and this requires to
produce a real business models in these
kind of activities so that if I serve 84
84 service which ours by then we can
stand up can be provided for example by
a commercial company or system
integrator etc rather than a university
it is a much more sustainable model and
the European Commission is encouraging
us to to go strongly in that direction
so there are two new initiatives
starting next next year called the GI
and emi the european grid initiative and
the European Middle were initiative
which have been tasked with this this
challenge so the the outcome of this new
project must be please don't ask any
more money to european commission we
know from now on you're on your own now
I'm this is a bit too strong a statement
but certainly the idea is we should find
ways order of moving this morning to the
community or having ways of making this
more commercial business
and hide the users from these users our
users are dentists not computer
scientists are physicists the biologists
oceanographers astronomers and they
simply won't want to upper to you want
to have a web portal an application I
need this i estimate i and this may take
so much time and I need so much memory
and it's kind of bandwidth this is it
probably isn't too much for a biologist
but all the intricacies of how this has
to be done and what are the security
models etc or how to get resources to be
completely hidden from them and this is
a huge challenge so in conclusion I I
believe I'm proud that I can say would
we have done in the conditions we have
done it I can say that the ethics has
established a real distributed facility
for water engineering in Europe in this
kind of restructuring infrastructure to
analyze and hopefully improve the
quality of the software that is being
developed and we had the several
challenges to to confront to to address
and we have done it we have doing it
there's still a lot of work to do but we
have hopefully raise the bar a bit in
that and we have raised awareness in
many many communities and hopefully also
the level of the decision-making power
level of the European Commission on the
need of making these processes a bit
more sophisticated them out to be a bit
more professional oriented if you want
more information there is a website www
ethics project view or the free to
contact me and time and with this thank
you very much
thanks a lot this was very interesting
i'm sure they're quite a few questions
out there yeah I have one question about
the distribution I guess we'll actually
have two so I guess you anonymize the
data so that it can be distributed to
whatever data center is available for
this so that you don't have to worry
about privacy issues or did I understand
you correctly yeah in some case it isn't
okay then about the distribution so i
guess the individual like participants
in the project host based data centers
so how do you handle the cash flow
between the participants or is it just
because they are participating in ethics
that you can use resources from whatever
research is to do this happens to be
available and has suitable nodes yes
there is a very particular concept in
the research infrastructure which is a
view of virtual organization so a veal
is really an organization of people
resources and site so in order to work
with a particular in a particular
community and access particular
resources you have to be registered with
the particular bit organization using
your certificate and once you are
registered you are given access
according to established rules to do to
a share of those resources and the only
an organization of that it's better
still based on on these credentials
there are key stores there are ways over
the sides don't have access to do this
even if you store information a
particular side to the side themselves
cannot decode the information thank you
hello my name is John Brown I come from
the vmware in switzerland office and now
you mentioned that ticks project you're
using them well that's very good and
thanks and my questions that normally
during the test procedure some tests may
take a very long time say maybe one week
or even longer and somehow may be added
at the end of near the end of the test
procedure there's something some service
failed and then probably we couldn't get
the result we expected so is there a way
that or or any Mexican had been
implemented in the ethics project that
chelate they use the whole procedure to
be recovered in the middle point or
somehow and then can save their time to
rerun the test thanks thanks for the
question any other quiz and yes I know
so I mean all the information it doesn't
matter when when the test and if you
tend successfully or it is abort it
doesn't matter everything that has been
produced until that point is recovered
now we we are implemented now a way of
actually storing the entire virtual
machine not just that the data so we are
in the main problem is actually storage
at this point storage for us but in
general because torture is actually
priming can be can be easily found but
we don't have enough storage in the
project to to learn to do this but we
are experimenting with this concept so
upon request of the user instead of
bringing back the actual no fine we
bring back the entire set of virtual
machine images snapshots until the point
so you can actually replay them modify
something and replay and restart from
the point where are you were you left
but this is not even experimental this
is almost at the thought it's the design
level but yes it's an
sorry so what what I think it's right
it's based on each individual
applications it's not have a DNR o globo
make me them to automatically recover
know it originated his environment now
it is global it is global poetics and
say this is an ethics option so you
could say for this test please bring
back all the images that have been used
for this test not for a particular
application on all of them so if your
multi-node tests involve the 15 notes
you get 15 images one for each know that
was involved you can reinstall them
yourself on your new hardware or
resubmit these 15 machines and restart
from the point where it was a booty but
it was left okay thank you that's also
one channel one difficulty I encountered
during my work thanks I'm next what's
your schedule for open sourcing this it
is open source I mean it is already is
released under apache2 license beautiful
it can be taken at the moment is on our
website at the end of the project the
idea is to release it a bit better in a
number in a more common and mainstream I
open source repository sourceforge or
something like this but at the moment
for for legal project requirements we
have it on on the cell service but is
still publicly accessible user committee
open source apache2 license thank you
no one else comes I I had a question
could you talk a bit about the size of
the system how many users you have for
big stew codebase right but what's going
on every day on the system how many
nodes or worker nodes are there etc so
there are several levels so they the
system yet exist amid self II I don't
know exactly the number but we are
talking about six hundred thousand lines
of code in Java and Python users there
are almost three hundred users
registered the moment fortify the
projects of which which 38 are active in
the sense that they have submitted the
either build or a test in the last 30
days and about 10 which are very active
says that you use it on a regular basis
at CERN we have our own pool which is
about 150 courts and then the grid I
mean deserve principle that is is only
limited by the available course on the
grid which is at the moment he's a
hundred and fifty thousands of possible
subsidies the net but using this vo
mechanism so ethics is a vo itself and
has a result share of these resources on
participating sites and these changes
depending on the on the on the needs of
the site so on a closer to I release a
particular site may decide to allocate I
don't know ten percent of its resources
and far from the releases it's only 1%
of my resources which keeps changing
hi good morning can you maybe talk a
little bit about the staffing of these
efforts how many people are involved was
the management structure of the of the
teams are doing this of ethics itself so
it takes up and well the activities are
around this kind of built a threesome
some quality verification started six
years ago as part of the of the first EG
project so the time as he surfs ago
ethics did not exist and we started when
we started with three people and we
recreated the first version book other
sorry the first version of the system
but at the time I was based on cruise
control not on our own sort and at the
time cruise control was them the best
tool we could find in English in this
domain but we had the number of problems
namely was very job oriented and we had
them any other languages coming too so
we had we customize the cruise control
or we put sort of layer on top of cruise
control to use it but at the end when
when the first EG project finished and
ethics was created we decided to design
the system from from scratch and in the
first statics project there were 10
people and then the last latex phase
which is finishing now we are talking
about 30 physical bodies not all of them
working full time on these kinetics but
ya around pending on their own on the
face of the the project between 25 and
30 people across the eight partners that
I mentioned so some external in Italy
some in Hungary in Germany
and you want to know about the cost the
first ethics project was was about 1.1
million euros and the second is about
2.8 million euros or three we're talking
about 44 million 4 million euros in four
years not all paid by the Commission
ambien it's not only taxpayers money is
also the individual universities paying
for this which is team packs players why
not maybe have maybe one question it
nobody else has one on the testing site
how do you visualize the results and do
you know how much percentage of tests
actually running on this infrastructure
and whispering attention to the results
hey this is an interesting question
answer so all the all the tools of their
the test can be can be visualized since
that for the builder for the unit test
you have a complete test of all the
complete list of all the unit tests that
have been around and the coverage
etcetera and for the functional tests on
the multi-node you have the report so
you see exactly on each northern what
happens so from a reporting point of
view we can see everything the problem
is this one of the challenges very few
of this project the projects actually
have something to run on this so the
moment the average of coverage of unit
tests for example across all the project
we are working with is about twenty six
percent which is pretty low and in terms
of functional tests there is a one
project fully using the functional test
but I cannot tell you I don't know
exactly how many tests they have what
they do with this test and all the other
projects are doing some experiment with
this and we are working with delight
which is the biggest to to start doing
more functional tests with them first
deployment configuration test and then
functional test using the multimode this
is still very the beginning
I have one I have one more so if I heard
this right the objective of the current
phase is to basically phase out of
building this infrastructure have the
objective to establish it for good and
for longevity and then CERN and other
research research organization can use
that infrastructure ongoing and the anti
visit anticipation is there will be no
group to maintain this and fix it and
and you know other the nasty part of it
soft very relevant is that true no no
well to be too extreme so in the sense
that it's not true that there will be no
group to maintain at the hope is that
there will not be any more sir nor
research institute to maintain so either
becomes a fully community open source
project hunting but the community or and
this is what the commercial companies in
ethics are trying to do it becomes
something maintained by the commercial
company still open source but they use
it they are they are doing marketing now
themselves to use it for providing
services and therefore they will extend
it and do maintenance for their own
profit or interest then in addition to
this the model is actually to to have
the infrastructure maintained not by
central funding the from european
commission but to other the the national
research programs to contribute so these
are called eng eyes and the national
grid initiatives every country
contributes to the entire European
infrastructure in various ways with
money or with resources on to do some
some task so but the effort is need to
get this out of the research
infrastructure and move this more to
companies or dedicated maintenance teams
ok I think that concludes our first hour
of the day thanks a lot thank you very
much you and let me hand this over</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>