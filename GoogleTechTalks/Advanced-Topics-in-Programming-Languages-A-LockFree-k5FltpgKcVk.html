<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Topics in Programming Languages: A Lock-Free... | Coder Coacher - Coaching Coders</title><meta content="Advanced Topics in Programming Languages: A Lock-Free... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Advanced Topics in Programming Languages: A Lock-Free...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/k5FltpgKcVk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the latest in our series of
talks on programming languages today we
have a very special guest star a a man
who works across the street at azul on
computers that have many many processors
he formerly worked at son where he was
one of the chief architects of the
hotspot vm and he is doing some very
similar work at at azul and he's here to
talk to us today about his experiences
creating a lock free hash table for java
that scales very well his name is cliff
click and this is he thanks so um just
to show that I'm only sort of snot too
far behind the time I actually have a
blog now I started a week ago this is
how fast I end up moving with the things
here so I'm going to talk today about
about two things about hash tables and
about a different way of thinking about
concurrent algorithms and and I'm going
to start with the hash table piece and
I'm assuming everyone here knows what a
hash table is but maybe i can i can
throw in a few extra things that maybe
you haven't thought about ok so they
always saying is it's a constant time
key value mapping sort of by definition
right but from a key value mapping you
can build arbitrary functions out of it
and they're extendable they're defined
at runtime what the function is so
that's totally useful thing and then
there's a thousand uses for it I give a
few here turns out that it's incredibly
useful in these large business
applications for usually for caching
paradigms some form of content caching
web materials DB access whatever and and
these applications are themselves both
very large and very heavily
multi-threaded and it's very quickly
it's very easy to get these hash tables
to become a scaling bottleneck right so
there's a bunch of Java implementations
out there that are all well known well
understood no hash table the old one
hash map which is not thread-safe then
now is a concurrent one which has 16 way
striping internally that's only on
rights readers are all concurrent
writers have to fight for one of 16 way
but it turns out that
it's easy to get machines with more than
100 cpu-z stays you go to azul you get
one with 750 CPUs and we do have people
using all those CPUs all the same time
so rapidly 16 way striping hash table is
like a major bottleneck and you can make
it a bottleneck on on lots of machines
these days so somewhere along the line I
started looking at a lock free hash
table I guess I sort of fell into it um
and what I came up with is in fact
entirely lock free so so no locks here
means nothing that looks like a lock not
just synchronized keywords or reentrant
you know Java that utilità locking you
can't have spin locks or anything that
basically grabs onto a shared resource
and holds it permanently so among the
other effects that come out of this is
that means that you can make progress
even if other threads died in the middle
of doing table updates so you can have
arbitrary manipulations going on table
people inserting deleting elements and
shoot them down mid operation and the
table will not be damaged all the
threads make full progress without
anything without any problem here so we
also out of this I think I lost my mic
okay its back okay I need some sort of
atomic update instruction and I've been
informed that maybe not everyone knows
what a Kaz is anyone here want to admit
they don't know what a Kaz is so there's
actually fair number okay so Kaz stands
for compare-and-swap it's essentially
the unit of atomic operations on all
modern CPUs it allows you to test for a
value in memory and if it's equal to
what you expect it to be equal to then
do an update and if it's unequal you get
a report back saying I didn't do the
update so from this sort of building
block of atomic operations all your
locks and synchronization primitives are
all built out of that and then from that
you can build all kinds of other things
all your concurrent algorithms involve
this kind of operation there's a couple
variations of this load link store
conditional happens on power pcs and
there are other things floating around
that do similar stuff but Cass happens
to be the one that's on x86 spark Azul
itanium
I don't know almost every modern machine
you can think of and you can get at it
directly from Java you can write a
little bit of unsafe coding directly Kaz
objects in memory so so it's not just
sufficient to have a walk free hash
table I actually have to have one that's
you know faster than locking and the
usual problem with sort of lock three
algorithms is that they're very
complicated under the hood and the
constant factors just kill you but not
in this case so i end up with something
that's essentially tied is a ten percent
faster than Java util concurrent which
is sort of the fastest concurrent hash
table I can find for people for tables
where you're doing like ninety-nine
percent reads on a modest count of CPUs
so ninety-nine percent read applications
are very common for people doing caching
you occasionally update the cache and
rest the time you're hitting in the cash
right however if i add more cpus i get
somewhat faster even with very large
striping compared to the java.util
concurrent certainly a much faster if i
take the default arguments of 16 way
striping as i start to add more right so
ninety-five percent reads five percent
table mutates I started getting a lot
faster and I continue to remain faster
essentially my performance does not
degrade very much as I start to do you
know more and more updates and in fact I
get a decent amount of scaling if I do
only updates to the table if I have a
hundred percent you know inserts and
deletes in the table and maybe one
percent reads I still get you know very
high performance so it's a it's a it's
scales extremely well scales basically
linearly and it certainly scales better
than anything else I've ever seen for
doing updates okay so so enough bragging
rights here so uninteresting hash table
details so when I say uninteresting mean
I mean good engineering stuff I assume
anyone who's written a hash table can
can work their way through all these
kind of details so basically a hash
table is a collection of key value pairs
and what I'm going to show you the meat
of the talk is about how to manipulate
the key and the value pairs in a way
that's concurrent and provably
concurrent and provably safe right so
but really you start to have a
collection of them and the collection
has to have its own problems with
dealing
a large set of keys and values and you
have to be fast and get constant time
effects kill you that's what usually
happens with these locking algorithms
fast means these days happy cache aware
all right and I'll present this sample
solution but it don't claim it's the
only possible way to do this there's
lots of ways to to skin this cat and
different solutions probably make sense
in different kinds of domains so I ended
up using a closed power of two hash
table that means my table is an array
it's the power of two sized array it
means that I can limit my hash function
into the table by simply doing an mask
on the size right I'm closed means that
instead of having a bucket a chain of
key value pairs on bucket lists Yuri
probe into the array itself and it turns
out that because you know if I'm using
stride one repro by get better cache
behavior because collisions turn into
linear scan as opposed to linked list
reversal so you know I messed around a
bunch to get my key in my value to land
on the same cache line and I memorized
the hash function other cool things I
don't actually have to do any allocation
on a put that's kind of unusual and then
the big one is I auto-resize the table
so I ignore whatever argument you give
me on what the table size ought to be
and I'll just get a size as it comes up
so here is sample get code and I'm again
I'm going to assume people mostly know
what's going on here compute your hash
function you know while true that's the
repro being loop mask to the size of the
table get a key whether the magic get
key function and the magic get bowel
function i'm going to talk about in a
minute that's sort of the meat of the
talk how you do that in a way that's
safe in the face of people are mutating
the table out from under you right and
then you look for hit know I've got your
keys equal then you're gonna return the
value if your key was an OL you must've
missed in otherwise your repro by adding
one and trying again so the actual gate
code is I mean this is essentially I
have a little tiny bit more code in the
actual implementation but it's very very
fast and one of the reasons this tables
so fast is because what goes into get
key and get val is nothing more than a
load instruction
so so this is the entire get call and
that's why it's fast it's just hash
table lookup got a hit on the key done
okay so odds and ends here these are all
engineering decisions that people might
choose to do differently hashtable the
existing one uses a prime size table and
the mod function but a mod is like it's
like the cost of an l1 miss L to hit a
little more expensive than that if I'm
going to be hitting in my 0 1 i'd rather
not screw with a mod i lost all rated
rather just reprobed a few times i want
to get my hash function on the same
cache line but keys and values or object
pointers and hashes an int and Java it's
hard to moosh that all into a package
that fits in the same cache line but you
know so there's some engineering
decisions to make here and that's sort
of the end of the uninteresting stuff so
does anyone here have any questions on
that cuz that's just like how to build a
hash table
looking up is your primary thing that
you want to speed up it turns out that
my foot is extremely fast as well but
that wasn't the original goal the
original goal was to sustain some
interesting number of puts while having
a huge count of people doing gets famous
same table mutation whatever it is
insert change an existing value delete
insert only if it's not there already so
you guaranteed exactly one insert that
kind all those operations I'm calling
put but it's there they're actually
implemented the same piece of code under
the hood in the very bitter end there's
a place where I do a cast to insert a
value into a table and that one Cavs
instruction covers delete it covers
insert covers change it covers put if
absent put if matching old value delete
if matching whatever all the variations
are up the size of the number of entries
yes oh sorry mi okay yeah yeah so what
about what about operations other than
the classic put our insert or what about
read elite what about change and the
answer is it's all the same piece of
code it's all using the same tiny chunk
of work to do the same operation of the
table I'll show in a minute why those
are all semantically equivalent
operations any table mutation goes to
the same path and then also am I
collecting size a table size which I am
and that's this is intended to be a
drop-in replacement for a hashmap or
java.util concurrent hashmap in which
case you have to have a size now the
size as with all these concurrent
algorithms the size function is sort of
lazily maintained within a single thread
your guarantee guarantee to see your own
updates to the size but other threads
will see your size changes sort of
lazily as the hardware place catch up on
the disjoint rights to things okay so
let's go look on on sort of getting to
the meat of this thing here right so the
real problem with all of these
concurrent algorithms is how do you
prove correctness and and classically
it's very difficult to prove correctness
right I want to know if I'm DUP dating
my table how do I show that I got it
right
and people traditionally have done
arguments relating to fencing or memory
model fencing sort of the hardware
implementation of proving something
happen before after something else
memory models I guess Jeremy talked
about these very recently that's sort of
the the the language lawyer semantics
way of talking about what happens when
right or you know getting your load
store ordering right it happens before
relationship so instead I'm going to
prove things via a state machine that is
I'm going to define a pile of states and
some transitions that together makes a
state machine and then I'm just going to
show that all states are legal I don't
care what state you start in or what
state you end up in do you get something
legal out of it so what I get out of
this is that I'm not going to care about
memory ordering that means that gets can
read keys and values in any order so in
particular in my get code i said here's
get key and get value in different
places it didn't have any fencing and
there didn't make ordering constraints
even if the compiler didn't reorder
those loads or try to prefetch one of
the other the hardware is free to
reorder the loads and that's very common
for the hardware to do that so you know
I'm going to allow them to read keys and
values in any order and as soon as I can
read them in any order I can write them
in any order if I don't have strong
ordering on the read side I don't have
strong ordering at all now I don't care
about ordering on the right side so
suddenly I can just use cows alone to
change keys and value and I don't care
what order any of it happens and I'm
just going to get a different state I
change a piece my state changes and it's
legal however that works and i'll show
that coming up so no fencing required
for correctness and and i claim the
proof is simple although maybe I've
stared at it too long and so it's not
fair for me to claim that um so what are
the states what i mean by state here our
state is ok so a key is either know or
it's some key and I'm never gonna change
that key again if I change if i added
put a key in the table it can never go
away and that's key to getting
correctness out and value is either know
or it's some value or it's a tombstone
meaning it's been deleted you insert it
and then later deleted you can resurrect
somebody by putting a new value in if
you insert delete insert delete same key
over and over again it'll flip from
tombstone and value back and forth right
and a state is just a pair of those
on a transition and the state machine is
taken on a successful casts on an atomic
update all right and here is the state
machine and I'll talk people through it
and then I'll show up a minute you can
stare at it some more so upper left
corner has the obvious empty set this is
the key value pair which you know it's
the initial state of the table and if I
insert a key then I'm just going to Cass
and so a transitions on a successful
calves of null to some key and because
i'm using a cavs i know that there's no
race here and there weren't two people
putting different keys down in that slot
of which you know i don't know which one
one in fact because I mean cause I know
which guy won and he's the guy who now
owns that slot forever in all time and
then I have a still of a no for a value
and eventually insert some legit value
there and if I would do a change i'm
just gonna mutate the value in place and
if i do a delete I jam a tombstone out
over the value and if I want to insert
after Lee shin then the tombstone gets
replaced back and so forth so that's a
state machine
so you're about to slides ahead of me
but in fact I'll talk about how to how
to free up keys that get stuck in the
table and then I have ass funny empty
state down here which is uh somebody
looks and sees a null key but they see
an actual value inserted which doesn't
happen in the put side the puts don't do
that but it get can read out of order
and see this I'll talk about all this
stuff here okay so a couple things so
once the key is said it never changes
and that's the that's the key to never
getting the wrong value for the wrong
key right if I actually change a key
that I might get a hit on a slot on one
key and pull a value out from a
different key so that no chance of that
but it also means that my keys leak
right because my table fills up with
dead keys that's your question okay so
which I'll fix in a few slides by
cleaning the table out in a minute okay
and then I have no ordering guarantees
so this is a bring your own ordering
bring your own synchronization party
here right I'm more on this in a second
and then you know this weird state which
really basically means that a reader has
fetched a key and prefetch the value
hoping the key is correct and you got a
null key and the prefetched value is
even though what it's for its for some
random key he has no clue so it counts
as a Miss i only found that state
because i went and computed all possible
combinations built the whole state
machine and i had this weird state left
over and i try to deduce what's the
meaning of the weird state and the
meaning is some gets i dread junk and
got a Miss on the table okay so other
things here that there's no machine wide
coherent state here that means for any
key value pair different parts of the
same machine might see different
combinations of key value pair set of
setups according to whatever read order
the hardware is handing you and that is
correct if you are doing racing updates
as you have multiple people inserting
the same key but with different values
then you don't know which value is going
to end up in the table and different
people might see different values at
different times and that's that's this
all the semantics you get out of Java
and more than you get out of most of the
languages right okay so no machine wide
coherent state and no need for it either
so this is sort of what you can think
about this is consider the degenerate
case of a hash
it was with but a single key and for
that single key I'm going to provide you
the same guarantees as if you had a
single shared global variable named that
key and you know a lot of whole lot of
readers and writers who are accessing
that single shared variable without any
synchronization you just define a global
x and a bunch of people riding into X
bunch of a reading from X i give you the
same guarantees if you have a key and a
bunch of people are reading to that key
a bunch people writing to that key you
get the same answer outright which is
not a whole lot of guarantees oh no not
yet but I will be in a minute this this
as presented so far no Cass does not
give you volatile semantics know if you
whip ins which flavor of calves and in
particular my hardware on Azul does not
sense unless I ask it to and it's much
cheaper therefore so I'm happy to have a
non fencing calves and exactly here I
don't need a fence and so there is a
version of calves and Java that does not
fence called week as and that's the
version i'm using but i want volatile
semantics here so i probably want a
slightly stronger guarantee than what i
just presented I probably want what's
called happens before relationship but
only on the value side that is to say if
I construct new value in memory and I
damn i publish a pointer to it into the
hash table and another thread fetches
the pointer out of the hash table and
then reads through that pointer to see
what i just wrote you wanted to see the
initialized state of stuff that went in
there right and that's that happens
before relationship on the values it's
essentially the same semantics is what
volatile gives you it so if you if you
don't use volatile if you write an
object and you Jam its value into some
global shared variable and somebody else
reads it and you're not using the
volatile keyword you don't have a
guarantee that you're going to see what
was written and classically it's called
the double-checked locking idiom and
until you have the volatile keyword it's
broken you could go Google double check
blocking if you don't believe me anyhow
so this one is actually pretty easy I
want to have a fence in here to get
happens before so this is a
how many defense turns out that the
actual fencing semantics i end up in the
hardware depends on the exact piece of
hardware you're on and what kind of
memory model the hardware provides under
the hood okay so so far I've talked
about getting put the actual real part
this is where I'm going to put my my
state table to its test here I'm going
to talk about how to do concurrent
resizing and this is where all the other
concurrent hash table algorithms I could
find sort of almost a fell down but got
really really ugly this is going to get
a little bit ugly but it's not going to
get nearly as ugly as the other stuff
I've seen so one of the things that
happens here is I have to resize my
power of two table if it gets full five
picked too small a number in fact I
start out with a very small number
because most hash tables are actually
only used to hold like a handful of
things and then maybe I want to resize
if my hash functions ugly and I'm REE
probing because I'm getting bad
collisions or maybe I want to resize
because I got a bunch of lie a bunch of
dead keys in the table and I want to
clean them up and resize to the same
size not really resize it's cleanse it's
basically copy the table from here to
there copy only the live stuff and the
dead parts get cleaned out so that was
there was a question how do you handle
that i'm going to copy the table and at
this point actually need of fencing and
the algorithm between the tables not
within a table but with between it and
the hard bit the thing you have to look
out for here is how do you handle
picking up the last update to the old
table that's racing with your copy into
the new table that's the tricky piece
okay so the way I'm going to do this is
I'm going to expand my state machine
that is you know i'm going to add new
states and as a side effect of this mid
resize is sort of a valid state and it
also means that my my resize is entirely
concurrent that is people can read from
the existing half copy table and and
just go or they can help with the copy
and then you know go i can do it in
parallel i can do it incrementally
partial copies okay i can have stacked
partial resizes in progress that's okay
I do want to get rid of the resize
eventually I want to
I'm paying this extra in direction while
resize is in progress so I eventually
want to get it over with but while it's
in progress everything sort of charges
ahead at whatever pace they want to go
there's a bunch of heuristics here that
you can pick from oh here I go y'all
talk about heuristics so um get in
general will work on the old table
unless it sees a sentinel talk about the
sentinel a minute put or other
modifications have to go modify the new
table and they have to check for the new
table every time and if they see the new
table they have to go run to it and they
have to fence between the tables and
that means that because I'm fencing
between tables at the last right to the
old table is guaranteed to be happens
before the Java memory model semantics
before the resize operation that's key
to getting this thing done but actually
copying the key value pairs is
independent of get input so I have a lot
of heuristics to choose from the
heuristic i'm using right now is
everybody who touches the table does a
little bit of copy work and then they do
their operation whether it's a good or a
put or delete or an insert or whatever
but i could have like only the riders to
copy the table if I want the readers to
be really fast they can just read and go
on the old table unless they're told to
go to the new table kind of thing I can
have it with unrelated background
threads right I could spawn extra
threads we got extra cores I get
background threads do the table copy for
me so let's look at the new states here
I have to add a new state I'm going to
add the ex state which is the Sentinel
and it tells me not here go to the new
table and I'm going to use this as a way
to avoid having to look to see if i have
a new table all the time or actually to
say i'm halfway between table copies and
some of the slots are still in the old
table not copied and some are now on the
new table and the ones that are in the
new table have an ex in the old table
right so i added 2x as a way to stomp a
key and X lot now a key slot either goes
from Knoll to a key or from Nowell to an
ex if I'm going to say this slot is dead
now you cannot insert something a
late-arriving insert cannot update in
the old table anymore yes to go to the
new table okay and a value slot has the
same kind of thing
it has what it had before plus one of
these new things meaning it's not here
now go to the new table it's been copied
so this is the transitions that can go
through from though to some numbers if
tombstones are values as you do inserts
and deletes on a slot until somebody
comes along says I'm done with a copy
now no more updates the old table go to
the new table so I have a state machine
this is the same state machine I had
before except i added the two yellow
states on the right and one of them is I
take an empty slot and I mark the key
out so no one can try to insert a new
key into the old table and the other one
is I took an existing key value pair and
I've marked it out indicating that i
have successfully copied it into the new
table and you're on the wrong table now
and there are some states that are no
longer possible and if you had to do the
math you can count 3 times 4 12 states
in here and there's more states that are
uninteresting if a get comes along he'll
realize he's in the wrong place he'll
realize that he's just got to miss so
I'm gonna stare at this will let people
start this a little bit longer and then
I'm gonna break down what the little
transitions mean a little bit more in
the coming slides
yes as I mentioned before maybe make it
clear it's possible to have stacked
partial resizes and I did the current
heuristic I've chosen doesn't allow that
but I my waffle around with various
heuristics that did do change stacked
resizes and and the algorithm all works
I mean it's all fine it's functional if
you have stack resizes it just means no
you go to the you look at the oldest
table yeah and you see an X up go to the
next table up and you see another XE go
to the next table up and and yada yada
yada and you can do this if for instance
you need to get 700 threads like jump on
an empty table and they immediately all
insert and the tables brand new it's got
like 32 in trees or whatever the default
minimum size is and you know a couple
hundred people jump in try to an insert
well immediately its full so they melee
start copying to the next double size
table well that's full to instantly and
this is the next and the next and the
next and you get like five doublings in
a row before you can swallow the 750
instant concurrent puts right so you
know the copies are all in progress and
moving along and it all works it's just
as a performance thing it was more
convenient to force the old table to
clean out before making yet another new
table so I make you do more copy work
essentially till the table clings out to
the old one clean tub it turns out I
still end up with a constant amount of
copy work / update to the table if you
do a touch on the table you get a fixed
amount of work as part of your copy
before you go on so every thread is
stalled by a fixed amount of time during
the resize not by like the time it takes
to copy a megabyte table 2 a 2 megabyte
table they just do whatever piece of it
okay so we all bored with this slide
here so let's look at these transitions
in a little more people this is an easy
one this is the transition that says I
have an empty slot I don't want to
prevent another key from being inserted
in the table I just has an X n if I cast
a null Tonex then no key was in there
because the the cast would have failed
with a key if their key showed up right
so here's another one which is I got a
dead slot in the old table and all I'm
going to do is put an X down saying no
more updates to this dead slide if you
want to do another if you want to
reinsert this key you got to go to the
new table and then sort it or fresh
there a more complicated one is I have
something in the old table but also
something in the new table except that I
can happens before
our Java memory model style prove that
this thing is older than this thing and
I'll talk about more that about that in
a minute but the the way I can know this
is operations that happen on the old
table or guaranteed to happen before the
resize because the guy doing a put
looked to see if or resizes in progress
right so what this means is that this
update is v2 down here that's a newer
put and there was a race going on
between people doing updates this is a
more recent put and I can just ignore
the last put I hit ignore the guy in the
old table i can claim I'm uninterested
in his value got stomped by somebody
racing to do a put here so that the
trick here is I have to know that this
is a more recent foot than that and I'll
talk about that in a second but that's
what these are all copy pieces of the
copy where I don't actually copy any
values I simply say I'm uninterested in
the old table anymore so if I actually
have to do a copy i'm going to do
essentially a two-phase commit i'm going
to introduce primed versions of values
and tombstones I'm the prime values
represent things that are copied into
the new table from the old so they are
values which were not recent in the new
table but there are merely copies of
what was in the old table anything
that's put directly in the new table
happens after the table resize has begun
and that's guaranteed to be a more
recent update than any prime value and
this is how i'm going to get the last
late arriving right from the old table
I'm going to do I'm going to attempt to
copy atomically between the two tables
and the old table might be getting
continuous late arriving updates that I
need get the last one out and eventually
a new update to the new table might
appear and make me uninterested to
anything in the old table but until that
happens I have to assume I'm going to
keep trying to get stuff out of the old
table so let's look at this little more
detail here i have the same key values i
had before Noel key X the same value
slots there's a new version where I just
take a prime on tops of T and V and it's
my old things copied in the new table
two-phase commit right and so now that
the transitions I'm allowing here I'm
going to go from no to
primed and this is in the new table
taking a copy from the old table I'm
going to strip the prime off each of
that I'm going to get a recent update to
the new table which is going to be
uninterested in the old table and that
will also be with no Prime and
eventually I'm going to copy again to
the next table down the road and that's
what the ex is therefore so I have a
state machine and I add one state
although it's getting pretty thick up
there and it's the orange one here and
it represents the point where i'm
copying in a value from the older table
i'm going to copy it in with a casta get
it in and a prime to say it's an old
value and if i can successfully slap an
ex down in the old table so this is
what's in the new table but I
successfully slap an ex down in the old
table that I know I'm done I
successfully did my copy no one else can
update the old table because I got next
there so this is all complicated to read
here because I'm doing updates into the
old table on updates into the new table
using the same state machine but
different state transitions so I really
kind of want to stare at this in a
little more detail i'm going to look at
in the new table how do i get a prime
value in it and then get rid of the
prime saying I've got the right thing no
more updates are showing up from the old
table and I want to look at what's going
on the old table where I'm going to say
I'm still pounding in values in the old
table because I'm a late-arriving update
and somebody wants to you know put an X
down tell me I'm in the wrong place you
need to go to new table so those are
that I'm going to zoom in on those sets
of states and I get this thing and these
are things happening on the old table up
and things happening the new table down
and this way i'm going to read something
from this is my unfortunately my fencing
now between tables i have to do happens
before via fencing via java memory model
kind of things read something from the
new table if it's not primed by the way
i'm just done because i know it's more
recent if it's primed it's it's an old
thing that's been copied and a more
recent old thing has appeared it's
different if it was the same that i'm
going to step over the state where I
know that the new and old tables are the
same but if they're different then I
need to update the new table by
replacing the prime value i got with
another prime version of v1 so that the
new table now has the most recent copy
from the old table now i want to go
hammer the old table so no one can do
any more updates and again it's a Kaz
and if this one succeeds I got my ex in
and I know that the new table has a copy
of what was in the last thing that made
it to the old table and at that point I
stripped my prime and the copy is
complete if any of these Kaz's fail
along the way then I didn't get my copy
done atomically and I have to try again
I have to roll back to the beginning and
do this copy again that copy effort
failed because a late-arriving update
screwed with the old table basically
there's a finite number of those that
can happen because it can only be the
count of threads that entered the table
past the point where they tested for
resize and didn't see it but haven't yet
committed their updates so this is a
cow's spin loop if I fail but it's
limited by the count of threads that
arrived late in the table in practice
it's almost never it's once in a blue
moon a lot a lot of glazed eyes there's
a few people going on ah dear boy okay
so um some things to look at here old
values could be V or tea it could be i
end up copying a tombstone if i first
tried to copy a value and that copy
failed and then something deleted and
now i'm stuck having to copy the
tombstone over so i still have to handle
that might be a prime diversion if i
have a nested table resizing progress
turns out that i can quit trying the
copy if i discovered that the new value
no longer has a prime on it it means
somebody either stripped prime from an
old copy because it was successful or up
put happened in the new table and it
stomped anything i care about in the old
table right I can get if I kaz into the
new table fails here it means somebody
who did a put or there's somebody else
doing a copy I could have multiple guys
copying the same slot and if my calves
failed I should just get all the way
until the guy finishes copy right and
and really the way to think about this
is that any thread can see any of those
states at any time and you just look at
the state machine say if I see this
state here's the action ago due to go to
the next state that's sort of the real
trick they're thinking about it saying
you know I did this Cass therefore the
state looks like X isn't the right way
to think about it because there's two
pieces of kena value and they could both
waffle randomly up from under you as
fast as they possibly can you just
really have to say you know I think I'm
at this state so i should transit and
then i'm going to get one of several
states in the end depending on which the
other value flipped it works okay
mentally it worked for me too but it
took me a while to get there to realize
oh i don't care i can't know what the
state really is a memory because there
isn't it a state to find a memory it's
floating around the cache coherency
protocol the machine flipping randomly
all over the place oh yeah but i don't
want to it's not really i went to this
to work with Java which is going to only
be limited to what other hardware does
so as soon as I can convince Intel to
provide me with D calves I it would work
right and it's all over with I got
decals I'll just decals key value pairs
as a pair and I'm done right so that's
assuming that's not happening I want
this to work without decat so the plot
is easy there's lots of ways to do the
Prime if you're in C code you just steal
a bit from a pointer if you're in Java I
wrapped it with an indirection object so
it's an engineering hack and and yet
there's more than one way to skin that
cat pointer is that I have cache
coherence
now a wrap it with an indirection object
all I have to do is test for are you an
instance of prime or prime prime objects
are never any valid value their own my
own private class so I just ask the
instance of test which is actually very
fast on all machines these days no i
don't i only need one I did I did work
through the nested resize what happens
when you pull a prime from the old table
to the new table dancers you only need
one prime it represents a value which is
older than the table you're copying into
right and if you're nested primed it
means you're definitely older you're
from an extra table ago okay so here are
some performance numbers let's see here
if I can okay so how to do this here so
so this is impossible to read so I'll
figure out how to summarize here so the
orange lines are I say X 04 here and it
means x86 40 it's actually a dual
hyperthreaded so kind of cheats it's
really to CPU non-blocking algorithm is
the faint line on top and the diamond
the the triangle down is Java util
concurrent co for concurrent with 4000
waste striping and I have four thousand
ways striping because I'm going to jam a
lot of threads on the future graphs here
and if I don't have tons and tons of
striping then I'm just going to choke on
the locks that are built into that in
the hash table this is a ultrasparc
three with two CPUs that's the Sun 02
and everything else is either Niagara an
older son box with 32 CPUs or an old
zool box or new Azul box and we're all
on an upward ramp and that's the end of
that chart and I'll quit showing some of
the the two cpu things going for it this
is a table doing ninety nine percent
reads one percent insert updates on this
is million operations per second so I'm
doing you know the x86 is doing 25
million reads a second and one percent
of those are actually in sort of delete
so ramping up to 32 I get some funky
dropouts usually on the concurrent guy
usually for places where he's
arts to get contention on locks and gets
funny dropouts as he goes most things
just ramped up pretty straightforwardly
and I dropped the to CP you guys out
here and we're all going up to 32 and
the only the only anomaly i have here is
that I'm not faster than the concurrent
guy on nagra it's generally ten percent
faster on the other platforms not
Niagara and that's because the size of
the table I've chosen happens to fit
perfectly in the Niagara cash and for
the concurrent version and not for my
version sort of i could have picked a
different size and it would play the
numbers a little differently so then i
keep ramping up the azul guy to 400
threads and and the light lines are the
non-blocking algorithm and you can see
they're running you know fifty percent
up over the blocking algorithm even with
four thousand ways striping and if I
keep going out here to 800 CPUs this
eventually hits 1.2 billion operations a
second and the concurrent guy gets all
kinds of weird problems with contention
and garbage collection algorithms and
stuff going on so that's 1.2 billion
reads a second of which one percent so
12 million opera updates a second into
the same hash table and I looked at a
ninety five percent table which has
exactly the same scaling characteristics
except everything shifted down and my
version doesn't suffer so badly in
general as the concurrent algorithm guy
and going forward I get the same scaling
algorithm everything pushed down
concurrent guy push down harder
generally and then again here 400
threads ago up to 800 threads here I'm
getting like a 3x difference here
between concurrent and the non-blocking
algorithm so it's a ninety-five percent
guy so he's getting 750 million reads a
second and whatever 120 if that comes
down to the updates a second and I did
for a ninety percent has the same thing
when he goes to the 75 here 75 person so
this is a table a lot more modifications
here and basically this guy's flatlined
he can't even a 4000 way striping he
can't handle the update rate so that's
600 million reads a second
I know a quarter of the 150 million
updates a second on the sharecash table
so I'm sorry this 75 Oh Chris back up
you can eat it yeah it's it's all it's
like tidal Niagara and for everyone else
at beats pretty well handily so here's
green which is the older son box
splitting non-blocking beats blocking
here is Azul 384 way here's Azul 768 way
and here's an agro just a plot line tied
ramping up I didn't keep going here on
the on the Niagara thread count but he
hasn't pegged out yet even though he's
like should be pigging out of 32 you'd
think so right so I always started the
benchmark with a tiny hash table and so
it rapidly inflated to whatever the the
ideal size was Iran 72 second trials and
threw away the high and the low and then
averaged and in that time the first one
was always sucked on the non-blocking
while he was doing his resizing so sock
meaning factor of two to three slower
than sort of steady state and once he
got to the right volume then he was
consistently up by 2x or so so there's
clearly an overhead paid during the
resize I could go through and do the you
know do a version which showed with the
resized cost for a little more directly
but I kind of think that in a normal
case the resize should get out of the
way pretty quick you should end up with
the right size and be done now I did run
a version like I did run a version where
I forced sort of the worst possible
behavior out of my hash table where I
did only inserts and deletes of a
continuous rolling key set such that i
only had like a thousand keys live but I
inserted a million of the table on the
other 999 billion were all dead so I had
to resize the table constantly to clean
it so there's a non-stop resize
operation um and there
you know you did performance was clearly
gone from these numbers by an
interesting amount but it still held at
a throughput rate compared to the
concurrent guy which has to do now
non-stop blocks in order to do
concurrent updates on his four thousand
ways striping um I was still like 5x
faster so the updates rate was killing
him as well now my in on my version of
things because i'm using prime rappers
i'm doing garba allocation to do copy
and i hit GC limits and so the maximum
throughput i achieved hit like it like
500 threads and it was because i was
turning some number of gigabytes the
second of allocation in order to do the
continuous table copies and the
concurrent guy pegged out at a much
lower number because he just ran out of
locks I needed to stripe it much bigger
than 4,000 way did you had a question ok
so yeah I don't know what the right the
right benchmark to show here because I
don't have somebody who has a need for
you know well I mean I do have customers
who are screaming they want a better
hash table so I'm going to hand this off
and we'll see how it goes but I don't
yet have an obvious use case so I can
talk about in public where this beats
anything you could do any other way why
you start always with the small hash
table if the if the user knows the
correct size and practice so the answer
is that the users think they know and
and you know time and time again that's
sort of proven correct sometimes they're
right and sometimes they're badly wrong
and then if I just do it all the time
then they pay a cost to get started
except that that cost is always over
with in a couple seconds and there's no
more cost and then then they're never
wrong again right Kohler guess is too
low then it's no different and it's no
different broccoli gets too high a waste
a lot of memory so right so if i have a
million entry table and the guy guesses
10 million then i can blow off you know
nine million times eight bytes for key x
8 bytes for value i can blow off you
know 20 megs 40 Meg's it's pretty easy
to get when you get really big them and
get small numbers you don't care when
you get the big numbers it's easy to get
it wrong by big factors and then you can
blow off big chunks around the other
thing that happens is people will guess
that they need a modest-sized table but
they need lots and lots of them and the
real answer is you know they picked a
number which the noes pretty much bigger
than what they really need but not a
whole lot bigger so they say I need a
hundred elements or 200 element and they
only put one or two and ever but then
they make 10,000 of these tables and
every one of them's too big by a factor
of 100 and then they lose a lot of
memory that way too and I've seen it go
both ways so just resize and do your
thing and you know at some point maybe I
want to take it as a hint and I can use
that as a hint but at the moment i'm
happy to ignore the hint and go my own
way
okay so that's sort of the end of the
talk it's a faster hash table faster for
more cpus much faster for higher table
modification rate and the more
interesting thing to me is that i'm
using this state machine to do my
reasoning to figure out how i can be
correct to look at you know i don't know
what's really going on but I got a key
into value so I'm gonna pick a spot in
the state machine here i'm going to go
attempt to cos to go to there now that
means that i can i can dodge the
ordering unfenced engage them turns out
that i have to pay attention when i go
between tables but within the same table
i can ignore that ordering and that
actually helps scaling a lot as well it
means I don't have to do machine wide
coherency on updates I just need to do
local coherency on updates and then you
know more games any thread can see any
state any time kind of changes way you
think about things and that state
machine picture I drew I drew lots of
those on pieces of paper walls working
fuse those really help coding and
debugging and really in the end the code
I wrote look like the state machine I
mean it just look at the state machine
and every point there's some transition
to go to somewhere else and that's what
the code does so i end up with some
piece of code that's really small and
fast so obvious future work tools to
check the states did it get them all do
they have all sane transitions right
given either have a state machine that
I'm just coding exactly an algorithm
straight from the state machine why
can't I just automatically generate the
code right the whole notion of using a
state machine to think about things
seems like it ought to have broader
applicability I haven't got sort of like
another smoking gun here's an obvious
thing to do with it although I have been
looking at a concurrent version of Java
util vector and you know some pieces of
that are you know makes sense now do a
pinned and delete and you'll get last or
what it was a bunch of things people you
use vector sometimes for work list style
algorithms I think I can do that
concurrently I'm I've got a blog I'm
tending to put the code there at this
point I think I were stuck on a name and
we're stuck on
picking your favorite open source
license du jour so I don't know what the
right license is here we're debating
that at work but it's clear that we have
customers who are interested in we clear
we have a broader audience that's
interested in it as well so we'll open
source it at some point here that's it
for race issues with maintaining the
size and deciding when to resize like it
besides gets up there too late you might
go through entries and never find one
too so the size is never never
guaranteed to be coherent with like an
iteration over the table unless no one
else is doing updates right this is that
one of your questions I mean there that
basically how do you keep the size
coherent really the issue is how do i
update the size in a scalable way
because if I have 750 threads all like
incrementing a counter then I'll drop
counts unless that count is synchronized
and if it's synchronized then it's a
choke point so I had to have striped
counter updates to have a chance of
scaling the counts up that was sort of a
step one solution problem there that's
striped kaz counters to get counter
updates once I did all that work I can
do the counts accurately and asking for
size has to walk through the striped
updates and tell you the you know some
them all so it's not a not a variable
read it's a little bit more complicated
but there is no guarantee than otherwise
on the size that you got back and the
contents of the table unless nobody else
is updating the table right so you're
asking maybe you know if somebody came
along and deleted 10 elements out and
you asked her size and got 100 now
there's 95 or 90 cuz punctures things
got deleted and you do a for loop and
try to iterate over the table you know
honey guarantees there any in the first
place
girl with paper with the shrink the
table okay so growing happens when I run
out of slots which I count the same way
account size slots are when the keys get
consumed by a permanent entry of a key
right and when that hits some fraction
of the size of the table I just time to
grow the table the other way I decide is
if a single thread REE probes too hard
too often he's looking for a key that's
lots full he's looking for another slot
looking in the next next slots all full
full full full holy he hunts a long time
besides I've hunted a long time it's
time to grow the table and that will
double the size the table and spread the
keys out matter and then I can go you
know find an empty slot to insert my key
in I've made it back and forth in this
at this point answer's no I could same
issue I have to decide the tables full
of dead keys and and after a resize
realize that it remains you know I mean
I have to count the key I've count the
live slots to debate to read it to
shrink it at the moment I'm not counting
live slots directly guess I could I have
it sighs yeah I could do I could figure
out how to do it it is it really an
interesting thing though if you've
already inflated to some large size
aren't you gonna get back there again
you survived being big now why shrink
and then have to grow again at some
point I'm sorry not reassuring already
yeah you already shown you're not member
constrained good big is so it's an issue
if you're playing ping-pong with
somebody over here right you're growing
and shrinking so he can grow and shrink
so you can grow and shrink it seems a
very complicated use case I unconvinced
that it's an interesting thing to do not
that I don't think it can't be done I
just think it's uninteresting to do it
all all the standard data structures
have the same issue
at all here they absolutely do so but
there's one word which holds the porn
into the next new table and they Kaz it
from a null to the new table one guy
wins the Kaz the other guy loses a loser
throws his table away he doesn't copy it
you first Casas it in once you inserted
the new table all you've inserted is a
blank array an empty array and then now
people have to start copying from the
older than new so it's all the state
machine based thing one of the states is
insert the table and then it's fractured
into a billion little states where
everyone copies individually the slots
from the old to the new and then there's
you know stripping the primes off things
in the new table and then when that's
all done I can say you know I'm done
with a copy on the old table i can now
promote the new table to be the root
table and then the old table will get
garbage collected at some point you're
really your government construct
analogous to a copy garbage collector if
primetime access
sure although
portable he considered actually linking
in the garbage collector who always work
you know like I said like you said like
I want to be portable if I didn't want
to be portable the first thing i do is i
get rid of the Prime wrapper and use a
prime bit and that was the sort of the
major cost and any of the table copy
operations is messing with that extra
bit by doing a rapper you know if i go
to write this in c code yeah i'd use the
prime bit in a second I knew I'd steal a
point a bit in a second oh sure I just
don't want to integrate at that level I
out I'm trying to push this out in the
public domain so I get people customers
who come to us with it already in their
code so don't have to go say okay well
you rate managed to use four out of
seven hundred CPUs let's rewrite the
hash table implementation you got right
it starts out the good side good version
that I don't care oh yeah so all right
so yes i have talked long and hard with
doug leon this we go back and forth all
the time some version of this is likely
to hit java.util concurrent at some
point last time Doug and I talked he was
of the opinion that the identity test
version made sense and the rigor and the
non identity requiring an equals test
did not for whatever reason with a
minute will you memorized hash or
something yet some version of a reason
why one was better than the other I
can't remember the exact details but the
end result was yeah some instance of
this probably goes back that was say
three or four months ago since then I
have sort of refined the algorithm a
bunch got correctness a lot more amount
were comfortable with the correctness of
the algorithm and I've shown performance
is very good across a wide range of
things including against java.util
concurrent hashmap with very large
scaling with very large striping factors
so some version of this is likely to hit
the Java libraries eventually anyhow
what one is the founder memory usage of
this seems to me that it would be the
size of your cash table turns a number
of threads because let's say you have a
hash table which is one gigabyte and
it's getting full so today wants to
level it to two gigabytes a further goes
to allocate the two gigabyte observe
that takes a while so if he comes along
and Ellie also knows the devil is
allocated some two gigabyte object to
the oh is that right so so the the
practical upper bound is that you only
get a handful guys attempting to the
concurrent allocation the theoretical
upper bounds that everyone tries to go
at the same time and grab a large array
and if they throw it out of memory while
trying to do that you can simply throw
it away and say I give up and go back
doing the old table not bother with the
resize so it's survivable in that sense
I could certainly do a version where you
were discouraged from making multiple
copies but I can't block on the
allocation or becomes no longer lock
free right so what I really do now is I
do the allocation and immediately
install it before i do any sort of table
clean up preparation kind of things so
that people quit trying to make
concurrent copies and in practice with
700 dies in table resizing rapidly I
only get a handful of extra arrays made
it doesn't it seems very hard to hit
that particular race you'll get a couple
and then the question becomes how long
does it take to allocate a large array
and for Azul it's not so bad I think for
other folks might be a little more
expensive
so if you if you're not going to use the
array you just allocated because
somebody beat you to the punch it's
garbage collection you drop it on the
floor the next young generation GC cycle
will reclaim it for no work doesn't like
girls talk about looking super system
yes yes that was what I was getting at
we have zeroing hardware it's not
totally free or anything but it helps
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>