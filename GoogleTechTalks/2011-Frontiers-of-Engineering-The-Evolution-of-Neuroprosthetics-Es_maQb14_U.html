<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>2011 Frontiers of Engineering: The Evolution of Neuroprosthetics | Coder Coacher - Coaching Coders</title><meta content="2011 Frontiers of Engineering: The Evolution of Neuroprosthetics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>2011 Frontiers of Engineering: The Evolution of Neuroprosthetics</b></h2><h5 class="post__date">2011-10-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Es_maQb14_U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">dr. Eric Luthor the neurosurgeon from
Washington University in st. Louis we
will be talking again remind me be
talking a little bit about the we can
sort of the other major arm no pun
intended of neural prosthetics can we
control external devices through
implantable devices in the brain that's
right well first off let me thank
everybody for being here let me thank
the National Academy of Engineering let
me thank Google for the privilege of
kind of talking about some of the stuff
that I feel very passionate about again
the title of the talk is called the
evolution of neural prosthetics and so
first let me really introduced this idea
of neuroprosthetics or another term that
we you'll commonly here is this notion
of a brain computer interface basically
it's some type of device that's taking
some type of electrical signal from the
brain that's in some way reflecting the
user's thoughts and converting that to a
machine command and it can be anything
from as simple as controlling a curse on
a screen to something more complex such
as Krupp controlling some type of
machine is like a robotic arm and the
ideas and part of the reason you can
have you know from I neurosurgical
background that I got involved is that
by tapping into the brain directly we
can create a new methodology to restore
people with motor deficits whether it be
because of stroke traumatic amputation
or diseases like ALS or Lou Gehrig's
disease and so there's several different
platforms that kind of characterize how
we can create a brain-computer interface
and they really rely on different type
of brain signals and so again just to
kind of brief anatomy lesson can we have
our brain and the majority of the
processing goes on and the the mantle of
the the brain called the cortex and
again that's where we have a substantial
number of neurons and again the brain is
surrounded by a leathery membrane called
the dura which is uncovered by the skull
which is then covered by the scalp so
how do we get these electrical signals
out well one way as we can just put
electrodes on the head and that's a EG
your electroencephalography and i think
most people are probably familiar with
that I mean it's relatively easy to do
we can go the opposite route or you can
actually put electrodes within the brain
and these are called single unit systems
where you're putting hair like
electrodes into the brain to monitor
single neuron firing or you can take an
intermediate route such which is called
ACOG or electric choreography and that's
where you put electrodes under the skull
but on the surface of the brain and
that's kind of intermediate in its level
of invasiveness and again I may be a
little bit biased cuz I'm a neurosurgeon
but so let me start with the single
neuron and I'm going to work my way up
in terms of how we can use these signals
for a brain-computer interface control
so for the single unit systems basically
again you're putting electrodes into the
brain and it can be anything from one
electrode to upwards of kind of 60 to
100 electrodes and basically and then
there's a several different types of
electrodes and you'll hear terms like
the Utah array or the Michigan pro but
basically you're monitoring a voltage
change for that single neuron and thats
that voltage change our kind of a
membrane potential is called an action
potential kind of very brief what kind
of spike in activity and again that's as
the signal is being passed down the
neuron as a Justin was telling you
earlier and how we get information out
of that is in the timing of that
basically we start to look at the rate
of that firing that can give us
information on the processing that's
going on in that single neuron and it
got in a layman's way of thinking about
it you can think about almost like as a
morris code kind of you know for what
that neuron wants to do okay now I'm
going to go back and kind of take a step
back to the 80s there was a guy by the
name of George opolis and what he did
and he kind of really kind of got this
in a movement going in a lot of ways is
that he did a very simple experiment he
basically put a single electrode kind of
micro wire electrode in motor cortex and
he had and he did that in monkey cortex
I should say and basically had a monkey
manipulate this kind of articulated arm
here it's called a manipulate them and
basically you kind of see a picture a
crude picture of it here and he had the
monkey draw from the center of that that
that table to peripheral targets here's
kind of what the monkey drew and he
looked at the neural activity of that
single neuron and what he found was
again if you remember those little tick
marks that I was drawing just earlier
the kind of representing a spike is that
depending on the direction that that
monkey would move his arm kind of being
up into the left versus down to the
right that there was differential
firing rates and so for instance if he
was moving up and to the left you saw a
kind of a high degree of firing rates
again that you can see that spiked
density right there versus if he moved
say up and to the right it was much
sparser and then you can take that brain
activity you can regress it to a line
and basically this form is kind of this
curved line here and so each neuron in
essence in motor cortex had what we
called a preferred direction and if you
kind of looked at the shape of that line
basically it formed a cosine tuned wave
and so the term became cosine tuning of
a neuron and that's one neuron with one
preferred direction and so if you take a
multitude of neurons with a multitude of
preferred direction you could actually
start to understand the actual predicted
motion of the arm for instance and let
me show you kind of an example of that
and this is from my mentor dan moran and
this is going to again a stylized
version of real data and so what you can
see is again thinking of those yellow
lines the length represents the firing
rate and the direction that that each of
these lines is the preferred direction
of that neuron and I think there's
around 60 to 90 neurons that were
recorded from and so what we're going to
see here is that how those firing rates
change with time for given preferred
direction you can some those preferred
directions to create a vector and what's
really interesting about that is that
you can predict basically what direction
that monkey is going to move his arm by
about 60 milliseconds and that makes
sense because right the brain creates
the command in the motor execute or
excuse me the muscles execute and so and
this is really one of the first
instances where we can take brain
activity and we can know the intention
of the being right and so and that
becomes a very exciting possibility
because once you know the intentions
it's not just about controlling this arm
it's about controlling whatever you want
because you can start to translate those
intentions if you know what they are to
sit things outside the body let me show
you an example of that so here's an
example again multi-unit or a kind of
implanted in the motor cortex he's not
controlling his arm he's controlling
this robotic arm so he can feed himself
and we have his eyes covered for privacy
reasons and he says monkey buddies don't
know that he's actually doing this and
participating in this research but again
it doesn't take a
a lot of imagination to think you know
look if we can decode this activity from
the brain and he can control instead of
his own arm a robotic arm somebody with
a spinal cord injury somebody with a
severe motor deficit this could
facilitate their ability to interact
with the world around them now that's
the rosey side of things so what are the
what's the downside why aren't we doing
this right now and so one of the
problems with microelectrodes is that
once you put into the brain there's
there's a problem with what we call
durability the electrodes don't record
signals in a stable fashion over a
longer period of time basically they
form scars around them it kind of glial
scars these support cells proliferate
around them part of its because a micro
motion of the implant part of it is just
a natural reaction of the neuronal
processes to a foreign body also there's
kind of a chronic inflammatory component
but the problem is that if you can
imagine if let's say we put that monkey
implant to a human if I've got to do
that if I've got to take it out every
three to six months and put a new one in
that doesn't make clinical sense so
again there's a great upside but there's
also a downside right now single unit
systems so let's take a step back and
think about what other ways can we start
to draw out intentions from the brain we
can look at single neurons but we can
also look at populations of neurons and
see what they tell us and so again I
always kind of say don't lose the cortex
for the neurons and so again now we can
think about okay if we're putting an
electrode kind of either on the surface
of the scalp or on the surface of the
brain kind of what does it look like
when we record from millions if not
billions of neurons again we have our
electrode on and again what you see is
kind of this junkie looking signal looks
kind of chaotic it looks relatively
almost like a random walk but it's not
it's really the superposition of a
multitude of different neural sources
participating together and I think one
of the really the interesting things
that we found is that this superposition
of different neural sources have
different frequency scales meaning that
it's really the superposition of
different frequencies doing different
things at different times whoops oops
catch might catch up with myself here
and it's the superposition of different
sources that have different frequency
scales that allows us to parse apart
information from this kind of very
chaotic signal and so now just painting
with the broadest brush there's kind of
general classes of frequencies and how
we think about that in terms of their
neural sources so for instance you can
think about low-frequency rhythms kind
of less than 30 Hertz and they typically
represent deeper brain structures and I
won't go into all the names of those
deeper brain structures but basically
deeper brain structures which modulate
cortex which essentially release or
inhibit the computational processing the
cortex is going to do and so they have
various names theta alpha mu and beta
but again they represent kind of you
know wider control systems then you have
what are called higher frequency rhythms
stuff above 30 Hertz and again the
typical term for this is called gamma
gamma rhythms and these typically
represent smaller cortical ensembles
smaller cortical circuits that are again
doing kind of localized processing of
information and so we're going to talk a
lot more about this kind of an ongoing
in the talk and so now let's look at
what happens how do these rhythms change
what do they do how do we get this
information out for a brain computer
interface and so we look at the power or
you can also think of it as the
amplitude versus frequency and this is
typically what you see with EEG you can
see stuff under 40 Hertz because in
large part the skull acts as a low-pass
filter the electrodes are distance from
the cortex and basically you can see
when cortex becomes active and kind of
blue represents kind of a active task
excuse me a rest task red represents the
active task that cortex shows a decrease
in amplitude in the low frequencies and
that tends to be broadly distributed
remember it's these deeper brain
structures releasing cortex to do some
computational processing now once you
put electrodes under the skull again
that's econ that you can basically start
to have access to these higher frequency
rhythms and again they actually manifest
a different behavior where when cortex
becomes active it actually increases in
power increases in amplitude and also is
much more cortically
constrain smaller regions of cortex show
these kind of amplitude increases at the
high frequencies and we can start to use
these amplitude modulation zaz control
signals so we basically take the raw
signal and again in real time we look at
Power versus frequency and you look at
how the power is changing in various
frequency bands and we can use for
instance if this is a single electrode
kind of as you oscillate between kind of
active and arrest task you know that
range and power can control occurs or
four engine for instance in one
dimension and so let me show you some
examples of that and this is signals
taken from EEG again you can see the guy
wearing a head cap and this is courtesy
of Justin Williams so the stuff he's
doing in his lab again this is a very
simple example we're basically you know
you can modulate in this particular case
to low frequency amplitude where you
know up and down can control you know go
right and left for instance again one
dimensional control of freedom and so
but again people even today you're
seeing kind of online gaming systems
that you're using this type of
technology for kind of interesting user
applications they're not critical but
you know they are usable now the problem
with kind of these systems is in part
because of noise that you're susceptible
to external noise from the environment
such a sixty line noise or susceptible
to noise that you yourself generate such
as when you blink your eyes and so this
is an example of an EEG after somebody
has an eye blink and you can see how it
distorts the signal and the problem with
that is it really it hampers training so
you can train your brain to make the
appropriate signals and I was really out
of kind of this environment that we
started to become interest in this
notion of e kagra kind of as being the
ideal signal sweet spot for a clinical
application and again I'm gonna get
return to this notion of gamma rhythms
again we were thinking well okay we
really want to create an implant or some
type of technology that helps people
with motor disabilities so they can
again facilitate their ability of
control appliances speech writing what
have you facilitate their ability to
engage their environment and we're kind
of caught between the kind of two
opposite ends of the spectrum EEG not
not too risky to use but it has some
problems with again limited degrees of
freedom limited control
prolonged user training single unit
systems you saw you know you can get
some marvelous control but lacks
durability now but placing electrodes on
the surface of the brain under the skull
it has some again some features that are
kind of the best of both worlds you get
a much broader frequency access again
you can up you know upwards of actual
we've shown now up to 500 Hertz the
signal is much more robust and even
because you're looking at high
frequencies you can get much better
regional discrimination separable
independent but independent controllable
signals and so and again because the
electrodes a larger and they're not
penetrating the brain scarring is much
less of an issue and so and this is kind
of you know we're kind of I came into
doing a lot of this reach research on e
cog is that and as promised to the kind
of a bloody brain picture is that we put
electrode arrays on the surface of the
brain actually for a very different non
brain computer interface reason but for
the treatment of epilepsy and again a
certain patient population there
epilepsy is quite quite bad and to local
locate where those seizures are coming
from and actually take that area out we
actually will implant electrode arrays
over the surface of the brain that you
can see here here's a lateral x-ray you
can kind of see each of those dot
represents one of the electrodes there's
a stylized version of it but basically
they get implanted for about a week so
we can figure out where the seizures are
coming from and actually operate on that
area of the brain and so they get their
grid put in and then basically while
they're waiting for Cedars we it's
actually an incredibly unique
opportunity to study human cortical
physiology directly we can put
electrodes directly on the surface of a
human brain and really understand the
physiology not through kind of a some
type of surrogate monkey model but
through humans themselves and so while
they're doing that we test them and then
eventually they go back to the along we
take the grid out so now I'm going to
show you some of the results of some of
the stuff we've done thus far so one
thing we found again looking at these
high frequencies we can locate very
focal areas of activity which we can use
as control signals and this is an
example for instance of kind of somebody
you know moving their tongue or moving
their hand and again we seek I'm an area
of activation kind of that separate
between these two and these you know
high frequencies here these high gamma
rhythms now another interesting thing is
it doesn't matter whether you actually
do it
to create the the signal change where
you imagine doing it it actually looks
very very similar and so and that's an
important fact because again if you've
got a spinal cord injury patient you
want to you don't want them to have to
move their hands to create a signal to
it for control right so they need to be
able to imagine doing it and actually
could the physiology is incredibly
similar and so just to show an example
this is one of our subjects is a few
days out from surgery you can hopefully
see him controlling this little cursor
here and he's using imagined hand move
and imagine tongue moving to control
that cursor in 2d space and I think
what's you know kind of cool about this
and I can't really quantify this but we
can you ask these patients well you know
what were you doing and they'll say well
you know at first I was trying to
imagine moving my hand as it first
that's trying to imagine moving my
tongue eventually they'll just say you
know what I wanted to go up and I wanted
to go down and I think one of the
fantastic things that we've learned over
the kind of you know the years we've
been doing this is how incredibly
plastic the brain is that basically it
can take its brain activity which is
originally associated with kind of a
hand movement or a tongue move or some
motor movement and transform that too
controlling something that's completely
non-biologically intended and it does it
very quickly we actually got we get high
levels of control in both in 1 and 2 D
chance in under 30 minutes so and that
was quite you know quite striking at
that time so and again it doesn't you
know once you get control it's what do
you want to get control so he got bored
so he wanted to play space invaders we
have happen to have that video game and
so you know this is kind of neat you'll
see him now we have him start off with
by moving his hand and you're going to
see him but again it's completely
controlled by his brain signals kind of
get a sense for the fidelity that he's
able to do this
eventually gets shot and I think that's
Sidney's kind of he's kind of pissed but
now but again it doesn't matter whether
you actually do it or you imagine doing
it so here he goes we said we told to
stop moving his hand and just do it and
then off he goes and the interesting
thing so he is the Guinness Book of
World Records a highest record holder
for playing a video game with his brain
there's not too many competitors right
now so but we we will claim your rights
for that record so again how do you want
to use this and we Justin was telling me
see if I can get this plugged in here
but basically you know again how do you
want to use what apps do you want to
create from these control space down
here in this particular example we have
in controlling a robotic hand so again
we saw the Luke Skywalker hand well you
know here's kind of a very early crude
version of that so now we want to start
moving beyond just motor control you've
seen kind of you know two dimensional
space control you've seen kind of you
know opening and closing a hand but we
want to take it one step further and so
again when we think about how humans
today interact with machines we have a
continuous style control which is our
mouse and that's kind of what we've been
doing with doing Mouse style control but
we also have keyboards right we have
kind of things that have
discriminability to create more complex
languages and more complex commands and
so we want to really think about can we
start to create keyboard style brain
computer interface control and that's
where it got us really interested in
this notion of decoding speech and so
i'm going to show you an example here of
basically this is somebody basically
doing a very simple task they're hearing
a word and they're repeating it and
again I've been really big on this high
frequency stuff but one of the things we
realize is here's ninety hurts here's
290 hurts and they each have very
different behaviors and as it turns out
when you look at this high frequency
space literally it's you know frequency
upon frequency upon frequency it gives
you layers and layers of differential
activity and it's in some sense is how I
would pile
jalate that you're able to do all this
massive parallel processing because
things are happening at different
frequency scales and so the words that
we had to repeat were kind of very
specific meaning we had them they were
of four different vowel classes AEI ooh
and nine different continent kind of
combinations and what we found is when
we started combining the frequency the
location and the time scales of these we
could actually create very different
patterns to separate out all these
different phone emic classes and this is
an example of an MN word and frequency
time space and the color represents the
power change and this is a PP word and
certainly we could classify these words
are really well but we could also on a
single trial basis again whether you
actually said it or you imagine set it
on single trial basis we could actually
predict which of these nine classes of
words that you are saying so we're
really working towards decoding the
literally the vowels and the constants
of the words that you're saying in your
brain and so again to put in a part in
the pun to put our money where our mouth
is we want to start using this for
control again we want to have people
basically either actually or imagine
saying oh and you know oea and AH and
use that for a control feature and so
again here's one of our patients and
she's actually saying the word and we
always use this but we can kind of
demonstrate and of the performance but
you can see this is her just starting
you know no training with this and this
activity was actually taken from a micro
grid so again for millionaires are four
millimeters and again the frequency
scale rusted around 250 Hertz for this
patient was allowed us to start
separating out these phones so we can
actually make the scale of these
implants very very small so the
footprint could be mentally invasive
again we've done this across multiple
subjects and so how are we thinking
about kind of implementing this what are
that you know what are the barriers what
are the necessary steps and so first off
you know where do we put this implant we
know we can kind of do motor physiology
we can do speech physiology we can do it
with a relatively small implant but
where exactly do we put it how do we
no where to put it part of that is
relating that electrophysiology with non
invasive technology such as functional
MRI and emmy gee so we can have a sense
for instance well here's the here's the
predominance of activity related to for
instance a motor movement and so we need
to you know map that back to the actual
brain then we need to stereo tactically
figure out where that is in an atomic
space and to give Tim Denison and
Medtronic credit that's been largely
figured out you know with stealth
navigation and and the technology
similar to that next step is we need to
actually create the implant and that's
things that we're working on right now
you know all the kind of electrodes
certainly adjusting Williams is in you
know kind of pioneering a lot of those
efforts the amplification the
transmission the power requirements that
we can have a small implant but also how
do we do this surgically and again I
think you know we've been kind of
starting to map out the surgical
technique and it's relatively simple
quite honestly they can incision the
scalp drill a hole in the skull and
create an implant that fits into that
hole but it right now the way its timing
out it will probably take around 40
minutes and finally you know integrating
both the hardware with the software so
that you can configure to an external
computer and can wirelessly transmitted
wirelessly communicate with that set in
the end what we want is basically a very
simple implant the size of a thimble
that is easy to apply surgically at a
minimal risk so that you can really open
the doors what's the app well you can
envision well our iPhone how many iphone
or excuse me Android applications do we
have at this juncture I mean it's really
thousands if not you know millions and
so and figuring out all the way to use
those control features for things of
manipulating our environment
facilitating communication control
whether you know of physical structures
such as a robotic arm or just kind of
things in your material space to
potentially augmenting function you know
and this is kind of where gets a little
bit science fiction is you know if this
is low-risk enough would people who are
abnormal function do this to enhance
their ability to pay attention to
facilitate their ability to absorb
information and so finally let me finish
with kind of a quote from a Time
magazine seven quarters later they were
having extended volleys and the constant
pong noise was attracting the curiosity
of others at the bar
before closing every being the bard
played the game the next day people were
lined up outside Andy Capps a 10am to
play pong that's this game right here
for kind of the younger people around
ten o'clock that night the game suddenly
died the machine coin container was full
people were lining up outside to play
the video game pong in 1972 that's
amazing because right here's what we
have today which we take for granted you
know we don't even think that much about
this these days it's just kind of a
product that ubiquitous that we can buy
no big deal but in 30 years can you
imagine what these people would do if
they saw this and it when you think
about it kind of here we are today you
know playing video games in a very
simple fashion with our brains and I
would argue that in the next 20 to 30
years we're going to see the same kind
of transformative explosion of how
humans interact with machines and again
right now it'll boggle our minds even as
this kind of you know amazes us today so
with that I'm concluding my talk again I
would like to thank the National Academy
of Engineering I'd like to thank Google
would like to thank you all for the
opportunity to speak and really it's not
just me that's kind of doing all this
obviously this is a team of people that
I'm fortunate enough to work with so but
that'll be happy to take any questions
thank you look at that Luna column
University thank you for a very
fascinating talk I may have what is a
maybe very naive question yeah I miss
you I kind of heard before that the
brain is very plastic and but I was very
surprised from you talking about the
fact that some of these people patient
are able to you are able to control
either because they activate the
particular muscle or because they may
imagine to anyway now for human beings
imagination or you could say that is
almost boundless know without limits so
am i understanding correctly potentially
one could control I don't imagine to
control for arms or five arms it's a
good way it becomes an attentional word
you know for its how many things
can you do in parallel and you certainly
you know we as humans are pretty good
from a motor control standpoint of
controlling two things in parallel arms
or even maybe ten things our fingers you
know whether we can add a third arm with
you know another set of fingers I think
it's theoretically possible but again it
may be attention elite axing so that our
global performance may decrease but it's
not impossible and actually speaking of
the they mentioned yet yesterday the the
about to say Society for Neuroscience
but no the NSF we've recently got a
grant to see what non physiologic stuff
can you control how far can you push
cortex to control things beyond kind of
our physical limits and that's actually
one thing for getting rid of study Eric
Johnson from UT Austin very nice work
I'd like to work with surgeon with
engineering mindset every time saw those
video make huge impact on patients so my
question is going back to this
optogenetics I think in Jim's
presentation he mainly talked about for
retina prosthetic systems there are two
limitation for optogenetics one is on
this intensity is lower than the
electrical stimulation second is you
know the resolution is not quite yet for
those bipolar photosensitive cells so in
terms of the brain machine interface
right so it actually costs emulation is
one way there was a recent very exciting
trend on using the optics so
optogenetics coming from a Stanford
group and also some very nice falling on
work from MIT very any comments on those
techniques apply for the bring machine
interface you know it's a it's a very
good question I think there's a couple
things one is again what we're doing in
these type of experiences we're drawing
information out basically for kind of
some type of external control but i
think really one of the next generations
of a brain-computer interfaces you want
to have sensory input so for instance
just as we operate our arms and one of
the things it really gives us good fine
dexterity is not just the motor movement
but it's the sensory feedback of that
motor movement we can envision
optogenetics really playing an important
role of feeding information back into
say sensory cortex to start to give you
better proprioceptive sense of kind of
where whatever it is that you're
controlling you have a feel for it
beyond just controlling it and getting
feedback with your vision that'd be one
row
I think important role for that
immersive ammonia from google first up
really cool stuff so i had to specific
questions regarding the speech interface
so um in the case of the motor interface
you said there was like a 60-minute
second lag between when the neurons fire
and when the the you know the move right
yeah what's the is there something
similar for the speech case as well and
that's it a little bit longer actually
okay um oh it is and well what is it
specific you know I'd to be honest I'd
have to check as far as going to be the
cortical activation relative to the
speech articulation it is definitely
longer than 60 milliseconds you know I'd
maybe put a hundred hundred 50
milliseconds but I'd have to double
check that the other question I had was
I was wondering if you guys have looked
at sort of if there's a correlation
between the spectrogram of the actual
speech and the the plot you showed of
the neurons that's actually one of the
things we're actively looking at and
there is to some degree quote is one of
the things that you can we're working
towards it we actually want to have you
imagine speaking and have kind of an
audio voice box that basically says it
you know because I that's really and I
kind of preliminary we're almost there I
could I can't do it now but I think that
we will get there was again it's
interesting I think I heard somebody
mention like deep belief networks as an
analysis you know that's a great signal
analysis package for getting information
out like that so we are working towards
that Oliver Williams microsoft research
obviously as everyone else says you know
this was when I saw that space invaders
thing you know it's a tingle factor a
little bit it was like I was amazed how
good it was but what he showed was
everything where the control signal was
being piggybacked on something that the
brain sort of already had machinery to
do so in the case of replacing a missing
limb that's an obvious thing to do right
to overlap the robot limb with with with
that functionality but when you're
starting to control the computer or if I
were like driving my car by thinking who
or are it's going to be pretty dangerous
if I start engaging in a conversation
and I say who are and steer into the
nearest wall so are they part of the
question
there's nothing to say that the question
is really is there are there parts of
the brain that functionally there is
sort of empty space white space in which
we could actually park extra
functionality I guess it's related to
the good you know the thing is the
amazing thing about the brain is and I
don't have this movie what's certainly
one of my collaborators does a really
nice job of showing somebody doing
joystick control and using that so and
using that same patch of cortex for to
do something completely else so like for
instance you can play doom for instance
you can use your joystick and you can
shoot with your brain and and you can
use those same regions of brain so the
brain you know that one area of cortex
is always doing multiple things at any
one time so certainly that it you do get
concerned about crosstalk and that's
actually one of the things when we move
forward for a true clinical implant and
in terms of reliability and durability
we have to make sure that doesn't
overwhelm but you can certainly we've at
least have preliminary evidence that you
can use these signals and your brain
will still do the stuff that it wants to
do without it without substantive
contamination this is RC from Eastman
Chemical and this is a wonderful target
feels like as if I'm what I'm watching a
movie so along that line can it comment
that what is personal in the movie
inception is real number one number two
I'm sorry say that again the movie in
substituent where you can implant or
interruption inception ok implant ideas
into human brain ah taking the other way
your cousin to some of the cases where a
person can imagine and it can be
transformed to computer can we do it the
other way show some good things behavior
in the computer and it can go back to
the brain so that it will opportunity to
change some of the culprits so basically
the matrix type of stuff you know can
you put in you know can you know virtual
perceptions and so there's a kind of a
fundamental difference between output
brain computer interface where you're
basically decoding intentions and having
that manifest in the real world and
doing stuff in the real or virtual world
and putting that into the brain and it's
easier to take out than it is to put in
because it i guess you may be kind of an
analogy have how i think about it is
imagine that you're kind of at a
football stadium right and basically
you're watching the football game and
you can you can infer a lot of in
information about that football game by
listening to the crowd but it's harder
to control the football game by
recapitulating the sound of the crowd
and so kind of putting information is
actually a lot more complex now I think
it's possible to do it again we were
talking about optogenetics and that may
be a way to put in information but I
think we're still we're still I think
we're further off from putting
information in and we are for taking it
out Sam vehicle or Cummins I was too
simplistic questions but it's kind of
where I am right now with respect to
this Lee the first one is when if you
want to control an arm versus a leg and
you drop this gadget in are there
different places that you need to put it
in order to do that and the such a very
good question actually it's not so maybe
to answer that is you there there is a
somatic topic distribution of motor
control in the brain so for instance
there's a very different area for for
instance leg area foot area hand area
arm area tongue area and mouth area so
you would you could you could put them
in potentially different areas to get
differential control and the second
question was and how much does that vary
from person to person bring the brain
that's another very good question so
there is a fair degree of variance
between people and that's or if you
remember me showing kind of that panel
for instance where exactly do we put
things when we decide you know and
that's where can a functional imaging
will help us kind of not give us the
exact perfect area but the general
location of where would be the best
place for instance to separate leg
control versus arm control humans talk
at MIT I think you discussed this
briefly just a second ago by saying that
the input is more difficult and output
but do some of these ideas lead to a
person-to-person communication as well
well I mean again I think that's kind of
the input issue I think that when you
overcome that not a technical barrier I
think it's possible again this is kind
of it's a pet theory of mind but
basically you know technical and social
innovation kind of our kind
exponentially parallel to the rate at
which we can exchange information right
so that for instance if you imagine kind
of the world has evolved and changed
dramatically now that we have things
like Google and cell phones and I think
as you know we can exchange information
more rapidly from brain to brain I think
that you know that can potentially
facilitate more rapid expansion and
development of ideas hi Chris manager
Carnegie Mellon very nice work of course
so I have two questions the first is on
one hand you talk about the plasticity
of the brain you say it has amazing
potential to adapt to the infinite let's
say right and the other hand you're
saying well it depends where we put it
because it's different such people you
know it's right so so where are we yeah
you know you bring up a really good
point you know the brain is plastic it
does change there are probably some
limits but also one of the and this has
kind of always been a big challenge in
neuroprosthetics is creating a co
adaptive system because the brain is
changing somewhat and we have to change
the system also to adapt to the changing
brain function so it goes back and forth
yeah so my guess is does it does it
really matter you know is it you just
kind of leave it up to the brain to
figure it out right and then and and
again that's one of the things that
we're still working to figure out what
so for instance we've done again one of
my kind of partners in crime his name's
dan moran at Washington University he's
taking the complete plastic approach
where you said okay just put an
electrode array and motor cortex
arbitrarily pick electrodes arbitrarily
pick frequencies how do they do and you
know what they can get control you can
take the opposite tack and say you know
we want a really hard code this
intention you know ooh EEE ah and and we
can do that too you know and again
what's going to be the best kind of you
know come essentially kind of cognitive
physics you know for which gives you the
most optimal control I don't know the
answer yet it's still working on it
there's a quick practical question so on
a scale of 100 describing the clinical
barriers to entry for econ versus
optogenetics any well I will did confess
the disclosures that you know I am I'm
involved in a company creating a cog for
brain computer interface today and I
think we're pretty close we're actually
I'd say we're maybe three to five years
away from a clinical trial because the
hardware's out there the technologies
out there we need to integrate it and
put it into a package but i think that
you know versus optogenetics i think
you're probably little further away but
again just to disclose my bias i'm steve
murray exponent you saw you should a
picture of a fellow with a brain cap on
totally non-invasive has there been any
effort to proliferate that to sell a
whole bunch of them that spit out signal
that a hobbyist and yet there's your
some companies neuro sky and a motive
and actually we're working with their
head caps to create again non-invasive
simple control possible therapeutics and
so but yeah they're they're out there
and people were playing video games with
them you know I I have a personal
question so my dad had a hemorrhagic
stroke in 2002 and he's been a
quadriplegic for the last nine years and
the gross motor control area was excised
as part of the hemorrhage so my question
is regarding brain plasticity are
obviously it can't help my dad now but
in future can the brain be retrained so
that if the gross motor function area
has been excised the other parts of the
brain can possibly could actually that's
a great question because act in the suit
and that's a very and I obvious I
couldn't talk about in this time but
we're very interested in using brain
computer interface technologies to
induce rewiring of the brain so for
instance the interesting thing about
stroke especially hemispheric stroke
like your father had is that when you
lose one half of the brain whether it be
because a hemorrhage or ischemia you
actually haven't lost the motor command
you've lost the ability to execute it
and actually the motor command and the
motor planning is that there is residual
information on the unaffected hemisphere
and we're looking at ways of using that
that motor planning to use a BCI to
reanimate kind of motor impaired
patients with chronically affected
stroke and so we actually have got that
study underway right now yeah Eric great
talk so Chad mountain from Mattel is we
talked by yesterday my group was very
involved with the brain gate program and
I wanted to kind of follow up on that
question of plasticity so one of things
we found we were in the fifth layer of
the cortex and so we have the pyramidal
neurons and we found that actually we
didn't seem to see a lot of plasticity
and I don't know is you go up more to
the surface like like you do with acog
do you think that will remain true it is
it something really at the primary motor
cortex that that will remain true and
because some of the training we did in
matter of 10 or 15 minutes you know we
were in business and people were we're
back to doing things they hadn't done
for 32 right seven years it's it's a
good point you know certainly you know
with you being in a deeper layer you
know kind of closer to the Betz cells
right you know and certainly we're on
the surface where there's a lot of more
dendritic arborization which is it set
by definition interacting with multiple
regions the brain in some sense is
involved with different areas of the
brain influencing different areas of the
brain so I think maybe with the ACOG we
could we have more access to plasticity
maybe you know but you know certainly
with single unit stuff you know with
stuff we were also talking there is a
signal drift you know they're there
they're cosine tuning their direction
tuning kind of changes from day to day
to day and I think that and I think I
remember talking to Krishna shenoy if
you know who he is but basically you
know it seems like you know that with
prolonged training they start to see
kind of some of those plastic changes as
well okay time for one more question
before break Eric really nice talk a few
years ago I interviewed a student coming
right out of MIT working on measuring
neuronal firing on an individual level
and he gave me the metaphor that what
we've done here is we've essentially we
can see all the pixels in a movie
individually but we don't know what the
movie is really telling us and so the
question is the problems where you're
seeing 60 of a billion pixels you know
what I mean and so that's the problem so
the question is if getting ahold of
single neuronal firing has sort of been
a Grail for the BCI community in a
variety of ways to really understand
what's going on with starting with cyber
kinetics are the companies like that how
do we build up higher level models about
avian activity yeah you know I would say
you know is single units the Grail I
don't know that you know because you
know it kind of let's think of another
analogy is that when we're taking the
temperature of a room do we really need
to know the kinetic energy of each
individual atom in that room probably
not you actually want to take you know a
population of that activity which is
mean a thermometer and i would say that
by taking population activity because
even with the single unit systems to get
the decoding that they need they have to
do a number of units to actually get
that decoding and so and kind and kind
of kind of where single units and we're
meeting we're going to micro
I Coggan by looking at these populations
of neurons again not 60 or hundred but
you know maybe you know a million that
that combined activity and we start to
able to separate different you know kind
of population behavior by looking these
very different frequency scales that we
are actually getting you know the
population information which i think is
where the sweet spot of kind of
intentional decoding it is at it's time
to break let's thank Eric one last time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>