<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Music and Machine Learning Workshop: Variations on a theme: Factorisation based models... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Music and Machine Learning Workshop: Variations on a theme: Factorisation based models... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Music and Machine Learning Workshop: Variations on a theme: Factorisation based models...</b></h2><h5 class="post__date">2012-02-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZSnKn50WBos" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so let's get started with the silence
having been reading title so nice time
now okay in our town well that's a well
I don't give everything so I like to
acknowledge a lot of people actually so
this work has been carried a license
would you check my robot you and you are
inspired by other colleagues into your
car not working together and basically a
so this talk will be about a particular
way of modeling audio each other in the
last say six or seven years times it's
actually the modeling techniques are
based on matrix for accumulation sorry
that we will be somewhat extending and
hopefully you defy some of the metals
there in the general kind of umbrella
under the tensor that won't answer
occupation and I will in this respect
you were kind of like a frosty
interpretation of statistical
interpretation of the standard
factorization model and give some
example models of existing and noble
models of for audio analysis for various
tasks and I will depart at the air
describe a kind of a general framework
me to hope that you might find it useful
also for kind of future work so that you
can also develop new models use of this
particle frame and then there's the toad
will leak in the couple thousand
factorizations that is essentially a
kind of a paradigm value one to
integrate several knowledge sources it's
essentially sensor fusion information
integration type of hiya and if time
permits and if not still a in some time
I will talk about a few applications in
various fields like them
I have so you know depending upon the
kind of how it goes I have you know some
type of slice or so I can cut it so the
our main work has been focused in the
last couple of years especially is it
related to all your modeling in the
actual amazing paradigm so here's what
we actually try to do is as follows that
we want to build algorithms which by
which we can analyze and understand
audio a miracle structure and this is
one time space essentially you can give
the second inverse synthesis type of
approach so here in this particular
frame we are actually developing models
so that relates the absurd audio so the
particular structures that we are
interested in and we have typically some
prior knowledge about that structure and
must be actually define that model then
the rest is hopefully in kind of
mechanical so we can turn the basin
handle to actually confirm the type of
things that we are interested and this
is the assumptions in contrast with some
others traditional or algorithmic
approach where there is no clear
boundary between what and how so in some
sense these models define but we really
want to kind of do and the inference
mechanism is actually how we will be
doing it of course this thing started
here at the company you know cannot
really write a model to fold it but
anyway so there's every kind of the
general framework essentially that I've
you think and say so then it comes to
you know and now is just a folio I you
kind of it just a overview the main
problem my opinion is it Annalise
musical
in the superposition problem so you have
several strong sources even if excited
it's actually a monophonic source that
can be some kind of a background noise
or you know if the intro instrumental is
general some glitches I said that you
might not be interested there is a lot
of the river variation or 30 variation
problems that you want to rate kind of
get rid oh and if you want to do of
course music information read to you but
typically if you kind of develop your
features for st. monophonic audio they
don't apply a minute before for the
phone equal mix close it because
typically you know if you compute as
feature from this superposition it is
typically not the sum of individual
features of this so you need some kind
of a separation type of another kind of
light there are of course several
applications but one of the important
application in this particular framework
is the polyphonic music transcription
that's actually what you really want
this in this particular application
giving it article representation of the
audio signal here it is a spectrogram
the axis is quite some time it is a
stray currency and the energy content at
the individuals frequency fine madam and
that's particular representation we wish
to convert to some human readable
location and this is actually a quite
hard problem and hopefully this type of
models that I will disable fit you have
to some extent for solving such problems
okay so there are many computational
issues you know like in process music
transcription I don't want to just leave
them at this stage and add many actually
a signal models for all your also music
have been develop over the time so this
is kind of a very crude the kind of
classification of those you know like
time to my state space dynamical model
for just today morning we saw some of
the examples there like karma filter
marvels I said or there are in living
information rateable very much you know
feature-based by L FCC's or chroma base
that you can all kind of design it a lot
of models or
kind of masters on top of this in this
particular kind of mother prep for the
photographer bible talk mostly on
analysis of transform domain so we have
essentially kind of the Fourier
representation some representation of
the food co efficient and people likes
to kind of model the nature of those
coefficients let's hear people use I
kind of have quite well established
already well-established approach for
modeling distant and so this is
essentially I'm sure that many of you
are familiar with this kind of more like
a pro the approach is essentially like
this or the paradigm is based on matrix
factorization suppose we hire a matrix
in this case in dog in case it will be a
spectrogram typically and we won't want
to write this particular matrix as a
product of two matrices z1 and z2 and
syren I will explicitly write down kind
of the indices because later it will be
useful for a generalization etcetera so
here X because it's a major he says
essentially two indices here near top
and in our kind of decomposition we want
to approximate this thing with this
product of again two matrices CF is a
kind of a matrix that we are some ago
here is a kind of a picture of that so
that is suppose the data that we want
the approximate here those red sprites
correspond to possibly miss Ainge points
you don't have to observe the whole
matrix in some no missus is called the
matrix completion problem as well and if
you want to now describe this matrix as
a product of two matrices here they are
low rank in some sense which is the kind
of a low-rank approximation to network
but in this particle model friend that
doesn't help you can have also become
representation so let's widen is matrix
factorization also quite popular lately
is because most of them well known
algorithms can also be cast as matrix
factorization problems like forces
k-means clustering by imposing certain
constraints upon the kind of individual
factors you can
develop several hours so that is quite
nice for instance cain is clustering can
be the interaction is flavor or animals
non-negative matrix factorization
campaign by old pc a latent 17 days
later to reach the location with some
kind of variations can always be customs
as possible kramer so the computational
problem here is in a general sense we
want to minimize actually a kind of a
divergence magic it's in the observed
data and this product goes to the zen
weneva so why this is typically good
model for all us actually comes from a
very simple observation detective so
like vs interview because either musical
or typically the individual instruments
have a certain in a periodic structure
of the signals which are generated by
music let's pretend incredibly structure
i needed to set by the for example of a
guitar sound here it is the time and
here is the frequency as you see the you
can see the organic structure that is
due to listen elected the harmonics in
charge in equal space between among 30
services essentially this particular
matrix describes the energy content how
it varies over to summon this particular
object can be very well approximated
which actually even you know out the
product of two vectors you know that is
kind of a very nice approximation and
this can act as a kind of anal like
starting point for modeling spectrogram
so that is the you know I one of the
observation made first but it's more of
this and grown and I think facial never
stop who use actual NM f type of
approach for morning go so there is also
an underlying trauma stick model to all
these things so you can think of in on
this X new top as random arrivals not
and now this is actually you can think
of now this matrix or this latent make
matrix in the form factor this is
actually some kind of a kilometer of
this prompted distribution so you just
generate actually the perimeter of the
description some kind of a factored form
and then given them this parameter is a
product you generate
this particle is running so that is the
kind of the problem if you have a higher
end so this is for the one grand chase
you can't think you know in some subset
of model not all but some of them you
can think of like this so if you think
about matrix for multiplication
essentially you can think of it is the
sum of one rank vector multiplications
and then it's actually this particular
object which three indices now
correspond to the individual one rank
components that you generate
independently and that sum them up to
actually recover the original oh so this
fits in quite well with source
separation etc I think very actuality
there are meaning so this is von Raab
objects that you call the sources and
they get superpose and you want to find
kind of given their mixture the
individual components so that's fitting
quite well forces in a so-called music
transcription problem where you have a
kind of a particle all here and here the
goal is now to represent it hopefully
with the product of that matrix weeks
looks like this so here this matrix
contains the frequency of signatures of
the same individual no series 800 PX and
full circle the corresponding index to
the North index and this is the
frequency and this is the type of
information that we want to get out that
is the something which is correlated
pretty much with the musical score so
this is time and this is vinod is
implied so this type of the
factorization is actually quite useful
because many important features can be
derived from it but the problem is just
to make it completely on stood in an
unsupervised a is typically not
successful so if these are geared to
this article spectrogram to your site
nmf and hope to the cover this fact off
you typically don't get it unless yes
how do you know that those two axes
corresponding notes because you're just
factorizing it right yes x like that's
not I'm saying now so this is it you
know like do if you actually really jump
put a lot of prior knowledge about those
individual factors and not force them to
be oh so that is that is the point so if
you do it completely you know in
unsupervised you get a kind of two mixed
representation so that that is actually
do hope you want to hope that you
recover this particular factorization
yes please very good question is that
yes and I put you guess it from here or
from the stock does provide some
information as you see the speed of
correlated with human this new
york-style goes so a lot of work has
been done for you know actually for
deriving factorizations which may also
in some sense in not semantically
meaningful information so that is Don
typically by putting some try over this
individual factors many people have
tried many different things and I don't
want to go over all forces here this
decomposition must get by actually
coupler coupling to the individual
coefficients along kindnesses not like
enforcing some kind of a continuity and
there are other ways of communicating
some side informational inferences in
the stomach NM f football that is a
typical tasted so that you actually
force your decomposition to contain
something which correlates very much
with the individual spectrum of
templates as well as the mythical
stories suppose you want to decompose
this particular spectrogram in don't
they enforce that you have as a kind of
a like a template matrix you also kind
of concatenate to this matrix some kind
of a individual isolated nose and kind
of try to decompose everything together
we to hope that you can recover actually
something which is correlated
it is the way you one you are expert in
expected and actually what I'm a later
described is essentially a kind of a
generalization of this idea so you can
think of this actually it's like
providing site information to the
decomposition ok so you I have two
products and not this particular
template I kind of provided that of it
some site information the ones who are
familiar with bayesian networks will
find this bunch of the presence of quite
use the semantic slightly different but
the idea is and they're having a lot of
work and some of the models are pretty
complicated as you will be seen so it's
actually all this model based on the
father factorization of you know spec
programs and they are typically highly
structured and quite complicated and you
know like love this frameworks that I
will describe is aiming to is some kind
of a bringing everything play common
framework which is very much inspired by
probably graphical model so that you can
actually design different all your
models and that kind of inference and
depth and here in this context i will
describe two things that we have
developed recently well is the promise
of a tensor factorization this is
essentially for factorizing individual
10 stores and then the couple's work so
that the sender that's that's
essentially so I already said the kind
of main research question so I go a
little bit not technical so if I talk
about cancers typically i use them as a
synonym for multi-dimensional area so
people were coming from a physics
background my face noticed or not really
very convenient but it is not very
community always say a multi-dimensional
early so it's actually what we will be
talking this I kind of an object with
several industries test if you look at
the literature about factorization of
tensors some very you know common models
their eyes and those are the kind of
things you will immediately see like
Parvati
positions over here and object between
does this think of it they taught you is
 or as in a certain way this is
essentially Justin if you want to do it
is a simple extension of matrix
factorization type of problem there are
other type of decomposition with their
respective algebraic and algebraic
properties as at random it's a quite
well-known and investigated field and
are several kind of generalization but I
will actually tell them 12 12 years
actually if you think about texture
factorizations you don't have to have a
multi-dimensional data even if you have
force a single dimensional data is
useful to think in terms of tensors so
here is a kind of an example I will talk
about commotion from which who actually
makes maybe this idea a little more
clear supplies an altered signal at
second and said to that what is a old
origin of that signal that I want to
recover and z2 is a filter in houses of
the title and there is some noise again
so this is you know in some sense this
is a typical convolution operation set
from cobalt it's 82 and this is kind of
recovering so what we will be doing is a
very simple in kind of substitution so
we will introduce a dummy index d and
sets d equal to i minus T and by
introducing this Neil kind of object the
Delta Dirac and then we sum over tea and
that we call it yet another transfer ok
so in some sense you have not three
objects one of course you know it
already but now the decor motion problem
is actually finding this building so
this of course doesn't lead to any said
what what will interesting is not you
can work to model these individual
signals in a hierarchical way and you
get actually increasing the more
complicated models for which may be
inference will be harder to do ok how
much higher
let's give you so you have 30 minutes
total but I wanted you to stop at 25 10
minutes yeah so I've gone till 425 okay
I am supposed so I new chief to slice
okay so for instance this is a typical
situation where it says if you have it
so now i denote the signal that you want
suppose this signal is getting in some
kind of subspace so it's a kind of a
suit of constraint that you can see and
this can be written in this framework
why just imposing a source of cases and
I'm trying to just recover the expansion
coefficient in the space said only thick
the mom becomes slightly more difficult
and you can do the same thing to the
filter etc so this is an example of a
kind of consumables basis to put by here
triangular basis a spline basis if you
can actually buy justice to proposing
such basis vectors that kind of a
piecewise continuous e so this is a
simple kind of modeling guide so this
can become okay you can do the same
trick over the filter coefficients as
I'd rather kind of get more and more
complicated models of those so here is a
kind of an example on a kind of video
how this applies when we have a blurred
image there's a kind of a very difficult
filter is just taking the average and we
have the original image here but if we
train the subspace of the images that
you want to recover and also the kind of
the filters if you know something about
it is typically quite possible to
recover something which looks so this is
a kind of a nice way of putting prior
information so now begs to audio there
is a versus a common one which is used
quite often for audio so which tries to
circular this one right type of
approximation in all your typically if
you have harmonic calm times that
particular content is not modulated fire
constant volume so this kind of not
you need parallel for high frequency
coefficients drop faster so this type of
structure can be captured by taking the
temporal structural intercom and SN
model also proposed by party cimarron
this year the model is as follows so you
have basically two matrices which do not
actually a combo with those two basis
vectors and then you get something like
this and the hope is them given this
particle representation to recover this
individual so that is the type of
models that one and on on this and
cottage there have been many different
models developed which aim to actually
computing different type of kind of
factorization but what is not difficult
is you know this models become
increasingly complex and it is hard to
derive the inference algorithms just
starting from scratch and that's why we
have actually developed for your hand
like this once they've kind of a
framework which we named the fellow
spectators tensor factorization
framework and here we describe a tensor
factorization model as follows so we
have in an abstract as an object a
tensor which leaves on an index that v-0
so those are the kind of things you can
have several indices here and that this
particular index is actually completed
product of several tensor factors which
collapse over the indices which are not
part of the observations so that is the
general framework for them so let me
give an example for it so in this
framework you can describe the nmf model
here except to tow this a simple matrix
factorization model all indices are
corresponding to x TI and then the
obscure indices are ft this v 0 the
first factor has the indices F&amp;amp;I the
second factor said I and T etc and then
the indices that we are summing over the
V 0 hat are I so that describes in arts
I change the entire model so that is the
simple
chico and the baby will represent as
models is very similar to graphical
models we will apply again the factor
graph formalism it just by values in it
slightly different setting instead of
random variables we will not denote the
particular indices in the factors
correspond to this black nose so that
won't remember has the elements even I
so those are not connected to this
particular factor Z to as int so and is
connected to that so that is the
description of the model and you think
its framework you can describe several
different models and the center a bit
increase in kind of complexity and but
now the not nice thing is that once this
model is described in this Famer the
inference algorithm is easily readable
so we don't have to derive it from the
Scotch so this is not to be mixed the
actual probabilistic interpretation of
the smallest for instance the simplest
model NM f actually if you write it as a
Bayesian network loses a lot more
complicated so all kind of modeling sara
is a lot higher level so rather than
raising them and we have derived for the
general graph formalism and
update rule so that is essentially you
want to learn the individual factors in
your decomposition and for the non
negative and chase this is the one a
very general update though so i will go
over that one and then talk about
special cases over there so here the
alpha is the factor that i want to
update and I fix all the other factors
that
going to fixed rate and what I have to
not compute is it first a kind of a
tradition of the data which is given by
X X so that is the actual factors as
they are in this state and this w is a
model specific kind of function which
you actually specify a priori this is
the called inverse variance function it
is inherited a related to your noise
model and then first this particular
model and the am here is the missing
data and this is the general of it so
this Delta is a function which has the
spartacus complicated form which takes
as an argument an object beaches on the
data space and all the product of the
factors that you do not want to update
at this stage and you know them to the
Train I this actually looks like a
marginalization operation for you
multiply all the factors and all
something which is related to the data
and somewhat the indices which are not
part of the software that you want up so
that is the general description and we
have all four articles for general theta
so let's see how that looks for the nmsa
updates so you first calculate the kind
of tradition over near town and then you
take out z1 compute a pairwise marginal
over me no mind that can be done
actually community on this photograph
and you iterate basically so that is the
essential algorithm specialized for n
you can also put some priors over the
individual factors the update rows are
animals and so I will jump to my eye we
need two more minutes I don't play
something so now this particular
framework can be generalized in as you
know convenient way to actually
factorizing several attackers at the
same time so here the problem is
slightly different suppose you observe
several things so those are can be in
some sense like information leeches
complementing each other similar to
anyway problem i showed you in that
month here some of the factors are
shaped so you can actually now ask how
do i compute this individual factors and
for that particular problem we can
actually define an analog of update rule
so it is very similar to the first one
we'll beat only differences there is a
kind of an indicator matrix our new
alpha this is very simple to construct
the baby constructed it is essentially
the adjacency matrix of this graph so we
just ask if is a a member of x1 yes if
it's ESS vo that one otherwise we put
the zero and that's the kind of a flow
matrix and this update rule is again
available in a kind of a concert in so
you can actually by using this algorithm
compute the individual factors now to
cut it short I would describe a
application of this particular framework
and then finish so here the problem is
we have a musical audio where we
actually are missing several frames and
a front of the net standard nmf
framework this is impossible to recover
but by throw out hoping to provide you a
signed information we might actually
recovered actual audio signal so this
system tensor factorization model that
we are come up with so here said all
your little missing beds here we provide
a side information some spectrogram
shapes from say a piano if you notice
the piano piece and the interesting part
of this model is we also provide side
information from musical scores which
argue again as matrices and the idea
here is that well if you have a musical
score there is some harmonic structure
which is repeating itself so that can
also be represented community using a
factorized structure so I don't want to
go into details of that but this same
idea is in some sense this particular
data is providing site information to
the spectral templates and the scores
are providing a site information for
excitations which hopefully
the scores so when we actually do this
and then run the general kind of update
rules you indeed huh yes
so this is them
I need to go a lot of very rude or
unloved enough alone
bless you little here hold on uncut the
monitor this one yeah so this is so this
is the equal stretch those of course I'm
later reference for so the score that
medium to the sir this will buy
something for a yellow
and this is the constructive
and this is the original didn't have a
session in like a garage okay so you're
choosing have some nice emo minutes so
p.m. you will look at metal actually
computing quite a large class of
factorization which are useful
especially for all the analysis but also
from levels and other applications and
there are other extensions possible you
can also do pacing treatments in
treatment if one is interested in the
array a toolbox currently in alpha form
so you just specify a kind of a model
like you to specify a graphical model
and it computes for you the
factorization so it is not security
supporting a couple case but that will
come soon as I see quite fresh out of
stone and if you are interested more in
feeding this particle framework I have a
few references and I'm happy to take any
questions if there's time for that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>