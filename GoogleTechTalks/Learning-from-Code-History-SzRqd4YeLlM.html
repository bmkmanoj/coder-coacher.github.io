<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning from Code History | Coder Coacher - Coaching Coders</title><meta content="Learning from Code History - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning from Code History</b></h2><h5 class="post__date">2009-11-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/SzRqd4YeLlM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so thank you very much for having me
here at Google today's Tech Talk is
called learning from code history and I
guess I should start by telling you a
bit about myself so starting a bit with
code history or maybe a bit of history
itself are more for something let's go
to the year 1997 anyone here being
conscious already in the year 1997 you
look so very young to me I know it's ok
ok ok ok ok I'll give you a couple of
hints what was what was all the rage in
97 it was the lost world and protecting
the earth from the scum of the universe
could have mean early Google logo I
guess that one yeah they also was in
terms of songs there was for instance
Elton John my candle in the wind
princess die had just died this very
year there would be a loss Macarena with
los del Rio Rio with a Macarena the
Spice Girls all together if you want to
be my lover and all that and Chumbawamba
for those of you with a more socialist
touch and yeah and and finally that was
me in 97 actually I don't belong really
in this group because in 1997 in 1997 I
was doing my PhD thesis and PhD thesis
was called configuration management with
Russian sets you think oh wow there's
configuration management he has
something to do with code history but
actually that's not so much the case um
I was at a chair where formality and
coming up with cool formalisms was all
the rage and applicability only came at
a very distant commit only at a very
distant place we would bash our heads
against each other on finding good
applications for linear logic so first
came the formalism and then came
possible applications and my PhD thesis
is somewhat and along this direction
it's a it uses description logic for
modeling version control bottling
version histories after I finished my
PhD thesis on version control I thought
I wanted to do something rather rude or
rather you
full for a change so instead of looking
at code history and actually looked at
code and a student of mind or whatever
ludka house and myself we came up with a
debugger with a visual debugger called
ddd are the fun part about it is its
ability to visualize data structures as
you can see up here there's a linked
list as he can directly visualize it
within DDD that was a pretty fun pretty
fun - did he was a problem actually was
post card where if you liked it you
could send me a postcard and eventually
I got a whole bag of them and then while
we were working on DVD and making
release after release
well we encountered the usual problems
of maintaining a program that's being
used by hundreds of developers all right
well hundreds well would rather be tens
of thousands of developers all around
the world and of course we would also
get bug reports bug reports like this
one for instance are this comes from a
guy at this came from a guy at Motorola
and he he described that his earlier
version of DD had worked but now I'm DDD
was a front end to command-line
debuggers called gdb and he had upgraded
the gdb component and all of a sudden
DDD didn't work any more properly this
was a classical situation you have
something say your old version of the
operating system and now you install the
new one and all of a sudden things break
well and that's when even though I had a
debugger at hand I would have to enter
the usual mode of debugging which would
be at the time well sitting in front of
your laptop of your computer you look at
the code you have a piece of well coffee
him drink or maybe have a smoke if
you're so inclined and it gets late and
it gets late you realize you're still
hungry you're getting your pizza and
you're back to your computer and having
another drink and look at the code again
and have a smoke maybe in between your
significant other calls you up and most
likely at the moment when you are really
really hardly when you're totally
concentrated when you're in the flow and
you're getting this call where are you
right now come on please come home at
this point and you realize that while
you're talking you're still you're
starting to lose it you're losing your
concentration and you know you have to
cut short this call because either you
because because you're losing your
concentration it will take you another
hour to get back into that mode and you
have to cut short your significant other
which is an awfully bad thing to do the
other choice is other choices to lose
your code which is also an awfully bad
thing to do and this is this is how
eventually well you spend your days and
nights with debugging and actually
actually I wouldn't be surprised if if
half of the divorces and IT actually
have some background in in staying late
for debugging or staying overnight for
debugging maybe it's even say if you
have a significant other and you cheat
on them that's one thing if you cheat on
them because if you cheat on them with a
computer that's really really bad so um
so and and now and now so while
maintaining DD di to debug like crazy
and like almost everybody else I never
got any formal training and debugging
and I didn't know how to do that oh and
I did my best in doing so are I wondered
and at this point I wondered say I had
done this work on version control I
wondered whether it would be way on
leveraging leveraging the history of
changes leveraging the code history in
order to debug better in order to
actually solve problems and the first
thing I came up with was actually using
code history to simplify problems
so let's come back so what do I mean by
that
let's come back to this bug report this
is a we have this situation I have the
old version that worked and a new
version which no longer works and in
this case the appropriate engineer had
upgraded gdb from an old version to a
new version and then behold there we go
our things just broke how do you figure
out what precisely caused the problem to
occur first thing I came up with and
that's pretty straightforward is called
bisection
the idea is pretty simple again here's
an arrow of time and you have situation
yesterday where your configuration
worked and you have a today's version
which no longer works between these two
points in time something must have gone
wrong
straight forward so what you do is for
instance you look at place say today
morning check it out does it work or not
well it works so maybe it's today
afternoon our low and behold today
afternoon it no longer works that
something must have happened between
today morning and today afternoon and by
doing this sort of binary search again
continue this for a number of times you
eventually figure out hey here's one
precise point in time where some change
was made that Raymond made the program
go wrong I actually did precisely that
and in the case of gdb in the case of
gdb I immediately found that there was
one single point in time where
unfortunately not only one change had
been applied well actually there was one
single logical change and this one
single change that had been applied was
178,000 so the diff was one hundred
seventy-eight thousand two hundred lines
long that's pretty amazing if you
considered that gdb at the time had
about five hundred thousand lines so
some of these changes actually actually
actually came from from a change of
address of the glue Foundation so every
single source file was changing but
there were also plenty of code changes
in there and so my wonderful scheme of
figuring out what has what had changed
didn't really work and it turned out
that what I was actually looking what I
was actually looking for is a causality
problem because out looking problem
means that you have two situations you
have one world in which your problem
occurs or in which the effect occurs
this is when the program fails and
another world where the program works
where the effect is not there and
actually if you look at the definition
of causality in particular the
counterfactual definition of causality
you will find that the cause is
precisely the
friends between a situation in which the
effect occurs and in which you does not
have does not occur in our case our in
our case we had the unfortunate
situation that the cause was there
upgrading to gdb made the program fail
there it is
here is your course you didn't know that
before him you can even come up with
with with other causes you can also say
that for instance oxygen is the cause
for my program to fail because without
oxygen which would be an alternate world
there would be no developers and without
developers there would be no program and
therefore there would be no fail but no
failing program either there would also
be nobody to witness it and so we could
immediately stop it so this this idea of
causality as the difference between
world is not necessarily something
that's useful but fortunately this
problem was also discovered by day and
by JB Bluest is a fellow who was a
philosopher in England at the time and
he said that well there's actually a
better definition for causality because
what he introduced was the concept of
actual causes and actual cause is not an
arbitrary difference but it's actually a
minimal difference between a situation
where the effect occurs and where the
effect does not occur in our case this
would be the difference which mean a
program working and the program failing
and you want to have a difference that's
as small as possible in order to figure
out what the cause is so how can we
apply this to how can we apply such a
definition in order to figure out what
the problem causes well you can again go
and systematically try to narrow down
these differences more precisely
narrowing down the difference between a
situation today where the failure occurs
and a situation yesterday where no
changes have been applied so if
something is bright up here this means a
change has been applied if something is
dark change has not been applied now we
have a multitude of changes and
something in between here has gone wrong
so how can you do that again you can do
a binary search for instance by applying
half of the changes and this is actually
something this is actually something I
did
what happens if you apply half of the
changes while you test it and if you
figure out that for instance the program
now works then what happens is you now
know that the failure cause must be
somewhere within that difference that is
this difference here no there's no
difference anymore so you have never
just narrowed down the difference by 50%
you can do this again and sort of a
binary search again never again the
difference if you find that there's a
failure up here you again have narrowed
down the difference to another half and
you can try this out again but
the bad thing is that the bad thing is
that this may not work forever
for instance what happens if you haven't
if you have an undetermined test outcome
which is actually likely if you take
just a subset of the changes apply them
and want something meaningful to come
out of that well this doesn't help you
any further same thing goes if you take
the other half let's assume for the
other half we also have an undefined
test outcome this doesn't help us so
we're stuck in here there's no way we
can continue with just binary search in
here so the idea that I came up with and
this is probably the one single idea
that summer that was most significant in
here is well maybe we can come up with
something that's not right halfway
between these two configurations but
rather something that's closer to in
this case the failing run that is we
have a la only apply a smaller set of we
apply a larger set of differences such
as the difference the potential
difference is smaller and it turns out
that if you do this repeatedly you
eventually come up with this with a
configuration where you have a
determined test outcome that is an
outcome where the for instance in here
where the program fails you are can
continue this game narrowing down the
difference again and again
systematically until you do have just a
minor difference in here minimal
difference in here which remains in this
minimal difference between these two
configurations is the failure cause now
there let me repeat this again the idea
is you have an automated test which
tells you whether configuration is
failing or passing
or whether it yields an a
non-deterministic sorry an unresolved
result and then you have a strategy that
systematically narrows down the
difference between the passing and a
failing run until it has narrowed down
the difference to a minimal difference
and this minimal difference then is
indeed an actual failure cause there's
also formalism behind that you can
actually formalize this pretty well you
have a testing function which u-turns
you either a pass or fail or unresolved
and based on these definitions you can
actually describe the entire the entire
strategy for narrowing down these for
narrowing down these configurations in
well seven lines let's make that eight
lines of things if you're from France
for instance if you're interested in
formal formal methods this is your slide
please have a look at it it actually
took me quite some time until the entire
algorithm would fit on one slide so
actually actually I was applying the
simplification process to the algorithm
itself and this algorithm later became
known as Delta debugging because Delta
debugging the idea is to have a delta
between the passing and failing
situation and you narrow down this very
dull so until we find a failure cost so
this was what the four most formal
people if you're more programming
inclined here's the very same he's the
very same thing in Python code actually
it was programming in Python at the time
so I still have it in Python if it were
also Python had the big advantage of the
entire algorithm fitting on one slide
again had done this in C++ I would have
well would have used to slide so the
entire so the entire algorithm does
enter a Delta debugging thing actually
fits on one single slide all you need is
a testing function that takes care of
setting up the appropriate configuration
and coming up with an appropriate
outcome so this is what Delta debugging
does and so let's come back to our
original gdb situation I have actually
applied Delta debugging to gdb and this
is the log of the actual run actually
it's under multiple configurations what
you found in here is what you see in
here is this
this line going down here on this line
the y-axis tells you how many how large
the difference was initially we select
8720 changes in here you see this is a
logarithmic scale so don't worry too
much about it and you see that for some
time it stalls around 2,000 changes
where it's not able to find a
combination that comes up with a with
the resolve test outcome and then all of
a sudden all of a sudden we have a large
you drop down here after after
approximately 60 tests we've allowed you
to up down this is precisely the
situation when all of a sudden half of
the changes already suffice in order to
make the failure occur again and then it
rapidly goes down and down again until
finally after 98 tests that's one hour
that's one hour on a regular PC if you
have multi-core machines say 16 cores
you can easily divide this by 16 because
it's because it's very easily
parallelizable so after one hour what
you get in here is the actual failure
caused the failure cost is just one line
one line that was changed and lo and
behold it's not even code that was
changed it's not even code that was
changed but it's a documentation string
it's a documentation string within gdb
and this is because this is actually the
if you if you anyone here ever use gdb
on the raw command line mode oh yeah
let's see people nodding yeah it's a
pain I know I know but it's very
powerful at the same time if you type
something like help set Ahrens this is
the text that you get this is the
documentation for the set rx command or
in the old version it was set arguments
in the new version it was set argument
list this is the text you get when you
type helps at arcs at the same time
though this very help text also is the
base for the output of the set command
through some so some pretty magical
thing if you type if you type view arcs
then this very prefix of this help text
is being used in order to print out the
argument rest it probably saves too
dozen bytes or something like that in
the executable and of course if you well
if you were born in the 70s or 60s this
is really something usually and output
output of argument because DDD expected
a string to start with arguments and gdb
put out the wrong output in here so okay
I saw the difference I knew what it was
so I patched DDD in order to come up to
accept anything that would start with
our ogre and then as far as I understand
until today it's still working purple so
I wrote a paper about this and I called
this yesterday my program work today
does not why or my advisor didn't like
the title at all are they the whole of
my my co advisor for my PhD thesis
didn't like the approach at all when I
gave the talk at the conference people
were actually asking me so he came up
with something so simple that's really
amazing I mean why did you get the real
paper accepted for that and I said well
it took me one year to get it that
simple oh we wouldn't have believed that
okay okay well actually actually it's my
draw I draw quite some criticism on the
mayor but incidentally just this very
September this very paper got an award
for being the most influential paper of
1999 when it was published or so in the
past ten years well not for the entire
period of the past ten years but at
least in software engineering that was
one of the more influential papers we
also wrote a tool called DD change which
would implement this for the Eclipse
framework initially we pitch that as
debugging debugging at the touch of a
button so you just press one button and
those two debugging would automatically
figure out what the change was it draws
on the local history as well as on the
global history of a system and my
student eventually also figured out that
are not only with Delta debugging would
you be able to
to figure out what the cause was you
would also be able to immediately
automatically fix it because all you
need to do is to revert that very change
definitely but if you apply to debugging
you can actually prove that the failure
at hand will be fixed that's within the
algorithm not sure though whether this
would introduce any other any other
problems so actually I asked him to have
a to have an dialogue that would confirm
that's this whole thing he always wanted
to go and Charlie without dialogue and
in terms of simplicity I think that
going without any dialogue would ever
would have been even nicer so while
you're programming and you make a
mistake totally buggin steps in finds
out what the change was reverbs the
change and maybe it can put some simpson
squiggly lines under the code that it
just reverted or something like that but
there's there's many ways to put this
into a nice user interface or delta
debugging even made it into the
Wikipedia and the Wikipedia you can also
see that there's a that there's a number
of additional uses for Delta debugging
for instance if you have a program input
you can use the very same city they're
the same algorithm to figure out what
part of the input made your program go
wrong suppose you have this big sequel
query for instance and you send this to
send this to a database database crashes
you want to figure out what is part of
that
what is part of that what's the part of
the sequel query which makes my database
crash you have a big HTML input you'd
send it to say to Internet Explorer
Internet Explorer crashes and you want
to figure out what was what was the part
that made it crash because to combine
this with random testing you create a
big input randomly send it to some
program credit should I chose a chose a
failure you want to figure out what it
was you can use Delta debugging for that
you can also use that for user
interaction that's a fun part are we had
an experiment with Mozilla at the time
where we had a description of seven
steps that you needed to well you need
to select specific menu items and press
specific buttons in order to make a
printing fail Yoker turned out that only
three keystrokes sufficed that is
hitting ctrl hitting P and release P
again that was all a day all it took in
order to
made the browser crash and of course
changes to the program code as we just
seen it I should add though that there's
a nasty node right now in Wikipedia so
in case yeah in case you have nothing
else to do feel free to add more
material and through that article
okay so that was learning from code
history a bit on how to simplify
problems and as well as a so as I
thought more MORE about this and as I
thought more and more about this
debugging problem and thought about
thought about okay these are ways to
debug things automatically well I guess
I made the the obvious next step which
everybody who's been debugging too much
or thinks about the question is are can
we so debugging is a good thing and if
we can automate this that's also a good
thing but how about not having these
bugs in the first place and so I went
into thinking about whether there would
be a way to prevent such power such
debugging problems and again I wanted to
I was thinking about a leveraging code
history for this very purpose the idea
is as follows user is Bugzilla a bug
database you have a problem with say
Firefox you enter this into the bug
database hundreds of thousands of
entries in here whenever somebody
reports the bug in Bugzilla in Bugzilla
this goes into the bug database and
after it's been to the bug database well
there's people like you folks look at
the bug database eventually fix it and
therefore committed change the version
database these two databases are
frequently separate bugs would be
handled say in a system like bugzilla
versions would be CVS or subversion or
some other version or some other version
management system although you can just
as well moves you to and have an
integrated system the idea though is
that we wanted to know where would bugs
occur
in our system where wood bugs be fixed
in our system so we came up with the
idea how come how we how about wait look
at the individual bugs figure out where
they have been fixed and then figure out
and then figure out well are there
places where the bugs tend to accumulate
this is one of the earliest and this is
one of the early studies we made this is
for the aspectj compiler or maybe some
of you have been programming in aspectj
let me tell you that the aspectj
compiler is a super tool for for doing
empirical studies like that because it's
some because it has plenty of
opportunities for improvement inside we
always use it for our studies that I've
seen coding there which made me which
just made me laugh and scream at the
same time it's in development and what
you see in this is what you see in this
picture is every rectangle stance or a
class and the color of the rectangle
tells you how many bugs have been fixed
in the particular class and the size of
the rectangle tells you how large the
classes in terms of lines of code so
what you see in here for instance this
is a place where 16 bugs have been fixed
over time the dark places in here mean
that there have been no fixed they have
admit that there have been no fixes in
the past and it goes up to I think
there's places in here which go and
which deal specifically with aspects
which go up to 25 bugs but you have
occurred in this particular place or I
should add at this point the fact that
no bugs have been fixed in these dark
places does not necessarily mean there
are no bugs so we're not so we're not
counting the number of bugs we there are
we only count the number of bugs that
have been fixed if we start if I wanted
to start the number of bugs that I have
said that that I could find in a spec J
I could probably if you spend me $1 for
every before everything I consider a bug
in a spec J could probably make it make
a nice living out of that no these are
these are just the fixes so but still
you see there that these fixes tented
that there's places where there's
many many more fixes than others and so
we wondered how come there how can that
be
what city to study on Firefox Firefox
well that's almost a Google product well
I don't know that would be chrome of
course but Firefox is in Google there's
a certain relationship in here and in
here and this Firefox study we only
looked at a specific class of bugs
namely security violation so we wanted
to know whether there would be specific
but it would be particular places within
Firefox where these vulnerabilities
accumulate and again the redder a class
a red with the red or a rectangle in
here the more bugs the more security
bugs have been fixed in this place what
you see here in the left lower corner
this is actually JavaScript you see j/s
source and you see JavaScript obviously
you ever skip obviously is a good
playground for security vulnerability is
it plenty of security vulnerabilities
have been fixed but there's also places
here like there's the Bayes data there
there's a classroom in the HTML layout
which has been fixed again and again and
other places over here there's the
document object model which is over here
these are places where security
vulnerabilities have been found and
fixed for instance because of cross-site
scripting and the idea of course is
wants you such a map it's something we
can generate more or less at the touch
of a button because all we know all we
need to do is we map the individual bugs
the individual changes the fixes and
then we know for every single fix where
it has occurred and so we can assign it
to a particular component in here and
then of course once you have such a map
you know where to focus upon you know
where to focus your tests upon and you
know where the bugs are and if you're
looking for security vulnerabilities
well these are the places you should
start with what we also looked at is
what can also look at since we were from
her society's wanted to know where do
these bugs actually come from is there a
correlation between the number of broad
any other feature we could find and this
was this was
this was a very fun game to start with
first thing we looked at is it the
developers sure developers make bugs
that's that's where bugs come from
let them desert for it does it make a
difference how experienced you are our
first study of that kind we did that on
Eclipse and on the eclipse bugs are
number two in number two on the list of
developers who made the most bugs was
was Erich gamma himself the head of a
clip number three was and rave Island
who's the head was another head
developer uh it turns out that the more
experienced the folks were the more bugs
they made before you now go out and bash
your manager uh let me tell you that to
actually talk to I talked to Eric Emma
about that we sent these results to him
and we talked about that way we have a
having a joint plane flight and we had
lots of fun and so I asked him how Eric
come on you're the you're one of the
smartest software architects around how
come your code is so bug-ridden are they
very easy he said because you know the
developer there's always problems that
developers do not want to do not want to
tackle
so here's developer a and here's some
piece of code which is too risky sorry
so he s collides that to his supervisor
who again escalates that to his
supervisor who then escalates this to me
and I have nothing to escalate it to so
I have to do it so he is the one who has
to do the most risky things because he's
the most experienced and well because if
there's all the risky things well he
also makes the most mistakes say if you
start as a well I guess that's at Google
is pretty much the same on the very
first day of your work you don't start
to work on the crown jewels you get some
assignment which is less risky than that
and this is the reason why we found that
the more experienced people were the
more bugs they made we also looked at
history if you found what
birds in one place will there be more
the answer is yes it's like a fishing
you go and go fishing in one place find
some fish come back to the next day yeah
there's more fish fish tend to
accumulate in specific places where they
like it seems for bugs except that for
fish we do have a decent theory on how
they reproduce for bugs no such theory
we looked at code metrics just to have
fun you know there's a big branch in
software engineering considering a big
branch that takes care of complexity
metrics and all the due complexity
metrics correlate with bug density we
looked at that and the answer to code
metrics is sometimes sometimes they
correlate sometimes they don't which is
from a scientific standpoint more or
less worthless oh and we didn't and we
found and we found that not only on a
number of open-source systems but also
on on Microsoft code for instance
including Internet Explorer and parts of
the Windows kernel yeah sometimes they
do but there's no there's no pattern in
there which would help you in any way
something else testing people in here
we'll also look at coverage is it so
that if you test some piece of software
a lot that there will be less bugs in
there actually it's the other way around
the more you test something the more
bugs will be in there there's a this may
be surprising it this may be surprising
at first but the holder that's it but
but there's a reason for that there's a
reason for that so you're a test manager
and you need to decide where do I test
okay and of course you test in the
places where you suppose the most bugs
you know here's a place which is
probably bug written so I'm going to
throw one more test and another test and
another test on it and you increase the
coverage that yes your intuition was
right your tests are still not enough
though so yes test coverage very well
correlates with bug density test
actually pretty smart people accept that
well we did accept that the tools were
squashing the bugs are not smart in and
we also looked at language features
because that was fun you know
well if you were born before if you were
born before 1970 you probably remember
this famous quote by Dijkstra or the
same paper by Dijkstra goto is
considered harmful
if you were born afterwards you never
saw go to in your life probably because
of that very code actually we actually
looked for go to more precisely the
equivalent of a go to that would be a
break with a label in Eclipse code and
our and we figured out well if there is
a go to there should be some correlation
with some correlation with bug density
no correlation at all if any if anything
code with go-to tends to have little
less bugs and regular code simply
because code would go to his tents to
her has a higher likelihood of being
generated code rather than written code
or while we were added we actually had a
look at all the tokens they were in Java
at this stage well there would be
correlation with anything some people
say that do-while loops for instance are
more bad form than others are turns out
that there were three tokens import at
extends that implement yep you know
these these are the tokens these are
these are the is a language construct
that determine which other which other
components your component interacts with
interestingly enough though it wouldn't
be the number of such tokens so it
wouldn't be the number the number of
imports but more precisely it would be
what you import what you import what you
extend and the interface you implement
this would determine how many bugs there
would be
yohko this was a this was a fun so so
for instance in eclipse if you go and if
you go an import something that starts
with org eclipse compiler internals
you're pretty much doomed because your
chances of chances of having a bug is
about seven times higher as if you
import say something like or
eclipsed gree something that's why
newcomers would rather work on GUI
rather than their compiler internals
compiler in turn is the stuff that every
gamer has to do see this is this is how
it all this is or how it all fits
together
the nice thing though is that what we
found is that you could actually use
these imports pretty well for predicting
whether your component was going to have
a bug or not in Firefox for instance or
if you included in C in C++
these two header files NS and as private
dummy event or agent NS readable utils
oh you're pretty much doomed because
these are all xx these are the 20 source
files which include these two header
files and all 20 of them had a security
violation and no it was not the same
security violation all over but it says
that actually it was a number of
different security violations so for
some reason for some reason interacting
interacting with the document object
model it's just it's just so it's just
super risky well again all these bugs
are also fixed if I talk about the
number of bugs always actually mean the
number of fixes I've seen so forth we
actually use this for making a
prediction so we trained a mission to
Commission loner and which and we
trained it on 2/3 of the code in order
to in order to predict for the remaining
third of the code a based based on their
imports of their own based on their
recluse files alone whether these would
be risky or not and this is this is our
this is our ranking as we predicted it
at the time and this is the prediction
and as dumb class infer would be the
most that would be the one that would
have an out prediction the highest
likelihood of having a security
violation and anyway then you can just
go down the list and the actual the if
you look at the actual fact in here this
is the real this is the real number of
security violations in here you can see
that we were actually pretty good
because one two three we actually found
six of the ten of the ten components
with the most
purity fixes in there so our prediction
was pretty accurate what was even more
impressive than what it does without
them half a year later when we when we
revised our when we revised our work
turned out that two more four houses in
the meantime at had have had a security
violation so we were pretty happy not
only did we have a simulated prediction
but you actually had a real prediction
so these files which at the time did not
were weren't known to have a security
violation were actually properly
predicted by us so this is and this is
also something your version history can
give you it can tell you where the bugs
are we're able to calibrate bad
prediction based on appropriate features
we can predict where the next bugs will
be and again this is an automatic
technique you press a button you get the
map you can get the prediction all of
this is part of a part of a movement
which we help to which we help to our
build that is mining software archive
archives that contain a full record of
the history that are maintained within
programming environments you don't have
to do any extra effort as developers in
order to check take care of them because
well version history gives you enough
benefits for that all the maintenance
and access is fully automatic em for
research purposes for us in particular
are there's plenty of such open source
archives available
and besides bugs and versions well
there's much more there's the code to
look at all the other and Al all the
static analysis techniques you can think
of are in there there's models to look
at their specifications formal and
informal specifications there's email
between developers which you can
leverage there's effort data in order to
predict where the effort will be there's
traces around which come from that which
can either which can either happen which
can either be collected in the lab or
from actual users that is profiles
there's chats between developers there's
test data available on how the
individual parts were tested and when
and what the results of this was and
there's also even people who collect the
navigation data that is they collect
where developers what the piece of code
is that developers actually look at in
order to make even you know
to make prediction which parts of the
code are related to each other and the
big challenge is for us as researchers
to bring all these individual sources
together and to make use of them this is
actually pretty neat situation because
in the past in order to get said.you
data about real developers and real
development our the process was much
more painful I just recently asked an
empirical well recently that's two years
ago I asked an empirical researcher what
his most important tool would be in
order to collect data about the
development process he says his most
important tool is the phone book Oh a
phone book so do we actually look for
say hierarchies of people or joined
telephone numbers in the phonebook no no
no I used the phone book and I call up
the developers individually so I make a
phone call and say dear dear hel
Lightner hello
you've been in charge of the testing
this YouTube component can you tell us
this was about three months ago do you
still remember what the results of this
of this test were did it fail then a lot
a will hopefully remember and say yes if
sometimes failed thank you very much and
you have another data point this is well
this is how lots of empirical software
engineering is done and still it is
still being done today and at the end of
this huge effort not only from your side
also from the developers side because
you actually interrupt them in your work
and and in trend and torture them with
appropriate surveys are at the end of
the day you get a glass of water a glass
of data you get this glass of data
drink it you're done what we get with
looking in these archives of changes of
version histories this is this is not
you have to go to the data this is the
data that comes to you and there's much
much more than it much much more it and
much much more than we can actually then
we as researchers could ever could ever
think of we could ever think of
processing what do we do is such
development it's fun so we can do
studies say three years afterwards we
show here
a curve that tells you how much effort
goes into individual stages of
development sure we can also go and make
nice visualizations of it but the thing
that I like most actually is to make
this data actionable to have
consequences that fall something like um
something like that tool for instance
are a tool that tells you during your
software development where you are where
you should go how much time it's going
to take you if you if you choose to take
another path it will if you choose to
take another path it will oh it will
happily it will happily take this into
account and constantly taking care of
you looking over your shoulder and
leveraging the experience of the entire
development so far as among others it is
it becomes manifest in the history of
your code so uh if you want to learn
more about these are here's a couple of
here's a couple of references or this is
the book why programs fail which Andres
mentioned initially this is a this is
our this is lots of material from the
systemic debugging site both automatic
debugging techniques but also how to
improve your manual debugging and coming
up with many many more techniques and
the one I just showed you are there's a
book on software evolution which
actually describes our research into
mining these databases open source
databases and Microsoft are if you're
interested there's one chapter of the
book that is freely available in the net
web and incidentally it's ours so you
can read the chapter on you can read the
chapter without buying the book or
there's also the book beautiful code
which you understand is pretty popular
around here there's a chapter by me on
on Delta debugging which describes how
the whole thing works including also
including code or have the appropriate
code snippets and what I'm talking about
beautiful code there's a new book coming
out beautiful testing
our which will be out which will be out
in the the first copies have been sent
to the author's a couple of weeks ago
and this beautiful testing also has a
chapter from me and my co-author where
we describe something that's not related
to leveraging virtual history at all but
where we describe our latest and
greatest in efforts alleges and greatest
achievements in terms of testing in
particular if any one of you have ever
heard about mutation testing we're the
first ones in the world to scale up your
change interesting to work with programs
of a hundred thousand lines of code and
more and this is also in this beautiful
testing ok with that
learning from code history shown you two
topics on how you can leverage code
history first is for simplifying
problems techniques like Delta debugging
who dive into the history of your code
in order to figure out what the problem
causes and preventing problems that is
trying to figure out in the code history
what went wrong where did it go wrong
and therefore focusing on specific parts
of your code here again Delta debugging
given you the fairly cost and finally
mapping these bugs to individual parts
of your program and here again reference
for further books that's for today thank
you very much for attention and I'm
happy to take questions
so please
look
yep
so the question so the question is we
discovered that using specific api's
interacting with specific modules
increased your chances of getting or
having a mistake and the question is
whether it would be a metric for that
are I've been thinking about that for a
long time when I have not but I have not
been able to come up with a with a good
metric on that why is it that a compiler
is harder to how to do program than
graphical user interfaces
well actually user interfaces are tricky
in their own right but they're but this
is more of an aesthetic or a more
ergonomic problem then if you deal with
a compiler in particular there's one
thing there's one thing that strikes me
if you do something wrong in a compiler
chances are that the bug is going to
stay hidden and it's going to stay
hidden for a long time until after
release whereas if you do something
wrong in a user interface it's going to
jump at you the very moment you start
the program and but coming up with a
metric that captures this that captures
this violation of hidden assumptions as
I might like to know into named it okay
it's very difficult because well you
cannot measure you can you cannot simply
measure how hidden an assumption is or
the assumption is hidden it's not there
you can qualify it and coming up with
coming up with a way of figuring out
that there are that there actually are a
number of hidden assumption hidden of a
number of hard hidden constraints that's
quite a research that's number one
number two actually is that and this is
this is this is this is worse the number
of bugs that escaped into production is
actually pretty low so these all of
these are pretty isolated incidents are
it's like if you try to sometimes it's
like if you try to establish a pattern
from plane crashes there's not that many
plane crashes anymore okay then even
though they were in the past so every
single plane crash today comes to be
because of a because of of a chain of
individual very unlikely events and each
of these events is unlikely has bent a
has been taken care of
simply bad that these these events all
happen to all happen to take place at
the same time but it's very hard to
establish something like a pattern that
this freaking the dead this is or that
is occurring frequently and we're
running into the same well run into the
same situation we suffer these days bugs
are hard to predict that's fun that's
good that that's a bad thing but at
least we know where they have been fixed
and we can therefore make a prediction
on where the next bugs might be
I have a question
can you hear me
okay please go ahead
how do we find how do you verify that
the failure cause found out by the
algorithm is actually the period cause
and not just a deviation how do we know
how do we know that the cause that we
find is actually a failure cause and not
just a random deviation that's what you
say okay yeah well this is this is a
tricky question because our in order to
know actually you want two things you
want a course because you know this is a
course and if I remove it the failure
will no longer happen and the second
thing is you also want an error this is
plain wrong and therefore needs to be
corrected what you want in debugging is
something that's both the cause and an
error a cost is something that can be
verified it causes something that can be
verified experimentally this is what
Delta debugging relies on but figuring
out that this particular place in your
code is something that is wrong is
something that's almost impossible to
decide automatically just for just just
because as you know from a daily world
it's very easy for multiple developers
to totally disagree on where and how a
bug should be fixed and they're there
they're simply that they're simply
simply are many many ways typically to
fix a program are to fix a program and
to evolve the program because fixing a
program in the end is writing a proof
and there are many many ways to write
programs so I would be happy if a system
could tell me this is not only a cost
but this is also plain wrong but in
order to do it but in order to tell that
this code is plain wrong the system
needs to have an idea of what the right
code should be and not even and I'm not
talking about the specification that the
output should be correct you know this
line of code is wrong because and this
is something that is this is something
that can only be done if you have
extremely fine-grained specifications
that tell you whether every single line
of code is right or wrong if you do have
a specification like that you can just
as well use it and and you can just as
well use the specification instead of
your code because then you also know the
correct
so this is what this is what this is
this is a limitation of these tools they
can tell you the cause and they in the
case of changes that gives you very good
they give you a very good hint this is
the reason why the thing failed but this
doesn't necessarily mean that reverting
that change is the best way to evolve
your program just gives you a good
understanding but then then again it's
up to you and your authority to evolve
the program again so the human stays in
the loop that's a good thing
did I did I ever study programs that are
unusually bug-free like ela like for
instance email transfer programs or like
things are of course of course the
programs were looked at had had their
very large differences in terms of bag
density there's programs it's very very
few bugs there's programs with lots of
bugs that have been distributed and yes
we see these differences but again it's
began from a from a number of say 20 20
projects that we investigated it would
be hard to tell here's here's a specific
feature in the development process
that's much better in terms of
preventing bugs yes yes yes colleagues
of mine colleagues of mine also have
looked into pairs of programs that one
open source one close source that solved
that we solved the same problem turns
out that turns out that not only do the
same through these programs make the
same mistakes it also turns out that the
bugs tend to tend to accumulate in the
same places and that's and that's for
Thoth for two totally different code
bases where two development teams one
opens or will close source has have
simply have looked at they simply have
implemented a specification and they
made the same mistakes which was
somewhat depressing if you believe in
closed source or if you believe in open
source whatever you take yes
if the question is whether we ever
consider the age of the bugs if
something has been fixed a long time ago
and if something has been fixed a long
time ago or stuff is all new yes this is
actually something we're looking into
they were looking into our weather a fix
is fix disrupts the stability of a
particular component the idea being if
you made him and this is something that
you can that you can find confirmed and
quite a number of studies if you have a
piece of software and there's lots of
change being made in the last couple of
weeks this is much much more likely to
have bugs and something which has been
stable for a long period and therefore
the age of the it's not so much the age
of the bugs that come up but rather the
age of the last change that counts in
this place and this again is of course
an indication of well an indication of
the testing process not which is the
testing process which is not yet
perfectly aligned with the number of
changes and the risk dangers yes
so the question is the question is can't
we solve this can't we solve this
problem it is and it's route calls and
the question is from all we learned
about old code bases what can we do
better about new code bases in the
future ah that's that's that's a tough
question I believe that I believe that
new systems will also new systems will
have bugs just as old system will have
bugs simply because eventually they are
made by humans and human specifications
are incomplete there's always a risk of
people introducing bugs but what I see
for instance during Operation automatic
debugging as well as in manual debugging
is that is that our is that there's
quite a number of established techniques
established techniques which help you
tremendously during debugging and these
techniques also make your programs make
your program much much more stable and
also help you as a human to understand
to understand better what you're
actually dealing with one such feature
which is totally under use
underestimated in my opinion is contract
assertions if you as a developer write
down this is what I assume about the
parameters of this method and this is
what I guaranteed to come out in the end
this serves three purposes at once a or
it helps you documenting what you
actually think about in therefore also
your colleagues second it gives you an
automated test fully automate tests
while your program is executing all the
time and you do have these exercise
icons for that and third thing if you do
debugging if you have a program that is
full of assertions full of contracts if
you do debugging you know well these are
the assumptions you have all these
online you have all these inline checks
which run all the time while your
program is executing debugging becomes
so much easier because the very moment
the very moment the data the data and
the state becomes faulty chances are
very high that some contract will catch
that and
bugging manual debugging as well as
automated debugging we'll catch the bug
much much fun much much much faster and
solve your lots and lots of problem and
this is this is probably the it's
probably the one single recommendation
in terms of debugging and and also that
would give two new programs yes
so the question is so questions to put
it very generally what's the best way of
using assertions or isn't there also a
risk of me making bad assertions rather
than good assertions at this point and
so and the question also is rather than
having assertions in my code should I
rather come up with or should I better
come up with something that outside of
my code say some form of some form of
external document I think that I think
that it's very important to have
assertions right within your code I also
think it's important but I also think
it's important for them for for having a
for learning and for teaching how to use
them as part of your daily a part of
your daily programming program work but
such assertion also can form a nice base
for formal verification for symbolic
techniques this of course requires that
you have a language for assertions
that's that is expressive enough to
express what you want to say and on the
other hand is still limited enough such
that you can actually reason about it
symbolically and there's also and in
this area there's also lots another
thing to of things to be done but we see
in particular in particularly in
companies like Microsoft Microsoft is
definitely a place where where if you
want to look for bugs yes it's a it's a
great place it's a great place to search
for are where the research department of
Microsoft does large and large efforts
in teaching programmers first to you
first to write specifications to write
contracts which are first checked at
runtime and then the whole thing has
been extended over time in order to form
the base for full fledged formal
verification and I think that having
such an incremental approach that caters
to developers just as well - and at the
same time increases quality is a good
way to go</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>