<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning From Examples Using Quantum Annealing (Google Workshop on Quantum Biology) | Coder Coacher - Coaching Coders</title><meta content="Learning From Examples Using Quantum Annealing (Google Workshop on Quantum Biology) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning From Examples Using Quantum Annealing (Google Workshop on Quantum Biology)</b></h2><h5 class="post__date">2010-10-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HKUZ6IuJyHw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in this talk I want to come suffer from
the other side essentially the user side
of quantum computing in particular
quantum annealing and we have studied
earlier this morning I sort of gave her
a basic motivation how can you do
certain or key tasks and artificial
intelligence better by using
acquaintance resources and we have
looked in particular at learning
supervised learning and how can you do
supervised learning better using quantum
annealing I should say a lot of this
work has been done by a vizier dan chef
at purdue and we collaborate closely
with the forks from a d-wave jordi who
talked earlier and Bill McCready was
also in this previous life machine
learning person we get some help from
Edward Phi and his student David Gossett
on quantum Monte Carlo simulations we
conducted and we get some on from
vishwanath on also in Purdue some help
was he's a specialist on using
optimization methods for machine
learning
maybe I skip the outline and immediately
jump to two small inertia people I
assume sort of half of you are a part of
you it's familiar to some degree with
machine learning but many of you won't
so we discusses these simple situation
and machine learnings that is binary
classification so you have two types of
patterns I'd say a good example would be
a face detection and I give you pictures
and some pictures contain a phase and
other pictures don't and then I ask you
a face or no face or Rosa asks the
algorithm is your face or not a face but
it can be many other things it can be a
vector of data from some medical
diagnosis and then the machine could say
should you do a secondary diagnosis or
no problem here or
could be some credit report and the
algorithm could say issue credit or not
so binary classification is sort of Z a
staple of machine learning and all it
really is is a binary classifier once
it's done it takes input patterns acts
and map them onto an output Y and ya
minus one plus one binary neighbors so
here are depictions are typically of
cause the input vectors like let's say
an image they are high dimensional live
in high dimensional spaces that's of
course large part of the problem we are
facing so you can of course not
visualizes so here's a simple
visualization we get let's say I just
have two features or two elements in the
vector so the blue guys and let's say
the faces and the red guys are the
non-faces
and then doing classification means you
want to find functions that divides the
partitions of space in two areas the
plus 1 and the minus 1 area and
hopefully you do it such that you don't
have any of the red examples being
classified as plus and vice-versa
now of course this can be more difficult
more rugged boundaries and again one
danger with all of these pictures are
that and it's sort of a basic lesson
that unfortunately never internalized
well enough is we are playing in very
high dimensional spaces and geometries
in a very high dimensional spaces are
just very different so a lot of
intuitions drawn from these little
diagrams tend to mislead so now how do
we find these separating functions that
gets the positive from the negative
separates a positive from the negative
examples so modern machine learning
literature likes to a state training of
a classifier as an optimization
so typically you start out with a
classifier H of X but it's not just H of
X it has a set of parameters like sinh
of it as little knobs and typically
called the weights and if you change the
weights then this separating function
changes and what gets labeled as plus or
minus 1 and the y side changes so you
can if you go back to here let's say one
set of weights would have maybe done
this rugged separating line and another
set of weights would have done this more
smooth line and then training means you
want to find a good set of weights such
that this gets nicely separated but
there's one more complication in machine
learning and in some ways that makes it
may be a difficult area to apply quantum
computing to why is in supervised
learning how this works typically you
take your data and you separate it into
two sets one is a training set the other
part is your holdout set and then on the
training set you will do what we will
discuss in a second you use it to form
your classifier but of course what
you're really interested in is not
making very few mistakes on the training
set that is of course good condition or
good if you are already bad with your
training data you cannot expect to be
good on your test data but unfortunately
the converse is not true
meanings that if you are perfect on your
training data you can still make a lot
of mistakes on your test data so you
need to set up your optimization problem
such that you generalize well because
what you're really after is new unseen
examples on those you want to have
little error rates small error rates and
one way to achieve this is to set up a
training objective that typically
consists of two parts
so again training means to find a good
set of knobs
characterized the classifier and the
optimization problems that you set up
has two components one is the so called
loss function and the second term is the
regularization so the loss thing is
fairly easily understood the loss is
just a measure on how good do I do on my
training data now to appreciate a little
bit more on what we do later and need to
discuss with you a little bit that there
are different types of loss functions
and to appreciate those different loss
functions for those who are not machine
learning people I need to explain you
one item and that's the so called margin
the margin is essentially the smallest
distance to the separating function
between the two classes and you can
imagine that's larger the margin the
more robust you are the better you will
probably generalize imagine if I would
have put the separating line just very
close here then a little bit of noise on
the read data side would have put it on
the other side of my line and I would
have lessen misclassified it so what I
we try to do is maximize the margin
that's typically considered good for
classifiers because you better
generalization and now if you look the
most naive way to measure on a training
set how good is my classifier doing as
you just count so whenever I do a
mistake that is I have a negative margin
I'm on the wrong side you know then I
say okay plus one you know you get a
count one error another one and so on if
you classified it correctly trying to
say that's that's fine so that's called
the zero-one loss simply counting the
number of errors you make on your
training set you know but then there are
other losses first of there are
different ways to motivate them but
maybe for starters if you set up your
loss function as zero one loss
can be shown that the resulting
optimization problem is formly and be
hard so machine learning series series
of course didn't like this and they used
instead what optimization people call
relaxations convex relaxation so they
don't work with the non convex zero one
loss but instead let's say is a
approximated by some upper bound like an
exponential or quadratic function and
that on one hand gets you off it's not
np-hard anymore and it's not necessarily
all that bad you get other advantages
also because Z zero one loss is not
margin maximizing while those convex
relaxations are you see it's a larger
your margin is Z lower your objective
value and if you try to minimize the
objective values and and gets rewarded
so essentially is the further away your
samples get from the separating lines
the more you like this so that's a
reasonable measure to say how good is
your classifier coming along so there's
an another term as I said so the first
term is when you try to find the right
set of knobs is try to minimize the loss
and second is regularization that's a
little bit harder to understand but it
makes essentially precise a notion of
that the simplest explanation tends to
be the best one and it's pretty easiest
to understand this in the realm of curve
fitting so here's this green curve is
say where I'm the process that generated
some data for me and it's a little bit
noisy and I want to fit those dots that
come there half there and I want to fit
it with a polynomial and I have it
different polynomials of order 0 of
order 1 and so on and you see if my
model or with which I try to fit this
it's too simple let's say if it's
Xero's and i tried to fit this data with
a constant function said of course
cannot work too well and then here if
it's order one linear function i will
still do poorly here's our three seems
to be good but you don't get better and
better as you make your model more
complex here well if your order nine
then you do that what i mentioned
earlier do perfectly on your training
data but this will generalize very
poorly you can imagine like if your new
example and would be completely off you
know so it's a lot of adages and science
that at seven einstein said you should
make things as simple as possible but
not simpler you can see this yes this is
too simple no and here it doesn't pay to
make your model overly complex Occam's
razor the simplest explanation tends to
be the best one and machine learning
series are actually serums that show
that if you pick a classifier with lower
complexity then it will see bounce on
generalization error will be lower okay
so um and yeah didn't give you my
example one way for example to choose a
regularization term is you put some norm
on W and say once it's norm small for
example you can say I want the zero norm
to be small that simply means you switch
certain parts of your classifier off so
you make it as compact as possible but
actually this choice again would have
rendered the problem formally np-hard so
what we see is that four important
choices of the loss function and the
regularization training problems are and
I always you know that I've discussed
enough with complexity and people to
know that you better always put formally
np-hard in front of it because we don't
know let's say a true face a real word
recognition problem like face
recognition or car recognition is it
truly generally np-hard I don't know but
that doesn't really help us all that
much because to the algorithms it looks
like an np-hard problem so now this is a
good motivation to try to look at
quantum algorithms that again are not
known to solve NP hard problems exactly
but it's very reasonable to expect that
they give us better solutions and
classically available and so quick
excursion to optimization so
optimization you have an objective
function and you want to find is the
minimum of this function that's an
optimization problem and I just was a
picture from this morning here I have
this video and I apologize several
people have seen this already many times
and I keep showing it again to give
people who are not familiar with it's a
basic idea of a quantum resource that
can help you better with finding the
global minimum here classically you
could only have this bar could have only
rolled down and would have been stuck in
a local minimum if you have a second
resource tunneling then of course if
this barrier would have been too fat the
tunneling amplitude would have been very
small and probably the advantage would
have been tiny but it's actually the
beauty of the diabatic quantum
algorithms that it forms this landscape
slowly and hence at any point in time
you have a good chance of having a
reasonable tunneling amplitude and
overall of course physics determines
what optimization problems you can solve
and bringing in this additional resource
of quantum tunneling expands the reach
quality of your optimization algorithms
and so this was a bit C Scientific
American view in Georgia this morning
didn't have sometimes actually a figure
from him to explain how zzd wave chips
really work and they actually do
exactly this process we just looked at
but here's a little bit nicer quantum
explanation and quantum mechanics got
its name from certain entities in nature
such as energy being quantized so what
you do here is actually have explains
this also here see the principle here
and or the key idea in adiabatic quantum
computing is that you start out with an
optimization problem has a beginning
Hamiltonians often referred to which has
only one easy to find global minimum so
any algorithm it gets you there and then
you slowly deform it and until the
Hamiltonian looks or has a shape that
encodes a problem you're really
interested in and now if you do this the
right way the following happens so in
here is the energy spectrum quantized
for the beginning Hamiltonian and I
start out in the ground state now I
start to deform it and by the time one
I'm sort of in the Hamiltonian that has
a shape I'm really interested in if I do
this carefully enough such that you see
there's a difference in energy between
the ground state and the first excited
state and actually if I look in the zoom
in a little closer you can see this
entity here which is called a minimum
gap if I do this evolution meaning it's
a transformation from beginning
Hamiltonian to end Hamiltonian careful
enough said I don't inject enough energy
into the system that it can jump into
the next excited state then of course at
all points you would have you would stay
in the ground state and then at the end
you would still be at the minimum of the
function you're interested in so that's
the idea of a diabetic quantum computing
and of course as you can imagine the
critical entity here is the minimum gap
if the minimum gap is too small you have
to
smaller it is more careful you have to
do it meanings it was slower you have to
do it and then of course there's a
question that is currently under hot
debate and many people looking at it
for certain problems how does a gap
scale as let's say my learning problem
gets harder I look at more examples or
larger classifiers as my problems get
larger how's the gap shrinking if it's
shrinking exponentially fast then I'm
screwed then the abetik quantum
computing will probably not give me good
solutions for this if it only shrinks
polynomially as that bodes well I think
I skip this slide you
DBF has built now systems as that
execute this and of course we haven't
discussed yet what Hamiltonian what
energy landscape are we realizing I
don't know whether giorious sauce is my
rendition of what happens inside a
d-wave chip essentially what I realize
this sort of the simplest many-body
physical system knowns as the Ising
model so the qubits are organized on a
grid and they are nearest neighbor
connected actually that's not quite true
but their nearest neighbor plus so
they're also community I saw the
connections earlier so there are
connections beyond just nearest
neighbors
but so what you do now you start with a
strong what's called the transversal
magnetic field
so that's your beginning Hamiltonian all
these guys are randomized and now you
face in those connections between the
qubits that really is the blue and the
red arrows they really encode your
problem and you fade out the transversal
magnetic field and then at the end of
this evolution some spins will be up
some spins will be down and this you can
read out this is the solution to your
problem again you programming this chip
means you give it the blue and red
arrows and say how strongly negative or
positively they're supposed to be and I
also linear terms called Z bias terms
that bias every qubit saying a Rosa
won't just been to be up or down so what
this creates is a new computational
resource again a physicist what causes
says they realized the Ising model and
there's a quantum process for finding
the minimum the ground state of the
ionizing function or as a mathematician
would prefer to call this a quadratic
optimization problem and using this new
computational resource in a problem like
machine learning essentially means you
have to take your problem and map it
such that it fits on to the format of a
quadratic optimization problem and the
good news here is that this looks a
little bit limiting for example what is
if I want more than quadratic and need
to cert order terms force order terms
sun-young you can by introducing
auxiliary variables you can map it back
on to quadratic also you may say oh this
nearest neighbor business I didn't like
and need to connect the qubits in a
wider way yeah you can also by
introducing auxiliary variables can
bring this back on the existing
architecture so the good news is in
principle pretty much any problem you
can map onto the izing format and
thought is the fine print is that you
need that you need Observatory qubits
and often you need polynomial many so
sometimes let's say if you have a third
order interaction and you have a hundred
variables then you would need 100 square
10000 auxiliary qubits to get rid of the
third order interaction and that of
course it's a given moment where we talk
about hundreds of qubits being available
in the chip that can of course be a deal
breaker so that is also why and say
software guys like us are needed you
have to give it some salt
how can you map your problem in
careful way or look for problems that
map well on to this architecture without
the need of too many auxiliary qubits so
now I go back to training combined Ori
classifier and I know some of you have
heard this talk before here comes
something new now I'm pretty happy about
this so I'm sort of taught this thing a
new trick so we want to try and classify
off this nature so we take the sine of a
sum over a WI I the H eyes are often
referred to as weak classifiers or
features again the why is easy plus one
minus one output the W's in our case we
choose them just to be binary 0 or 1
weights this is a set we want to
optimize the overall classifiers often
referred to as a strong classifier and
then we set up the optimization we have
a set of training examples and using
those we will set up our training
objective and I discussed earlier little
bits of two terms it remembers as the
loss that measures how well am i doing
on training and regularization that
essentially says try to keep your
explanation as simple as possible so may
ask which loss of which regularization
is best
unfortunately there's no good answer to
this it depends on the structure of your
noise in the data and there's something
called the no free lunch theorem in
machine learning that shows that there
is not a single training objectives that
is better on all data sets better than
some other machine algorithm so we
looked at something very specific so
this new work where we looked at how we
can deal with outliers you see have
again those two clouds but we put a few
outliers in there and that's a situation
that happens all the time let's say to
Train something like a face detector we
are talking about the order of between a
hundred thousand to two million
images and of course you can imagine
that wrong ones creep in there or just
very unlikely faces and faces present
even the best example we looked at data
sets for character and classification
optical character classification and
there was actually plenty of wrong
labels in there's just a fact of life
and that's actually an intelligent
system you know I keep teaching you but
or sorry you know it's an elementary
school and how you teach the kids but
maybe once a while you say something
wrong and a smart kid will eventually
figure out hey that's not right so we
want our classifier to be able to do
this to to to find what the outliers are
and discard them so how do we do this
here just want to motivate that was a
typical losses you can do this let's say
if we would have used as a square loss
maybe here put in what's the optimal
possible classifier here was the best
margin so it's called the Bayes
classifier the Bayes classifier sort of
the gold standard that's as good as you
can do so if we would have used the
square loss because if you remember do
that yeah the square loss really doesn't
like big negative margins and the
outliers of course create big negative
margins so the optimization would put a
lot of emphasis of making these big
negative margins to two explains the bad
things not quite as bad and damn it it
doesn't really fit the picture how can I
deal with this and I mean familiar with
this so square loss wouldn't do well
here but how about zero one loss
zero one loss essentially just pays
attention let's get everything right so
it would probably create I mean this
metaphorical pictures would create maybe
a classifier like this here get roughly
the separation right but over here
because it really doesn't like to make
anything wrong put a little box or a
fence in the outliers and put
as a different class and of course in
there when I then see new real test data
then I might fall into this box and make
mistakes here so you can see that
there's not really an existing or one of
the traditional used lost functions that
would do any good here so um
what we did we created a family of loss
functions that can be tuned to any given
data set such that it operates
reasonably well how do we do this so we
start out with square loss and I should
allow labels to be flipped so you can
essentially look at an example and say
you know what I don't think it's a
positive one I think it's a negative one
Willie just changed everything it comes
at a cost you have to think when do you
want to say was this example is from the
other class and we also introduce the
second parameter maybe which I should
given the time not bother to explain so
essentially what is happening is that we
have now a two parameter family of loss
functions we call it the new family of
loss functions and in a generic example
you see here and here you can
essentially see really low if positive
margin to classify it correct
and the cost you pay gets higher and
higher as Margie becomes more negative
meaning you misclassified it at some
point the pain just become so large and
just doesn't fit into my picture such a
system would say you know what screw it
I flip this point where the lipid comes
at the cost but it wouldn't keep growing
exponentially so if you look at the
complete family again there's a two
parameter family here we looked at the
generic mule loss but you can see I can
find a pair of mu-1 mu-2 where it
becomes a square loss or is a truncated
square loss where we can nicely
approximate the zero-one loss so those
are all contained in the family and now
we did a neat experiment with this we
did the following thing we start out
with it's a toy experiment and it goes
like this you start out with a
classifier your sine of some over WI H I
and we die a random set of W so some are
one some are zero and then we give the
system input values X and it generates
output wise for us and that generates a
set of training examples that I can use
but and what we want to do is we want to
recover the original can we learn what
the original classifier ones that
produce the data for us and to make it a
little bit meaner we flip some of the
labels now you can easily see you're
maybe have just trust me on this that if
you would have used zero one loss or
square loss or any of the other known
losses you would not find this
classifier back that's maybe just
discuss it for zero one loss
zero one loss could have retrieved it in
the absence of labor noise and it
wouldn't want to do anything wrong so on
the training set you would have to do
exactly the same thing as is your
original
classifier but as soon as you add some
noise then it's it's lost it tries to
get this noise right so we asked the
question can we retrieve it and then we
used our new family of loss functions
and we play it sort of with different
sets of MU and there's a technique
called cross-validation it's a technique
how you can find those meta parameters
and then for a small problem because
this is very India had Indian formally
there's no good solver for it so we had
to do it by an exact solver so we need
to keep it and small 16 so we had a
classifier of 16 we classifiers strong
classifier of 16 weak ones and 200
examples and we added 10% of label noise
mooning randomly flipping labels and
then we did 60,000 runs and in 99.9
hunting cases of this toy problem
admittedly we were able to retrieve the
original classifier now I'm not sure you
know to what degree sort of you're
amazed by this this is actually pretty
neat is there's no sort of system that's
typically news that would have been able
to do this essentially you your hand
here your system a bunch of data put
noise on top of it and you ask it please
make sense of it try to find the best
possible explanation for this data and
the system was able to do this so yeah
that's a new piece we did singing I'm
out of time I wanted to show you some
older maybe if you forgive me some of
the older works that people hadn't seen
so just using the square loss we had
done in winter and experiment trying to
classify cars so we try to build a car
detector and we used inches it's the
d-wave hardware at the time and had 52
variables to train our or use our
training objective and solve the
training objective on the d-wave
hardware and used to 20,000 images for
street view scenes and at the time you
know the chip was supposed to look like
this 128 cubits but this was a very
early one
so not all chips were functional and
also not all the connections existed so
on this somewhat beaten up graph we
trained our classifier and to our
delight we found if he compares his
hardware solver to heuristic solvers
that would run Tabu search which would
run a tear on a conventional machine we
were able to eke out not a tremendous
but nevertheless small advantage and we
also did I will skip see Monte Carlo
piece that maybe just your concluding
with what what you saw were so far what
we were able to do is that it seems to
us that the quantum optimization is a
useful new resource for intelligent
systems and between the older work and
the newer one think we were able to show
that training maps well to quantum
optimization we found that we get lower
generalization error we get more compact
classifiers that means that would
execute faster we could train it faster
by using less training cycles and here's
a new result new achievement was that we
can better cope without liars so this is
just a motivation why intelligent
systems really could benefit from
quantum optimization is it really used
and a slide on this but I know it's late
so thank you
you rather any questions for hobbit you
could use the microphone please
so then where is the Ising model and all
of this and is it the quantum or
classical Isaac is a 2d or 3d Ising
model if it's there in your algorithm it
is yes the Ising model comes I mean
there's a question I guess to the
hardware so the it's it's a quantum
Ising model and it's not a planar graph
actually I think there's a result that
shows that the planar graph could be
efficiently be solved by a classical
algorithm so it's not a planar graph if
that's what you mean by a 3d I think and
I thought on this which I don't know the
answer to but somebody's a friend of
mine suggested that might be a a similar
concept at work which is and use the use
of NMR of proteins because you have very
similar it you can describe it with nm
with the Ising model the spins of the
protons and you have the transverse
field and you have the frequency
different frequencies sweeping the range
so so the question is can you think of a
protein as a as your quantum computer
yeah this is what we love about the
Ising model is as I said it's the
simplest many-body modern known to
physicists and many physical systems we
see could be in first order
approximation be modeled by an Ising
model and it Eric pointed that ones out
to me in a quantum Ising model is
powerful enough to pretty much any piece
of universe as far as we know it right
now may be bearing quantum gravity
effects can be mapped onto a quantum
Ising model and be properly described
which is not true for let's say Google
server center which couldn't even
describe a single protein as you know
Luca
not so much a question as a statement I
wanted probably on behalf of everybody
or to thank you for organizing this
thanks um Jaffe Stewart and uh near Bonn
and Julie and this is a it's a daring
thing to do and it worked so thank you
very much okay thank you okay shall we I
think after this is not good to have any
more questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>