<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Systematic Testing of Software with Structurally Complex Inputs | Coder Coacher - Coaching Coders</title><meta content="Systematic Testing of Software with Structurally Complex Inputs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Systematic Testing of Software with Structurally Complex Inputs</b></h2><h5 class="post__date">2008-01-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wHJKiGURgKc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so I want to introduce dark of
Marin off from University of Illinois
urbana-champaign he's going to talk
about some automated testing tools to do
automated test case generation okay
thanks thing thank you John yeah thank
for the introduction it's nice to be
back at Google I was scared about five
years ago it was somewhat smaller at the
time came and visited since then but I'm
back here and i'll be talking about
testing i usually start with a few
slides saying why testing is important I
guess that's unnecessary to say here and
I let everybody knows the testing is
important you have testing on toilet so
you know what can be more important in
the space occupied in the toilet right
so actually what I'll start from is a
motivating example this from recent work
done in cooperation with Google and what
we actually wanted to do was to test the
program developed at Google the joint
work with pneumonia petrich is in the
New York office so what this particular
program does is that as input it takes
some a cyclic directed graphs what these
graphs actually do is they represent web
so they start from a web graph so the
nodes are actually sites and then the
edges in the graph are links you had
some pre-processing step and reduces the
strongly connected components so
eventually what one ends up is having
some directed acyclic graphs and
basically what I'll be talking about in
this talk is how how to generate such
such inputs and this just an example is
something that we call structure it
complex inputs what I mean by this is
that the input itself is structural so
it consists of some nodes that are
connected in some way and by complex I
mean that these nodes need set a certain
complex properties in this case how how
these nodes are connected just here for
the sake of completeness I mention what
the output of this application is but I
don't exactly even know because I never
saw the application we would just send
here the tools for for testing and get
back the results I never even ran any of
that I just know it compute some kind of
sets of nodes on certain pets it does
some kind of traversal so key point then
is that the inputs for this application
are some kind of complex data structures
then the question is how to generate
those
here's some other examples of such
luxury complex data for example library
code often has a lot of such data
structures say something like red black
trees or other complex structures if you
look at the programming language
something like a Java code can be also
viewed as a structurally complex data
now if you just look at the the text
itself it does not look like it has any
structure but if you build something
like an inheritance graph or rebuild an
abstract syntax tree from this code then
we are going to end up with some
structure complex input the same goes
for something like an XML document right
so if you have an XML document if you
pass that build some kind of a tree
again we end up with a some number of
nodes that are connected and need to
satisfy certain properties in order to
be a valid document okay so there's a I
would argue a lot of code that
manipulates are structurally complex
input so here are some of the examples
of such code and what you would like to
do is to test such code for example
operations on absolute data types if you
look at something like library
operations say a set implemented as a
red black tree then effectively each
operation that they removes or insert an
element into the set actually takes is
an input data structure that needs to
satisfy appropriate invariants for this
data structure if you look at some code
that process a Java programs for example
an integrated development environment
like eclipse or netbeans that the input
effectively there is interesting java
programs they may be legal or illegal
maybe we want to satisfy the syntactic
and semantic requirements may be
intentionally not in order to test
certain parts of the of the ID we can
look at XML processing programs again
they take as input XML documents and so
on basically in all these examples we
have that the inputs are structurally
complex here's them the general setup of
of this testing how one may want to do
tests out code and in certain
assumptions behind our work so we will
first start with some test input
generation so the goal there is to
produce a number of input remember each
of these input is the structurally
complex thing will give one by one to
the code under test
this will produce a certain output maybe
we are just giving an XML document and
then this code proceed and outputs
another XML document maybe we are just
giving some red black tree and we are
inserting some element or removing and
then as an output V effectively obtain
another 3 and so on and then we take
each of these input and output pair and
in some way we check whether these
passes or fails whether this the code
was correct for this input or not so I'm
not going to talk about the testing
Oracle at all here I'll just focus on
test input generation and some
assumption that i'm making this work is
that the first basic one is the tester
has some good intuition about these
inputs I guess probably the zeroth
assumption is the test really cares
about doing this testing and cares to to
produce good inputs it's usually the
case and I also use tester II in the
broad sense to mean the person who is
doing testing I know that here we have a
lot of developer testing going on to
actually people who have the title of
developer who are actually doing the
testing but basically the person who
wants to test the code the person who is
coming up with these inputs so the idea
is that there is good intuition there
and the person knows what are the
properties of these desired inputs if
it's xml documents you know what kind of
documents you may want to generate you
have some kind of intuition what may
expose a bug you know what kind of way
where where the bugs may be in the code
which parts of the code may may be more
buggy than the others however the
problem is that even though you know the
properties this desire import there is a
large number of them if you just look at
our example with tags this the google
application that was processing the eggs
there are just many corner cases for
that you know you will need to test your
code with an empty graph maybe something
looks like a list something looks like a
three then you won't have some kind of
sharing where there are multiple
incoming nodes you need the grass in
multiple routes disconnecting components
and so on so even though it would be
fairly easy relatively easy to stay the
properties of this and just say the
inputs to my code are directed acyclic
graphs it's quite hard to go and
manually actually numerate one by one of
these graphs so if you look then at this
the comparison of manual and automated
testing the men are just tedious and
error-prone
you know you need to start from some
cases and just generate you know an
empty graph for some small graphs and
need to go to larger graphs and so on
until you run out of patience or just
run out of the space on the slide and
then you just say that you're exhausted
with your testing and you stop there
also if you go and change something in
the code if you need to change these
inputs you will need to go and manually
you not change change all these inputs
so I'm not saying that you shouldn't do
any of this clearly you should do that I
mean people do right manual test you
should write some of them but what I
would like to do is to help to help
testers when they actually want to
generate a large number of tests and
hears them the solution that that we
propose for for doing that it is that
instead of manually writing these
individual tests tester manually write
something that I call test abstractions
so the idea is that each of these tests
abstractions actually describes a set of
inputs I'll show more examples of these
tests abstractions as we go so you just
described here that you know I want to
generate graphs that are directed and
acyclic graphs and then the test does
this manually and then the tool will
automatically generate the specific
concrete inputs so the good thing here
is not only the tool can generate a
large number of them you know thousands
millions or billions of them but also
that if there is some change that's
necessary maybe you want your inputs to
be represented different way maybe you
want to test a different part of the
application where the input should be
slightly different you only need to
change this test abstraction the tool
will automatically regenerate inputs you
don't need to deal with individual
inputs here's some sort of a summary of
some results that we've done for these
tests distractions we've actually
developed two kinds of types test
abstractions one is based on decorative
so the idea of decorative is that the
tester simply describes what the inputs
look like so in our case the example
with eggs you would simply say that you
want graphs they do not have cycles in
them the other the other kind of the
other approach for test abstraction is
imperative as instead of saying what the
inputs look like the tester would
describe how to generate these inputs
and I will touch
it's on both of them if you go now back
to this decorating example so there the
tester should write what the inputs look
like they still the passion of what
language to use to actually describe
these properties right if I just tell
the Machine you know I want the graphs
that are directed and a cyclic it's not
going to understand that you work a lot
with the natural language processing
zone that machines are not there to
understand that so we will need to
express this in some other in some other
language it actually there I worked on
two approaches one is to use the
actually decorative language for
properties of desire the inputs and this
was relatively good so we get you know
publications out of there is it
something that counts in academia
unfortunate we don't get users it turned
out when we use this this language when
we use this approach that we couldn't
get many people to use this the issue
was that view Sam you know languages
that are just developed in academia and
mostly used in academia something called
alloy and there is some learning curve
there maybe I ought to be steep learning
curve you just couldn't get people to
use that so then we switch to to doing
something else and to using the actual
programming languages such as Java or C
sharp to describe these properties of
desired test inputs this turned out to
work much better this something that has
been used in industry or Microsoft even
now at Google and this isn't that I'll
be talking more about the cific are we
talking about in a project we call kirat
there it stands for a saw that where
this comes from and also a touch briefly
on this SD gin which is a more recent
work so before i go to describe the
details of this what these tools do i
would just like to say to mention one
common use case for this tool and
sometimes we call bounded exhaustive
generation so the idea there is that you
want to generate all of these test
inputs up to a given bound it's not
necessary don't necessarily need to do
that you can always sample in one way or
the other number of inputs you may do
that you know randomly or in some more
informed way in a sample but nowadays
that the machines are quite powerful
there is a no reason to not try all of
them at least for small bounds so the
idea then is that the you
there will not only give this test
abstraction not only how the inputs look
like but we also provide the bound say
in our case with the graphs the user
will say how many nodes there are maybe
what are the possible values for these
nodes and so on and the reason why you
may want to try this testing with all
inputs up to a given bound is that
clearly it can find the bugs that can be
found within that part so this can cover
many corner cases without explicitly
thinking about them and the set up there
looks like this that the user has to
probably test abstraction in the bound
and the tool will then generate all
structures or almost all structures
within that bow so here's the outline
the rest of my talk after this overview
I present one of these tools called
kirat present an example of what it does
then give some brief demo of how to use
it hopefully the Nemo will work and then
I'll just briefly discuss how it works i
won't go much into those details spend
more time on the results of where where
it was used and you know how it was used
and what kind of bugs it found there are
briefly mentioned this st jen which is
more recent work and conclude if you
have any questions please feel free to
stop me at any time and ask
okay let's see then the example so as I
said there was this application to want
it to to pass that was developed at
Google and thus import effectively takes
directed acyclic graphs now in order to
use any of these tools that we developed
the user has to first describe how these
inputs look like so karato was
implemented for java so one way to
describe that would be for example to
write these classes here the user can
write some class deck which represents
the graphs they have some list of all
the nodes in there and certain size and
and then the these graphs consist of a
number of nodes and each node he has a
number of outgoing edges called here
children so this is one part that you
clearly have to do we have to describe
how the inputs look like also the user
has to express these the properties of
objects of these classes the fact that
we called something dag does not mean
that we cannot create a cycle there you
can just put two nodes at Point 2 to
each other so the user has to describe
to the tool these properties that there
should be no directed cycle among the
nodes and that all outgoing edges from a
given edge should be different and said
we worked on a number of languages and
approaches for how to do that the one
that I'll describe is sometimes we call
kirat and the idea here is to describe
these properties as imperative
predicates an imported predicate is
basically a piece of code say written in
Java that identified these desired
structures so the user will have to
write a piece of code show that on the
next slide and this will take an input
that's either a dagger or not so this
code takes as input an object of a class
dag but then it needs to check whether
these objects that are reachable from
the node actually satisfy these
properties or not then it will simply
return throw falls to indicate whether
this is an input that's desirable or not
as already said we've tried some other
approaches that are good for publishing
papers and doing research and
unfortunately take some time for
something like that to take off in the
industry and using actual actual
language is for
for expressing this property has a
number of advantages first language is
familiar so people know how to express
these properties then their existing
development tools so there you know in a
development environments that people can
use to actually write these properties
to debug to see what's going on and also
these predicates that describe the
structures can be already present in the
cold here's an example of how this can
look for the deck I'm not going to go
into all the details but I wanted to
show the entire example first to show
that this is not too hard to use another
reason another way to argue that it's
not too hard is to say that usually have
undergrads who go and write things like
this so we just write us the undergrad
students effect it to write the piece of
Java code that will check whether
certain graphs satisfy properties or not
in this case remember we are writing the
eggs so what we want is that the nodes
reachable from the root actually do not
have any of the cycles do not have a
directed cycles and also that the edges
that go from one node are different so
what this particular code does is just
some standard textbook traversal of the
graph I believe it does bread first or
deb first III don't even know the exact
details as i said the usually under it
we just ask the under is to go and write
things like this the point is that this
is not too hard to do so effective in
this you're 20 lines of the code one can
go and code this property instead of
generating individually one by one of
the graphs what you need to do is just
write this and then the tool will
generate a large number of the graphs
for you okay but before the tool does
that it also requires another piece of
input which is synthetic all finite
ization and the idea here is that the
user needs to bound the size of the
structures so if you want to generate
these these DAGs these are need to say
how big these decks should be for
example we may want to say that we want
to generate the eggs that are of the
size exactly three so won't have exactly
three nodes there so that means is that
the user has to specify that there is a
why
they're go object in in one graph in one
given graph will be generating large
number of them then there are the three
node objects and then also to specify
the values for these fields for example
for the size we may want to have the
value exactly three in general we want
to put religion or 0 to 3 or 0 to n we
don't want only of a specific size but
maybe all of them up to some given size
and then he needs to specify the values
for this outgoing edges so we had some
summary called children in the dag node
so there it's necessary to specify what
are the possible length for that
effective what's the number of outgoing
edges okay so now if the user provides
that if the user writes this imperative
predicate basically this piece of code
the checks the the properties and also
rise this magnetization that describes
the bounds on the inputs then this tool
which we call kirat can generate the
almost all structures within these given
bounds and then you can use use them all
effectively to test your program the way
that this internally works is that kirat
search is this input space to find
appropriate structures and I'll mention
just briefly how it actually works
inside in a few slides but actually what
I would like to focus on instead of just
describing how it works inside like to
give a bit of a damn of how one can use
that and you know what exactly it does
so the tool itself is available from
sourceforge so it's in open source most
developed by two undergrads x and urmila
treats in sashimi sea voyage it's very
hard to get grad students to spend a lot
of time to depend something to develop
something goes in open source especially
they're close to graduating but
undergrads can can get these things done
so the two itself is important in java
and it works on java predicates so i
mention later in the talk the same idea
has been used at microsoft oh of course
they are they work with c sharp and the
other languages and this particular tool
is just a command-line tool so basically
takes a number of parameters
you need to say for which class you want
to generate these structures that are to
be used as test inputs what is the
predicate that describes the properties
of the structures and then provides
these bounds and then what the tool can
does is either visualize these
structures or you know save them in a
file for later use around the code and
the test and so on here's an example of
how that looks like so if you were to
type something like that on for running
the tool you say that you want to
generate these dags of the size exactly
3 and you want to visualize them the
tool will effectively produce something
like this as the output and here's then
the demo I will actually demo the tool i
will run this in in Eclipse so what I'll
doing this demo I'll show some example
predicated magnetization and then i'll
show how how the tool visualizes this so
we didn't build any of this
visualization we just use an existing
module developed for the other language
and this visualization often can help in
correcting the predicate if you just get
it wrong and then also point to issues
this generation of equivalent structures
and the total number of generated
structures namely one using this
approach one can end up with a large
number of structures so then the
question is what to do about that ok let
me proceed to demo for I do that let me
ask any questions ok yes actually help
cut so the searching algorithm produces
lots of structures and then tests
whether they're ok or not so what if the
search space is much larger than the
actual space v1 ok so so that's a very
good question a question actually is I
guess it at some level how does this
work internally right because if you
look at all the graphs here's the answer
was on the next slide but i'll come back
to the demo after I answer this so so
the question was you know there can be a
large number of grafts and we want only
those that are Dex how does the the the
the tool actually work and this is
actually the key challenge in building
these two how to efficiently generate
these inputs
right so if our goal is to identify only
those graphs that are actually directed
in a cyclic well one thing we could do
is we'll simply go and generate all
possible graphs within this size and
then for each one of them check whether
it's a dag or not and therefore only
output those and say these should be
used as test inputs but the problem is
exactly as you said isn't it we call a
sparse input space that the number of
those that are desired can be much
smaller than the total number of inputs
and then this brute force search where
you would try to enumerate all of them
is just not going to work so what this
means is that one has to be much more
clever than that so I'm not going to
talk much about that i can just mention
here one side summary of that having a
whole talk there just dedicated to that
basically what what it does is i mean it
is is is relatively simple so what it
does is it still starts the enumeration
as if it's going to generate them all
and eventually it is going to
systematically explore everything but
what it does is the pruning that's the
key thing is if it tries this predicate
on one structure and find that it does
not satisfy these properties for example
if it tries one graph and find that it
has a certain cycle in that graph but it
does then it can prune a large part of
the search space effectively saying
anything that sort of has this as a sub
graph will also have this cycle and will
not satisfy these properties so that's
the key idea that you generate one
structure you execute this code on that
structure but while the code is
executing the two monitors what's
happening during that execution how is
this code inspecting this structure and
basically tries to learn from there what
does what the properties are and then
uses that information to actually find
that a large number of similar structure
should not be even explored because the
this piece of code is still going to
return false I said this is just you
know one slide summary but there who
yeah much longer descriptions in the
paper yes to create a set of testing
which
which were all directed graphs with two
cycles each then this approach would not
exactly work okay so the question is how
what if you want to generate graphs that
have two cycles each yes yes yes yes so
so said the approach would not work I
guess the approach was still working
sense it would generate them the
question would be how efficient it is
right or how effective it is if you want
to generate only to you would need to
extend this the description right
instead of having just this you will
need to add more code that maybe checks
here you know that check the number of
cycles and see how many of them there
are if you add that at the very end then
the two won't be able to prove anything
because if you're just counting that at
the end once you generate this dag and
you count the number if it's easy there
your two or three or four there is not
much it can learn from that however you
can be counting the number of cycles as
you go and then you can say if I see
more than two I don't want any more so
what I want to say bye this is there is
some you know intelligence that the user
the tester needs to put into writing
these predicates you cannot just
directly right there may be the first
thing that comes to your mind you need a
bit to think and understand how the Tool
Works in order to write the predicate
that would make the to work most
efficiently it's not always the case
sometimes you can just write the very
first thing that comes to you naturally
and that will work fine sometimes you
need to tweak and tune these to get
better performance from the tool but you
know it sometimes it will work it will
generate everything it may just search
too too much in order to find the right
things okay any more questions on things
that I didn't want to talk about how the
Tool Works okay there are no more
questions let me then show how the tool
actually works so here I am just showing
the Eclipse development environment what
you use here what do people use for
writing Eclipse and IntelliJ okay well
we don't use IntelliJ at school because
it costs money so use Eclipse and
netbeans okay so here's the Eclipse and
here is the
he hears this the code that i showed
before there is a class deck on the left
and so it has these lists of nodes and
the size and then there is this the rep
okay meta there is this piece of code
that I wrote to check the property here
I'm checking for that whether it's a
graph or not and here's the class for
for the node and it also does its own
you know traversal however that it does
so here I've intentionally put an
example where there is a problem so I'm
actually going to generate multi graphs
so I'm going to generate things that I
don't actually want to generate suppose
that I'm not aware of this this of
course just for the sake of the demo I
go run the tool okay hopefully so the
two is running so one part of output it
gives is just down here basically it
says how big was the search so it tried
21 structures and found 14 of them to
satisfy the property and just as you
know how much time it took there so
that's part here and then it's also
shows this visualization where it shows
the graphs that were generated so
suppose now that our goal was to
generate the X and we wanted to have
only one outgoing edge from each node
now from this here visualization we
would see that we actually wrote an
incorrect piece of code we didn't
specify the properties correctly and so
we have these two outgoing edges here
all right so what you do then is go you
know and go and the change this this
piece of code of course I've done that
in in advance so I've prepared the one
and here I'm executing actually another
one that corrected that that problem
such that we are actually checking that
there are no outgoing edges that then
that all the outgoing edges from any
given node that are different so in this
case we run this again and now we are
getting these grafts here it turns out
we are getting eight of them and you can
go and you know see them one by one how
they look like
and now of course the careful viewer
could have notice that some of them are
the same anyone notice which ones are
the same actually this one and
effectively this one they just look the
same except that they are flipped around
right and the thing is that you may not
want to waste your resources and to test
with the both of these right so it may
be very well that they are just
equivalent inputs and they're either
both going to find bugs or none of them
is going to find a bug so you wouldn't
want to run them both so there are some
ways for to tell this tool to actually
limonade some of them and I've also
prepared that this thing here which is
called reduced effect Lee what I'm doing
here every time I choose to run one of
these configurations I'm actually
running a different method here so there
are these methods called rep okay
correct and reduced and so on these are
different ones that are slightly
different and do different things so you
as the user of sorry so you as the user
would need to actually write this to
obtain different results so now if I
rerun this so now instead of a time
actually getting seven of these
structures and as it turns out I don't
have that equivalent one all right so
there is no need to go through all of
them so that's that's basically what the
output is now of course I don't need to
run this only for three right I can go
to larger sizes so if i run for four
this is still sort of acceptable you
know it finishes less than a sucker less
than a second if you're on for size five
now this is almost coming to the second
but we see that the number of this
structure is is growing so now here we
are getting about 5,000 of them so
clearly when we go to larger bounds this
is going to grow exponentially so we'll
soon you know the sizes six seven eight
you're going to hit millions of them and
you know probably wouldn't want to go
anywhere beyond that dead bound so it's
not that this testing will solve all the
problems not that this tool will will go
through all the cases but it will
definitely help with all the corner
cases within small bounds
that will also argue that there are a
lot of bugs that that are actually there
that if you try something like this you
find a large number of bugs for which
you don't even need the larger input of
course this doesn't mean that you
shouldn't try any larger input if you
want to do any kind of performance
testing need larger inputs you know if
you even if you want to do correctness
testing you need larger inputs to cover
certain cases ok so the this was
basically than the summary of this demo
so I showed the bits and pieces of this
code how it looks like and what the tool
does and how it visualizes these things
and there was this part which I want to
skip over which is how to use the tool
how the Tool Works I rather internally
and I want how to show how it's you know
how this tool has been used in actual
scenarios any questions before I go to
this ok so here's example testing
scenario something where where this idea
was actually used at Microsoft not the
crowd tool itself as I said there is a
different implantation therefore
different languages but the goal there
was to test the program that process xml
documents in particular this for some
expat compiler if you know what what
that expertise if not some sensitive
relevant the point was that they had two
implementations for the same thing so
they had a base code which was a slower
version of the code that was doing the
same thing as the optimized code and
then effectively the goal was to test
this so in order to test these XML
processing programs you need to give
them some some kind of XML input so way
to use this crud tool to use the idea in
there is as follows you first create
some kind of a model for these test
inputs in this case for xml documents
you don't want to generate them at the
character level rather you want to
generate the syntax trees then you would
write the predicate that specify which
of these inputs are valid so you know
how do you want these elements in the
XML document to look like maybe what
depth of nesting you want to have and so
on then you would use the correct tool
to generate these valid inputs translate
them into the actual inputs and then
just run them through the bow
two of these versions of the code and
then compare whether they're getting the
same output or not so this is just one
possible testing scenario for for for
using this tool some similar was also
done here at Google there was optimized
code written in C++ that was doing this
web traversal and then they wrote this
base code which was a very neiva
implementation in the slow algorithm
just written in Java and then just
compare the outputs from the two all
right so here then some of the results
of using these tools and using these
approaches we've used this at school
we've done some kind of unit or
evaluation of textbook data structures
that's definitely not all that
interesting for you know for industry
but something should be done for the
papers and basically the results show
that this tool was was useful more
importantly this talk is we've also used
these tools to find errors in some real
applications here's a list of some of
them there was some work also done by
some other people initially on testing
something called full three analyzers
basically these are the programs that
take as input something called a fall
tree this fall tree describes how system
can fail based on how the subsystems can
fail it does not matter but the point is
that the input is again structurally
complex data something for which these
tools are very well suited and then you
know they've used the tools to actually
do this this checking with those
decorative predicates point here just to
show some of these numbers that you know
you can generate millions of this test
and then it can take you know hours or
days to actually generate that and
execute another point also is to show
that the tools are useful for example
there were 20 bugs that were found in
those things okay so even more
importantly the karate idea has been
used at Microsoft so initially at
Microsoft Research the foundation of
salt engineering group there has
implemented this The Karate algorithm in
a tool called SML tea that's what they
did initially and so what what this tool
does is it works with the language
called abstract state machine language
so rather than using Java or C sharp one
just uses this SML and you want
eventually the two valuable so there is
some GUI for setting all these finite
ization manipulating tests re executing
that and so on the this the crowd part
can be either you stand alone to
generate these these test inputs or very
often you are not interested in just
generating the these graphs or any kind
of input by themselves but maybe they
are just part of a longer sequence so
you can also use that there and then
there are a number of extensions that
were also built so when one goes to
actually build this tool and use then
there some extension it needs to be done
compared to our just our academic use
and building these algorithms initially
so some of these extensions involved is
controlled non-exhaustive generations if
you don't want to generate all of the
inputs within given bound but only some
of them then generating complete test
from partial test and and so on building
a library that understands actually many
of the common data structures and
virtually them that was also summer
intern there is 5 45 years ago and
actually worked on some of these things
and the tewk has been used there it was
initially built in in research but then
moved to production it was used by
testers in several product groups and
enable these testers to find numerous
errors and I would like to point out
that this tool is not magically so I'm
just going to look at your code and find
the errors you have actually to put some
effort into using the tool you need to
describe the input you need to write the
predicate and so on the most poor thing
is you need to have some good feel for
you know where the bugs may be and what
kind of inputs to generate but the thing
is that the tool still help people to to
actually find these bugs so they've used
that for example for XML tools
specifically for that exped compiler I
have shown that graphical of view of how
they use that and there they found some
ten coding errors and as it turns out
this this was a piece of code that was
about to be released so they've already
had a very extensive test suite built
manually so in this case they use the
tool to just augment that test suite and
they just found the number of coding
errors that they did not expect to be
because they've already done you know
the best job they could manually and
even doing some random things with
randomly generating XML documents and so
on I problem with random generation is
that you don't have much of control of
you know what to generate and where
whereas using tools like this you can
you can have a more focused generation
those tested something called
serialization they found three code
errors but this wasn't all that
interesting because this wrote this code
was nowhere near a knee release it for
just said the initial stage stages what
was interesting there is that the spec
was changing they would keep changing
the spec and what this code should do
and how and there they found that using
this tool was really helpful because as
the spec changes as the the code changes
they could much easier change the input
if they just go and change that
predicate so if they have you know
thousands of the input manually written
whenever they need to change their
format or how they look like or what
properties they satisfy they would need
to do that manually it will be quite
involved with the tool they need to make
much smaller changes and the tool would
just regenerate everything they also
found a number of issues in these web
service protocols and many others I
don't even know what are all the other
things for which the tool was used just
a few a few years back when I need to
talk about this I ask for permission for
talking and I was allowed to talk about
this much so that the point was that the
arrows were found in your important
applications that they already well
tested and here's some comments that we
received from Microsoft from the actual
people they are in the trenches from the
actual testers who used this tool so we
got some positive and the negative
comments I want to point out that
negative comments and not on crowd come
to death so the positive comments are on
the tool itself because that's what they
are using then I like to point out that
these positive comments are also on the
karate so karate is my idea so the
positive thing is about my idea so one
of them says so far our stateless SME
models are pretty successful but
remember the tool that they are using is
called SML T so basically the way I want
you to read this is so far karate is
pretty successful so the thing that I
did is pretty successful SML parameter
nation to is quite community and
powerful as you can guess the way I want
you to read that is this that the crowd
algorithm is quite convenient and
powerful and it was just implemented in
this tool so these were the positive
comments but then as I said we got some
negative comments but I like to point
out here is that they are just on the
tool they are not on the algorithm okay
positive stuff is about my algorithm
negative stuff is not about the
algorithm so what what these negative
comments basically said was most of our
testers prefer to write as much c sharp
as possible and things very difficult to
debug SML the issue here was that the
tool was initially built SML T around
this language SML because that's what
they had in the group they already had
the tool they just steady this is the
extension so it was a quite natural
choice to do but it's not something that
people like because it's a new language
and they have to learn that and so on so
as a result then the group has
reemployment a new tool for C sharp and
actually all dotnet languages and the
tourists called spec explorer and it's
also available online in some some kind
of agreement from from them definitely
available for for academics well this
was about the use of carotid at
Microsoft we've also used this at Google
as I said this was done in cooperation
with the pneumonia from your New York
office the the goal there was to test
some web traversal code I said they are
the test inputs were based on decks and
also as I mentioned I don't even know
what the code does they never saw that
that code but the key thing was that we
could use Karate for that the issue
however was that we would get a very
large number of input so if you just go
to generate the all graphs of the size
seven or eight you already end up with
millions of them and what they wanted to
do was to make this generation in the
execution faster of course the first
idea you know one would want to try
would be to paralyze this but there is a
big challenge there that the karate
search is mostly sequential again
because I didn't present the search
current argue white sequential so you
have to trust me that it's that way so
that was a challenge but we came up with
some solution and developed actually
family of algorithms
it can paralyze this this execution and
generation and hear some of the results
or this is for the these graphs of size
8 for one of the algorithms that we
developed these experiments were done on
your computing infrastructure so so
here's the speed up sean is the number
of machines increased from you know 12
thousand the the testing time itself
dropped almost linearly so it went down
to over 500 times so it's reduced from
some 36 hours to about 4 minutes on
thousand machines so I guess comes down
from some weekend break to the coffee
break that you can run this this is
mostly for execution and again one could
even ask maybe I can just at least a bit
mention what the challenge here is well
if I just have this way to generate
these test inputs why don't I just save
them on disk and then later on go and we
execute them and of course I'm going to
get the curve like this right i'm just
going to distribute that for generation
and do this but the problem with doing
that is that if you have too many of
these inputs then it's going to take a
lot of time to distribute that and so
you don't necessarily want to do that so
this actually includes the generation
time as well as execution time here's
some more experiments this is for some
decks of size 7 and he actually the
curve does not look all that good
because it reaches some pecan 128
machines and then he starts going down
and here is actually the issue where
it's feasible that a lot of time goes on
this file distribution so we use this
Google file system and whatever they did
exactly doesn't cover that it works so
that was one one part of this doing
polarization making this thing to work
faster another thing was to reduce the
number of testing put that get generated
so as I said there is a way to do that
by slightly writing those those
predicates that get written one can
eliminate some equivalent inputs and I'm
not going to describe the details of
that or how it works but
here's some summary of the result
basically by investing some more effort
this roughly measures the effort that
the tester has to invest in in using the
tool by investing some more effort you
can obtain impressive speed ups in the
execution and the generation time so
here the number of inputs dropped
significantly from 1 million to 20,000
and then he is the generation time that
went down about seven times okay so so
equivalent I guess in general I current
classes would be those that if you have
a set of inputs in one class either all
of those input show a bug or none of
them shows about so clearly we don't
know that unless we run them all and see
whether they show bug or not so there is
this part where it says here are deemed
equivalent so it's whatever that the
user believes to be equivalent so if
you're testing this code you may want to
say well I think that there is no need
to test with the with all graphs of size
3 i'm going to choose literally only one
graph of size 3 and then you would just
say all inputs that have size 3 are
equivalent or you could say well all
input that look like a 3 or equivalent
if i have some bug it's enough to test
on only 13 I don't need all all the
other trees probably have some bug when
the recycles and sharing don't face time
with the trees so basically it's
completely up to the user whatever the
user finds to be equivalent so the tool
has some built-in equivalence it can
deal with some isomorphic structures it
can remove those but the user can
manually add some more things and then
remove even more okay so so so basically
these finishes then the talk about the
Curragh tool so in summary what it does
is your it requires the user to describe
what these inputs look like and in them
to provide the bounds on the size of the
inputs and then the tool will just go
and automatically generate all those
inputs any questions about that part yes
alright little bit more how pruning
works to do actually they're all the
validity predicates for each thing or do
you sometimes avoid calling them based
on produces outside not in standard okay
okay so the question is called the
pruning works let's say to keep that for
offline I need to finish in like eight
minutes and I have few more slides that
I would like to address and then we can
we can discuss that after I mean yeah I
would yeah no no por no problem I would
definitely like to talk about that by
just if I talked about that I wouldn't
have time to talk about anything else so
okay so could the question about pruning
a discuss that after that okay so the
point then is that yes there is this
pruning that goes on in fact if you just
tell what to generate and then the tool
somehow needs to be smart about that and
to do the search in a smart way to
actually generate that and now with this
this other tool does this tool called st
jen is is different so rather than
describing what the inputs look like the
user or the tester has to specify how to
generate these inputs so rather than
writing the code the checks properties
you have to write the code that directly
generates these test inputs so the trade
of here is that this usually results in
faster generation because there is no
dis search going on there is no pruning
you can directly generate this but it's
often more involved to write these
generators so what we they actually done
is you know built a large library of
some of those generators and and provide
this this brightest library provide this
framework that has a number of them
built in and then if you want to use
that for a specific purpose one has to
extend that so if you want to generate
certain kind of test inputs you need to
extend that in a specific way so the
library just provides some some generic
basic inputs so the first extension that
we worked on was for generating abstract
syntax trees of Java programs and stp
actually is the name of larger library
there is an underlying library that can
just generate the basic things like here
on your list trees graphs and things
like that so so so what we did was here
for the abstract syntax tree the goal
was to actually test some parts of
Eclipse and netbeans particularly want
to test something called refactoring
engines if you know what that does it's
great if not the details don't matter
the point is that they take is the input
they take effectively Java programs so
the question then is how to generate
those Java programs and you know if
you're testing this you may have certain
intuition about where the bugs may be so
here's one of those examples you may be
able to succinctly express in a natural
language what kind of input you want
maybe you want to generate the Java
program that has a pair of classes it
has two classes that are related in
funky bass maybe one is inner class of
the other one inherits from the other or
maybe it's both inner and inherits and
so on and you want one class to declare
a field and the other to reference the
field in some way so you know we can
write this in English fairly easily the
problem then is if you want to actually
generate programs that satisfy this this
property then you know there are like
thousands of them or millions just
depends on your what bound you put there
is actually unbounded number of them so
so the question again is you know how
can we help people to turn this
intuition into effective a test
generation and as I said this SD gin
helps with that but you need to you know
invest some work and to actually write
pieces of code that will generate
appropriate abstract syntax trees and
some of the results we've used this tool
actually to test this in Eclipse and
netbeans and we reported 47 bugs which
we believe to be new and unique and
they've confirmed 20 of them in Eclipse
and then in netbeans they've confirmed
the number of them fix some of them but
then they've labeled some of them as
duplicates all the ways to think that
they are not duplicates it's a
completely different question what
testers think versus what developers
think ok so that that was about these
these tools just briefly st john he's a
list of people that I worked with these
projects and this line of our contest
abstraction has been going on for seven
or so years so clearly I wasn't the only
one working on the left are people that
I worked with the more recently
some of them at Google I said naman is a
full time at New York and then examiner
Miletich was an intern this summer and
then on the right there are people who
were involved in somewhat older work the
initial work along these lines and the
person in common is our first khushi he
just turns out that the name came also
there in the alphabetic order so the two
of us have been collaborating on this
sanctuary for years okay so this is
basically about the diss approach so the
idea was use these tests abstraction so
rather than manually generated number of
testing put just describe how they look
like and then the two will automatically
generate there are a number of other
related you know testing approaches
doing that so there's something called
model-based testing you know you came
you this way of test abstraction as you
know special case of that where our
models are actually these predicates
it's something called specification
based testing again the idea is pretty
much the same you you write some
specification for how you know test
input should look like or what is that
your code accepts and then generate test
inputs from there may be a bit of a
difference in our work is that we
focused on this bounded exhaustive
generation rather than just random there
is constrained bein generation again
fairly similar to that then there is you
know random generation something people
do use but it does not provide the same
guarantees is bounded exhaustive it also
makes it hard to generate inputs when
you have these power spaces their
grammar based generation they choose if
you want to generate programs XML
documents things like that but again if
you want very complex properties it's
hard to express that in grammars and so
on okay so here then to conclude well
testing is important as we know and as
you know and I guess as you practice it
what I talked about in this work was
something called structurally complex
data so it's something that's you know
increasingly used in modern systems and
poses some important challenges it's
just not obvious how to generate that
automatically and I've presented some
tools that help with that for automated
testing of structurally complex inputs
or 12 is this crowd again you know it's
available online provide some efficient
on the exhaustive generation so it was
effective for data structures in our
revelation also adopted in industry you
know use that microsoft found the number
of bugs in in actual code and this more
recent tool called st jen this does some
impressive generation somewhat different
and they use it to find a large number
of bugs in these IDs so i would
definitely encourage you to try out
these tools and you know let us know
what you think should have some sort of
manual on these web pages and it would
be great if you get to try that and give
us some feedback okay let's finish my
talk question yes okay you say something
about vertical generation because okay
relationship between input in an awkward
with automatically generated data okay
yes so the question is if I can say
something about Oracle's well there's
not much I can say I'm including you can
build one Oracle this way but this is
going on to to involve some work right
so if this is the actual code you want
to test you can go and implement another
version of that and then just go and do
comparison another things that can be
done is just to have some partial
Oracle's so simply you know you would
run the input obtain the output and in
just some way try to you know see the
other is this output you know incorrect
or not even though you don't have this
the full check as in here so the
simplest case your if your application
crashes then presumably there is
something wrong with the application for
that input and other things that we've
done for example in in the in checking
the these refactoring engines in IDs so
there first so what refactoring engine
does I can explain that in sentence it
takes your a program let's say a Java
program and then just changes it
basically just translates from source
code to source code so now if you give
it a program that compiles and it
produces something that does not compile
that's definitely a bug in the
refactoring engine even though you don't
know what the correct output program
should be and you know what it does if
it
this is something that does not compile
that's a bug so then this is a very
impartial Oracle that just checks for
some some kind of sanity property on
that sorry oh no no no no for this for
for for the actual AST jan we built a
large number of of Oracle's folder for
that i mean the the one the basic one
that we used is this differential
comparison between two things so we
would give the same program running both
through NetBeans and eclipse and then
compare are they getting the same output
but you're even if they get the same
output they may be both getting the same
incorrect output so then you will still
need to run some additional things to
make checks actually we found things
where both of them have the bug on the
same output right so you couldn't detect
that if you just compare the output ok
any more questions
but yes the pruning is a pending
question but taking some time to explain
what that does and how okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>