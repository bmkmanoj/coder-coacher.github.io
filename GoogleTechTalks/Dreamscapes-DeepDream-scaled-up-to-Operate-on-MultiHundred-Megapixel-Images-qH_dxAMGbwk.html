<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dreamscapes (DeepDream scaled up to Operate on Multi-Hundred Megapixel Images) | Coder Coacher - Coaching Coders</title><meta content="Dreamscapes (DeepDream scaled up to Operate on Multi-Hundred Megapixel Images) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dreamscapes (DeepDream scaled up to Operate on Multi-Hundred Megapixel Images)</b></h2><h5 class="post__date">2016-05-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qH_dxAMGbwk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hi I'm Joseph Smarr I'm a engineer on
the Google Photos team and I had a small
part to play in getting some of the tech
of this ready which you'll hear about a
little bit later I'm gonna turn it over
without much introduction to add an
ambrosia who is a longtime Silicon
Valley entrepreneur and artist and
recently done these amazing dream
escapes taking the combination of this
multi hundred megapixel HDR that you'll
hear about plus adding in some of the
Google deep dream technology that we we
tweaked in order to work on that scale
he's going to give you a little bit of a
background of the sort of the artistic
motivations and some of the hurdles you
had to overcome to create it and then
I'll follow up with a little bit of a
nerd burst on some of the tech around
how we actually got it to work and both
I'm think we'll have plenty of
interesting fodder for discussion so
we'll leave plenty of time for Q&amp;amp;A and
get a chance to just hang out and look
later so without further ado Dan please
take it away and thanks for coming thank
you hi everyone thanks for having me and
thanks for coming I'm going to switch
over to the presentation mode here and
talk about my artistic journey coming to
this point which really started in
earnest about five years ago it was a
journey that was born of frustration
really of being in places like this I'm
an avid skier and hiker and often found
myself in these beautiful places having
a real experience you know visually and
being frustrated by my inability to
capture that photographically the point
that I'm trying to make here is that
when you're standing atop say heavenly
mountain looking out over the entirety
of Lake Tahoe it's more than a visual
perception it's a visceral experience
you feel it in your chest you feel it in
your gut and I don't care how many times
you go back there and I've skied this
mountain many times it never gets old
so I struggled to think about how to do
that I wasn't successful for a long time
with photography but I knew it was
possible because other artists
in particular the painters of the Hudson
River School and the great landscape
painters before them achieve that they
were able to create these master works
these large works of art that very you
know representationally captured these
amazing scenes in a way that gave you a
real experience as a child living near
New York City I went to the Metropolitan
Museum of Art a number of times and
became enamored by the paintings of the
Hudson River School which you know
included those works of people like
Thomas Cole who's considered the father
of the movement his good buddy Asher B
Durand who was incredibly skilled and
from whose work I learned almost
everything I know about composition
Cole's protege Frederic Edwin church who
was incredibly successful I want to take
a minute to talk about this particular
painting the heart of the Andes because
not only was it a total sensation when
it debuted but today is sort of an
anniversary of sorts for this painting
it debuted in New York City in 1859 on
April 29th and was a single painting
exhibition up until May 23rd when it
closed over 12,000 people paid 25 cents
for admission to see this one painting
which was unprecedented it was put in
this gallery in a way that really
intensified the experience this painting
is 5 feet 6 inches high by 10 feet wide
the amount of detail in it is absolutely
breathtaking and people had they would
just wax poetic about this like you
can't believe there's a see if I can
find this real quick a passage that was
written at the time by contemporary who
wrote women felt faint both men and
women succumb to the dizzying
combination of terror and vertigo
that they recognize as the sublime many
of them will later describe a sensation
of becoming immersed in or absorbed by
this painting whose dimensions
presentation and subject matter speak of
the divine power of nature you know this
painting made Church a wealthy man it
went on to exhibit be exhibited in
London and then six other US cities the
painting was widely acclaimed poetry was
written in its honor a composer
dedicated a piece to it Mark Twain wrote
about it eventually church sold the work
for $10,000 which was you know that's
about 286 K in today's dollars at that
time the highest price ever paid for a
work by a living American artist my
point is that depictions of scenes like
this can have that kind of effect I cut
that kind of power and I really wanted
to figure out how to do that you know
even other painters like Martin Johnson
he'd you know didn't do necessarily
images that were so grand but his
ability to capture the light in the
atmospherics like in this painting
called April showers it's almost like
you can smell the ozone in from the
fresh rain I also have to mention that
much later maxvill Paris came along and
I was a huge fan of Maxfield Parrish and
and the vibrancy and detail and lighting
that he brought to his landscape work
later on so as I was saying I knew it
could be done the question is how could
it be done so I deeply thought about
this and I studied it and I experimented
and one of the things I found out is
that there's a discipline in health care
design of trying to figure out what sort
of art in health care environments
hospitals and clinics and whatnot could
make people relax and feel better and as
it turns out there is really only one
kind of art that can do that Joseph's
joke to laughed about this
here evidence-based design study what's
an evidence-based design study I mean
you've never heard of an evidence-based
scientific study but in the mushy
subjective subjective fields of
architecture and interior design and art
you know it's apparently a rather novel
concept of actually testing things and
and and gathering evidence but this
person writes that only viewing
representational landscape scenes
measurably decreases heart rate blood
pressure and pain while improving mood
as I take you through my reverse
engineering of figuring how how to do
this stuff I'll be using my own work
that I've captured over the last three
years to show you to illustrate that
starting with this scene here this was
captured two summers ago in Colorado
this is nymph Lake in Rocky Mountain
National Park so it turns out is four
things that really create what's called
the pastoral experience or generate what
some people call healing art and it's
subject matter composition technique and
presentation so let's first talk about
subject matter in a nutshell again it's
about representational landscapes
featuring things like green fields water
scenes Hill and country scenes sweeping
views coastal views marshes farmland
groves of trees beautiful vistas
sunrises and sunsets but that's just the
subject matter it's more than that other
people have studied this and pointed out
again around the concepts of health care
design that composition plays a very
important role specifically immersion
compatibility and extent immersion is
achieved by
introducing strong foreground elements
and wide fields of view it helps to have
a clear vanishing perspective this is
the quality of the composition that
makes you feel present in the scene or
at least makes it feel like you can step
into the scene compatibility really
speaks to the resonance between the
natural and the man-made worlds it turns
out that seeing some man-made elements
in a representational landscape scene
makes people feel safe it makes them
feel that other people are thriving
there and they can too and then extent
which is achieved through very long
distance views this creates a sense of
being connected to a larger world it's a
key compositional element that I always
try to find when I shoot this quote sums
it up nicely the most fundamental
feature of a restorative place is that
people have to feel that they can move
into those spaces and have a wonderful
experience I'm happy to be able to
report that the most common response
I've gotten from people seeing my work
is it feels like I can step right into
the scene that's always music to my ears
let's talk about technique it starts
with what I call XYZ photography which
you'll understand why I call it that in
just a bit but let's cover the gear
first I'm a big believer in trying to do
the most with the least I want to make
really big pictures I don't want to
carry around a lot of gear when I was
ready to really step it up about three
years ago I got really lucky with timing
Sony came out with the RX one the
world's first full-frame sensor compact
camera my little beast as I call it is
really amazing people were scratching
their heads as to why Sony made this it
was the $2,800 camera with a fixed 35
millimeter lens that you can't remove
replace you can't zoom it the most the
common wisdom about why Sony made this
camera was really two things
one is to prove that they could and the
other was that top journalists out in
the field need to have something really
small that they can unobtrusively
capture the heat of the moment in in
their hot scenes the truth is Sony made
this camera for me as far as I know they
still don't know that but it's got
everything and nothing more than what I
need it's got a beautiful piece of glass
this 35 millimeter Carl Zeiss lens it's
got a 35 Miller millimeter wide
full-frame sensor 24 megapixels and it
does auto exposure bracketing that's all
I need in addition to that I've got to
have a tripod this is a small compact
little tripod and critical is the
panoramic tripod head which I want to
talk about for a second this gets
mounted onto the pan onto the tripod and
you calibrate your camera with this very
carefully metered you know highly
precision piece of equipment so that you
can rotate the camera both vertically
and horizontally around the cameras
nodal point the nodal point is that
point where the light rays intersect and
cross over you know the image that hits
the sensor is upside down and backwards
if you don't rotate your camera around
that point and by the way that point can
be in outer space it doesn't have to be
inside the camera then it that is the
only point where you will have no
parallax and hence no stitching
artifacts when it comes time to stitch
these scenes together it's not a hard
thing to do to calibrate but you need to
do that just standing up there and doing
this is not going to quite cut it when
you want to do really precise large
pieces so the interesting thing is I'll
get back to this in a second
this is all I need I I'm lucky enough to
live in a couple of really beautiful
places - Bay Tahoe City and and soon
Park City and there are a lot of amazing
places I can just drive right - without
even having to do any hike
so a lot of times I'll go and shoot with
nothing more than this not even a
backpack I pre mount everything together
and I literally just put two fingers
underneath the tripod head and carry
this thing on my arm that's all there is
to it and I can make these giant images
I'm happy to report that after three and
a half years Sony came out with the
successor to the Sony rx1 the Sony rx1r
2 which I really been excited to to
purchase because this practically
doubles the the resolution of the sensor
from 24 point 3 megapixels to forty-two
point four that helps me in two ways in
one way it will essentially double or
roughly double the average size of my
panoramas it's important for me to the
metric I use is I need to have about
15,000 pixels wide minimum to achieve my
goal which is I want to be able to print
my images out at least eight feet wide
and have them be Retina display quality
at roughly elbow distance that's about
what you need to do now to achieve that
with the previous camera 24 megapixels I
would have to shoot 5 views 30 degrees
apart to get to that number and when
you're doing that with the aperture of
the camera you're talking about a scene
that's about 180 degrees wide and let's
face it not all scenes warrant capturing
180 degrees now with this new camera
it'll open up so many more seems to me
that maybe only warrant 3 views wide
closer to 120 degrees and I can still
attain that 15,000 pixel minimum that I
like to do to be able to do these large
scenes so really psyched about that I
just picked that up here at Keeble and
shoe chat last Thursday so why do I call
it XYZ photography because I put this
gear together and I capture multiple
views horizontally let's call that X
multiple views vertically Y and multiple
exposures deep from dark to light let's
call that Z
now that's not real easy it's not depth
but I've been paying the mortgage as a
marketing person for the last 22 years
and you know how much marketing guys
like to bend the truth a little to suit
our purposes let's call it X Y Z it's a
simple way to explain that I'm capturing
a cubic array of photos and then using
three different software packages to
blend the multiple exposures stitched
together the multiple views and crop and
sweeten the final image and by that all
I really do when it comes to sweetening
it is boost the contrast just enough to
take the haze out and that's it this
particular illustration is important to
me means a lot to me because this was
where I came up with this technique
almost five years ago on September 27
2011 a red-letter day and Danna Rama
history yes I'm a legend in my own mind
but I was confronted with this scene
this beautiful natural geological scene
called the double arch alcove and kolob
canyon Zion National Park and there
literally was no other way to capture
this scene I had been experimenting with
single row panoramas I had been
experimenting with high dynamic range
photography it was here that I realized
wow maybe I can do a multi row high
dynamic range panorama let me try to do
that so I actually captured these 60
photos four wide by three high by five
deep and I have to go to the airport in
the airport on my laptop I put them
together and I achieved my first XYZ
photo and I knew I was on to something
it turns out you know while I may have
invented this independently I was not
the first you find out working in
Silicon Valley that's usually the case
but as far as I can tell I've done this
more than just about anyone else and
refined it further it is a technique
that's very simple in principle but the
devil is in the details and there's a
lot of things you have to figure out
over time to get these to look right so
I'm not too nervous about sharing my
details with everyone else be
you've got some work to do to catch up
to me so why is this good I'm calling
these interim results and the previous
slide I called image processing round
one because all this stuff we're talking
about right now is before we get to the
deep dream stuff that's introduced all
the interesting detail in these images
you see on the side of the room first
and foremost it creates a scene that's
more immersive due to the wide angles
both x and y it also makes a scene
that's much more vivid because of the
high dynamic range and of course these
are much higher fidelity because I'm
collecting so many pixels typically 10
times HDTV and about to be close to
double that with my new camera the
interesting thing is that this is really
the way we see we see not how the camera
sees but we see with a very wide field
of view probably at least 150 degrees
horizontally 60 degrees vertically we
see with an incredibly high dynamic
range we don't have a problem seeing
details and shadows when the Sun is
bright and so on and we and with healthy
eyes everywhere you turn you see things
in sharp focus so this illustrates I
think very succinctly the XYZ difference
what we have in the middle is a single
exposure full-frame sensor image of this
scene up on the Columbia River and what
you're seeing all around it is what you
get with my technique again much more
immersive more vibrant more detailed
just like we see in the Hudson River
School painters knew that and because
they were shooting they were painting
before photography and it's interesting
now when you go into galleries a feature
representation on landscape art that's
more contemporary you'll see that a lot
of these folks are painting from photos
and the view feels constrained they're
so brainwashed by how camera see that
they're not thinking naturally in terms
of the way we see
and then there's presentation which is
key I'd like to say that you know you
guys mostly operate in the world of bits
but I hate to break it to you we are
still three-dimensional creatures and we
live in a world of atoms when it comes
to still images the ability to print at
high resolution large gives us the
opportunity as human beings to stand in
front of these things and get close and
see the detail while having in your
peripheral vision the entire scene I've
been in this struggle for the last five
years getting my stuff purchased and
printed because it gets really old just
looking at all the detail of my own work
through the narrow blinders on window of
a computer to monitor computer monitor
in effect a lot of my images have been
imprisoned and it's been my quest to
engineer a mask jailbreak for my images
and it's finally starting to happen and
and getting produced and it's very
gratifying also it really helps when
there self-illuminating you know we are
creatures of light I like to think that
we are in fact essentially bottled light
which is where I came up with the name
of my company when things are backlit
like this even in bright environments
it's just it just punches it we're just
so much more attracted to it
and I should also mention that when
you're dealing in the world of light
boxes these are boxes they're containers
they're the images are interchangeable
especially if you're putting something
big on your wall even 4x8 let alone 8 by
16 at some point you may want to change
it up and and that's totally possible
with this stuff so inspiration part 2
then deep dream came along well you guys
I'm sure well aware that there's been
this revolution in computer science in
the last 5 years or so in the areas of
deep learning and artificial
intelligence
last summer Google released deep dream a
visualization tool does
to help understand how neural networks
work and when they had a look at that
they thought it was so cool from what I
understand that they decided to release
it as open-source code and let people
play with it and the internet went crazy
it went very viral you saw headlines
like this a lot of people started
hacking up little web apps that would
allow you to take your family photos and
turn them into psychedelic nightmares
from something like this to something
like that and you know when you look at
the more popular works that everyone was
talking about back then they were very
intriguing you know that you could see
why they got so much intention attention
it occurred to me that just perhaps this
software could be used in a way that
would be perhaps a little more subtle so
I actually use one of these web apps and
did some low resolution tests on my
panoramas and posted this and using by
the way effects that were more subtle
not a higher higher in the layer of
neural networks than the deeper levels
like you have in this wooded scene with
all the animals in it the more
impressionistic side of what deep dream
offers you I posted this image in the
lower left to Facebook and got a huge
response people loved it and and that
was that was interesting to hear and and
also I was pretty happy with this and I
was thinking wow you know if I could use
this software on my giant images then
just like the art world moved on from
representational landscape painting of
the Hudson River School into
Impressionism and the more expressive
modes of depicting landscapes I could
maybe do the same and I thought of the
works of like JMW Turner in the early
1800s who was almost like just a pioneer
in what later became Impressionism the
pointillism of George George Seurat you
know these people were painting
landscapes but
they sort of had a different way of
looking at them Cezanne almost cubist in
the way he he very geometric you know
you know expressiveness and his stuff
and of course Monet
you know the master of Impressionism so
I really really wanted to try this but
there was no way I you know it wouldn't
the software wouldn't work on my multi
hundred megapixel images it would just
crash and burn so I thought to myself
who can I get to help with this
oh yeah there's my friend Joseph he
lives in my neighborhood he works at
Google in the photos group he's
brilliant
what can how can i entice him into doing
this and I tried to get in touch with
him and I had the good fortune we live
in the same hometown um I ran into him
coming out of a microbrewery in our in
our downtown area and I think he had had
just enough beer to entertain my
proposition I pounced and I said Joseph
you know that deep dream stuff yeah well
this is probably gonna be easy for you
if if you could hack that code so that
it won't crash on my giant images you
could have my ski house in Tahoe for a
week while we're up in Canada in January
he's like okay send me an email let me
see what I can do so I put together an
email with some of these sample images
and didn't hear anything for a week
which isn't a lot of time for to get a
response from a busy Googler but then
the next Sunday night I got one of the
greatest happiest emails of my life
Joseph said sorry took some time to find
the right people but first of all I just
want to say that your images went viral
inside Google everyone loved them people
were saying things like finally someone
who's using deep dream for artistic
purposes rather than as a novelty you
even got a plus-one from Jeff Dean who's
Jeff Dean you know Chuck Norris yeah
he's like that with like in the coding
world okay awesome
so he's like I think
I'm gonna help you with this and I'm
gonna get my friend Chris Lam who who
I've known since I was three three days
old he's a senior director of
engineering at Nvidia obviously this
stuff is going to need to use NVIDIA
GPUs let's see we're gonna start hacking
on it we'll let you know how it goes and
this was in the summer Joseph after my
talk is going to talk more deeply about
what it took to do this but in November
with one of my full resolution scenes
they achieved liftoff and it was very
exciting I'm like great why can I get my
hands on this it took a little bit
longer before I could but when I did get
the code back in January not only did it
work beautifully right out of the gate
but you have to love the interface that
these guys built for me look at the
wording on this new dream Start dream
dreaming dreaming success now here's
here's a button you'd never want to push
Castle dreams you're not don't know you
never want to cancel your dreams so stay
away from that button in any case the
results surprised us all not just in
terms of the quality but one thing that
wasn't clear I had a suspicion this
might happen but we weren't real sure
about the scale at which this would
operate and how we could control that it
ended up creating this far vs. near
dichotomy not unlike the experience you
have in a museum looking at these master
paintings from across the room you see
this beautiful scene that compels you to
get closer and you get right up close to
it and look and it's got these beautiful
brushstrokes and all this detail and all
this expressiveness well not only did it
do that but you know when you got really
up close you notice that the content in
some cases was wholly on it unexpected
it's just like wow how did you know
that's just crazy stuff deep dream
actually has about 82 layers of the
neural network that all create a
slightly different look you know to the
detail and I should go back and just
mention one of the great things that
these guys did about setting this up for
me on this on these quad and video
GPU systems up at the Amazon Cloud was
that I was able to climb up the learning
curve very quickly because it was a quad
GPU I could run for low to mid
resolution tests at once and just start
trying all these different layers and
seeing what they did and cataloging them
and it was just a wonderful system and I
was able to achieve the results very
quickly so once we saw this once I saw
this that it could do this I thought wow
there's a whole additional level I can
go to now there's a long tradition of
people concealing things in their
artwork camouflage art dual meanings
multiple meanings and so on here are can
bulldoze back in the Renaissance was
making portraits out of fruits and
vegetables and flowers and whatnot Abbot
Thayer turn-of-the-century
the last you know 1899 1900 century did
a lot of experiment with coloration in
the natural world and camouflage and was
actually instrumental in getting the
British Army to adopt camouflage
uniforms from World War one Salvador
Dali of course with all his multiple
meanings you know these are the things
that all of a sudden are opening up to
me as I think about what could be done
with this software and Bev Doolittle
popular artist who's made an entire
career out of hiding things in her
images so what's happened here is that
this software which you can argue in one
sense is simply the fourth package in a
pipeline of tools that I've been using
to put these images together it's
actually so much more than that unlike
those other tools deep dream is so much
more powerful so much more compute
intensive and seemingly intelligent in
the way it does things that it's almost
like I'm collaborating with an AI now
and it surprises me as much as I
surprised it I don't know if I surprised
it but in any case you know in terms of
the power for example this scene
would had seen Chris Lam our friend
Nvidia computed that over the 10 hours
it ran on the on the GPU that it was
using it computed it it did perform it
approximately 90 quadrillion
floating-point operations
90 quadrillion that's like wow and you
can see when you get up and see that
there's there's like 5,000 animals in
that scene so for those of you at home
that can't see these big dreamscapes on
the world on the wall I've I've chosen
five of my I've got two dozen of these
dreamscapes now in my gallery I've
chosen five of my favorite to show you
both the full scene and what a one
square foot detail of that scene looks
like when this scene is printed eight
feet high so here is the aptly named
dream lake in Rocky Mountain National
Park we're gonna zoom in on that little
red square there and there you go you
know I look at this stuff not only do I
think it's beautiful and what it's done
to my images but it would take a
lifetime for someone to paint something
like this it's such an extension of my
artistic power it's really gratifying
this is a high you ranch in Park City
captured at first light about a year and
a half ago again very impressionistic up
at the higher levels of the network the
effects really look at the software kind
of looks at lines and edges as opposed
to you know looking for features like
eyes and noses and faces and so on I
tend to prefer those effects but there
are instances where going lower in the
network makes sense
this is ethica falls on the Cornell
University campus where I went to
college in the 70s and I can tell you
that I it's looked exactly like that a
few times back then to me on more than
one occasion this one is a lot of fun
this is
go Canyon in Zion National Park look at
what it's done here it looks as though
the Native Americans carved every square
inch of this canyon with some sort of
hieroglyphic you know pattern it's just
fantastic the Japanese tea garden in
Golden Gate Park this is a fun one where
the lower levels really are very
compatible I think you zoom in real
close if you look real close at these
people here in the red and yellow jacket
look what happens to them they become
birds and it's great how the software
sort of you know knows that things in
the water area should probably be more
scaly and amphibious looking things in
the greenery and the trees and branches
should be more bird-like it's just
amazing our first opportunity to
actually see these at a large scale was
digitally Joseph's father the
illustrious dr. Larry Smarr is the
director of Kaela to the California
Institute of technical communications
and information technology down at UCSD
and they've got a 32 foot wide 32
display a 30 32 display
yeah I think is it that many 64 mega
pixel screen now this was really a fun
day we looked at all my work here and it
really you know it was the first time we
could see that wow this pastoral
experience really works it when you look
at this stuff but this is only 65
megapixels I'm sorry my images are
anywhere from a hundred to a quarter
gigapixels and about to be double that
so again to really get all that detail
you need to print these things now when
Chris and Joseph first saw what I had
produced Chris said you know we have our
annual GPU technology conference coming
up in April and these should be
showcased there you know I want to I
want to get you on the phone with our
event person
this is like in February mid-february
I'm like when is it April when in April
the first week of April and that's not
gonna happen I'm a marketing guy I know
what it takes to organize a big event
like that but they were so captivated by
the work that they decided to go for it
and they actually purchased these three
eight by sixteen foot light boxes and of
course graciously agreed to loan them to
you guys to have up here for the week so
we put these things up I actually offer
them I don't want to print them any less
than 8 feet wide because then you're
gonna lose the detail but another thing
that's really cool about these is that
because the software deep dream has such
a rich parameter space I can as an
artist disrupt the traditional art
photography business model and commit to
offering one-of-a-kind digital originals
I'll never print the same image twice
except for the owner at cost in the
event of loss or damage because I can
always tweak deep dream just enough to
make it not a pixel match to the
previous works and that's gotten the
galleries really interested you know
it's I don't know I can't think of
another instance of being able to offer
that sort of one-of-a-kind piece that's
photographic based so in any case they
made it over to GTC and these are some
shots from that experience it was one of
the most gratifying and validating weeks
of my life
these were seen by 5,500 attendees from
over 50 countries they were a huge
crossover hit everyone from security
guards to CEOs just fell in love with
them jaws on the floor taking selfies
taking videos taking pictures of me and
Joseph in front of them it was really
exciting we had a an interactive hangout
discussion not typically you had about
five to eight people sitting at these
things a short presentation a lot of QA
we had over 40 people record crowds got
some press coverage I was interviewed
and
put up on the nvidia site it was a
really great week and then at the end
these things all three of these get
packed down into this little pallet here
this is how they came in and then now
they're on tour and they've come to
Google this week Joseph asked me to show
some pictures of the setup on Friday
yes this way you can get a little better
look of how these things are put
together there are LED edgelet on top
and bottom only as long as you keep two
not going any further than eight feet
tall you won't get a dark band in the
middle they'll look pretty good like I
said they packed down very easily
they're very easy to assemble
you put a reflective vinyl backer on the
back these things have what are called
they're called silicone edge graphics
they have little channel on the front
and back and the fabric is sewn to a
strip of silicone that just tucks in
there so it's edge to edge graphics so
there we were when they were set up the
other night again for the home audience
this is what they look like and you know
now I like I said I've gotten a lot of
interest from other galleries I'm now a
representative fine artist at a couple
of really nice contemporary art
galleries one in Miami one in Steamboat
Springs over the next two months I'll be
flying back and forth there quite a few
times for openings and exhibits there's
a major art plus science event happening
in Seattle in October that I'll be
participating in this is a really
exciting event that's the 50th
anniversary of a similar show when
people first got the idea of doing an
Art Plus technology event that happened
in New York back in 1966 so this is an
exciting event you should look into it
it's called ninety-two go to 92 seattle
dot org it's sponsored by some very
well-known companies such as Google and
Facebook and Adobe and so on thank you
so now Joseph is going to
come up and join me here and talk a
little bit about the tech I'm gonna go
to present camera hopefully that works
what do you guys think I'll I'll be
brief but just it maybe anticipates some
of the the QA which we can go as geeky
or artistic or back and forth as you
guys want this is really for you but
once once I stumbled out of the fine
establishment the den referenced with a
little bit more detail than I was
expecting
to talk about working together on this
you know it seems like a cool technical
idea to see how you could scale these
algorithms up and I didn't have any
particular familiarity with graphical
coder with this particular library but
you know I figured hey I'm a smart
engineer I can figure this out
and it was cool cuz it was you know just
up on github kind of Python source and
actually you know the people who built
it are at Google and so once or twice I
pinged on it you know the internal
Google+ and said hey what do you think
about this or that and they were
actually super helpful with giving me
tips and pointers so that was that was
really nice and the first thing was just
this is it's useful for it was
interesting for me to understand this I
thought it might be useful for you guys
to know the way these neural networks
work is they actually you feed in the
pixels and so it's actually trained on a
fixed pixel size which is about 224
pixels on the side so when you're you
know if you can Google photos you're
trying to have it recognize a dog or a
cat or whatever they scaled the images
down really small so that they're all
the exact same size and that way
literally you know each pixel it gets
wired up to one of the neurons and the
rest of the algorithm just flows and and
the idea is then you sort of get a scale
invariance right and so you just sort of
learns the features but it's actually
not a lot of resolution if you think
about it right compared to what you see
normally I mean most even normal camera
phone images are many megapixels at this
point so obviously that doesn't work
from a visualization perspective because
anything you do to the image is on a
224 by 224 you've lost all the size of
it right and if you try to put the giant
image through it just it doesn't really
work so what you end up having to do is
a combination of scaling it up and down
and then taking little tiles of it and
and running on each little tile and then
stitching the whole thing back together
and in order to avoid any kind of
mosaicing what you end up doing is you
compute based on the size of the image
and the size of you know that you 24 how
many you know rows and columns you're
gonna have to do and then you jitter
each one randomly and you just run
multiple iterations at each level and
that way the whole thing kind of gets
covered and blended together and it read
you know wraps the image around the
edges of necessaries that you always
have full pixels that you're working
with and so once we could get it to do
that and get it to not you know the GPU
does the actual evaluation of the
network but you know it's only got a
certain amount of memory on the device
and so you have to feed it in in in
sizes that the GPU can get filled up but
not run out of memory otherwise it'll
crash so that took a little bit of
figuring out to get working and then the
next problem that was only obvious in
retrospect is the amount of just Ram
that you need to run this because you
know these images are a few hundred
megapixels but and and so I think as a
JPEG it's like what a couple hundred
Meg's something like that right yeah so
I was like how bad can that be but of
course when you're when you're when
you're operating on the image in a
neural network you're not operating on
the compressed JPEG right you're you
actually have to blow it up so that
every single pixel is a full RGB of you
know which is sort of maybe 24 or 32
bits times three right so it's it order
of magnitude larger representation of
the image when it's when it's
uncompressed and actually being dreamed
on and and then the way the algorithms
were written there actually wasn't a lot
of attention given to minimizing memory
copies and so there were a lot of times
where internally the entire image would
get copied as a result of you know how
you guys are engineers you know that's
where you hand it off to a rep you know
a routine and it makes a copy and
returns it back that kind of thing and
so even with the biggest beefiest amazon
instance we could get by the way I
should apologize we didn't do this on
Google compute you know Google cloud
because they don't have instances of
GPUs yet maybe I don't know but as it
was if you wanted to get an instance
that actually had GPUs Amazon was sort
of the only way to go anyway so even
with the very largest instance we could
get our hands on
we were actually more limited by the
total ram than we were by the the amount
of GPUs and so we just had to do a lot
of very careful memory profiling you
know at each step and figuring out you
know how much have we allocated before
this line how much after this line okay
go into this method instrument and you
know very quickly we realized where we
could make improvements and of course a
lot of the memory copies are happening
at the lower
like a lot of the built-in Python
libraries that are just used for image
processing and American puing whatever
have these in there and it had to go in
and figure out how they worked and fix
them but you know you just sort of keep
turning the crank and after a while you
get to the point where it kind of works
and there's it really more we could do
but we got to the point where it was
running comfortably in these in these
large instances and so that's that's
sort of where we stopped and then really
you know the the way just I don't know
how much familiarity you have with the
original deep dream stuff but you know
so there's a there's a network which has
many layers of neurons each one you know
you feed in the output to the next one
and so you can sort of think of it as
you start by just looking in the pixels
and then you look for patterns in the
patterns and then you look for patterns
and those patterns and as you get up you
go more and more abstract so it's what
the higher level you start to recognize
faces and animals and things like that
but that emerges over a series of layers
right and so you train this network on a
bunch of images and where you know the
right answer and then afterwards you
sort of wonder like well what did it
learn right it's basically just a whole
bunch of numbers and it's pretty opaque
and so we're deep dream actually came
from was an attempt internally to
visualize and understand where these
what these networks have actually
learned and the way they try to do that
was they said well what if we ran the
image through the network stopped at one
of the intermediate layers which was not
just the pixels and not the final
recognition and then we asked ourselves
okay you know how much do you see
whatever up you know whatever patterns
or swirls or eyes or at this level and
how could we then instead of changing
the weights in the network like you
normally do when you're trying to learn
to train the network to recognize the
images what if we instead change the
pixels of the images so that whatever
you saw you saw it a little bit more
intensely right because the remember
that the the once you've inflated the
image it's also just a whole matrix of
of floats basically right so you can do
gradient descent in pixel space with
respect to the network as opposed to in
network space with respect to the pixels
which is what you normally do when you
train right and so that's where the
hallucinations come from because you
basically say it's I think of it as like
you know if you have heard like stare at
clouds and you start to see like animals
or something in the cloud and if you
kind of like really focus you can like
see them almost more intensely than they
really are because you're essentially
giving top down you know biases to kind
of help push your visual system in that
direction that's essentially what we're
doing we're sort of saying tell me what
you see here now how could I make you
see a little bit more and then you feed
that back into iterative
and you know what about this what about
this sort of this and so one of the
parameters is not just what layer are
you expressing but then how deeply are
you expressing that and that'n combined
with how much you scale up and down the
images as you do this gives you kind of
the different scale effects of the
features within the pictures and so at
the end did that that was so successful
was he's not doing giant scale features
because there's so many pixels that even
when you scale it up and down a lot
you're still talking about a fairly
small swath right like the number of
pixels in any given you know a few inch
square is still quite a lot and so he's
able to and then he's you know if it's
not obvious from looking at these
pictures if you haven't done them close
they have very different effects and so
a lot of the artistry was just figuring
out which layers in which settings work
well for each image and the nice thing
about that is to some extent you can
fake it on smaller images to kind of
figure it out of course you don't really
know until you run these big ones
because it takes ten hours or so to run
the big ones you don't want to just have
that be your learning step right you
want to kind of play around at a smaller
scale and then blow them up but
essentially that was all there was to it
and then you know we just once we got
the core code running we threw a little
Django server in front of it with a
little celery cue to handle the stuff
async student to sit there and wait for
the webpage to load for ten hours and
that was you know so it was it was nice
I mean I just thought like this is
something that if you guys ever get
expired to sort of hack on stuff like
this it didn't take a PhD in computer
graphics or something to to work on this
it just required a little bit of you
know kind of spit and polish and
willingness to kind of keep going and
then you know it was it was obviously so
worth it once I saw what Dan took the
ball and ran with it I miss this feels
like a time really well spent in
retrospect anything I think we said what
he said okay that's not for the prepared
remarks um we will open it up for Q&amp;amp;A
now if you want also we'll stick around
for another hour so to chat with you
guys as you see the pictures there's a
food and beer and drinks and stuff in
the back up yourself and thanks for your
time and if you want to ask any Q&amp;amp;A here
there's also a mic or we can also just
do it casually afterwards so I know does
anybody have any burning questions that
they'd like to ask all right yep please
do you want to come up to make
oh maybe maybe make sure it's on you
should be switches away switch on this
thing okay yeah I was just wondering
about the printing um that's something
that you kind of glossed over and you
had to figure out what to print it on
and how to get your resolution and your
color trueness and all that in the grey
and it seems like that was probably yes
yes I'm all about that yet thanks for
reminding me so as a marketing
consultant my wife and I my partner
we've been for the last four years
working on the Dreamforce conference for
salesforce.com as graphic managers
getting specifying and producing a lot
of stuff like this so we've become very
familiar with large format graphics when
you go to Dreamforce up in the city you
know you see the stuff you see building
wraps you see you know tension fabric
structures all over the place some
frontlets some backlit so I had fairly
good familiarity with large format
printing anyway and even with some of
the vendors and that said when you're
going to commit to this sort of thing
for yourself you want to do some testing
so I actually talked to a handful of
folks got some recommendations do some
research online in some cases paid for
samples to be sent to me and there was
one outfit in Michigan who does a lot of
these for high-end retailers that just
killed it they in every metric they had
the best prices the best product the
best printing and the best service
customer service they're called 40
visuals 4-0 visuals they were they've
just been fantastic to work with sure
nobody else
yeah I can hear the questions what's the
material of these printed on it is
fabric it's uh you know what kind of
fabric I'm not sure it's called premium
backlit fabric you know again marketing
right so I don't know exactly what it is
but they print them on large roll fed
printers they can go up to 8 feet by you
know very long lengths you know just FYI
I mean this really blew me away I found
out last year after seeing some really
large graphics guess what the largest
seamless fabric print that can be made
on the planet today is any guesses
seamless seamless 50 yea 50 feet high by
a hundred fifty feet wide there's one
printer in Germany with one printer that
can do this custom built you know it's
actually 15 meters wide and and there's
only one company who also happens to be
in Germany that can print that can
produce fabric that big seamlessly a
different company and they then they can
produce these pieces yeah absolutely
the other thing that blew me away just
having seen these only recently once we
got them for Nvidia is the the effective
dpi of the fabric is incredibly high
right I mean if you go right up to these
it's pretty hard to see pixels and so to
be able to do that at that size is
pretty amazing because if you think
about it digitally it's very hard like
if you project onto the wall like what
you're seeing these screens are large
but there's really only a couple of
megapixels worth of you know image there
if that right right and even with a 4k
projector it's I mean again this is 250
K right so well it there's really no
substitute to do this kind of thing and
but it's kind of amazing that you don't
really see the grain of the fabric very
much and in fact you still get a lot of
sharpness and there's an image that's
interesting too that it's backlit so it
has to be somewhat like permeable and
yet obviously vivid enough as well so
there
be some double in the details there yeah
I'm glad they figured that out yes what
I considered photographing non
landscapes I yet what was your other
question right so first of all when it
comes to XYZ photography when I first
figured this out I went on a subject
matter search and started shooting
everything you know trying all sorts of
things and it turns out that the
technique is really tricky it works best
on scenes that are last primarily
landscape in nature with some minor
percentage of man-made elements if you
have a lot of people remember everything
there's a triple exposure so you have
ghosting to deal with people are moving
you know if you have more than 20%
man-made stuff it very you very easily
see the panoramic distortion like you
start to see in the city here that
composition it seems to kind of work but
in a lot of cases it doesn't so it's
really you know it's kind of a two-way
street
you know I'll uh I'd look for a
technique that could do this and it
turns out it's the technique that pretty
much only does this you know as for more
serial istic things I did do some tests
one of my graphics oriented friends
suggested trying to do multiple layers
of dreaming at different scales so that
the effect becomes more evident right
from the beginning and as you get closer
you see more and more stuff at a finer
detail it wasn't I had some quasi
success with that but but the truth is
I'm really taken by that far versus near
dichotomy
that sort of fact that that crazy detail
is concealed within a scene that from a
distance looks essentially photographic
so I'm kind of I've got a lot more
exploration I want to do there first
yeah
anybody else you can shut stuff out and
we'll repeat the question okay well
thanks well yeah thanks again and we'll
hang around a little bit thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>