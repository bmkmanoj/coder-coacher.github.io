<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HCIR 2011: Keynote: Dr. Gary Marchionini, &quot;HCIR: Now the Tricky Part&quot; | Coder Coacher - Coaching Coders</title><meta content="HCIR 2011: Keynote: Dr. Gary Marchionini, &quot;HCIR: Now the Tricky Part&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HCIR 2011: Keynote: Dr. Gary Marchionini, &quot;HCIR: Now the Tricky Part&quot;</b></h2><h5 class="post__date">2011-12-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jj5Q3FmPVl0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning again it's my pleasure and
honor to introduce our keynote speaker
today it carries see bar shimmer
professor in the school of information
and library science at the University of
North Carolina dr. Gary marchini I'm
sure that many of you are familiar with
his work which his record is quite
impressive and I'm just going to give a
short survey of some of the things that
some of the fields he's worked on
because we do have limited time but
Professor Martini has made numerous
contributions to information interaction
human-computer interaction
human-centered computing information
retrieval digital libraries information
architecture digital digital government
cyberspace identity information policy
and I'm sure I'm leaving out about half
a dozen things and while embracing that
the benefits of Technology his research
has always focused on people and the
role of people play in in this space
which is quite important I think he's
also contributed through organizing
numerous conferences editing academic
journals and other publications he's
been the president of a cyst and
recently he made the ultimate sacrifice
by becoming Dean and finally I'd like to
add that Professor martini can be quite
creative with words and he's given us
such terms as and I'm going to take a
minute to pronounce this one sim and for
OSIS share iam and of course HCI are
please welcome dr. Gary martini
well he didn't say that you you're going
to be disabused today by someone who
doesn't even know how to pronounce his
last name so we can't have done very
much every time I go to Europe I get
ranked by folks who see what how did you
do that to that that mark Keough Nene
euphony okay so just to get us started
here first of all thank you for all
being here thanks to the organizers for
inviting me it's really quite a humbling
experience you know Daniel and Ryan have
sort of been the name organizers and
sort of heart of this series of
workshops from the beginning bill Kathy
Rob have sort of really stepped up in
and bolstered the community a Dan a
longtime member of the community more
broadly is we thank for hosting us and
there's just kind of an interesting
synergy between those of us who sort of
aid kai our home or sagai our home or
were schizophrenic and would sort of try
to go to both of them and learn from
really two different I think fundamental
points of view about how people interact
with computers and so I'm going to start
with a little bit of context for HCI are
and then focus on some cases based on a
work that my students colleagues and I
have done over the years so a lot of
this will be up a little bit
self-centered I apologize for that in
advance that i'll try to also be a
little bit self-critical and then really
talk about challenges and and the sticky
part the hard part and i think the hard
part in our field if this is a field is
evaluation and how we're able to really
demonstrate that our results are robust
extensible so a little bit of history
here 3101 I could have had I started put
lots of names on this I thought this is
going crazy I can't do this so let me
sort of emphasize a couple of names that
maybe you haven't heard people who back
in the 70s were actually doing work at a
time when before certainly before the
web when the way retrieval got done was
you'd have a person you'd have some kind
of system and then there would be an
intermediary a real life person usually
we called them librarians and you would
talk to the librarian and they would do
what's called a reference interview
which could be quite extensive or it
could be early cursory and then they
would go search for you in those early
days when everything except maybe the
Eric database cost a lot of money to
search per unit time and so no one could
be trusted to actually go and do your
own searches and as a little ironic sort
of anecdote one of our great colleagues
Chris Boardman her mother was a
librarian at Wayne State University
where I was doing my PhD and she did my
Eric searches and I you know we
discovered this sometime later yeah and
I blir emember going into the library
and I had been used to going and doing
my own searches in rented indexes
painful stuff and you know you write
down something and then hopefully it's
somewhere in the stacks and I heard
about this new service and so I went and
talked to this very nice lady who
actually did a fairly extensive
interview and and then through the
campus pickup sent me printouts of
bibliographic citations you know week or
two later and you know that's the way
you know retrieval used to get done and
there there people you know who were
studying the intermediaries especially
folks I think God Don Hawkins is here
actually in the audience
Charlie meadow who was came out of
dialogue and sort of joined the Academy
you know the usual names you would
expect to see in a TEPCO sriracha Vic
and Dan Russell George furnace I put
Karen spark Jones in there because I
think she actually had a lot of
appreciation for the human side of
retrieval and we have the luminaries the
pioneers and on the IR side that you
know the Sultan's van R Eisenberg's
cross and so on we have the pioneers on
the HCI side you know the Normans and at
all and there were a couple of folks in
a ben shneiderman do card for example
who not only were doing the founding
sort of HCI but they sort of were
working in the area of information
seeking their Pauline Cochran another
name you may not sort of be so familiar
with the studied OPEC's Richard Marcus
the guide MIT libraries who was trying
to develop expert systems that would
emulate search intermediaries and doing
really interesting stuff that certainly
influenced some of my thinking when I
first came to the field in the early 80s
folks out at in London Michelle Hancock
vallejo Bell you steve robertson stephen
walker i think we're doing really cool
things with a pax that influenced a lot
of what went on in the retrieval
communities but they were doing from a
from a human side and if there are two
people I guess who I would say our kind
of well Sue's not here but she'll kill
me you know mother and father of HCI are
it's it's it's it's probably a pseudo
may and Nick Belkin
whoo i'm guessing that between that no
two people have more papers at CAIR and
HCI than the two of them so there's a
rich history here and I think what's
happening is we're starting to see some
of those gelling as a sort of newer
generations of people really sort of
make a difference Marty hearses here who
sort of put faceted on the on the map
from the HCI point of view and certainly
other others of who really I guess
brought us to where we are today so
these little pictures to me are
meaningful the important thing is that
that green face the intermediary has
disappeared yeah so from the sort of
early the 70s and probably early 80s
there were these intermediaries and I
suspect that going back and trying to
understand what people were trying to
learn from studies of intermediaries is
is probably something that would be
worth some sort of revisiting given the
tools and the technologies that we have
today so that's kind of the go back and
do a little history and we might
discover some things certainly the 80s
and 90s we we got the web we got this
intermediary disappear but also the
database instead of it being this kind
of plain vanilla text database that was
bibliographic in nature we got
multimedia we got connectivity through
the web and things began to really
change and and the current state of
affairs today extends that with lots and
lots more people if we consider what's
going on sort of with social media so
that not only do we have those that
incredibly rich a database if you will
that system we we also now have a lot
more humans involved and so this this is
our time I mean if we really are
thinking about
taking the human side of retrieval then
there are a whole lot more humans out
there and the one thing that I guess is
always sort of bugged me is that we
haven't really had a had a good way to
leverage human intelligence during the
search process it typically either is
all on the human or we sort of turn over
everything to the system side and that
delicate sort of back and forth
interaction is is really I think what
this sort of subfield is about okay so
to move along here now that you had your
history lesson we do a few little case
studies I'll start with open video which
is a platform for research first and a
service to the community second and then
probably an educational outreach sort of
project third and over the years those
three kinds of roles have have
interacted and switched around the
original notion was to try and provide
the basic search it wasn't fancy search
it was sort of just keyword-based search
using the standard sort of my sequel
type out of the box search based on some
pretty good metadata and then faceted
selection and that's where I think we
made some interesting inroads and we're
dealing with video so things like genre
became kind of an important facet you
know not just things like topic and in
person so that was sort of one direction
the second big theme is this sort of
layers of representation in the search
engine result page in there in the
results themselves but but also for the
objects the the notion was that video is
can be can generate sort of big files
and so before you actually download a
video you really want to know a lot more
about that video before you make that
sort of commitment
now that was you know 10 plus years ago
but I think it still remains true that
the idea of looking ahead is really
important and how do you look ahead well
you look ahead by having representations
that are sort of cascading now in our
sense they tended to be hierarchical or
going from sort of a broader down to
narrower other though I don't see any
reason why they couldn't be lateral as
well and we sort of developed what we
called the agile views framework in that
what we wanted to give people were agile
views they could change their view very
quickly so you could look from the
overall corpus sliced up by facets very
quickly at some sub partition of that
database if you will and from there you
could look at individual objects you go
back and look at subsets and you can
look at abbreviations or what we call
surrogates and I think the surrogate
work has really probably been the
hallmark of the open video project over
the last decade i distinguish surrogates
from metadata and that surrogates are
really meant for people or as metadata
very often is meant for machines or
people but it's it's really useful for
machines and and surrogates really are
designed for people and so the the
notion of asking the question what are
appropriate surrogates for video objects
and then trying to empirically
investigate those different kinds of
surrogates has been pretty much the the
bulk of the work that has been done by
mainly fantastic students the the kinds
of surrogates that we were mainly
interested in from the visual side where
things like fast forwards storyboards
poster frames kinds of circuits we're
interested in from the audio point of
view are snippets can't really do so
much fast forwards with with audio even
visual representations for
audio when that's appropriate it sort of
overloads the visual channel if you're
also using them in conjunction with with
visual surrogates and and then how those
things interact became sort of the most
recent kind of dissertation that came
out of that that was Michelle songs work
one of the things to me that's been most
interesting about open video is how well
it stood up as from an interface point
of view Jerry Geisler sphere somewhere
was the designer of that interface and I
think it's a testament to his skill and
careful perception about what would work
that has made that interface stand up
over time there are a lot of studies
that came out of out of this and for
dissertations but the most sort of
rewarding thing for me and this will
sort of serve as a counterpoint for some
things i'll talk about shortly is that
the framework for looking at video i
think makes sense we we try to actually
create not only tasks but stimuli that
were appropriate to video they weren't
text-based the work text-based sort of
stimuli but they were really meant to
sit in the context in which people do
video retrieval the takeaway message I
guess for me is is that there's this
kind of interaction between research
practice and mixed methods most of the
studies that were done were lab studies
kind of you know classical user studies
but there were a number of qualitative
studies Hmong Young's dissertation did
intensive interviews with three
different kinds of users of video to try
and sort of determine roles but most of
the studies here were actually looked at
through the lens of the laboratory study
and I think there's some contributions
from from that certain point of view get
to in a second in a he
here's aunt just one example so I'm not
going to go through a whole but a bunch
of the screen dumps here you can go to
the website and check it out still works
just kind of amazing after thin here and
these were the three kinds of
storyboards that people could are sorry
about three kinds of visual circuits
people could select there were other
levels of representation where people
actually we're making choices about what
to look at next because it's always a
matter of asking yourself should I go
further is this still interesting is
this worth going down that path any
further and my my estimation is that
only in the very simplest cases of sort
of known item look up is that question
always an easy one it's a matter of do I
know now have I learned enough I want to
sort of do a quick little transition
here this is an old interface that was
done probably late late 90s probably
1996 I think was when this this
particular one was was put together this
was the Baltimore learning community we
were working with schools in the city of
Baltimore and the Discovery Channel and
a few other Apple I guess was a partner
at that time and the notion was to try
and give teachers a small digital
library of science and social studies
materials that they could then build
into their lessons and their lesson
plans and this was inspired of course by
the work at the human-computer
interaction laboratory on dynamic
queries and the what we were calling
star field displays and the way this
works is the facets on the Left were
topical or that was the topical facet
the categories within the top expensive
and the categories across the horizontal
axis that are kind of read there because
of the overlay where the actual
standards so those were Stan
for them from the social studies
teachers association and the science
teachers association and so what people
could do is say well I'm interested in
this standard and I'm interested in the
topic of ecology and they could see
pretty quickly that there are a lot of
blue dots and a few yellow dots and
those represented different kinds of
objects the objects were videos text and
images and if they clicked on one of
those small partitions they would get
the popup on the right which was sort of
the the metadata for that sub cluster
it's kind of like a search engine result
page if you will and they can then
scroll through there and as they scroll
the bibliographic or metadata for each
of those objects would show up and in
the case of the visual surrogate those
were we were just slide shows so if you
click or hovered over I think that yeah
I think that was a click on the image
you would then get in this case a
storyboard we also fooled around with
doing these a little flashing slideshows
of the same key frames so this was kind
of the inspiration for open video before
I moved to North Carolina I still think
this is a useful interface and I guess
I've tried to have people implement it
this was done in like the original Java
the buggy oldest stuff from the mid-90s
and I haven't quite seen this done in a
way that makes sense now it's not going
to work for the entire web right it
would work for a fairly small sized
let's say 100 K or fewer kinds of
elements a database or it might work and
this is where I think it has some
potential for a search a search results
kind of cluster of things right which
you said ok I've done my usual web based
search let me now visualize it in a way
that is dynamic lots of stuff has to go
on in the background here right I mean
you got to have good metadata otherwise
this doesn't work at all
and so we did a lot of work with trying
to automatically generate metadata using
machine learning techniques and other
things and it's okay I mean it'll it
actually does well enough to make this a
viable way to go so I'm kind of waiting
for folks to go back to these kinds of
of you is after people have sort of done
the the search engine magic to move to a
second case here the relation browser
this is another I mean I guess I think
of it as a project it's it's a way for
for us to think about a problem to build
something that might actually be useful
and to study human interaction unlike
open video which actually have a system
had some data behind it and continues to
be used by lots and lots of people
especially teachers and artists around
the world the relation browser was
really more of a well what if we could
actually do some kind of dynamic query
widget and let's push on on that and see
if people could sort of plug plug it
into things again the notion behind it
was can can we do this look ahead
without penalty where people through
brushing or Mouse seeing activities get
looks into what will happen if they take
a more let me say aggressive action so a
click is an aggressive action used to be
much more painful when you clicked on
something because you have to wait
longer you know now you know you click
and you can start undoing it's not such
a penalty but before you click the
action of the action of brushing can
give you kind of a look ahead so that
was part of the motivation here but more
importantly this is user driven so it's
like how can the user take control
rather than having the system we started
spurting out suggestions or trying to
sort of drive the user toward the answer
or or set of answers the other important
aspect that was important to many
importance there in the relation browser
work was being able to see relationships
between and among different categories
within the facets and i'll see if i can
demonstrate that the second and and that
this this was about exploration rather
than search remember when we first
implemented this at the bureau of labor
statistics there were there were a
couple of most people got it but there
were a couple people who just thought it
was about search and they just never
quite sort of sort of saw that the power
of that i think we we sort of were able
to win him over over time but the it
really empowered exploration and with
exploration the expectation should not
be the kind of precision that we would
have it with really high quality search
a whole lot of implementations over the
years been brung was sort of the
original developer of early relation
browsers Anita I think you've probably
spent some time at BLS doing user
studies in those early days Rob Capra
has sort of taken over well he got stuck
with actually a couple of years ago
doing sort of a more up-to-date version
of the relation browser and and we've
done a number of studies not as many as
with open video but most of these were
laboratory studies we have I think the
one field study we did was at BLS where
we actually mounted it and because it
was a government agency we couldn't put
it on the homepage and so you had to
actually go a couple of clicks down
before you could actually you know do
the survey and you know sort of give
some feedback but most of these were
laboratory studies and I'm going to
speak to one particular laboratory study
that I think demonstrates some of the
tension between trying to do serious
laboratory evaluation and having
too many variables for those of you
haven't seen this you know earlier
version basically as in this was I guess
for the energy information
administration we did this one and as
you as you brush over the type of energy
all the other things geography sector
and will update immediately so that what
you're able to do it's a really sort of
primitive data mining sort of tool and
it severely depends on really good
metadata secondly it severely depends on
having all the metadata on the client
side which is really problematic if you
want to actually do this at scale beyond
say a hundred thousand or so kind of
items so you know if you're willing to
pay a little bit of a price of waiting
for the metadata to come to your client
then you can actually have this very
dynamic kind of system where everything
is connected and as you're rushing over
any one of the facets you actually see
immediately where how it relates across
all the other facets so it's a really
powerful way to look at things but you
can't do it with many millions of items
at least I don't know how to do that I
think it's a good computer science
technology engineering type challenge
but it has again some possibilities for
all right I've now narrowed my results
down to 50,000 or some something that's
somewhat reasonable I'm willing to pay
the price of waiting in a 10 seconds or
so three seconds whatever it takes for
the metadata to come to the client side
and now I can really do dynamic things
with it and I we're still not quite
there except for sort of databases that
are kind of more well-behaved the right
side is rob's version for some work we
did with the science and engineering
indicate
is in the National Science Council so
here's the study that I'll sort of self
criticize and I think this this is
actually perhaps a little bit in my
experience too typical maybe it's just
because I'm not discriminating enough or
I can't sort of parse away some of the
variables that I'd really like to study
part of it is that these things as many
of you know evolved over a long period
of time I sort of jealous of my
colleagues who work in the search engine
companies because they can actually run
things really quickly in a university
setting you know you know how this works
right you you'll get the grant you
assemble the team that team is
completely dependent on semesters not
unlike you know any other real-time sort
of thing but when people you know come
come to campus and all that and then you
have meetings weekly meetings at least
and you sit around and you say well what
you know how do we sort of partition the
right question the right variables to
and is great for students because you
know they see all the complications of
doing a user study and you know if they
happen to have come from computer
science or engineering they get kind of
frustrated some of them even you know
managed to stick around like chirag and
you know not say this is too crazy I
can't do this and and so for the from
the students going to be it's a great
learning experience but from a kind of
overall moving the science ahead there's
a lot to be criticized so here's a study
that we did I I don't young we were
interested in this relation browser
instance we we were still working with
via the bureau of labor statistics kind
of data so we were we really
wanted to look at search tasks simple
look up more complex look up the simple
look up was just you know pretty much a
a single concept the complex look up had
not only multiple concepts but the more
abstraction in in the concepts and then
the exploratory search that was much
more open-ended we're also interested in
different sort of user interfaces and on
in here's where I think things really
went probably a little bit too too far
we were interested in the actual
architecture and the interaction style
the interaction style being kind of
query versus a selection or browsing and
the architecture being really well
formulated user-generated metadata
that's hierarchically presented at or or
presented in a in a in a human centric
sort of way versus automatically mind
that metadata in our relation browser
instance so we probably needed to have
actually more variations of the user
interface but you know the problem there
too where would we get all the subjects
right and so the the problem was was
probably overly ambitious in terms of
these two sets of independent variables
and so we we did two three by three
kinds of designs with one between
subjects and on within subjects which
also complicates things now imagine
writing the methodology section for akai
or CGI our paper which you probably have
like one column or like maybe a page
where you can explain this and you're
trying to explain all of those decisions
you've made after sitting in a room
together for a year or something like a
year to make all these decisions right
this is I think the heart of our problem
is how do we actually capture all of
that thinking that goes in the rat the
rationale the reasoning for the kinds of
studies we do and we're always sort of
interested in just the results but I
would claim that sort of our design
competition the channel
here that started last year may give us
a little bit of leverage to begin to
push on on that problem it's it's a it's
a hard one and and i would suggest in
the age of data which we hear all the
time we're in the age of data we somehow
addressed from information anyway we
that that we probably should make these
these processes more visible to people
and i don't have a real good solution on
this but i hope you'll think about it
now not only did we have to pretty
complicated independent variables but we
had a lot of dependent variables and
this is I think fine I think this is
this is actually a very good thing to do
the problem is when you very often find
when you're dealing with humans that
it's hard to get high correlations
between your dependent variables in the
sort of direction you like them to be in
and so yeah it it's it's another one of
one of the things that that sort of
causes us to have to be somewhat
apologetic when we go to say say guy our
community and say take my paper or even
the chi community so what did we learn
from this really complicated you know
literally I think did take a year to
plan the study to build all of the the
stimuli the different tools the system
that collected the data and and sort of
ran the study in a controlled sort of
way well we learned that you know
automatically classifying some of the
the bureau Labor Statistics data web
pages was okay I mean it certainly
wasn't as good as what BLS had done by
their handcrafting over the years but
you know it did all right and the the
other thing that was painful to learn
was that the plain old BLS website was
preferred to our really cool interfaces
you know and and and even from our sort
of the in-between faceted
sort of browser that we built as kind of
this intermediary and you know it's
about familiarity in comfort levels I
think you know maybe that's a
rationalization but it's that kind of a
message that is really difficult to sort
of explain to people well what did you
learn what was your system better did it
win what's better about it well yeah
yeah it was pretty good so how do we get
over this well I I don't I don't know
the answers to that question I will I
will end on sort of a discussion about
the one particular aspect but let me go
to a sort of a third case one that's
still going on now the results based
project which is a little bit newer
probably four years or so now the the
notion here is how can we actually
support results the the fact that you've
done a query and you get stuff back is
pretty much the end of story for a lot
of search right but it's certainly not
the end of story for humans because you
know that's actually kind of only the
beginning and how do we be begin to give
people better results page it's it's
pretty amazing that lists of snippets
still work as well as they as they do I
can't we do better so the notion here
was can we begin to get beyond the query
and search a sort of part 2 examining
results manipulating results and
possibly doing so in collaboration so
the notion was searches over time and
possibly in collaboration and the main
sort of system advance that came out of
this was 'shrogs Co Ackman tow system
which supported collaborative
acronis search and I have to hand it to
Chirag for recruiting all of those dyads
of people who who came to multiple
sessions in this dingy old little room
in the ceiling of Manning hall and
actually showed up twice and all of that
just logistical nightmare right and and
yet he was able to sort of pull this off
and and demonstrate that this awareness
of what people are doing while you're
searching with them is really pretty
important and and how can we begin to
take advantage of that awareness and
make it more informative in revealing to
two partners is is I think the main
outcome of that work right now Rob Capra
and Jaime arguello are and I know well I
lost and I'd like are working on looking
at at a similar kind of study with
asynchronous collaboration as as people
are not actually working in real time
together how can we provide support for
them what's the value of actually having
a sort of a strategy meeting at the
beginning where you say okay we're going
to we're going to do what gene and
Jeremy have sort of suggested with roles
and assign roles or assume roles or
we're going to divide and conquer what's
the value of that versus just going at
it letting people sort of do search ena
on their own so stay tuned on that and
we'll see what we can discover I guess
here there have been probably a more
equitable set of field studies versus
laboratory studies they still like the
laboratory studies I'd really love to
sort of get the perfect laboratory study
to work I've yet to have one of those
but the field studies actually my sort
of experience have taught me this
insights where you sort of say oh wow it
didn't sort of think of that and then
that maybe become become the basis for
something that you test in a laboratory
study that's the way you know your
research methods class would tell you
that it should work and sometimes it
actually does I guess one little
anecdote with some of our video work
when we're doing studies of audio
surrogates and we were trying to look at
the interaction that you value belit for
visual surrogates and audio surrogates
to be synchronized now we know that for
video if the audio and the visual are
not synchronized it's a bad scene right
you never want that to happen but I
suspect that if people are really
looking at surrogates that assuming that
we can believe the notion that we have
multiple channels for processing
information that we probably don't need
to have those things actually
coordinated because it's unlikely that
the visual scene and the audio scene are
both having the most salient piece of an
entire video clip the most salient
visual might actually be different than
where the audio is taking place is so if
you're showing people the visual most
salient audio visual scene then maybe
actually having them here something else
that's most salient is better all right
so that's what we're trying to test and
so sounds great right nice theoretical
question sounds like a dissertation and
it was and yeah we're doing these really
cool studies and Amendola the Lamb
watching people do the study and I see
that there are folks who are in that the
three conditions you know the pure
visual the pure audio and the mixed and
there are people in the mixed who are
closing their eyes while they're
listening or looking away
right now I never would have sort of you
know thought of that or see or yeah that
wasn't part of what we were trying to
learn but that's the way people are
right they're actually pretty smart and
so if we don't have that kind of
combination of the ability to look at
the sort of field environment the
natural environment then our laboratory
studies are going to be somewhat
impoverished this is a theme you'll hear
again and again so let's get to the
heart of the talk challenges they're
about at the evaluation I think and a
lot of this is about sort of mixing
methods you know integrating the
quantitative and qualitative people and
I think the the information schools have
actually done a pretty good job of doing
that integration it's you know it's
still bumpy you might you know you want
to go back to the old AI sort of
phrasing can we get the NEETs and the
Scruffy's to work together
you
I don't think
about human interaction by just doing
laboratory studies and you can't learn
by just doing the field studies I think
they really have to go hand in hand I
just don't have a good algorithm for
that I mean that my sense is to say
without the the natural studies the
qualitative type studies should probably
come first and that then allows you to
generate hypotheses that you can test in
the laboratory but I think it actually
can work the other way as well and so
this is something I guess I'd like to
hear some discussion about if you've had
experiences going the other way now
you're doing some some laboratory
studies that then and not just because
you got so frustrated from doing the
laboratory studies did you know sort of
fell back to the quality but where
there's some really substantive things
that occurred that's that caused you to
say I really need to look at this in a
much more naturalistic and perhaps
intensive but not as expansive sort of
sort of way um I think we have lots of
challenges to understand information
seeking behavior getting beyond
retrieval to extraction this this notion
that it it really has we've gotten
beyond the content becoming accessible
that my little sort of the anecdote
about doing the Eric search or having
somebody do the Eric search for me you
know we're well beyond that the contents
there is actually not so much finding
any more fact we find too much but
filtering in but we have to get too into
the content and it's right there on our
face pretty quickly so as that becomes
the norm then the distinction between
search and consumption of information
internalizing learning understanding or
as dan would say sense making it grows
less distinct and so retrieval it's nice
if you can just focus on retrieval but
you know I I don't want to say it's a
dark it's us it's a solved problem
because we certainly is not but it's
getting harder and harder to
disambiguate the retrieval part from the
consumption or or learning part and I
claim that surrogates be more valuable
as a result because they become the
transitions from the retrieval to that
deeper understanding I think there are
in there's a transition from individual
to group that gives us some challenges
and of course then the whole you know
user experience thing so this is by no
means a comprehensive list of sort of
challenges but these are the kinds of
things that I suggest we should be
wondering about so queer equality now
you would think that this is a pretty
basic concept right you know if you
can't judge whether this is a better
query than that for a given problem well
probably don't have any business running
a search engine but it's a really hard
problem and and so you're trying to sort
of take this sort of usually the first
signal that we get from a user and make
some sense out of it to try and help
them Dave caramel and yom tov have done
a nice job of sort of looking at
different strategies of pre retrieval
and post retrieval sorts of approaches
this problem I apologize publicly Orion
Wyatt for working with him on a study
where he did all the great work and I
tried to you know deal with this query
quality stuff and it just it was it was
not quite hopeless but it we didn't get
very far the the notion was to try and
have a panel of non cert search experts
but people who weren't doing the
searches judge the post hoc quality of
queries that had been expressed and and
to see if we could use that as a metric
and it was it was okay i think the
students again the students learn
something and you know I i find that
unfortunately a more and more that
that's that's the not all I can say
about
a lot of our studies but it's you know
it's not quite the the same thing as
saying we advanced the science to the
point where you know we now actually are
able to do something a lot better that's
really what we want that's what the
nature of research is and it's
devilishly difficult in this this realm
perhaps we can extend this and and say
well okay what about the quality of user
profiles is there a way that we can
begin to assess the profiles that people
express on the web and you know you can
imagine all the different social media
profiles not to mention the cookies and
things that you know are on people's
machines and how much confidence can we
put in those profiles and I don't know
if the same kinds of techniques will
work most of the techniques have been
back and sort of techniques in which you
look at the documents or the social
media the people but there may be some
sort of front-end kinds of things we can
do on query profiling link densities who
knows how do we use search behavior as
evidence in the actual behavior not the
end result lots of work of this in the
sort of implicit feedback and
collaborative filtering a sort of arena
I want to sort of single out Shen foo
who I think did a really interesting
methodological spin on on this problem
to investigate implicit feedback instead
of trying to say well you know where the
usual thing is to match queries to
documents says well can we match
theories can we match the behaviors the
traces of search to queries I was a
clever strategy created a corpus of
queries you happen to be under specified
queries then
got really rich captures of people doing
those searches including I tracking
traces and of course law of video logs
and as well as the usual transaction
logs and then got a bunch of reference
librarians kind of expert searchers who
didn't know anything about these queries
to watch one of those different sets of
traces and try to infer what were they
looking for and at and and how do they
make those descent and of course
articulate what the evidence they were
using to make those inferences worth and
do that using confidence in those
inferences as one of the measures so
it's a very clever way to kind of
reverse the process and III think that
you know what I'd like to see is kind of
more ways of sort of thinking a little
bit outside the box on the sort of the
classic way okay we're going to take
these queries now let's see how these
queries match on to documents or people
or whatever we haven't be looking for
and do a little bit of around the block
in this case the around the block was to
bring back those intermediaries those
green faces that disappeared you know in
nineteen eighty or so so my own sort of
I guess pet challenge is still how do we
create effective surrogates and then how
do we measure their effectiveness so
this this little graphic is meant to
suggest that there's there's kind of a
you might think of the two axes here as
the vertical axis is effort whatever
however you want to measure effort and
there are lots of different think about
it and then the kind of complexity or
abstraction on the horizontal axis so
you might might operationalize that as
the number of relationships that exist
and there's this a sort of psychological
process of recognizing well perceiving
than recognizing making some quick
sort of justine assumptions something
that we might call understanding and
then all the way up through the the
usual Bloom's taxonomy of analyzing
evaluation and surrogates I think come
in down here near the lower left-hand
quadrant of this grid and there's a lot
to be said for work that a creates novel
kinds of surrogates and B tries to
assess their efficacy and it it seems to
me that I I personally would put some of
my effort here if I have any time lately
there's some other challenges about
loads you know the cognitive load is
been well studied lots of good
psychological studies there's the sort
of standard instruments like the TLX
from NASA people have used secondary
tasks to try and assess cognitive load
great stuff I love it and I think we
should continue to look at cognitive low
but there are the kinds of loads that I
haven't seen as much so perceptual load
what's the perceptual load of actually
working in this sort of web environment
in which everything looks the same no
it's not like the real world where every
time you go to a different part of your
office even the things are different
where's here yeah it's not the same
screen it's the same keyboard and it's
all coming through this kind of single
kind of view and so the perceptual load
sorts of issues are I think quite
interesting a Felix Portnoy a current
student is has hypothesis that for
exploratory search is interested in
banner ads and you know how people sort
of get sort of used to those annoying
ads and we never even see them anymore
because we've sort of totally tuned them
out while have we really I don't think
so but somehow at the cognitive level we
have and so looking at the end
action of banner ads aliens the the sort
of intensity of of the gatt itself and
different search tasks is what he's
studying and I think that'll be one the
you'll want to pay some attention to
eventually but the one that's probably
most of interest to us all here is
cognate a collaborative load so um
Chirag and I had this probably debate I
suppose a friendly debate for years now
at and and I guess I'd like to suggest
that you know when two people work
together they're less efficient I heard
Eric say that I don't can't wait for
that poster all right so yeah well and
we all know this we all noticed you know
do a proposal with someone across campus
right I how many meetings do you have to
have before you really sir oh that's
what you mean you know so now the belief
and and and and the religion of the time
is collaboration interdisciplinary
studies you know work together all this
yeah there's something there's something
really good about this but we're not
really paying attention to what are the
costs so the the study that we never did
that I'd still like to do there's a guy
in journalism has the same eye tracker
as I do and we thought would be kind of
interesting is to look at people
collaborating across a distance and and
and sort of studied the actual loading
effects now people have done this in the
cscw community in the psychological
community for looking at the channels
and sort of maintaining the Colet the
actual communication channels you know
you look at the word utterances right or
the type of typing streams you see how
many of these can we classify as being
you know just keeping the conversation
going hey hi how you doing are you still
there you know that sort of stuff that's
that's a load that's a cost and it's
necessary but it's there so how how do
we begin to kind of minimize that in
collaborative search alright here's sort
of that big old challenge session
quality search quality the overall
problem solution I mean recall and
precision which we all
is there there point-based metrics and
we have to keep that in mind I mean
sometimes things get worse before they
get better and that should be taken into
account in looking at the overall
efficacy of an information seeking
experienced you know the I think I've
said enough about controlling multiple
variables there's this notion of the
installed base the the installed base is
what people know what people expect and
that continues to evolve so it you know
it's not fixed all right because people
learn they adopt new kinds of strategies
they become used to certain sorts of you
is or or interactions and it's kind of
you know trying to change that is
difficult and it has to be put into
context so by my quiz is here's a a
search session let's say and I don't
care what kind of measure you want on
the horizontal axis here precision or
recall or how many smiles people make
which is actually is not a bad measure
and I mean horizontal axis are the
different sort of acts that you might
think of them as queries I suppose are
we both that's and the the Green Line is
a one that sort of minimizes the
distance from the beginning state to the
end state at whereas the blue line the
solid line is one that sort of goes back
and forth which is a better search Don
orange orange oh yeah oh yeah tricked me
yeah it depends ah the solution that's
the answer to all the research questions
right it
hannahs it depends on the first game its
antigen and averaged over okay but let's
pursue that I like that so if we using
sort of mean average precision or
something and we average then the
straighter line kind of wins all right
keep that right doc
well III mean maybe it doesn't involve
suffering though yeah yeah yeahs era
okay so more knowledge sort of covered
on and then gene in it
okay okay good good summary yeah like
that sure does
right
okay the user I'm only talking about the
user here yeah well well maybe I should
just start it with this and this could
have been the whole discussion the IIIi
think this is the kind of question we're
sort of not really grappling with enough
and certainly it depends but this
actually might be a way to disambiguate
sort of maybe exploratory searches from
non-iron searches right if you look at
some behaviors and you see this kind of
I mean it's like sorry I mean if you
think this is from driving around I just
need to go to the grocery store and I
know where it is and I just want the
shortest route but you know if it's kind
of a nice day and I especially if I'm on
my bike and I'm not quite in such a
hurry then the hovering more distance
actually is more gratifying right so yes
the task matters the context matters but
the trouble is that too often we're
putting in boxes in which we have to say
this is better according to a rubric
that is checked off by this community
okay and it's and it's that sort of
thing that I think we suffer from all
too often okay so last slide I promise
what might help lots of stuff certainly
better experimental a pariah you know
more let's share more stuff I mean I
keep hearing about you know you've got
to save your data and if you want an NSF
grant you have to say how you're going
to do it right and that's great but how
can we how can we save our data I can't
even run the old relation browser demos
anymore because the servers don't you
know run that level of tom cat that you
know doesn't run on the latest version
of red hat that you know you go I don't
want to
with that will just make a video and put
the videos and and so how do we how do
we save how do we share the experiences
the processes so those of you who
participated in the challenge fantastic
work I mean I'm I'll bet all of you
spent more than 10 or 15 minutes all
right now what happened on all of those
to all of those discussions to all of
that thinking of all of that processing
that took place you know you're going to
have a little bit of time to explain
what you did but not enough right so how
can we begin to share those processes
you know is there some kind of
repository that this community should
build that talks about wacko experiments
run away or I or you know what I wish I
had done after having done this and
here's what I did I I think we could
probably get some leverage by trying to
do more sharing of all sorts of records
so I kind of like video so I'll
emphasize that a more than perhaps
others but you know we should we should
do a better job with this can we use
crowdsourcing you know probably happy
you've used Mechanical Turk for
something but you know are there other
things we can do to make sort of get
people involved and capture those
processes shared instruments you know we
all create surveys and and instruments
even in my own experience getting the
you know the incoming students are going
to do the next thing to share their my
sequel database and PHP code that
captures the study the experimental
study yeah very difficult longitudinal
traces of things can we like have
explanations or recordings of processes
that you know go for more than a
semester or go for more than that one
study I'm especially thinking about
individual people you know I'm all for
from our eyes and biometric kinds of
data i think you know we learn from
those things they're expensive we don't
know how to really do them very well but
i'm sure we'll see more attempts and you
know what sort of came up in several the
posters wouldn't you love to have all of
the queries that a hundred random people
do on their iPhone with Siri or the
Android poison remember I am what can we
learn from that what would you do with
that data okay so lots of challenges not
the only ones we've made a tremendous
amount of progress from those earlier
Eric search days there's lots more to
learn last last week I was at a event in
Oliver Smithies Nobel laureate and
medicine was being interviewed by a
journalism student and she goes well
he's about 80 and she said are you still
working and he said young lady I've
never worked a day in my life I've been
having fun I've been playing my entire
life and I suggest that what we do our
work you know wheat we sweat over
getting those papers accepted and
agonizing over how to design those
studies and do our analyses but in the
end this is fun and let's have more fun
thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>