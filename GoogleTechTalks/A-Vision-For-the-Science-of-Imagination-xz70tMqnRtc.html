<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Vision For the Science of Imagination | Coder Coacher - Coaching Coders</title><meta content="A Vision For the Science of Imagination - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Vision For the Science of Imagination</b></h2><h5 class="post__date">2010-11-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xz70tMqnRtc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hi everybody I'm Anthony Francis I
work in the search quality department
and in a former life I was a graduate
student at Georgia Tech working on
making computers smarter and it's my
pleasure to introduce to you today Jim
Davies who was my colleague at Georgia
Tech and now is professor at Carleton
University Jim studies visual reasoning
and cognitive science through the tools
of artificial intelligence and is the
director of the science of imagination
library laboratory at Carleton and he's
going to present a talk today on the
science of the imagination
thanks yes the title isn't on the slide
is the science a vision for the science
of imagining so I'm I'm a scientist
trying to study imagination I'm gonna
talk a bit about what imagination is and
why anybody should care about it then
I'll talk about some of the theory
behind it and what's been done and what
could constrain imagination how we node
to do what it does and then finally I'll
talk about what I've been doing in my
laboratory and at what the future holds
for science of imagination
so imagination is the way I look at it
is how people picture things all right
so there are two kinds of views of
imagination the basic one is creativity
and the second is visual instantiation
so creativity this is what people talk
about when they say for example that
somebody has a good imagination or
something a story is imaginative or
somebody says oh I have no imagination
at all this is kind of equivocating
creativity and imagination as having the
same meaning that's one one sense in
which we use the term the this the other
sense and that's the one I'm going to be
focusing on is what I like called visual
instantiation and that is how you
picture things in your head ok and it
doesn't have to be particularly creative
so I made eggs this morning
and if you can picture that you might
picture a stove and a floor and I might
be in my pajamas or in my clothing and
you will put things in that image that I
didn't say okay if I say I cooked eggs I
said nothing about a stove or a floor or
a house I could have cooked eggs about
by a campfire but your brain your mind
collects a bunch of things together and
creates a visualization of that and
that's what I'm focused on another
visualization task you might do is if
you imagine the capital letter T if I
ask you how many corners it has be
required to use visual thinking to
figure out that answer to that nobody
has stored how many corners are in the
letter T unless you've seen my talk
before okay but if you picture it you
can go ahead and count and reinterpret
what you've seen so why is it important
well when you start thinking about
picturing things you realize that it
happens all the time
recent studies in day dreaming have
found that we spend about 20% of our
time daydreaming 20% of our waking hours
daydreaming of course we spend a lot of
our sleeping hours visualizing too when
we dream but any kind of hypothetical
reasoning planning for the future
thinking about the past there's a vast
array of tasks that require visual
thinking and imagining hypothesize
scenarios there are some scientists
every every psychologist likes to talk
about what's the one thing that makes
humans different from animals anyway one
of them one of these psychologists said
that it's the ability to picture virtual
things that don't actually exist okay
and we're all very good at this so if I
have a I have a cup of coffee here if I
were to toss it down into that stairwell
you wouldn't know at a physics level
what would happen but you could all
picture basically what would happen and
you'd use your visual reasoning to to
know that the top would probably come
off and coffee would spray everywhere in
these vague terms you'd have an idea of
what would happen they've also found
that if you picture yourself doing
sports
you actually are better at doing the
sport this is pretty remarkable they
found this number 30 different sports
just sitting there thinking about doing
it actually makes you better at doing it
so imagination is terribly important
very very important and I'm trying to
crack it and level a level of detail
such that I could get a computer to do
to do it just the way that a person
would so these are the influences I've
actually at one should be added to this
here but we've what constrains your
imagination so if I said I made eggs
this morning you know you could picture
hippopotamus in the scene you probably
wouldn't okay so what would a scientist
use to constrain what would be in that
visualization what would not okay so
what we know about the world is this is
knowledge like to cook eggs you probably
need something to cook with some kind of
source of heat usually a stove something
like that you have mental models of how
things work and you'll use these mental
models to help know what to put in the
picture but at a similar level we've got
the the your visual history your history
of your visual perception everything
that you've ever seen in the world okay
so here we are ready to talk I've got a
badge on there's a screen there's a
microphone I'm tapping at a computer
these are things as you've probably seen
many many times so when I ask you to
picture someone giving a talk you are
likely to put those things in there
simply because they've tended to be in
those images in the past all right and
that's what my work focus is on is try
to mine the visual memory for to know
what goes into an image and an
instantiation and where it should go
the final thing that should be on this
slide is probably the the task
environment that you're in when you're
asked to imagine so when I say imagine
eggs or if you're reading a book or
someone's telling you a story and your
picture what's going on obviously them
telling you the story or somebody asking
you to picture something is going to
influence what you've imagined okay so
now I'm going to talk a little bit about
some of these constraining things of
what science has found and this is this
is hard stuff most people think of
imaginations being really hard
to study impenetrable to objective
measures and I will grant you right now
that this is not an easy field to be in
but there are ways to do it I think
you'll be surprised at some of the
cleverer things people have come up with
but the hypothesis in my laboratory is
that a great deal of our visual
imaginations can be predicted simply
through the regularities in our
perception okay so if you are to when I
ask you to imagine a cat versus a dog a
dog has a higher likelihood of being
outside in your imagination than the cat
cats tend to be indoor animals in this
part of the world I talked to somebody
from India recently who said that cats
and there are many many stray cats in
India so perhaps if you've got that
different visual history you'll be more
likely to picture them outside than in
this part of the world but if you grew
up in this part of the world a cat might
be typically an indoor animal okay I'm
going to talk about some of these
constraints here so the first one I'm
going to talk about are the
psychological findings there's a bunch
of there are a bunch of people in
psychology doing research that is
relevant here I'm a cognitive scientist
I use a little bit of psychology
philosophy and computer science
primarily to do what I do I focus on
artificial intelligence but my lab does
run some psychology studies and I
certainly read them and use them okay so
one quite famous bit of research is the
research and categorization called
prototype research where people have
these prototypical ideas of what things
should look like so if I ask you to
picture a bird
most people will imagine a small singing
bird very few people will think of an
ostrich or penguin unless they are
trying to be particularly creative or
they've got some other reason to think
so
but we found this that in many many
instances there are these prototypical
elements and this is even true for
shapes if I ask you to imagine a
rectangle you probably aren't going to
imagine a square
even though squares technically a
rectangle and you're probably not going
to mention a rectangle that is two feet
or two inches wide and a mile tall okay
that's a perfectly valid rectangle as
well but it's not prototypical they've
even found prototypes with numbers there
are prototypical odd numbers better
examples of odd and even numbers so when
I ask you to imagine a cat or dog
eggs you are going to imagine ostrich
eggs or lions you're probably going to
imagine the prototypical cat egg etc
there are also canonical views of
objects there's been some research
particularly by Michael Tarr who's found
that there are certain views so this is
what you're looking at right here me
this is a prototypical view of a person
okay it is a valid view I'm still a
person if you're looking at me from the
top and all you can see is my head and
head and shoulders and maybe the tips of
my feet but you don't tend to picture
things that way and that's true for a
lot of objects bicycles and chairs and
all these kinds of things it gets used
in the debate over whether we picture
have 3d representations or a bunch of 2d
snapshots but it's relevant for
imagination research in that I will you
are more likely to imagine it from a
canonical view this gets particularly
important when you're trying to get a
computer to do it because if you've got
a 3d model like in your Google Sketchup
thing or whatever it doesn't really
specify what the direction is where is
it supposed to be viewed from but there
is data on that okay so this this is a
neat little study this is the most
direct view into somebody's imagination
I've ever seen this is crazy
so what they did was there are some
scientists they showed people white
noise okay you see these well it's not
really these aren't pure white noise but
it looks something like that TV on
channel fuzz kind of kind of business
and they showed people 20,000 of these
so it took a long time and they said
some of these have the letter s in them
and some of them do not now none of them
have the letter s hidden in them okay so
people are like clicking yes I see it no
they don't and people tended to choose
about a quarter of them as having the
letter S in them okay this is top-down
processing when you're looking so hard
for something that you see it even if
there's if it's actually not there now
what they did was they only did it for
three subjects because it's so
time-consuming but when you average the
ones they said yes to you can sort of
see the ghostly image of the s that they
thought they saw okay so here's the
actual average and you can't see much
but if you clean it up a little bit you
get these things so these are the three
subjects you can see that they all had
different font
which is really amazing to me so this is
you're giving them noise and they're
imagining the letter S and you get this
thing with a fun this person's
participant Li does not have serious so
this is a this does not scale needless
to say it's torturous to the subjects
but you know there are ways to to look
directly into somebody's imagination
soon we'll have brain scans that allow
us to do it even better
another thing that I would like to do if
I can get myself an eye tracker you've
all heard of eye tracking it's it's
where you have cameras on the eyes you
can see where people are looking you
usually do it with some kind of stimulus
to see where people are looking on the
stimulus but what you can also do is
have them do it in just darkness and you
describe a scene to them like oh there's
a dog and there's above him is a bird
that's looking down and the person will
look into the darkness where those
things are and you can get an idea where
everything goes based on where their
eyes are going so you see we get all
these like indirect ways of trying to
figure out what's in where things should
go and what should go in the image all
right so there are there's another body
of research coming from linguistics
image schemata there's also a growing
interest in embodied cognition now this
is this is interesting up tends to be
good okay this gets reflected in our
language like things are looking up or
anything up has this metaphor of being
good and down as being bad or sick or
dead or something like that
and you know this this turns out in our
language all the time it also is part of
the folk wisdom of movies and theatre it
turns out that good motion right to left
or left or right depends on the way that
you read so left to right motion is good
in this culture in the english-speaking
culture and if you'll notice and if you
watch movies The Wizard of Oz Dorothy is
almost always moving left to right on
the on the screen every time Neal gets
into a fight in the matrix
he's running left to right as enemies
running at him from right to left if you
go to countries where people right in
the opposite direction it is reversed
okay so how does this influence
imagination well if you're if you're
picturing something that you that you
value as good you are
more likely to imagine it going up or
left-to-right than you are going down so
this would constrain that and there are
all kinds of metaphors this year I don't
claim to completely understand but I
think everyone can intuitively get
what's happening here this is a cartoon
by Steinberg in The New Yorker and we
have a tuba blowing its sound and
there's no sound associated with this
here's a harp noise it's it's a
visualization of what the sound is and
even though but I bet you that anybody
could match these images to the
instruments I bet we'd have that a lot
of agreement that this is more like a
tuba and this is more like a harp
looking sound okay so this is stuff that
we're just starting to crack open and
trying to to to figure out what ways to
visualize things that aren't even visual
like music okay and this is really
relevant to scientific visualization and
the growing field of visual analytics
and the information deluge that everyone
is experiencing in sciences and
information technology where we need
ways to make pictures to make sense of
things and if we can understand people's
natural inclinations to picture certain
things certain ways and we'll have a
much better time creating visualizations
that make sense ok so now we're going to
talk about mental models so I mentioned
this before here but part of
visualization in addition to just your
visual history is that you know how
things work and you try to use it this
is very hard to model because it is
knowledge intensive where I can use a
database of pictures to try to get at a
visual history I actually have to go
through and describe the mental model
for each object to be able to reason
about it this is a problem that AI is
always struggled with how do we get all
the knowledge in the world encoded into
a way that a computer can understand so
that's part of why I'm not pursuing it
very strongly right now but it's
something that will be necessary to get
good visualizations the computer needs
to understand how things work to get the
visualizations close to perfect or
usable
now spatial reasoning happens much more
than we knew say twenty years back okay
a very interesting example is with time
it turns out that people picture time
spatially in our culture we talk about
the past being behind us all right so
way back then we use the word back okay
and you'll they found that when people
talk about time they gesture in
accordance with that so in our culture
when we talk about Oh back when I was
young they might refer behind them
futures in front of them in the past
behind that might seem completely
unintuitive to you but there are
cultures where the past is in front and
the future is behind and they think
that's totally normal because well
obviously you can see the past you can't
see the future that's there that's been
Asian for it and then when they gesture
they refer they do the same way it's
like back in the past and they'll refer
in in the front now although it's
interesting that the different cultures
have different directions for past and
future what's important to me is that
everybody represents time spatially okay
and if you really want to mess yourself
up try to present a graph where time is
going right to left in your graph or
something like that okay so we've got
these cultural conventions and more and
more we're finding that there are
spatial metaphors for abstract concepts
it it appears that we are using our very
basic spatial reasoning processing in
our in our minds to make sense of
abstractions and other cultural
artifacts that have subsequently been
invented okay so getting more into the
computer science II part we've got a
bunch of visual databases that we can
use to try to collect information about
perceptual histories game I think I
think Google might actually own a
version of it or something but this is a
game in which it's a fun game that is
meant to collect important data so
here's how it works
two people see the same image and
they're trying desperately to type in
the same words but they can't
communicate they're randomly
paired up on the internet so here people
are typing in corridor columns and if
they write the same word they both get
points and it moves on okay and after so
what's great about this is that you if
two people type the same word it's
probably a good word to associate with
the image because you have that
agreement okay that's that's the key
inside of this and after you're pretty
sure that the word house is associated
with this image it becomes a taboo word
for future players okay this was
invented by a Luis von Ahn who's made a
bunch of games like this the whole field
was called human computation okay well
what's good about this is that you end
up with a database of images with
associated labels that you can do image
searches over whatever but that one he
did
Nina's students made another game called
peekaboom which has now taken down
because he's replaced it with a game
that he thinks is better but what this
is it one person sees a black square and
another person the other player sees a
picture with a word so here we have a
cow and it's got the the the word cow
associated with it and this person is
trying to get this person to type cow
what they can do is they click on parts
of the image and they are revealed over
here and this person is desperately
looking at the revealed parts trying to
figure out what the hell was talking
about and it's and when they say oh it's
a cow you type cow and then they get
points then they move on and these words
are taken from the ESP game we know what
labels are associated with the images
because we got them from the other game
now we're finding out where they are so
here we know that the cow is roughly
here in the image and not in the lower
left corner because that well those are
the places that needed to be revealed to
get someone to successfully guess it
this is from label me it's a database
that tries to do the same thing but
without a game format it just requires
people to volunteer their time to go in
and do it it has two disadvantages one
is that it's not a game so it's not very
fun so people just have to be willing to
it's not mean it's not very fun to
outline things in an image so people are
less likely to do it but the other thing
is it doesn't have an internal error
checking so people can and I've seen
this they've just outlined random
section
of the of the image and given it names
either at real labels or just made-up
words
polluting the database and making it
less useful so when you've got this in
the games when you make people agree
you've got this internal checking
mechanism nonetheless the label mu
database has a lot of stuff in it
squiggle is the game that von Ahn made
that is supposed to replace peekaboom
and what happens is two people see an
image and they get a word and they're
supposed to outline it and the the
similarity of the outlines determines
the number of points you get okay
now and you might have heard a Google
Sketchup this is a 3d image database now
I when I'm trying to create new images
I'm trying to do it mostly in 2d now I'm
going to be moving to 3d very soon and
I'll be using databases like Google
Google Sketchup in various warehouses of
free 3d images so I can populate virtual
environments and I'm going to yeah okay
so now I'm going to talk about
okay right so my goal here what is it
what am I trying to do I'm trying to
automate imagination I'm trying to make
a computer program that can create a new
image that is realistic
when I say realistic it makes sense and
it's like the kind of thing a person
would imagine okay so if I just get to
imagine me talk it should know to
populate it with chairs people a
microphone a computer a screen without
my having to tell it explicitly to do so
okay and the applications are many
automatic illustration okay this is this
is could be important for scientific
papers or for entertainment purposes
creating diagrams level design for games
okay so you've got these games now games
are more and more games are
three-dimensional and they've got these
large virtual worlds that need to be
created by hand this is true in video
games this is also true for movies and
more and more computer graphics are in
movies there are lots of movies that are
completely in 3d computer graphics and
the vast expense with these movies is in
artists okay you you've got a lot of
programming to do but there's an artist
behind every little tree and every you
know every element in that design and if
we can automate that we can get more
more bang for our buck and in case all
of you are thinking Oh Jim's trying to
put artists out of work well kind of but
I will also say that I think it's a
shame that we have to wait a year for a
new Pixar movie when if it was automated
we might be able to watch one every
night that is based on our what we saw
that day okay that's very far off but I
see the world moving in that direction
if we can automate any any of this
design it'll be a great win for creating
these worlds it's not just for
entertainment there's training
simulations the military and medical
lots of people are starting to create
virtual worlds for training and they
need to be realistic and it's a lot of
effort to create the world and
once they create the world it's good for
a person maybe once because then they
know the world and they the learning is
reduced when they use it again it's like
playing the same video game again and
again but if it can create new worlds
every time then the learning might not
slow down as quickly okay I've talked a
bit about how we can study it these are
some other other things we can do I'm
not going to go into them they're quite
psychological ok so now I'm gonna talk
about my laboratory and what we've done
in the laboratory so I'm in a cognitive
science department that gives me the
great advantage of being able to do use
whatever methodology I want to try to
get at the problem and was something
like imagination that's very important
so the first and most successful thing
we've got is a program called Visio okay
so we all can imagine to greater or
lesser degrees one thing that we're all
good at is imagining quantitative
magnitudes okay I said let's use size as
an example but it can apply to anything
that you can put a number to so if I ask
you to imagine a chair you will imagine
a chair and you'll imagine that chair
being a certain size probably a
realistic size okay but if you go into
most 3d databases databases of 3d models
they don't give you the size like in
feet or something like that so how does
a person how is a person able to do that
well you have in memory some kind of
indication of the size of the object and
you can use that but we're also very
good at imagining things that we've
never seen before or never even heard of
before so if I say imagine a tiny
Cheshire cat you all have no problem
doing that you've never seen I'm sure
you've never seen a cat that was labeled
as a tiny Cheshire Cat but you're able
to do it
how so this program is designed to come
up with those values how big is it big
tree how how long is a very short rope
okay this is what this thing is trying
to do and the program is able to imagine
things that it has never experienced in
its database here's how it works okay so
the mascot for my school is the Raven so
my student used crows and ravens for the
example so let's imagine that you've
seen a whole lot of crows in your life
you've seen a whole bunch of crows and
you've seen them you know so they all go
into a distribution so ignore this fuzzy
number business on the bottom just
imagine this as a distribution of size
of all the crows you've ever seen it
forms a roughly normal distribution now
some of them have been labeled as large
so somebody said oh look at that large
that's a really big crowd really large
crow there's a separate distribution
created for large crow so you can see
that it's shifted and it's smaller and
the variance is smaller other things
let's also imagine that you've seen
Ravens okay now Ravens are rarer than
crows they're also bigger than crows you
can see that this distribution is a
little bit shifted but they're rare and
let's say that you've never seen a raven
that was labeled as large you haven't
seen enough Ravens in enough situations
for for anyone to have said oh that's a
large raven so how large is the large
raven gonna be that's the that's one of
the basic problems here how do you know
how large to make the large raven oh if
you've never seen a rate of raven
labeled as large because large although
it seems like it's an objective
objective kind of transformation it's
not a large mouse and a large oceanliner
are very different the difference
between a regular Mouse and a large
Mouse is smaller than the difference
between a regular ocean liner and a
large ocean liner so all of these
spatial adjectives are dependent on the
thing that they are modifying so the
insight that Visio has is that it uses
analogy with semantically related things
to know how much larger to make it okay
so in this case this is what the program
outputs this is what Visio outputs an
estimated distribution of how large a
large raven is
it uses fuzzy numbers to represent this
is a neuron thing here so neurons have
receptive fields and they fire they
increase their firing frequency
depending on how close to what it is
exactly they're looking for that the
stimulus is so we have this fuzzy number
distribution to represent an input so
there are two phases of this program one
is this input phase where it sees a
whole lot of things that's just its
experience it's like you seen crows and
ravens and chairs and coffee cups and
improv groups and scientists for your
whole life and then you've got the
visualisation phase where you ask it to
imagine a you know a small scientist or
a long person and every time it sees
something it represents it using these
fuzzy numbers here it's not very
important if you want to ask me about
that later I can talk about it but it's
a distribution over different numbers
and their memberships so what happens is
it looks through the database if you ask
you to imagine a large raven it looks
through the database looking for
something semantically similar
so you've seen crows you've seen
buildings you've seen ocelots you've
seen chairs well what is the what is
most like a raven
well crow so we use the word net
semantic similarity there are a bunch of
semantic similarity measures out there
and it finds the thing in memory that is
closest to it that for which we do have
a large distribution then Vizio finds
the mathematical transformation to turn
one distribution into the other so we've
got all crows here we've got large crows
over here how do we turn the
distribution of all crows into the
distribution of large ghosts that's a
mathematical transformation then it
applies the same transformation here and
then it generates an Imagine
distribution of large ravens from which
you can imagine a single large raven
okay and it has some very neat
properties I'll give you some
qualitative results and then go into the
quantitative results so in this image we
can see that it is shifted what I mean
by that is that the the Ravens
are bigger than crows so we would hope
that the large Ravens would be bigger
than the large crows in indeed we can
see that that's true so that's good ok
here we have differences in variance so
here we can see that the Ravens have a
smaller variance than the crows crows
have more variety if you need a good
example dogs are a great example okay
dogs have enormous variety an adult male
dog depending on whether you're looking
at a chihuahua or a mastiff have a great
great variance in size compared to
pigeons for example so you would hope
that in the imagined large Ravens you
would have a smaller variance and indeed
you do these are these are actual
results from Visio now when I say their
actual results these are actual results
with made-up numbers we don't have
numbers of how big crows really are I'm
working on another project to get those
numbers but right now these are just
made up it's just to demonstrate that
the reduction in variance is maintained
this also works with high variance here
we have the Ravens are a very high
variance and we see that the resulting
distribution also has high variance okay
so if we're gonna look at the I'm sorry
this is probably not readable but what
these are the quantitative results here
and basically we show that the take-home
message of this is that the error rates
for the estimated sizes are small so
here we have trying to imagine a thin
cat a medium cat or a thick cat
okay these are this is taken from the
peekaboom data so remember I talked
about peekaboom where people isolated
where things were in an image what we
did was we calculated the height weight
height width ratio for width height
width height ratio because it's distance
independent the problem with these is we
don't know how big something isn't an
image because we don't know the distance
from the camera but the ratio should
stay the same and what it did was it
retrieved dog dog is the most similar
thing in the memory of all these things
here we had about 10 things and then it
estimated the ratio and if you and then
we did this with Raven person dog poll
building and so what it's doing is it's
you're asking it to imagine a
hi width height ratio cat but it's never
had anything has never seen anything
labeled as such and it's guessing how
what that ratio is going to be and the
overall average error rate is six point
nine eight percent which i think is
small it's hard to know what to compare
it to but it's it's it's fairly accurate
when you compare it to the actual width
height ratio and another interesting
thing is that it greatly depends on the
number of objects in the database so
there are lots of people in the database
there are very very few crows and ravens
and when you have more things it gets
better this should be no surprise to
anybody in this audience but there are
lots of applications where just adding
data makes it work a lot better
the peekaboom database only has 57,000
images with an average of 12 labels each
when we get into the millions we will be
I'm sure that these error rates are
gonna go down even more so that's the
visual program and we're gonna use that
we're gonna use this thing because we
need to know how big things are right so
when I asked my computer program to
imagine a office it's gonna need to
figure out how big everything in that
office is going to need to be and if I
say imagine a large tree it should know
how large to make the tree and come out
with an actual number so that I can put
that in the image with a really concrete
size it also works in a less interesting
way but it does work with prepositions
so if you ask for a airplane above a
mountain it's gonna give you a different
number than a bird above a tree because
the airplane should be much higher above
the mountain okay so even words like
above prepositions like that also our
context dependent on what they're
referring to okay we also have a need
for understanding prepositions in human
beings so when I say that something is
above something else you might think
that oh that's easy just look at the
let's look at the axis and if it's above
that axis then it's above well it's not
that simple so
let's see here the it could be that a
cup on that rack over there is
technically above this podium but no one
would describe it as such okay I might
be you know to the right of my
University but who's going to describe
it this way okay so when something is
that far away it's less likely to be
called above so there's this like sweet
spot of above the podium that sort of
starts here and like looms up like this
and you have to figure this stuff out by
looking at data collected by linguists
and and psychologists and stuff to
figure out what above really means so
anyway we've got one project where we're
trying to make computer programs that
emulate this kind of detection okay so
what it does is we've done above below
and close to an occlusion and try to
figure out what it means so we I
actually have my students do this in
class projects I had they have to pick a
new spatial detector that's never been
done and create a detector for it in my
AI class and they have to read the
literature in in cognitive science and
figure out what these prepositions mean
and then try to replicate it as best
they can
so here's above and close to was an
interesting one because it depends on
the size of the frame it turns out that
these two things are perceived as closer
than these even though it's the same
physical distance because people do use
the size of the frame to help
something's actually close to something
else but this kind of stuff is really
important because when you ask the
computer to imagine something you might
use these prepositions so if I say
imagine a clock on a wall or a cat on a
sofa those are different right
particularly in English where on has
these two meanings a clock on a wall is
against it and and flat up against a
wall in different languages these are
different these spatial prepositions are
all over the place
Korean has a different word for fitting
loosely and fitting snugly for example
right so these are English specific I
don't want to say that these are general
human kinds of things but I got to start
somewhere I'm gonna start with English
if I can get a computer to imagine
things from English input I'll be very
happy
so we're trying to create these models
of spatial prepositions I'm gonna be
presenting this work at the diagrams
conference up in Portland
here's occlusion okay figuring out if
two things are covering one another and
in peekaboom this is an interesting
problem because all we have are point
clouds so here we have the red dots for
a in the and the blue dots for B how do
we know which ones including what well
one's going to be in front of the other
one but if B were in front of B were in
front we probably wouldn't see a so a is
probably in front there are three
different kinds of occlusion we try to
calculate and you can see where with B
extend and try to estimate where these
things are going to be and come out with
an occlusion metric and this is good if
you want to say that a cat is in front
of a tree or something like that and
we've actually applied this to make a
little mini search search over the the
peekaboom database which is only 57,000
images but what you can do is you can
say a hand above a plate and it actually
returns hands that are above plates in a
way that's realistic with the way a
human would which I haven't seen before
in a image search okay so reminding
peekaboom and reminding label me and
probably squiggle too and anything we
can get our hands on for relationships
between things all right co-occurrence
is a big one if a computer always
appears in the image with a monitor or
does so 30% of the time or 90% of the
time that's very important for our
system to know because if you ask you to
imagine a computer it's got to imagine
more than just the tower right it should
imagine a desk and a keyboard and a
mouse and a and everything and
co-occurrence can get us that okay very
simple you look at all the images in the
database you see what tends to be in the
image with computers not only that but
because we have information about where
they are in the image we can know where
they're supposed to go so we look at
like the angle in the distance and we
can know that the keyboard tends to be
below the monitor and we know by how
much and we know about how much we can
see that into this
so for any given image we can figure out
exactly how much that's supposed to be
and we can populate a 2d image with
what's supposed to be there okay using
probability and all this kind of thing
not only that we analyzed those things
with those spatial detectors I just
talked about in the previous slide so we
know what's above what's below what's
close to what's far what's including
what's not what's in between okay so
that when we know which ones are
examples of that when people who so that
when we ask the system to imagine things
like that it can say oh I know what they
mean by in between now you don't need to
be able to read this this is someone
else's work that's we're moving into 3d
now okay words I is a program out there
I'm trying to eat my hands on it but
it's it's been difficult but according
to the paper what you can do is type in
something like this an orange umbrella
is on the same is on the small patio
table a window is behind the table a
small red umbrella is five feet behind
the table etc you go through all that
you give this textual input and it
generates this 3d image it can also do
lots of fun things if you say like the
devil is in the details if it doesn't
know what details looks like it just
puts the word so it has a picture of a
devil and the word details sort of
surrounding it it's fun so this is
related work and we're trying we're
basically re-implementing this and
trying to do something like it so that
we can create 3d things now there's a
there are a few we're trying to find a
good platform that we like and if anyone
has any ideas I'd like to hear about it
but we want to use some kind of open
source virtual world to put these things
in there's a there's a community called
open sim which is a kind of a open
source clone of Second Life and it's got
its problems but it is open source and
we're thinking of having our computer
programs generate virtual worlds that
are usable by open sim however the
people who work on it are mostly
interested in socializing so there's not
a whole lot of physics when you touch
something basically the avatars hand
goes out and dotted line goes from the
the finger to the thing so for modeling
human behavior it'sit's limited at this
point but there's always hope for
open-source things they get better and
better but we want to actually create
virtual worlds to me I think it would be
really fascinating to be able to tell a
computer system
imagine a virtual world that has a lot
of mushrooms and darkness and just have
it populate the entire world just as a
human designer would so those are the
things going on in the laboratory I also
want to say with this co-occurrence and
co-occurrence and images and knowing
where things are we are also trying to
improve object recognition because
object recognition right now does not
tend to use context okay so if it
detects a computer and a mouse and a
monitor
it doesn't look for a keyboard we know
to do that
okay but if it looks like you know a
penguin on a desk it's gonna say I
detected a penguin ignoring the fact
that it's unlikely that there's a
penguin on a desk okay so but with with
this database this model of what should
be in images we know what it's likely to
find it works so we're trying to modify
an existing object recognition system to
give it better results we make an
advisor based on this imagination model
so to conclude the imagination is
terribly important people use it all the
time I firmly believe that we'll be
spending more and more of our time in
virtual worlds 3d virtual worlds as the
hardware gets better and as computer
processing gets better we're going to be
spending more time in virtual
environments and there'll be a great
need to automate the creation of these
things both for conferencing and virtual
travel entertainment training
simulations and all this and all the way
to making movies if you invite me back
for our talk in 20 years I'll tell you
how the automatic moviemaking is coming
along but that's a tough one but
personally I'm very excited to see what
kinds of what kinds of images that these
virtual that these can
are going to create for us and what
they're going to put in at this point we
can only imagine thank you very much we
have a few minutes for questions
happy to take some yes 20 use a mic
further questions ok so the latest
version of Adobe Photoshop has as
impressive feature they call content
we're editing if you see yes yes I have
I've seen the demo demo and so they they
take a tree and delete it and or a road
and delete it out of the scene and the
thing fills in the rocks and rock
pattern so I'm wondering you know what's
going on there how much does it you know
bear on on your research and you know
how much is the system just sort of
extrapolating maybe some you know
fractal patterns from the nearby area
versus kind of recognizing a bit more
what's going on okay so what he's
talking about is part of a broader field
that's including something called photo
stitching where you can there's a lot of
work on this you could take like two
photographs and like stitch them
together to look like it's one
photograph and there are even systems
where you can say wedding kiss sailboat
tree and it goes from the database and
it puts them together and makes an image
that actually looks relatively coherent
I'm going to be using that technology
for creating 2d images so the short
answer to question is it's very relevant
but so okay so content removing
something out of context what it does is
it takes find some pixels elsewhere in
the image in Photoshop it only uses that
image okay in the I was just at SIGGRAPH
at this the SIGGRAPH kind of people the
people doing research at the technical
talks there use databases of images to
give them more power but what it does is
it finds some pixels that are similar
and it fills it in with those that
doesn't I don't see how that's going to
scale to 3d so for the 2d stuff I'm
definitely going to use that kind of
thing and I'm in conversations with
unfortunately they all have a user
interface and I need it to interface
with my with my AI so I'll probably have
to get a programmer to work on that for
me but yeah that's I follow that that
research because it's really important
so they call it stitching in general
photo stitching is yeah putting two
photos together in a way that makes
sense so you might have your favorite
search engine that you can type words
into and it'll come back with lots of
images that you can run correlation
analyses on you know for example you
know Bing and to what extent are you
able to use these kind of commercially
available products to do some of the
things that you're working on you know I
haven't thought about it a lot but I'll
tap dance a little right now you know I
can type in I can type in cat and get a
bunch of images with cats in them what I
don't get is for each image what else is
in that image so if I could type in cat
and then get a whole bunch of images of
cats but also a list for each image of
what else is in that image that would be
great
most image search engines to my
knowledge use surrounding text to know
what's in it or what words are relevant
and that might be different from what's
actually pictured and what I ultimately
need is which pixels are a cat in which
pixels are a doorknob and and and and
there's a slightly different goal with
image search right if you type in
victory you want you know you might want
somebody like going through a finish
line but well actually I actually I
would use that too actually if somebody
wanted to pick your victory I guess I
would want that too so that's relevant
but that's that's the reason that I
haven't really looked into it you see
what I'm getting at or is there a way
around that I don't know can you put in
an image and get the work can I type in
I mean can I like query with an image
and get what words are associated with
it with any search engines now
I would use the mics for the recording
reasons I don't know if this is entirely
relevant but I read some article that in
Korea they're doing this thing with ads
that there to serve ads against it
they're trying to understand what's an
image they have a whole database worth
of images and they're reading the image
directly not the text surrounding it for
a visual context so they like you know
see that there's a boat in the image and
they're trying to use other images and
match it against it and say using using
computer vision yeah using computer
vision oh I'd love to I'd love to see
that okay yeah it's hard to remember but
there and just as a note it might not be
something that's available through the
interface of search engines but if you
actually talk to the people at your
favorite image search engine I'm pretty
certain and that there'd be a way to to
access the data that you're talking
about because it's it's implicit in the
way the databases are structured right
okay that'd be great I mean I'm I would
love some kind of collaboration with you
know a big search engine in that way
because right now the 57,000 images are
not enough and I there's a I saw a talk
at SIGGRAPH where they said you know
when we tried it with 20,000 images it
sucked and we went up to 2 million it
suddenly worked and I have no doubt that
this is gonna be one of those instances
yes I'm kind of fascinated by those
games
you showed hmm and I've confessed my
ignorance I didn't know about these
things but how popular are they how much
is that being used on the Internet
I don't know but it's it's generated a
lot of data if you go to GW AP comm guap
it's games with a purpose okay we've got
a whole bunch tagged a tune and they're
whole bunch and I've just created one
that I haven't published yet but to try
to get sizes of things and distances but
yeah if you're gonna if you're gonna
waste time playing a video game play a
game on gwap because then it's not a
waste of time you're helping researchers
like me and helping the world out got
time for another question or two dr.
Tulio
yeah so I was wondering about how bounds
some of your the stuff coming out of
your lab is as to what's sort of like
bounded in reality because the images
that you're using are they all
photographs of real things are they
drawings so if you ask me to imagine a
big Raven I might or a big cat I might
imagine something that's fairly
plausible if you asked me to imagine
like a giant cat then that would be
something that you probably wouldn't
have a photo of does that make sense so
would your you know if you pose
something like that to your software
would it be able to come up with things
that aren't bounded by you know the
potentially real world input that you've
given it know right now the best it
could do and it's not even totally
working yet but I it will be soon if you
say a giant cat it'll take at regular
means if it can make it big and that
obviously is not ideal a large like a
person that's thirty feet high well I
mean physically probably wouldn't
wouldn't be able to walk at all but to
be a good visualization of it would have
to have thicker legs and this and that
move more slowly but yeah we don't we
have to have the ability to do that yet
I see so you'd also have to have sort of
like the physics and you know how that
would actually work out in a 3d world
yeah that would that would be a lot that
would be a lot more work and the other
thing is that this database of images is
they're images from the web they're not
even necessarily photographs
so there are cartoons there are logos
there are all kinds of there all kinds
of things so you know we have in our my
students when they have to make this
above/below detector you know they have
to look at a the nike swoosh and a you
know a tagline and say is the swoosh
occluding the tagline you know that that
those are the kind of things that has to
deal with but we can specify only photos
but really the way I look at it is we do
look at logos in real life and those are
those do influence our our
visualizations and we're using images
from the web as a proxy for human
experience which is questionable but you
know until we have people walking around
with cameras on their heads and
recording everything that they've ever
seen and we get them all tagged you know
that's what we'll be working with can we
take one more no more okay thanks
everybody for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>