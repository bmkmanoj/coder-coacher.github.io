<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PostRank: Intelligence from the Social Web | Coder Coacher - Coaching Coders</title><meta content="PostRank: Intelligence from the Social Web - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PostRank: Intelligence from the Social Web</b></h2><h5 class="post__date">2011-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rwE_Eg5iiIU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">on that threat now there could be many
reasons why there is many votes are many
comments or many discussions on Twitter
it could be that the article is
controversial it could be that it's not
completely wrong and people are just
this dream with it we don't make any
judgments about the actual content on
that page you know we we don't try and
figure out if it's a good article or a
bad one you know technically speaking
anything like that we're just saying
look this specific page is getting a lot
of conversation on the web today it's up
to you to figure out what that means in
your own context so all these
conversations are happening across web
what full strength does effectively in
some cases crawl in some cases we get
you know a fire hose of events basically
we have a variety of mechanisms to
gather all of this activity data from
all the popular social hubs and that
includes on-site and off-site comments
as well so for example he you know our
crawlers will actually go up to fetch
the page detect where the comments are
on that page you know tally that up and
repeat that process every softened to
make sure that we gather on-site and
off-site metrics as well so all along
today we gather about 20 million plus
activities so this is across 20 plus
kind of most popular social networks you
know so anything and everything popular
that you can think of we know we do have
some access now I'm missing out
everything from Facebook Twitter reddit
digg hacker news you name it we got it
kind of thing and we've been archiving
all this data since we started so we
have an archive about nine billion year
olds and or 9 b 9 billion activity
events around your calls and the
observation here is we're not storing
this data for specific set of URLs right
we're starting across all so for example
in the case of Twitter will ingest all
tweets that have your browser and just
record that for some point later so such
that we can service it with another
application
so what exactly is an engagement event
it's you know we've iterated through a
number of approaches us to how to define
engagement but intuitively it's very
simple right and there's a couple of
components broadly speaking that make up
on engagement to that one is the actual
weight of an event and this one is
pretty simple and it's arbitrary and
when we started we basically like that
okay so now you have different ways of
engaging with the page you can link to
it right you can bookmark it you can
comment on it you can do all kinds of
stuff and each of those actions requires
a different amount of effort user of
just in terms of performing that action
so for example let's define an arbitrary
scale right let's define a scale one to
ten and say that a page view is worth
one point just because we don't know
anything about the fact you view the
page but did you like you that you not
like it how much time is spent without
having kind of on site analytics we
don't know now let's say that you
writing an article links back to that
our goal is worth 10 points because
that's kind of the gold standard of the
web the link then you know somewhere in
between in terms of amount of effort is
something like engaging in a
conversation on the site itself right
leaving a comment so it's called had
let's say five points right so basically
we defined this pyramid of engagement as
we called it and adjusted over time
based on the rankings that you know how
our users perceive the rank is not the
rest so the way it is pretty simple yeah
there's a question
sure so the question is you know do we
distinguish between retweets and snails
or some other forms of engagement right
sure right so oh there is no difference
to us in terms of if you just press the
retweet button or you actually you know
just that your tweet provided your own
comment today so today I'm right right
now for Twitter we're basically looking
at what's the number of mentions
primarily although that's a good
question because I'll get to that in a
second we offered starting to adjust
that as well to take into account some
context information so first there is
the weight right that's that's a pretty
simple attribute and then next one is
the rank so rank is something that we
started adding fairly recently I'm
instances that something that we've been
working on for the past year but we
started rolling this out three or so
months ago and we're doing is
incrementally across different networks
so the idea there is previously he will
give us a rebel or a set of euros and
we'll tell you oh yeah and this one had
50 bookmarks on delicious and 60 people
retweeted it all this kind of activity
today what we're doing is because we're
getting all of this activity stream data
from all of these social problems right
so think of it as kind of the fire hose
of all the fire hoses which is what
proof aggregate and we're ingesting and
we also have profile metadata about each
actor and we have historical archive of
what kind of stuff you share in all the
rest so we're starting to do or we've
done actually is where we've aggregated
all of those profiles so today we have
from north of 60 million profiles across
all these different social networks and
we're linking them together right so
we're actually able to say oh you're
this Twitter user but you're also this
reddit user based on social graph data
and also matching as well so we're able
to link all these profiles and then
based on you actually
say well are you power user of the snap
for example or for each now requite
define our own set of attributes so it's
a mixed model we rank you against all
the other users on that network and then
we have basically a score 1 to 100 score
which indicates you know what is the
weight of your activity so an example of
this would be lets say Tim O'Reilly
share is an article about some tech I
know share shares tweets that points to
my blog and that's fantastic because Tim
Riley has a lot of followers those
followers trust them and that's going to
drive a lot of traffic versus you know
my friend Bob just joining put who has
two fathers in tweeting that previously
we would have counted that is the same
amount of engagement now we're actually
adjusting that to say well you know Bob
two boys is the point to a point of an
engagement point but for Tim well that's
maybe worth 20 points right so we're
incrementally rolling this out across
all of our networks and that's that
that's a big deal for us and there is a
couple of different models that we've
iterated even there you're building on
that example of Tim Riley now does it
doesn't make sense to say if Tim
O'Reilly votes on a story and read it
but Tim O'Reilly is not a power user
reddit does it make sense to give more
weight right so we're able to link all
these profiles and say yes this is tim
o'reilly but is it the case that we
should attribute his voice morbley
something that we're still experimenting
with just in terms of em algorithm and
all the rest but that's the approach
that we're taking and as I said how
we're doing on this point crawling the
social graph you know we certainly make
use of API is provided by by Google and
others we also have wrong crawlers that
augment that data we have our own
matching algorithms to crosslink all
these profiles because
you know as great as the social graph is
today it's still feared sparse so we
often have to do what we call the deep
crawl across all these networks find in
all the nicknames and they make sure
that they all line up and you know a
certain probability when all the rest
and that in the future what we actually
want to get to you know this is kind of
the big adage call for us this year is
to start looking at context and what
that means is now because we have all of
the activity that you've generated we
actually have a lot of metadata about
what kind of stuff that you've done or
kind of stuff that you like so for
example if you follow me on Twitter
you'll very quickly discovered that i
tend to share a lot of programming Ruby
related links so next time I share link
that points your Ruby resource you know
that's that's a good better that's a
good contextual relevant and all the
rest tweet going on to my network but if
I turn around and share a link to a
fashion blog he can probably discount my
my influence if you will on that topic
by by certain margin so what we want to
do is actually augment all of our user
models with sub notion of what do you
like to talk about what is your topic of
expertise if you will so we'll see how
that works out obviously the big
challenge there for us is just scaling
that in terms of now we need to build a
model per user now we're has currently
word be that we we have a this
promotional kind of a distribution
across you know what would makes up a a
power user on any given network so at a
high level postrank aggregates all of
the activity from a whole bunch of
networks so on left here you guys can
see some of them there's 20 of data sort
of 20-plus data sources 20 million plus
event and then we process all the data
in real time and basically persistent
variety of different ways to a person
doing different and interesting types of
analysis so at the very bottom level we
wished or each individual event with
time
stamp such that we could say now for the
specific URL here is the activity graph
or here's a time series of how this
conversation has developed and this
leads to some very interesting analytics
that you guys will see in a second then
there's the just the overall aggregates
and real-time counters in terms of at
any given point you can give us a
troubling we can tell you that as of ten
seconds ago 30 seconds and go this is
the amount of activity that's been
around this year there is we do other
roll ups like domain and feet activities
we can do reporting on the main level so
if you guys are familiar with services
like compete or alexa or some of the
others this would be an equipment or but
from a social perspective so comparable
stuff and then there is the actual real
time activity stream which is the who is
doing the action what action are they
performing what URL are they talking
about so at the very top level that's
that's what postrank is all about so
we've been iterating on you know let's
find all of these conversations the web
social people are engaging with content
in many different ways across many
different sites let's aggregate all of
that and make it available for you know
analytics search anything like that so
here I actually want to show you some
some examples and this is kind of the
the temple part of the presentation and
what I can do is if the death of gods
are good can actually show you some live
examples instead of slides so we have a
fairly popular google reader plugin i
assuming the eyes of his group over here
this is the original problem that i was
trying to solve for myself right i mean
this observation that i was using all of
the social data to basically adjust my
own writing in terms of here's content
that might readers like here's what they
didn't like so on so forth so I had this
epiphany where said well if I could
aggregate all this data for all the
other side then I could use that
filter so the first iteration of
postrank was actually for RSS filtering
or he could you could say you know I
only want articles that have a lot of
conversation around them and this is
effectively what the chrome plugin does
it pulls them so you just install the
extension that pulls on the data life
and as you can see it has post make
scores on the side now and the postman
exporters us pork 1 to 10 it's it's a
normal highest human readable score the
actual engagement score which is we're
talking about previously it's kind of
this app to track number you know from 0
to whatever but here we're just trying
to normalize it and what you can do is
you can actually filter the content here
so I can say well they have to only show
me the stories we can spit out the story
is that our below us are intractable the
humble Oh 5.4 or 7.6 and I want to go
5.4 you can scroll down and you can see
that as you as you go down it'll just
pull in the pulse ranks and show you the
stories that are getting a lot of
conversations on web so personally I
find it very effective way to kind of
filter through the noise and find
stories that have actually been picked
up so that's you know that that's a
discovery use case you know we've also
built some fun prototypes for stuff like
search so for example you submit this
query and everything goes well come on
okay enabled in search
shouldn't have reloaded have you here so
as the search results in our ever fallen
we also pull an automatic data you know
when would we know about this year
hasn't been in share on any in social
networks non the rest and here is here
is interesting example so this was matt
cutts tons and tons of engagements
100-plus comments on this page lots of
trackbacks across a little networks in
all the rest then you know to me this
one stands out because it has three
thousand engagement points which is can
our own measure and you know compared to
everything else in the page it's much
less so you can imagine how you know you
can play with sort data and figure out
which of the URLs that are getting a lot
of attention like why is if you use you
know sites like hacker news or read it
you can also use a plug-in to detect
which stories are getting a lot of
conversation on the web so sometimes
it's just interesting to compare what
different networks like to talk about or
share non dressed now we've done we've
done stuff like top posts which is for
publishers so one other aspect that full
strength does which I haven't described
yet is we actually index RSS feeds as
well so make it make we make that
content searchable so as a publisher you
can come in and you can get one of these
widgets so for example i can grab my own
as my own site it preloads it here so
what it does is show you a dynamic list
of the tories that shared the most were
you know generated the most
conversations across my site and then
you can also do a search so hope so for
example ii i've written a couple of
articles about this the 0q framework so
you can do the search general it'll
search the archive find articles attack
buds your human done sort and by
engagement so that's kind of a fun demo
and these are what i would call you know
we don't have twenty percent time but
these are weekend projects so
scratching an itch the leaders wanted we
did something that's near and dear to my
heart is you know I tend to watch a lot
of TED Talks we launched this last week
where we said well you know hey there's
like thousands of these things let's
actually apply our update and sort them
by engagement you know which is the one
to generate the most conversations so
you can for example navigate into the
technology section and get this stuff
you know 300 plus or whatever it is
talks sorted by the amount of
conversation they've generated on the
web so these are all kind of examples of
we have these APM is we have all this
metadata bet how are people engaging
what are they doing with this content on
the web let's apply it and this is a
product that we've built so postrank
analytics a couple of observations that
we made early on that we agree it all
this data we ran some analytics and
realize that broadly speaking there's
two very interesting trends the first
one is that eighty percent going to be
or your rule of thumb eighty percent of
all the conversations about publishers
content happens off their site so what
that means is if you have logged over
you a news site and you post an article
and you have comments enabled right and
it wasn't that long ago that it wasn't
as far back as two years ago and we were
talking to mainstream publishers and
they they're telling us there's no way
bring enable comments on our on our site
can you imagine if users were able to
leave comments on our stories never
never of course either later they all
turned it on but even though they you
know whether they turn it on or not most
of the conversations eighty percent of
the conversations are happening
elsewhere so that's Facebook that's
Twitter that's all these other different
social hubs and of course from a
publisher's viewpoint you're what we
call traditional web analytics whether
that's log analysis for some JavaScript
chocolate you have installed can't
that they they can't tell you where the
conversation is or what the conversation
is about certainly it can tell you that
hey you've got 300 refers from facebook
or 300 refers from Twitter but you won't
know who was the individual what they
said dead like its own sofa so that was
the first insight and of course we have
all this data and the second insight was
that when we looked at the actual
distribution of when does the engagement
happen because we have all no
time-series data we realize that in
another rule of thumb the half life of
an internet story or a news story on the
internet today is about an hour right so
in terms of conversation Patriots and
all the rest first power is what is
worth fifty percent of all this happens
and part of that or in part that's
driven by how the social networks are
architected so for example you know dick
and reddit are great examples they
actually penalize you if the story's all
right so they actually in one in their
ranking algorithm they'll pull your
story down if the older it gets so it's
very hard to get to the front page of
your stories add a hold and in cases
like Twitter Facebook well you know if
your friends don't read your tweet or
wall post in the first our chances are
it's going to be on the fifth page
they're not looking at that right so you
really have to know how to execute so
what's the best time to post a story are
there specific individuals to whom I can
you know share this content first so
we'll then republish it to other
networks not the rest so giving those
two things we realize that hey there's
opportunity here let's build an
analytics product for publishers what
can surface that data right we don't
have to reinvent the wheel and redo all
the page you tracking and all the rest
in fact we did pull of you know Audrey
users and realize that virtually all of
them had google analytics installed
right go Hollis has the right price
that's called free it's it's great it's
got a lot of data and
gives you a lot of voice to faster than
all the rest so when we start building
this product inside okay let's take the
base the poor metrics so stuff like
pages unique stall the rest from google
analytics will upward that but then
let's layer over our social date on top
right and give you a different view so
i'll give you a quick tour of postrank
analytics so have my sights set up in
here so i'll just navigate into that
actually i'll open this guy as well so
what we're doing here is my site is
integrate google analytics so for
example all the page you and uniques in
all the rest and that data is coming
directly from the google holics API but
what you can see here is two grams on
the bottom there's pages so this is time
series from all that extend at the top
is our post drinks engagement data and
you can see that you know there's peaks
and valleys in here and the peaks lineup
so at certain point you know something
has happened on my site which generated
more PA jews and more engagement so
because postrank tracks you're my RSS
feed in this case we're actually able to
annotate these events and say hey this
is when you published that new article
on your site right so in this specific
case was you review 19 features or in
this case was the handlers are to plug
in post that you did so we can annotate
that and we can correlate those events
and of course you would expect that you
know when you post a new story get a
spike in traffic because you have all
your purse a subscriber is coming to see
it but likewise is generating all this
activity on to web the one anomaly you
can see here is this guy there is no
posts around it so that's that's
interesting right what happened there
and our article we'll see what happens
before we go there i want to show you
that the activity stream is what I was
describing before so I'm sure you guys
are familiar familiar with friendfeed or
at least the concept where they would
aggregate all of your activity kind of
in one stream what we're doing here is
effectively providing friendfeed for
your content so we're aggregating all of
the
conversations all the activity events
with your content and showing you in
what place so for example on march forth
you know somebody bookmarked my one of
my articles on our services twitter
share the link on twitter to one of my
articles then somebody bookmarked smile
on delicious and they use the tag ruby
and all threats they can you can go down
and seek on all the conversations around
what are people doing how would be
engaging with the stuff as a publisher
that's invaluable because i can actually
see what keywords are people using
wonder bookmarking my stuff right now
very very interesting feedback so let's
actually drill n into one of these
couldn't go to analyze here in analyze
you can see a chronological view of all
the stories that you've that you've
posted on your site and the key
performance metrics so events shows you
the number of distinct activities so
this is a bookmark or a commenter all
the rest and at these events translate
into some number of engagement points
and of course you can see all the actual
distinct that let's drill him to the
specific guy so now we're looking at a
specific article and you can see you
know the full trend for that specific
article in terms of page use and the
actual engagement that happens with the
article as well as we can actually focus
on one of these dates and see what
happened right on the first day there
was a lot of Twitter activity 73
retweets but then something happens you
know almost a week after the fact so
this part here and you know if you zoom
in and you look at this you'll actually
see that there's one metric that stands
up and that's a chance port so that's
that's hacker in using score so what
actually happened there was my Oracle
got shared by somebody on the hacker
news site it got to the front page you
know got 54 votes there are 17 comments
and not draw that page spike a week or
so later so that already tells me a lot
about what happened and this a great
example of social network doing is
stuff or driving traffic to my site now
we have integration with Google Google's
goal values so you can see up the these
are the values and values I've defined
for my site and there's some feedburner
integration so all in all we're trying
to provide kind of a holistic view for
the publisher these are the pages that
happened off-site this is the number of
pages that have been generated to your
RSS feed these are number of pages that
have been generated on your site these
are conversations that are happening
elsewhere right trying to bring it all
into one view and that's this data is
invaluable to publishers because it's it
allows them to to see me all of the
conversations at once and social is
becoming more and more important as a
traffic driver for economies now you
know we also provide some other
functionality like you can look at your
three-month trends so for example you
can see that you know forty-four percent
of all my engagement or at least my
audience engagement is happening on
Twitter delicious is big hacker news is
big too kind get a visual breakdown of
where are people engaging with my
content what kind of the tags you know
keywords that are generating the most
engagement and in this case there's only
one author myself so I get a hundred
percent of all the engagement yay
optimized is an interesting section for
us what we found was most publishers
today don't understand social or how to
engage with social and this comes down
to even just plain education right
somebody starts and blog on knitting and
believe it or not there is thousands of
logs and knitting they have no idea how
to engage on all these different social
hubs so what the kind of information
they're looking for is very basic at
some level right they just need to
understand what is what are the
demographics how do i how do i actually
distribute my content on on facebook is
there something I can do there plugging
i can install is there a specific set of
you know things i could do and so we
provide all that information but we also
show you knew or influencers or people
who are already engaged
with your content on these sites so hey
maybe you've never done anything on
facebook but here's an individual that
are shared 10 links to your content
maybe you should engage them in
conversation right and next time you
publish an article push it out to them
early why not right they'll they'll
distribute it to their to their own
father's so you can go to hold the
networks you know find out the
demographics and all the rest now if I
go back to the beginning now when we
launched this product we allowed each
accounts to have up to five sites and
our thinking was well you know we'll
actually get users who have five sites
will add all of them and you know track
their analytics turns out what almost
everybody is doing with with the seven
hits they're putting in their site and
then we're putting in for their
competitors and this is a really
interesting and key insight
differentiator for us at postrank all of
the data that we collect is public right
which means that we can provide
virtually all the same data that you
just saw from my own site for any site
we can show you the conversation in back
your competitors we can show you all the
trending information and not the rest
you don't have to install and in fact
even when you install this on your own
side you don't have to install the
JavaScript Raptor all of the data is
already there right it's already sitting
in our database so for example like you
can click into the Google Analytics blog
right and in this case I don't have
access to the actual google analytics
and data but that's okay because I still
have all the full strength date so you
can hover and you want these and you can
see all the posts that have been
generated on the engagement has been
generated you can see the activity
stream water people saying about this
content that's being generated and you
can also drill him into one of these put
into any one of these pups and see what
happened right now okay hold there's
been a lot of conversation on Twitter
you can read the actual comments and not
the rest so in practice this is
incredibly valuable tool for publishers
to look at their
petition and figure out that 08 they
wrote this article yesterday on this
topic it's gotten this engagement and
they can use that as a feedback loop
into their own editorial process or or
whatever one thing I that demo is custom
pages so if you deal with custom pages
just just like what you just saw with
Google Analytics here you can add any
page right so we don't lend you to say
oh you only have to track pages on your
site if you produce a fantastic youtube
video you can just put it and we have a
PDF link you can give us that link and
we can tell you that hey people are
sharing tweets that point directly to
your PDF we can still give you that data
so its on-site and off-site kind of all
rolled into one so that's been a very
very popular feature for us so I mean go
pack here's we talked about search so
benchmarking I talked about competitive
intelligence that's obviously a big deal
for us and in fact a lot more
applications a lot of our clients today
are using our data to power competitive
intelligence type stuff so as I
mentioned before we do domain and feet
level aggregation so you can type in any
you know three domains that's just a
quick demo that we put up on our site in
our labs and get a visual breakdown of
which some domains are getting a lot of
engage so for example you'll see that
seventy-five percent of all the
engagement for toyota's coming from
press room right so clearly they're
doing something right there so there is
analytics on that level you know where
we do track your RSS feeds we do have
all the content indexed so in fact we do
have a blog search engine if you walk on
Red Hood we don't tend to talk about it
just because that's not the primary use
case so that's we don't really surface
it in that way but you know we're able
to rank sites so for example if you if
you have list of sites related to any
prints
killer topic would be that web analytics
/ you know white blogs or anything like
that we're able to do all the analytics
in real time and that we talked about
the actual postrank analytics all the
trending and on and off-site
conversations tivity stream and
benchmarking so at this point I'll take
brief pause any questions and he no I'll
good all right so the second half of
this it's the the technical part and
here I'm really looking forward what
kind of things you guys are interested
right so i will talk about kind of been
more broad terms as to what we built and
how we built it but at least we solved a
lot of interesting technical challenges
at full strikes so happy to dive in into
any specific quantity if it comes up as
with februari 2011 we're indexing about
20 million new events a day and about 5
million new posts or RSS content pages a
day I'm that you're roughly speaking
that's about 50 gigs of data that we add
to our index every day and in terms of
the actual ppi's and all the rest we
cover all our own applications based on
on our own API is enjoy the same API is
the weights posts or partners now there
we tend to do most of our software HSP
so that today that translates roughly to
about 500 request since i came across or
API our architecture broadly speaking
has two big components there's the
content indexing and under is the
metrics or the activity stuff so for
content we aggregates and we crawl the
web in sense we consume it through ping
servers we have to pull we we certainly
make use of stuff like pop some pop up
we have our SAS brawlers which are a mix
of you know we have the performance
critical sections and see a lot of
action
code is Ruby you mixed with C extensions
where we need the speed we take all the
XML you know we transform it to JSON we
do normalization because of course
there's at least 30 different flavors of
RSS so normalize it to a kind of a same
standard that we can use internally
transform to everything to utf-8 just so
we can search it sensibly with your
language detection because most blogs
either a misreported or don't report
correctly and you know a bunch of other
stuff we do basic sentiment analysis not
nothing extraordinary they're just kind
of for fun just to see what we can get
out of it now somebody's against the
extraction on the rest we impacts all of
that data in leucine leucine and solar
so that's that's a charted setup that's
hid behind our API is and that's
ingesting all that data we provide
real-time filtering so we actually have
clients before example so cute words
with us and say hey any time you pick up
new content about or let's say
blackberry on the web and a head that
has a certain amount of engagement
higher than acts right center our way
and so we're able to do that kind of
stuff or we can just stream you the full
the full pipe of content that postman
can just so the HTTP or other protocols
then there is the metrics so kind of a
similar thing there's many different
ways we aggregate this data there's in
certain cases we have to pull so Commons
is probably the best example on site
comments there's no standard
unfortunately for you know how many
comments are there on the sorrowful so
we actually have robin scheduling system
and all the rest were once a new store
is generated we we throw it into our
scheduler and they'll be periodically go
back and check how many comments the
store has generated and that's based on
the amount of activity that the story is
generated suing or if there's odd
conversation around the story we'll
check it frequently if the conversation
dies down we kind of throw them back and
at certain point we just stop but that
requires prodding that means we have to
download the page basically figure work
not pay
is the actual comment section because
that itself is a fun problem that we had
to solve and then emit Adams metric in
certain cases we can use stream api's so
you know something like Twitter be a
good example so that we push the data to
us that's obviously our preferred way to
get this data and in some cases we have
to actually hit some other AP a-- we
pull the Activity Stream normalization
so likewise each one each of these
networks specifies around format
appropriate different amounts of meta
data and all the rest so if you
normalize that all to an activity stream
format you know what's the actor is the
verb what's the action and then stream
that through our system we do social
graph resolution which is something that
we talked about earlier that's
incrementally rolling that out with the
ranking because that's that's obviously
a big step for us and it requires a lot
of resources and then you know once we
basically we've taken an event something
like that tweet has happened about this
year about you can go through as it goes
through a set of stages where we
normalize it we augmented with multiple
strength data and at the end it
basically goes to a fan out where we
have a lot of our internal subscribers
which are listening to the screener just
incrementing all three counters and all
the replaces and all the different
databases to say okay you know i need to
aggregate it based on this parameter so
the interesting part is you know we
realized at the very beginning that
we're dealing with the real-time data so
right from the get go wee-wee architect
with the system to avoid any sort of
batch processing so everything is done
in queues and we try to keep the latency
to a minimum so as an example Twitter
today they're the public number is that
they've shared with us is from the
moment it takes you to type something in
here plus it your web client to the time
that it takes for them to show it in
there hcp search is about 10 to 20
seconds right that not so you can see on
Twitter side so if it takes us
20 seconds to get it in the real time
stream and that from the moment it hits
our servers it takes us anywhere between
28 seconds to maybe I'm up to a minute
to index it in order all to berate the
eyes so roughly within a minute of the
tweet being sent out it's available
within our API when you hit a Piazza so
there's you know there's that actually
creates a lot of caching problems and
all the rest but you would try to be
aggressive but also make sure that we
deliver timely data so needless to say
databases have always been kind of the
the arch nemesis for everything that we
do right just in terms of throat but not
rest I'm this is kind of a fun graphic
kind of I don't know how well you guys
can see that we put together this you
know fun infographic at the end of the
year just to showcase what it is that
we're doing kind of data processing so
fortunately hard to see but I'll read
out some of them 20 building engagements
20 million new engagement about today
about 240 comment checks a second what
was interesting in here about 150 feet
checks the second are actual all
hardware processing is done through
message queues so our primary message
queue is handling about 3500 messages
per second so between all the
subscribers not the rest and her own
scheduling system was processing embed a
thousand thousand jobs a second so all
in all kids if you know it's not a
patriarchal system so we're somewhere in
the neighborhood of about 16 to 20 mega
megabytes a second in terms of the data
that we're pushing through a full step
to actually make all of this work so I
did mention that we built lot of her
stuff with Ruby whore round ruby having
said that you know we we certainly
pushed the vm in terms of what it's
capable of doing and we had to build a
lot of our own tooling around to make
this work so for example we Oliver API
is our
our own web stack we call Goliath it's
using Ruby 19 continuations complete
completely asynchronous and you know the
reason we want this is very good memory
management keep-alive pipelining
middleware support all this kind of
stuff that some of the other frameworks
just did not give us in Ruby so that's
actually no we're it's been a beer you
could perform or for us and on the rest
comparables would be something like no
GS or even Nettie we have our own HTTP
library same reasons you know we didn't
find all the features that we needed so
we do make use of stuff like keep alive
and pipelining all the rest so we want
to make sure that we have a long had
covered so and there's a whole lot of
other projects that we've built in
process you know anything from Ruby
bindings to bloom filters to proxies to
WebSocket server is not instead of stuff
so a lot of code is available on our
labs page and also know on our github
accounts as well in terms of just kind
of a soup of names the types of
technologies that we used in hey so I
mentioned routines you know C and C++
extensions where it makes sense the the
actual web you is so for example the
analytics product that I should we do
are built in ruby on rails rails is
great for the kind of stuff that is
designed to do for the actual API and
kind of data level access we run on our
own Goliath stack so in fact Ruby on
Rails talks to three speed services to
our clients tack most of the time
indexing in search and mentioned leucine
and solar databases we use a lot of my
sequel that's what we started with work
you know the activity stream stuff we're
indexing in Cassandra if you guys are
not familiar with Cassandra it's kind of
a clone between big table dynamo not
long mix between big table dynamo or and
then of course there's no supporting
cast so many how's the databases
memcached reddits mon going on the rest
for hughes and messaging i mentioned
that we use a lot of a lot of that
rabbitmq
the amqp protocol and pants master
cooing broadcom there's been a very
solid performer for us and Beanstalk
which is something that we've built on
extended as well which is a job
scheduling system proxies and you know
all the other stuff that you would
expect to find and kind of all we have
to start so Nigel's ganglia for
monitoring all the rest Hudson for
continues bills and all the kind of fun
stuff in terms of high level
architecture you know I mentioned that
most of our stuff is hidden behind HTTP
interfaces and the primary reason for
that is you know we have to continuously
scale out her database here and all the
rest so we want to track that from our
front-end code which should should not
depend on any of that so in fact many of
our other services can talk HTTP back
and forth which is why we've actually
invested in some building you know a
reasonable web stack including an HTTP
client and all pressed so content API is
postrank API his metrics api's and all
the rest metrics api's are obviously
kind of the poor infrastructure that a
lot of other API is built on so for
example when you open up google reader
or plugin it actually queries the
postrank api which in turn goes it makes
an HP com to the metrics api fetches all
the underlying data and then performs
the contextual ranking to give you that
one to ten score and then that's return
back to the user I'm activities
committee i mentioned that status
running in front of cassandra the
processing stuff which is the stuff you
don't actually see as as a client but
this is what we have to do to keep
ourself running is i mentioned we have
RSS crawler is metrics aggregators so
some of them are pulling some of their
pulling data and all the rest we have
dedicated result of our instances
obviously a lot of links coming through
twitter and all the rest are bit ly
yours and not the kind of stuff we
resolved that up to 10 levels deep make
sure that we have the the canonical URL
although
the notion of a canonical URL is obvious
a challenging thing as well so we tried
our best in that in that respect leucine
content things that and content indexing
is based on charting so we've iterated
through a couple of different
architectures there the first one also
just fanned out across many different
instances we found that that was that
became a problem after a while so now we
actually do a mix where we have the
time-based indexes so basically fresh
content gets indexed at the head that
stuff is very small that looks like a
very small so we can search them very
fast because most of the time our user
is interested in you know the most
recent content and that the further back
you go back you know don't longer it
will take but that's okay because they
also usually happen infrequently and
when they do they usually cash anyway so
the user doesn't even notice so that's
good and that metrics and content
processing you know my sequel on that
that's what a lot of that kind of
infrastructure is today and you know i
should say that to date all of this is
roughly you know fifty-fifty machines 50
distinct machines that power the service
we're definitely hitting some balm necks
with my sequel today just in terms of
previously we were able to just start it
out in terms of going wider and getting
higher throughput what we're actually
finding that because the rate of the
metrics that we gathering is also
doubling roughly doubling each year so
you know today we gather about 20
million I expected by the end of the
year will be at around 40 million it's
actually my sequels actually struggling
to keep up with this kind of the insert
rates and all the rest that we actually
need out of it so you know we're
investigating other approaches and I'm
the last one that the last thing that i
put here just just for fun this is kind
of our main office dashboard you know we
have a big TV monitor shared with our
team just in terms of this is our one
view on our own system in terms of you
know what's happening so you know two
big green numbers the the one at
top-right would be the
were of engagement events that we saw in
last minutes eighteen thousand events
what's the number of actual API requests
the post trinket I request that we
served in the last minutes of about
fifty thousand and then you know a
little different cues and processing
pipelines not dressed what's working
what's not what's happening so it's it
allows us to get kind of a real-time
view on what's happening in the system
it's our place and go for diagnostics
and this is powered through ganglion
angulus and a couple of other subsystems
so that's that's all I happen and
actually it's too hot on the mark but if
you guys have any questions I'm happy to
dive in technical or product or anything
so spam was interesting challenge for us
so we certainly had users try to game
our system right so they want to get a
higher so for example I showed you one
strange on it just bullcrap here this
guy right here so we have a site and
poster a page on post on comm where you
can type in any topic for example wine
and see what are the top wide related
sites right and some communities are
actually very much invested in those
pages like yield you know we see tweets
every day it's like oh hey and moved
from number 42 number three today
because I had a great post and we do
have individuals that try to spam that
you know so they literally have
thousands of Twitter accounts which are
just farming out links and you know we
we actually we try to work with
companies like Twitter and all the rest
to let them know that this is happening
because of course it's in the interest
of sites like dig and read and all the
rest to stop that right so you know part
we rely on those sites to do their job
because it's in their best interest but
we certainly see a spam manual and in
those cases you know we do
unrequited for have no abnormalities and
try and stop that so don't know if that
answers your question exactly but the
one interesting thing that we did find
is the engagement data is actually a
very good spam filter so as humans we
are very good at detecting spin right
lecture you can land on on the page that
republish is some RSS content right and
as human you can look at that and see
that oh this is actually from another
website usually people don't share links
or bookmark those sites right so given
the four versions of the same content
you can find a canonical version of that
content page just by looking at our data
right so we for example I mentioned that
we provide data to some people to some
customers we can adjust our engagement
filter to say oh hey give me content
just from sites and generate about
straight my new engagement and very
effectively cuts off the water spam
every once in a while you still get you
know the gaming scenario but in general
it's an incredibly effective so that's
that's yet another fun application that
you know we've explored
anything else do you guys usually review
at all you should now I guess your fight
on shop and everything else is first
alright well thank you i'll be around
for a little while so if you guys have
any questions then feel free time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>