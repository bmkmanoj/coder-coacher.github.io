<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Simple Pricing Schemes for the Cloud | Coder Coacher - Coaching Coders</title><meta content="Simple Pricing Schemes for the Cloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Simple Pricing Schemes for the Cloud</b></h2><h5 class="post__date">2018-02-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WyhdA9vd_CI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I was thanks for coming world will be
giving today's a great seminar talk
he's a theory since Theory student at
Stanford he has worked in algorithms
mechanized design fair division is
general area here about simple pricing
schemes for the club I'd so um first of
all I would like to thank Kostas for
inviting me to give this talk and
obviously it comes to all of you for
being here so this is a business convert
with Ken cash and Peter Keith both on
Microsoft Research and I just presented
this work last month at the wine
conference in Bangalore India so I
probably don't need to convince you of
the importance of the cow right so
there's a huge amount of computation
occur in there with billions of dollars
involved and so it is crucial to come up
with a good pricing scheme and here the
second question is how do we decide
which jobs to accept from the set of
incoming jobs and what prices should be
charged for these jobs or in other words
that what makes a good pricing scheme
and here I'm going to focus on two
things so first we want the steam to
have strong welfare and revenue
guarantees for obvious reasons but in
the distance that we also want the
scheme to be simple so wanted to have we
even to be easy to implement and also
easy to participate M what we do in this
firm is that we combine the two
objectives and show that we can more or
less have the best of both worlds so
there are simple pricing schemes that
can perform almost as well as more
complex ones with respect to welfare and
revenue guarantees and to make things a
little more concrete let's take a look
at the pricing scheme that's used for
personal machines on Microsoft Azure so
Harry here once the user specifies some
basic parameters such as region type and
instance size the prices been calculated
just by multiplying an hourly based
price by the number of hours that you
want and the number of virtual machines
that you want so for example in this
case the hourly base price is 0.15 $3.00
per hour we want one virtual machine and
we want it for a hundred hours and so
the final price is just fifteen point
three daughters don't even see that this
is a very simple pricing scheme very
easy to understand on the other hand
that you'd imagine the more involved
pricing scheme where for each number of
hours that you might want there is a
specific price for that number of hours
so on the question that we study in this
work can be phrased in this setting as
follows how much more welfare or revenue
could be created if instead of this
simple multiplication formula we were to
use a context table that specifies the
price for each number of hours and what
we saw for this setting is that in fact
the simple multiplication formula
already gives you at least a 50%
approximation and compared to the
complex table both both in terms of
welfare and revenue and so that's for
the setting with a single server we also
extended for instance to multiple
servers here you could imagine that the
server's may be located in different
parts of the world so the world so they
can be they can have a fee for different
kinds of jobs and what we show is that
setting a single price for this group of
servers even though they receive
different kinds of jobs can provide a
reasonable wolf earn and revenue
approximation compared to setting
different prices for different servers
alright so before going on to the
details of our results let me mention
some related work so there's been a lot
of recent work on deciding
with scheduling mechanisms with voter
guarantees and incentive properties I
just want to highlight a couple of them
so as our I'll show that we can get a
constant approximation of the alcohol
welfare with a truthful mechanism but
only if slackness is allowed so that
means there mechanism might not tell you
immediately whether your job is accepted
or not the delays amendment and also it
could preempt your job through job to be
a pre-emptive and then resumes later
later and began yet L so that we can
still get the constant approximation of
the welfare even without sadness but
that only if you have information so the
stochastic information on the under on
the job and in both of these works as
well as several others prices depend in
a complex way on a number of parameters
typically including job men arrival time
deadline and value as well as on the
current state of the system and in
practice this information is not always
so easy to obtain and even when it's
possible for the participants to figure
out this information there's often a
cost both in terms of time and resources
to figure it out but this program we
show that good results of good
guarantees are possible with no upfront
information and our work falls into a
broader area of the design and analysis
of simple mechanisms in particular
poster price mechanisms which also has a
very rich and beautiful literature
alright so unless getting to our model
so we start with a single server he's
constant at all of some length I strong
with some probability and the value for
each amp of the job is drawn from some
distribution that is independent of the
job plan so later on the lastly relax
this assumption and the real large
incentive price per town step
so if the price of the if the value of
the income and job is at least this
price then the job is accepted and then
the the machinist gives his job and for
however many concepts it takes otherwise
the job is rejected so the question that
we ask is when we set this price do we
need to take you through account the
length of the job so can we just set a
price per topped up for any job month or
should we discriminate between john
locke's and note that if we are allowed
to discriminate between job plans then
what we want to do is that we will want
to set a higher price for longer jobs as
a premium for accepting it for a longer
amount of time in other words that once
we accept a longer job we're stuck with
it for a long time and so we set a
higher standard for cutting it so the SM
example Amazon recently started offering
a product called them defined duration
spot instances where users are allowed
to specify the number of hours in early
increment from 1 to 6 hours and unlike
the goosal spot instances where the
prices can fluctuate periodically
depending on demand and supply and here
they're all live prices fixed beforehand
and the defined duration prices are
higher than the useful spot prices but
still lower that the on-demand prices as
you can see here the price per hour
indeed goes up as the number of hours
increases so here for some of the first
row we go up from we go from point 1 5
to 21 for two dollars per hour for one
hour two point one five seven dollars
per hour for six hours
there's this assumption that you want to
charge more for longer jobs is that
because there's more jobs in capacity
right we've also so that's part of it
and also because there's there's
preemption right so it could be that for
example for four spot instances if the
spot price goes above the price that you
sat in your job but could be pre on
and so here you're you're paying the
price for certain for the guarantee of
the have you got that
SP yeah so just kind of following up and
similar questions so coming back to the
modern right so you have one job coming
in every time step rent now whether you
choose a long job right now or a short
job uh or rather what's the cost in
picking a longer job was it to the job
for two time steps making the money
anyway for two steps is just proceed
from the third step onwards right then
in between you're missing that the
chance of choosing other jobs right
which could have a higher value so it's
like you're making the commitment of
this job for that user need to know the
links upfront or can I just run the job
however it finishes and then it get
charged yes are you so so actually here
we assume that the user knows that lens
up front and then submits that to the to
the mechanism so the metric is yeah
exactly it's actually both suppose are
well from revenue the approximation that
we're gonna give you so a man so is
there ever a time that the you would
want the cost for a longer job to be
less per hour because in some sense the
job is also kind of committing to being
salt like being served for six hours
it's kind of nice to be able to serve
this high-value job for six hours
um yeah so so there I mean there could
be that effect but I think that's
outweighed by the by the ability by the
guarantee of having the job executed for
that number of hours and I mean either
both both in our model that the in our
model that the analysis of our model and
also in practice for this Amazon's
defined durations instances turns out
that absolutely what you want to do is
you want to set a higher price for top
stuff for
for longer jobs I guess my question is
theoretically is there a case in which
it is lower but in practice there is not
or even in theory you there is no such
instance in which you would want cheap
urge the long jobs to be cheaper no so
in theory so if you if you saw the model
then you would find that immediately in
all instances you all always want to set
the higher price for any other persons
okay so let me move on and so as I
mentioned earlier our main result in
this single server setting is that the
same price per top step for all job
lands can get you at least a 50% of
either the welfare or revenue so this
metric depends on what what you want and
this over a revenue that can be obtained
by setting an individual price for each
job plan and in fact that we can say
something even stronger than that so
what we can say is that that the signal
price can be chosen from one of the
discriminatory prices but that means if
that doesn't have the optimal set of
prices in the multi price setting and
the optimal price in the single price
setting or it could be different from
any of those prices but what we can
guarantee is that the shooting at least
one of those prices as the single price
will get you this 50 percent
approximation you don't need to fess
this single price from out of nowhere
you can get it from exactly from this
set of prices and this approximation
also holds for arbitrary so not
necessarily optimal discriminatory
prices though you just start with any
set of prices in the multi price setting
then still is true that's using one of
those prices in the single price setting
will get you description person
approximation we don't make any
assumption or the distribution so it
could be a discrete could be continuous
could even be a mixture of the truth and
this one is tight even with their only
to top nuts and if the two governments
are far
art since one is one and the other goes
to infinity and one important thing to
keep in mind is that there's 50% it
might not seem that impressive is that
you're losing a half of your welfare or
revenue but this is a worst case aren't
and so in practice when the input is not
adversarially tailored we can expect to
do a lot better than this guarantee okay
so um right so recall that this 50% this
is a worst case bomb over a number of
parameters it's over the set of top
manage the distribution over top lands
and the distribution over job bad news
another feature of our result is that
when there are only two tons or in
ordinary when we know when we know more
information on the parameters we can
actually get the better approximation
and in particularly when they're only to
talk lens we can even get a tight bound
on the approximation if you know the
lens and the distribution over them so
for example if the governments are one
and two and they occur with equal
probability then this bond goes up to
about 86 percent and that is tight for
bimodal distribution where the value is
either low with high probability or high
with no probability so this is the graph
for the distribution so here on the
x-axis we have job value and on the
y-axis we have probability so we have on
the left hand side the low value with
high probability and on the right hand
side high value with low probability
just writing us in the setup so it each
time one job comes in not to decide so
if it's a light job of mine too after if
I don't accept it that means I don't get
anything for once that's right radius
focus and right so intuitively what we
want to do here is that we want to have
self also our jobs but only long jobs
with high badness and that is only
possible if we can discriminate between
job max
okay so um right so that was the
overview of main result in the single
server setting now let me go into some
he tell what method we used to obtain
this result and I'm going to do that
with the Anna found elastico example
which I mentioned earlier which is only
two job Nance one and two and they occur
with equal probabilities and in as I
mentioned in this case we get the
guarantee we get is about eighty six
percent or to be more precise it's six
over seventh and so what we do to get
this guarantee is that first of all so
we we write down the formula for either
the welfare or the revenue of of East
settings of the single price setting and
of the multiply setting so for example
here I do we're doing the welfare and if
we set the we set the prices P 1 and P 2
then we can write the formula for the
wealth expected welfare / constant and
as the formula right here there's in
terms of the integral from from p1 or p2
to 1 and it's times of s so it does some
some stuffs like the expected expected
value of incoming job provided that the
value is above the price P I mean so
it's not exactly that because for the
expected value you'd have to like divide
by the probability that the job is
accepted but it's certainly something
related and then in the denominator we
have we have the term capital F of p2 so
that's the probability that the value of
an incoming job is below t2 and or in
other words the probability that the job
is rejected so um yeah in this case that
actually went when one of the top legs
is one you can see that it's always
optimal to set the price for that job
meant to be zero because the top of
length one when you it doesn't interfere
with future Charles so you could always
accept it but we won't even need this
in order to fill our our guarantees that
we just remember our guarantee holds for
any set of prices in the multi price
setting and okay so now that we have two
formulas so what next is well probably
the what the first thing you want to do
is that you write down the inequality
that you want to prove the what we want
to prove to want to show that be you can
approximate that you can get an
approximation of fear of the welfare in
the market price ending by stepping one
of the prices as the single price so
that's in the inequality OH
so the value of the job is it then it's
drawn is if the value per time step or
is it the value of the whole job it's
the value per Tom stuff yes so there's
there's a signal distribution that's the
value for Tom stuff and this
distribution is for jobs of any length
okay thanks a question so in this
formula you somehow don't expect the
formula to be much more complicated
where you have to incorporate all the
difference that happens if you take a
long job and then the next time step is
kind of helps you to then the next time
step yes the value is correlated with
the previous time step so there's
there's no uh-oh
so so you're still for for any job the
price for Tom stuff so there's only one
price for concept for that job so it's
not gonna be like it's not like after
one times of you redraw this value good
tough stuff yes I mean if the job of
them to arrives and it has value per
time step point for then that holds for
both concepts the formula doesn't
explicitly have to say that because of
linearity of expectations right right so
after this though so you can you can
write down you can access if it's not
very complicated to write down this from
the so you have the quantity you want to
solve for is they expect that
well Farrakhan stop and hear you care
you can imagine the very long time
horizon and then like you know so for
example like say you have Joseph's
length one and two you can't think of
like okay javis length one concern like
it has we set this price p1 and like
what's it probably did probably did it
it's accepted it was accepted but how
many times does it taste like what what
what's the world fair is that of yields
and so on and they even solve for this
formula they don't have to be this it
turns out to do this for manages okay
yeah so um right so that the claim is
that the any party that we want to prove
and then in simple so that's this
follows from the formulas in the
previous slides so this is the in
quality that we want to prove and even
though it might seem a bit complicated
it's actually in terms of just three
main qualities the first is the ratio
between the two integrals and then we
have a capital F of p1 and a capital F
of p2 and so um you're gonna divide into
two cases here which is I think very
natural here so um the first case we
have this integral from p2 to one is
relatively large compared to this the
integral from few month one typically
what that means is that the value of the
job value of a job and it has value
above p2 is relatively large compared to
that of the job and it's above few ones
so there's a lot of value from from jobs
of valuable p2 so what we're going to do
there is be enough set the single price
p2 and in this case we take the second
term in the the the mass here and you
can see that the denominator is
cancelled and so we were just left with
comparing the numerators and that's just
that's in terms of the two integrals and
then the inequality is just followed
that from the from the case assumption
of case one and then for the other case
so now the
of jobs above p2 is relatively low
compared to those above p1 and so in
that case need to set the single price
p1 so we have the first term in the mass
and so now the denominator is no longer
cancel so we have 3 minus capital F P 2
on the left hand side and 3 minus
capital F P 1 on the right hand side but
what we can do there is that we just
assume the worst case on the
denominators so we assume that F of P 1
is 0 and F of P 2 is 1 so this is like
the worst thing that can happen for for
this inequality and even in this first
case it turns out that the inequality is
stolen going to hold and that's also why
the inequality is tight for a bimodal
distribution so we want the one one
price to accept pretty much all jobs and
then the other price except pretty much
no job but the mix between short and
long jobs doesn't occur in this doesn't
appear the mix be cooling how many
what's the fraction of small jobs or
special small jobs in fresh of not jobs
so just to be clear that I yeah yeah
yeah so the right so this is gonna be go
to very close to 1 and this goes to so
this very close to 0 but then the
quantities that comes a matter is that
the ratio between the welfare that you
get from from short jobs and from from
long jobs so that would be that would be
held and some some constant so because
like the the fraction of short and long
toss is it's going to be I mean we're
gonna have pretty much like all jobs
being there in charge of saying that in
this distribution but then like that the
launch out they're gonna have must give
you much more welfare so the bad and
Picasa or the start crops can be to be
very close to 0 also short jobs right a
low value short jobs and it means are
high so right so that's basically that
the the proof for this this illustrating
your sample and in the general case that
we could tell for any any two Joplin's
like a and B and any any any
distribution over the top lands and the
proof just follows I mean it's more
complicated but the idea is more or less
the same
ok so any any other questions up to this
point so reminded value per time suppose
independent of the junk and the place no
fergus we've been using that as
awesomeness okay so right so so let's
take a look at the right so that's only
for one one example with their jobs of
length one and two so let's take a look
at what this approximation ratio looks
like for more general cases so if we
have a dominant one and Atari B and
still occurring with 50/50 probability
then we get a confirmation race owed us
about two thirds and it goes to two
thirds as B goes to infinity so it
decreases and process to thirst and that
makes sense that it decreases because as
with other
southland that gets longer and longer
there's more and more to be gained by a'
being able to discriminate between top
man's and so these ratios should go down
and then if you have dominance 1 and B
occurred with arbitrary probabilities
are in 1 minus R then we get the
approximation ratio and there's always
at least 1/2 and closest 1/2 when P
equals infinity and then R goes to 1 so
the longer top lands gets very very long
and then almost all probability is put
on the shorter jobless and finally the
most general case with to top man's name
dot of length a and B occur is probably
deeper and one my as her so we still get
some formula which is tight for this
these Joplin's and these probabilities
and there's always that leads to have to
recall that this one half holds even for
any number of governments way too tight
even even for a pretty particular case
with which is to Joplin's one and be
according with my experiment and they
thought and with the appropriate
conversions all right so right so so far
we've been comparing the signal price
setting to the multi price setting right
so we've been attention me so that we
can have to compare the welfare from
setting the single price to an even
higher bar which is that offline optimal
offer so here you can patent that that
you you know this is the welfare that
you get when you see all the
realizations of the top themselves
values and everything and then you can
schedule you can schedule all the jobs
in such a way as to maximize your offer
and let me show is that still in this
case there's just a single price that
can get you 50% off the offline optimal
over and here also we don't need
independence between Joplin and value
per concept however there are also some
disadvantages to this method compared to
the bathtub that I just described to you
so for this result this the single price
cannot be cannot be fetched just from a
small set of prices and also um it does
not give a bound for non optimal prices
and even if you have more information on
some parameters it's not going to get
you anything more than this fifty
percent and the proof of this method
uses techniques from the profit
inequality literature which I'm going to
describe to you naps yeah so even in
this offline case is it the stolen when
a job comes I still have to either
accept it or I can't delay it till later
right because those so this this is the
pricing schemes are you sending a single
price and then the top if the child is
that each this prize yourself if not so
so this is a point of a simple scheme
okay
how do we solve this result so let's
assume that their tops of classes went
through and so here we gonna assume a
discrete distribution there is also
forced even if we have a continuous
distribution we can just replace all
sums by integrals but for simplicity let
me just tell it for a discrete
distribution so we have jobs of these
classes and top class J arrive with
probability n RJ has been AJ and value
proton stop Vijay and these values can
be a sum of these values can be the same
across different job classes remember we
are not assuming independence between
Joplin's and value per Tom stop and what
we can do is we can write and expect
that the linear program and upper bound
the maximum loafer kirtan step so here
in opt is them and maximum expected
loafer for top step and that this
quantity so this the race of SJ over RJ
you can think of as the probability of
that if a job of type J a job class J
arrives and what's the probability that
it's accepted given that it's arrived
and so at the top it's almost I still
your eyes are trade over time and it's
going to be accepted este over RJ on the
time given that it arrives and so in
total is going to be accepted XJ of the
time and of course this Australia cannot
exceed RJ and then also job cafe arrives
so at all 50 is accepted exchange of the
time and whenever it is accepted is
executed for her AJ Tom stuffs and so
this last constraint here has this face
that we cannot accept more jobs than
would saturate the Machine if when all
these drop jobs are executed and finally
this odd so it's just the maximum of
this so the welfare can be calculated by
the sum over all top all job
classes of the time the percentage of
the time that the Java class days is
accepted times the value per time step
of that job pass and then times the men
of that job pass and so that's why you
have this senior programs and so what
how does this linear program help us get
our result so what we do is let me set
the price to be over to so um this might
seem surprising but it's actually a
standard technique from the profit
inequality literature and that YT be the
probability that the server is occupied
at time T so that it might be occupied
because of the job that just arrived at
time T is accepted or it could be a job
that arrives at some earlier time but
it's still being executed at this at
time T now what is expected revenue at
time T the bestest the price comes the
probability that the server is occupied
at on teeth so that's why T and the
price we just said to be operative
bottles there is surplus expected
service as time T so here I claim that
it's at least this quantity here why is
it also a the probability that this
server is not occupied and can't eat so
that's the one minus YT and then so we
have this this is probability times the
expected surplus phone from the incoming
job at time T right because so this
probability we are already conditioning
so we this is the condition that the
server is not occupied at time T and
then so we know that it we can accept
the job that arrives at on T so we look
at what the what's the expected service
from that job well so it's this T if so
RT remember is the probability that our
days the probability that the job of
class day arrives and then
arrived so we what we get is the
difference between the value of the job
and the price and then once it's
accepted we have that job for whatever
concept that it's less acute it at this
quantity on the left hand side and then
from two girlfriends from the left hand
side to the right hand side and as a 101
minus YT he goes straight over and so
remember from from the side that RJ's
that least XJ right so if we are Dave
like XJ and then we have the term XJ
times VJ comes AJ and that's exactly opt
right here and then the other term we
have a minus P times R J times AJ so our
day is then replaced by that stage with
SJ x is JT and that's its ally this
quantity here which is that at most one
F minus sign we have this our take on
say J is at least one and then we agree
just stuff is at minus P but P is the we
set it to be over two so we have a minus
all over to here
so it's wet it and stop being is minus
over two which is just out over to right
here alone that's why you get the term
on the right hand side and finally so on
expected well first of welfare is just
the sum of the revenue and the surplus
right and then we used a linear
linearity of expectation and so we just
sum up the two quantities and what we
get is exactly this October 2 which is
1/2 of the offline optimal welfare and
that's so that's the proof of this
result so any questions about that
seconds one thing
just confusing so Express expected
revenue at tea and expected surplus at
tea are presumably the surplus at time
step T that's what it is right right
right but the formula for surplus has
the AJ in it which is the length yes so
so I guess we calculate them in slightly
different ways so you're right so for
for revenue so we asked you to look at
the revenue at time T sort of the jaws
has attributed that that concept but
then for the surplus we calculated the
surplus when for for jobs that is
accepted at time T but then we
calculated for whatever passed up it
pays to clean that job so we could not
go in to calculate it in between in the
middle of the job so it's right that we
calculated in different ways but that's
fine in that case the expected revenue
at T should have a greater than equal to
from the ye
I never mind then take it off yeah okay
so um yeah so that's that was for one
servers so as I mentioned earlier we
also extended our results to multiple
servers and I'm gonna just mention that
briefly
so um here we still assume that these
pom stuff free server Java some lens
appears with some probability and right
so the set of top management the
distribution over top lens can be
different for different servers so from
sample that could be because the servers
are in various geographic locations or
they're used by different users I said
that we asked here is analogous to the
one that we asked before except that
here we are allowed to we have two
dimensions in which we can discriminate
so we have we can discriminate between
job lands but also we can discriminate
between servers so the question is can
we do all by setting the same price per
ounce tub for different for all servers
and also uh plants compared to selling
an individual price for each job month
and you server
and the answer is again positive so what
we saw is that for any prices reset in
the multi price setting and we can
achieve an approximation that is so it's
not with me in either the number of
servers or the maximum job mask so on
what this means is in most situations as
long as the parameters are not too
extreme we're not going to lose too much
welfare or revenue by setting a single
price for all documents and all servers
and as before if we have more
information on some of the parameters or
we put some some more constraints like
for example if we have to if we can
still discriminate between servers but
we have to set the same price for all
job bands of each server then we can
again take better approximation because
the value distribution common i/o for
servers not so processor we can have a
different value distributions okay yeah
but in each server we have another step
right so this corresponds to the servers
being in different geographic location
so you can think of the server's has
been separate from each other so one
could be in euro one issue and in North
America and they did just receive
different kinds of jobs of different
distributions of Joplin so job ad okay
so um yeah so let me conclude so this
work is studying how well simple pricing
schemes that did not take to account
rameters can approximate more context
schemes with respect to welfare and
revenue and our results help explain why
such schemes are an efficient in
practice including the scheme for
Microsoft Azure that I showed you
earlier and simple schemes that does not
require Asians to spend time and
resources to determine their specific
parameter values our results also serve
as an argument in favor of using these
schemes in practice and finally again an
important thing to keep in mind is that
all of our results are of worst-case
nature and so if you actually
in practice the guarantees on welfare
and revenue is slightly going to be
quite a lot better and that's all for me
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>