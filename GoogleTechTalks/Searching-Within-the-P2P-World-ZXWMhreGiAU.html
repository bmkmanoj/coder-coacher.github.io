<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Searching Within the P2P World | Coder Coacher - Coaching Coders</title><meta content="Searching Within the P2P World - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Searching Within the P2P World</b></h2><h5 class="post__date">2010-03-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZXWMhreGiAU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm a faculty member at Delft
University of Technology and
coordinating the older peer-to-peer
research there and so for the coming a
slot I would like to explain the state
of the art in peer-to-peer and also a
bit would of the state of the art but
first a word of thanks actually to the
people that sponsor us because the peer
to peer group at delft university is the
largest around and that's actually the
only reason why we've been able to to
make things work because these things
cost a lot of resources getting searched
right I'm standing here in the Google
building so I don't know it's obvious of
course but getting these things right
costs a lot of resources and i'll be
talking a bit about the context the
future of television in years to come
and what problems that creates actually
for for search and dealing with spam and
and the challenge of reputation and a
bit about the state of the art so first
the context of this research when we are
going to a few years ahead for group
we're looking at a few million people
who are watching TV on on a small screen
or a big screen a 3d screen or something
few hours of TV day a decent bit rate if
we're talking about a lot of data that
that's coming up and these are realistic
numbers as people I we did some
measurements we did a few million
scrapes with our supercomputer of
YouTube that we see these numbers coming
up so that actually means that searching
this this this fastmedia cloud black
Olivia Chow and to put a bit more
dramatic the importance of search and
what you are exposed to is actually the
media cloud is where society things so
it's not just about precision and recall
and what comes up it's actually if
you're exposed to the media and you're
dealing with the media for for a decade
this actually changes a bit what you're
exposed to
and what you're not exposed to and the
first search result actually has a
long-term a truth it's very society
things so to illustrate that I just have
one slide on the dark side of this this
is a study on on quality and reputation
as you have these user-generated content
site which probably will be important
for the future of TV I will only grow
that this sort of source and reputation
and search quality is really interesting
and really challenging and difficult
even if you're not in the peer-to-peer
space so you have central trusted
servers to deal with then end of 2007
published studies 153 feos investigated
on youtube on vaccination immunization
do a lot of them the majority was
positive for that yeah come on get that
shot EF accident there were some
negative ones and they do what's not a
problem in this in this community that
the negative videos actually got more
ratings for quality and the quality
ratings they got they actually got more
stars on average and they got a lot more
views so the negative things were more
popular even though they were mine on to
your mother for you and he's negative
videos I had unsubstantiated claims that
contradicted a medical I medical
knowledge and sort of the professional
consensus so this is sort of when we
talk about search results and where
society things it's like that people go
to their doctor they asked our family
first but then as some some measure they
actually go to the Internet and what did
I find it and if they go to the
peer-to-peer search what will come up as
the first video that's sort of showing
the dark side and the challenge that
lies ahead to get this this reputation
this is not new to youtube or and just
go to Wikipedia and ask for
controversial topics and you'll see that
this is happening more
so in peer-to-peer you have a challenges
are even more and no trust at central
server or serve a cloud to to ask things
for peer-to-peer means it's it's it's a
collaborative network and you have small
nodes and big nose big pcs and small pcs
or think thing so illustrated here with
the elephants who have a lot of
connections and and the tiny mysidia
appears and this can be a network of
millions huh so I don't know how many
people have experience with bit torrent
or emule or these these sort of systems
which are now emerging and this role as
it was discussing on the future of TV
slide and this this sort of technologies
is likely or is already included in
televisions you can buy in China and it
will also go probably in the TV sets in
the years ahead so what you need to do
is like if there's some flash drought it
should not be that one peer-to-peer
engine in one specific TV is suddenly
overloaded or 1pc so it should be low
balancing the whole queries and things
across all notice let other challenges
that you actually would like to exploit
Samantha clustering keep this locality
that some people are interested in
certain content and that you don't need
to go to different continents to answer
queries or to to to to keep this overlay
together and that you actually rewire
the network that you do links we have
the cheese lovers overlay portion and
the people who have the sausage tastes
sort of that day they form a cluster
cluster together but a problem with
these things is the reliability so you
have a note for you in peer-to-peer and
very slow these machines which fail
after a few minutes or a few hours and
what you have to do that is is rewire
the network to compensate it is so in
peer-to-peer
you have quite a challenge so if we have
is we want to have a trustworthy
reliable fast make it isn't for
searching this media cloud but all we
have to work with is donated computer
resources which even can be fraudulent
has spammers or are people who misuse or
just corrupt memory and it feels on an
hour so that they're going offline and
all these things so they're really the
opposite of a trustworthy server in the
cloud quite some challenges if you look
at a bit more detail the overall
research question when you want to solve
and then then integrity and Trust how
how to do what's fight and pollution
i'll be talking a bit more about guitar
like things detect popularity and in a
fully decentralized way also robust i
don't think this problem is never solved
in a real system how to do beyond me or
file name so what's now the state of the
art imperative search in real systems
it's just a foul a matching that a lot
of big challenges how can we organize
the overlay I probably want to exploit
locality that add the semantic
clustering that things which are sort of
together there somehow expressly the
overly another locality that you have
this low latency that that you don't
need to go to the other continent for
replying to circuit and also the social
locality as the web is going social that
probably if your friends are also in
this peer-to-peer system that they liked
this video or something that you
increase say the relevance ranking or
something you promote that surgery
though one of the difficulties is for
many years that if you turned off these
peer-to-peer notes so that these
applications these client all state was
lost and when you come online again you
have to preserve everything indexing and
all these things all the metadata was
all lost they
so persistent storage by keeping it
light weight it's been a challenge so
the project I'm coordinating as is the
first bit of a flying with a fool a
lightweight SQL engine in it none of our
challenges how to exploit these terabyte
hardest also these routing tables all
these things then prove a very difficult
to to exploit dad effectively and one of
the things with modern technology like
the swarming of victory and bigger
swarms are better but usually if you
have a few that we've seen that you have
a hundreds swarms of the same content
then you actually have fragmentation of
songs instead of a giant swarm with tens
of thousand or a hundred thousand
appears then they're all fragmented into
little swarms that actually means
performance loss and this is also a
problem which you should saw probably at
a peer-to-peer search layer find not
only do good content but also the most
healthy swarm so how do people have done
peer-to-peer search over the ages in
June 1999 there was the first real
system built the Napster where well it
was just central servers there is no
nothing peer-to-peer about the search
perspective they had a bunch of sermon
i'm leaving at the height it was 50
service you just select one of the
servers and you you do your QT words
there and you only get returned to the
pier who have a certain public so very
unsophisticated very simple technology a
real sister was launched in march two
thousand it was more decentralized and
not very sophisticated again but it
worked you said your crew use out to a
bunch of people they forward it again to
another bunch of people etc etc and
actually this system proved to be
popular just for keyword matching but
this kanakala protocol as it was called
actually literally flooded the internet
back though there was more creamy
traffic on
Internet backbone then there was actual
downloading with this protocol that's
how inefficient the the system Mayor was
and also prone to a lot of spam so there
was not they didn't survive that long
then we're going march two thousand one
where because our system was launched
well it was a bit smarter that instead
of these central servers all this
flooding and rolla parts you're not
actually more preserving of state and
indexing that from roughly 300 fears the
system automatically promoted a super
fear which is connectable and had a
decent uptime and then these these
queries it stopped being broadcasted one
of them he's 300 300 peers could be
reached by the single super period had
an index all these farmers so you could
just talk to one super peer and then you
also had a decent a search result but
again no solution of spam because it had
voting in it you could read it but um
that was already very early in the
indicas our system there was only one
problem you could just as easily inject
fake content and spam as you could
inject positive fake votes for this
system so it never worked in the real
world then we going a bit further in
time but in 2002 roughly then because of
previous failed attempt no more fear of
here we're going backwards in technology
trusted web server so you just had a
every pip edonkey links or or or
bittorrent a lynx became popular the the
web servers became the dominant form to
access these things so even though the
downloading was exploiting the purity of
paradigm the search was still using or
was again using central trusted web
server with standard moderation feature
and spam prevention then a bit forward
in time june two thousand seven another
real working system
they talked about for a lot and then
there was an interesting study done on
the DHT where you use hashes so instead
of keywords or all these things or
indexing or file names what you do is
you convert searches in term hashes and
then you begin to search for those
hashes so it's a bit of a you have a bit
of indirection that there so its
difficulty to do fuzzy matches or say or
combining queries but the problem was
again nice idea lots of papers published
about it but if we look at an evaluation
of how this performed in the real world
yeah first the scientist had to actually
do some bug fixing because it was a big
too bad and so a thing talked about for
a long time the DHD the real deployed
one so you do a keyword search this is
not many seconds this is seconds so 50
seconds of waiting time or a hundred
seconds of waiting time with a high
probability that's not what you want on
the system imagine you have to search
through videos in the peer-to-peer
system that you you will have to wait 50
or 100 seconds so this is what the real
world was like of peer-to-peer search
according to this same measurement the
month say or actually the years
afterwards they got it down to two or
three seconds say yeah which it is today
but still you see that these things took
quite a while to become mature and
something which your dozens of papers
are published about that was not not
usable in the real world takes a lot of
resources so we'd like to talk now a bit
about what we believe is the state of
the art in there in peer-to-peer search
it's stuff and one of the problems is
that this takes a lot of resources to
get right and a lot of programming and
bug fixing so what you actually do at
universities is we do bug fixing of
prototypes and things that actually work
at
have thousands of users who actually try
to break it every day so that's not what
university is build up and so it takes a
big team so we are bigger than then we
have more resources than most of the
startups in in peer-to-peer so that's
quite a problem so that's probably the
reason why not many people are working
on that research so we've been working
on this for a while and the algorithm is
actually that you instead of searching
for four boxes or 444 hashes or four
things it's actually what you do is you
go towards the human side of things very
very challenging we're not working on it
for four years and approving it and so
what you have is you have some you take
into account the taste of people and
which we have is an algorithm to
determine the people who are on the
network currently online we have the
most similar tastes to you in terms of
previous download their behavior and
then you have a few bunch of random very
colorful people who are not like you're
very plain profile and what you do is
you send a query out first you look at
locally because you everybody has a big
in debt but you send a query out to 10
people who look like you into a bunch of
people who will come up with colorful a
search result your your taste
neighborhood won't have so you sort of
have a lot to work with one of the
things we changed is that everybody has
a thousands of items already locally
index so this is exploiting the the the
terabyte hard disk age and and this is a
made possible because a few a full SQL
engine is bundled in our software that's
not very definitely it's a not very easy
to do this sort of semantic clustering
finding peers which are similar to you
the basic idea is shown here in the
slide that at Pier 1 2 &amp;amp; 3 with the
Panda don't impact and koala not impact
and that you see a bit of overlap
between these sort of file names that
these three
you say like you and then you put some
fancy math to it and then you can
actually see in the user write a matrix
and all these things you can calculate
how similar somebody is to you when you
meet them and that's what we use we cash
the people around you who have the most
similar tastes and we also take it to
the next level so instead of just
keeping one or two like one connection
open to super fear we keep a thousand
say of thousands of people around us we
keep track of where of them just to
improve these search results so it's a
very simple protocol underneath you just
say these are this is the basic message
content you just tell which hashes you
like as indicated by a bit torn to show
one half of a bit turned identify bit or
swarm identify then you send around
there's also public/private key pairs in
there we fully implemented elliptic
curve cryptography all this this is
hardcore work that needs to be done and
then you you give the public key and the
current IP number of people who are
currently online and that was the person
who was the most similar to you on the
network and then you give a bunch of
random Pierre so everybody's telling
this to everybody and what you can now
do is is crawl this network me you give
this message and you get a message back
and then you go to the next one so you
can sort of Kroll the network you get
these thousands of sort of user item
profile thingies and then you have all
these hashes and then you also collected
the following information on all these
details but with you and office is that
you contact a lot of people and you can
build a very interesting local database
so we recently we've been able to add a
click loss functionality to that so you
should have the term in this so this is
beyond sophistication of the other other
peer-to-peer systems are currently in
deployment and how this actually work
for real searches so you do a keyword
search and you asked a bunch of people
around you please answer this query you
already have a lot of metadata you know
who to ask and this is now in seconds so
we have the median search response time
is 325 milliseconds so we had various
versions that we've been at this for
four years we had various versions of
our software and improving it and the
latest push is now 325 milliseconds
response that and once you have these
search results a on your screen then
these are all just a bunch of BitTorrent
swarms and you want the best match to go
first and all the said their relevance
ranking you can do then the user clicks
on it they actually want to see this
video or start down on this content so
you need to do another problem and
that's the how to find this swarm so the
this is collaboration within the
European Union funded project
peer-to-peer next so in last December
there was a big open source code release
and there was a DHT implementation in
there which actually cut down the time
in half so you look at it just a bit of
experiments here you see the look of
time is now let's say 500 milliseconds
or something if you actually want to
contact the swarm it's now five hundred
milliseconds so this is faster than
proprietary clients a like new torrent
do it but just there are in the range of
two or three seconds or one second
roughly so this is now acceptable for a
free end user performance and no longer
the the day of 2007 when it took 50
seconds or 100 seconds so then you have
this content you can search it's keyword
result but then you have this problem of
spam probably some sort of reputation
system needs to be in place or these
things because like I briefly said the
our system you could just as easily in
Jack spam and you also just got a lots
of positive votes on it so there was no
no sort of reputation system to keep it
in check if there's if you can just as
easily vote on content as you can they
inject the spam than they are say
there's no no effective mechanism in
place yet so this was 2001 so people try
one of the best examples is the really
working system of credence by Cornell
and if you look at their web page this
see that 920 young users have used it
and actually started voting on the
authenticity of peer-to-peer on the
philatelic protocol so you can see that
that they never did an update or a new
release or this is a one one time
project typical of academia and it takes
too many resources usually to do a full
time a update and work on this stuff
three years and difficult to get
publication so I don't have much
publications we have working system so
this is what you want their life as a
faculty member working cold bug fix what
this is did is you have to vote on the
authenticity and then you can discover
other people who also voted on
authenticity and if you have some
overlap that you also thought this was
real stuff then you collect these
profiles and you begin to trust the
people with you have overlap with so you
don't have these seal of authenticity
directly but through those overlapping
peers you begin to trust these things so
the challenge was that you have to
bootstrap the system with real users but
also users have to bootstrap it
themselves that proves do few votes and
then actually disp an engine begins to
work so let's say that work but that's
not what you normally use it what they
don't want to train the system for a few
days what we're launching today
actually is some untested omt spam
technology is where you can start a
peer-to-peer channel so in bittorrent
fully decentralized that you now have
the concept of channels sort of an RSS
feed in PDF form and where everybody can
sort of start a TV channel that's so it
doesn't cost anything you don't need a
satellite transponder you don't need to
buy some frequency on the cable spectrum
on on the on the cable network and
everybody can start their internet
channel and you have these subscriptions
and if people subscribe to you it's
actually a vote and these people who
have their subscribed they they just
default is that they broadcast their
love for you on the p2p overlay and
actually all these people see that it's
like ah I'm hearing all people around me
who vote this and they all come from
unique IP numbers and all these things
and then lots of subscriptions gives you
a high reputation of your channel and
then if you do content search and you
have for found a match and this is
actually approve then this is it in a
certain channel then actually we
increase the trustor of this of this
file because because essentially a
peer-to-peer moderator had a channel
owner he actually approved it and users
who proved it by implicitly subscribing
to this channel so this is all untested
but it's more sophisticated that what's
out there and then the challenge behind
it getting a step back this is the
general challenge of our internet
reputation system not only in
peer-to-peer but also a look at ebay or
all these things that nobody has a
really decentralized reputation system
which can be reused for multiple
application there's pin for success
specifically for p2p been no successful
deployment and want to remove a lot of
ideas and nice in theory but probably
infeasible it takes a lot of resources
to get them where they are and a lot of
the proposed
those are the prototypes or actually
deployed things they sort of what what i
would call sheet using central
components then this system is not
self-organizing anymore it doesn't have
the the property if you do it right of
unbounded scalability and that all these
500 million TV sets in the world could
potentially include this peer-to-peer
engine and participate in the search so
this is a difficult problem that
academia has not or industry has not
solved i believe so just three slides
and then I'm out of time good and then
talk a bit about the Bartok cough which
is the decentralized and which we've
deployed and improved so one of the
basics is like the previous one that you
lost something the protocol arm your
preference is around what you here have
it's sort of a vision of a bighorn swarm
or multiple swab it's just abstract this
is fierce we actually have flow between
them so this is notes in the peer peer
network could be bitter that's our case
then you have in a bit torn swarm they
have exchanged bites so they uploaded
know a uploaded a big flow if you look
at no.5 then there's a few arrows here
and now the trick is that there's these
flows but everybody is gossiping that's
the small like the Dalton life so
everybody's just talking by default you
exchange they also how many people gave
you a lots of megabytes and how many
people download it from you so very
simple message and no says 100 megabytes
up 80 megabytes down from p1 p2 600 down
here 6 50 megabytes off so what you have
is everybody just sends around these
messages periodically you again collect
thousands of them in your local database
you end up with a warcraft so how many
how many bytes they actually uploaded
and download it for you and then you can
use things like max flow to to limit
floor and
which we use is the this formula of flow
subtracting up and down to calculate
from your perspective if you have all
these collected these where are these
thousands of messages that you can
calculate the reputation of a peer and
they use that for a for content and
other things so how does this deal with
well so much law is a known algorithm a
that you actually need to have a doubt
so even this is voted link if there is a
gossip around that are a thousand
megabytes were exchanged but that
actually the only the real megabytes
rates exchanged they they limiter this
line so you only begin to believe people
you directly hear from you believe them
proportional to their megabytes exchange
with you personally so this is not just
a theory but this is improved and
deployed since two years now so a real
Warcraft is shown here where each node
is a fear of here client in our overlay
on top of the bait or network so they
are all fully connected in a fool work
graph where you can do nice mathematical
properties say on these things and the
beauty is that each line is a directed
our fair city so our two exchanges in a
bit orange form any bit towards home so
you abstract away and now you have some
nice things to calculate the reputation
yeah and I usually also in this isolated
and this is the large cluster you have
these isolated nodes we're trying to do
or the PhD team is dealing with these
things um well after this new version
launch then we probably have another
10,000 downloads or something so it's
just periodical for how popular how much
press attention we're getting so um
basic physical fighting that's that
that's the sad
thing so this stuff is difficult to get
right so I've talked a bit about
relevance ranking semantic clustering
that you have keyword search based on
taste and this voting and that you have
these channels and Pierre Pierre so this
is the channels in Pierre Pierre are now
launched and we have this search speed
and this therapy RSS feed sort of and so
you can do voting on this one per IP
number and the sad thing is that if you
happen to have a few thousand or half a
million IP numbers around we haven't
linked it we're not able to link it yet
with the with actual word graph this is
still beyond our capability so that's up
for the next version in the years to
come so this is justices show you what's
the state of the art and how much
engineering is involved in these systems
and how difficult this is for a foreca
demia or other institutes to go beyond
the state of the art here as we are sort
of building the future internet
infrastructure for television um so I've
talked about very search solution say
it's been developed over the years sort
of have with the central servers and and
the web servers super peers so there's a
lot of ideas but the resources are
staggering and so we have more than 22
people in my team working on these
things both on the academic side and
really bug fixing and tracing our Python
code there's been 10 years of evolution
of this field of peer-to-peer search and
the challenge is the complete
decentralization so we now have an open
source system so we hope that that
researches role will start to pick up on
this especially the problem of
reputation and spam prevention this is
not many people work on real system and
we hope that our data set especially
this row graph once it grows a bit and
it's interesting and it can people then
people who work on the Motlop side of
things that they will pick up on this
and and work together with us that we
get realistic algorithms we can
boy in the real world in the real world
so thank you for your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>