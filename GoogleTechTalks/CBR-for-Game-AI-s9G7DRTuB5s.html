<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CBR for Game AI | Coder Coacher - Coaching Coders</title><meta content="CBR for Game AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>CBR for Game AI</b></h2><h5 class="post__date">2008-04-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/s9G7DRTuB5s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Anthony Francis I've been a Googler
for a couple years and rich
Georgia Tech and Aafrin ramas not only
my thesis adviser he's an international
expert on case based reasoning natural
language understanding as applied to a
whole variety of areas including
information retrieval and artificial
game artificial intelligence and today
he's going to talk about case based
reasoning for game AI so Thank You
Anthony pleasure to be here we're going
to keep this informal if you have
questions as I go raise your hand stop
me we'll talk my lab at Georgia Tech is
called the cognitive computing lab and
this work is done with number of
collaborators people shown in red are
people who are currently in my group but
you'll see some papers by people shown
in blue as well
yes I've turned into a pointy-haired
boss I think all these students doing
cool stuff more work with few people ok
so what does gave me I when you talk
about gaming I most people conjure up an
image like this in their mind right
there's some kind of a game this one is
Vargas it's a clone of Warcraft 2 my
teenager tells me I'm outdated because
now he's playing World of Warcraft and
this is a couple of generations old but
it's actually strategically it's very
much the same game in this game you have
of course the two armies the black area
here is the fog of war you don't
necessarily know where everybody is if
you haven't explored and you kind of
think of game AI as this engine that is
going to craft a strategy for you so in
this case we're going to build a base
set up resource infrastructure
production infrastructure a base defense
built towers etcetera and so AI is this
thing that's going to practice this plan
out for you but both the notion of game
and the notion of AI is much broader
than that and what I'd like to do today
is give you an overview of some of the
kinds of things we are working on in our
in our group and happy to dig into
details of any project or any techniques
that you are interested in so to begin
looking at what gave me AI might be
let's start with what games are so we're
also familiar with the notion of games
as entertainment right new era
technology and creativity will fuse to
produce
stunning entertainment but games are a
lot more than that games are being
widely used as educational tools they
particularly like this quote because
it's from the Economist is really coming
from the business community games are
being used in management and leadership
training these are called serious games
you've probably heard of the serious
games initiative there's the website
and they're really being used to engage
the country in a dialogue about
challenges in the public sector in
education and governance city planning
health and so forth and games of course
there's also social games of human games
which interactive games that are
designed to engage people in humane or
social causes
so why games right why am i working on
games why should people be interested in
working on games well games clearly
irrelevant we have all these kinds of
games games are heart these statistics
actually a couple years old the the game
industry in the movie industry go
neck-and-neck one beats the other by a
billion or two any given year but
roughly speaking there about two games a
household any given time in you when you
survey people but a little under half
the people are so in the immediate
market for a game so it's a pretty large
and engaging industry so what games are
people buying people know what what are
the top-selling computer games any
guesses
vigil yeah it is here's a hint some
hands right it seems people on this one
this is one of the top five games roller
coaster tycoon so these are some of the
ones there's actually a couple new ones
now that are starting to make the charts
world of warcraft The Sims what's
interesting is it's a very wide range of
things from things like simulation games
to really just hardcore paddle games you
know the nerdy teenager games if you
will so games are this hard thing is
they're pretty broad games appeal to a
very broad segment of society and as
academics especially in AI a lot of us
have tended to work on fairly esoteric
problems we work on robotics and we work
on expert systems and things are of
interest to so important but I of
interest to niche groups games on the
other hand have a very very wide appeal
in fact there's some really interesting
statistics put out by the Electronic
Software Association educator they
entertain a software education people
know the average game player ages this
is some surveys of people who call
themselves gamers there's not people who
play game once in a while yeah close
thirty three in fact they're pretty
interesting statistics are 25 percent
over 50 any any parents in the audience
a third of us are playing games I don't
know where they where they find the time
I don't about half of them are moms this
one is relevant for for this year what
percentage of gamers bought any guesses
these of nerdy dysfunctional kids who
don't give a damn or these serious
engaged citizens it's surprisingly high
seventy three percent in fact if you
look at the statistics and I must
caution you this is put out by the ESA
they want us to believe that
games are played by regular people but
fairly some engaged to have people there
they're playing sports they read they
attend theater yeah I think are eligible
games yes that's a that's a good point
okay but basically these are regular
people is the point right so it's games
appeal to a wide range of regular
average people from my perspective the
the most interesting thing about games
is that games are AI complete okay what
I mean by that is if you look at what it
takes to be good at games right here are
some quotes from the same economist
article players must construct
hypotheses solve problems who have
strategies learn rules juggle task right
good game players do all of these things
well if our AI systems are going to play
at games at human level they have to do
all of these things as well these are
all unsolved problems in AI so a games
at AI complete in the sense that
developing human level game AI requires
you to solve all the of AI and of course
we're going to try to make a dent in
that okay so the kinds of games that I'm
working with there's games like Vargas
this one's called mad RTS the real-time
strategy games I'm sure you've seen them
and let me see if I can
get this thing open okay so here's
here's kind of a clip from this game and
basically we have blue troops as US red
red is the enemy and we're playing the
enemy here if you notice the enemy is
starting to bunch up an attack but as
we're spreading out trying to engulf
them turns out this is a very good
strategy here so the blue is a gaming
eye system playing prior to any kind of
learning going on and in this this case
this the red strategy which is a human
player overwhelms the blue and and wins
the game in a few more seconds so that's
kind of an example of war grass or other
type of game battlefield 2 type game and
we're doing a bunch of work in my group
with games like this looking at how game
AI systems can not on just not just play
these games but learn how to play these
games better by learning strategy okay
we also have interactive fiction these
are some of the popular interactive
fiction games you've probably seen they
often not even call games interactive
narrative might be a better term here's
an example of one that my student Manish
Mehta worked on in Denmark this is a
simulation of Hans Christian Anderson
it's a museum in the museum setting kids
go up and talk to this character through
video hello how are you show you a short
clip hello glad to meet you do come in
and let us talk it is a pleasure that
you come visit me in my study before we
talk about other things I would like to
know about you I cannot see and it goes
on so basically it's sort of an
interactive character that you can you
can talk with this particular one is
targeted towards kids in youngsters you
can also visit various fairytale lands
that they've created you speak through
speech and and touch and there's this so
animated
embodied characters
so that's another kind of game domain
that we are dealing with so when you
start working on so creating characters
like this or even strategic games game
players that play games like this one
the first question that arises is how we
going to represent strategies
personalities goals actions etc we need
a language for doing that the formalism
we are using is called able assistants
for a behavior language it was
introduced by Matthias in stone in
County at Carnegie Mellon it is a
programming language I'll show you some
examples of it but it's a programming
language that allows you to implement
sequential and parallel behaviors goals
for individuals as well as teams of
agents it implements joint
intentionality framework so similar to
million zombies if you're familiar with
that work from USC you can have
reflection behaviors that reflect upon
behaviors there's a sensory motor
abstraction a service here's of some
here's some example of Abel code that's
a parallel behavior where to attack the
enemy they're these two sub goals you
have to execute in parallel here's a
sequential behavior there's a set of
preconditions that trigger the behavior
and then something you do at the end and
and so forth so this production system
see like syntax okay so given that we
have this language where where does the
AI go
well one obvious place for game AI is in
the non playing characters so we can
have you can be playing war Girgis and
fighting against an AI enemy or you
could be interacting with Hans Christian
Andersen with AI powering the character
you're interacting with so this is
what's called character level AI we have
believable agents with complicated
behaviors that are programmed using some
kind of AI programming language the AI
is focused on achieving the NPCs goals
there's another kind of AI which is at
the director level so this in
interactive narrative is often called
the drama manager so think of it as the
game designer the author of the game a
certain effective and narrative goals in
mind they want to engage you in a
particular
the job of the drama manager or the
director level AI is to watch over your
interaction with the game and try to
manage the game - the interaction to
achieve the author's rhetorical goals so
for example if you are trying to educate
somebody we might change the game a
little bit on the fly to make it more
educational or more entertaining or more
whatever the purposes so the objective
there is is is to enhance the player
experience not to pursue the goals of
any particular NPC so why is this hard
if you look at these types of games the
state space the decision space is
massive in fact there's a nice paper by
David ahah and his colleagues in ICCB
are a couple years ago that shows that
it's basically undecidable thousands of
actions are possible the state space the
perceptual space is very very large
games are non-deterministic if you're
familiar with AI planning classical AI
planning work for example strips no I
Sarah you have these operators that
define what agents can do we have a set
of preconditions that trigger them and a
set of postcondition results that that
entail when you execute those operators
if you unlock a door the door is then
unlocked well it turns out in game
domains you can't write post-conditions
because what happens when you pursue a
strategy depends on what the opponent is
doing and a mass of other things that
are not under your control so you write
it gets very very complicated
the games are non-deterministic and and
things happen in real time you have to
adapt to if you look at the games like
the ones I've showed you at or shown you
are several others you look at so this
code that you're writing the hard part
really comes from two perspectives
the theory is hard how do we model
realistic human level behaviors goals
personalities emotions interpersonal
relationships strategies we don't know
theory you know AI and cognitive science
isn't advanced enough to capture all of
this yet and this is kind of what makes
it interesting for me as a researcher to
tackle the game AI problem there's also
an engineering problem Hans Christian
Andersen if you look at the effort that
made in venting
building this museum exhibit the AI was
much larger really than the rest of the
game put together in part that's because
they're very good tools graphics engine
speech engines our sera
whereas for AI it has to be crafted from
scratch that's one character facade
people heard a facade
so they facade won the slam dance award
last year two years ago it was Michael
matias game it's an interactive version
of if you've seen a heart of Who's
Afraid of Virginia Woolf the play by the
famous American playwright Edward Albee
you get invited to this couples house
for dinner the couples bickering the
marriage is on the rocks
and you saw play the the the play with
the characters the characters are
scripted using able code and but what
happens and what they say and what they
do and how the evening goes depends on
what you do you can interact with them
in natural language or more recently
through an augmented reality headset so
it's like an immersive theater going
experience that has over 200,000 lines
of able code for two non player
characters the husband and the wife okay
that's not scalable it's a lot of effort
required to craft all of these
characters and all of their behaviors
goals personalities etc that you're
gonna need okay so that's partly what
makes it makes us hard so we can't
engineer the game AI it's too much
knowledge to program in and your users
the the kids in this museum are going to
come in and say something or do
something that you're learning to
anticipate the words gonna be different
you can't learn everything by trial and
error either you can't just throw
machine learning at it because the state
spaces are too large this has genetic
engineering got us into this mess and
genetic engineering will get us out of
it
okay this isn't a reinforcement learning
problem where you can run thousands or
millions of trials and somehow the game
AI will train itself you really need a
combination so the three key ideas that
I've pushed in my research or
asynchronous reasoning and learning goal
driven learning and case based reasoning
I'll touch on each one in turn and I'll
give you some examples of them so that
the asynchronous reasoning and learning
idea is this if you look at again
traditionally AI you have systems that
work
one of two ways in in so classical AI
you build systems that reason they solve
problems and then they analyze what they
did to try to learn from that experience
explanation based learning works this
way machine learning is of the reverse
you take a burning system that is empty
in some sense and you train it using
tons and tons of data and when it's
ready then it's ready to solve problems
so the asynchronous reasoning and
learning idea is that you have to do all
of these things simultaneously
perception reasoning action adaptation
and learning all must happen
continuously and all the time
continuance of online manner can't
separate the two so that's one theme
that goes through most of my work second
theme is goal driven learning again
going back to traditional machine
learning systems the human researcher or
the application engineer decides what
the system needs to learn what
algorithms to use what training data to
provide it and the systems are crunches
the numbers for you the goal driven
learning idea that is that the system
itself has to decide for itself what it
needs to learn even whether it should
learn these too much to learn everything
what should we focus attention on when
should it learn what kinds of algorithms
to use and this requires meta reasoning
or reflection this requires the system
to think about and look at its own
traces and figure out what went wrong
what it needs to improve and there's a
book that I've edited with David leak
which collection of papers on this topic
and the third key ideas case based
reasoning again going back to this
dichotomy between go fire was called
good old-fashioned AI and statistical
machine learning is it knowledge-based
as a statistical the case based
reasoning really pushes the idea that
it's not an arson and it's both of them
wait and these these are some some of
the authors you probably recognize in
this area if you know CPR the basic idea
is that we have this repertoire of
experiences that an agent has agent
might be you or I it might be a computer
agent it remembers what it knows brings
it to bear on a new problem and then
tries to learn from that experience for
next time learn a lesson so it is
learning from experience in that sense
it is incremental empirical statistical
but it's happening in a lazy man is
happening as you have the experiences
not kind of pre trained the agent all up
upfront so those are some of the ideas
this is of a snapshot of the
architectures that we're building we
have an agent that gets in a set of
goals it has a set of actions strategies
personalities behaviors available to it
there's a planner that looks at the
state of the world and so decides what
to do next the execution agent then
sends back actions watches what happens
the learner is sort of watching the
state of the world and and the the trace
of the execution and so updating the
action library of the behavior library
and all of this is all happening at the
same time so that the the actions
available to the planner might be
changing out from under the planner as
it's using them to plan and the planner
that has to decide whether replant or
keep going or whatever in fact it gets
more complicated
we have stacks of these things we want
to have a range of of asynchronous
reasoning and learning agents all the
way down from the primitive action level
where we're just selecting the next
action to perform all the way up to us
so planning with strategies and tactics
and even up to drama management or
looking at the whole evolution of the
game and deciding if the game is going
in the right direction and each of these
is an AI problem in itself
I have students working at several of
these levels let me give yourself taste
or some of these projects so at the
lowest most level and I'll show you some
sort of citations here if you're
interested papers on my website or you
can send me email I'll be happy to send
them for you to you but so the idea the
action selection level is we have this
so large state space that we've captured
we perceived in some some manner we're
gonna try to find actions in our past
that were performed under these
circumstances that did well for us by
some metric and so so here's so in in
abstract terms here's the point we are
at along some dimensional space we're
gonna find a few nearest neighbors that
so our past experiences and from them
try to decide what we want to do next so
this is the most statistical and machine
learning style layer in the architecture
and this is how it works and we just
show you a picture of that same scenario
I showed you earlier this is after
learning so we're gonna play play the
same game again we are blue again enemy
starts to bunch up as it as it did
before we've gotten a little bit smarter
and we're starting to bunch up as well
and penetrate the enemy there's a bunch
of exchange of fire but we're staying
clumped up together instead of trying to
go all the way around like we did
earlier and it turns out we are able to
defeat that clumped up group over there
and after that it's and it's pretty easy
to wipe out all the stragglers so the
interesting thing is the system got to
this point learn the strategy for doing
this purely autonomously I didn't have
to program it okay and that's where the
case faced reason comes in so that's at
the lowest level at a tactical level we
can use a similar technique to select
tactics rather than just actions to here
a couple of examples from other
researchers who are doing doing this
this is David a has work at the Naval
Research Lab you have a description of
the state space a set of tactics
available to the system and system
remembers these cases which are
essentially tuples of a state
description and the tactic that was
performed and how what actually happened
the system can use this to learn which
tactics to select under which situation
consonance Franck have a similar
approach they call it dynamics scripting
instead of picking a particular tactic
they're picking sequences of actions or
sequences of tactics they call them
rules that need to be performed one
after the other so in this case we're
going to build a town a town hall and a
barracks by building a rumble middle
chopping more wood etcetera this whole
sequence gets learned through through
experience I've done some work in this
area in a nurse or robotics type domain
as well this is work with the Juan
santamaría one of your fellow students
many years ago and here the idea is that
we keep
so track time history of sensory
readings or perceptions from the world
as we are playing it from the game world
as we are playing it as well as a
sequence of actions that were performed
in the system then learns patterns over
this to recognize that when I'm in a
certain type of situation I can find a
similar matching pattern that looks a
little bit like what I'm seeing right
now
and from that decide what to do next
this type of approach ends up learning
so technical knowledge was it extends
over short periods of time so system
learns for example that if I'm entering
a very heavily crowded environment I
might want to slow down or might bump
into something or get ambushed the
system can learn those kinds of tactics
autonomously when you move up a level
I took this light from Anthony's PhD
thesis work this is a snapshot of a
planner when you move up a level to a
strategic level now we are getting away
from Sir just looking at numerical
values over time and looking at
strategic planning type issues so here
we have to reason about goals and
strategies and plans and counter plans
and so forth so what the system is doing
here is search in the space of partial
plans there's a paper that I did with
Anthony Francis on this the system then
remembers partial plans from his past
experiences and spices and together to
create plans for for the new problem so
what we've done here with with Vargas is
extend this idea to real time domains
the system has this goal to win the game
is currently considering a plan which
involves pursuing goal one followed by
goal 2 and 3 in parallel followed by
goal for goal one has been expanded into
a sequence of actions using a case space
which tells it what to do for goal 1 but
unlike a traditional AI planner we
haven't yet planned what we're going to
do for goals 2 3 or 4 we don't know what
this world is going to be when we get
there right and that's so the difference
because we cannot predict the outcomes
of our actions we just have to execute
them see what happens so this cursor
gets close to our actually one of
Charlie Morton's colleague Jim for peas
work on unwraps reactive action packages
which is a way of doing planning
you know in a reactive or unpredictable
space in this case we're going to build
this plan for delay adapting the plan
and expanding it until we get to that
point in the game and there's some
papers about this kind of delayed
adaptation techniques as well okay um
another project we are working on is is
learning these case libraries if you're
going to watch an expert play either
because he or she is demonstrating it to
you or because you're just playing
somebody who's better than you are you
what the system does here is looks at
the trace of the game as it progresses
and from that tries to capture little
snippets that can be stored away as
cases system doesn't actually know when
if the cases will always apply the
details might be different but it's a
starting point and when the system then
goes to play the game if you see
something that is sort of like the
situation that is seen with the past it
will then remember this this trace and
try to adapt it and and work on it and
try to learn its applicability
conditions we've done some experiments
with this we go on to my students love
this part we play lots of games on
battlenet which is of people who into
games
it's a popular I guess the portal for
for for human players they're a bunch of
these these these maps that are highly
strategic in nature this one's called
nowhere to run nowhere to hide and
computer systems are typically poor at
playing these games these types of
strategic maps these are very popular
maps among human experts they tend to
and and they're so variations of them
what we do is we we train our systems to
play this these types of maps by playing
them against experts or our own students
and seeing how they get better over time
I won't go into the experiments in
detail but roughly speaking the system
is of getting this is with learning
versus without learning getting better
over time as it plays against in this
case one of my students you okay now we
jump up a level so it's that's far we
had these systems that were focused on
to achieving the goal of the game a lot
of this work has been done in these
real-time
hadji games now I'll show you a couple
of projects looking at the authorial
goals or the rhetorical goals of the
designers of the games this is a game
that was built on top of Unreal
Tournament it's a game of tag intended
for kids you go in and these these are
characters with different personalities
are you going to play tag with with
these characters and in this case that's
Jill she's very aggressive if she likes
to talk the other players and Jack Jack
is somewhat more shy he gets frustrated
very easily and gives up if he's not
having fun and and so forth there's a
series of characters you can play
against so the problem you're trying to
tackle here is that the people who
created these characters didn't get them
quite right if you try to create one of
these characters using able for example
Jack may not be quite as as easily
frustrated as you might you as the
designer might have liked him to be
right so what we do is we have jack or
JLo whoever displayed these games look
back over so what's going on in the game
and say hey my designer intended me to
be this kind of personality it's not
really coming across can I tweak my own
behaviors and and be more like what I
was intended to be so we're getting now
into this drama management's director
level AI we're using meta reasoning we
can have the games or fix themselves if
you build a game like facade which
hundreds of thousands lines of code and
these characters are not quite what you
intended they can oftentimes fix
themselves or at least help you fix them
so it's sort of I think of it as
automatic programming if you will and we
have some papers describing that this
work as well
so here's of an example of how this
works we start with this behavior
library in this semi reactive agent the
agent performs a set of actions in the
world it could be a real-time strategy
game could be interactive drama type
world there it's a non deterministic
world loss of exogenous events system
tracks what's going on this we call that
the runtime trace the text anomalies
detects things that aren't quite going
the way you intended them to be
and then identifies rules that let it go
in and tweak its own behaviors these are
code rewrite
system matches those into into the
traces fixes fixes the behaviors
reinsert them back into a behavior
library
we had fun Java trying to get Java to
reinsert running code and and have it
keep going we wish we had done this in
this easy easy to fit it handout back to
an eval and you have reinsert that back
into the running agent in and so forth
we've also looked at at what's called
player preference man modeling using
Dhamma management the goal here is to
make not to change the game but to
gently guide the player towards more
enjoyable parts of the game so we have
the game engine here that's interacting
with the player and the game engine is
generating a trace that is fed to a
player modeling engine that then is used
by the drama manage to decide how to
interject actions into the game here's
an example from Ankur hair this is a
very popular interactive drama we've put
a 2d interface this is a text-based game
where you a search classic adventure
games or type game you type to it in in
so this broken English and the system
then tells you what's going on in the
world we put a 2d interface on this and
so in this example as you enter this
room the player in this example the
system has figured out that you're a
novice player and he's giving you a hand
drawing your attention to an artifact
that you might otherwise overlook if you
were an expert player the system might
decide to lock the door and have you
hunt for a key because finding the
locket too early in the game makes it
too easy in system figures that out
itself we run studies with human
subjects showing that with the drama
manager turned on people tend to enjoy
playing the game a lot more so we're not
measuring so success in the game in
terms of defeating anybody but just in
terms of enjoyment of the players
okay so let me get back to let me get
back to this this vision of this
architecture we have these multiple
levels of of reasoning so roughly
speaking goal driven learning comes in
as each layer directs the layer below it
towards certain learning objectives so
the the metal reasoner so tells that it
strategically what to learn a strategic
layers telling the tactical layer what
to learn and so forth and that helps
guide the learning process down at the
bottom we have this reactive execution
where again you're trying to execute
based on the knowledge you have never
quite sure what the world's going to
throw back at you and that's where the
asynchronous reasoning learning comes in
k-space reasoning in sort of a bottom-up
process where as you get experienced at
each level the level above it can
aggregate over those experiences and
learn cases that then tell it how to
perform how to behave next time we don't
have all that all the levels hooked up
yet
I have students all working at each
level and our dream is to try to get
everything working together we have a
couple of layers connected but a lot of
the work is done currently in individual
layers ok so let me sort of jump away
from the technical work and let's talk
about is this intelligence if we were to
build this thing and connect up all
these these levels would we get
intelligence and how would we know right
so the interesting thing to me is that
game AI or this AI this attempt to build
interactive virtual agents is actually a
very very old pastime it used to look
like this right the punch in 2d or any
of these things that's an that's a
believable agent there's just us trying
to control a puppet and make it feel
like a human make it talk like a human
behave like a human interact with you
and relate to you like the human what
changes the technology right so this is
a screenshot from kanaeva it's a Second
Life type of environment it's one that
was done in Atlanta so I like to use
this screenshot but it's the same kind
of idea that we have puppets us
puppeteers controlling our avatars as
those are the
but they go in and they interact well if
we had one of these things and let's say
one of these characters was controlled
by an AI how would we know how would we
tell in fact what happens if you have
intelligent drama management and the
whole world is controlled by an AI the
world is are changing itself based on
your experience in the world how would
we know and how do we tell so the
classic answer to that is the Turing
test right let you read that says hey
Bert ask if it has a favorite color well
the idea is that you would if you can't
tell which of these avatars are
controlled by a human or and which of
them is controlled by AI then they're as
intelligent as the humans are at least
in this kind of setting so that's not
the idea of the Turing test if you can't
tell the difference they're intelligent
right there
of course counters to this you'll see in
the Chinese room argument right few nods
a few shakes so a bit in a nutshell the
idea is that that's supposed to be at
the URI or one of us who doesn't speak
Chinese I don't
with a massive rulebook here's somebody
talking to us in Chinese they're feeding
symbols we look up the rule book and
rule book tells us what to say back in
Chinese and we produce Chinese from the
outside it looks like we're speaking in
Chinese we understand Chinese but
there's no understanding here I don't
know Chinese and surely four walls and
some paper doesn't have doesn't not send
Chinese and so the argument is well even
if you could fake you into thinking that
that character is human inside of it is
just a bunch of rules just a bunch of
able code or some other kind of code
it's it's like a big Chinese room tour
book my favourite counter response to
that is is is is drew McDermott's
they're actually lots of arguments
against the Chinese room argument which
is which is the sense that I think
computer scientists understand that it
isn't the set of rules that understands
anything just like it isn't a bunch of
symbols on marks on a piece of paper
which tends to which encodes the
quicksort algorithm that knows how to
sort arrays it's when you run the
algorithm you create a process and the
process has in it the knowledge to sort
an array
or in this case to understand Chinese or
to play a game or to interact with you
so it isn't it's a fallacy to say that
the room doesn't I'm sent Chinese or
it's a misdirection because it isn't the
room is the process has been created
where the intelligence really lies
anyway so that people interest in
philosophy there's so fun stuff to think
about okay so let me just close with my
contact information and take questions
so let me ask about the perception of
situations in all the various different
levels that you've talked about so
clearly at the very low level of action
selection your two dimensions are
probably things like position or
something like that where it's very easy
to tell how the distance metric you get
up at the top with partial plans it's
much harder to talk about a distance
metric would look like so since a lot of
case based reasoning involves
identifying cases which are similar but
not the same what's your general
approach to distance metrics along this
wide axis of approaches right that's
that's a great question so yeah so the
basic idea the idea behind case based
reasoning is you've got some new
situation is characterized using some
descriptors it could be low-level
descriptors like position it could be
very high level strategic descriptors
and you have to find cases that have
similar descriptors in them that then
allow you to so replicate or or adapt
what you did in the past in what we do
is we have to develop similarity metrics
we have to look at at a higher level
when you have these strategic structures
they look like hierarchical task
networks or graphs we have to do a
partial graph matching between and to
look for so graph structures that look
similar and have similar ontological
elements in them so we would develop an
ontology or a vocabulary that describes
a domain that then says okay these are
all examples of this kind of attack or
that kind of defense or this kind of
personality and and look for distances
in in sort of a classic AI sense
so and in fact this is a good good time
to plug Anthony's dissertation work he
Anthony did some really interesting work
on a system called Nicole which was in
some sense solving that distance metric
problem inside of a case based planner
and the idea was that we would build a
semantic memory a semantic network also
in psychology is called an associative
memory that recorded all of your
experiences that were interconnected to
each other via conceptual links just saw
an abstraction of how human memory works
when you've had when you're in a new
situation the new situation would then
activate certain concepts in your
semantic memory those concepts would
then spread activation now to other
concepts like them and through the
spreading activation process would then
trigger at the intersections of the
spreading activation would trigger prior
memories that would then hold lessons
for you that's one way to serve
implement conceptual distance matrix
this but there are other approaches as
well in in the case based reasoning
literature there are things like case
retrieval nets which is sort of a sort
of an approximate approximation
extension of a semantic memory idea
they're things like fish and shrink
which is an algorithm for for the way
that algorithm works is you you you you
are probe into a case memory using the
cues you have and then from there you
walk to nearest neighbors and so trying
to do a nearest neighbor search of
everything walk to nearest neighbors in
so the heuristic algorithm trying to
find things are a little more like like
what you've seen but all of this relies
on having a good conceptual network or
conceptual memory of concepts and
relationships between them not not
unlike what you might do in in for
example in information retrieval
problems which I've also done working in
my group where if when you want to go
beyond this keyword matching
then have to connect words in a document
or in a query back to concepts and then
use so conceptual connections between
them to find good matches so we are so
doing the strategic planning equivalent
of that that's a great question so just
to follow up on that second one of the
other things about the work that that
the usher and I did in Nicole was using
context beyond whatever you're probing
with the query like you know that's for
the trace to reweighed the links in the
network so you could have the same query
having a different ranking at different
times depending on the agents context
and we've had some evidence that that
was a pretty good thing to do and we're
still working on it
right so so my question is did you have
any success working with the commercial
companies with under real new games I
think it depends over to my success they
have their hiring my students but mostly
not mostly not and my sense is that I
get interest from them and you know we
get I actually had one of my papers here
got blogged about in by some game
developers and there's a whole argument
about whether this thing would work or
not in a real game and so forth which is
kind of interesting to get their
attention we hit a couple of snags one I
think the biggest bottleneck right now
is that most of the CPU in a game is
reserved for the graphics which is very
CPU intensive we get very very little
CPU for the AI and what works within
that limited amount of time is really
just quick scripted algorithms we also
just hit a lot of the stuff I think is
is not really ready for for primetime is
still very much in research phase
although some of the results we are
getting now I think would be good enough
to transition into a production
environment if we found the right
collaborators so I'm starting to look
now for
want to work on this and make that
transition across into commercial games
if you if you know if any then Excel we
talk with them actually I know the
problem for both sides so I worked on
game AI on my University and then I am
currently working Google but before that
I was a games company yeah and it's
really hard nearly impossible to do
something more than just scripts because
there are drives for delivery
it must be stable everything and nobody
is really interested in creating better
behavior it's because it's not the main
focus so that's why I'm asking it's very
hard to do that's right and there is
there are the delivery pressures and the
budget constraints and so forth as well
it's still even with these techniques
it's still a huge engineering problem to
build these AIS and so it adds
complexity one other issue that you run
into with game AI is that a lot of the
techniques that you're talking about
involve learning which scares the heck
out of the testing departments of a lot
of gaming companies and I've heard many
people say that in the game AI talks at
the Game Developers Conference that's a
good point I have heard that as well
because if the game is gonna learn it
gets unpredictable it's gonna do
something different from what you
programmed it to do absolutely I was
gonna I'm just gonna mention that and
also in addition to this have you done
any work on limiting the resources that
the the AI actually takes in terms of
memory in terms of CPU time because a
lot of the time in game III you if
you're going to take all of that sensory
input and learn from it you have to have
a reasonably high resolution and a lot
of games you can't do that because that
might involve raycast into every single
other and every single every agent in
the world or different entities within
the world and that just is not viable so
if you you're going to think that
pursuing that in the in the research
world that's a good question I have not
pursued that line in my own work there
are people who in AI working on on those
types of those types of algorithms
either resource limited memory limited
they're also what are known as any time
algorithms where the system is is
allowed to do what it needs to do but it
has to produce in a result on demand so
as soon as time's up you have to have
something available but in my work I
haven't I haven't looked at those kinds
of constraints anyone else so on the
resource issue I have noticed a lot of
people in the game AI community once a
an algorithm they know what they need to
do there's often a way to come up with a
set of clever tricks that make it
deployable and scalable if you can if
you can specify what has to be done
so I think as Ashwin was saying if if
you know a lot of this stuff is from a
game AI developer's perspective and an
earlier stage but as the algorithms have
become more mature and the work becomes
more the results become more you know
replicated and reliable there gonna be
things that people can take advantage of
and and they'll find a way to make it
work so there's an actually nice example
of a company that was formed recently
it's called
ai ai live or AI dot live just you know
they're using techniques somewhat
similar to some of the ones I use at the
lower levels of the stack to learn
strategic behaviors for games and you
demonstrate the behavior using a
controller we control or whatever
systems or captures that index and
builds the scripts autonomously so that
you don't have to program them and they
seem to be having some success they they
came out I think some of them came out
of our tent for business group and a
couple of other research groups and
transition their technology so I think I
think you're right and maybe I think
some of this stuff is starting to get to
where it is deplorable and some is still
in in Balham and you know it's going to
take some years
it's just just to comment on that it's
just funny and the method you describe
for learning and like taking a number of
sensory inputs and then analyzing that
date you're using an algorithm and then
you know building behaviors out of that
that effectively is what a lot of AI
programmers will do right they'll sit
there they'll run their game they will
trace the data look at the output and
kind of figure out okay I need to build
this set of behaviors to make this this
work for me so I find that interesting
but that's more of a deterministic way
of producing reliable way I rather than
rather than your method where
potentially you could end up with
behaviors that that you don't want to
happen in the game yeah one of ideas for
the learning by demonstration work was
that this could be a useful tool for
game developers in order to if you
wanted to build an AI you could go play
the game using a kind of strategy wanted
to the system to learn it would capture
that in a script and play it back for
you and then you could go tweak it and
get it perfect as opposed to so writing
everything from scratch
I mean that's that's the problem there
are always educators in these in these
situations like for example one guy I
used to work with II he played around
with fly fly and I I like my aircraft to
fly around and shoot you and all this
sort of thing but there had and he
worked on learning procedures as well
but every once in a while that the edge
places where it will just decide to
crash or who decides fly into a mount in
and and those are the sort of things
that you really don't want the end
consumer to see because they'll go you
know you saw this game starts right I
know that's points well-taken
so you said earlier this you made the
point that the state space is very large
so you can't just throw a machine
learning of the problem but then your
approach is to show your many-layered AI
at every level of which you've made an
abstraction of the state space from the
level below so of course you've reducing
the size of the state space at every
level so have you made your abstractions
why don't you just throw machine
learning at the problem at every level
so is this is the abstracted space space
state space small enough now so at the
planning level like at the top like at
the level of like plans for example
right you have let's say a limited set
of actions planning actions it's ten or
twenty or thirty or however many but
that's a lot smaller than working in
like XY coordinate space very so so yes
and no so we are beyond in some sense
throwing machine learning at the problem
but we are doing it lazily the problem
it's a pre training everything is that
even if your state space and your action
space are somewhat limited games
temporarily extend temporarily over many
many cycles and to place of all possible
combinations of all the games and try to
capture everything up in advance it's
still a huge computational problem but
but so one of the ways that learning by
demonstration helps for example is if I
watch you play I'm getting soaked a path
and I can explore some of the region
around that particular path whereas
there might be another path over here
I'm not going to explore because it just
might be completely off the wall wait
the system would have no way of knowing
which one it wants to explore until it
actually sees a demonstration by an
expert another player in that direction
so in some sense it's it's using
experience to guide the exploration
process in productive directions
so it seems like when a human starts
playing a game like Warcraft he brings a
lot to the game that he doesn't
necessarily learn there like basic
algebra to figure out what he can what
he can purchase with his available
resources and it might it might not be
effective to try to train the game to
learn that sort of thing within the game
right that yeah that's that's a good
point so there is I think there is a lot
of stuff that we bring to bear to the
game that potentially could be loanable
but may not be fit may not be productive
to spend only energy on that right and
and so you're right the game's the the
game playing agents do have a lot of
stuff built in already which is all the
stuff we don't want them to learn and
we're trying to focus on on so what we
turn to stay focused on what we think it
would be productive for the game AI had
to learn so for example one of the
things we we're looking at is if you if
you take a spray a game where you have a
large state space the many possible
combinations and and derivations of that
safe space that could yield some
high-level abstractions not all of them
are equally useful how would I say you
write a system couldn't compute all of
the the deeper or more abstract features
out of the surface level features
because that would be computationally
too expensive
now we could knowledge engineer set of
features that we would like the system
to use which is what we've been doing
thus far but I have stood now looking at
could a system actually learn which
particular abstractions are worth
learning through trial and error
anyone else all right well thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>