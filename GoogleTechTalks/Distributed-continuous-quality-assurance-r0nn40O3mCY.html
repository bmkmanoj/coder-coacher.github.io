<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Distributed continuous quality assurance | Coder Coacher - Coaching Coders</title><meta content="Distributed continuous quality assurance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Distributed continuous quality assurance</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r0nn40O3mCY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I didn't expect you to read all of that
but what I'm get started so as Alan said
my name is Adam Porter and Vanderley
talking about some work that I in my
colleagues have been doing class from a
couple years exploring tools and
techniques for what we call distributed
continuous quality assurance so as we've
heard many times the in this conference
modern systems under lots of different
measures are a measure getting bigger
and bigger and more complex so we see
systems now to run on numerous platform
compiler and library combinations
they've got tens hundreds even thousands
of about configuration options they get
involved in a rapid cycle by sometimes
just geographically distributed in
development teams we've got they were on
top of other frequently changing systems
and they have not just one definition
quality it's not just functional testing
but lots of different things performance
reliability compilation time memory
footprint lots of different things so
I'm giving you a sense that that for a
lot of systems that we're seeing about
for now this it's pretty chaotic it's a
big difficult problem to do QA and it's
not it's not just one system the rock
and looking at but maybe the think of it
as a vast web of partially
interconnected rapidly changing systems
so the question that we're looking at is
and well how do you even think about QA
how do you do QA for systems like this
let's talk about some typical things
that we see people doing various
projects that I've been involved with
the top two so you get developers check
out code make changes locally and then
perform some kind of QA on their local
copy remember they have available that
got me one linux box 11 mac box and
that's what they do and then they check
this stuff back in sometimes you've got
continuous integration building test
servers that are typically looking at
the freshest latest copy the system OCS
ed if this is being done by multiple
machines are often uncoordinated okay
have different machines doing various
things we're not really talking to each
other so overall which is there is lots
of humanity
effort being expended but we still have
systems a break out of the box it will
compile they too many bugs escaped in
the fields go get laid integration
surprises and all kinds of things like
that so looking at these kinds of
processes were asking so what's you know
what's not so good about them when
working in Groovy's these processes and
we see a couple a couple of contributors
to failure there so we see a lot of
humane being done under the land books
are just for the most readily america
platforms and justin default
configurations a lot of redundant
efforts so assistant knowledge QA
artifacts QA effort the results of
activities are not being shared among
different people on different machines
and among different projects software
limited to a very narrow scope limited
kaijus compilation or just a couple
simple functional functional tests and
then we also see a lot of times the
process itself is static it doesn't
learn over time so we will see a build
server that's building system and it
doesn't compile and then it just turns
around and goes it again even though
there's there been no changes made in
the meantime so there's a lot of you
know there's a lot of sort of spinning
your wheels in certain areas where we
might be might want to use it
information say well I already know that
configuration doesn't work when we let
me go find something else to look at
where we really need more information
okay okay so sort of generals General
assesses we've got you across seas that
work reasonably well but typically they
work well for a very few things on a
very thin slice of the system okay buddy
lots in the rest of the system you've
got big deficiencies and developers have
built a blind spots in terms of how
their system performs and they don't
really know enough about their systems
so you've got large portion of assistive
space they go unexplored because of this
developers when they change the line of
code they're not always really sure
what's going to happen okay because
there's lots of parts that lots of
different configurations or different
setups in which they really can't
predict what's going to happen part
likewise is hard to interpret from the
field failure reports and feedback so
this is a system consider the situation
of ec and our approach to dealing with
this like about a couple of good things
talks we've seen is
few days is what we call distributed
continuous quality assurance of a CEQA
so our idea is to sort of redesign 28
prostate so they'll run around the world
around the clock on powerful virtual
computing grids where a grid might be
run directly on end-user machines for
some things it might be on you know all
week all the computers you can get on a
company-wide internet it might be stuff
run on a dedicated computing cluster the
any of those things work for us in terms
of our grid and our channel approach
then to sort of redesigning these
processes is to take some high level job
chop it up in the millions of little
pieces and then hopefully we can
intelligently distribute those pieces to
remote clients wherever we can find them
okay so we'll send out these little
partial sub jobs or tasks the clients
and get they'll execute them give us the
results back and we'll hopefully have
some way of merging those partial
results together to try to complete the
overall analysis so that's our that's
our general model and we're going to be
playing with with ideas about or looking
at how well that works and what we can
do with that model some of the reasons
why I want to do this obviously NASA
parallelization when you lots more few a
window faster we want to do QA a much
broader scale one when greater access to
resources and environments that may not
be available to a single developer
especially thing like open source
systems or end developers with a limited
set of resources under their direct
control but the system still runs on
lots of other things so how does that
developer know that their changes work
okay on other other resources they don't
have that finally we'd like to do this
hopefully do coordinate the effort of
all these different QA players so that
we knew more sophisticated things and do
much more mature aging processes by
working working together with on the
problem okay so will the rest the talk
we'll talk a little bit about the what
we're doing here and so the themes will
see over and over again are we want to
leverage developer
location community resources okay we
want to maximize task and resource
diversity we want to opportunistically
divide and conquer the QA analysis we've
got large problems big problems will
chop them up and take a little piece of
the time not necessarily trying to do a
perfect job every time we want to
coordinate these different in the
different efforts that we have its due
process to improve efficiency and
effectiveness and where we can't let to
gather information proactively so I want
to be just looking necessarily at the
current version of the system and
telling you know give you about us or
one bit yes things work though things
don't but trying to sort of also take
things like what kinda learn about the
system today that will set me up to
answer some questions I'm going to need
to answer tomorrow or week from now okay
we're doing this work of a lot of other
folks we have clatters and Vanderbilt
Georgia Tech Nebraska National Institute
of statistical sciences and lots of
folks at the University of Maryland menu
for companies heard Sondra talking in
the new audience here so he's here today
okay so the rest of the talks are
divided into three pieces on a little
bit of a very high level overview of a
project we call school it's an
infrastructure and approach for
implementing these secret processes then
we'll talk a little bit about how we use
this infrastructure to do what we hope
they're cool things in terms of PA
across large configuration spaces and
I'll just have a short wrap-up some
conclusions and future work ideas okay
notionally now here's our here's our
school servers on on our left and our
clients wherever they are out there on
the right by the way in this talk about
it expect more details it's all going to
be very high level but details I've got
some references to papers and things
that you look at and you're going so
check out our website
this whole project if you want more
details and I'm have to talk to you
obviously afterwards okay so what we do
clients register and they get a piece of
software from us that we call the client
kit they install that client kit and
then periodically that plank Lee or
whatever then whenever the client
decides that they're free that client
calls back to the server and says kind
of here I've got some free yes the work
would like me to do okay at that point
are our sole servers I'm going to look
at you know what problem we're trying to
solve what parts of the problem we've
already done what's left to be done what
sort of rules and other things have the
QA engineer set up and it's going to try
to find the best next job to do and
match that to the client I mean
basically clients characteristics of the
client says not here I'm ready to do
some work and and I will the next box
and I have a GCC compiler what we needed
we need to get a job it is going to work
for a linux box to the GCC compiler so
there's some matching them have to do in
so there's some opera and some
opportunistic and aspects of this we
have to fit the job to the resources
that are presented to us okay the client
that gets that job they execute it they
give us back the results and then the
server will update its internal
databases and a bit of information about
results and then you can essentially
just sort of imagine lots lots of
clients doing all of this at the same
time okay and then the quest so the
reverberating that's over general I
didn't question is how do you implement
an interesting bc great process using
this model so basically there's two big
steps that need to do first thing we
didn't do is to define how r QA analysis
is going to be subdivided by defining
what we call generic QA tasks and then
you're going to have to define also it's
called the QX pace which is the set of
configurations in which that generic QA
task operates so q8 a stem cells are
templates they're basically kind of
workflow descriptions that get
parametrized by a configuration where
configuration is some some capturing
the variable information is needed to
execute a particular concrete QA task
and then the QA space is just a set of
all legal legal configurations in which
list those QA tasks can run so which is
which again this first step is a sense
of a giant good things for a giant
n-dimensional space that says these are
all the configurations in which this 38
capsicum run okay then the definition of
the process itself need to find how that
the QA tasks will get schedule and how
resultant process by defining what we
call them in navigation strategies and
so you can think of these as kind of
like visitors that walk around somehow
walk around this QA space applying tasks
at various points and somehow you know
gathering the information processing and
stuff like that so again very high level
picture of what we're trying to do here
I'll try to drill down now and give you
a few more examples and motivates a
little more concrete okay so we've put a
lot of work with the project's called a
thousand Xiao it's a julienne line open
source korba implementation it's
maintained by over 40 core developers
who are geographically distributed
around the world you know it's out there
it's open source to lots of people also
setting a little patches here and there
but there's most about 40 or so is the
core group about 20,000 users worldwide
it's a product line architecture the way
it's set up it's got over 500
configuration options it's intended to
run over dozens of OS and private
combinations but when when they're when
they're doing a lot of money or pink
moments they've got over 200 CBS commits
a week sort of like one an hour
constantly and for them and quality
needs a lot of things what's not just
correctness it's very quality of service
measurements its memory footprint
compilation time etc etc so we want to
keep that in mind and we've hit the gay
musical to essentially set up a
to build an integration integration test
service for race and down okay just give
a weird x or just beginning that but it
is sort of a partial picture of how we
do that so remember I said the first
thing we need is to find a huge space so
we go through we define things like the
operating system on which we couldn't
which the system is to run for certain
internal static compile-time options
there's now as minimal korba there is a
rut there runtime options various kinds
of policies various kinds of
optimizations and what levels that can
be set at there's a style the child
components which versions we want to put
together we have options to talk about
with whether or not you can run a test
in a particular configuration because
some tests are meant to run certain
configurations that are not allowed to
run in other ones and we don't want to
deploy obviously the work that the test
I can't run or not intended to run a
certain configurations we don't have to
plug those to the to the IMP to a client
finally if you look at this you know
getting some n different options and a
whole bunch of different settings and
configuration can be sort of any one of
those some of these are not legal them
again some you know some options cannot
go exist some options settings handle
coexist with other option settings so we
have also constraints here we have it
doubt has a mi which is a secure his
message invocation support best turned
on you must not be in a configuration
which now has minimal korba ok so the am
I stuff needs more than the minimum
korba implementation show boasts a
configuration which days am I and
Desmond or boat would be illegal and we
don't want to look at that and then
they're also about tests and stuff like
that we talked about before okay so
we've got a QA space now this exam
getting example of a generic you a task
so basically what this is it's a kind of
workflow of services and these services
are provided by that client kickin
talked earlier so we sort of give this
service oriented architecture kind of
thing
the client kid and then the QA task will
essentially call services that have been
already deployed on the client side so
we've got some that are built in turn a
logger on you know do it as he gets the
download upload the results back to us
some of those are built in most of the
interesting things have to be provided
by the project itself okay so we know
you have a multi-platform system and you
want us to build it on different
platforms you got to gave us some gold
files that make files whatever it is so
we can do that okay can dig your scripts
and things like that okay then just a
simple example of whatever we have like
a run tests we've passed and again I've
sort of been elided a lot of the details
but it does things like it starts it
turns on logging it defines which
components going to be built the sets
configuration options environment
variables doesn't download from CVS repo
it figures and builds compile the tests
execute the tests and then uploads until
to the server so this is a kind of again
this is not the actual format it's it's
a it's next time a lot more detail in it
but just to give you a cent sort of
overall peanuts the kind of things that
we do okay so now we've got a QA space
and we've got tasks to apply in that qh
space and the next question is in what
order how how does this all taught us
all get put together so we give you an
example so the Austrian building should
say on navigation strategy and something
we call nearest neighbors search so
these black dots here represent one
valid configuration and this is just a
piece of a horrible puzzle hope the real
system and then when i've done here is a
drug arc between every two
configurations or so any two
configurations that differ in the
setting or the value of exactly one
option setting in the configuration have
an arc between them okay so this this
configuration might be kept k options k
minus 1 or exactly the same is this one
and one of them is different okay so
this just gives us a sense of distance
between the various various
configurations and so you can imagine
now clients out there who have download
our software and they they you know one
calls up to gain some work to do and say
here take this configuration go bill
didn't run some tests for me send some
results back okay let's say it say it
passes well then I'll most part that
green here okay and then some other
client calls in and says I can buy got
some work to them right do some work
what would you like we can do I go to
configuration and it takes this one over
here another fails okay so in this
particular navigation strategy what we
did with in as we find all the distance
when neighbors of that failed
configuration okay and we make those
high priority tests so if other clients
come in who can execute those
configurations we will do that first
okay and so we start from there and we
keep seeing and if we have if the
neighbors failed and we will make their
neighbors high priority etc etc if the
knee go past is like this one up in the
corner then we're going to stop there
okay and then we'll just keep sort of
spy during out here and the intuitive
idea is we're going to keep trying to
find the border of this failing subspace
okay and then this this picture will
just sort of keep going for a long long
time but what you'll see is via this
area here we've got failing failing
configurations and turns out these ones
all paths okay in this particular
example and so I will
keep going and bore you one other point
here is that if you look at this section
over here that had this failing subspace
if we can determine early on that this
can be very large so if we can determine
early on you know sort of what's special
about this configuration who can model
that and some understand where it is we
can also then introduce temporary
constraints into the model that say look
I already know this area is broken you
don't have to run you don't have to
execute every configuration here to tell
me that's broken I already know that all
right so let's stop wasting time here
that's why we put temporary constraints
in here that say go look someplace else
because these are now invalid
configurations and then we can also in
fact use this later to look at attaches
we have we have a fix to this problem we
can actually negate the temporary
constraints and then start at spawned a
new process that looks exactly in that
area so sort of an example of how we use
this all right let me hope that I think
hope you get the general idea here
nauman try to do is get a couple other
examples and other kinds of DCF a
process we built this model and also
talk in a very very high level or just
going to summarize some of these
abilities studies we've done then apply
these techniques and look at how will it
work okay so the first thing we looked
at so that we call configuration level
fault characterization so the goal is
with what I was talking about before we
want to help developers not only know
where things are breaking but also not
only that things are breaking but also
tell them where okay so we might be able
to say you get this error message right
this kind of failure when this is true
this is true this is true a bunch of
configuration you have this other kind
of problem when this is true and this is
true about your configuration so we want
to not only find the bugs but also try
to give some information to the
developers about where we're lives okay
our approach then that we can talk about
this in this stage is the strategically
sample the QA space to test for sub
spaces where bad things are happening or
complement
Vail's where regression tests fail
things like that and then we're going to
take that data we're going to feed that
to some learning basically learning
algorithms AI type machine learning
algorithms and we're going to try to
learn that information what specific
settings of the options explain where
this fault is now or can you do that ok
so our sampling strategy or your goals
here is to try to cover maximize
coverage of the various options study
combinations while minimizing number of
configurations tested so the point here
is that at a certain point these
configuration space is start to get very
large very fast okay and you just can't
do everything so in this particular
example I'm going to try to come up with
a way to try to really cut down in a
work that we're going to do and our
question is well does this still give us
good characterization does it still help
about responding the problem is okay
it's our approach to compute something
compute a test schedule using something
called the teeway covering ring and in
English a TV coverage is just the set of
configurations in which all ordered tea
couples of the option settings appear at
least once in the test schedule so let's
take it a simple example where T is too
all right so what I want to do is I want
to make sure that my I'm done with my
running all my tests i have tested every
combinate for every two options every
combination of the option settings has
appeared at least once so let's take a
simple a simple assistant here I've got
three options 01 02 and 03 f three
settings each 0 1 and 2 and what you'll
notice or at least the nine
configurations are reading you know this
is one configuration two configurations
three etc if you look at options what an
option to okay you'll see that we've got
all combinations of the options 00 01 02
10 11 12 20 21 22 now look at let's try
20 2 103 the same thing is true 00 01
let's go to 10 11 12 20 21 22 same thing
is true about 01 03 but hard to show up
our friend and so what this says here is
that instead of looking at 27 and
configurations which is the total number
you have here in the space we're going
to look at nine okay and we know about
this nine is at least we've covered the
two-way the 2a combinations all right so
we're going to that's our test schedule
we're going to give that to the various
clients as they appear rain get the data
back now we're going to number and ask
the question can I figure out what's
special about these failings statement
or if there's anything special about
these feelings subspaces I can tell the
developers and we use something up this
work we use something called
classification trees really doesn't
matter there you know a whole bunch of
different algorithms you could use this
is just one we happen to pick that's
well known and has some customized
properties we applied this in a begin to
acen down and chow the scenario is one
ano do all the regression tests passed
across the entire configuration space we
built a small configuration smallish the
iteration space and about 40,000 valid
configurations that included 10 compile
times up and compile kilometers with all
constraints 96 test options 120
constraints states run times up runtime
options with no constraints to operating
systems the analog accommodations you
got about 40,000 here we look at to
navigation strategies the nearest
neighbor which is the first one I showed
you and this last one based on these
dewitt covering raised we applied this
to one stable release of a scout out
running on that kind of computing
cluster we have a Maryland with 120 CPUs
and we just looking around and look at
the you know sort of local citizens and
saw what happened you do this
exhaustively not including compile time
to just just run the tests takes about
19,000 CPU hours doing it with the
nearest neighbor approach again spread
out over all the machines we can do it
in about 70 days using the
the cover approach though if we only
want cover grade to make covering raised
we can do that if only 116
configurations which is about ninety
nine point four percent reduction on
three way accommodations we can get down
to 90 or ninety eight percent savings
for way five way we're still at about 82
percent the 6 and 16 are games a six-way
upgrade then let gets a little hectic
and we start sort of approaching with
the with a full space looks like but in
any event these schedules give us a
controlled way of looking at the
configuration space and a much smaller
than doing the exhaustive exhaustive job
we have lots of different results from
this we found 89 possibly option with
failures 40 on Linux 14 on Windows
interesting point is the models that we
build even using just two way coverage
using just only 116 configurations we're
nearly as good as long as we got from
the exhaustive data okay so so we not
only were able to not run cement ask but
the information got back about where the
specific bugs were showing up this was
pretty good was close comparable from
the exhaustive data to this very small
configuration very small cover great
test schedule which we thought it was
very good I'm obviously if they're there
some bugs that just work very easy to
classify ivica the exhaustive data and
usual not going to do that too much
smaller small example here okay just
some other things some several tests
failed that don't fail with default
options so this is project currently
depends a lot on installation tests in
the default configuration isn't it
what's working or not working and
obviously we run the tests we say we've
got lots of problems that are not here
default configuration any go look at
those two this sort of reinforces our
idea that test and environment diversity
is probably a good thing your test
process some of the things we're just
kind of finding some tests failed on
every single configuration lead them
into fall configuration even though it
we only around them as default they
didn't fail what does that mean so as
soon as basically was the problem in the
option processing code so as soon as we
actually physically put an optional
the set even was the default option some
some problem was kicked out was
basically hit there and then things with
it but my bad ok so again it's sort of
interesting thing they're just you're
only looking to default configuration on
on a couple readily available platforms
you really are missing potential miss
him a lot some other things are
interesting we had a couple tests that
failed when a particular runtime
optimization was turned on I'm starting
to turn off ok so an Oracle location is
no basically when applications no
objects in this quarter implementations
korba application have to talk over the
network if you said it's a global or /
or then there are times when local
objects can communicate through function
calls as opposed to going through the
network and what we found as you know
the student when things weren't talking
on the network they didn't fail right
when they didn't talk in the network
they fail because that's good at the
developers and some pretty good clues
something about the way they're moving
data around on this network ok so in
fact it was it was a problem with a
marshal none marshalling data so again
you know there's sort of this
interesting benefit by giving this
characterization to the developers it
helps them to discard it doesn't
necessarily tell them exactly the
problem is but it helps me discard a lot
of other things and improve debugging
time okay at this point basic summary
for this thing basic infrastructure the
school of instructions in placements
working our initial results are
encouraging we've defined large control
spaces perform complex processes found
many test failures respond corresponding
real bugs some of which that a stash
house in find themselves the developers
tell us the fall characterization helps
them in debugging and another really
interesting thing
happened was documenting and
centralizing the constraints information
about which configurations are legal
Englishman's are you have to get
enormous benefit because they did the
developers in the room and they were you
know violently disagree about what
configurations with legal or illegal so
in this in this sort of distributed and
open source type environment there it
turns out that there was a lot of
there's a lot of knowledge of the system
that it just ends up being dispersed
among the different players and it's not
in any one place in November limits this
was sort of a an interesting point that
once we were to centralize this the
developers actually had a half shot a
lot of issues about which things really
were legal issues weren't breakfast
before that you had developers writing
code for configurations that couldn't
exist and they had leaving out stuff in
because they thought a configuration was
illegal when in fact it was with the
legal said there's this problem there
okay so smug way extensions we're
continuing to do this work on a stout
Chow and trying to expand our QA space
for this process of the stuff that we've
done online with the a star child
project now is very small and there's a
very small number of options that we're
looking at and written process of
expanding that must see how far we can
go with that is a live test of our ideas
we're also looking at expanding this
model for platform virtualization it's
sort of like what I saw some of your
talking about today but what we're sort
of getting asking is if given I've got
you know Zen or VMware whatever on my
machines what's an efficient way to to
reconfigure platforms for example if
this guy's already got a Windows
operating system lon make it cheaper to
move the shift some jobs to them and
just change other libraries or things
like that as opposed to doing a Reaper
reconfiguration the ground up so there's
some interesting problems that pop up
about given that you've got platform
virtualization how you how do you use
that an efficient way and scale things
okay second second process of looked at
so the person look that was headed with
testing function testing we also think
we can
and ideas in certain ways for
performance so our goal here was to
quickly determine when whether a
software update degrades performance
somebody asks about that question
earlier this morning our approach is to
proactively determine a small set of
configurations on which to estimate
performance across the entire
configuration space so we don't want to
we don't want to benchmark the entire
configuration space you want to find a
nice small subset benchmark those and
get a good estimate of the performance
across the entire space then we've got
proactively now that's before anybody
has made any changes to the to the
system okay later on when the actual
change happens and you're checking that
end then we want to remove middle on a
basically benchmark though that small
set we just determined before we'll call
it a screening suites want to mention
are the screening sweet and look at the
look at the performance estimates and
decide have things changed or not based
on the last based on last update okay
okay so let me give a little more detail
about that process so the way that we
find this little screening sweetest by
basically defining a statistically
designed experiment using something
called screening design although gangs
other other approaches and the idea is
to say well given all these options
which options and the interactions among
the options effectively define the
estimate performance which ones are
important and which ones are noise from
the perspective of a particular
performance metric we execute the plan
across our QA grid we analyzed the day
that we find the important options and
in this proactive loop here can be
recalibrated as often as you want based
on how fast your systems changing on the
reactive side so once we've got this
screen screen information now software
changes what we're going to do then is
we're going to evaluate all combinations
of those important options so that
screen this week what we randomize the
rest we've already determined the rest
are noise for our purposes okay so we're
just going to look at this all
combinations of the small sentiment came
up with and then we're just going to
compare the distributions and
change that should be a signal that
change in a bad way that should be a
signal to you that there's something
that's happening you need to investigate
further okay all right does this
actually work though so we had guinness
own study based out round group they had
some changes to how they handle message
queuing and they wanted to know does
this degrade performance so they
identify for us 14 potentially important
binary options things that had to do
with with messaging and communication so
it's about 16,000 16,300 whatever
different configurations to look at and
they were various kinds of runtime
options and things like that you know
various questions about when they when
they purged certain cues and and also
the kind of stuff there's already known
as a point out early there were some
some papers that are referenced here on
earlier slides as when you want a little
more please check these out and because
the slides will be online at some point
okay so if i should put sweet me that we
find this screen is where we do we
develop the screen sweet okay and the
first question is does it really return
the right information about which
options are important or not okay so
what we did is this is the full data the
full data set and we look at the option
effects and then we sort of sort of
invited by my effect size and what you
see is that BJ I see it so being J are
clearly important they clearly affect
maintenance in this case I JNF possibly
possibly affected all the rest are
pretty much pretty much debt they push
on to anything okay so those five
options BJ I C and F are going to become
our screening sweet now the question is
when we use the when we actually run our
screening design in order to compute
this the screen sweet then we David come
up with the same information and what we
have here then is the the outcome of our
running just 128 carefully chosen
configurations as part of our
experimental screen design and what we
find is in fact DJ icey
show up as being having the right levels
of importance of pictures like we
thought and again we did this instead of
running 16,000 through June 380
configurations we did that with just 128
so it's a highly efficient mr. distantly
based process for coming up with these
options and then this gives us a sense
that the that approach that part of the
approach worked ok now the idea then was
well then that shouldn't software
changes we're going to going to
benchmark just those 32 combinations
above the screen asleep and supposedly
this is going to give us a good estimate
performance across the entire
configuration space ok so what we did
here is we actually benchmark everything
which is on the horizontal axis and then
we benchmark just being 32 configuration
that are straining sweet and then what
we do is we basically plot the quantiles
of the distribution against each other
okay and so the point is that if the
quantiles of the distributions are the
same okay then for the real data or the
estimate then everything all the diff
should line up on 45 degree axis okay so
if the quant house in the same place
that this data shouldn't you end up on a
45 degree line and you know basically a
definite about one hour later at the top
but but effectively this is this is
pretty good it's good enough for
government work here this means that
running 32 configurations did in fact
give me the same information or most of
the same information as I would have
gotten if I'd done all 16,000 so clearly
that's that's great ok ok so again on
this data you're the same to work so
then we did is be applied it to to an
actual evolving system so in fact the a
style Chow system we're going back to
the release that we looked at when we go
through and opening the our model and
then we basically took a CVS snapshot of
the system every night for about 14 days
and we ran our screening sweet on that
and when we plot again is the
performance distribution the actual is
promised
the distribution of the actual basis of
this is a full day here this shows us
the the actual distribution of the full
data across these 14 days and what you
see then is the first two days you know
if we sort of assumes the baseline third
fourth and fifth date latency starts to
creep up which is bad okay and then this
six-day things really go go haywire okay
applying our approach what we found will
come that you found out developers and
their records notice the deviation just
on this day and not before and in fact
they only noticed it because they've got
lots of irate emails and phone calls and
stuff like that okay so people were just
calling up screaming oh my god looking
down you broken things very badly they
and their benchmark that they did at
service they weren't you're worried
about it placed assaults were like a
five percent drop in latency when the
rate when really as we see heart
information it's more like going on
fifty percent drop okay so our approach
we think basically you know did good
does a good job at the estimation and it
found the problems earlier then then
what the agent now shot guys were able
to do so we think we got a cheap process
that gave us information early and
better than what they were doing its
that'sthat's Irwin overall summary of
this part we've got negative liable
effects screening process and efficient
effective for people approach to
estimating performance impact of
software updates in this case it was
effective in finding actual depredations
and real real data a very interesting
thing from our perspective that it can
actually cut the benchmarking work by a
factor of a thousand so this would
probably for fairly short benchmarks but
instead of taking one with the two cpu
days to compute the full all
benchmarking best part of all
configurations we were able to do
justice 32 configurations in
two minutes was our five minutes so now
this process goes from being because we
did the hard work up front of finding
the right important options this thing
goes from something that's like a
special deal that you got to set up for
you know for two days worth of work
there's something that's fast be part of
the check-in process and again that's
something that we think I really want to
push this idea of doing things
proactively so that you can get a nice
time bounded answer to QA questions when
you know when you really want them okay
and sort of our first example of doing
that will be happy about that okay
ongoing extensions we're working with
some statisticians who come up with a
new experimental design process how cool
the nova which we think of a better than
the screen designs over so little safer
fewer assumptions we're also looking at
things like where we've got these sort
of multi-tier two component component
bae systems we often find that you know
in order to get some some outcome you
know setting an option at level 3 also
requires you to do something else at
level 1 or level 2 and often these
instances components are often built by
different people the application guys
they're integrating this up don't go
back okay so we want to use a similar
kind of processes or look for
interactions across these layers so you
can sort of thinking think about this is
a kind of configuration advice kind of
system they're going to run one clip
that idea okay last little piece is
something called code level fault
modeling and this is something that so
before we were talking about in our
first little process we're talking about
configuration glidden problems here
we're going to try to get that into the
code itself and here you also see that
our notion of a QA space is no longer
runtime configuration options or static
configuration options or the things that
you think of as being served traditional
configurations it's the term that it's
actually looking at which things we
measure in the system okay so we don't
just want to give a sense that our
approach is limited strictly to
tradition the traditional sense of
configurations it can be usable
things as well okay so our idea why
automatically gain a little insight into
why it meant specific Falls occur in the
field or so and we're focusing on
fielded programs here our solution
approach then is to lightly instrument
deploy and execute program instances so
we've got multiple copies we're suddenly
have multiple copies of this program
we're going to instrument them deployed
into clients gather some data and then
you know try to build models and say
well what is it about the execution
profiles that you're just capture or is
there anything about those exclusion
profiles that will give us a clue as to
where the system is failing or even you
know for what the characteristics of the
executions are or they do our some
failures different than other failures
this kind of things a couple deformation
I use the data okay so to do that we
have to step so we have to go through
the first one is our choice of what to
instrument and all the different
instances okay so what we do is we come
up with something but what we want to do
is to minimize overhead we don't want to
have too much fun times slow down the
components we don't want to have to
you're too much code rewriting to go
mean so in the insert the new probes
when keep the data volume down analysis
costs etc so we're use an incremental
data collection corruption yet this is
sort of school is good for this because
we can sort of do something get resold
back modifier what we do and then
instead of next client something else
modify things based on their results and
keep on like this so what we do the
individual instances are going to
sparsely sample the measurement space so
if we've got in just a simple example
we've got you know 10,000 lines in the
program I want to measure execution you
know hit counts on every line okay well
I'm not going to have every instance
measure all thousand doesn't another I
could have their reasons measure all
10,000 points I'll have them maybe pull
out a hundred apiece okay so each
instance is going to probably come up
with a different hundred instruments to
measure on their run okay
and then the question is which which
hundred you pick okay initially we start
with sampling weights their uniform so
all all measurements are equally likely
but over time what we start to do is we
start to correlate the data is coming
back in with its ability to or its
correlation with the outcomes all right
does this measurement sort of give us
any information about whether the by
itself whether the program pass or fail
okay and the ones that start to show
over time some connection to to passing
the family we're going to up their
weights we're going to just their rates
up make them more likely to need to be
picked in the future and then hopefully
the things that don't tell you anything
who eventually sort of go by the wayside
and that set of a hundred instruments
that we're picking in each instance will
start being more and more reflective of
the things that really literally matter
okay another important point here is
that in order to do this there's no free
lunch and we have to typically have to
make a trade off between the amount of
stuff we capture about each into Creech
individual incidents with a number of
instances we observe so if you the more
you want to sort of compress the amount
of data captured for instance the more
instances you're going to need to
observe okay now what we end up when we
do this this adaptive sampling approach
i just talked about if we end up with
the data step is pretty much all empty
all right it's very sparse so you've
thrown away 90 95 99 percent of the data
and that doesn't really work very well
for most learning algorithms so we
developed the new marine amo called
association trees I'm not going to go
through all the details of that but just
in this kind of sketched out for you we
basically look at each measurement and
we discus eyes it right now we're with
me just to two parts so we have a high
and a low so if the measurement will say
its measurement am is less than k then
you know the data in this necklace was
low if the measurement Adam comes back
you've been greater than equal to k then
that measurement is considered high
right so we're just we're just taking
our integer data or real data whatever
it is and turning it into two components
you know lower high in this case if if
they
in this case the measurement was low
with Emma Susskind k that alone is
considered to be present and heís the
sitter to be missing it was FN was
really regal dicated highest is present
and ethinyl and low is missing and if we
measure a min this run and go for
missing ok so now we're sort of turning
this is data into a set of items that we
can look at using to traditional data
mining algorithms isn't something called
the Opry algorithm and it's the kind of
stuff resource amen you know pin go to
the store and they buy peanut butter
they often buy jelly right in my paper
and jelly off my bread or something like
that so we're sort of transforming and
data for a slightly different version of
it and then applying the state of mining
algorithm to it and the nice thing about
this is that this then allows us to make
predictions about whether or particular
bug passed or failed even though most of
the data is missing and individual
instances have different things measured
okay which is a that has to be a problem
for other kinds of techniques and then
you can use this data for things like
you can just analyze the rules directly
to see you know where the code or we get
when we what things are supporting the
failure and some that might give us some
clues about pretty bugging and we're
also looking at new applications where
for example we use these models so a
system fails in the field then we're
going to build a model of that failure
and then trying to use it as a kind of
lightweight test Oracle back in house
you're going to run lots of tests on the
copy of our own copy of the program and
sort of at and try to ask you know when
does the test case in house look like
that failure we saw on the field okay so
there's some some different kinds of
ideas are looking at all right play with
this idea of the sub low feasibility
study views the system called the Java
byte code analyzer or Java it's about
sixty thousand lines of code for our
class is thrilled about this we have a
707 test cases that comprise some test
cases we made up and some actual user
programs this is a code analysis system
so its input or the test cases are
actual programs I'm going to mix
artificial and real programs and so test
cases there are 14 different versions of
the system half of them have one full
piece in them the other ones have some
combination two three four five six or
whatever these are actually actual bugs
that came about during the other the
system but just that we just sort of
pulled those out and then creating new
versions with them again ran this we on
this process across 120 cpu grid and we
off and for comparison we look at
standard classification techniques when
we actually measured everything okay and
those techniques basically build perfect
models so that so the the standard were
sort of up against is you know something
that does perfect modeling if you do all
the data all right now if we want to
compare our approach to ok so again some
sample results whereas I broke up I've
been mentioned this but in some
sometimes we ran the program we've just
collected only method entry counts other
times we captured block count so but we
have a method for cows we only have
about 2,400 when we have stayed in
County avoid 14,000 so I wanted to look
at how how this work with different
levels of different scales of data and
once you see here if we look at because
I didn't tell you also is we aren't are
associated tree technique will predict
we think this run is going to fail we
think this run as been in past or I
don't know ok so we're because sometimes
we just have all the data obviously our
quality instrument between on purpose
sometimes I'm not going to be able to
make a prediction so coverage is our
measure of how many times Omega
prediction so we see here is the on me
on the method counts versus the coverage
stuff we have 85 to 90 percent coverage
so Rhea a reasonable amount of time but
not always we can make a prediction but
there are times
Justin have enough information and we
have to sit with Rover and saddle know
based on when we could make a prediction
we see our Miss classification raise
false positives and false negatives are
pretty much near zero okay although in
this case the false negative sometimes
script up a little bit but anything
we've got I would say good models here
again give it the unit the exhaustion
ones are perfect this is the supreme
this is reasonably close and do it at a
greatly reduced cost so each individual
instance here metra instrumented about
5k percent of the total data we ran up
four times as many observations with
with this thing as we did with exhausted
data so basically for about twenty
percent of the total twenty to thirty
percent of the total cost we were able
to build in pretty good models that tell
us something about which which
executions are failing and why okay
summarise our preliminary results we
created a highly effective models and
greatly reduce costs which above which
is really what we were trying to get our
key shoes cost the data this approach
team to scale well to novo level method
councils or the high-low method counts
to the lower level statement data and
that investing the promising if we want
go to become different systems a lot of
extensions and ideas in the works i'm
particularly want to look at how how
much can we reduce the overhead on each
in each instance or how much can we get
that near zero and still come up with
good good good models we're also
currently writing up some new stuff on
new utility functions so right now what
we do is when a when a measurement
provides is predictive of failure or
passing we bump up its weight but some
of those measurements are expensive some
of those are in hot pads in the program
other ones are not caught passing the
program what we'd like to do is look at
some combination where we sort of sort
of ask for the best metric so the best
measurements from a cost-benefit
perspective rather than just a benefit
perspective and we've got some get on
that now that's starting to look really
good we got some other ideas from well
if you're you know fix cost sampling if
you're
willing to give up one percent of
overhead and you let the number of
instruments range what can we be able to
get some different ideas there and again
we're looking at new applications i just
mentioned earlier decide to the
lightweight test oracle if it got you
know failures in the field and we just
we don't we sort of don't know how do we
create them can we use this kind of idea
of a model this model an idea to sort of
compare failures in the field to known
test cases that we have and maybe maybe
try to get some idea if we have anything
that looks like these failures of people
are seeing the people also we look at
not just perhaps a fail but multiple it
fails multiple multiple feathers with
other kinds information exceptions
throwing error messages some other kinds
of stuff and do some work more cop more
complicated hold on okay so that's
pretty much being the set of processes
that I had that we looked at some bar
results and then I'm going to just think
one little no sweat at some future work
idea so in particular one of the reason
I'm here today so I'd like to talk to
people and here if you have systems that
we might be able to look at play with
try to apply some variety is too so we
know a lot of work with this this
corporate system but again it's still
just one system and it's some fun with
Java so that's so the second system but
we really are looking for other you know
the people if I'm going to collaborate
on the stuff new ideas new problem
classes want to look at things about the
performance Redbus this optimization so
the same idea of doing experimental to
these giant distributed experiments
should allow us to also build of
information about performance robustness
lots of other things possibly some ideas
on configuration advice looking at lots
of configurations that maybe even
delivering to a client or to a user a
piece of software that would tell them
and we don't know we don't know the
right configuration for you but you know
based on what we've seen these are some
of the key things you should look at and
here's a piece of software that will
help you run Rome opposition experiment
for example we right now we're at a room
or at the higher level control layer
here we'd also have to see if this this
idea could be push down for example in
the test generation so what my
colleagues the university air
octave memon has done some work where
he's got essentially the item planner
type approach that generates test cases
for goodies so maybe we can use our
ideas to say well you sort of you a new
fluid heart at these kinds of events in
your GUI Machado apart of these kind of
events yet let's look at those so maybe
there's somebody to integrate our ideas
right now our QA tasks are limited to
things i can run on one machine we
reserve investigating ideas about how we
can get multiple clients involved in
sort of distributed testing kind of
ideas still under the school framework
and in the last thing is as we push more
and more to real systems we have to
start paying more attention to you know
just sort of crazy crazy system issues
that happen machines that reasons and we
need to do a better job looking at
statistical treatment of noisy data you
know outliers and things like that sort
of important what everybody again okay
that's all I had to say and I'm taking
questions
hi I'm sending film from sir you
mentioned that using the two ways Korea
or erase if you manage to end to find
almost all the books with one person at
the total amount of different settings
you can you can have in your confusion
if you take the same amount of tests
using random random configuration
settings do you get any one person at
the folks okay so first of all I didn't
say we found all the bugs with the
converse on the data what we did is
what's the right word here we looked at
things that might be related to
configuration options so we actually
this what they said that failed to say
one time in 20 / 20 thousand configuring
where that was sixteen thousand
figurations that really can't be related
to the solar we can't tell that's within
to the to the configurations themselves
but I could just be an intermediate or
something else so we actually had a cut
off but about it things like two and two
percent or something if two percent of
the runs fail then we consider that
possibly option related failure ok so
for there some things that know if
there's a random failures that happen
you know whenever you're not going to
find that with you may not even find it
with the full data set frankly but your
mission we're not going to find with a
Brit not what I probability you're not
going to find it with the reduced set so
it's really for thing and editing some
problems that are related configurations
themselves should show up a little more
often then your once in a million okay
at least an intrinsic we can
detect okay so it's not that we found
all possible bugs but of the day nine or
so that had two showed up in
biotechnology two percent and runs
mostly ones we look at and those aren't
really well with me with the smaller
corporations right then that's the words
these technology as part of that text
wrap up we use by a super version the
keeper actually I'm speaking about just
the small pairs we've got thousands in
figuration options for a set where we
split that down eating just to test
different pairs of configurations gets
down to a natural set of tests and
that's great new clients lots of obscure
corner cases but the problem is when one
what we get a test failure we've got
this test run with this maybe get 30
different configuration options and
we've got no idea which of those
configurations of calls to failure you
spoke a bit about your optimization of
the failures to fight like that which
configuration options right close to
failure how does that work could it
doesn't narrow it down to so so he Mia
the issue here is that your service or
if you have others that are really are
due to the setting of two options okay
and if you get a couple examples of
those two options you may be able to say
boy you know when these options are
present we see that fall so they're not
presently don't see them and so we use
those classification trees to do that I
think you actually is a machine learning
algorithm that looks through and says
what you know what the Declaration of
the data would that I had I find things
that are flipping option or two options
whatever it is the fault goes away right
but if it comes back then I I see the
fall and that's that's really what these
machinery
let's try to do try to match you know
the characters for the data to to the
outcome now if that's not enough you
might be able to use the like the
nourish neighbor idea we had before so
so given that you know where the failure
is after your under your your
combination you're coming here comment
protesting you're going to start with
the failures that you see and then start
systematically jiggling those those
options to see what what know at what
point does it go away okay we have a
test run that you'll just get one of the
configuration sets the files so is it
likely than willing to use to doing so
instead of just doing pass to three way
to get more failures to narrow it down
so again I think you have to make some
assumptions about what kinds of bugs are
trying to find so let's say that you
have to a new year sale I want to find
bugs that are caused by to a
combinations well if you run three way
combinations as your as your test suite
okay you're actually probably going to
get more examples of all the Tuuli
combinations and that tends to lead to a
better a better ability to discern with
what the problems are okay now if the
problem is a four-way problem right you
might or might not see it okay so it's
sort of making sure if it's and
assumptions about what what kinds of bug
patterns you see or in general how far
you want to go because the more you can
create steam the larger the test Suites
can you start losing some of your
advantage but that's something you might
wanna play with a little bit and kind of
you know kind of kind of see orale said
I think our approach of sort of finding
a bug spot and then searching around
that might also help as well
I are cool okay over here I really like
what you're doing to track performance
profile of an application over multiple
versions but with the distributed and
potentially many machine configuration
such reconcile the quants numbers across
different runs I mean you couldn't
guarantee in the Rue they have the same
machine can see recognize the only thing
you can do there is just try to learn
more and get and get a way you is to
addiction to wanted to try to run more
in essentially just essentially spread
out the machine differences across the
different configuration so you don't get
one observation for configuration with
multiple ones okay so earlier today the
word from google talked about having
like five runs of the test case and you
make sure they little more statistical
sampling there okay that's one thing you
can do the other thing is if you know
that certain configure to certain
platforms are just very different than
others you may just want to separate
these into into sub experiments and do
them separately and I guess you know if
you experience that those things are
already so different there's no no value
comparing them directly that's probably
a good thing to do that the existing
experiments if and a schauder did you
have similar machines now in this case
we had similar machines we had this is
our computing cluster and set up with we
have this fiscal hundred twenty del
boxes you know rack and they can be
summer running windows from where Linda
Linux but very pretty or operating
system they're more or less the same
even though there were some differences
but it's they were such as
Curtis Pope roll foundation with you
running this problem so many boxes um
what about the security implications
both melissa's and accidental yeah
honestly what's a drink drugs we we
really haven't consider selves too much
with us that point it's clear as we go
to war projects and in real situations
we're going to have to do that but
really as a research project at this
point are in our mission that certainly
did that gets work at all and then we're
going to have to get to some security
things later so some ideas we playing
with it's like I mentioned sort of a
good platform virtualization for some
things where we can run our programs
essentially some you know some sand
boxes of effectively but for some of the
stuff like alas the code level fault
monitoring that you really want to do at
the user level at the end users you know
that point is volunteer computing and
you know it's just like if you know if
somebody's that if the Martians from
stay at home and did something malicious
to the code just that we couldn't find
them you really start given up already
but so we're not really that's not
really where we're we're focusing on we
clearly need to spend some time thinking
about that as you go forward we have
really do or not that's really not hard
for Model T
so we've got good questions I'm sure
thanks very much okay
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>