<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How a Kiwi Built an Interactive Vision Guided Robot | Coder Coacher - Coaching Coders</title><meta content="How a Kiwi Built an Interactive Vision Guided Robot - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How a Kiwi Built an Interactive Vision Guided Robot</b></h2><h5 class="post__date">2009-05-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JmpPm2Di0Bo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Charles Baracus and I'm
the host for Hana who is doing work sort
of on his own playing with robots and
seeing how cheap he can make them he's
graduated from Stanford a few years ago
we've been friends for a while now and
he's recently moved to New Zealand where
he is happily retired I believe is the
term after having started his own
company and sent it free so he's a
pretty much a true engineer he plays
with hardware he plays with software and
he plays with buildings he's built his
own wine cellar he's built his own
second floor but he did it underneath
his first floor so without any further
ado I give you honey thank you Charles
and thank you google for having me over
here yes I did move out to New Zealand
about four years ago before that I spent
some time doing marketing stuff but I
did get a computer science degree from
Stanford so I am a true engineer and I
have been doing lots of hardware and
software lately and I'm having a lot of
fun with it and so I wanted to take this
opportunity to share some of the things
that I've been working on some robots
some software and some cool hardware
heads coming up pretty soon to share
that with you and people watching this
video so I my motto is that I build
sophisticated I get affordable robots
and one of the programs that I built is
viewport and unlike a marketing person
I'm going to do lots of demos so all
we'll see today are demos and I'll talk
about my dance pot which balances and is
guided by vision I'll talk about
viewport and how that's how that can be
used to tune the dance pond and other
embedded systems other robots I'll talk
about the debugger that I built for
debugging propeller code and I'll steer
a simulated dance spot with OpenCV
that's a computer vision library and
I'll talk about the prop scope all of
this stuff runs on a parallax propeller
and parallax is a company that's been
around for a long time they've built
basic stamps and bow BOTS that are used
heavily in education and by hobbyist and
robot roboticists and they've recently
put out a very interesting processor
that's ideal for building hobby projects
but is also being used in education and
also being used in the industry to
control relatively sophisticated
projects and it's an eight-core
processor so there is eight processors
running on one chip they share one
global memory and are 32-bit they run at
80 megahertz and the whole thing cost
$80 $8 in quantity one and the nice
thing about having multiple cogs is that
you can split complicated items into
their own separately running processor
they all share memory so it's very easy
to share data but it's very easy to
split your projects and debug them one
at a time you can use C but the
preferred language is called spin looks
sort of like C I'll show you what it
looks like a little bit and you can also
dive down very easily into assembler and
that's fast enough to input and output
video signals and I'll show you some of
that so first I move that I'll show is
the dance bot and this was a project
that I set up as a challenge to myself
to build a balancing robot and in the
beginning I spent quite a bit of time
trying to come up with a low-cost yet
very precise way of measuring tilt so
measuring which way the robot is leaning
that's very important to know when you
want to balance something you need to
know which way the robot is leaning
and there is quite a different methods
of doing that one of them is to use
light or sound to measure how far the
distance to the floor and another one is
to use some sort of substance that
changes so mercury or something to
figure out how far it's leaning back and
forth the best method is to use a
gyroscope which tells you how quickly
something is turning about an axis and
an accelerometer which tells you the
direction of gravity and so those two
give you two different ways of measuring
tilt one of them is the exact tilt at a
given time and the other is the rate of
turn about an axis so you need some way
of mathematically combining those two
techniques and I used a common filter
it's a mathematical approach that
combines those two signals a signal and
a third derivative to come up with a
very accurate measurement of both the
accelerometer is very sensitive to
gravity but gravity is a very small
force compared to being shaken back and
forth and the moving object or being
pushed all those separate things are
much less much more than 1 G and the
gyroscope is very good for measuring
weight of turn but integrating that
alone is fine for a short period of time
but not for long periods of time for
long periods of time that signal will
change will it will drift so that's one
sensor and this picture in the upper
corner here shows a servo where I'm
tilting this platform that I built back
and forth and where I figured out how to
optimize the Kalman filter and where I
played with those sensors then I
progressed to building up one of these
and very carefully trying to keep it
standing up favorite story I have about
this is that my son was about a year old
at this point and so as a race against
time who is going to balance first my
son
my robot and all day long I would either
play with my son or play with my robots
and what both tried to guide it to start
off from a known good position and then
to go from there
and they both sort of balanced the same
time he's much further along than I am
right now he's three now and then from
there I kept going and added vision so
added a camera and added some vision
processing and had lots of fun with that
so I took it to my daughter's
kindergarten it was a picture of her
taking daddy's real about to
kindergarten and I spent about half an
hour answering all sorts of questions
questions I get here today will probably
be much more sophisticated but it's
amazing what kindergartner has come up
with for questions and I think they're
almost the same questions the vocabulary
and jargon is a little bit differently
they might say how long does it last
before the battery goes out well you
might say what's the battery consumption
what's the power flow all these great
things and being a marketing guy I like
to sort of talk about things and write
things up and so I've been pretty active
in the hobby and dwell about community
and write articles and have lots of fun
with it and recently I had my robot
balancing a glass of champagne a flute
of champagne in an art exhibit in
downtown Christchurch in New Zealand and
that was a good learning challenge for
me and it's a lot of fun a lot of new
people exposed to robotics and computers
and those type of things so I like to do
that sort of stuff and so what this
robot does is it has a camera it has a
quadrature encoder which tells it where
it is it has the gyroscope and
accelerometer I pre process information
to find out where a person is position
velocity tilt weight of turn and then
there's some logic that controls the
behavior of a robot and I use fuzzy
logic to combine all these different
inputs to eventually steer the wheels
the only thing the robot can do is steer
the wheels and turn around and move
backwards and forwards with that a
little bit more information so the demo
that I'll show where I'll look at some
signals that are produced by the dance
pots oh look at those signals using what
I call the viewport debugger and it
shows you all the information that's
currently being processed by the
processor and then there is the
processor itself and that's the parallax
propeller and again it has eight cogs
I'm making full use of it I have a
software frame grabber that I wrote
myself that takes an NTSC signal from a
nine dollar black-and-white camera and
processes that into memory then I have
another cog that does image processing
very very simple image processing I
don't have a lot of memory I don't have
a lot of processing power on the system
itself but I am able to find for example
the brightest spot I can also look for
barcodes and so with that I can do some
pretty interesting things and the nice
thing by having these eight cores is
that I can focus on one project at a
time I can focus on one of these tasks
at a time get up working and then
combine it all by running it on this $8
jet I have another cog that looks at the
quadrature encoder and measures the
position
the velocity of a robot another one that
measure is killed using the
accelerometer and the gyro another one
that does this math processing that
applies the common filter to fuse those
two inputs a fuzzy logic hog that keeps
running
fuzzy logic code to control the robot
some pulse width modulation to drive the
motors and then a conduit cog where I
continually send data for a telemetry
purposes over to the PC and I'll show
you what's coming over the wire and then
on the robot itself there is a gyroscope
and accelerometer and corridor camera
and the motors so now let's go to an
actual demo so this is the software that
I wrote it's called viewport and it's a
way for me to look into the propeller so
the propeller is running what I just
told you about on seven of the eight
cogs and I have wrote some firmware that
continually sends data from global
memory over to my laptop
and now I can display it and the way I
like to debug things the way I started
debugging things is to use simulated
instruments like an oscilloscope a logic
analyzer spectrum analyzer to look at my
variables over time so there is so you
can set breakpoints and step and so on
to look at a program as it's executing
but when this guy falls over I need to
be able to see what happened in the past
I need to go backwards in time and sort
of like a black box recorder on a plane
figure out why did it fall down
what happened five minutes ago and what
variables how did they change over time
how do we get to the state right now
which I'd like to fix so it's running
right now and these are the actual
outputs of the sensors that are coming
to the propeller the top one over here
is the SPI data coming from the
accelerometer chip it's a very cheap
small little chip that tells me where
gravity is pulling this from and it's a
simple protocol where you send it some
bits so we're really at the hardware
level we're not talking operating system
we're not talking our threads we're
actually talking about sending a couple
bits over the wire and then getting a
couple of bits back and this is that
this is an actual pin that I can look at
on on this processor and the last byte
over here tells me the quantity of
acceleration and that tells me where
gravity is pulling so that tells me
where where it's being pulled down this
next one over here is the gyroscope and
that's a normal hobby gyroscope so
there's many $500.00 sensors out there
that give you a sort of information but
this is a 10 $20 solution to put the
same problem and I send it a pulse and
what comes back and purple here is a
another pulse and you'll notice that as
I'm tilting the robot back and forth the
length of up folds changes so if I'm
turning up one way it's smaller if I'm
turning it the other way it's longer and
we also have another one I'll trigger on
this bottom one here this is a
quadrature encoder
and the quadrature encoder it is just
like your mouse on your desktop so
traditional mechanical mouse with a ball
and with that one the number of pulses
tells me how quickly I'm rotating the
wheel and the phase of the pulses tells
me the direction that the wheel is
traveling so with all that information I
can figure out what where the robot is
at any given time I also have a camera
on here and it's just a little
black-and-white camera so it's not very
good and see if I can find someone there
so it's a little black and white camera
and there's a person there and here's my
hand to my fingers and the signal to
this camera here is going from this NTC
camera to an analog digital converter to
the trip the processor where I'm very
what's encode to sample that
continuously look for the horizontal
vertical sinks and then write that into
memory and then do some simple vision
processing on it I can take my laser
pointer and what I'm graphing on the top
now is the position of a brightest spot
and so if I find my laser there you'll
notice now the blue and red lines are
relatively steady and now when I draw a
circle they're making sine waves that
are shifted by 90 degrees so it's
finding the position of my bright spot
and that's what I could use to drive a
robot around
let's go back into this and look a bit
more interview port so viewport is this
tool that I initially wrote so that I
could debug my own robot but over time
more and more people became interested
in it and so now this is my full-time
job from building and I'm selling this
this tool it's a debugging tool but it's
a very fancy debugging tool my show I
did a large estate analyzer it has a
spectrum analyzer it has a those type of
simulated instruments but it also lets
you monitor and change variables over
time so your program is running and in
real time you can just go behind the
scenes and change the variable value so
if you want to change some control logic
you can't change that behind the scenes
it has some fuzzy logic visualization
built in it has some computer vision
built in with OpenCV data show and I'm
also show here a simulated physics
package that's included that lets you
simulate how a robot would go in the
real world but do it in a simulated
environment is elevated by graphics
cards that you can simulate very complex
physics simulations
this is architecture review port on the
left side here is a propeller the shared
memory and input an output over 32 i/o
pine pins and then your program running
in seven of those cogs and view port
shares all that data with the PC using
one additional cog and then there is a
USB wire that it streams the data over
both ways full duplex at two megabits
per second and an inside a viewport you
have customizable views so you can add
widgets you can drag-and-drop them sort
of visual studio like you have these big
analog easy-to-use controls and you can
view some data minimums maximums and you
can change data by using Windows
controls I Explorer bars and buttons and
all that good stuff let me show you a
little bit more in report so here is the
fuzzy logic screen and what what I can
do with fuzzy logic is take variables
that the value of a variable and using
fuzzy logic I can specify that into one
to five classes and then act on that as
if it's just in that class so I can
write much easier logic I can say if the
robot is leaning far forward and it's
going too fast then you need to do this
as opposed to doing everything at the
head level at the at the value level
and so viewport also has a terminal
built-in where you can send data back
and forth the old way where you print
the springs and input strings I showed
you the fuzzy logic there's an analog
mode where it has a spectrum analyzer or
an XY mode and it also has this is what
we'll get to now a code view where you
can look at the code that's running on
the processor so here is some code and
let's look at a program so here is a
little program
so we'll look at this
so here is a program that's written in
this language called spin and you
declare some variables
there's Long's and bytes and also
floating-point and some simple
constructs like ifs and loops that you
deal with repeat and when I started with
this there was just a compiler for the
propeller and so I like debugger so I
wrote a debugger for this and I'll show
you how that works so you click the
start button to start debugging
this is now running on the propeller but
I can control the debugging from this
environment that I have here so if I
want to pause this I just hit the pause
button and it pauses in this line that
it was just executing and I can step
through this code so there is stepping
and then I can step over and step out of
routines I can set a breakpoint so it
ran all the way to there and all the
good stuff with a debugger so it shows
you variables and I can change them in
here but it also has fun things like it
transfers all of memory over so I can
look at the complete memory space of a
processor I have a watch list where I
can look at variables and I also have a
call stack as well as a profiler so I
can see how much time is spent in each W
each of the functions so fun project
that now all the people that are using
the propeller can apply this to and can
make a little bit more progress with
their projects
after presentation so another demo is
using open CV and physics open CV has
been a project for about 10 years
it was initially started by Intel to get
people to use more of their Pentiums and
to buy more powerful tips to do computer
vision with their processors and for a
long time people researchers scientists
professors have been writing their own
packages to do vision processing and
this was a open source way of combining
that skill and for a while it was at
Intel and now it's a little garage
funded by one of the Google founders and
OpenCV does lots of interesting things
so it lets you use your standard web
camera and then it applies all the known
algorithms to that so there is an
algorithm to find colored blobs there's
an algorithm to find faces is an
algorithm to find circles and squares
and polygons and triangles and anything
in between so it's similar to what we
have in our brain where there's lots of
different areas that find different
things for us and with OpenCV these it's
all open and you can keep changing it as
you want
so what I'll show you is a simulated
dance pot that's running that's being
controlled by code under for color so I
still write my controlling code for the
propeller I use the same spin code that
I would use later on on my robot but
what I'll do is I'll simulate this in an
environment where all the physics are
simulated - good very good accuracy so
it simulates gravity it Grima simulates
friction it simulates all sorts of
joints out there and
with today's graphics cards you can
actually accelerate this physics
simulator with your graphics card so you
can examine the simulate millions of
small particles that are acting like
water particles or snow and see how your
robot would perform driving on snow
surfaces or those type of things and
what I'll do in this demo is I'll have
viewport be the centerpiece so the glue
for three different processors I'll use
the propeller till you control the robot
I'll use the graphics card to do the
physics simulation and I'll use my
processor and my main CPU and a laptop
to simulate to do the face detection
algorithm with open CV to steer the
robot so let's start that and I'll just
go back in here this is viewport again
and inside a viewport
I'll pick up this physics program and
I'll run it when it sends it to the
processor and we'll go into the video
screen so this is
so here I am this is the camera that's
built into my laptop and it's finding
its it's showing a picture of where I am
Here I am and the face detection
algorithm is finding my face so it's
drawing a red rectangle around my face
and when I move back and forth it keeps
finding where my face is and the
location of that face is used to steer
at this vision test simulated robot so
I'll bring open this pane here and this
is a simulated world so it's this nice
3d world which has some sort of floor
some sort of textured air it has little
mountaintops and so on
and in this world I can reset this very
easily so I don't break things in the
real world my robot breaks all the time
and I have to solder it together and fix
it in the simulated world
I hit a key and everything gets reset to
the initial status and I can also apply
forces to it so I can tip it over if I
wanted to and so several things but what
I'll do is just move my head and by
moving my head
it turns one way or if I move my head on
other parts it moves another way so
there's
lots of complexity Engineers like
complexity so I tried to make a very fun
for you guys but what's going on behind
the scenes is that this simulated dance
pot there is actually being controlled
by the parallax propeller and there is
lights blinking here all the time that
are sending the data from the simulated
world back into the propeller and then
it figures out what to do and it sends
the instructions to turn the wheels back
and forth over here so that's that and
now let's go back to this so Leslie um
I'll talk about a project I'm very
excited about which is called a prop
scope and this is what it looks like
right now there's a nice glossy picture
of it out there and it's a very general
purpose multifunction USB powered
oscilloscope function generator logic
analyzer that will be sold in retail
stores like fries and RadioShack for
under $200 so a lot of Engineer is a lot
of students and so on go to school and
then they go home and would really like
to have a oscilloscope a function
generator all those things back at home
but it's it's relatively expensive to
set up a lab like that and it takes a
lot of space and they're also relatively
complex and so working with parallax I'm
doing the software they're doing the
hardware and we're building this device
that combines all those functionalities
one sample box and it's powered by the
same library that I wrote for viewport
but it's applied to this very simple
motor function so let's go so that is it
any questions all right so you dumb note
everything under windows what about Mac
and Linux support Mac and Linux support
for viewport so I I think I wrote all
this sort of stuff in about 10 different
languages so there is a spin there is
assembly there is c++ for the opencv
there's a c++ for the physics
integration but the main part is all
written in dotnet and dotnet there's a
project called mono definite that lets
you that gives it support to solar
Solaris Linux OSX to run natively on
there these days there is support
there's emulation support for running
Windows code on lots of other platforms
and viewport has been running in that
type of mode for the last couple years
so it is possible to run it in emulation
but down the road there is at least a
pathway for me to run this under mono
and both the viewport and the prop scope
itself and the prop scope itself the
communication protocol will be published
and open so that people if they want to
use it as a hardware and what the firm
were running they can build their own
tools and
to other uses as well for it
how much memory do I have right now it's
running on preprocessor so there is
memory distributed everywhere but on the
parallax propeller there is eight
processors and each one of those has two
kilobytes of RAM dedicated to itself and
all eight share a further 32 kilobytes
of RAM so compared to our desktops where
we have gigabytes and so on there is
very little memory to play with on here
but as you saw it there is still some
room to do very simple vision processing
and some room to do pretty sophisticated
stuff
so you're new to stuff where you're
talking to servos final things how much
I hope you bility the question was how
much Iowa capability is there in the
chip the chip is designed to be very
general purpose so each of the eight
cogs is exactly like every other one and
there are 32 i/o pins and each one of
those is completely general purpose
there is no I open dedicated to video
there's no I open dedicated to rs-232
each one of those is just an eye open
that can be set to either be a output or
an input and if it's an output you can
very easily through the code to turn it
on and off yeah so everything that
you've seen is through software the
connection that sends data from the
propeller to here is an rs-232
connection and that's a bit banked so
bit banging means that you are
outputting a one for a certain amount of
time and then outputting a zero and the
nice thing about the propeller is that
there are no interrupts so with a
standard chip you have interrupts
because you're only running on one
processor and so you're running for a
while and then you get interrupted and
then the operating system takes some
time away for you to update the mouse
and then you to your program for a while
and update something else there is no
operating system there's nothing
interrupting you so over here you're
running on a processor on a clock and if
at least in assembly language each
instruction takes exactly this much time
so 80 megahertz 12 and a half in a
second so four and four cycles per
instruction so it takes 50 nanoseconds
per instruction and so if you want to
output a pulse that's 200 nanoseconds
long then you have
to have this many instructions in
between there and that lets you
relatively easily come up with a way of
inputting video or counting quadrature
encoder pulses or all the rest so very
general purpose thirty-two pins that you
can allocate I'm actually using I think
basically all the thirty-two I opens
there's a couple for the serial
communication there's a couple for the
quadrature encoder there's a couple for
the H bridges there's a couple for
accelerometer and camera so it adds up
but worked out
so us how good is the physics engine 90
was skid-steer vehicle and knew the
right thing
question was about the physics engine
how good it is is it I just started
playing with it
but it's been around for a couple years
there's one that's open source OD e and
there's another one that I use physics
that was bought out by Nvidia right now
in games all the physics is most of the
physics is approximated right if you if
you shoot a gun and the bullet travels
nothing is simulated there it's just
sort of cast away and figures out that
the person got shot and then the person
blows up and dies and what the gaming
companies are hoping will happen is that
physics will actually be simulated and
that if you shoot a person then it's a
rag doll and everything has mass and
inertia and there's joints and the joint
only goes as far and that's when it
falls apart things like gravel and grass
get pretty complicated because what you
have to do there is simulate every
single part for example driving on grass
there is nothing simple about it what
you have to simulate is every blade of
grass is a as a bunch of rods that and
rods don't bend or anything and in
between the rods are joints and the
joints have a certain stiffness and
damping the damping factor and all those
separate things and there's a little bit
of inertia and in order to do a square
meter of grass you should count how many
click great blades you need but that's
how much processing power you need and
that's why it's nice that you can run
this either in simulation where you can
run very simple things or accelerated by
your graphics card and NVIDIA has made
it so that if you have an Nvidia
graphics card then you just run the
software and at the text that there is a
graphics card that can be accelerated
and everything's accelerated by a CUDA
and so it is possible to simulate your
robot running
grass with some gravel and then the
gravel is a rock which has some sharp
corners maybe not but all that's coming
so I'm certainly Nvidia is hoping that
that's the future of gaming and that
when you play a game soon you do
everything with simulated things like
that water you have to simulate every
water particle right and to figure out
how it's interacting with other isms
there
I'm using a whole bunch of Google
technology so custom search for my
website to have people find stuff Gmail
of course Picasa I use Google Checkout
which is wonderful I got an email in the
morning that tells me how many people
have bought my software and it goes
directly into my bank account very easy
I have Google Analytics which tells me
where people coming from yeah lots of
Google stuff okay I'm I think I'm the
best Picasa a salesperson out here
okay thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>