<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Towards Privacy-aware OpenSocial Applications | Coder Coacher - Coaching Coders</title><meta content="Towards Privacy-aware OpenSocial Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Towards Privacy-aware OpenSocial Applications</b></h2><h5 class="post__date">2009-06-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IeqKZfIK568" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody I'm Patrick Shanna's all
from google we are here today at Google
for a tech talk by IBM research labs
about a new approach to privacy in
social networks so here's a coon view
from IBM who's going to explain the very
innovative approach to dealing with
privacy in social networks that the IBM
team has built Thanks ok good at home
box and my name is khan leo Emma for IBM
almaden research center it's my great
pleasure to come here visit Google today
with my colleagues and to introduce our
work on privacy and risk management on
social networks ok so before i start i
like to ask you some questions so how
many of you are facebook users and the
myspace users are linkedin users please
raise your hand ok great everyone oh
maybe you are out like ok ok so another
crash tech question is how exactly you
know how much information about you is
being shared on these networks and who
can view that information do you have
any idea ok no sir question how much
information about you is being shared on
these networks compared with other
people such as a private expert like me
any idea ok nevermind I don't know
either ok so but today I'm going to give
you some solutions that help you answer
these questions ok so now let's start so
here because this is the teamwork I like
to first introduce some of my team
members these are great people have been
working with during the past years and
Herron glancing is not here today but
his manager and he oversees this project
and kuna this is me and Max mass mailing
and his he's here in his expert of web
applications and it actually he leads
the architecture and system part of this
project and RJ is the expert of web
application have has deploy some
application on the clock platform and
every movie A to Z issues also here is
expert
machine learning and data mining and we
also have three engineers from us IBM
Silicon Valley lab who helped us convert
some of the ideas from concept to
reality ok so so now let's start begin
with the video pleasant suburb were
living in the basement at er um dad so
we can't get along respectable hall just
because my girl defaulted on some credit
card if we gone to free credit
report.com idea bachelor with a dog and
a yard ok ok so I'm not trying to do
Edward Heisman for free credit report
com but how come is credit score is
related to today's talk ok so as many of
you may know that credit score was
invented in the 1950s by a company
called fairy stack ok at that time
nobody knew how important credit score
would be in 50 years but today this
credit score is everywhere it determines
everything from the interest rates we
pay on where credit credit card and how
attractive you are as a job candidates
ok so how about something like privacy
score it tells you what's the potential
privacy risks of you on social networks
and it tells you how much information
value is being shared on social network
who can view that information it can
automatically gas you towards a better
privacy protection or configuration that
makes you feel safer uncomfortable about
your online life
okay so this is my question so as I am
giving this talk I like to ask you to
think about discussion whether you want
to design something like privacy score
in your OpenSocial and some other social
applications such that this private
school will have the same impact as
credit score in 50 years are much much
much much much less than that okay so
this is my question please think about
that and next I'm going to tear you and
discuss why this is important and how to
do this if you really want to do this
okay so I'm going to first elaborate the
motivation ago again and then I'm going
to describe some serious mathematical
models behind this this private school
computation and the Semites applications
then I'm going to discuss how this thing
and thats application can be
incorporated with OpenSocial and other
social applications and finally at the
proof of concept Max and the my
colleague will demonstrate a prototype
we have developed on facebook it's
called the previously aware marketplace
and this prototype has adopted many of
the previous models and concept that i
will be covering today okay so this is a
roadmap so the motivation as well we
know that meanings of users are sharing
their personal information online okay
and we have friends we also have many
many different strangers who can view of
information so inevitably the discovery
of sharing of information had some
implication on our privacy digital
stalking and identity cept a some of the
most common threads okay and we all know
that but unfortunately unfortunately
even very sophisticated ear privacy
often compromised it because I really
want to improve my digital presence
online to become popular or cool or
something like that so I share a lot of
information and also because my friend
have share lots of information online
okay so so the problem is that i cannot
estimate long-term risk
to the shot him again this is one
problem and another problem is okay it's
very difficult and complete for me to
configure the private setting on social
network it's often a time-consuming
overwhelming task and many user will
skip so act like to ask you like how
often are you going to revisit your
private setting on facebook in the last
three months have you ever reveals your
privacy standing on facebook no okay so
because it's complicated and it's
overwhelming so eventually as the time
goes by we share more and more and more
information online becomes that we lose
control of our information we do know
what information we have shared and who
can see that information okay so the
goal of our work is develop a model a
platform and mechanism that can help
user to monitor and measure their
information and privacy risk online so
the goal is to boost public awareness of
privacy of course but also most
importantly it wants to help you sir to
manage the information sharing online
easily and and all you can see okay now
we're talking about privacy or talk
we're talking about identity saved and
risk so it's very important to note that
our goal is not trying to prevent people
from share information okay instead we
believe that simple and effective
privacy and risk management techniques
can create a safer and more comfortable
online environment that will eventually
facilitate information sharing and
integration is it like if I know all the
search has views then i will feel
comfortable about using some services
but if there are some hidden fees i
don't know then it comes up i feel very
frustrated and upset okay so how can we
achieve this goal so we developed with
the notion of periscope and this scar
indicates the potential privacy risks of
user in surah social networks and with
this girl there could be many
applications like for example similar to
our credit report we can provide user
our information sharing part that hurts
user okay what information I have shared
and who can read that information it
helps me to track all my information
online okay and also the user can
monitor its privacy risks and compare
that with other people in the world just
like we can compare about credit score
with other people's credit score okay so
when the overall previous risk on the
social network is lower than the risk of
this user the system might recommend
this user are better a stronger private
setting for this user automatically so
user justice like oh I want to this
privacy setting to increase my my
privacy protection then everything is
down okay so i'm pretty sure you may
come up with some other applications
like just as in case we do for credit
score right in the real world we have
many different applications and the
revenues are generated from these
applications for credit score so so next
i'm going to describe the theory behind
the credit score the private school
computation and some of the applications
because we're talking about private
schools so how can we compute that one
okay so this is a very high level like
Bowl lifecycle private school so it
takes the social network as input and
the system extract the private settings
of our users and other profiles about
different users and calculate the score
and this guy is then delivered or
visualized as or something like 80
meters in to the user so user have the
score and know how it looks like and
then his God delivered to the user user
can monitor his privacy risk score and
take a more active role in safeguarding
his information okay and also
information sharing report and azure
parasailing recommendation applications
can be developed pud based on your score
and then you score the user may take
some actions to protect this information
I'll do some other privacy's
reconfiguration on a social network and
then it just keeps looking like this so
so the private settings here actually is
nothing but this traffic control like
what information about me can be
accessible by whom like my birthday can
only be viewed by my best friend and my
cell phone number is only viewable by
my coworkers or friends or colleagues
but other information like my mother's
maiden name should be kept confidential
no one should be able to see that so
this is a private setting just like on
physical you have different visibility
settings okay so this is the very high
level lifecycle of this privacy score
computation okay so now how to compute
that so from a very technical point of
view intuitively not technically but
intuitively we require this Prairie
School satisfied two properties ok so
the first one is sensitivity which means
the higher sensitivity the information
you revealed on social network then
potentially the high the risk of a
network user will be facing for example
mother's maiden name is mass sensitive
then mobile phone number from many
people's intuition right so if one guy
only reviewed his mother's maiden name
but another guy only revealed his mobile
phone number in the first time is much
delayed to be a victim of identity theft
ok so the second property is visibility
it means that ok the wider the
information about you spread over the
network then the more likely you're
being a victim of identity theft or some
other evil things so for example the
home address if it's only knowing by my
best friend then it's probably much
safer than it's known by everyone errors
in the world ok so this is a visibility
and sensitivity these are two properties
that the prayers go with think should
satisfy but how to combine these two
parameters the gathered computer score
it can be very simple ok so these are
the contribution of a single item in the
overall private score of a user so you
can see that it's the product of the
sensitivity of the information and the
visibility of the information it gets so
here we will talk about profile item it
means either your birthday or address
your phone number mother's maiden name
or even your sexual orientation ok so
you can see that a single item may
contribute to the overall privacy risk
by combine both Simon sensitivity and
visibility
so then the overall score of the user is
nothing but combination of the
individual contribution for each profile
items so we can do that just to do a
simple summation over out simple
individual private school from each
individual items and this gives you the
overall private school okay so now the
question again comes up so how can you
estimate the sensitivity and how can you
compute the visibility we have two tasks
if you feel so for simplicity let's just
consider that we have a big table that
can represent other users and all the
profile items how they share the
information out users shared information
how to item being shared in a big table
so Ichiro represent a profile item such
as a birthday of mother's maiden name of
cell phone number okay and each column
represented user and a seer locating the
ice row and GS column if it's white
means the user J will share this
information with the public if it's
great the means the user will not share
we can see that it's very simple case
it's binary case either share or not
share but in practice we have many
different sophisticates like i only
share with my friend with friend of
friend is threatened our friend our
friend but for simplicity i'm only going
to talk about this binary case but bear
in mind that automatic mathematic models
i'm going to talk it's going to be
easily extended to this most
sophisticated just focus on this binary
case so sensitivity so intuitive
speaking if item like my cell phone
number if it's very sensitive then not
many people will share this information
online it will keep this confidential
right so so based on your situation the
simplest way is just to count the
proportion people that will now share
this information just look at the row in
this big table and count how many people
are not going to share this information
and use this proportion at the
sensitivity value and you can see the
higher the value then the last people
who've your share this information okay
this is sensitivity so how about
visibility user can also be very simple
because we know the explicit private
setting of the user on this item so it
can be either one or zero we can just
use this one as our visibility share our
not share one of 0 ok but because we are
data miners where merchant learning
people so and we our statistician so we
know that what we have observed in a
real word you already comes from adjust
the sample from some underlying
probability distribution ok so this big
table is no exception user so what we
want to do is instead of know the
explicit studying we want to know what's
expected setting in this in this table
in that case the visibility becomes a
probability just like what's the
probability that this user J is going to
share this item I ok so so now you can
see the probability then how to compute
this probability again there's a very
very simple way if we assume that the
item and the user independent dear
there's no interaction between them then
this paper billikin just can be computed
as the probability of a1 in this row and
the probability of a1 in this column
multiply them together because we assume
independent had an ID distribution of
the data so you can just do this
multiplication simply means if the user
has very high tendency to share many
information than this user is also
likely to share item I but a nun and in
the same time if the profile item I is
very it's not very sensitive it's being
shared by many other users then it's
also more likely to be shared by this
user J we just compute the row and the
column and get the probability it's a
very very simple case ok so any other
approach we can do that to make this
better so now because this one you know
that this independence assumption your
it does not make much sense in reality
so we have to come up with a better
better kids so
so okay so this is the periscope use the
base down its sensitivity and visibility
we have to come up a banner caves so so
here we introduced our new model called
item response theory model you could use
this model computer sensitivity and
visibility what's what's this model this
one was originally used for its due
current being used for for analyzing
data from questionnaires and tests it
actually is a foundation of today's most
popular computer adapted computerized
adaptive testing like GRE or gmat so
basically the models the ability of the
students and and the difficulty of the
question students answering and it
models that the probability that the
students is able to correctly answer a
question is based on some logistic model
and the model the curve attorneys like
this example if the student's ability is
high which means the students very
knowledgeable or something then it's
more likely that these students able to
answer the question regularly ok this is
a this is a very high level idea about
item response theory but in a privacy
case the students ability at respond to
is helping here an attitude okay now
here comes something different attitude
like whether I'm very conservative a
very control extra vote or whether I'm
very careless or very open something
like that so if I'm very open up very
careless and I probably i want to share
much much more information than a
conservative people right are
introverted people so so now it's why we
come up with a new model called IRT
model you can see now in this case the
probability that a user J will share
some item I is modeled by this logistic
function okay and in this function the
parameter beta models a sensitivity of
this information it's analogous to the
difficulty of a question in the new
taking exam and the higher sensitivity
pay the lower the probability which
means if this probably in various the
item is very sensitive then many people
will now share this information
and that the parameters theta here
models the users attitude whether he's
very conservative or actual world of
very liberal or relax okay so you can
see if this attitude is very high then
this probability is going to be high
which means if the user is very extra
volver open than these people is more
likely to share the information so the
probability that is equal to one will be
very high and nice thing here is that
you can see that we place the attitude
about the user in hearing attitude and
the sensitivity bought item on the same
scale they can compare with each other
so if the user is very open and its
value is higher than sensitivity which
means I don't care about this this
information I don't care my master made
a name then the probability of going to
be very high this user will be share
this information but if this value
attitude is less than the sensitivity of
the information that okay I can't
tolerate with the discovery of my cell
phone number then the probability is low
that this user will not likely to share
this information this is a very basic
idea about how these things going down
okay and and this is another auxiliary
parameter that just that there are some
some some some probably about the
profile items such as DF see after
number of birthday and I'm not going to
discuss this parameter in in this case
50 50 50 50 that's the that's a very
important that's definitely yeah that's
a definite yes yes yes exactly yes yes
okay so okay now let's come back to the
original overall private school
computation is simply a combination of
the sensitivity of the information and
the visibility the can be either
explicit setting like one or zero or in
the probabilistic is its probability and
we know that sensitivity can be asked
them can be obtained from this model in
here and the visibility is from this
model directly okay and also we know
that we have some byproducts like the
discrimination of the year the profile
and the users attitude okay I'm going to
tell you that how we can use this the
information
the information also we are interesting
so so now the question is okay if we
know all these parameters we can compute
the private school for the user easily
but the question is we don't have it
okay we have to estimate that but how
can we ask me this the information
maximum maximum likelihood estimation
OEM algorithm because because you can
see this is the probability so it models
for that for each user and for each item
how likely the user is going to share
this item okay so that means this is a
generative model so then we can just
compute the likelihood ratio likely
maximum likelihood of the data based on
this model and you use the eem algorithm
or some other algorithm to compute the
parameters and then we use these
parameters to calculate scott final
score of which user ok and ok and now
you may ask questions so why this mod
why not other other models maybe this
model is too complicated or something
like that and the advantage of this
model is that at the generative model we
conducted some user study to get some
survey from user we collect some real
word data and we do experiments and we
found that this model fits the real word
data very well in terms of the
chi-squared goodness of fit okay and
this is one advantage the second one is
like the quantities the IRT model
computes like the sensitivity the
attitude visibility a very intuitive
interpretations for example the attitude
to matter whether this person is very
cultural were door open or careless of
Labor litora can be used as a
psychometric instrument by sociologists
we can use this information to study
people's unlike behaviors okay the
sensitivity gives you how sensitive some
information is so the user can monitor
his privacy risk and if some information
is being shared on LY the sensitivity of
this information is outside of the
comfortable region in the system might
send allure to this user oh the
information you share is too sensitive
just like okay this month I spend the
hundred thousand dollars on my credit
card then the credit card company is
going to send me alert something like
that okay
and the third one is because although
the maximum likelihood estimation am is
sounds very complicated but actually
many of the computations can be
paralyzed by which means you can do the
computation probably a MapReduce and
some other pair like putting flat firm
so so this can scale very well for real
so Chanel recommend for millions and
millions of users okay so that is
practically efficient okay so we do some
evaluation of course we have to do some
evaluation to the test the theory and
model so we are we collect some data
from a hundred fifty users / 13 I
profile items them such as the name and
gender birthday political views and we
asked them to specify their information
sharing preference such that okay given
the birthday how how are you waiting to
share this information you want to share
with no one with only friends with
friends of friends always everyone
something like that okay we get this
information and these are some statistic
from about this survey and that we do
this computation we asked him in the
sensitivity of the information and in
the upper right corner in this figure we
visualized using a tad Claude the
sensitivity of the information we
started so the larger file means higher
sensitivity as you can see mother's
maiden name has is the highest a
sensitive sensitive information okay but
on the other hand you probably can't
feel this small dog and this is gender
so it just located right above the
letter H of matter its gender which
means this information almost no people
would care about this infirmities close
your gender information on social
networks very interesting finding okay
and then we also compute the priority
score for each of these 150 straight
users and we then group them according
some geographic locations like North
American Houston coast and North
American West Coast and this bar shows
average score per location and as you
can see people from North America and
you
at high prairie score but people from
Asia and Australia have relatively lower
private school okay so you may find
different reason to explain these
phenomena but usually we know that
people from Asian are kind of
conservative and don't want to share
much information with other people but
the social network inside in North
America and Europe my describes so
people tend to share more information or
even understand social pressure to share
more information to become popular and a
coup okay so that probably the reason
why they have high privacy risk scores
okay so so again coming back to the
applications given its social the
private school what can we do about that
privacy risk monitoring is probably one
way of natural way and privacy reports
similar to our credit report it tells
you what information you have shared and
who can view that information helps to
track all the information flow about
your own social network and the probably
selling recommendation for example I
want to lower my previous call a risk to
range from a range of a Henry to 150 in
the system can just enter I the
population and find other people with
score or between this this range and use
the most for example common setting or
average setting about these people as a
recommendation to these people that will
give you automatically or recommendation
just like some collaborative filtering
systems okay so okay so that's pretty
much about the theory and models about
periscope so now I'm going to talk about
okay given this thing how can we
integrate with OpenSocial how can we
work work together to create a mall
previous aware open social environment
okay so at the first step probably did
say the easiest way to do the
integration so the OpenSocial might
provide some native implementations or
private school calculations to the
developers and also the OpenSocial may
provide some AP is to enable application
developers to implement their own
priority score calculation because there
could be many different models they can
calculate private school just like the
FICO score and
sep different credit agencies they can
calculate their own scores and bass
sound is the open structure might
provide some API is to enable
application developers to build some
information sharing power modules or
private setting recommendation values
these are very a simple approach we can
get started but in order to do this this
is some some API we recommend for
example one API it opens from I provide
is at private school for a user and the
key here actually indicates what
mathematical models the year the
defender is going to call user I our
team adore a knife model this is a for
native implementation and the second one
is it more like a generic or it's the
developer can implement their own
privacy score calculation based on their
own models and because we know that in
order to calculate Prairie School we
need to know the the privacy settings of
the users who can see what information
what's the privacy control and we also
need the function like this get private
settings first a user regarding a
profile item so this profile again can
be chosen from existing OpenSocial like
a person field the address field email
field like persons name address
telephone number even gender or
something information like that and also
for the automatic recommendation we
should have something like set private
settings for a user based on the
existing recommended settings and
regarding some profile items so these
are for recommendation system okay so
this is pretty much like that and if you
are very picky you may you may ask
question okay my privacy settings
themselve a private okay okay so how can
you get my parents that into k oq my
privates go to indicate my potential
profits it says like a chicken and egg
problem ok so again this one in order to
access is privacy setting we have to use
some other authentication protocols like
this for example me this holas protocol
so it simply get authentication from the
user ask you sir do you want to share
your privacy settings so that i can
compute private school and as they
advance to previous management
application for you if the user grace
then application will get a token from
the social network and then do this
calculation okay this is the one way so
but I know your your OpenSocial guys
your application jr. so you probably can
come up with some other ideas to handle
this problem but this is one possible
solution okay so finally at the proof of
concept where you have developer
application previous aware marketplace
on facebook so this application has
adopted many of the privacy models ideas
we have I have just dimension so also
next max and we will demonstrate some
this application to you too and also
discuss some features about this
application okay very quickly thank you
so we what we did is we went to go to go
after ebay just kidding we decided to
implement a application on facebook that
would allow us to play around with some
of those concepts and what we did was to
build a marketplace and this is sort of
an example of sort of how you see it I'm
refreshing the page because jit here
posted this angel and demon book and you
can see those the price when I was 0
because we were playing with it he
actually blocked it if he goes ahead and
changes it you know then we can see you
know the price changing so the point is
that you can control pretty much
everything but the key and very quickly
and this is the part of the demo is that
you get a score and I don't know if you
guys do you guys recognize this little
thing here this is a google o meter
which we use your charts API to do this
so it tells us that your current privacy
my current privacy since i'm logged in
here is 49 in the recommended one is 25
so all i have to do is to change it is
to just basically click here i'll do
that laughter but i'll show you the
basic model for those items so we have
item in profile because that's the
application and you can see you could
also go just like you can do on facebook
and somewhat
intellectual application in Joe's items
and then your score will change and you
can also do the same for the pool file
so what I'll do instead is I'll just
click on it the recommended and what it
does it calculates it since we don't
have a lot of users on this application
which might change after this talk is
posted you know it basically changes it
so if we go back to the score you'll see
everything change so this is one way of
implementing it's a basic application on
facebook certainly for OpenSocial you
know adding it as part of the platform
would mean that every application could
actually use something like this would
implement it and so on so forth so
that's the basic demo let's finish up
and let's take questions if you have
questions about this we can go back it's
okay so
okay so conclusions so in this talk we
have discussed the importance of privacy
score computation and its applications
and we also provide two ways to
calculate this private school and some
potential applications okay we also
discussed how Hasbro we can't agree with
this thing to open social or as your
social applications and again our goal
is to develop our mechanism and platform
that can help use your manic monitor
their privacy risks and help them keep
track of the information they are
information that being shared online and
also to boost the public awareness of
privacy okay but again we believe that
this is not trying to prevent people
from share information okay but on the
other hand by using this the West
privacy and risk management system we
can create a safer and more comfortable
environment in online social networks so
that people will be willing and feel
safe to share their information and
eventually this will facilitate
information sharing flow and integration
so here comes back to my original
question to you whether you want to
develop or something like this private
school it was previously management open
social or some other applications so
that 50 years a much less and that
people will appreciate the effort okay
so if your answer is yes let's
collaborate on the road maps and talk
about how we can do this in next step
and thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>