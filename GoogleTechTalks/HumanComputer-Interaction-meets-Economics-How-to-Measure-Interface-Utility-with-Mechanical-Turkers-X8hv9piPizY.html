<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Human-Computer Interaction meets Economics: How to Measure Interface Utility with Mechanical Turkers | Coder Coacher - Coaching Coders</title><meta content="Human-Computer Interaction meets Economics: How to Measure Interface Utility with Mechanical Turkers - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Human-Computer Interaction meets Economics: How to Measure Interface Utility with Mechanical Turkers</b></h2><h5 class="post__date">2011-06-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/X8hv9piPizY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">very happy to introduce Michael cumin
and Klaus partner both from University
of Washington this is work that they did
George achieves magic and your home
detail going to give you the full time
here so take it away cool hi guys okay
um I'm Michael this Klaus uh so um ok so
I'm a PhD student in computer science
and I study HCI and I was kind of
concerned that in HCI what we really
care about like what really matters such
as HDI researchers isn't something that
we really know how to study and I came
to see that the only way to study this
is through economics so today we have
Klaus partner here he's an economics
professor and we've been collaborating
on this project to be able to study what
really matters to HCI so I'm gonna make
a claim that this is what HCI really
cares about so let's go back to the
roots of HCI in 1983 so 1983 was when we
had our first conference and
human-computer interaction called Chi
and in this first conference the very
beginning of this conference in the
first paper session actually and the
first paper presented in this session
it's kind of a coincidence is a paper by
Don Norman some of you might heard of
him he brought some popular books in the
field and there it is here's the paper
is called design principles on
human-computer interfaces and in this
paper he defines this thing called user
satisfaction or U of X and he says this
is what we should be measuring HCI
should be about optimizing user
satisfaction user satisfaction is kind
of the ultimate in user centered design
this is paying attention to what matters
to users we want to Ma optimize what
matters to users and it encompasses a
lot of different characteristics of an
interface like you want your interfaces
to be efficient and accurate and that
matters to user but also things like
being user friendly and learnable which
there may be a little bit harder to
measure and today there's a lot of stuff
that really matters you want to be fun
pretty aesthetic sociable these are
things that matter to people on
and this is all captured in user
satisfaction but we don't really have a
good way of measuring this stuff Doron
Norman's idea we'd be creating these
graphs of things like what's the user
satisfaction of a menus of different
sizes and display times but he in this
paper he just kind of made up these
figures he didn't you couldn't measure
what they were going to be so we just
like said this would kind of look
accurate and in psychology we use a lot
of power laws so it kind of makes sense
to have a power function and so this is
kind of so I said this is kind of a
problem that user satisfaction defines
our values in human-computer interaction
is what we want to design for is what
matters to our users it's what Google
oftentimes cares about but we don't
really have a way to measure this so we
can't measure what matters and so let's
go through the history of HCI a little
bit because this is a growing problem of
growing import like we've sort of made
it so far but I don't know how long it's
going to last so let's go back to in the
60s the original interfaces were
designed for people who were like
nuclear power plant operators or in
switchboards and these users didn't have
any choice and what they were doing so
this is this is a history of choice the
textbook picture history of HCI is that
users slowly got more choice in what
they were doing and as they had choice
it mattered what they wanted so the
original interfaces since users can
choose anything it just mattered if
they're fast and error-free these are
people who are paid to be trained to use
the computer they're paid for like four
days even to use it only in the 1980s
users suddenly had the ability to choose
different computers computers were
invading the office you could buy a
computer off the shelf you could buy
different kinds of software we had
advertisements trying to convince you
that these things were user-friendly and
learnable because that's what people
cared about because products wouldn't
sell unless that happened now in the
2000s we have the internet and there's
so much choice we have websites
everywhere Gil zillions of choices what
are people going to choose the more
choices you have the more that computing
pervades your life the more all these
different types of things matter so
the history of HCI is one of increasing
choice in computing and with increasing
choice there is an increasing diversity
of things that matter and we don't know
how to measure all these things and if
you look over the history of HCI we
started out with human factors in the
60s in the 80s was beginnings of our
field Chi and this is when we started to
measure user satisfaction because we
start to realize that all these things
matter we still don't know how to
measure them and now we're in this era
of free choice and we really have no
clue how to talk about this stuff we
don't know how to say what is a good
interface free choice is a fundamental
value but we don't know how to measure
the factors in it yet and so let's just
so in practice this is maybe we can see
the effects of this of companies like by
Google Eric Schmidt says you know what
we really care about here is getting
more users to use stuff that's what our
engineers are a workout and some sense
he's saying we want more users to choose
stuff because choice is the issue all
major websites now measure choice with
a/b testing this is how we optimize our
products we look at success in terms of
ad clicks pageviews user choice monthly
active views this is successes choice
it's getting people to choose your
interfaces the world is here but HCI
science is still stuck here measuring
time and area so my conference people
tend to still measure and optimize these
things okay so this is a problem the gap
is growing between our science and
practice and we need to be able to solve
this we need to be able two measures
choice and user satisfaction so let's
look a little bit more closely so I've
talked about user satisfaction I've
talked about choice what's the
relationship between these two
quantities I'll say the user
satisfaction determines choice so the
idea with user satisfaction with your
satisfaction is that your SATA if you're
satisfied with a choice then that means
that you're going to you want to choose
it again that's the point of
satisfaction it's sort of your feedback
you're like yeah okay that's a good
choice but the problem here is that if
we want to measure users at us
action we can't really because it's
inside the person's head so what we've
done is we've said okay well there's as
user satisfaction thing but actually in
economics there's this quantity called
utility and utility is defined as
representing a person's preferences and
representing their choices and the key
point here is that we can actually go
backwards since I cannot utilities
defined in terms of choices if we
measure a person's choices we can go
back and understand something about
their utility and we can't now and I
just want to clarify we can't really say
that we know what their utility function
is but we can get a measure of utility
we can talk more details about the
specific definitions there but this is
what this paper is or this this talk is
so we're measuring utility of user
interface high level idea utility is a
concept from economics we can measure it
today by doing choice experiments so
rather than just give people tasks and
interface and watch them use it we're
going to create experiments where they
have choices between different tasks and
different interfaces and today I'm going
to demonstrate one method that uses
Mechanical Turk and this isn't going to
be able to solve all of utility
measurement but this is going to give us
one point here and then I'll talk about
the rest of it so here's our basic
method yeah
you're saying mama facility is the best
way we can measure this user
satisfaction so 20 years ago no people
had similar ideas but it was confounded
by the fact that most agent paid money
for software and so utility was often
measuring things related to actual
financial costs as much as it was you
know there was some complex function of
user satisfaction of financial costs
where yeah we people were never able to
keep a heart so mean like people
measuring user satisfaction by looking
at what people pay for software well
well know just what what software people
chose in various contexts but a piece of
it always had to be one of the software
costs because while software costs money
and so I think what I'm inferring you to
say is now that money is not the issue
in any of these things that the only
thing left is user satisfaction as
utility is a direct measure of user
satisfaction do you believe that or what
other things do you think might still be
compelled um well maybe we should have
asked this question Jen after the talk
so essentially what i'm doing is I am
using money in this to get out user
satisfaction we take tasks of people do
for free and then we add money to it to
try to see what happens okay so maybe so
I know for taking away a confound we're
adding it into like I don't know so
we'll see but so let me go the next
bullet so we post variations of
interfaces and tasks Mechanical Turk we
put them there at different prices okay
so mechanical turk is yeah exactly yeah
so we go yeah so we switch it a little
bit so yeah so we're paying we're paying
uses Mechanical Turk is a web
marketplace where you can like a lot of
people are just on this website and
there's a bunch of tasks they can do and
you can post a task and put a little
amount of money for like pennies and how
people do kind of whatever you want so
we're gonna take an interface on tasks
we post on there and now we can see
basically how much you have to pay
people to do your task but what we
really do is we post the task in your
face at multiple prices and we record
how many are done by each
person who sees it okay we have multiple
conditions of the interface the task and
multiple prices so what we're doing is
kind of using I'm sure backwards from
how most people do it we threw out way
we don't care what people actually do if
they're actually doing work they think
they're like doing something important
maybe and we just ignored that data and
look how much we have to pay them and we
pay them weird amounts so here's an
example of a task we put on there so
this is a fit slot task we've run like
thousands of these fits law studies and
HCI view with Fitz law is you have a bar
of different widths and depending on how
wide it is and how far away it is from
the cursor we can predict how long it
takes you to click on it and this is
this is pretty much all the science to
HCI has to offer this is the hard
science we have there's one model and
this measure is how long it takes to
click on something so okay this is cool
but we'd like to know how much utility
does this have how much does it matter
how long it takes to click on something
so we took these three versions of this
interface and we post them on Mechanical
Turk now the way our study works this is
sort of the brief the brief view of how
we make this a fair auction on
Mechanical Turk so we hide every task
and the pay behind this mystery task
interface only when you accept it then
we show you here's a task you get and
here's the amount of pay that you get
for it and you can choose to do it or
not and you can choose to do it as many
number of times you want and that way we
we get to like track everybody as soon
as they see it we know how many done it
and how many have bailed and how long
they did it for ok so here's what
happens we basically have now an a/b
test will ABC test because we had three
interfaces is a big bar medium bar and
small bar and this is a mound of work
but got done on the y-axis so you can
see people like big buttons they do more
work ok so that's cool but the thing
that we really added here was that we'd
also added multiple prices so let's see
what that looks like so we had we pay
people six different prices between one
sense and six cents do this task so this
is a 60 clicks I'll give you one penny
or six pennies and now we've created
labor supply curves so this is a basic
economic analysis
this shows you not only as we change the
interface how much more work is done but
as you increase the price how much work
gets done and so you can see now the
difference between the price and the
interface and what makes this really
cool is that now we can relate the
y-axis with the x-axis and see how much
pay is this interface change worth so
let's look at the difference between
lines be and day and this depends on
where you track it out so we tracked it
right here this is at three cents we're
at the three jobs or something and if we
subtract the difference between these
lines we can see that this interface
change was we're three point eight cents
to workers okay so now we have a money
metric that tells you how important this
is to them and you could turn this into
an hourly wage or something else that
would be great as the next up we haven't
done it would be if we can now predict
like we now but we can now quantify the
change in interface how much it's worth
to people well now what if you are
developing this you want to deploy this
interface change on a real website and
you're thinking man if I could make this
ad utility to this task by one cent or
two cents how much more work would I be
able to or how much more use with my
entire website get so this is somewhere
we'd like to be able to take this okay
okay so let's yeah
yes yes so in some sense this is could
be measuring the amount of perceived yes
totally is that the same dissatisfaction
yeah yeah yeah so i'm going to i want to
get to that clarification yeah but this
is really good insight so what we were
measuring hear more of the cost of using
the interface then we are the value of
doing the task in the first place right
yeah urban tripling to save the button
were somewhere between those two sizes
what it would be or yeah does it is hope
the is the curb not shaped like it's
like her so um I we did this and it's in
the paper actually i didn't put in the
slides and the curve was as you it went
like this where as you got it fit pretty
well it fit well yeah but it was um it
was convex as you got a bigger button it
got disproportionately more utility at
all yeah right way okay yeah although I
mean the intercept we plotted on the
index of difficulty scale which logs it
already so I don't know what that would
do but
would be interesting to rely to this is
go back and read frederick taylor in
frederick taylor was the time emotion
guy yeah 1910 and there's a there's a
very nice biography from MIT press a few
months ago but he was doing exactly this
with physical labor mechanical tasks I'm
making things not been carrying on
delaying breaks of time and motion study
was kind of a kind of motion study
really yeah it certainly it's a ton of
motion study buts more about the people
have more choice he was measuring how
much you had to pay to get these tasks
done right okay so who is that Taylor
Taylor Taylor how to come forward and I
understand modern manufacturing oh I'll
tell you that way ok cool so um okay so
let's sum this up a little bit so what
we did was we were able to measure the
utility of efficiency here so this is an
interface called a bubble cursor which
is very popular in our field people come
with crazy ways to click on things it's
like a little bit faster and we can now
measure how much this really matters we
can measure how what's the utility of
having the start button in the lower
left corner so it's easier to click on
and having the menu bar on the Mac up on
the top so it's easy to click on and
this gives us ability measure efficiency
we can take lots of different principles
of UI design we can start to actually
see how important they are we can start
to measure the utility of fun one thing
I'm doing right now is I'm taking this
fits lock clicking testers clicking back
and forth I'm making it to a game with
points the scoreboard and my hypothesis
is actually as it gets more difficult
these difficult is going to get more fun
because there's going to be some
challenge and then maybe after that
sweet spot is going to get less fun and
so instead of just and so we can see
some tricky things like that we can
measure the utility of errors pop up
some dialog box is saying oh you've
messed up how annoying is that two
people learnability we can measure
social reward on and aesthetic so let's
look at aesthetics a little bit here's
another study we ran this is like you
prototypical human computation task now
and human computation is a great thing
to study with utility because you really
care about getting a bunch people to do
stuff it's answering CAPTCHAs we didn't
just care about captures here what we
really want to know is well what would
happen if we took an interface and made
it really ugly so we took this interface
and we
made it really ugly we added this bright
green background an animated banner ad
and we calculated the utility difference
of this this was worth negative point
six cents for every ton CAPTCHAs that
you answered dollar see have a dollar
CPMs of 10 to the set well what the
advertiser is getting is roughly a tenth
of a sentence cause you to use or
successors oh my god that's awesome I
mean the way we think about it here on
the outside bring this over in the
search world but they but the idea that
you think about the cost of the user
yeah no no and the cost of the user you
try to compare that to how much it's
worth to the advertiser yeah and in this
case you know it was clearly costing the
user more than it's better with the
advertisers well well no Fitz money to
you should try this without the green
the screaming green it doesn't show up
quite as green as it actually was so
it's just it was a really sick color but
it's a nice rated they don't all of this
all of these kinds of things in terms of
that so $10 CPM which is like musk
ordinary show on TV yeah that's a penny
user cool off so that's how much the
TV's paying about 20 25 cents for an
hour of your time it's giving you and
it's a good metrics really good yeah
look us up so I can use in the future
thanks
yeah we did the same thing as the
previous one so on people come up to the
to do the hit and they get one of two
options they can't choose between and we
just measure how much work gets done so
what this means is that in order to get
the equivalent amount of work done know
if captures answered with the ugly
interface you had to point pay point six
cents more per ten CAPTCHAs to get the
same amount of work done by the average
person they did the bus work yeah or
they quit the beginning where they quit
in the end or something and you can
actually see over time so people i don't
have the graph here but we can see that
people care more about aesthetics in the
beginning but the people who like do a
lot of work don't care what it looks
like yeah i also removed a certain
feedback i changed like three things
that's yeah it's not good science yet we
could do that later okay so here's what
just to summarize what we've shown here
we measure the utility of fits law of
efficiency we can measure aesthetics so
this is just like our first steps in
this method we want to say okay look we
can measure some basic things that are
important and now with this money metric
were able to compare the value of
aesthetics and efficiency so in our
first steps of this method like it's got
some limitations will talk about but
there's also got some really nice
qualities it's very fast and cheap you
can so you can do a study on an
interface without an existing user base
without developing the full website you
can just take any random thing and put
it on there so like researchers can do
this and it's easy to rerun a study or
to have someone else just give your coat
of somebody that can change a little bit
and then run the study again and now you
can replicate results maybe they'll
generalize it to some other situations
or maybe they can refute it you can do
real science hear that HCI oftentimes
doesn't do so now i'm going to hand it
over to class portner for Ben he's going
to talk about or the economics and our
next steps in validating this yeah yeah
so
is the number of tasks that got done
yeah yes not for a person not the
actress Yeah right not the accuracy and
it's dependent on Mechanical Turk is
being able to just sort fail at any
point yep exactly yeah and you could do
accuracy but then we have to measure it
and that's just something we didn't do
yet yeah it's a lot of houses well
recapture my imagination yeah the syslog
task seemed a little hard to cheat
although I suppose you can measure the
addressee whether they actually because
you to sit there and click click click
click and you know they figure out
they're going to be paid the same for
that as they are for actually moving
mouse you're clicking the half thing
with an awesome quick why can't they
just leave them elsewhere it isn't click
which is the fastest way to get through
the task oh you have to click on the
button as it moves across the screen and
then it just sits there until you click
on it ah it only pays you have to do six
equipped for that well you have to be
you have to pass the CAPTCHA you have to
pass the caps at any time so as worried
biology is at what point do people start
gaming this because I know that we can't
culture yep do that a lot and how have
you prevented gaming yes so that that's
essentially what we're going to be
talking about the list so yes so
yeah some people actually did yeah we're
on the throat they're like this is
really easy on a iPad okay but you know
it's randomly assigned so I don't think
it's biased our data right people there
are amazing people on the come that's
actually that's also batter what we will
be trying to figure out so well so if
nothing else you can tell that they
can't miss this in the room because the
child it slides got a lot more boring
all of a sudden so this is this is all
based on the hope the whole practice of
what we're doing is actually based on
probably the most famous economist or
ever lift which is adam smith who in the
wealth of nation wrote about why wages
differ across types of employment and
one of them fits and most of them fit
very nicely with what we're looking at
and how we think about people choosing
different types of employment so one of
them is agreeable agreeableness of
disagreeable ness of the employments
themself which is exactly the capture
the capture version where we saw the
green the screaming green and which all
the nice white ones and also something
else which is essential to HCI which is
how easy is it to to learn them how hard
is it to continue to use them and the
trade-off between those two the last
part are sort of less important although
the smaller great trust which must be
reposting those who exercise them it's
essentially directly the quality part
that that you mentioned it a little bit
ago this theory is also known as
equalizing differences a compensation
variation it has a long and storied
history and economics obviously but it's
been something that's been incredibly
hard to prove partly because people
choose and it's hard to randomly
allocate people to different task and
that's one of the advantages of this is
that we can actually do this so we can
directly test whether or not this
compensating wage differential holds in
real life and it's released a
preliminary evidence indicates that it
does just to tell you a little bit more
about exactly how this works it's
essentially we're just taking these two
jobs one of them is
taiwan is fun easy type serious fun
easily interesting nice whatever the
other one is not so what we've done so
far essentially just have these easy
comparison we then see for a given
amount of work how much do we have to
pay people and then we just take the
difference so it does vary according to
what type of work you require but the
nice part about it is exactly like Mike
said is we can get a measure of how much
do we have to pay people to undertake
the less appealing job Oh vice versa how
much do we gain by making it more
appealing for four people to work on
this the way we do this in practice is
right now as Mike said what we're doing
is we're offering people a wage and so
we have the tasks and the wages of
randomized based on user ID so they
don't really get a choice they just get
that particular set of that combination
of an interface and a wage and then we
can observe how much do they actually
work then we collect some information
about where people about the workers we
know their work IDs right now we know
where they're from so the two
predominant countries are the US and
India and we estimate this for both us
workers and Indian workers and
interestingly enough we get the same
assaults the actual amount of money
required is going to be different of
course but we essentially observe
exactly the same pattern between the two
countries and then we can estimate these
labor supply functions the one downside
of doing what we're doing right now in
terms of just randomly assigning people
a wage and a job is that it's not going
to be very easy to have them do repeat
work and so we're if we're doing things
that are more complicated or if we're
doing things that require sort of
multi-step processes or that what we're
interested in studying learning over
time this method is not going to work as
well so what we the next step what we're
going to do is essentially run auctions
and so the idea is that we give people
an interface
and then they bit since you bid on a
contract saying how much will we have to
pay you to perform a given number of
task for this interface so they will be
shown the interface they will be of a
chance to try and see whether what they
think about it and then we will ask them
how much would you how much would we
have to pay you and what we then can do
is once we collect all the information
for people making their office which
essentially can start with the lowest
bidder work our way up until we reach a
predetermined number of hits that we
want to have accomplished and then
essentially we directly get the labor
supply function in that case we need to
have the actual work done because people
can say anything and so they might say
oh I'm willing to do this for one penny
I'll do 100 captures for half a penny
but that doesn't really hold any water
unless we can actually run the actual
experiment so we need to have people
actually do the work and that's one of
the things that we're trying to figure
out how likely is it that people
actually come back and do the work once
we offer them the wage but one of the
nice things if this works is that we
will be able to have the same workers
and we can have them do stuff over time
and so we can give them if we have a
more complex interface for example where
this ease of use versus ease of learning
then we will be able to follow their
offered wage overtime and see whether or
not as they become more proficient in
using this interface do the wage go down
how much is that worth that is that
learning experience over time and that's
one of the advantages of the auction
method in terms of what we're also
working on is a basic validation of the
methods that we have right now so first
of all a sample right now is relatively
small especially once we divide them up
by countries we had about 300 per
country if I remember correctly for the
captures so we need a larger sample in
order to be able to control for other
factors that might be important for how
much people work so we can do countries
right now so we can do India us but we
can't do time of day
we can't do time of day a week etc so we
want to control for that as well we want
to be have a more precise measure of
where people live so instead of just
saying the u.s. we might be able to say
Northwest etc and importantly what we
want to do is we want to have a worker
survey where we actually asked
demographic informations from the
workers and we'll pay them to fill out
the survey as with any other survey
response the circuit it's a question of
how truthful are these but we can put
some questions in there will at least
get some gauge of how truthful they are
we can ask them where do you live one
region to live in and we can check that
with the IP address and if it looks like
if they say China and they live in the
in Seattle and it's probably the rest of
his problem i'm going to be terribly
truthful as well one of other things we
wanted to do is estimating baseline
wages so essentially hourly wages for
these for a given benchmark and an easy
way to do that would use for example the
captures and how much will you have to
pay people to do this and calculate it
into hourly wage what's nice about it it
will then give us more of a benchmark to
hold all the other results to one other
thing we're planning on doing is
comparing these what we're doing with
the original lab approaches and say do
they look except do they look the same
if they don't why is it because our
method is wrong is because the lab
results are skewed in some way another
another part is to hold this up against
a be testing there are some things that
our method can do better than a/b
testing so we can do sort of more
structural parts of it better than a/b
testing but we could still hold this up
against a/b testing and say well the
departing the size of the button or the
famous yeah well I don't have to say the
size of the Google search bar should we
all know about that and so that's a
perfect example something that we could
do here we can hold it up against they
are method
really what we want to do though is try
to get a tasks that are much closer to
real world tasks so first of all we need
more complex tasks the ones you've shown
here are very easy very simple to put up
so we want things that more complex we
want things that were quality matters
it's exactly getting into back to to
your point and we want things that have
multiple steps in them and we want for
example with the multiple steps we want
to see if we split the multi-step
process up into individual parts run the
experiment what results do we get how do
we get it if we want the whole thing in
one go how do the results hold up
between the individual steps and the
full steps this is still matter how how
the design is made so some of the
examples that we've been thinking about
some of them are very easy like a
possible where we remove people people
move the puzzle pieces by keyboard or by
mouse for example we can do simple text
editing where we give a a pre-assigned
text that needs to be edited for
spelling grammatical errors etc so we
actually have some measure what the
final product is supposed to look like
and that will give us a way of getting
the quality part into it then we have
things like file management tasks to do
so in to out do we mouse who needs a
command line and another thing that
actually consists of a series of steps
which is searching and purchasing on a
fake shopping site for example so Amazon
for example would be one day building
they build different search ways of
searching and purchasing things on their
website and we could imagine essentially
taking that whole process from searching
from something to purchase and then we
will be able to observe people along the
way and then see what are the end
results and which one of these
mechanisms works best yes
security not that occasion related tasks
yeah because that's always a problem
right there such a pain in the ass and
there were something so we want to trade
off the user satisfaction to the
effectiveness of the authentication or
whatever yes right yes there's been a
little more bet on that already not not
using this button yeah yeah
unfortunately can't search for how to
people not to give out their passwords
to people who send the emails to them
like it could be various warnings I mean
you can play a game where if you were
smooth that was a your prize went down
yes or Ken where you have you need five
different passwords yes I'm like yeah
yes yes yeah I guess we could actually I
don't think about it it's just uh yeah
you want a buzzword here I I've called
this kind of thing nano economics so
microeconomics about the person yes firm
and Daniel economics is going down to
the task oh that's pretty cool yeah how
did I like yeah that's a nice word it's
my mind already yeah thanks oh yeah how
when should we quit a 45 or since we've
got like 10 minutes okay damn almost
done here so yeah so that's some other
important consideration here is the ease
of learning versus ease of use and
that's what we will eventually like to
get to and we need to run the longer
term employment to study these then we
also have some this might seem like just
pure economics to the rest of you but
there's some questions here that are
sort of important both for economics and
four for the studies so some of them are
what's called the law of one price
whether or not you get the same labor
supply function we're using the
different methods talked about how do
people set and update prices and
reputation effects and so these are talk
about each of those and just a slight
more detail and the important not just
for economics but there
also important for a method to make sure
works so one of the big ones is what's
called the law of one price which is
essentially saying that you can if you
if you offer to things like in our case
we offered a job if you offer the same
chart at two different wages people will
only do the high-paying one and so we
can we can test this by off essentially
doing exactly that offering the same job
and say do people actually go to the job
that pays the most we were essentially
we should see no work done on the job to
pace the least amount of money if we
don't we have to figure out why that is
you could imagine that would be search
costs for example and Mechanical Turk is
a nice way of testing that because the
task come up on different pages and so
depending on how far you have to click
to how much search you actually have to
do we can then see how much work do we
get and so this would be give us an idea
something we can actually test directly
in economics and has implications for
hoop which people take up our task in
which people actually doing our work and
so it's important for validating a
method then there's the price setting
part which is especially important for
the labor supply bird since we're
estimating labor supply curves and was
it but again it's fairly easy to do we
run the offered wage method versus the
auction wage and we should in principle
get the same labor supply function minus
maybe a little bit of search costs a
little bit of transaction cost but for
the auction version because people have
to think about how much they do they
have to put in a number and it's a
little more steps involved but in
principle they should look alike at
least the relative differences between
the different tasks should be the same
and it will give us some idea of how
rational are these workers and how
reliable our results are and how many
people do we need to have to do it we
can also test to what extent people are
influenced by outside information so we
can publish base amount of information
about other people's are how much how
many other what wages other people
offered and what was the last ways that
we paid what is the labor supply
function looks like etc and see to what
extent people
change their behavior based on that
information and then finally we have the
reputation so each work on Mechanical
Turk has it was amounts to a reputation
it's not actually says how many tasks
have a completed to the satisfaction of
the employer and we call that reputation
one of the interesting things we found
that sort of initially true us off a
little bit is that we're finding lots of
people who are working for sale sense
and that was just odd and especially
different economies that shouldn't
happen probably more for me than for
other people but what we would turn out
what happened is that with the fitts law
you would get a correct it will count to
watch your reputation essentially and so
you were willing to work for free or
what looked like it was for free because
there was a benefit to you in terms of
your reputation and you can then go use
that on other task on Mechanical Turk
and so we can actually test this by
randomizing how many credits you get
providing these tasks so whether or not
you get zero you get why we have to give
them one at least if I'm Linda correctly
but whether you get one whether or not
you get half of them or even get all of
them or even more for example and so we
can then see how much of an effect does
that have and one of the things that's
nice about this we can actually see how
how good is this reputation effect at
predicting quality once we get to change
the tasks that are actually
quality-related this is important
especially for these more complex tasks
i was talking about but it's also
important because it might potentially
bias our results if we don't take
account of this because at the low wages
to look like we're getting more work
done then when some sense really should
have because people working to enhance
their reputation within that and then
pass it over to Mike for future work all
right so it's important for us to
yeah thanks so I'm glad you're here is
makes it more fun so so what I'm going
to talking about now is more like the
broader space like stuff that like so
far but has been presenting this one
method that we've been doing but this is
just that there's a general state spacer
of utility measurement looking at
preferences looking at choice of which
you guys know a lot about with a/b
testing and boom here's a be testing on
the upper right so I think moving
forward like this is just important for
HCI to tackle but there's a lot of
different methods and a lot of stuff
here so this is a way of visualizing the
space we have labor market methods like
mechanical turk you can also do
preference measurement using existing
websites on the right like a be testing
okay so this is our method in the upper
right rubber left maybe testing is in
the upper right i'm going to go into
these other ones in a bit but first
let's just compare these to Sal ittle
bit so AP testing is not very good for
early ok no but i have not done regular
AP tests you guys are the expert this is
my intuition i'm just going to suggest
something so maybe testing is not very
good for early stage designs and mock
ups because you have to develop and
deploy a full website ok so now we can
test some some early idea something
that's not going to be like a fine-grain
tweet because we don't need a fit in the
system also we can now allow academics
and independent designers to run
preference measurement because they
don't need access to google the only to
access to a full existing user base you
have mechanical turk and it's just got a
bunch of users sitting there for you
this is great for us we can do science
experiments we couldn't do before it so
it's kind of why we're stuck setting
time and measurement in academia we can
also learn why more easily so an a/b
testing is often times you get you learn
what you don't learn why it's two
reasons why we learn why one is that
we're paying users they kind of love
doing surveys it's hard to get a user of
your website to take a survey you get a
small sample size but Mechanical Turk
as you pay them an extra penny and
they're like oh yeah I'll tell you
everything about this and we also have
freedom to control these tasks if your
google maybe you would like to
understand the utility of your page
layout on the search without having the
actual search there for some reason
maybe you just want people to be
browsing and you want to isolate the
browsing but you can't remove search
from the actual website to do an a/b
test we can do it weird things on
Mechanical Turk like having people click
on buttons and answer CAPTCHAs ok so
this lets us by controlling the
interface we can control and isolate
different factors and do science
experiments that tell us more about why
what's going on and this money metric is
a very powerful way to communicate
results now you don't just say hey I got
twenty percent more conversions now you
say I just gave five cents to my users
and if you have 100,000 users and you
have like five hundred thousand sense
which it's a lot of sense maybe it's not
as much choice okay so let's look back
at this space again so the labor market
approaches so we did this existing labor
market we just use Mechanical Turk but
you could also roll your own and
apparently google has almost a labor
market is what Dan was telling me that's
really cool i would love if we could add
some sort of bonus payment to that and
we can start doing these tod measurement
on my mock-up is like here's in gmail
you have this little ad over here beta
test for google and you can start
earning credit so this is the way you
can recruit people to your labor market
and then set up a little labor market
that people do two different tasks or
differing amounts of money this is how
Mechanical Turk was started Amazon put a
bunch of ads on our website and said hey
we're going to pay you pennies to fix
the information or publishers give us
about our books when they put database
fields in the wrong place so whenever
you have a partner with Mechanical Turk
this is a way to solve it you can
control anything you control your
demographics it's very useful for all
that on the other hand there's webs
methods with existing websites oh man
this fonts not readable but on well you
have
never ending this is great um oh it's
not that useful anyway the text you have
your traditional a/b tests we can
augment them with pay now so let's say
you start paying people different mounts
of money to create reviews on Amazon now
you can get labor supply curves and and
you can get all these same things I'm on
existing websites the reason why you
might okay so why do we have these two
sets of methods underlying all this
think of the utility as consisting of
both the value of accomplishing the goal
and then the cost of using the interface
because usually like you want to get
something done but you have to go
through this crappy thing on a computer
in order to get to your goal and this is
why we do tasks the way this is a nice
way to separated is that on the labor
market people aren't pursuing natural
goals instead we're paying them money so
we can't measure this value you just
can't measure it what we do measure is
the cost so this lets us isolate the
cost but we can't measure the value
unfortunately measuring the value is
really important like that's what makes
websites work you care about the value
well so that's why we have existing
website methods because this measure is
the overall utility maybe test is just
let's see how much value there actually
is to people how much work it's done and
now if you can use these methods you can
probably triangulate and subtract one
from the other to get up the value it's
just hypothesizing but I think it'd be
pretty cool let's move a little bit
forward so let's talk about the hard
thing about running these studies which
you alluded to is how do you get these
people to do what you want how do you
get mechanical turquoise you might want
to do all sorts of other weird things so
imagine that your tasks this video this
is like all the different things you
might do on Facebook in one session and
there's different scopes at which you
could test this maybe you're clicking on
a button in that little scope and a
bigger scope if you're sending an email
and bigger overall scope maybe just
using facebook and you can when you run
a study you get to choose which scope
you're going to have people do what's
the task are you going to say use
Facebook you're going to say click this
button 60 times and each one is going to
have different characteristics for how
you want to ensure people do the right
thing so clicking the button you can
just test that automatically that's what
we did okay the computer can tell ya you
click the button or not so that's easy
to do and then you have an incentive
which is if you don't click the button
you're not going to get paid if you're
sending an email well now there's
different ways to send him you could
write a really nice email or you can
just type a compass characters and click
the button so you're now you want to
test the quality of that email okay and
the way to do that is to take this text
send it to other medical turquoise and
have them grade it and for even more
open-ended things you might want to
record the screen session of the worker
okay and have other people verify yeah
you're doing kind of what we want you to
do and you want to trust a beta-test
pool probably this is I don't know if
this is going to work but this is
speculation things you might try if you
want to do these kinds of studies okay
so almost done here's an example of a
science experiment that I think it'd be
really cool to do okay a TD is a big
problem and it really determines a lot
of how the internet works like why is
Twitter successful may be more
successful than blogging now a lot of
more people seem to tweet them blog
people don't it's very hard to get
people to put extended attention on the
internet like to tend to something for a
long time just like it is with real life
now that everyone's got a TD and it
seems like this maybe determines a lot
of the shape of the internet determines
which tasks succeed we can start to
measure this so like what is the cost to
getting someone to write a small tweet
versus a longer one you know if it's of
the same quality versus something even
longer like a full paragraph that's
thought out what's the cost there what's
the cost of a whole article so I am what
I patha size it may be the graph might
look something like this on this axis is
the length of the thing you're having
them right and here's the cost of
getting them to do it and it's probably
not going to be linear having them do
something big probably has some curve to
it the amount of Bend in this line might
be a characteristic of the user
population of their level of a TD and
you can try running this by recruiting
people from YouTube which maybe is very
a TD maybe if you recruit people from
bloggers right after they finished
writing a long article maybe they're not
so a TD and it would be useful way to
characterize way the internet works so
let's conclude on economic speech HCI
this is HTI's first science of choice
and I think this is very important for
the future
the internet important for how we
understand things way the Internet's
going is we have a lot of things like
gains we have to design now which you
know people spend money to have choices
ways for them to spend their time like
compelling ways from in this fellow time
and it's all about the utility of these
choices that you're giving them
crowdsourcing is a really exciting new
field that depends on finding ways to
motivate people to do tasks web surfing
there's a bunch of things here that I
just think are totally interesting
attention economics is this theory that
we're now basically measuring attention
economics and has really been measured
before and so I think this is the future
of HCI this is most of my screen saver
but this is what matters to us as a
field is measuring what people will do
measuring the utility we have this
history in HCI of borrowing methods in
different fields like cognitive
psychology and ethnography from
anthropologists and other social
sciences now but these don't really fit
what we care about these don't help us
design the interfaces and measure what
matters so it's time for us to develop
our own methods to solve our own
problems and measure what matters that's
it thanks also I'm just really excited
to be here and hear everything that you
guys talk about because I just feel a
lot of resonance with google and I would
love to like understand really what's
going on and see if there's some
collaborations or something what I think
would be there in fact we supported some
work by Yan chat
University vision 2030 limitation got
down the questions you could figure out
what people were asking turned out it
was about six hundred questions and then
she took one team of students and sent
them to the library to answer the
questions and the other team of students
were said to google the answer questions
we measured the time to completion of
trans antics 22 minutes dancer question
the librarian and think seven minutes
this was one of the interesting things
that they reported back was that there
was a much much higher satisfaction
survey because students found it much
easier much better even for the same
accuracy old it didn't even accounting
for the time difference what's that was
flying on google or in the library who
would be quite a night I mean they must
be declared on so of course all we
measure from the survey is how month is
that they did prefer it that no idea of
how much they prefer to you according to
your method you presumably pay them
different wages to answer this and then
one last point is that it's something
that people really misunderstand about
utility yes you could pay money and
that's very convenient me to pay an ice
cream mm-hmm you could pay in chocolate
compare anything you know just how much
it in order to do this task how much ice
creams out to be to make your bed or how
much whatever so it isn't necessarily
tied the money to the other trade offs
as well but I think money is the most
natural communication thanks I'll
rephrase one of my earlier questions
so you talk first about doing these
things based on efficiency and then
that's what you're doing with your fits
law casting and then you talked about
now you're trying to establish sort of
the same cast but game atmosphere and
you think the relevant metric is really
a measure of fun you know they'll pay
for the maximum amount of fun so how do
you understand the trade-offs how do you
know that that isn't a you know that
they are maximizing efficiency or or
that in the fifth law case you know
purif its law case they working for fun
or something like that given that user
satisfaction is this multifaceted thing
how do you know what facet you're
looking at you never you never really
know for sure it's always on I mean
these are just like psychology studies I
think where there's some a matter of
interpretation where the person looking
at the study says that people agree that
this is kind of what we're manipulating
in the study so that depends on the
study design right what we're measuring
is just the black box overall output
we're measuring overall utility it's up
to you to interpret what was the
manipulation you made in that study and
what does that mean is that tata
logically true but what are you doing to
maximize the chances that i will
interpret this the way you want me to
interpret it Oh liking in this specific
bike game vs vs efficiency case like
we're change any incentive structure to
sew in the efficiency case you're paid
per button click you're getting done and
the game we're going to get paid for
minute playing the game okay so it
doesn't matter how many quicks you get
done that's just up to you you you're
motivated to do whatever you want there
they are tightly intertwined yeah but
that's and that's exactly what if the
advantage of the method this you can you
can tweak eat a little bit or you can
treat the whole the whole thing in one
go that's also why one of the things
with the multi-step process where are
the more complex tasks where you can
split them up into the individual parts
and you can see what the results are
there and then you can combine all of
them and do the studies for the combined
version and then that will teach you
something about how they how they that
will tell you something about how they
match together so that's one of the
advantages and the idea about hopefully
eventually what we get is a morph a once
people start doing this enough well
since you get a library of what works
and what doesn't then how much does it
work and that's sort of the idea that's
probably not on task but other people
can do that
easy to use initially but easy once
you've learned it to you but I think
people are particularly good at judging
that based on whatever they will see
before they have to make the commitment
to do this so clearly you can I mean at
one level you can just study perceived
like that but do you have any ideas of
getting at some of the deeper issues
could really use this economic approach
to get at actual ease of learning as
opposed to what people think is going to
be one thing you do get here was I
didn't show it was we are recomputing
these survival curves so we could
succeed over time how many times at a
person do the tasks when did they drop
out of the study okay and that can show
you that like maybe they learn things
initially and then there is a big
problem when they got to this part of
the interface or something like that and
we could also simply that we could also
that's why watch one of the advantages
of the auction method that we talked
about is that we will be if we can
continue having people work on this
interface we will be able to observe
their learning over time if we can get
the same workers to come back and
perform your tasks so that I agree that
they probably upfront won't be able to
say I think this one is going to be easy
to work on once I learned it that
requires actually sitting down and doing
it but if we can if we can observe them
repeatedly then we can get an idea of
how how much in fact does this
ease-of-use have over time yes yes yes
exactly yes no no they bet that they bit
every every single time so and that's
hopefully that will exactly get it what
you were asking that
no no they're bidding this methodology
what I'm worried about is how do you
ever tas tmax because getting people we
have the bail in malad to start using
him yes yes yeah that for the rest of my
life yes far exceeds no bad I mean yes
but you can't tell that in the sort of
the initial 10 minutes you'll be
considering their bid well we can we can
run these studies long-term too so
that's that's a perfect example of
something that would have to run over a
long period of time and would have to
get people so you run them once and say
well you give you get emacs on your on
your screen you have to do whatever it
is safer file which is bad enough in
emacs and okay and then you can and then
you we have people have to bid on that
and then you then go and actually have
them do it then you do it again the day
after you do to do it again the day
after you go back to the same people and
say how much do we have to pay you to do
it tomorrow and you can observe over a
week whether or not we have to pay them
less and less editor and you have to
start with two separate populations one
that was saying how much will we have to
pay you to learn emacs and one you're
saying how much thing we have to pay you
to run note that and then later in the
study you have to merge the two
populations and say how much will we
have to pay you to edit the stomping
well if we're just interested out sorry
yeah hot yes so if you know anything
even wants to come into our conversation
with these guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>