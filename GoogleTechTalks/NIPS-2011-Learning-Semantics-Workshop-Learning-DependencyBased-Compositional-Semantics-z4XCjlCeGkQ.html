<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Learning Semantics Workshop: Learning Dependency-Based Compositional Semantics | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Learning Semantics Workshop: Learning Dependency-Based Compositional Semantics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Learning Semantics Workshop: Learning Dependency-Based Compositional Semantics</b></h2><h5 class="post__date">2012-02-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z4XCjlCeGkQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so at first
so this topic is going to be very much
in the same thing as race lock you want
to
learn some sort of language semantics
without cheating too much or is using my
supervision as I souls to be more
company let's take a look at the problem
of question answered suppose build a
system to answer questions what is large
city in college okay some so actually
with this question these days it's not
so hard to get an answer you just go
over and here too okay so if you type it
into your favorite search engine which
it uses Google then it actually not only
gives you the answers what you see a lot
of basically the answers are in all to
left Los Angeles largest city on ok so
that's maybe a kind of salt problem in
some sense but what if you wanted to
know what is the largest city in a state
bordering California okay so let's go to
our Google here and so you get a lot of
results about hand States and bordering
but you don't really see anything
resembling that the answer you want
right and what if this illustration Las
Vegas or Phoenix at what Venus um so
this is just a lil astray that we're
interested in ultimately we're
interested in language
real language understanding requires
more than just superficial naturally of
keywords it requires you to take apart
the designs so let me show you a demo
which is the system that i'm going to
describe later are able to handle these
type of more complicated ways so let's
just begin with something what is the
largest better work was completely
person ok so what the system does is
it's going to take the sentence it's
going to part it into an internal
representation which it's a label-free
started with some labels on it and then
this this is a logical form or program
or if you want to think about in a
sequel query its evaluated with respect
to a database of facts about US
geography and the answer is this great
and one day I want to point out is that
we're going to be inducing somatic so
this is a semantic to the sentence but
we're never going to observe since
everyone knows they're just messing okay
get a bit this always with what the tree
is in alimony much later we're just kind
of good feelings or capability so what
is the largest city in California what
is the largest city in the state for
Graham
better work too okay so it gets Phoenix
which confirms race answer but and you
can compose it so you can say what is
the population and then so visa that's a
little bit so it says more how the idea
is that because we're kind of analyzing
the language even make this fairly
complicated and it kind of composes me
when we try state bordering the state
that order in this state that borders
stands alone little city yeah yeah right
you get this transitivity yeah okay so
um so now I'm going to go one to the
video so but just to kind of illustrate
the point what will help know what is
the nature of this problem ever consult
we're going to be learning but the model
are going to be lady is very you know
different from a lot of machine learning
I might see on text so take for example
doctrine classification here in this
document outlets a category and hear
what isn't terribly difficult because
all you have to do is learn these
associations between the words and the
category and going to get enough
training examples in your CDs learn
these correlations directly but if you
look at the problem if you already wants
have a sentence here's the input antlers
output on here you can see that there's
no superficial correlation to exploit
there's something deeper going on so
let's try to kind of work through what
is so i'm going to write something kind
of logical for me looking at
congressional edges give you the
intuition so there's this is definitely
talking about a city let's call the CHC
and the cities in some state apps and
the state is for California and if you
take the waterless one of these with
respect to the population metric and you
get this and if you evaluate this on the
database you get the answer you want so
notice that there's this kind of
important things and there's
communication that has really
complicated is this kind of executing
somehow that database that separates the
the sentence have an answer and
furthermore it's unknown so we're going
to have to induce this that's the
expression so so the first name of the
talk is a programmer person so I'm
calling these programs are logical form
or some queries where you want but the
idea is that you want something fairly
structured to be able to capture the
complexity of language and another theme
is that how are you given that you want
to use these hated representations how
do you go to them and know this ray
imagine it is hot too for a a lot of
methods go and say here's a set
a lot of perform but this requires an
expert someone who knows how to reach
them right these forms and there are w
experts out there so promote scaling
back with this you can't give too many
sentences this way we're going to try to
learn from natural natural supervision
which is you just get
question-and-answer pairs and this form
of supervision just requires a
non-expert so you can put this off
turkey or give it to you I and anyone
who has access to the facts july this
form of application in the skill another
point is that this form of supervision
is have dependent on your representation
and if you are credibility naturally
system in some sense on what your target
your ultimate goal is to answer so in
some sense this is providing you the
full pipe pipe line rather than a selfie
it's so natural supervision i'm just i'm
using this term loosely is where it's
kind of more from the data collection if
you activated with which is i like low
natural supervision something data which
you can get from non-experts so this has
been very useful in other places in
menifee for example mission
solution where machine translation
systems learn from examples that look
this you have influenced energy analyst
translation but you normally don't get
how the translation happens that city is
here and so that's kind of a first-leg
barrel and it's been very successful
because you have a lot of data that
looks like that and basically no data
that has more details in position to
even if you can exploit it then great
but also creates a harder learning
problem so we're gonna have to deal with
that okay so there's the two parts
program representation in a provision
that are kind of the key themes and
gradients I rhythm in this one place and
the rest of the talk i'm gonna go over
more detail about how this works so
first i'm going to talk about the
representation right so i wrote some i
drew some trees and i wrote something
logical form expression so where do what
is this latent variable actually going
to be um so there's few consideration
one of them is computational what the
learning algorithm sees is a question
and answer and it kind of has to you
know infer this link variable and
there's a lot of different things that
this could be most of them are incorrect
they don't feel they're the answer that
you want but and one of them is correct
or a few of them on track so the
landscape looks like you have a sea of
incorrect logic or down on maybe one or
two of different logical forms
I have to find it so it's a kind of a
hard surface often intrinsically but
even if you know if I give you this
logic form there's still the statistical
question how you parameterize this
maverick from sentence too emotional for
me now you know this is kind of the
classic phone in linguistics is
compositional that takes our kind of
from a brain perspective it's kind of
more of a franchise a shoe because it's
how your primer is your model so I'm
just too hard on this little more so
it's not clear you know you know that's
kind of city corresponds to I see out
here by the way i'm using italics denote
words which are going to be distinct
from these symbols which could be this
city could be XYZ 123
so this is this map me is not true so
what we're going to do this in this talk
is I'm going to talk about on a formula
zamora framework which are called the
pansy based compositional semantics
which is a particular way of
representing semantics which has a
number of Avengers hotel surely an idea
that the lovable forms are going to look
like this and intuitively you can think
of on taking the words formula
dependency tree and replacing the words
with these logical pressure that's a
pretty some labels you'll see how this
kind of stuff away a little bit later
but there's one kind important piece
missing which I haven't I kind of
lighted over which is what are the
answers come from I mean this is just
I'm understanding the question in order
to answer the question also know the
answers night for example what is larger
state boarding in a way to our city in
the state boring for Nia I'm sure hope
you understood the question but it might
have not helped and here we're going to
assume Li Hao just database of that's in
this case you're a star p what
publicans and database looks like this
where you have encouraged predication
you have a set of two bowls of things
for example this says San Francisco is
as the creation walk cornea and pencil
so it's fairly straightforward ok so now
given this database yes have to say that
the relations if you're going to use or
else plus i to the difference so these
are symbols are fixed in advance and the
contents of the day of your salsa fix
I'm not there I'm going to simply
dislike the company had art max but
that's not in your obviously right so
you that's a good point so conceptually
you can think of our matches one of
these predicates is your right on the
table it would be a sin like the largest
outside hook it on division ignition
it's you know just so it implicitly
represent ok so now even one of these
dcs duties which are the slot performs
and a database I'm going to tell you
what this so no we're not considering
the language here just considering how
relatives okay so the idea that dcs free
encode the constraint satisfaction
problem where each variable introduce
each node variable and each edge
introduces straining is very welcome so
your sees America has an element of
cities is set in spirit and in Our
Strength's I'm the first element of C to
see what nuts with what is one response
to is same as l1 which is the first
column of this of this table so you have
this a system of constraints and one of
the solutions might be settings his go
out of services from California and as
to California okay and the nice thing
about having this kind of strength
formulation is that dcs trees AR trees
and for trees we can compute this and
efficiently using kind of programming on
in a much basically the same as if you
know we're doing the repopulation on a
tree and the time right under suburb in
general sake cities are you know hard
but since we're going to be building
these trees and it's going to be right
you lost me what does that want to help
chili 14 so I was a tuple of two
elements l2 is a second component oh I
sense a tuple corresponding to that
table yeah so this is table fingers
set of tables this says the constraint
says that al is an element of that set
so I always any umbro here and l2 is the
second element what does the 200 make
the look on the diagramming so this is
kind of notation for denoting this is so
this says that this edge introducing a
strength APIs to is this this one so
that if this is I straight and Belgian
of a line bus question ok so you can
snap this is kind of like three personal
mail that larger just gives you an idea
of what these things okay so this is a
city that's located in state court in
California and city also produces a
major river that Arizona so as you can
see with venom only the newcomers a
semantic slap with relatively limited
means you can start developing rather
complicated utterances and just to
highlight the fact that we're building
these trees and on remember i mentioned
that these kind of look like dependency
treason mystics and there's internet i
kind of if you look at syntax there's
kind of only local relationship between
the words ideas I'm syntactic
dependencies and it turns out that those
same cement expenses correspond to the
tree structure which are important for
computation as we saw as well so these
are kind of a nice way to have an
efficient performance of that has
expressing offers ok so if everything
were that simple then that would be
great but language was always has a lot
of bucks knees and just to illustrate
one of them take this phrase most
popular city in California so here's
kind of its course in X so here's a most
popular process of modifying a device
which modify the city but if you look
after semantics this is a crime kind of
writing it out in the not the calculus
of notation that most corresponds to
this art mask and our max is kind of way
out in front so on top if you were to
write this out in the tree our packaging
counter there's really no because has to
be applied last but so the rib thing now
is that if we're going to build trees
like this and but we want to get your
cosmetics which in in which the most
element is high up in the trees so
here's the syntactic position as low and
the static position is high from on how
to reconcile this discrepancy so we have
a solution to this problem in the
context of our framework it is on where
I called mark execute and ideas on the
intuitive ideas fairly straightforward
ideas that we're going to build our
trees which are going to look like ass
but we're going to insert these kind of
simple mark relations which are going to
say hey there's something just hang on
to that guy for now and then I'm going
to execute at the appropriate place
where the this element is Larry
that so the street remember now it looks
like this syntax tree but it includes
all the information that you need to get
the correct a symmetric reality so we
kind of how are you bae systems and so
this is kind of a superlative
construction we i won't go through the
details but you can this is kind of a
general framework that you can use to
handle others scope divisions problems
like a negation and quantification and
maybe it's worth going through this
example so there's this is have a
canonical 15 minuites example flow in
Lucic's waiting out some different
refers to the city has two readings
either there's a long river that does on
tsp or on every city there's a pic you
stream that goes through and here we can
see in this this formalism we don't have
to commit to this when you're building
the tree up always say that some is on
fire albert is upon meyer don't do
anything and then up here we execute and
here we see that you specify the order
12 means that we're going to handle that
every first and that the songs are
getting no reading and if you swap and
you get the other so this kind of is is
nice because when you even when you
parse this did the tubes and a career
you know the same but and localize the
the symmetric him back in one place
instead of
and I should mention that you know this
solution isn't this is all problem and
number of other you know linguistic I
mean basically every serious Korsak
framework has to deal with these and
other issues and they kind of go by
different names on raising my hand
Cooper storage and so on so I'm just
presenting this in the context of this
acsp ok so those rough sketch of the
representation we're going to be trying
to learn these trees are we actually do
it so here now i'm going to set up a
holistic model before i saw a show you
how you can take a lot of clumsy and a
database and evaluate to get an answer
by haven't told you anything about how
to hook up with language all i said is
that yeah i was an extreme tree but we
have to do a little bit better than that
so this part is called the
transportation is deterministic but it's
not trivial and now we're going to focus
on the other part of the picture which
is that you're given a an utterance
capital of california and you want to
map it onto logical form with the aid of
some parameters so this part is
typically called on semantic parsing and
it's probabilistic because and we're
trying to you know language is ambiguous
and we have to make an uncertainty over
okay so so now this is kind of a rough
structure I'm going to dive in by
telling you what are possible what is
the support of this distribution center
what an impossible idea CS trees we're
going to consider forgiving utterance
and then tell you about the actual this
is your intention that you're going to
be I understand you're discussing a
prior not too busy but at test time what
you're doing this with respect to your
number of candidate answers so you have
the hate of that does look as well um so
I learned exactly also the prior so this
is a thing about looking such a
discriminative on so here's the input
output there's a lane very bored the
answer is yes taxi will be using it join
ya will be enjoyable okay so so what are
the possible trees there's an infinite
number of trees we can answer all of
them well marginalize out them all um so
here let me start with an example
most populous city in California so we
wanted to find a set of possible trees
going on a cleanse distribution number
and to start out for each word we're
going to put it some number about
predicate so this is kind of the initial
word word word to prep direction so
raven called is cheating but it's not
that bad so for Constance I've got
California where the proper names you
basically say yeah looks like the
California have in my database so for
 words we're going to because
there's such a small post possible we're
just going to specify them and that's
going to kind of constrained the other
money and so now for on yes ability and
a lot in Italy most could be yeah so
this is ideas not to pin down at this
moment snot and condemned
right word on it just give a cabinet so
if you have other candidates with just
two in particular for nouns and
adjectives here we assume that we don't
know what a city is it could be with a
strange city could be a city-state river
that population a lever so we just let
them yeah okay so now at this point we
have the candidates and now we're going
to build up the trees on readers and
this kind of fall is kind of a rough in
flavor of parsing general an idea is
that for every sucks fan of the sentence
from I DJ we're going to have consider
we're going to build a set of pcs trees
we're going to consider all split points
okay recursively build us so trees for
those and then take every day basically
taste take the cross product and vinyl
treats and some local and then we
generate a bunch of hypotheses this true
this sub span okay so now I have to find
the set of trees we have to define a
distribution over that and here is a
relatively straightforward logging in
your model where we have the input
sentence we have the dcs tree which is
built on top of it and we just find some
features and these teachers are very
simple ones which have our indicator of
whether our word appears with a prayer
whether predicate appears with another
credit group via simulation so there's a
bunch of these simple things and very
standard if you the log linear model it
is a inner product between the features
and some progress which okay so learning
is basically going to be massive
likelihood where we marginalize out the
ladies and here on one thing I didn't
mention is that in practice so this
procedure for kind of building out trees
can blow up quickly it's an exponential
so at each point in time we're going to
say pick the top aundrea offseason ok so
the learning of works as follows you
initialize the parameters to something
reasonable sr 0 and then you use a
procedure I described to you break the
trees and now you can for each of these
trees you run them on the database and
see did you get the right answer and
your marker 17 did and this gives you
kind of now not are completely a
supervisor problem because there could
be some multiple registers but it gives
you kind of a monster flies volume
without
the kind of nasty search oh so now you
can optimize the parameters given this
by just gradient based methods and then
now it has some new parameters when you
explore the set of trees you might get
something differently because of
parameters have changed hopefully the
good guy so goes the top and that you
iterate until so I'm calling it an IAM
algorithm because it's it's not exactly
in this part is kind of doing the great
employee this is a structural so i've
broken up into kind of the structural
part out okay so how to experimentally
experiment with this standard smash it
parsing benchmark which premium public
telephones developers and so using
nineties and consists of examples
episode like this one special in florida
and sentences and each of them is
labeled a logical formula original
dataset overdressed not learn from this
one performs but instead learn from
these dancers so to a learning algorithm
is we have some training data we have
this lexicon so there's two version of
this experiment one is where we tell it
that city is so for every credit that we
have one board that we know too
so they see could we refer to other
things like towns or villages or
settlements but we just skip it one kind
of as an initial seed and there's
another version of experiments where we
don't tell it what it is and then we
have a database which is just kind of
fixed for good on so experiment one we
were trying to compare how well does our
method work compared to other so there's
another system which also learns from
question-and-answer occurs here it's
actually and they use kind of a
different framework which i'll have x go
into they don't the only thought
performs but they have this pretty
elaborate lexicon and we show that our
system despite using earth kind of small
of us con can improve the results and if
we kind of music something horrible to
their supervision things we improve even
more so the same set of experiences were
trying to compare to on the state of the
art semantic process on this data set so
in particular these are going to use on
logical forms as supervision so I'm just
there's been a lot of working this I'm
showing how the subsidy switches more
directly comparable so there's a slight
worth lying through seven water and my
collins and some of their colleagues
which are able to learn using our
performance but dating
lerner less kind and they are able to
get something like 88.9 if we learn with
a small amount of website will help but
performs that we do a little bit worse
but comparable and I just want to point
out that though you know logical forms
out of those remember those are those
complicated things which are would be
hard to get a human to a date words that
lexicon is saying that city is city so I
think it's less supervision and if we
allow ourselves to tell her that no
cydia city so there's a 75 words then we
get improve it okay so um let's see so
this is I guess to the point of the take
home message is that even though we
haven't have this huge nasty logic
performance of light durable we show
that with handed the ropes efficient
representation and some constraints from
the lexicon we're still able to learn
and pretty effectively okay so um so I
mentioned before that there's kind of an
intrinsic hard search problem which is
that in especially in the beginning your
grounders are zero you have no idea
what's the symmetric parts of the
sentences and you're supposed to get the
right answer so it's a very massive
coloring tutorial certain home and
Indian so hard that um you know you
might come across the sentence and you
get your top okay listen there's nothing
that is unity we were unable to get the
right answer and that makes you skip but
we've seen that as you train so after
the first iteration your skin
in my seventy percent of the examples
just because you can't do anything but
when the your training out that thirty
percent you get three parameters the
next time you're able to train on sixty
percent and it produces something like
ninety-eight percent so you see that
there's this kind of almost automatic
curriculum learning where you in the
beginning you're you don't know anything
so you train on the thirty percent of
the easy examples where you can just
kind of brute force search it and you
get the right answers and these later
that meaning you learn some nice tremors
so that enables you to bootstrap up okay
so so i'm going to put their very
quickly so this is high for elimination
/a future work I so currently were
thinking of the programs of black box
where we want to execute program get the
answer but really this probe this
problem is about inverting of going from
the answer back to the launch perform
and it might be useful to exploit some
more rich properties of the program that
so they're all this is constrained by
the database over there spats if you
asked how far is Los Angeles from New
York bbc's really has no database
distance informations are walking away
and there's also unknown concepts which
are what states are a lot more even if
the database has information you'll a
block is something that's not just a
predicate in the database but its kind
not boring the ocean and something more
complicated and there is a word that you
see if you never see settlement in the
training data of them you might not go
to do battle right on let me just show
you that for these last two we can
actually do a little bit more so let's
say what is the largest oh so that it
wasn't my photos at JPM Virginia
crashing so this whole idea is that well
so what is a large settlement in
California and it's never seen
settlement before so you know all these
weights are zero and it basic try
suggests guess and it decided well I'm
going to tell you the longest girlfriend
set which is horrible but if you once
the feature of the system is that you
can go down here and look at the
candidate answers and you see that
question was about your summer ok so
that's Los Angeles and here's Los
Angeles you click on it and say that's
correct and now what this does is it
gives the training example to the system
makes an online update and now if you
ask and we won't touch then you'll give
you the right answer but but more
importantly a kind of generalizing so
you can say what settlement in Texas
it's the largest and
we're on texts on okay so it does a good
job of generalizing from that one
example for this case there are other
things what if you want to know what is
the largest settlement and Pacific
Northwest
okay well that was clearly wrong you
know what happened here is that Pacific
Northwest is it's one of these kind of
more advanced concept it's not a city an
assistant doesn't know anymore but fear
not we can do so what is the Pacific
Northwest well it's kind of like
Washington State and states bordering
Washington right and we can say that the
Pacific Northwest now we ask what is the
largest settlement in the Pacific
Northwest it's able to use that piece of
information and tell you that Seattle is
the largest city in a month goes through
state okay so okay so let me put it out
so we started with a promise mental
preparation we I try to argue that this
required you know I have a more
complicated program representation you
can't just get by right no matching
words on other and we want to be able to
learn these representations from no
natural supervision so which means we're
going to be dealing with this heart of
learning moment with a large linker and
we saw that there's I mean from a
learning perspective is several
interesting things I want to point out
one of us is kind of on that acronym
learning I think which really helped in
this case because it is in the beginning
your model is really bad and you have no
idea so you can kind of only rely on the
simple examples
yourself up and on this kind of I just
showed you is I think that online
learning is a promising Avenue we're
imagining of a system which is doing all
I'm learning and it's also online so you
know users can interact with it in a fit
you're not in your line so they can get
media feedback and this in this matter
you could hope to train up and it's
rather more better our scale constanta
parts of the answers questions so just
kind of a finish off to the opportunity
picture of where I see all this so you
know that in the good old days or battle
phase however there is a lot of emphasis
on getting a lot of depth out of
language but not in very limited remains
and over the years you know that Cisco
revolution has pushed this in this
direction where we're able to parse the
entire web but we're not doing any
source for the understanding the earth
is give us before and you can see this
work is you honestly want to go into the
upper right corner so the challenge will
be to how to bridge these two and this
work represents kind of one little pinch</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>