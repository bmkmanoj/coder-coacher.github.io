<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Topics in Programming Languages: The Java Memory... | Coder Coacher - Coaching Coders</title><meta content="Advanced Topics in Programming Languages: The Java Memory... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Advanced Topics in Programming Languages: The Java Memory...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1FX4zco0ziY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">miss Jeremy Manson those of you who come
every week will know that this is the
series of talks on advanced topics and
programming languages before we start
every talk usually it's a different
speaker before we start every talk I
like to make a plug for other people to
come and give talks so if you are an
expert in something usually programming
languages or software engineering
related but it's necessarily have to be
then please come up to me so that we can
arrange for you to give a talk because
everybody else is in fact interested in
hearing what you have to say
all right so having said that I am the
speaker today and I will be speaking
about the Java memory model exciting
stuff by the way it says Google
confidential in the corner here that's
because the template said Google
confidential it's not really
confidential I'm not gonna talk about
any none I'm not gonna talking about any
confidential material today you can feel
free to ask me questions but don't ask
me confidential questions because the
video is going out live right so the
Java memory model this is really about
concurrency in Java and what I'm going
to do today is I'm going to talk about
how you can understand the building
blocks of concurrency and job and how
you can use them to make effective and
efficient code alright so this is
basically the rundown of where I'm gonna
go today I'm going to talk about the
scope of the talk a little bit for a few
minutes and then I'm going to talk about
the basics the fundamentals the
underlying principles behind concurrency
in Java and then I'm going to talk about
thread safe lazy initialization because
that's a topic that comes up a heck of a
lot and it's good to have something on
the record about that I'm gonna talk
about how you can use final fields to
write to have this decent design
patterns in Java and I'm gonna make some
very generic recommendations at the end
about how to design concurrent code it's
nothing terribly specific but hopefully
it will be enlightening alright so the
Java thread specification it was it was
revised as part of jsr 133 that's a Java
specification request number 133 and it
was incorporated into JDK 5 so it's in
JDK 5 day TK 6 and all future JDK s we
had a few different goals in revising it
if you actually look back at the
original javathread specification it was
really really impossible to understand
and even the even the people who
we're supposed to understand it like the
VM writers and they couldn't understand
it and they did all sorts of things that
violated it including including
optimizations in their JVM that was
actually that was actually violated the
specification and things like that so we
had a few goals in the revision one of
the goals was you make it make it clear
and easy to understand well if any of
you have actually looked at it you know
it's a little tricky to understand but
you make it clear and make it so that
every question you ask actually has a
clear answer the goal is then so that
programmers can look at it and write
reliable multi-threaded code that they
know what it's going to do such that
they know what's going to do and the
compiler writers and VM designers could
also look at it and say I'm performing
this compiler optimization I'm
performing this transformation that's a
legal transformation I have to as a JVM
writer I have to provide this guarantee
I have to provide that guarantee and
really know what they were supposed to
be doing this isn't always so easy most
of you have probably programmed
multi-threaded systems before and a lot
of your a lot of what immediately come
across as intuitive assumptions don't
necessarily hold in multi-threaded
systems there are some very widely used
idioms or some lithium's that have been
very widely used some suggested idioms
that we're going to talk about a little
bit later but that aren't safe so for
example something called double check
locking which is going to come back to
that
late third safe lazy initialization that
I mentioned a little bit earlier
checking non-volatile flag for thread
termination which I'm also going to talk
about a little bit later and
unfortunately as undoubtedly everybody
in this audience is aware you can't
actually depend on testing to catch
these things because first of all
certain anomalies are only going to
happen on certain systems you know with
depending on your cache behavior you
know on a mall on some multi processors
but I'm not on a unit processor on some
multi-core processors but not on multi
multi processors and so on and so forth
so you can't you have it's very platform
dependent some of these behaviors are
very platform dependent and furthermore
you can run it you can run a test and
then repeat a test at repeat the test
and get a completely different behavior
you can run a test once get repeat it
and then you
it because thread interleaving is
non-deterministic it's hard to recapture
what you've done so let's see in this
talk I like I said I'm going to talk
about the basics the building blocks of
synchronization what it means to
synchronize in Java I'm going to talk
about both language primitives and
synchronized blocks volatile fields
final fields and util dot can give Java
dot util twice a util duckin current it
means Java dot util dot concurrent I
just didn't want to do all that Java dot
typing and Java dot util that concurrent
abstractions I'm going to explain what
it means for code to be correctly
synchronized what it is that you have to
do to write correctly synchronized code
in Java and I'm going to try to convince
you that if you're not using
synchronization you're doing something
wrong and not only that but if you're
you don't need not to be using
synchronization most of the time what
you're doing in the synchronization
doesn't really cost very much okay
alright so again we're going to be
talking mostly about synchronized
methods and blocks and volatile fields
and we're gonna talk about final fields
also a lot of the same principles now
come back to it apply to the jsr 166
classes jsr l'm z66 means Java dot util
dot concurrent that was the number of
the specification revision that that
that got us Java dot util dot concurrent
and we'll talk about final fields and
immutability - all right so this is this
is this is a slide I like because it's
you know it's my taxonomy slide at the
top is what you really should start out
trying to do and what the bottom at the
bottom is what you should never ever
ever do and in between they're sort of
there's sort of you know gradations of
this is more permissible so at at the
top is high-level concurrency
abstractions if something exists in Java
dot util dot concurrent use it because
Java dot util dot current is is a very
very nice library that includes a lot of
things that you definitely want to be
able to do if that fails you if you
can't find what you want to do you'll
have to program it yourself sadly and so
you're going that you're going to sort
of failover to low level locking
and you'll use synchronized blocks or
use Java dot util dot concurrent dot
locks there are different locks in Java
dot util duck and current that don't
quite mirror the behavior of the locks
that are built into Java the
synchronized locks for example there's a
reader/writer lock there are fair locks
whereas regular java locks are not fair
and so on if those fail you if you can't
stand having blocking in your code and
you you you really need the efficiency
then you can failover to low-level
synchronization primitives like volatile
variables and the atomic classes this is
sort of this is already treading into
the zone where experts kind of feel like
they they don't want to do it but they
will do it and and you know try very
very hard to get it right and it takes a
long time and a lot of thought but this
does allow for non blocking
synchronization so if you want non
blocking synchronization in your code
you're going to have to use one of these
mechanisms and then deliver it under
synchronization Dudley Dudley is
actually a really really smart guy and
wrote the Java dot util dot concurrent
classes and he has tried to reason about
what happens he's tried to write classes
and reason about what happens when you
don't synchronize your code correctly
and he gets it wrong it's a really
really hard thing to get right so so if
my this is this is this is proof by
intimidation if he can't get it right
then you can't get it right and I can't
get it right
so just avoid it and don't do it yeah
all right so that was the fun that
that's that that was the scope that's
where we're gonna go in this talk and
let's talk a little bit about the
fundamentals so what do we think of when
we think of synchronization well usually
when somebody thinks of a mutual
exclusion lock like we have in Java you
think of well you know I try to enter
the mutual exclusion lock and anybody
who tries to acquire the same lock is
going to block until I release that lock
and that's very important that's a very
important property of a mutual exclusion
lock in Java or in C++ or in any other
language but it turns out that's not the
only property of a mutual exclusion lock
there's also this property called
visibility which ties into a property
called ordering we'll talk about it so
it it turns out that when I use
a lock it determines when another thread
sees the updates that I've performed in
my in my in my in my thread so if I
write to a variable in one thread
whether or not that write gets seen by
any other thread it is very heavily
dependent on the kind of locking I used
and if you don't use the right kind of
synchronization the right kind of
locking then your compiler and your
processor and all and the whole
underlying system are allowed to
conspire to destroy this and break your
code if you wrote it in such a way that
expects this it expects this sort of
these sort of strong bill its visibility
process properties so I'm gonna need
something that I'm going to come back to
again and again I've already come back
to it twice I think here's a third time
people worry a lot about the cost of
synchronization but the cost of getting
something wrong and having it be in
production is a pretty high one also and
so a lot of people will try to to devise
some sort of weird scheme to communicate
between threads without using explicit
synchronization this doesn't work don't
you can't you can't get away with not
using a lock or a volatile or another
concurrency abstraction I know I'm
beating on this kind of hard I already
said that Doug can't do it all right so
let's see all right
so here's here's my basic example of why
this is a hard thing to do
here's an example it's got two threads
thread 1 and thread 2 and it's got two
variables x and y and x and y are both
initialized to be 0 at the beginning of
the program at some time and then thread
1 writes to the variable X and then
reads the variable Y and then thread 2
writes the variable Y and reads the
variable X and the question is can this
program result in I being assigned the
value 0 and J being assigned the value 0
and well you think about it for a little
while and you think well let's see if I
is assigned the value 0 that means that
that read of X somehow came before the
right text so there is you know some
sort of thing that orders the read of X
before the right tax okay and if J is
assigned the value 0 well that means
that there's
some sort of ordering in the program
that that means that that that this was
assigned the value this was assigned the
value zero before y was assigned the
value 1 so there's there's this there's
this there's some sort of ordering that
reflects that and so now we have a
situation where the right to Y occurs
before the read of X occurs before the
right to what X occurs before the read
of Y occurs before the right to Y occurs
before the read of X and for which what
I could go around like this for a while
but I think I don't have that much time
so it sounds like this should be
something impossible now I was thinking
about at this point asking people if
this were possible I'm sure there's a
large segment of this audience that
knows that this is possible but the fact
is it's a little disingenuous because I
wouldn't have put it up on the slide if
it weren't possible you know I wouldn't
have bothered to put it up there so of
course yes this is totally possible the
fact of the matter is that compilers and
processors and VMs and all sorts of
things can actually switch the change
the order of independent accesses in
your program a compiler can look at
thread 2 and decide or a processor can
look at thread 2 and decide that those
two actions would be more efficient if
they were performed in the opposite
order so it can just switch the order
around and what happens in that case
well maybe the read of X will happen
before it will occur before the write to
X and then the write to X will occur
before the read of Y and then the read
of Y will occur before the right to Y
and you get that kind of loopy queer
result ok so again how can this happen
well there's a whole bunch of ways in
this in which this can happen the
compiler can just decide to do it can it
can decide well on my processor that I'm
compiling code for it's just more
efficient to switch them around the
processor itself can reorder them
processors do out-of-order execution on
a multiprocessor you might have the
values not be synchronized to global
memory so imagine if for example x and y
we're both store those two threads were
executing on separate processors on one
processor X Redis tail value excuse me
the processor ready to stay all value
for X which was 0 and another processor
had to stay off for value for Y which
was also 0 so on a multiprocessor these
these value might not have been
pushed out to main memory yet the main
the memory model the Java memory model
is allowed is designed to allow you to
do all of these things allowed the
processor and the compiler and so on to
do all of these things and we tried to
give it wiggle room so that there are
even optimizations that nobody is
actually performing that we said oh no
we have to allow this it's great for
your performance you know this sort of
stuff
gives you this you know these first few
bullet points they give you you know
orders of magnitude speed-up in your
code so they're absolutely necessary but
unfortunately for a lot of people it's
bad for their intuition about what's
actually going on in their code let's
see so I put in a slide yeah okay so I
should point out that this is obviously
incorrectly synchronized code because
you're not actually locking but I think
probably most of the people in this
audience are familiar with threads and
locks on some level and know that if
you're actually accessing the same data
you need to use a lock all right so this
is the slide in my talk where I when I
give this talk I always say it's the
most important slide one time to really
underscore that I took the microphone
put it right up to my mouth and said
this is the most important slide and a
talk unfortunately the videographer
yelled at me so I'm not gonna do that
today but this is in fact the most
important slide of the talk this is that
this is the takeaway slide if you like
and don't worry everything isn't up on
it yet there are two threads in this
example one thread is doing a bunch of
writes another thread is trying to read
the writes the first thread performed
the first thread is writing to a field
called X writing the value one to a
field called X 10 acquiring a lock
called M and then writing a reference to
that object that contains the field X
out to somewhere in global memory and
then unlocking M at some time later for
some definition of at some time later
along comes thread two thread two
acquires the lock on em tries to read
the reference to the global variable and
then tries to read the the the field of
the global variables that thread one
earlier wrote the takeaway message is
that
that everything that occurs before and
unlock all of the rights that are going
to occur here
are going to be ordered before and
visible to everything that happens after
excuse me it happens after a subsequent
lock on the same object so what does
that mean that means when this in the
second thread all of the reads this
second thread performs this read of glow
and this this read of X are going to be
ordered after all of the rights that
this first thread perform so that all
the updates performed by this first that
are going to be seen by this second
thread and that's because this unlock
and this subsequent lock on the same
object create a sort of pair of
something that we call a release and the
subsequent acquire and you can sort of
think of this as being the release
pushes out the the updates that this
thread made along this edge at wit and
the subsequent acquire sort of looked at
this edge and grabs the updates that
were performed by thread one and so it
will know that the that the the the
values that were written in thread one
can now be seen so is it the law oh no
it dawn now okay all right so yes
powers
so the question is is this is it's
actually up
something going on
this thing on yes this works okay so the
question was sorry no no the
videographer still has his earphones on
and that's why it's really a bad thing
because they they all of a sudden get
this really loud noise in their ear all
right so the question was has anybody
implemented a vm that sort of fulfills
the minimum properties such that so that
you can really guarantee that your code
is doing the right thing there are other
factors at work here one of the factors
is that you know you have to sort of say
that this thread too is going to come
along at some time later right and so
you you do end up with this sort of
notion of you know you can have
different interleavings among your among
the actions in your program and that can
be that can be a real problem when
trying to implement a JVM that does the
minimum because you're not going to
capture all of the behaviors of your
program because of the different kinds
of interleavings you can have basically
multi-threaded programs are
non-deterministic you can have non data
related race conditions and so so there
isn't a VM that will that will execute
that will give you all of the possible
executions of your program to so that
you can so that you can ensure that it's
correct there are simulators available
that will that will sort of take small
snippets of your program try out every
single permutation and and come back
with a come back with a set of available
results but for a whole program it's
it's it's it's it's not it's it's not
something that's been implemented see
all right moving on yes okay moving on
all right
so I mentioned the notion of release and
acquire and a smart audience which is
nice all memory accesses before our
release are ordered before and visible
to any memory accesses after a matching
acquire so this is going back
you know I mentioned this terminology
before I'm gonna come be coming back to
it again and again there's a release
when you perform this unlock and there's
a subsequent acquire when you perform a
later lock on the same object okay right
and I'm gonna be coming back to release
in the choir as terminology again and
again so it's a good thing to keep in
your mind this establishes a release in
the subsequent acquire establishes
something called that happens before
relationship and in addition execution
order within a thread also establishes
that happens before relationship so I'm
going to use the words happens before
again and again and actually it's
something for you to get used to even if
you're not a Java programmer because C++
is also adopting this terminology for
their threading model what it basically
means is that you know that instruction
happens before the second the first
instruction thread one happens before
the second instruction thread one
happens before the third instruction and
thread one happens before the fourth
instruction and thread one which happens
before this subsequent lock on the same
monitor which happens before these are
all these instructions and happens
before is transitive so you can talk
about say the first instruction the
first action by thread one being
happening before the the last
instruction and thread two the opposite
of happens before is happens after right
sometimes I say happens after and assume
that people know what I mean but they
don't always yes
yeah it's actually yeah it's an its
inferred it's referring to not lines of
code it's referring to actions in flight
if you will so what the VM is actually
doing and in some times sometimes I'll
say statement instead of action which is
really a bad thing to do it's not the
static program statement that has that
happens before it is the dynamic you
know I just executed an instruction in
the VM and that's what that's what has
that happens before other yeah I mean
you could you could also imagine this as
what is being executed by a VM so yes oh
okay keep it in mind for later sorry
yeah the question was do I assume that
thread 2 is starting later than thread 1
yes I I sort of referred to that I
alluded to that when I talked about this
earlier I said that at some point later
for some ill-defined notion of at some
point later which I don't want to get
into thread 2 comes along and performs a
lot yes at some point thread 2 is going
to start and it is in some sense
happening later than then this and this
then thread 1 ends so yeah that
assumption is built into this slide all
right and I'll try to repeat the
questions from now on I apologize for
that one I missed okay so a data race so
if there are two accesses to a memory
location and at least one of them is a
right and I meant to take out that thing
about volatile so don't don't don't
don't pay attention to that thing about
volatile then the accesses must be
ordered by happens before otherwise
you're in something called a data race
and if you recall the first example I
showed you with X&amp;amp;Y being read and
written in the opposite threads that was
a data race because there was no
synchronization between the two threads
there was no there was no ordering
between the two threads establishing it
happens before order among X or among Y
if you violate this property if if you
have data races in your program it's
really really hard to figure out what
your program is going to do because the
compiler and the processor and all these
things in addition to not having you
locking in all of these those good
things the compiler in the processor
going to conspire to violate what you
think it might happen it's not as
unspecified as a buffer overflow and see
we were very careful about that when
designing the memory model but it's
still kind of hard to figure out what's
going on yes Alex
okay so the question was can compilers
catch violations of this yes there are
various tools excuse me there are
various tools that will allow you to
check for data races in your program I
don't know which ones are and why use
here but I know there is a definitely a
program called J probe which will do it
for Java programs you know and it's it's
definitely an area of ongoing research
and I think that that your we're gonna
see more of it as these issues become
more and more important but it's
definitely something that people try to
do their various different kinds of
methodologies for doing it and we can
talk about some of those methodologies
later but we're not gonna have time in
the talk so a lot of people will think
about these things not in terms of
happens but before but in terms of
memory consistency operations so I
decided to put together a slide that
talks about them in terms of memory
consistency operations it talks about
what actually happens when you when you
go on to a machine so you have these you
have these this program and it you
encountered the synchronized block and
it will block until you obtain a lock
and then it will reconcile what's going
on in memory with with what's going on
in your cache and then it will at the
end of the synchronized block it will
push the values you have in your cache
out to memory and then it will release
the lock and that's actually what
happens maybe that's not actually what
happens maybe I was just a little bit
disingenuous there it turns out that
this is not what happens especially in
Java
a lot of people going into C+ coming
from C++ are going to expect those sorts
of coherency behaviors those sorts of
memory actions when they do when they
use Java locks and you're not guaranteed
to get them so for example in in Java
locks you are allowed to take accesses
that are outside your lock region and
move them inside your lock region so you
can take this last you can take that
first line that that read of ODOT field
and you can push it down inside the
synchronized block that's called lock
coarsening
now you can move obviously you can move
you can move actresses it's in but you
can't move them out so we actually call
that roach motel ordering because access
has come in but they don't go out that's
a television commercial from the 80s
which probably almost nobody in this
Capades remembers the other thing to
remember is that a release only matters
to a matching acquire I mentioned before
a unlock followed by a subsequent lock
on the same variable but the fact is in
some cases there may not be subsequent
locks on the same variable and your
compiler might be able to detect that so
for example in Java a lot of times what
will happen is that you have a lock on a
thread-local object and a lock on a
thread-local object doesn't do anything
because there's no later on there's no
matching acquire there's no matching
acquire in a separate thread because
you're only locking it or unlocking it
in one thread so they're compiler
optimizations built into this in in in
Java SDK 6 also reentrant locks don't
have any defined semantics so if you if
you acquire a lock and then acquire the
same lock that second acquire doesn't do
anything isn't isn't guaranteed to do
anything so you can see a lot of cases
where you can put these lock and unlock
operations in and the compiler isn't
actually required to do those sort of
reconciling out to main memory bringing
stuff back in from cache type behaviors
alright so don't rely on locks flushing
stuff basically is the if the moral of
those two slides all right so those were
the fundamentals I've talked about the
habits before ordering and why you is
that's really important that you use
that as your mental model somebody by
the way is going to come in and talk
about next week why he doesn't want you
to use that as your as your model but I
disagree with him needless to say I'm
going to talk a little bit more about
some of the finer details in the memory
model now including the volatile
variable so ok so I mentioned before
this concept of data races if a field
can be accesses but accessed by multiple
threads at the same time and at least
one of those accesses is right you
should really access it within lock
regions you should really
make sure that locks protect those
accesses to those fields another another
alternative is if you don't want to use
blocking synchronization if you want to
do something that's non blocking you can
mark the field volatile and that will
give you some essential virtual machine
guarantee that will say to the VM I want
certain special guarantees here and also
it's very nice to do that in general
because it serves a documentation it
means this flag is meant to be shared
among multiple threads it can be tricky
to get volatile right but again I'm
gonna go back to what I said at the
beginning if you don't use any
synchronization then your program just
isn't gonna work
so valo ends up being an important
component of doing non blocking
synchronization in Java
what does ball will do well I'm gonna go
back to that sort of general vague
notion of at the Machine level what does
it do well reads and writes you can
think of the reason writes is going
directly to memory if that's the mental
model that you prefer again there are
caveats for things like thread-local
volatile x' but but if you prefer that
sort of mental image that's what it does
involve the Long's and doubles are
atomic one of the properties of regular
64-bit integers and doubles at in Java
is that they actually are allowed Java
virtual machines are allowed to write 32
bits at a time so you can write through
the first 32 bits out and then another
thread can come along and see the first
30 the the new first 32 bits but the old
second 32 bits so it can look like some
garbage value came in there I think that
was done I'm not sure how many modern
JVM still do that I think that was
actually done for where the alpha
processor way back in the day but the
guarantee is made for non for volatile
Long's and doubles that all 64 bits will
be written you're never gonna see the
first 32 bits from one and the second 32
bits for another that's that's one of
those anecdotes that I like it's not
it's not necessarily integral to what
we're talking about here but back going
back to the notion of what's going on at
the compiler and VM level vowel reads
rights are not generally going to be
reordered and reads writes become
acquire release pairs that's the that's
the most important notion to remember
here that what you end up having is that
ball
right followed by Volvo reeds are going
to be a release and I'm matching later
acquire so a vowel right happens before
all following vowel reads of the same
variable and in this way you can think
of a volatile right is sort of being
akin to a monitor exit which is just we
call an unlock in in in Java and of all
we'll read is going to be similar to
that following later lock on the same
variable so how does this how does this
come into action well hold on a second
but I Drive another drink of water here
Thanks all right so I talked a little
bit before about a situation where you
can use volatile Flags or you can use
volatile Flags to as a flag for a
termination of a threat so let's look at
this example we've got two we assume
that there are two threads one runs what
one runs the run method here and the
other eventually calls stop and what
happens in the run method is it iterates
until it continually iterates until the
stop flag is set and what happens in the
in the other thread is that eventually
it will call stop and stop will set a
stop will be set by that method and in
theory the theory is that the first
thread will come along do the next
iteration see that the second thread has
set stop and then say oh well while not
stopped it stopped now and exit it turns
out that if you don't use volatile here
a compiler can look at this first thread
at this run thread it can say hmm what's
going on here well I'm reading stop on
every iteration through that loop but
I'm not updating stop on any iteration
to that loop so the value of stop is
never going to change well if the value
of stop is never gonna change
I can test stop once at the beginning
and then otherwise just have an infinite
loop here well I bother to keep going
out and reading stop so a compiler can
actually transform this run method
without volatile a compiler can actually
transform this run method into an
infinite loop which is a really nasty
thing to have happen to you
so it's very important in cases like
this to declare your variable bottle and
your compiler will look at that
annotation say oh that's a volatile
variable I'm not allowed to perform that
kind of transformation and it will leave
this it will leave this alone it will
actually go out and read the value stop
on every iteration through this loop yes
else this one matches that one and this
one matches that one right okay yeah no
it's just because you know at some point
you run off the end of the slide yeah
sorry about that
yeah I'm sorry this is not this is not
conformed to the style guide yes
so the question was if this was not
volatile wouldn't the compiler still
know that stop could be called
compilers perform the typical compiler
transformations are performed on single
threaded code and you look at what can
happen until the next iteration of this
loop in a single threaded context so it
only looks at what goes on here and
assuming one step doesn't invoke stop
you know and it looks at what goes on
here it sees that stop is not set
anywhere in the loop
and it can then perform that
transformation based on the fact that
it's looked at just of what can happen
in this thread and this is actually a
this is actually a fairly important
thing to do because if you if you have
to do compiler optimizations based on
the notion that other threads are going
to be going in and changing your data
all the time you're not going to be able
to perform any compiler optimizations
because a lot of them have to do with
you know assuming that the same value is
used for a variable over and over and
over again or that a variables value
doesn't change so use volatile here it's
it's it's an important thing to do if if
something can come in and update and be
updated by on multiple threads yes
Oh off the top of my head I don't know
if anybody if any of them do but it's
not an unreasonable thing to expect I
mean it's a it it it's one of those
things that some compilers have said
don't do this explicitly but it would be
very easy to take out the block that
says don't do this explicitly so it's
it's it's it's something that I could
very easily see it's doing basically
if Matt front says it's happened his own
code so so yes is the answer but it was
a long time ago and undoubtedly
compilers don't do anything like that
now yes
would be is it important to have English
stop the bleeding of the storm inside of
us right
no I'm gonna get to that it's not
there's no penalty to using the model in
this case well there's very little I'll
get to that that's one of these
misconceptions the other part of
volatile in addition to that sort of
ordering thing as I mentioned it has it
happens before relationship so the
question was about the performance
impact of volatile sorry about that vici
guys the question was about the
performance in get back tomorrow and
I'll get to that later so here's a very
similar situation and and the reason I
sort of spent along is because we're
only got 20 minutes left I want to get
it all in so we've got we've got two
threads again one of them is going to
set the value of data and then when data
has been set it's going to it's going to
set a boolean flag saying we've set data
and another thread is going to check
that boolean flag and if that boolean
flag is going is been said it's going to
say oh well we've constructed data so so
so return it and if if we haven't
constructed data then it's going to
return null so if we don't use volatile
here what can happen is in the second
thread the compiler or the processor or
the VM could just reorder the data
equals Oh with the ready equals true so
what would happen was it would set ready
to true and then maybe the other thread
could come along it would set ready to
true first then another thread would
come along perform get check ready it
would be true but we haven't in this
first thread we haven't said data yet
and it would return data which is some
garbage value some old value maybe no
well so this it can't do it because this
is a volatile variable oh oh oh no no so
so so volatile also so volatile I don't
know if I mentioned this clearly
volatile also implies that happens
before relationships see there's a
little arrow in there now so all of the
accesses that happen before you can
imagine that slide I had with the cones
before which is why that was such an
important slide all of the rights that
happen before this right to ready are
going to be ordered before and visible
to all of the reads that happen after
this read of ready in the second threat
does that answer your question
so the Frank's question was basically
why does that work well we can you know
you can look at the actual memory model
and we can well there's there's this
happens before relationship okay so we
can we can talk about it later we can
talk about it later but yeah there are
more questions about why this works and
obviously this is something that a lot
of people have a lot of questions about
here's some more simple notes on bottle
incrementing of Olives non-atomic
if you have a volatile into V V plus
plus means V equals V plus 1 which means
that you read V first and then you
increment the value you read and then
you write it and if between that reading
the right somebody else wrote to that
volatile variable you're not gonna get
evolved you're not gonna get an atomic
increment so that that's something that
a lot of people sort of think have to
think twice about volatile reads are
very cheap this is a question that we
just have about the performance of
volatile sometimes it's only the
compiler optimization cost specifically
on an x86 there is no cost to reading
the volatile variable there's a cost of
writing to a volatile variable but
there's no cost to reading it you don't
have to perform any additional memory
barriers because the coherence
guarantees of the x86 provide this for
you and so you do have to sort of
prevent yourself from doing compiler
optimizations around volatile variables
but you don't actually have to do
anything addition bill in terms of
coherence operations as of 2007
there are no way there's no way to make
the elements of an array individually be
volatile
if you save all int array that means
that the reference to the array is
volatile not the elements of the array
itself so if you save these array sub
one that's not going to be a vowel
that's if you read array sub if you
write to erase of one that's not going
to be a volatile right if you want any
of these properties can consider using
the Java dot util that concurrent atomic
package which has things like in atomic
increment and compare and set and atomic
integer array atomic byte array blah
blah blah so that so that you can
actually get those sorts of semantics
and they have the similar they have
their otherwise they have very similar
semantics to Atomics have very similar
semantics duvall evel's in terms of
happens before relationships so there's
some other happens before orderings like
if you start a thread everything that
happened before you started that thread
is going to happen before the actual
start of that thread and and the same
thing is true of joins but only in the
opposite direction and there are lots of
things in Java dot util dot concurrent
that that the setup happens before all
rings like if you put something into a
queue and then later take it out of the
head then that sets up a happens to be
for ordering and so on and so forth it's
pretty well-documented so if you have
more questions you can ask me later all
right so I want to get on to thread safe
lazy initialization and we have 15
minutes and we're not gonna have time
for any questions all right but don't
worry there'll be plenty of time to ask
questions any opportunity excuse me so
the principle behind thread safe lazy
initialization is that you want to
perform lazy initial initial ization of
something but you don't want to perform
it right when of a singleton of
something that you only want one copy of
and you don't want to perform it right
when the JVM starts and you don't want
to incur the synchronization penalty of
locking every time that you want to
access that data so a very common a very
common way to do it until recently has
been this which is called the double
checked idiom or the multi-threaded
singleton idiom some people call it and
what that does is you invoke a method
called get helper it checks to see if
helper is the pointer to this object
that you want to initialize it checks to
see if helper has been initialized if it
can't see that helper has been
initialized it acquires a lock checks to
make sure that you haven't initialized
it between when you last checked if
helper was initialized and now and then
if that is if you haven't if you haven't
initialized it then you initialize it
and and you finally return it now the
problem with this code is that there are
no that that you have the locking on the
writer side you have the locking on the
side that does the that does the
construction of helper but you have no
matching acquire on the side that's
going to be reading helper you don't set
up a happens before relationship you you
do this synchronized block only when you
read helper is equal to no well another
thread might come along accidentally
read helper is equal to no but not see
all of the other updates performed by
this thread and then it will see helper
is not equal to no and it will it will
return a junk value for helper so it's
actually really important to get that
happens before relationship working here
and the way to get that happens before
relationship working here is really
really simple you can just add the
volatile modifier here and I don't think
I have time to go into this and that
much detail but that's the basic
principle behind that for an even better
solution I hope I have an even better
solution here yes so lots of people have
tried to tell me that this works without
synchronization it doesn't work without
synchronization don't tell me it doesn't
work without synchronization I don't
want to hear it a much better solution
is actually to use to use lazy static
initialization lazy class loading too to
initialize your singleton value so
there's something in the book called
effective Java it's a very very
effective book it's an excellent book
it's by Josh Bloch who works here at
Google and it's called the
initialization on-demand holder idiom
and
what I time do I have so I probably have
enough time just to give you a quick
overview it basically relies on the fact
that that static initialization is not
performed until the first time you
access the class to initialize your data
lazily
and it relies on the guarantees that set
that are made about static
initialization and synchronization to
ensure that all the synchronization that
you perform is is correctly is correctly
in place and I had a much longer spiel
about that but I don't have time for it
all right so I do want to go over final
fields final fields are a really
wonderful thing use a mutable object
whenever you can in Java you know I'm
not gonna make claims about any other
programming language there's actually I
think there's a whole chapter on this in
affecting the affect of Java book I just
mentioned there's a there's there's a
lot on why you should use final fields
I'm going to restrict myself to I mean
you can maintain invariants without
having to worry about they might the
fact they might change them I'm gonna
try to restrict myself to the
synchronization benefits if you make all
of your fields final and you don't allow
other threads to see the object that
you're constructing until the
construction is complete so for example
you don't you know have a line in the
constructor that says some global
reference equals this then the spec the
the Java memory model actually promises
that that object is going to appear to
be correctly constructed and immutable
to all the other threads in your program
even if some malicious code tries to
attack you with a data race well what do
I mean by some malicious code tries to
attack you with a data race well they
try it means that some some piece of
malicious code is going to try to
leverage the fact that there's no
visibility to C and out-of-date value
for one of the fields and you know this
doesn't happen a lot but it only needs
to happen one in a million times it's
easy to to try to do this a million
times and and and have the visibility
kick you in the rear there's an example
of this that was actually found in a
real honest-to-goodness live JVM that
doesn't that nobody here is using don't
worry and the way it works is basically
a string constructor that that created a
substring of slash temp slash user and
substring come up the substring of four
comma eight basically means you take the
offset of of four until eight so it's
supposed to be that first thing slash
temp slash user is supposed to be slash
user that's what the string is supposed
to be
it's from from indices four to eight and
the way it did this was by saying you
have a string you have an offset into
that string which would have been four
in this case and you have a length which
is also four and the attack here was a
was a visibility thing where it it
passed it created this string a bunch of
times and passed it to another thread
until the other thread saw an offset of
zero instead of seeing an offset of four
and so what is this thread slash temp
slash user with an offset of zero
instead of an offset of four and a
length of four well instead of being
slash user the last four its slash temp
the first four so you were able to see a
directory actually change and if you're
dealing with security permissions on a
directory and you've got these sort of
data raise problems then that's a really
ugly thing to see
now you've nowadays you don't have to do
that anymore this was in a pre job at
one point five VM nowadays all the
strings all of the all of the fields of
string are our final and and you're
guaranteed for this not to happen which
is a nice thing there are ways to change
final fields I don't have to time to go
into them try not to change final fields
if you can manage it because it turns
out that modern VMs are allowed to do
very are allowed to do even more
aggressive comp transformations based on
final fields try to restrict it to just
when you're doing the serialization or
clone or something like that and just
with blank objects and I can talk more
about that offline yeah so all right so
some basic recommendations and they'll
get into questions I don't think that
any of these recommendations is too
confusing
if you can solve your problems using the
java.util got concurrent classes please
do so not only are they you know really
well-written and safe they're also
really fast because there's a lot of
stuff like non-blocking algorithms in
there that are really tricky to get
right when you try them yourself
and and really it's it's just it's just
it's a very nice package and if you can
manage it you should if you have to go
beyond that and even if you don't have
to go beyond that understanding the
memory model can really give you a sense
of how you can go about devising your
own concurrency abstractions you know
sometimes you're just gonna have
something that doesn't fit into Java dot
util a concurrent and you're not gonna
want to shoehorn it into Java LTL duck
concurrent you're gonna want to create
your own concern concurrency abstraction
so you should really take advantage of
that mostly the the memory model just
works if you lock correctly if you don't
share variables between threads without
synchronization which all of you should
be doing then really nothing has changed
here you don't even basically have to
think about happens before because you
just get get the right properties with
locking knowing the details though can
also reassure those who obsess over
details like myself and clarify the fine
line between clever and stupid which
basically means that you know that
double check locking algorithm well
somebody thought that was really clever
but it wasn't really clever it was
actually a little bit stupid because
they were being clever but not clever
enough watch out for useless
synchronization this is one of those
little performance tips if you use a
concurrent a class that was designed for
concurrent use in a single threaded
context you can generate measurable
overhead I said that Java tries to
remove unnecessary locking but doesn't
always succeed so you can in fact
generate measurable overhead if you use
things like vector or hash table or
synchronized map when you're not
supposed to be using a synchronized map
substitute unsynchronized classes when
you're only using them in a single
threaded class concept I don't think
anybody actually still uses the vector
class anymore but if you do and you're
only using it in one thread use an
ArrayList another thing is in Java dot
IO there are some methods which every
time you write them by
they acquire and release a lock so if
you want to release increment if you
want to reducing crona's ation overhead
you know you often have to use bulk i/o
or to use Java the java dot n io classes
which are much more efficient to doing a
lot of things you should all learn them
so that you can use them anyway
sometimes synchronization alone isn't
enough in a class I can't tell you how
many times I've seen this there was a
somebody found this in the actual JDK in
the api's a couple of years ago it's
there is a concurrent hash map class and
John without you two looking current and
you know when you call get that is
thread safe and when you call put that
is thread safe but if you call get and
then call put and in the meantime you
you make the assumption that nobody else
has has put about a class put that value
into that thread so then something
terrible is going to happen so in this
case you know you could call H get some
other not find the name you're looking
for some other thread could then call
could then put that name you're looking
for into the into the hash map and then
you could call H dot put and it you're
now replacing something which is not a
good thing to be doing so this is what's
called an atom isset e violation and
it's important to keep an eye out in
your code concurrent hash map
specifically has something called put if
absent but i can't tell you how many
times people have said people have said
oh well don't worry concurrent hash map
is thread safe I don't have to think
about these issues again current match
map has a yeah ok so I said these things
because I'm running out of time here
documenting concurrency right so it's
important to write good comments there
are a lot of times that comments are not
really particularly well written again
like isn't iostream thread safe well
what does it mean for an iOS stream to
be thread safe does it mean that two
different threads can both write to the
iOS stream and it's somehow safe for
them to do so l1 thread one writes one
byte and then another thread writes the
next byte and then the first thread
right so you get this sort of garbage
list of randomly associated bytes well
is that thread safe what does that mean
to be thread safe
so again it's not as simple as this
classes fridge safe as I said in the
previous example where you had this
concurrent hash map I'm sorry to be
rushing through all this I know it's
kind of up to velocity a lot look at the
detail a concurrent documentation the
util a concurrent documentation is
actually really nice there are there are
annotations described in the book called
Java concurrency in practice I recommend
this book I'm gonna give you in a slider
to information on how to get it these
are neat neat little annotations like
thread safe means this is thread safe
for your definition of thread safe this
means you know it's not thread safe this
means guarded by it means you know I I'm
saying that this field is supposed to be
guarded by a specific lock this means
immutable you know this class is
supposed to be immutable some of which
are checked by the find bugs utility
that's available from Bill P at the
University of Maryland who is actually
also my adviser so my graduate advisor
part of me okay so yes use the right
tool chain this is also important JDK 6
includes a lot of performance
improvements over JDK 5 linux 2.6 i
think everybody in this audience live
has probably heard me say that linux 2.6
is a significant step above linux 2.4 in
terms of threading performance you can
get you know depending on what your code
does you can get whole numbers multiples
to speed up on by spite by using the
right tools let's see just some general
things that i think i've already said in
terms of designing fast concurrent code
make it right for make sure it's it's
right first the way the way the way to
do it is to reduce your reliance on
synchronization without actually getting
the code wrong which is a tricky balance
to do and i think everybody will agree
that that's a tricky balance anybody
who's tried it will agree that that's a
tricky balance you know avoid sharing
mutable objects if you can again that's
the immutability thing use the Java dot
util are concurrent classes avoid lock
contention if you can if your lock is
going to be held for a really long time
try to shorten the length that your lock
is going to be held
and so on and just a couple of slides
have wrapped up cost of synchronization
operations can be significant but
usually just what you need to get it
right is not really all that significant
again something like the ball will field
where the reading is free you know
thread interaction needs so this is this
is the tricky balance you know that
interaction needs careful thought you
need to make sure that that your threads
are interacting correctly but you don't
want to be too clever about it because
then you're gonna kick yourself in the
rear and you definitely don't want to
have to think about these sort of
reordering guarantees that I've been
talking about these reordering problems
excuse me that I've been talking about
the whole time so try to avoid data
races because if you don't have data
races you don't have to think too hard
about it yes you need it happens before
edge to communicate between threads I've
said that you know 30 times so that's
what this slide says that's part of the
wrap up and here are some places to go
for more information this is a really
good book on the subject by Brian gets
and at Al and some of the members of al
work at Google so I you know it's I
shouldn't you know to be too denigrated
for out but the first side the first
place is a is a is a page which gives a
lot of pointers to memory model
information for those of you who want to
get really into the details
there's the concurrency interest mailing
list which Doug Lee runs out of Oswego
and it's for not only for questions
about memory model but it's also for
questions about about Java dot util dot
concurrent it's a really useful mailing
list and because I knew I would be
running out of time now I'm going to
actually try to answer questions about
this I started a blog just for the
purposes of answering questions about
this about this talk more or less so if
you have questions post them as a
follow-up to this to this blog posting
and I will I will answer them offline
and now I think we are out of time but
I'm not sure I'll hang around for a
while and try to answer questions I want
to see if I if I can't hang around and
answer questions live
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>