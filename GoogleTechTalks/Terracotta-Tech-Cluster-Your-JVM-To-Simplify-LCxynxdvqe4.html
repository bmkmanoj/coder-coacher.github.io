<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Terracotta Tech - Cluster Your JVM To Simplify... | Coder Coacher - Coaching Coders</title><meta content="Terracotta Tech - Cluster Your JVM To Simplify... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Terracotta Tech - Cluster Your JVM To Simplify...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LCxynxdvqe4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks Jeff so first
I wanted to thank Google for this
opportunity to talk to you guys get the
word out there I've been squeaky chair
huh I've been spending a lot of time out
on the road lately talking to Java user
groups and we've had a reasonable
response people are pretty interested in
what we have to say and do it's a kind
of a paradigm shift that we need to get
the message out there and so I'm just
going to treat this like a big group of
developers as opposed to trying to talk
to Google or something like that if you
have questions along the way just give
me raise your hand I'll try to speak up
because we are being taped today but I
will repeat your question so that's on a
mic somewhere and feel free to interrupt
as I go so basically what are we going
to talk about today right well
terracotta some of you may have heard
show of hands has anyone heard of
terracotta before about half the room
that's cool so basically what we talked
about drop in clustering right we talk
about codeless clustering and all of
that is like pie in the sky and we're
going to get into the nuts and bolts
today as to what exactly this technology
is capable of how to use it how not to
use it and we're going to see some demo
source code etc so it's a technical
discussion by the end of the talk we
have about 50 minutes left hopefully you
guys will have a clear understanding of
what i mean by transparent clustering or
runtime clustering i'll call it heap
level replication i'll call it jvm level
clustering but what's the difference
between that and AP is that you might
use to send messages across cluster of
servers and we'll talk about how that
makes development easier so with that
I'd like to start with the demo because
I watched yonas who yonas poner who
created aspect works actually works for
terra cotta and the first time he
presented terracotta in a public forum
he demoed it
before he said anything and that seemed
to work well so basically consider I'm
not going to go through much about what
you're seeing here but this window is
the clustering hub it's basically the
guy who's doing all the communication
back and forth and making sure all the
VMS have consistent view of the world
and that the stuff that they're changing
is available to other VMS and if I the
window at the bottom is another server
this is actually your application server
and this would be another a second
application server so terracotta server
up in this window and two machines
talking to it and if you just bear with
me while I start up the demo sorry
so basically what we're looking at is a
drawing tool one is started now there's
a second one and what happens if i draw
on one we're talking about clustering
right so as I draw on one it shows up in
both and I can click on things that were
created in one machine and move on etc
so we're not going to look at the source
code to this yet we but what you're
seeing is two machines talking this is a
swing application it's not a custom
built or hacked up thing so we're
actually clustering the internals of the
swing library inside the JDK / JRE and
so that canvas is just a an object that
we're sharing and everything that shows
up on it is shared with that I'd like to
take an aside at this point and say that
typically people listening to the
Terracotta spiel if you will you know
listen to it especially as a developer
and I come from a developer background
and I see people in the room that I've
actually worked with before and I'm a
hardcore coder and i don't like
listening to vendors who are trying to
get money out of me so I like to make
the point that terracotta as of this
December you guys will see a press
release that explains it all but
basically terracotta is completely free
all the way through into production you
only pay us for support if you want
professional level support from us as a
company so the technology is free why
are we doing it because it's all about
the developer it's all about giving you
the tools to build applications the way
you want to build them but without
actually hindering you with trying to
find manager approval budgetary approval
processes etc so you can cut a p.o
before you engage with someone and so
what you just saw will now get into what
what has been happening underneath the
scenes
so basically we're going to cover on the
agenda I keep meaning to fix this i call
it run time versus the load balancer
that's not what i mean at all what I
mean is basically the load balancer is a
proxy for me for the notion of locality
of references where objects can move
around a cluster of servers and they
move based on what that servers being
asked to do and the load balancer
basically means that we have an
operational mechanism for scaling out an
application so we have the notion of
scale out versus scale up meaning a
bunch of small machines like a Google
Network versus a big monolithic Sun box
for example from the late 90s the way
sites used to get built like a 6500 or
Annie 15k or 25k today so we're talking
about scaled out and when we talk about
load balancing we're talking about a
proxy for the notion of a bunch of
machines trying to work together on a
business problem and run time versus
scale out we're going to get into how
the two conflict with each other I want
to do as much as i can at runtime and
what's the challenges there then we're
going to talk about api's and why
they're bad little throw throw back to
south park there I don't want to come
off as a sales guy so when I say bad i
don't mean api's or horrible never use
them their products out there that are
older than terracotta that have been
working for folks you can use them I'm
not saying you're dumb if you do but in
simple terms api's will eventually lose
to what we're talking about which is
runtime clustering will explain how it
works will look at our architecture and
then we'll look at source code for a non
will spend a lot of time with QT like
swing demos and then I'll get to a non
cutesy demo at the end and we'll dive
into the domain model and the source and
everything so in short the Java spec is
very good right this is why we want a
cluster at runtime because we want to
adhere to this what do I mean by the
Java spec I mean things like object
identity where if I do map.put foo and
then map get food comma bar and I
then I do map get food then bar equals
equals bar right so equality works
object identity works i'm a old-school
programmer myself so I like to think of
object identity in terms of see
applications where I'm thinking about
heap and pointers into the heap and if I
knew up an object then in the heap
underneath the JVM it's a memory address
0 X 1 2 3 4 and it stays there right I
mean logically physically the vm might
repack memory as part of a garbage
collector sweet but logically I don't
have to worry about that object moving
around unless I start thinking about
things like weak references or stuff
like that so object identity is very
important it's very powerful what else
is why is it powerful well it comes to
the notion of sync of serialization
versus my domain model I want to
basically create natural business models
for example people right Adam is the
father of all people Cain and Abel have
one father it's Adam so they are
siblings that's how I think of the
problem if I'm in an object-oriented
programming environment I need to make
sure that all the underpinnings of that
programming environment are adhered to
extending that from the simple case of
equality to coordination right now I'm
not talking about objects and heap and
memory addresses now I'm talking about
wait and notify I spin up two threads
this guy waits for that guy I want the
two threads to be able to wait and
notify each other across machines if I
feel like doing so because the the
notion of scale out is really a
deployment artifact it's really a
decision I make as part of my architect
my systems architecture as opposed to my
software architecture and what we're
trying to do is d couple those we'll get
into more detail on this but these
natural rules of Java should not be
broken so if I'm clustering by
serialization I'm breaking these rules
right because if i have an object graph
where Cain and Abel point back to a
parent which is Adam and then I see
realize that off see you realize Cain
and serialized able to
separately I'll show this to you
graphically but basically I end up with
two copies of Adam because each one of
Cain and Abel deserialized their own
notion of their parent and now Adam is
not the same atom in vm to where he was
one atom in vm one which means now i
have to go do stuff as a developer
that's no longer Java it's clustering so
scale-out is the is the challenge
basically replication infrastructure
isn't up to the task if you want to
scale out today what does everyone tell
you to do they tell you to build a
stateless application right well maybe
not at Google but at the rest of the
world on tape they tell you to build a
stateless application throw everything
in the database is a very hibernate
centric message for example I don't
think Gavin King goes out and says
everybody put everything in the database
in o.r map it but I do think that people
take the tool and hammer everything's a
nail they start our mapping stuff right
the other tool that I've seen used a lot
is messaging let me send a JMS message
around the cluster and keep data in sync
on multiple machines by serializing it
and copying it to all my peers and this
is sort of a poor man's grid if you will
and so these kinds of infrastructures
messaging mq series was not built to
move megabytes of object graphs or to
move them very rapidly in succession
across nodes it wasn't built for the
kinds of transaction ality that the
memory model demands and secondly
serialization is just not fun so if
you're working in a scaled out world
you're serializing your objects all the
time which means you're changing your
application so that you can deal with
the impact of the violation of object
identity so if i do serialized foo and
put it put that ask for a copy of foo i
would write a different application if
i'm saying to my data structures like
give me a copy of the thing i put in 10
minutes ago I'd write a different app
than if I was saying give me a handle
back to the thing I put in it sort of
passed by reference versus past five
I don't want the values of things I want
the reference to the thing I created
before right otherwise Java changes and
replication is achieved through
serialization and serialization deals
with copies that's the depth of the
definition of serialization and we'll
get into how that's not fun and the the
most important lesson learned i found it
at running a big production site like
google does is tuning is sort of
never-ending you know I was taking
getting ready for this talk just ten
minutes ago and I was walking by an area
of the developer spend time in and there
was a thing posted up on the wall
talking about unit testing and code
coverage versus debugging and finding
errors at runtime so dev time workload
versus runtime workload and those kinds
of things are nice they're extremely
valuable but the end of the day you're
debugging and what I found is I spent
fifty percent of my day debugging
performance type issues that it was
pretty easy to QA business logic and you
knew whether it worked from a sandbox
perspective a single machine you knew
whether it worked or not fairly quickly
mercure winrunner all kinds of
automation tools have existed for years
to try and script the testing of user
interaction systems but the back end the
race conditions of like what if i'm
updating on one node and then a load
balancer sends me to another node and
the transaction begins again in my acid
and my transactional how do I know how
do I even test how do I get two machines
to race for the exact same resource at
the exact same time generally it's not
easy and most people don't even do it
and as a result clustering is something
that just causes you know end of pain at
runtime so basically terra cotta is
founded on the assertion that you need
to cluster in the runtime not as part of
the dev time the less you embed in your
code the less you have to test the fewer
things you actually try to think of in
terms of state machines and race
conditions and locks and
things like that the more stable and
application you can build from day one
and clustering at runtime is not
unprecedented right I mean Oracle
clusters at runtime that's my favorite
example I'll focus on that we'll we'll
move on but clustering at runtime
basically means I have the ability to
write the same application whether the
operator decides to build the app for
one machine and run it on one machine
running on two or run it on 20 the
application is the same application
there's no notion of networked sequel in
Oracle right I don't write a different
stored proc if it's going to run in
oracle RAC I mean I don't know if any
such thing maybe something exists but I
know you do a lot of tuning as a DBA to
the Oracle runtime to your sand or your
storage arrays etc and some of this
applies for google type applications and
a lot of it doesn't but conceptually you
have the notion of centralized
infrastructure that is black boxed to
the application developer all over your
data center already and so I'm not here
saying load balancing is a bad thing you
know load balancing is a great thing the
observation i've made historically is
that ops needs a stateless environment
they need to know that they can just
shut down a box and another box will
pick up what it was doing they can't run
the system that has a run book that is
larger than the documentation for the
programming environment that the
developer was using to build the app in
so if your java book is this thick but
your run book for an application built
in java is that thick something's wrong
and that's what happens a lot and it
happens mostly because we build
partially stateful and partially
stateless applications where operators
don't know what they can and cannot do
so the load balancers good but the
developer is being impacted by the
presence of stateless application design
so we we want a managed runtime that
relieves the developers what do I mean
by relieve the developers very simple I
want developers terracotta wants
developers to build stateful app
not stateless applications so don't
write to a database unless you're
writing business data I was on a joint
interview with Rod Johnson the spring
Fame interface 21 just last Friday and
he had the most eloquent single sentence
statement of what business data is and
that is if you need it for audit
purposes or you need it in a data
warehouse for for business analysts to
query against that's business data
everything else is transient it may live
for a day or it may live for a second
but it's transient the steps you take in
a state in a software state machine from
point A to point B like Jeff who's
sponsoring our talk here today works on
Google Checkout classic software state
machine finite state automaton it makes
total sense to have multiple states and
to make those states durable so that if
user gives a credit card they don't have
to give it again if they hop servers
right that's transient data though which
credit card out if your profile did you
pick if they add a new credit card to
their profile that's business data but
if they picked a particular credit card
for this transaction that is transient
state until the transaction is complete
and that state basically is what
challenges developers when they're
trying to cluster and so what we're
saying is take that notion of stateful
information inside the VM and make a
tool for the developer to manage that
state in a stateless world where load
can seamlessly failover between machines
the garbage collector abstract stuff
from you right I started working in Java
in 1994 I think it was one dot 0 beta or
something like that and you know I had
reasonable mastery at that point of the
notion of heap versus stack to a thread
and I could build an application that
ran much faster I could handle pointers
no problem and if I hooked and purify
you know I'd find memory leaks in a few
minutes to this day I've seen many
companies come by VC desks trying to say
I can detect memory leaks or I have a
better than
that doesn't leak or things like that
has a better garbage collection
algorithm so Java sort of theoretically
set us back at least we definitely
thought it set us back as developers in
96 97 98 people complained about the
garbage collector but today in jdk 15 or
with the advent of pause less collectors
you can write an application that's
pretty fast and why is that well the JD
the JVM has more information at runtime
than developer knows you know a
developer may say I need to be prepared
because the business says this string
could be 64 Meg's so I'm going to
allocate this string on heap in the old
c c or c++ terms I need I can't make it
a stack variable so I'm going to have
this string that is available to me that
I'm a lock and I free well it turns out
in production use it only stores 256
bytes of data which would a trivially
fit on stack which would have made it
for a faster application but you can't
tell that when you're writing the code
and so simple things that the developer
is forced to do the runtime can can make
decisions that are more intelligent
based on data-driven information and
we're going to see how clustering at
runtime is both possible and how with
data-driven information I can make
better decisions about what to cluster
when and where so the impact of
development time solutions we talked
about this already basically everything
is based on serialization does does
everyone in the room show of hands who
who disputes that with me no one
disputes that basically everything that
clusters for you today serializes data
to move it across processing context
fair statement it's a broad sweeping
statement I'm sure someone can point out
something that well the way things are
done is as you right but that does not
include systems their business you're
very correct absolutely I left that out
so the gentleman at the front of the
room pointed out that the way things
work across physical nodes is as I
described
systems based on shared memory don't
have to serialize which is completely
correct in fact IBM and son in 2000 both
tried to cluster Java in a transparent
manner how did they do it they started
on the single machine and they clustered
the vm by writing a vm that uses shared
memory heat instead of process exclusive
memory for that heap and they clustered
threads they clustered everything the
whole heap the whole vm was written
writing it stayed out to shared memory
which means you can start up multiple
copies of an application and they would
work together why would you do that well
in 2000 SMP wasn't great small boxes
weren't as fast you could get a giant
Sun machine at that point run multiple
copies of an application spread out
across that machine and get a lot of
capacity out of it the problem they
found was only certain types of apps
would run in this share everything jbm
clustering model sharing everything
didn't work basically the garbage
collector became a full blackout so if I
want to pause pause the vm while I clean
up memory in a shared vmworld everything
was pausing and that wasn't working for
them so they said okay we need to write
a custom collector then they said okay
now it's only certain types of business
domain models fit naturally in this
because if you do type for loop with
synchronization in it then you're
letting shared memory is much slower
than Ram so you can't get anywhere near
CPU clock speeds so this thing is
starting to make less and less sense and
has very finite set of use cases that it
works for and they shelved it both
companies you can google for CJ BM and
you'll get a google it's funny to say
here you can get Google you can check
with google and see I BMC JVM started in
israel in two thousand and stopped in
2001 this isn't an unprecedented
business idea it's an unprecedented
implementation of that idea and so at
the end of the day everyone is sort of
to your point sir they sort of have
given up on the notion of clustering at
this level and if instead said the
developer needs api's i say that your
comments are all correct in there
you're not restricted by the job the
world yes absolutely so the the point
the follow-on point was that I'm
speaking mostly about a Java restricted
context and that's totally true I'm not
thinking about clustering see
applications or C++ applications it
would actually be done in largely the
same way we do terracotta but it would
be done in a totally totally different
layer the reason terracotta focuses on
java's because the virtual machine is an
operating system as far as we're
concerned it manages resources it
manages scheduling IO etc and so from
that perspective you can't buy something
from VMware or download something from
zen source that can virtualize in
cluster a java application because the
JVM is just a black box process it's
basically a virtual machine just like a
VMware instance would be and so they
leave they meaning the community leaves
clustering in Java specifically to the
developer leaves it completely up to the
developer they say okay here's some
api's that wrap up and encapsulate
serialization and here's a collection
interface get input and recently they've
been talking about grids show of hands
who here has heard about the notion of a
datagrid outside the the Google context
like these vendors that sell data grid
software anyone show our fans who
refuses to show hands because they don't
feel like it today you were about to
raise your hand right okay so so vendors
sell solutions out there that they call
data grits and what is it it's the unit
of work or the master worker pattern
that you know subsystems at Google have
been highly scalable as a result of
these guys build software that they
asked people to use to build
applications in this distributed fashion
and what's the notion of a grid amount
to in their world I'm not talking about
the Google world because I don't know it
that well but in these guys world
basically what they're saying is
locality of reference is
what it's all about who accesses the
data can I avoid moving it on the
network all together and how do I do
that will i asked the developer to chop
up the data space so server one works on
data one through 1000 server two works
on 1001 through 2000 if I can ask people
and constrain their development into
this grid like model then I don't need
locking and I don't need to fault data
around and so the impacts of
serialization are lessened I'd like to
bring that up because when i talk about
api's as get and put people who live
with these technologies all day long
will say well no I have another API but
at the end of the day when these guys
move data these guys meaning ap is when
api-based solutions move data across
machines across processing context they
serialized those objects to get them
from one vm to another vm which means
you as a developer have to deal with the
impacts you have to deal with the fact
that object identity is no longer
preserved that memory address 0 X 1 2 3
4 is indeed your instance of foo but so
is memory address 0 X 2 3 4 5 and you
have two copies of foo and what are you
supposed to do with them and you have
two copies because you invoked map get
twice makes sense people are nodding
along so how do these things impacts
your simplicity I've basically covered
all this yep what you just said you need
to pass presumption
that identity was lost and in a multiple
machine copy example and say why and I
assume that you were assuming that
that's because the objects might have
different addresses on the different
machines that's not necessarily true it
is true when you're using serialization
serialization does not preserve memory
addresses in Java so the question was I
think you can fix that yes with both
with serialization without serialization
and so then you can fit then it wouldn't
be so much of a problem before it would
be so much from column because with the
same addresses you could use simple
synchronization or coherency techniques
to keep things update I'm not saying to
be cheap I just saying that you could do
it and you're right there people who
work on that right and so the point was
that people can keep objects coherent
across machines keep them in the same
memory space but that's not how tools
are built today the way people build
tools is they leave it up to the
developer the the vendors who provide
api's leave it up to the developer to
reconcile object identity mismatches
across machines and there's only one way
to do it that I've seen people do it
which is they move from pass by
reference object ID etc to a business ID
for those objects so I have the notion
of Adam Cain and Abel that we've talked
about already Cain and Abel I assign
them inside the constructor a person ID
based on the sequence coming out of a
system of record or a lot of that being
a database sequence or file system etc
so Adam is person 0 cane is person 1 and
abel's person too and then I say that I
changed my business logic so that
application the way I write the
application looks sort of like this
basically and this is just at this point
it's basically the way things are done
you know there are I there are very few
technologies that people are using to
seamlessly keep a shared view of virtual
memory in the OS layer I know of three
companies myself and none of them have
gotten off the ground
because their technologies aren't
scaling but the technology fee zabal but
what we're talking about is a mainstream
vendor so if you went and googled again
for clustered java or java clustering
and caching technology this is what you
would find an open source or in the
commercial vendor space and what you
find is that you write applications that
look like this so you'd say cane 1
equals new person cane and I haven't
provided the the definition of the
humans class or the person class so just
assumed that the constructor takes a
parent or there is a constructor
signature that takes a parent and a name
and then we put Cain into our
distributed map so a map is a collection
we are putting it into a distributed map
which is important because later on we
want to get access to Cain and when we
modify and we have to get him out of the
map again does anyone know why we have
to get Cain out of the map again anyone
speak up you can retrieve the mapping
cocaine yeah well you need to ask the
map the distributed map give me a handle
to Cain because you need to handle
together
right so the the assertion is you need
the handle to get to Kane but you had
the handle when you constructed k right
so why can't you just use Cain one that
you that you got back from the vm when
you constructed the person the answer is
basically the distributed map means the
presence of the distributed map means
that any other vm could have changed the
object while you're using it so it looks
very much like ejbs it looks very much
like any notion of impedance mismatched
data to programming and fire yeah so
basically Kane we get Cain out of the
map again we add his brother Abel
assuming there's an added brother
routine and then we have to put him back
in the map so that any other vm that
once a copy of Cain gets the copy of
Cain with Abel said as his brother not
the copy of Cain with no brother so this
kind of stuff is kind of weird because
if I wrote it in the single VM case I
would have written Cain 1 equals new
person mapped out put Cain and then I
would have held on to that reference a
cane one I would have said King one dad
brother later I could have done whatever
I felt like right I might do map get
Cain if I was in another method that
didn't have a reference to Cain but
we're assume we're in the same method
here this stuff gets really weird really
fast what happen is if two machines are
both doing
game that's you this that's an excellent
question so the question was what
happens if two VMs or two threads are
trying to put Cain on two different
machines so they can't coordinate well
they are here the api's fall apart they
say okay I'm just to get put API you've
seen me before behind the collections
interface now they say oh wait there's
no notion of clustering in the
collections interface so now I need to
introduce map top lock and it's not
synchronized but I can yeah I lock the
map I can be transactional without locks
I can just say that I'm consistent
meaning the last one in wins and I have
stabled the use of Kane meaning k
neither gets into the cluster sort of
like old VI type editing last person to
save only their changes as a unit get
into the file system so you can do it
without locking and then you have last
one in wins you can do it with locking
without locking some of this really
doesn't work because you're not just
mutating Kane you're actually mutating
the collection that Cain is in and if
the collection is not locked then you
start losing objects give us a good news
don't tell us what arakata has to say
right so the good news is basically like
this so clustering at runtime what we're
doing thank you Jeff got to keep moving
here so basically terracotta lets you
cluster java applications in the natural
fashion which we call no api's and zero
code now this is a Miss number there is
an API it's our configuration file and
you're going to see it very shortly what
we're doing is we're doing heap level
instrumentation of the vm so that we see
applications attempts to edit memory and
we see all attempts to edit we can see
any and all attempts to edit memory it's
like a hypervisor slotted into the Intel
Architecture but we're slotting into the
Sun architecture inside our notion of
the machine which is the Java machine
and so we can see all iOS that this
application wants to do which means I
don't really have to understand
applications anymore because I can see
when they're trying to write memory and
that's really powerful the only catch is
it's only powerful in the
ends up a developer or it's mostly
powerful in the hands of a developer and
that's why it's free right because you
guys have to be able to experience this
power before you say I'm interested in
building applications to this model and
basically what does a developer do what
is your interface it's we're doing
bytecode injections so you were using
configuration files to control which
objects are cluster ABBA land which ones
are not you're doing configuration
directives to tell us which threads
signal to each other across a cluster in
which threads can only be run locally
you're doing configuration to tell us
which locks are clustered locks in which
locks are local only and that's very
important because let me skip this for a
second in this world where basically
today without vm level clustering I
should stay here sorry without vm level
clustering you're basically clustering
the vm at the bottom of your stack or
your clustering the app server for
example weblogic clustered edition or
WebSphere clustered edition or tom cat
with pooled memory implementation things
like that you're clustering your app
server then you're clustering your
frameworks meaning you're building
stateless applications if you use struts
for example you throw a bunch of stuff
in the database and then you cluster
your business logic meaning you deal
with all the impacts of serialization in
a clustered world we keep the VMS
independent of each other and that's an
important revelation is keep the
independent keep the vm separate and
independent why for operations so they
have the unit of infrastructure that
they always had before one per machine
or n per machine then you cluster just
above the VM and make sure that all the
layers above are clustered so let's talk
about how that works basically you have
byte codes that look like get field
field these are just a sampling monitor
entry monitor exit the get field byte
code is takes object comma field name
and that is enough information for me to
figure out okay if vm one wants out
access to a certain object at vm to
wants access to that same object i'm
going to see them getting access to that
just by the fact that all applications
compile down to the get filled call so
when you use the access or operator the
dot like person dot name equals Kane
that dot operator turns into a get
filled well that example is a put feel
so in the person name equals Kane we're
saying object ID is the cane instance of
person the field name is named in quotes
and the value is the strain Kane and so
that's what's happening is on a put
field I can see what's being changed and
if I can see what's being changed I can
replicate that change at a field level
two other VMS and on the get field call
i'm seeing which field you need which
means if i don't have it on a local vm i
can go grab it over the network just in
time and now we're going to look at it
visually basically this doesn't show up
too clearly but there are two copies of
this object graph and this is not how
VMs are built but this is how i like to
logically explain the architecture and
the concept from a workflow perspective
and you guys can't see it but basically
because it's light grade but this object
graph that says route and object object
object etc is replicated inside the app
and the heap why is that well because
there's a physical representation of
your object graph in memory and then
there's a logical way you think about
that object graph as a developer and
today those two are in unison right your
your physical and your logical line up
as long as you don't cluster and so what
the clustering implementation needs to
do is sit underneath heap and watch when
those arrows get traversed watch when
your business logic meaning the methods
that are invoked actually access the
fields in your data structures so in
this example we touch the bottom right
object and in the example i'm calling it
object 5 underneath this route so first
of all i've introduced the notion of a
route that's a terracotta ism doesn't
exist anywhere else but it is what it
sounds like so if you have an object
graph you want a cluster you don't want
to you don't even know the shape of that
object graph at dev time right it could
be a list of things hang at plus a
string
two integers there are some static parts
to the object graph and some dynamic and
so with terracotta you have to tell us
the top level structure that you want to
share and then we'll figure out
everything that gets connected to it at
runtime so in this example we've built
an object graph flag the top of it as a
root and we're clustering five objects
hanging off of it then we mutate the
fifth object down at the bottom what
happens in a clustered engine that's
declarative like terra cotta is you
build a start building a transaction for
that mutation for that thread basically
that's doing the mutation on the graph
and you say ok what objects are you
mutating what fields are you mutating
how do I know that well I see all your
get filled in your put field cults
inside that transaction block so I've
synthesized a transaction ID 1234 and
I'm keeping track of everything you
change then if you wanted to introduce
this to a cluster all I have to do is
basically take that change and push it
to another vm the same object somewhere
else now how do i know which objects
align with which other objects across a
cluster of VMs that's why the middle box
appeared in the picture the middle box
knows that memory address one two three
four on server1 is memory address three
four five six on server2 and how does it
know that well because one of server one
or server to constructed this route in
the first place assuming no race
conditions it was created one place
which means the other place falta did it
in over the network and didn't construct
it redundant lee so it actually said ok
server one says I'm the first server to
start up I'm going to New up this route
right the server to says ok I'm the
second server to start up I think do I
need two new up this route that's what
terracotta does to this application and
the application says I want to do up
this route and terracotta says just a
second I have this app this object
already nude up by server one so now
terracotta has seen server one and
server to each create the route and
knows what memory address they each have
for it and as a central arbiter of the
cluster wide heap state the Terracotta
server knows
to push changes between one machine and
another where we don't have to keep the
memory address space aligned at all and
that's how you get a single VM context
from an operations perspective and a
clustered BM from a developer
perspective so transaction 1 2 3 4 says
okay there's two servers in this cluster
server 1 and 2 they're both accessing
the same object ID number five so the
change in server one has to get pushed
to server too so i glossed over two very
important points here which is one I can
page things in off the network just in
time which means i can get large virtual
heaps right i can have a two gig 32-bit
heap that's accessing 300 gigs of data i
have customers who do that today they
don't bother with 64-bit heaps they
don't need to they just access address
space and things get garbage collected
out to the Terracotta server and if you
try to access them naturally through
your business logic they fault in on the
fly the other thing i glossed over is
how fine grain this system is I'm
pushing the field that changes i call it
objects in the image but it's I'm
pushing fields as they change and since
I have a central arbiter of the cluster
wide heap I can know which servers are
accessing and using actively consuming
certain objects so i don't have to push
the changes to that red object unless
another server in the cluster actually
has access in its heap to that object i
also don't have to push changes until it
tries to access that object right I
could do it lazily so i don't have to
push out a lot of data to a giant
cluster until unless the whole cluster
is accessing that data do you feel with
anything
so the question was what do you do for
failover if server won the big box in
this picture dies and server to the
smaller box to its right is still alive
the answer is you can run a
transactional and acid compliant mode
where every change you make to one vm
makes it to the Terracotta server before
it's acknowledged so it's sort of like
networked memory in that case where the
cluster server can be clustered you have
to be available all the time in the
current version of the product yes we're
working on the notion of a disconnected
mode where a vm can go away and then
you're talking about mobile java our
internet based applications not meaning
internet services but meaning
applications that are distributed like
steady at home but that's pretty far out
yes I hope you talk about performance is
feeling along with
when it's a good time you get to it
because it looks like most observer s
doing a lot of work right so the
question sorry I didn't repeat the two
questions the first question was about
sorry i missed your i forgot your
question already o.o disconnected mode
was the question disconnected mode was
the question and this next question was
about performance and scalability which
we will cover so the Terracotta
architecture so now we're talking about
our specific implementation why do I
sometimes switch back between the
concept and the actual implementation
that is our software because I think at
some point in the future other people
will arise to compete with us and that
we're not the only one going to do this
and that there's nothing wrong with the
notion there may be flaws in our
implementation there may be reasons not
to use our implementation in our designs
but this notion it this concept works
with or without our implementation
specifics
there's a proprietary file store behind
it it's not a database no its bills to
disk the question was is there a
database behind it and does everything
up to fit in memory so let's talk about
features really fast I think we covered
all this it's hiep level replication
which means i can share almost any graph
I can't share sockets I can't share
native jni type resources so if you
start accessing shared memory I have no
idea what you're doing after you make
that Jay and I call so you can't share
everything with this but that being said
we've come across probably no customers
who haven't found a workaround all our
customers have been able to work around
the restrictions in what we can cluster
it is acid replication which means
they're known I cannot throw new
exceptions or new error scenarios at the
developer because it's a runtime
clustering so and this sorry I am
running out of time here so the notion
of clustering at runtime should be
thought of like network-attached memory
which means that if you're writing to
ram just like if you were writing to a
local file system versus remote file
system I could give you a general write
error I could throw you a ram failed to
update error but what would you do with
it in fact the operating system catches
those types of failures and kernel
panics in many cases underneath you so
if you can't write to the grid and you
need to write to the grid we tend not to
throw exceptions at you we tend to give
operational tuning parameters and hooks
for behaviors to be controlled so like
if one vm wants to write to the cluster
and can't then you could decide to just
exit that vm something's horribly wrong
but you can't catch an exception and do
something with it in line in the
application code because there's nothing
to do and that being said the failover
between clustered servers in our
implementation turns out to be sub
second so all the clients can
re-establish connection because it's all
stateless reestablished connection
to a secondary server and keep going
where they left off and it takes as
measured in our field team like 250
milliseconds to failover from a primary
to a secondary server we have acid
replication meaning you either push a
set of changes that a threat of MIT has
made or you don't which means there's no
world in which one vm thinks it's
changed heat and all the others don't
see that change and if the server fails
then a secondary comes online and
accepts the change etc we have central
storage which means you can keep
application state across restarts we
have our communication hub virtual
memory and we can coordinate meaning
it's not just data replication it's
thread signaling etc and will we can
show you that in the demo separate of
this so our next demo is a J table
meaning the java swing j table tool or
library and if I CD to it and start it
up
it's hard to tell because the way Jay
tables built the way we've used Jay
table we're not painting the grid lines
but this is like a Microsoft Excel
spreadsheet if I click in a Cell all of
a sudden you see what's going on so does
anyone want to guess what happens when i
type breakfast in room B at 9am and hit
enter anyone come on shows up in a
second window exactly and so this is
very different from the first demo right
because as I was moving the mouse and
the other demo I was getting events to
repaint the screen and that I've moved
the pixels and all of that event by
event which means a developer has come
in here and changed the locking
semantics such that I type and I don't
see the typing in the other window
whereas in the other application that we
clustered at the beginning of the talk
that typing those keystrokes should have
shown up would have been my expectation
at least if I were you guys but here's
someone has said where I need a coarser
grain transaction I need many thing I
need the field to be reset in the data
structure before i repaint the screen
not the I need certain methods to fire
basically and so with that let's take a
look at the source code I can't do it I
I mean it's transactional so what will
happen is if you could actually race
then the last one in would win I mean if
you could actually legitimately race
then they basically one would try to get
the lock failed the other one I mean
hang until the other one completes the
update so the last one in would win the
way this application is it is code oh
that would be a sense and then you try
to update you can't how do you end this
now because it's not it's not doing any
kind of versioning and roll back roll
forward so there's no new exception it's
just hung it's like the two of them
grabbed locks in order to write the two
threads on the two VMs grab locks in
order to write exclusive locks and so
one will grab the lock they both read
the data in order to display it when
they repainted the screen so they won't
read the data again
on the transaction if you wanted to
implement a transactional system you
could basically add a version field and
say oh the version I read is different
from the version that I'm about to read
while in the lock so you could build
close closer to lock less architectures
there's all kinds of things you could do
you with a runtime clustering solution
we've got the notion of read and write
locks so you could grab a lock that's
non-exclusive even though the vm doesn't
have that notion without util concurrent
you could grab concurrent locks meaning
everybody's allowed in together and last
one in wins it's all configuration
driven so let's take a look at the
source code basically you'll you'll
notice just a couple of things there's
no import statements for terracotta
library terracotta techcom nothing like
that you'll notice that there are just a
few things going on we're instantiating
a default table model which we could
guess from the import statement is Java
x-wing table default table model it's
not extended or anything like that and
it's a private field and table demo the
class doesn't implements serializable
furthermore you'll note that all this
thing does is basically start up an
event-driven GUI it doesn't do much this
is the entire application that we just
saw so in order to cluster this I have
to cluster the internals of the swing
library because there's nothing else in
this application so the magic is in the
config file this is our hello world so
we've drastically simplified the config
file not meaning that this isn't the
real config file this is the config file
on the screen but meaning if you took a
look at the config file for the drawing
tool we saw at the beginning of the
session it would be more complicated and
it would be more complicated by two or
three lines of config so specifically
what have I hidden from you it's the
repaint the screen trick basically
repainting the screen is a coordination
effort right it's not a data sharing
effort and repainting the screen the way
it's done is through what we call
distributed method invocation so when i
run the repaint event on one machine it
runs on all VMS that are trying to
cluster it's a GUI specific trick
it totally works it's accessible to the
developers but here the key point is the
field we're clustering it's called a
root and I described what roots were
before and everyone seemed to get it so
we're sharing the root of an object
graph and lo and behold it is called
demo che table table demo model which if
I backed up to the code there's a class
called table demo it's in the package
demo dot J table so now we're starting
to understand that that default table
model that's underlined whose instance
name is model that thing is basically
cluster wide thread instance wide the
same model for all copies of this object
everywhere in the vm if i knewed up
another one the way this configuration
is written that constructor call
wouldn't fire yes how do you want so we
are storing everything in an extremely
fine grain name value pair type system
so evolving classes the question was how
do you evolve your classes sorry
evolving classes is really quite easy in
some cases and in other cases you have
to flush the cache in order to do it so
this is meant to be a repository for
transient data so flushing the system
shouldn't be scary in most use cases but
we do handle field edition field
deletion field type changing as long as
a typecast could be done implicitly and
then we have scripting hooks through
bean shell for developer to come in and
say if an application is accessing so
version 1 of source code versus versus
version 2 if there's a mutation to the
class data that has to happen when
faulting into a version 2 container the
mutations can be done can be
instrumented into the application
through the config file and that piece
of code can be introduced into the
application so now you can handle
because you're not serializing you can
handle version 1 and version 2 of your
application logic running in a cluster
no problem you can also handle different
stacks so weblogic tomcat and websphere
clustering the same war at the same time
in in many cases yet well if you change
business logic then you'll end up with
the serialization exception if you
change the shape of the class so the
question the last bit of data is the
scalability of this model and the short
answer is hub-and-spoke as a single
point of failure field changes being too
chatty and network overhead to
clustering those are the general buckets
of performance issues the answer is in
the hub and spoke world you scale the
hub so we are clustered we are a grid
type solution we're just doing it in
infrastructure where ops can run the
service separate of the developer
environment field level changes we batch
them so how do we match them threading
and the Java memory model has a clearly
defined window where threads have to
have all changes applied before they're
allowed into a monitor we're extending
that to the network so we fault data in
lazily and threads cannot read data that
isn't consistent with the data that was
updated in another thread in a lock
volatiles all of that stuff is a totally
different contract network overhead it's
basically runtime optima so I batch and
window all my updates I can send a
thousand things at once I have customers
who have benchmarked us against API
based solutions and have found that we
dropped in whereas the API based
solution required them to take a week
and a half to rewrite their app when we
did cluster their application we took
about 10 minutes to update 30 million
objects and the API based solution that
was serializing deep object graphs did
not finish took four and a half hours
before it through an enemy and and
exited so we and then when performance
tune that application ended up taking
like 54 minutes with a developer based
optimizations yes where
scaling size of memory is stored on one
machine and can the size of the work on
be the sum of the memories and all the
jbs together or not it's it it's it's
use case specific so the question is
what are the limits to scale and the
challenge with scaling is there are
applications that have lots of data and
read heavy there are applications that
have lots of data and are right heavy
and then there are applications that
have little data so if you read heavy
right heavy to the cluster that's a
unique challenge from the amount of data
you're trying to access and generally
speaking what people do to scale a
terracotta type solution is they chop up
the data and window onto it so one node
will only work on the subset of the data
and they do a scatter gather type
architecture to get scalability but
physically the server can fit you can
store as much data as you can deploy
disk against the server so you can get
terabytes or petabytes of data onto a
32-bit heap the largest we've gone is
1.5 terabytes well the customer is
moving towards one point five terabytes
next year they're doing 300 gigabytes
this year and the last demo go into an
inventory item by skew and update its
price meanwhile someone wants to
merchandise that inventory and have a
taxonomy to it so I could have products
that show up in multiple places in my
store and so there I need a tree of
merchandising Department set cetera and
so I could see my products by inventory
in this case we have a tripod a mouse a
book and a one gig flash card and I can
see my departments the one gig flash
card is in photography and in computers
because it makes sense nowadays to be in
both so if I update the price of the one
gig flash card enter the new price price
of memories always falling now it's by
inventory and by department not a big
deal it's really easy to write
applications to do that what have I done
wrong here
and of course since we're talking about
clustering I start up a second process
inventory 2099 departments 2099 in the
second process that's not the
interesting thing the interesting thing
is if I CD into the source code actually
the best thing to do is start up the
console to help us make this point so
there's a console that bolts in through
jmx talking to the central hub gives us
all the information we want about our
data I can see transaction rates across
the cluster I can see it / clients there
are no connected clients right now I
killed them both in order to show you
guys the source code in this so what's
more interesting is the object graphs
here are all our roots there's our store
if we drill in da our store it's an
inventory of demo inventoried store it's
an instance of one sorry so if I CD into
demo inventory there's probably a file
yes store dot Java so there's my store
class but what's inside that store is an
arraylist and a hashmap and those are
called departments and inventory so if I
look inside the store and I search for
departments there is one new arraylist
store doesn't implements serializable or
anything inventory is a new hashmap you
can see in the constructor I'm
populating all the data so there's a
product I knew up a bunch of products
and a bunch of departments and I add
departments I ad inventory and you can
see I've added the products both to
departments arraylist and to the
inventory map and so between the console
and the source code I can make sense of
what's going on here if I drill in on
the department's I'll see a department
with a string name with the current
value books I'll see products inside
that department I'll see their IDs and
everything so basically I have a real
world use case
where I've built a very simple domain
model it clusters readily I don't have
to worry about serialization no JMS no
database backing no nothing and I have
all the data in the cop in the server
whether I start and stop the processes
or not if I spin up the processes again
the price is still 2099 that's basically
it I have a bunch of questions but we're
sorted out of time so server has a file
so the question is does the server have
to know what's in the config file so in
development mode you run a centralized
server or you can run it's a process a
standalone Java process you can run it
on your sandbox or someone can decide to
have shared development environment and
then each VM that connects when the
servers and development mode is allowed
to send its own config file when it
connects it says these are all my roots
that I'm going to share the opposite is
operations mode production mode where
you install application named
configurations into the server and
applications connect registering their
name through a handshaking process and
they can only share and get access to
the data the server has told them they
can share does that answer your question
yes she does I similar question if you
start this thing on scrap it's a really
big database mm-hmm dataset they said
well whatever I want to call her is it
you gave an example of something that's
really 300 gigabytes right so how long
you think the start that up scratch but
what's the lacustrine starting up a new
JBL and having it no I mentioned that's
pretty good oh just wondering what's
involved right checking state so the
question is what's the startup time when
you're dealing with massive data sets
both for the server and for the client
VMs that are clustered through it and
the short answer is we're faulting
things in on demand so the startup time
is again use case specific if you wrote
an application that checks for your
let's say let's talk about a cache like
a singleton cash type of pattern and you
get an iterator to your cash and walk
through every element of it just to do
some inspection upon those elements well
if you have to fault in all of those
will batch that
faulting but it'll still take minutes to
start up what would have taken seconds
to start up in a nun clustered world but
for the most part people don't do stuff
like that so we Fault in things on
demand the case where the customer is
sharing 300 gigabytes of data their vm
start instantaneously and in fact we
have a customer that same customer is
now using us to cluster weblogic instead
of b EA and they're deploying that in in
december because weblogic takes a little
while to start up in clustered mode this
thing changes it so their startup time
is instantaneous Tomcat clustering is an
interesting follow-on to because tomcat
when you're using it in a clustered mode
will actually not start servicing
requests until all clustered data is
cloned into the node from all other
peers so now you've got a peer-to-peer
architecture where you have to wait an
unbounded amount of time for network
conversations to happen before your
process even starts I've come across
folks who actually killed the whole
Tomcat cluster in case one node dies
they just kill all the nodes and restart
them so that there's no handshake that
has to occur and if terra cotta is
clustering Tomcat it starts up
instantaneously there was one other
question
legacy systems access is just a gap in
terracotta this product conceptually it
can be done basically we've stored
objects as name value pairs all their
fields and all the relationships across
objects so it is possible for us to
create an API for legacy systems to get
at that data but for now you have to
write a Java bridge to get at that data
they use JDBC to flush to a database
completely separate of clustering so
they will use like event callback type
structures with us and basically say
when an object changes invoke this jdbc
flush routine and in configuration they
can decide if the database is
communicated to synchronously or
asynchronously database is consuming
those transactions so I sorry I didn't
define databases legacy systems i was
thinking like kicks and herbs and things
like that sorry thank you everyone
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>