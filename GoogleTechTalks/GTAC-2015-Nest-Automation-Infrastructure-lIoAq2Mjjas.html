<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2015: Nest Automation Infrastructure | Coder Coacher - Coaching Coders</title><meta content="GTAC 2015: Nest Automation Infrastructure - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2015: Nest Automation Infrastructure</b></h2><h5 class="post__date">2015-11-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lIoAq2Mjjas" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next up we're going to hear about nest
automation infrastructure from Usman
Julia and Sam those little things
clinging to walls clickety clacking in
corners appliances from another era
things that go in the night kind of ugly
kinda dumb which is a little sad because
all those little things are too
important to go unnoticed and unchanged
year after year but we noticed them and
thought maybe they could notice us
because your home should know when
you're there and when you're not
know that you like it cool in the
morning and cozy at night it should give
you a heads up when something goes wrong
or when someone's at the door
so no matter where you are you'll know
everything's okay what if all the things
in your home worked together
your home could start taking care of
itself and take care of you so you can
focus less on little things and more on
the things that matter nest welcome to
the thoughtful home name is Sam Gordon
and I'm drawing on stage today by my
colleagues Julia guidi newsman Abdullah
and we're extremely excited to talk to
you about some of the automation tools
that we've developed at nest
specifically we're going to talk about
some of the more Universal cross product
cross-platform tools that we've
developed as they relate to censor
emulation data injection and power
analysis and then we'll take a little
bit of a technical deep dive into some
of the more device specific or feature
specific tests that we've developed as
it relates to motion detection on our
camera it's a lot to cover and we're
very excited but first we're going to
give you a little bit of an overview of
who we are and what our vision is for
the thoughtful home as the video
mentioned our first product the Nest
Learning Thermostat is an intelligent
thermostat that learns automatically
what temperature you like your home it
learns when you're home and when you're
away with the ultimate goal of saving
you money and keeping you more
comfortable our second product the nest
protect is a smoke and carbon monoxide
detector has a dual wavelength sensor
that detects more fires faster and it
uses voice alerts and a and connected
smartphone app that is much more user
friendly than typical middle of the
night chirps the nest can is our
wireless IP camera solution that is
truly your eyes and ears within your
home when you're away it comes with an
optional cloud video recording service
that is that enables you to relive those
special moments for up to 30 days lastly
there's the works with nest ecosystem or
works with mess devices contribute data
and connectivity to other devices within
your home so your Philips you lights may
turn red when your nest protect detects
smoke
or your nest learning thermostat may
start adjusting your house to your
optimal comfort temperature when your
car lets us know that you're on your way
home all this sounds great but there are
many challenges associated with building
these devices first there's a multitude
of coordinating sensors that provide
data both to the host and the cloud
services these auxiliary sensors and
radios must fit in a similar form factor
to traditional devices so they feel
familiar with in the home many of our
devices are battery-powered they last
must last for months or even years on a
single charge making power management a
critical item lastly nest strive to
build best-in-class devices that also
provide connectivity and data to other
devices within the ecosystem within your
home presents a unique challenge for us
and we overcome these challenges through
a rigorous testing paradigm we have form
factor device racks that are constantly
running new software we use
environmental chambers to test our
devices in different environmental
conditions we run device simulators that
run software regressions on a PC or in
the cloud with no physical hardware
required we use sensor emulators to
inject test vectors directly into the
devices microprocessor while also
running production software we use
real-world data injectors to playback
samples from devices like the nest cam
we run power and functionality
regression tests on daily builds using
continuous integration solutions we run
full suite regression testing on
potential releases lastly our beta
testing program dubbed field trial is
truly the last check before a software
build is blessed to go out the door and
all of these fit into three different
testing methodologies there's black box
testing where we test the device without
any knowledge of the algorithms running
in the device there's gray box testing
where we test the device with a general
idea of the algorithms running on the
device and then there's white box
testing or we test the device with
knowledge of the exact source code
running on the device we're going to
talk a little bit more about that last
bullet point sensor emulation and data
injection so the question was really
posed to us how do we test the
algorithms on an intelligent thermostat
from a lab environment how do we emulate
an icy cold winter in Ottawa or a hot
and humid summer in Houston all from a
office in temperate Palo Alto and you
first thought maybe well throw it in one
of those environmental chambers you just
showed me but I would argue
environmental chambers are not scalable
they're expensive they require frequent
maintenance they take up a lot of space
and I'm sure there are more things so
taking a step back let's think about
what are the sensor inputs that might be
useful for us for an intelligent
thermostat well obviously needs to know
the temperature current temperature
within the home and the humidity within
the home probably should know the HVAC
system that's installed in the home
might be useful for it to have a weather
forecast for future temperature
predictions lastly occupancy whether or
not anyone is even home at alt heat or
cool the home for we developed the
sensor simulation board which is a
microcontroller based platform that we
use to simulate sensors and monitor
outputs and we do that by switching out
all of the sensors on the device and
talking directly to the microcontroller
we use it to find software regressions
and validate algorithms and and we found
that it is capable of emulating most of
the sensors required by an intelligent
thermostat and it does that using two
micro processors and lots of interfaces
to the device under test over 200 direct
connections and lots of standard
communication protocols by I to see and
you are and on the software side we
write sense of sensor models and device
drivers all in our free art oz
application software that uses a custom
USB messaging protocol to communicate to
the host the tests and data collection
are all being run on the host in our
custom Python test framework
and our next question was how extensible
is this platform can we also apply our
learnings from the Nest Learning
Thermostat to our second product and
that's protect so you'll see a couple
familiar sensors temperature humidity
and occupancy but there also some new
faces now we're concerned about smoke
carbon monoxide and we have a push
button to hush alerts you may be
surprised to learn that yes we found our
sensor simulator board is capable of
emulating all of the sensors required by
a smoke detector and even better it's
capable of monitoring device outputs so
we can verify that our LED light rain is
alerting users when something's not
right we can validate that our speaker
is providing those vocal heads-up or
encouraging users to evacuate and we can
ensure that the alarm sirens to wake
everyone up in case of an emergency now
Julia will come up and talk about power
analysis hi everyone so you might wonder
why are we talking about power analysis
in the test automation conference well
power analysis for embedded system is
really important and it's really useful
first of all let's take the example of
the next nest protect with a nest
protect you have to run for multiple
years on six double A batteries so in
order to do so you need a good battery
life estimation and if you have real
data then you can you can have a very
accurate estimation so you can manage to
run for those multiple years but we
supply our analysis you can also
validate some component specs so let's
say you have a microcontroller and you
want to go you don't want your
microcontroller in sleep mode to go
above a certain current then with power
analysis you can make sure that it never
happens and last but not least you can
look at your software performance so if
you look at the graph here you see that
different builds have different average
current conception so we run the same
test which is rebooting the device
pairing it and we look at the average
current consumption over time and we can
see that some bills make the average
current consumption way better whereas
some other break it and
when you see that it breaks it what you
want to do is come back to your software
and fix it as quickly as possible so let
me give you an overview of how we do our
analysis what for electronic system
power and sip is simply voltage time
current voltage while we use an
analog-to-digital converter for current
it's trickier so we decided to go with
the arm law which says that which states
that the current is proportional to the
voltage and the factor is simply the
resistor the resistance that you put in
your circuit but you can imagine that
for us we want very small currents
couple of micro amp and we also want to
go to a couple of amps how can we get
that was only one resistance what we
need to switch from one resistance and
we need to do that in a smart way so we
develop what we call the automatic gain
control and thanks to that we achieve
precision of a couple one micro amp the
base case we also wanted to measure the
voltage because we want to have true
pirate conception and we do that at a
very high frequency very high sampling
rate so that every microsecond we know
what's happening in our system so we
have two different type of power
analysis you can look at the whole
system it's what's shown on the on the
picture here or you can look at a
subsystem subsystem is you isolate a
component so let's look first at the
whole system power analysis so what we
developed is a companion board it
supplies of voltage to your device under
test and at the same time it records all
of the current that is being and the
voltage that is required by your device
on the test and you can stream the data
to see it live you can choose to store
it on an SD card or you can even send it
to the cloud and retrieve it later on so
the system as architecture you have this
power stage as i mentioned that is
adjustable so that we can use the same
word for all of our devices creating a
platform a reusable platform then we
have this art sense that you see which
is your traumatic gain control we take
the voltage we amplify it we do all of
the measurement and then we
that to a processor in our case it's a
cortex m4 and of course we have all of
the peripheral for communication and
sending the data so here is the board in
action you can see it as i said the
companion word so it's standing by in
this case the next protect and we have
those racks of devices running the same
test suit and what happens is if you see
when you look at the current consumption
the power analysis if you see some
discrepancy as the test is exactly the
same for all of the devices you can look
back into the log and understand what's
going on in your system so you might
wonder well what does it look like let's
take an example the nightly promise so
what happened during the nightly promise
is your home it's night you turn off the
light you're gonna go to bed and you
want your nest protect to check on its
sensor and its battery so that you know
it won't wake you up and the device
itself it's going to tell you that
everything is okay by turning the LED
ring green so what happens when you turn
the LED green the LED light green as you
have the microcontroller the MCU that
wakes up and you can see it it's the
first peak that is here and then you
have the wave that you see on the graph
which is the PWM the command that is
sent to the LED you can wonder how do I
know that the first pick is in the
microcontroller that wakes up well
because we have the subsystem power
analysis so what it does is let's say
you have your device under test and you
want to isolate a subsystem the
subsystem can be a sensor it can be a
communication chip a Bluetooth the Wi-Fi
it can also be a microcontroller and you
have a measurement board that applies
specifically to the isolated system and
then of course you can get the data back
so what we develop is this small board
it's like this this size very small and
it has four different channels meaning
that you can sample four different
subsystems simultaneously and it's
strictly equivalent to those for digital
multimeters stacked together so you can
understand that for our engineers when
they're running some tests they would
rather use this small word on the desk
then this huge
of lab devices but for us it's also way
better in terms of cost because this
board is only a tenth of the price of
those four machine lab machines so we
use it on our development boards the
development board is simply the form
factor device so the device that you see
in your home but the electronic is
spread out so that it's easier to test
it and as you can see we have standard
headers they were highlighted in red on
the picture and we just plug our board
and we have the data let me show you a
video of what's happening so we have the
console on the on the right if you can
play the video thanks so we have the
console on the right you're going to see
that I'm I'm inputting comments to the
LED and to the Wi-Fi and the top chart
and is simply the battery power you can
see the LED one which is channel three
and the Wi-Fi on channel 0 and when I
pulse the LED and at the same time do a
Wi-Fi scan you can see that it adds up
on the on the top chart and also when
you change the LED the LED wave you can
see the current pattern changing so you
can have a lot of information of what's
happening in your device and when you
want to test you can understand that
it's really important and you can be
very useful information and yet the
scale is dynamically changing so so
that's all for power analysis thank you
very much and now this man is going to
talk about motion detection Thank You
Julia so if some of the hardware talk
caught you off guard for those software
engineers the motion Decker is going to
be more of a software challenges that
came up so I'm respond I work on the
nest cam team in particular the motion
detection currently working on making
the motion detection experience as
awesome as possible and hopefully you
can buy one of our products
so the nest cam as Sam had mentioned
earlier is your eyes and ears while
you're away it's designed to watch out
for your home and family even when you
can't it's there to alert you when
things go wrong but coming on a softer
side it's also as a baby monitor which
record all those funny things your
baby's doing are those unexpected dad of
the year moments that happen but the
best part about it all is the fact that
the nest cam is there to let you know
when things go wrong we have this
sophisticated motion detection alert
system which is our key distinguisher
between rest of the products so the
peace of mind that the nest cam provides
you starts on our sensor and ends as
alert on your phone the nest cam has
sensors it's got an on camera motion
detection alert system which for me
personally sends me an alert every time
my parents leave and enter their home
which allows me to use from the comfort
of my bed say good morning or good night
to them using the built-in speakers and
microphone we also have advanced
algorithmic analysis that's done in the
cloud which has a precision and recall
curve which is our secret sauce so for
those of you might know in pattern
recognition there is a PR curve which
says hey of all the false positives how
much do I want to miss and do I get give
you all of them caches of the motion and
all of the false positives as well it
gets a little confusing with precision
and recall but in summary what it means
is the motions that I catch how much of
those are relevant so we do all that
filtering in the cloud so that we don't
unnecessarily annoy you every second
every time the tree moves then we also
have a motion clip storage where you can
go back in history and relive and
cherish your moments so I'm going to
walk you through an example of what
happens when things actually do go wrong
what happens when a burglar comes into
your house well first up some undone
welcome wizards decide to drop in and
you're sitting comfortably in your room
how does the nest can behave first up
the nest cam sensors immediately detect
there's something up it passes on to the
on camera motion detection algorithm
says hey motion is
and check this out what's up the motion
detection algorithm where it runs a lite
version of the cloud and says hey this
is something of interest that the cloud
should look at and uploads the data to
the cloud the cloud runs those
sophisticated motion detection
algorithms machine learning neural
networks all that jazz and sends a
notification yes this is something of
interest to our user and immediately
sends a notification the user instantly
gets alert saying hey there's some sort
of activity that happened in the living
room and is able to view the clip the
next is either a 911 call are you
chasing your visitors out all of this
magical experience that nests provided
has a lot that goes on behind the scenes
and I'm going to talk about some of the
challenges and even testing this the
first step was the entire end-to-end
pipeline list right from the sensor to
the hardware to the interaction between
the cloud to the notification on your
phone and to recruiting the video clips
and alerts the entire pipeline was touch
so if any one of those mess around you
won't get this alert and this experience
one be as seamless and smooth so the
first test is to make sure that the
entire pipeline is tested and we need a
scalable way of testing each and every
one of those every time any of the
algorithms sensors hardware software
anything changes then second question
comes about reproducibility of the scene
how do i reproduce this exact burglar
seen in the same light conditions
obviously I can be hiring actors and you
know having troupe this because I
wouldn't be standing here I'd be
directing a script then comes the
question or repeatability how do i
repeat this 10 20 hundred times in a
scalable way and then if something
happens let's say at sunrise camera mrs.
things out on sunrise how do I bring in
twenty Sun rises in a day I can't be
standing out there every sunrise for ten
days and repeating the scene so all
these challenges were overcome and by
building in-house solutions we created a
simulated TV testing set up which gives
us free repeatability reproducibility
and gives a system performance metrics
that we can just run on continuous
integration some of the things that we
can automate such as night vision on a
TV we have to sometimes manually do and
we're currently in the initial phases of
bringing in robotics
help us out so if any of that interest
you come talk to us we also have
simulators which simulates the camera
because sometimes you don't want to run
the entire pipeline the precision recall
curve I talked about earlier in the
cloud can just inject in camera
simulated data instead of having to go
through real life scenarios the
algorithm characterization testing it's
just a fancy word for a be testing which
we also developed in the house because
this is not your regular a/b testing
it's not just a functional pass or fail
you have to measure what's better in a
very subjective manner and then the user
experience how does the entire
end-to-end motion detection experience
compared with our previous builds you
don't want to be notified every second
so no user experience also key for the
motion detection the simulated TV
testing as expected is a camera placed
before a TV we have real life uart
cables coming outs for real-time logs
and we place multiple of these to ensure
consistency across our devices and to
make sure that the field of view doesn't
mess around with motion detection in
case a user wants to put it in a
different angle different location
simulate TV box home and set up but the
the skeleton code is kind of something
like this we go out and first of all see
what the limitations of our code are and
what the limitations of our fielder and
what our users expect what sort of
scenarios would expect indoors outdoors
with pets without pets duration of
events how quickly cars lights shadows
all of that so once we come to terms of
what our success criteria should be we
go on and record high resolution videos
of those scenes and we store them in the
cloud but we also curate those data we
we title way we label them as indoor
outdoor light conditions number of
events duration of the event what time
does then start from the video and we
have that stored in the cloud so that
when we want to for example change
anything on the camera that says hey
that should only impact indoor scenarios
or that should only impact small distant
objects or just animals or cats dogs we
can quickly want just those subset of
the videos if you want to run an entire
regression sweet we just played
throughout the entire series we play
those videos on the TV screen and the
camera sees this as if it wouldn't
real-life scene though some people might
say hey this is you know field of view
the frequency but we'll come to that so
the camera plays in an irregular manner
and streams the video as it would in
real life and we can see when the
notifications came in what time the
duration came in how long would the
event was what did it detect what did it
miss all of that and if anything went
wrong we have smart email and text
notifications that come on your phone
that hey because the entire pipeline if
the server was down it gives you a
notification hey servers down you might
not want might want to fix that so we
don't wait for a whole week or days
before we come to that conclusion if I
want to isolate the entire pipeline I
just want to check the motion detection
on camera I can use the same setup I can
see what time the motion event happened
how long the duration was based on my
expected result if anything fails we can
quickly dive into it a bit more deeper
so what does this help us uncover well
despite the fact that it's not a hundred
percent identical it helps you uncover
end-to-end plumbing issues such as the
interaction between the cloud and the
device or the device and the
notification or the sensor and that
motion detection end-to-end plumbing
issues can easily be figured out for
this server side bucks cloud processing
books of the clips that were sent to the
cloud what we missed out what we didn't
easily figure it out we identified
memory leaks see butyl ization
temperature were long runs of time when
motion happens overcome the experience
how does it behave and all of this is
historical data that we store so we can
compare these metrics to last week last
month what happened in our previous
built the camera similar is there to
basically come up with our secret sauce
so we have all of our raw camera data
thousands and thousands of video and
this is raw camera data that we don't
have to play back into the camera from
the camera because all this is stored in
the cloud so we can it's all obviously
internal data not production data and we
can play it into our motion detection
algorithm and say hey from the curated
data that we had what are we doing how
many events are we missing how many are
we catching is their false positives
that are happening and this gives us our
secret sauce of coming up with the best
precision and recall curve the a/b
testing is an in-house solution that we
created for for comparing different
metrics so as mentioned the precision
recall curve is a trade-off between
false positives and true catches
obviously we don't want to miss all of
we don't want to catch all of the events
because that will give us a lot of false
positives for a user so it's a threshold
so do different versions we created
three or 3d stands that we gave out to
internal Googlers and nesters and said
hey take it home and if you're not going
to talk about your privacy we're going
to scrape your data and what we do is we
put these in indoor outdoor all these
scenarios and situations that are
relevant to the user and we scrape the
data so the field of view is exactly
identical because we created custom 3d
stands that make the feel of the exact
and we have a you know whitefield video
bangle so it doesn't really make much of
a difference first of all we compare the
overall metrics hey were there any major
known issues or did something go wrong
with memory usage cpu utilization time
our internal metrics that we have if all
that looks good we quickly do a
time-series merging data what that does
is merges both of the notifications that
came up from both cameras into a single
notification list and we start
traversing through that list to identify
difference between the camera
notifications which are which mapping to
alerts as soon as we identify them it
comes down from 800 900 clips / camera
to just two or four and these
differences we manually go through them
because it gives us valuable insights
and say what are we missing what are we
catching why is it doing better once we
have that we can train our algorithms
again to say hey this is motion you want
to catch on and this motion you want to
miss on and if the precision recall
curve and all of the other steps that we
mentioned if it all looks good we ship
our feature and that's why it's a
continuous loop of continuously
improving our motion detection with the
system so coming to our conclusions
hardware is hard as we saw but it
doesn't mean that we shouldn't do it
what we have demonstrated is only a
small subset of our testing paradigm
automation has helped us save time and
cop bucks it's provided repeatability
and gotten room of subjective items such
as motion detection from human bias and
error and of course we're always looking
for help so if you're interested come
talk to us
thank you before we go to questions I
have one in Minister via rossi from
spunk if you're around please go see the
AV guy so you can pop next and get miked
up now questions for you guys can you
speak how you test security on these
devices which are becoming part of the
family no well that was straightforward
I think I know the answer this one but I
have to ask it anyway can you guys help
GTX room fix AC temperature you'd have
to install nest thermostats first so
possible but not immediate yes sign up
for field trial most of the nest
products require Wi-Fi if internet
service goes out our nest devices smart
enough to know when to reset the device
how do you test these types of scenarios
so that typically falls to our
communications integration engineering
team so many of the devices we build our
just used specifically for device
testing right platform device testing
and then a lot of the interconnected
tests or Wireless tests are all run by
our communications of integration team
that I really have no idea about so you
guys just started the experts on the
molecular area ok but the camera I can
say yeah we have some sort of logic that
kind of understands when the power is
out or when the AP is down so we have
some sort we we have internal tests that
we can do that for that ok for motion
detection had you I lost my screen for
motion detection how do you effectively
distinguish between people who should
enter the house and unwelcome visitors
um
I can't really go too much into detail
about how we do that um yeah it's one of
those secret sauce things but but they
told us all again but you know one of
the things about motion detection is
very subjective you know some people
like shadows some people don't want to
learn on shadows some people want
notifications on cars passing by some
don't want it so some people want lights
turning on some people don't so a lot of
it's very subjective so things that are
like you know have difference of opinion
we kind of keep to the side when we're
testing we just kind of like on the side
just measure this is how it did but we
usually go for things that you everyone
usually agrees that this is what we want
to learn on for example a person walking
by in front of you you want to be
alerted on that or in front of the
camera so we try to eliminate things
that are differents of opinions when we
go out and you might be able to answer
this um the question actually
specifically asks how do you ensure
smoke detectors aren't flaky but how do
you desert in for any of the hardware
that you test isn't flaky and like
sending false positives and turning up
the heat or setting off a smoke alarm
but yes I mean this is all a part of
larger testing schemes right so we
talked specifically about features but
they're also the hardware teams all run
lots of heavy validation on their
prototype hardware and through every
build and then we have reliability teams
that are constantly running reliability
test is the best way to describe it
we've built I mean especially for smoke
detectors we've built things like dust
chambers and bought smoke chambers to
run accelerated life testing and really
try to make sure that people are
trusting us enough to put these devices
in their home and we certainly don't
want to lose that oh well thank you guys
I know want to automate my own</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>