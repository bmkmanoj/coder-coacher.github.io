<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Digital Design: Beyond Trial and Error | Coder Coacher - Coaching Coders</title><meta content="Digital Design: Beyond Trial and Error - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Digital Design: Beyond Trial and Error</b></h2><h5 class="post__date">2008-08-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QOcyGZvKkgU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming everybody it's my
great pleasure today to introduce Fred
fer tech for a very interesting talk on
a formal design methodology approach to
digital design Fred's been working in
this area for a long time on and off
with with his work and startup companies
and field programmable gate arrays and
so forth he tells me he started this
formal verification stuff around 20 or
so years ago it was at mitre and Draper
labs and places like that I've known
Fred since the days when we worked
together on some FPGA stuff at Apple
computer back in early 90s and as a lot
of good ideas here so Fred take it away
let me mention first that this talk is
based on a paper that I've just
submitted to I tripolis computer
magazine if anyone would like a preprint
of that or a copy of it it was just
submitted decline has a copy and please
give him something email if you'd like a
copy all right this is technology I've
been working on for quite a while it's
it's formal it's a formal approach to
verifying the behavior of digital
systems and i want to emphasize it's for
both hardware and software make no
distinction between the two how do i get
this little guy to go away here nope
that didn't do it all right
with rare exceptions digital design both
hardware and software is based on trial
and error we have incredible reasoning
powers humans have created extraordinary
complex systems but our reasoning is and
is not infallible we make mistakes and
we rely on verification to detect those
things fine fine where we've made
mistakes and correct them but the
standard verification techniques
debugging simulation and emulation can
only prove the existence not the absence
of bugs so when we feel we've got the
system working we think we've got it
working right we ship it or we deploy it
but we often find from our customers or
sometimes from hackers that we haven't
quite got it right there's bugs or those
vulnerabilities and our systems and my
thesis is that there can be no
fundamental advance and the reliability
and the security of our systems until we
move beyond this process of trial and
error so what's the solution i'm going
to list four requirements for
methodology to take us beyond trail and
error the first is we need a
mathematically rigorous methodology
there simply is no substitute for
mathematical rigor software engineering
can do only so much but at the end of
the day we need mathematical rigor it
also must be said that the have real
impact the methodology must be usable by
the average engineer if the technology
is onerous to use or its
incomprehensible except to an elite
group of highly skilled highly educated
experts it's simply not going to have an
impact in industry now I'm not saying
anything new here except maybe
requirement too there's been a
recognition that we need mathematical
rigor and verifying the behavior of
digital systems and this field this area
has gone by the name of formal
verification and there has been work in
this area for at least 30 years and I
want to very quickly cover three
approaches there are purely boolean
techniques
and the end within this area there are
two classes of tools there's equivalence
checkers and satisfiability solvers
these have been extraordinarily
successful they have very simple
interfaces and they can handle tens of
thousands of boolean variables the
problem with these purely boolean
techniques is they cannot handle time
and the approach I'm going to describe
does handle time and it does it in a
unique way but let me add that these
purely of pooling and techniques are the
perfect complement to what I'm about to
describe there's another approach called
they're improving and the the center of
research in that area is s RI up in
Menlo Park in this approach formal logic
is used to prove to approve properties
about the system and the technology is
extraordinarily powerful and they have
extraordinarily expressive proof systems
I'm a great admirer of theorem proving
the problem with theorem proving is that
it's not automated and it requires a
good deal of skill on the part of the
user and if you've got a PhD and form a
logic and a lot of time in your hands on
your hands this is the technology for
you but there is one exciting prospect
is to integrate their improving
techniques with the automated tools I'm
going to describe in a moment now the
approach that's receive the greatest
amount of effort over the last 30 years
of something called model checking there
must be at least a hundred or a couple
of hundred researchers around the world
that have been working on model checking
it's an automated verification technique
in which temporal logic specifications
are checked by an exhaustive search the
state space of a concurrent system the
fundamental problem of model checking is
it must address the state space
explosion problem than to give you an
idea of how significant that problem is
a system with one flip flopper
binary variable as two states a system
with ten flip flops of binary variables
as 1024 states and a system with a
hundred flip flops of binary variables
has this ridiculously large number of
states now for the past 30 years the
efforts and model checking have been
directed at mitigating the states based
explosion problem and they've developed
some quite impressive heuristics for
example they've got to the point where
they can handle hundreds who binary
variables flip flops I can't handle as
far as I know thousands or tens of
thousands of course there are systems
would great many more than a few hundred
binary variables however as clever as
they may be at the end of the day at the
end of the day they're addressing only a
symptom of a much deeper problem and it
is that underlying problem which must be
addressed and that problem was
articulated extremely well by edward lee
who is chairman electrical engineering
and computer science at berkeley and i'm
quoting the physical world is highly
concurrent and our very survival depends
on our ability to reason about
concurrent physical dynamics the problem
is that we have chosen concurrent
abstractions that they do not even
vaguely resemble the concurrency of the
physical world we have become so used to
these computational abstractions that we
have lost track the fact that they are
not immutable I think he's absolutely
right on the money and the problem with
model checking is that they have chosen
an abstraction finite state machines
that does not even vaguely resemble the
concurrency of the physical world so
what's the answer where do we look for
an answer where do we get a clue
unhandled on handling concurrency how do
we do concurrency right well I can think
of no better place to look for an answer
than those non digital disciplines like
physical like physics and electrical
engineering
that have the mathematical machinery to
deal with concurrent physical dynamics
in a wide range of systems I mentioned
those two disciplines in particular
because as an undergraduate I majored in
electrical engineering and all of the
systems we study both in physics and
electrical engineering and durable
courses I took I took in those areas
everything we studied involved
concurrent systems and yet the terms
concurrency and parallelism never arose
that's because concurrency was handled
in a natural in a transparent way so
what's the secret to addressing
concurrency how do they do it well
distilling distilling the approach that
in to it the simplest possible terms
each element of an analog system is
modeled by a separate set of equations
and mathematical tools are used to
derive or verify new equations
describing aspects of the system's
behavior not obvious from the initial
equations now notice here that the model
grows linearly with the size of the
system you had more components more
elements you simply add the equations
for those elements or components there
is no state space explosion well how do
we take this insight from the analog
world and apply it to the digital world
well I've distilled what I just
described for analog systems I've
distilled that into the final two
requirements each element of a digital
system whether it's hardware or software
must be modeled by a separate set of
constructs okay I get to exactly what
those constructs are in a moment and the
same constructs must be used in modeling
the system and also in describing the
aspects of system behavior that you want
to either derive or verify so the
question boils down to what is the
counterpart to the analog world's
equation what is it that
we can substitute for equations and the
analog world so that we meet
requirements 34 the answer is
implications we're all familiar with
implications in classical logic if a
then B where a and B are boolean
expressions and it's commonly written
pay with an arrow followed by be a
classical logic has no notion of time it
cannot express in particular cannot
express implications distribute it in
time and by that I hear some examples of
implications distributed in time if a
holds an estate than B holds five states
later if a holds in a state then B must
hold within the next five states pay
holds an estate than B holds their ever
after if a in the state and be until c
holds or simply be in every state which
is equivalent to if true and a state and
be in the same state now these sorts of
implications play a key role in how
humans reason about digital behavior I
don't care whether we're talking about a
programmer designing software or
hardware designer designing hardware
this is how humans reason about the
behavior the systems are designing
humans do not explore the state space
because humans can the human brain
cannot possibly cope with the state
space explosion problem now is there a
general form for implications
implications distributed in time and the
answer is yes it's based on integrating
boolean expressions and regular
expressions and I I know that there's
work going on here in code search using
regular expressions I assume i'll give
you a very brief overview of regular
expressions first let's start with
boolean expressions they're constructed
from equations and atomic boolean
variables using standard boolean
connective
and or not or whatever your other
favorite boolean connectors are and
quays equations are of the form boolean
variable equals of boolean formula or an
arithmetic variable equals an arithmetic
formula now the important thing here is
that we have arithmetic equations and
that's important because it's going to
allow us to describe both the control
and data path portions of the design
regular expressions regular expressions
have been around since I guess the very
early unix days with the inclusion of
the grep utility regular expressions
represent sets of strings in our case
there's going two sets of sequences of
boolean expressions regular expressions
are very widely supported the support of
egg Google and Microsoft there's two i
triple e standards i do want to mention
one particular standard and that's the I
Triple E p 1850 property specification
language which is derived from a
language called sugar which was
developed by IBM they also have
corporated within their language regular
expressions over boolean expressions in
fact what I'm about to describe is a
subset of this i triple e standard
although we've simplified the syntax now
traditionally regular expressions are
used to represent strings of characters
but we're going to use them to represent
sequences of boolean expressions now
we're going to enclose each boolean
expression within square brackets and
that will define a condition applying to
a single state or clock cycle now you
will also see and these will form the
characters of our the symbols of our
boolean expressions so we're going to
have I'm sorry regular expression so
we're going to have boolean expressions
enclosed in square brackets and we're
going to build up regular expressions
using these now you'll also see square
empty square brackets that the notes the
boolean expression true which is in
effect eight
describes represents a don't care state
sends a true holds in every state so
whenever you see empty brackets like
that look like this your that's going to
represent a don't scare state or don't
care clock cycle now our implications
are going to be of two forms we're going
to have a regular expression implying a
boolean expression in square brackets
what that means is the pattern of
behavior described by this regular
expression implies that this boolean
expression holds in the next state
following the set of the sequence of
states described by that regular
expression in this case we're going to
have a regular expression and enclosed
in square brackets we're going to have a
boolean expression implying another
boolean expression what this means is
the pattern of behavior described by
this regular expression and also
including this boolean expression within
that square bracket implies this second
boolean expression now I'll give you
examples of that here the examples i
listed a few slides earlier of
implications the scripture distributed
in time if we want to say that B holds
in every every clock cycle or every
state we've simply enclosed be in square
brackets if we want to say that if B
then if a then B 5 clock cycles later we
have a state in which a holds followed
by four consecutive don't care states
implying that be holds in the next state
so what this says is if he holds in a
state and one two three four five clock
cycles later be holds if we want to save
that if we want to say if a then B
within the next five states of clock
cycles we write a a is followed by not
be not be not be not be then by God in
the next state be out a whole if you
want to say that if a then B thereafter
we use the clean East are the cleaning
star represents 0
or more iterations of a boolean
expression so what this says is if we
have a followed by zero or more
arbitrary states than B holds in the
next state so what this says is if a
holds be holds one state later two
states later three states later and so
on and finally in representing if a then
B until see that's represented as a
followed by not see an arbitrary number
of times in other words if we haven't
reached c if c has not yet whole held
and in this and in the final state if we
have C has not yet occurred than B holds
so this is a very general formalism for
representing implications distribute in
time I call those temporal implications
so now rephrasing that that sentence we
had for analog systems we can now
rephrase that as each element of a
digital system is modeled by a separate
set of temporal implications and
mathematical tools are used to derive or
verify new temporal implications
describing aspects of the system
behavior not obvious from the initial
temporal implications but what are the
mathematical tools refer to here this is
the technology are called Toric's it
comes from combinatorics and the reason
I'm emphasizing combinatorics is because
the underlying mathematics is a body of
combinatorial mathematics and you can
see that mathematics in a paper that's
published in the Journal of
combinatorial Theory quite a few years
ago actually before I joined dick an
apple computer that's the fundamental
theorem there's also a much longer paper
that was posted on the web and archived
arxiv.org last year that builds on the
fundamental theorem and is a very
substantial body of combinatorial
mathematics in there that mathematics
supports free automated verification
tools and then for intention a verifier
a simulator now let me very briefly
describe the Toric's methodology there
are five steps in step one a digital
design whether it's hardware or software
expressed in a standard programming or
hardware description language is
converted into a set of temporal
implications step 2 now this is this is
a little counterintuitive so bear with
me each temporal implication of the
forum regular impression regular
expression implies boolean expression is
converted into the regular expression re
not be e now we've accomplished a couple
of things here we've gotten rid of the
implication and in so doing and we've
converted we've gotten rid of the
implication and we convert it into
something that's purely a regular
expression that will greatly simplify
that greatly simplifies the underlying
mathematics and the Underland the
algorithms now what how do we interpret
this this expression says that the
pattern of behavior are a must be
immediately followed by the boolean
expression be e which means that if we
have our e we cannot have not be e in
other words what this describes is a
disallowed or forbidden or prohibited
pattern of behavior and we're going to
do the same thing with the other form of
regular of implications we're going to
convert an implication of this form into
a regular expression of this form this
also describe this also
represents a disallowed or prohibited or
forbidden pattern of behavior now this
is necessary in order to get the matham
in order to apply the mathematical
machinery and the algorithms based on
that mathematics is this clear as this
is there anything confusing about what
we're doing here has the algorithms
don't have the lubrication the
algorithms could be designed to it's a
lot simpler to do it this way it makes
the mathematics simpler it makes the
algorithm simpler now from the
standpoint of the user the user at the
input and the output is going to see
implications but the mathematical
machinery internally is going to going
to be working with these regular
expressions representing disallowed
patterns of behavior step 3 now those of
you have taken elementary automata
Theory know that we can convert a
regular expression into an equivalent
finite state automaton and that's
precisely what we do but let me
emphasize that this finite state machine
is finite state automaton is nothing
like the finite state machine used in
model checking there they have a
combinatorial explosion here this finite
state atomic this finite state machine
grows linearly with the size of the
system the regular expression grows
linearly with the size of your system
and the equivalent finite state machine
also grows linearly with the size of
your system there is no state space
explosion now step 4 we take the atomic
on the finite state machine created in
step 3 we supply that to either the
Toric's inference engine or the torts
verifier and either tool both tools
return a new automaton a new verified
otamatone
which represents the property you're
either driving or verifying and the last
step we take that verified at on that
resulting automaton which was produced
by the inference engine or the verifier
we convert that back into a regular
expression and then convert that regular
expression back into a set of verified
temporal implications that in a nutshell
is a methodology towards methodology now
the inference engine let me briefly
discuss the three engines the three
tools inference engine is a fully
automated tool that derives or infers
new temporal implications from existing
temporal implications it can be used and
this is its most important the most
significant use of inference engine is
to derive the input the input output or
the black box behavior of a digital
design the i/o behavior is obtained by
resolving and deleting the hidden or
internal signals now resolution for
those of you have some experience and
formal logic is a it's an inference rule
form a very powerful inference rule
formal logic and what we've done is
we've adapted that resolution principle
to handle sequences of boolean
expressions as opposed to just
individual boolean expressions the
description produced by the inference
engine the i/o behavior mentions only
the input output signals the initial
input to the tool mentions both internal
and input output signals but what we
what tool produces as output mentions
only input output signals so using the
jargon of the field a behavioral model
can be automatically extracted from a
role model thereby supporting
encapsulation and information hiding I'd
like to give you an example for those of
you have a background in signal
processing you will know that first
stands for finite impulse response
filter and what I have here is a design
created by a very talented engineer he's
just extraordinarily clever and he came
up with a design in which he has
multiple multiply accumulates and the
result is that the computation for to
output valuable variable values are
distributed temporally over four clock
cycles and spatially over to multiply
accumulates it's a rather intricate
design i've actually simplified it he
had eight multiply accumulates but i
simplified it down to two so we have in
this example there are two boolean
variables reset start a frame and we
have 13 numeric variables and we have
for numeric constants this is a block
diagram a schematic of his design and
here we have and it was very
straightforward to take his design there
was no difficulty in translating his
design into a set of temporal
implications and we divided it into
those implications describing the
control and those in describing the data
path now what I have here on the left
are the actual temporal implications and
what I have on the right hand side is
the English language interpretation of
each one of those and so we have one two
three five control and we have all of
the remaining our data path implications
there's a total of thirty-three
implications here temporal implications
now we tape we then supply these 33
temporal implications plus a list of the
input output signals and the input
output signals are reset x and y so we
supply the implications and we supply a
list of the input output signals to the
inference engine and in about one second
inference engine returns a single
temporal implication and it is of this
form here now first of all let's look at
here's here's our implication here let's
look at what's being implied here we
have contained within these square
brackets a single arithmetic equation
this says that y equals the constant H
three times this so on and so on this is
for those who view of Stuart's study
digital signal processing you will
recognize this as an eight taps metric
for filter and now that's so it
implements an eight taps symmetric for
filter now let's look at the premise
what's to the left of the implication we
see here contained in square brackets
reset equals one in other words reset is
asserted in this state and then we have
one two three four following States
arbitrary States and then we have a pair
of states in parentheses with the
cleaning star which means that we can
have zero or more iterations of this
pair of states so at the first output is
produced when this is zero when when
there are zero iterations of this so
when we assert reset then one two three
four five states later we produce this
output
so five states after we assert reset we
get an output and this little couplet
here with the clean e star means that
we're going to get a new output every
other clock cycle after we assert reset
so we'll get an output five clock cycles
seven clock cycles nine clock cycles 11
clock cycles thereafter so both the
timing and the functionality of this
system are contained in this single
temporal implication so we have timing
we have functionality and so we've taken
all of these implications 33 of them and
by the way you you can look at these
temporal applications you can doodle on
them as this this designer did when he
designed the circuit he did not have
this tool he created a spreadsheet like
a spreadsheet of all of these head of
stretchy of various formulas and he
would stare at them and noodle on them
for hour after hour after hour
convincing him that in fact this did
implement what he wanted it to in this
tool in about one second we can produce
this representation of the input-output
behavior and it's exceedingly
non-trivial by the way deriving this
application now the verifier yeah
I'm are you so here you your ass or even
reset and then some number of don't care
is follow and I'm wondering why there
isn't a reset equals zero on the in
other words you said equals zero erasing
an excellent question and in fact when I
first did this I I I did in fact insert
those in there but it became rather
tedious to do that I have a special way
of indicating to the program that a
signal is asserted only once at the
beginning and reset is one of those but
you're absolutely right to be perfectly
rigorous about all of this I would have
you're exactly right i would have reset
equals one in this state and then i'd
have reset equals zero reset equals the
eye all of the other states would have
the reason i haven't done it it just
gets tedious it's it it it it clutters
it really clutters things up quite a bit
so what I've done is I've allowed the
tool I've allowed the user can specify
to the tool that a particular signal is
an initialization signal and it will
occur only once in the leftmost state
that way I don't have to clutter up my
diagram with all of these resets equals
zeros but that is an excellent question
in something that that annoyed and
annoyed me when when I first started
doing that's getting all of these resets
equals zero and I mean it was it was
tedious and it was just really
cluttering up the diagram and I says
when if there's got to be a better way
so I allow for the tool for the user to
specify to the tool that a particular
signal occurs once and reset is that
it's an initialization signal and it
will occur once at the very beginning
and it will not occur again and that
eliminates an awful lot of clutter the
verifier the paper has an example of the
clever little two-bit counter and how
the verifier works I decided to cut it
from my my my slides the verifier unlike
the inference in inference engine takes
just one set of implications describing
a design it infers new temporal
implications the verifier takes two sets
of temporal implications it takes one
set describing a design and another set
of temporal implications describing a
logical temporal property that we want
to verify and the verifier will then
take the the the set of temporal
implications and convert it into a
regular expression and then convert it
into a state machine and it will then
transform that state machine using this
logical temporal property and of course
and it will produce an output state
machine which gets converted back to a
regular expression which gets converted
to a set of temporal implications now
what's unique about this verifier
contrast other verifiers is in most
cases it gives you yes or no yeah yeah
it's verified no it's not verified but
what this can do is this fair fire can
indicate whether the property is
satisfied in its entirety or whether a
weaker version of the property is
satisfied or whether no part of the
property is satisfied so that a user who
is unsure of assistance exact behavior
can make an overly broad conjecture a
conjecture the user knows is false in
order to find a weaker version of that
conjecture that is true
and I'll just I don't have the diagram
in front of me but let me in the paper I
have an example of a 2-bit counter to
vid counter you know a freerunning 2-bit
counter and if you know anything about
2-bit counters it produces a carry every
four clock cycles well the conjecture
here the the conjecture was that it
produced a carry every clock cycle well
that's not true it doesn't produce a
carry every clock cycle but nevertheless
we know that's false but we we supply
that false conjecture to that 2-bit
counter and what it did was it
transformed actually I think I made him
say I said it transformed the the state
machine representing that is the design
it transforms the state machine
representing the property so what you
get is a new property so you supply it
with the conjecture that an output is
produced every clock cycle that gets
transformed into a new property which
says that a Kerry has produced three
clock cycles after reset and every
fourth clock cycle thereafter so we
started out with a conjecture that was
false and we ended up with a verified
property that was true and we're getting
very close to the end here the simulator
is again it's rather unique if you I'm
sure all of you most of you have done
used simulators in your life and this is
something that's always bothered me and
mild simulators and that is that third
opaque you have a massive input vectors
you get a massive output factors but
there's nothing in there and that mass
of vectors that tells you what what the
cause and effect is for example if I
have an anomalous output value I'd like
to know which input values cause
an anomalous output value well this
simulator uses is based on the inference
engine first of all you need the
inference engine in order to use the
simulator what you do is you use the
infant if you know what the signals are
you want to simulate you use the
inference engine to extract a set of
temporal implications describing the
behavior involving just those signals
and that set of temporal implications is
used to drive the simulator and now if a
user sees an open on an anomalous output
value the user can query the simulator
and say why does this particular signal
have this particular value at this
particular time and when the simulator
receives such a query it will identify
the implication that it used to
calculate that output value it will also
identify the input values appearing in
the simulation that caused the
implications premise to be satisfied it
will also indicate the input values
appearing in the simulation that are
referenced in the implications
consequence the thing on the right hand
side so we'll identify the input values
that caused the premise to be satisfied
the premise being what's on the left
side of your implication and it will
identify within the simulation the input
values that are referenced by the
consequence what appears on the right
hand side of implication
conclusions of this technology provides
a suite of mathematical tools to take us
beyond trial and error design and
digital systems and i want to emphasize
it again it's applicable to both
hardware and software I know the great
emphasis here at Google is on software
but again I want emphasize that this is
technology applicable to both hardware
and software the tools are fully
automated the input and output language
on the input side you can use week it's
it's straightforward to design
translators to translate a standard
programming language or hardware
description language into the language
of temporal implications but even
temporal implications are not that hard
to comprehend I mean if you know what
boolean expressions are if you know a
regular expressions are it doesn't take
much effort to understand the language
of temporal implications concurrency is
naturally expressed we used as
inspiration the approach of the analog
discipline disciplines like physics and
electrical engineering and I think that
if there's one key to that that the
technology is the way in which we're
expressing concurrency and it's been
said that we're entering the multi-core
era and I know Google is addressing that
thing you bought peak stream I like to
think of it is not the multi-core Arab
but the concurrency are the area of
concurrency Google and every other
company in the field is going to be
facing serious issues related to
concurrency and they must be they must
be addressed
and and because because of our approach
to concurrency the model for a digital
system grows linearly not exponentially
with the size of the system what are the
benefits of this technology increased
designer productivity for example this
engineer who noodled over his designed
for hours and hours and hours trying to
make sure using his reasoning powers
trying to make sure that it did what he
thought it did well this could
short-circuit a lot of that time and
effort spent noodling over a design it
also reduce it doesn't eliminate but it
reduces verification cause and it
improves time to market and ultimately
it leads to systems hardware and
software that are more reliable and more
secure thank you
pred this notion that you got from Italy
about concurrency primitives that are
closer to the way the real world works
it seems like a really good idea that
map's well on to the small examples of
hardware and designing filters and stuff
like that ed is a digital signal
processing guy to like like you and I
are to some extent but when you get into
the larger context of a computer system
with software you tend to have this
thing in their call to ram we're sort of
any part of your system can screw up any
other part by putting something in the
RAM where it shouldn't and there's this
sort of infinite potential for
long-range interaction between things
that shouldn't interact how do you how
do you capture that model that or make a
design methodology where you can write
implications that guarantee that you
don't have that class of problem I I
have begun work on looking at modeling
Ram let me just say that this is a work
in progress this there's still a lot of
work that has to be done on real-world
examples but you've got to start with a
foundation that addresses things like
concurrency in an appropriate way an
item I don't claim I have all the
answers I haven't tackled huge problems
I've looked at reasonably small problems
but I think it's imperative that the
industry I don't know if it's google but
the industry somebody somewhere has to
start tackling these problems we have to
get beyond trial and error there has to
be of mathematical foundation I can't I
can't answer your question on one
researcher I can't there's only so much
one person can do I think that this is
the foundation for the right way to do
things I think this is the foundation
for the right way to address concurrence
and whether Google likes it or not
you're going to have to start addressing
these issues and peak stream is and what
would Intel know what AMD are doing or
just the first timid timid steps in this
area but I do have to acknowledge my
timing hasn't always been right twenty
years ago i was i was working with dick
at apple and i thought all of this stuff
was just right around the corner you
know that you know i thought you know
member larry tesson Larry Tesler who was
VP advance of advanced technology you
know he was excited about this
technology by the way this technology
actually we kind of shifted into it's
all related there there's a common
thread to the work I was doing at apple
in reconfigurable hardware and these
tools and that common thread is
concurrency in fact it's it's comment
everything I've been doing but I thought
the industry was about you know was
which is right on the cusp of moving
towards and whether you want to call it
multi-core reconfigurable systems
whatever back Oh late 80s Early 90s yeah
we're still in the cus however what was
what what had have been happening for 50
years was we were just cranking up the
clock cycle well you can't crank up the
clock anymore and now the industry
everyone the mainstream players the
intel has to face up to the fact for
that concurrency is something that has
to be addressed and at least on the
theory side on the mathematical side
i've i've scanned the horizon i've
looked at what's available out there and
i don't believe that their improved
their improving the folks up at sr i--
what they're doing they've been around
for 30 years in fact i applied for a
position there 30
ago as head of that group and get it
because my vision was very different
from their vision they want to do
something very much akin to what
mathematicians do when they prove
theorems it's wonderful stuff if you
have that bin if you're you like proving
theorems but it's not it's not for the
masses it's not for the average engineer
and I look at model checking and I think
that any approach that involves
exploring the state space it's just it's
a dead end it's just not the way to go
and maybe maybe there's another approach
they're up there somewhere that's
occurred to no one that's who knows but
of the approaches that I'm aware of I
think that this has the best handle on
addressing issues of concurrency I'll
run the slides you mentioned that you
could you take the design file and then
the temporal implications file and you
can run some sort of formal verification
to ensure that design files
mathematically yeah I'm correct can the
design file be what form as the design
file can it be more traditional type
designs being verified against the
temporal implications file or does it
have to be is it a mathematically
constrained design file or the design
initially can be a program written in C
okay or a very very Verilog or that's a
hardware description language and I
don't know what you when you write see
here pretty much I love or whatever C++
now
at the front end the user does not have
to see the temple implications at the
back end if you're using the the
inference engine to derive input-output
behavior I'm afraid that that's
typically going to involve the regular
expressions see doesn't it you can't
represent regular expressions and see
however I there was a whole list of hey
you know you've got your google love you
know on the on the input side you can
have C or Java or whatever but in the
output side you need something with the
ability to with the ability to represent
regular expressions well well the grep
is only a you tits it's just the utility
but these are languages POSIX which is
what google code search is based on
these are languages so on the output
side you need something expressive
enough something that that encompasses
regular expressions the input side you
can have Java Sea or whatever but on are
those languages turning complete kids
you are those languages Turing complete
or no no we're not we're not doing turn
complete yet okay everything we're doing
here is regular that's an interesting
research topic how much of this i mean
with finite state automaton i mean you
can represent regular you know regular I
mean you know in the hierarchy that's at
the bottom but the top is turned
computable I've given a little bit of
thought on how one might extend this to
realm beyond regular area of the
context-free context-sensitive and
Turing computable that that's strictly a
research topic ok all right thanks sure
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>