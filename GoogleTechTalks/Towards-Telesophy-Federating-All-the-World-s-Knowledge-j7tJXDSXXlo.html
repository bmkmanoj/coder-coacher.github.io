<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Towards Telesophy: Federating All the World' s Knowledge | Coder Coacher - Coaching Coders</title><meta content="Towards Telesophy: Federating All the World' s Knowledge - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Towards Telesophy: Federating All the World' s Knowledge</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/j7tJXDSXXlo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is my attempt to increase the
sartorialist you have a coat on that's
true Greg Chesson gets two points for
for showing up with a coat no it's it's
a real pleasure to introduce bro shots
to you I've known Bruce for rather a
long time my first introduction to him
came as we both began getting excited
about digital libraries and the
possibility of accumulating enormous
amounts of information in digital form
that could be worked on manipulated by
process through software that we hope
would augment our brainpower so Bruce
has been in the information game for
longer than he's actually willing to
admit I suspect he's currently at the
University of Illinois Champaign Urbana
and as you will remember that's also the
area where the National Center for super
computer applications is located Bruce
was around at the time when Marc
Andreessen was was doing work on the
first browsers of the mosaic versions of
the browsers derived from Tim
berners-lee's work actually the the one
thing that Bruce may not realize he gets
credit for is teaching me how to
pronounce center of the disc elegans I
looked at it before and I couldn't
figure out maybe I didn't even say it
right this time but this is a tiny
little worm that consists of 50 cells
and it was the first living organism
that we actually completely sequenced
the genome for and then we got
interested in understanding how does the
genome actually reflect itself as this
little worm develops from you know from
a single fertilized cell so Bruce
introduced me to the idea of collecting
everything that was known about that
particular organism and to turn it into
a database that one could manipulate and
use in order to carry out research well
let me let me just explain a little bit
more about his background and then turn
this over to him because you're here not
to listen to his bio but to listen to
what he has to say he's currently
director or something called Kenneth CA
ni
so I thought it had to do with dogs
until I reread it it says community
architectures for network information
systems that's why they let me in the
building I'm sorry that's why they let
me in the bills that's why they like
because along with the other yes canines
that are here it's at the University of
Illinois Champaign Urbana and he's been
working on federating all the world's
knowledge just like we are by building
pioneer research systems and industrial
and academic settings he's really done a
lot of work over a period of 25 or 30
years in this in this domain and he the
title of the talk uses the term to
losophy which he introduced as a project
at belk or in the 1980s later on he
worked at you UIUC on something called
deliver de li ve R and now more recently
on semantics and that's the reason that
I asked him to come here he's working on
something called be space which is
spelled EEE as in the little buzzing
organism this is an attempt in mind as I
understand it but I'm to learn more an
attempt to take a concept space and
organize it in such a way that we can
assist people thinking through and
understanding more deeply what we know
about that particular organism so this
is a deep dive into a semantic problem
so I'm not going to bore you with any
more biographical material except to say
that Bruce has about 9 million slides to
go through so please set your modems at
50 gigabits per second because he's
going to have to go that fast to get
through all of it I've asked him to
leave some time at the end for questions
and I already have one queued up so
Bruce with that rather quick
introduction let me thank you for coming
out to join us at Google and turn this
over to you to teach us about semantics
thank you I get I have one here so you
can just turn yourself thank you
I was asked to give a talk about
semantics which I supposedly know
something about so this is going to be
both the talk that's broad and deep at
the same time and it's going to try to
do something big and grand and also try
to do something deep that you can take
away with it so that may mean that it
fails completely and does none of those
or maybe it does all those and I've
actually been giving this talk for 25
years and you know now of course it
doesn't work no it's am I not pointing
it in the right place I'm pushing it but
it's not going oh there it goes okay
sorry I can you just flip it back there
sorry about that small technical
difficulty but the man behind the
curtain is fixing it so I gave this I
gave this talk first more than 20 years
ago en the hot Silicon Valley research
lab that all the grad students wanted to
go to which was called Xerox PARC and I
think a few people actually have heard
of Xerox PARC it's sort of it sort of
still exists now we went down completely
there we go thank you very much and I
was pushing this idea that you could
federated search through all the world's
knowledge and they the uniform reaction
that was boy that would be great but
it's not possible and I said no you're
wrong here I'll show you a system that
that searches across multiple sources
and goes across networks and does
pictures and texts and follows links and
i'll explain each piece about how it
works and then they said that's great
but not in our lifetime well ten years
later was mosaic and the web and 20
years later I'm delighted to be here and
all of you have actually done it you've
done all the world's knowledge to some
degree and what I want to talk about is
how far are you and what you need to do
before you take over the rest of the
world and I die which is another 20
years so what's going to happen in the
next door
years and the main thing I'm going to
say is a lots happened on tella but not
too much on safi so you're halfway to
the hivemind and since I'm working on
honeybees at the end you will see a 50
of honeybees and here are something
about hide mine but it'd be very short
basically if you look at googles mission
the mission is doing a lot about access
and organization of all the world's
knowledge and actually to the degree
that's possible you do an excellent job
about that however you do almost nothing
about the next stages which are usually
called analysis and synthesis solving
actual problems looking at things in
different places combining stuff and
sharing it and that's because if you
look at the graph of research over the
years we're sort of here and you're
doing commercially what was done in the
research area about ten years ago but
you're not doing this stuff yet so if
this last few system was about here
mosaic was about here those are the
things that searching across many
sources like what I showed we're really
working pretty well in research labs
with a thousand people they weren't
working with a hundred million but if
Google's going to survive 10 more years
you're going to have to do whatever
research systems do here so pay
attention this doesn't work with
students with students i have to say i'm
going to fail you at the end but you
have a real reason to monetary reason
and a moral reason to actually pay
attention so back to the back to the l1
so we're going to I'm going to talk
about what are different ways to think
about doing all the world's knowledge
and how to go all through all the levels
i'm going to do all the levels and sort
of say you are here and then i'm going
to concentrate on the next set of things
that you haven't quite got to the two
particular things i'm going to talk
about our scalable semantics and concept
navigation which probably don't mean
anything to you now but if I do my job
right 45 minutes
actually now 10 of them are up so 35
minutes from now they will mean
something and at the end I'm going to
talk about suppose you cared about this
enough to do something what kind of big
thing would you actually do I sort of do
these be one of the kind pioneering
projects with stuff that doesn't quite
work just to show it's really possible
so the overall goal is you probably all
grew up on reading cyberspace novels is
sort of plug in your head and being one
with all the world's knowledge trying to
sort of get the concepts in your head to
match whatever is actually out there in
a way that you can get what you want and
the problem is as over time what the
network can do has increased so in the
can't say the old days event in the good
days people worked on packets and tried
to do data transmission the the error
that I sort of what worked mostly again
was an object area where we try and do
we information people to do text to do
pictures all the action in big research
labs now is on concepts is on trying to
do deeper things but still that work
like these two they work everywhere so
you don't have a specialized AI program
that only works for tax income taxes
that's not good enough no Google person
would ever do something that we worked
in one case unless there was a huge
amount of money behind it I'll stop
making money comments but the food is
great here
so this is one common layout and there's
four or five others which in the absence
of time i omit but if you want to talk
to me afterwards there's lots of points
of view about how to get from here to
there where there is 0 ease all the
world's knowledge and here is what ever
you can do now and depending on what
point of view you take it's possible to
go to the next step differently because
you have a different orientation so the
one that I'm going to do in this talk is
the linguistic one which usually goes
syntax structure semantics pragmatics so
syntax e is what's actually there like
an actual set of bits in a file a set of
words in a document structure is is the
parts it's not the holes so if you parse
something instructor you can tell that
this particular thing is a person's name
this is the introduction to a paper this
is the methods part you can tell what
the parts are and you can search those
differentially semantics is when you go
inside and you try to get something
about the meaning and as you'll see
people are pretty much given up on doing
real meaning and they pretty much try to
do rather than meaning they try to
context tooth what's what's around it in
a way that helps you understand it and
actually the when when Google was a
research project and the people that
started it were actually on the Stanford
digital library project I was running
the Illinois digital library project at
the same time they said there's enough
context in web links to be able to
really do something and there were a lot
of people that said no web links are
made for all sorts of things and they
don't have any semantics and they're not
useful at all but obviously they were
wrong enough to make this building and
employ all of you the real goal is down
here in doing actual reality in doing
pragmatics with so-called pragmatic
pragmatics is sort of when you use
something so it'sit's task dependent the
meaning of something is always the same
so if this is a gene that that regulates
cancer it always does that but lots of
time to test your working on varies what
you're interested in what you know and
I'm not going to say very much about
pragmatics because people haven't gotten
very far on it in terms of doing a big
grand scale but I actually know quite a
bit about it if you really wanted to
solve health care for example you have
to go down the pragmatic route and try
to measure people with as large vectors
you can possibly get and again if people
are interested that's a topic I'd be
happy to talk about but it's it's off
this particular talk this particular
talk is about Federation as I said so so
what does it mean the Federated each one
of those at each one of those levels so
to do syntax Federation which is what
the philosophy system pioneered and for
the most part what what Google does in
the sense of federating all the web
sources that are that are our crawled is
it tries to make essentially send the
same query into every different place so
true syntax Federation which is actually
what Celeste we did but not really what
Google does is you go you start at your
place and you go out to each one of the
sources and you have to remember where
they are on the network and they might
go up and down and so you might have to
retry them and you have to know what
syntax the queries need and when the
results come back you have to know how
to handle that you have to do a lot
about eliminating duplicates for the
when the results come back so it's a
very common problem is you you get you
send out a query to try to get a certain
beetle song and you get back 5,000 of
them but they're all slightly different
you know and they're in different
languages and they have different syntax
merging those all together is really
complicated so syntax is up that's what
syntax Federation is structure
Federation which is what this deliver
was the DLI the digital library
initiative project that I ran at the
University of Illinois and it took in in
about engineering literature it went out
to ten major scientific publisher sites
on the fly and allowed you to do
structured query so you could say find
all the papers in physics journals that
are within the last ten years that
mentioned nano structures in the figure
caption in the conclusion so you're
using the parts of the papers to make
use and at least scientists make a great
deal of effort in doing that in order to
do that you have to figure out some way
of making the the markups uniform so you
have problems that that you just started
to see and in in syntactic world we're
like who's an author if you have a
physics paper that has a hundred authors
which one of them is the author it might
not be any of them actually it might be
the organization that did it or if you
have a movie who's the author of a movie
is it the is it the the producer the
writer the star the director so there's
a lot of problems there and how you do
the mark-up uniformly and how you make
different values the same for the most
part structure has not made it into mass
systems yet although there's been a lot
of attempts to try to make languages for
structure like the Semantic Web that
midnight we're talking about beforehand
but the amount of correctly marked up
structured text is very small right now
so if you were going to use it to search
the 10 billion items that you can crawl
on the web now you wouldn't get you
wouldn't get very far semantics
Federation which is what I'm going to
talk about today mostly is about a
completely different topic it's about
going inside and actually looking at the
phrases and fig
out the meaning as much of the meaning
as you can and then when you have many
small pieces trying to match something
that's the same here it is something the
same here and doing that uniformly is
the is that is the job of semantics
Federation so let me now go into the
first of two technical topics so the the
first topic I'm going to do is is how do
you actually represent the things and
that's going to be a little slow going
and then i'm going to give some examples
of if you're able to get this deeper
level representation this deeper level
structuring what kind of system you can
build and it's in a somewhat specialized
domain it's in biology and medicine
because uh well if your professor and
you work at a university that's where
you get money to work on things you
can't get money to work on the kind of
things that are arbitrarily on the web
so scalable so we're now into scalable
semantics I've been using this for ten
years and every once in a while someone
will stand up and say that's an oxymoron
and it doesn't make sense because
semantics means really deep and scalable
means really brought in those pull in
opposite directions and I said yes you
understood what the problem is so in the
best case in the old days what it used
to mean is you do deep what semantics
used to mean is you do deep meaning so
you had a deep structure parser that
would go in and figure out yes this
document was on operating systems that
only work on this class of computers and
only solve this class of physics
problems so it's on a very narrow
detailed topic and there were many many
AI systems made that did that what
happened when the government started
putting large amounts of money into it
so most of this most of this got
developed in the the base technology got
developed in the DARPA Trek program
tried to read newspaper articles looking
for uh what would now be called
terrorists and what they found basically
is the deep programs we're very now
they only if you train something to
recognize income taxes you train
something to recognize high-powered
rifles it wouldn't help at all in the
next one and there were just too many
individual topics to try to pick out the
individual types of sentences and
individual slots so but what happened is
the broad ones beat out the deep ones
when the machines got really fast and
when it became clear as and I'll show
you some some machine curves when it
when it became clear that you could
actually parse noun phrases arbitrarily
out then people began using noun phrases
when it be clear became clear you could
do what are called entities sorry I'm
covering up entities in other words you
could cut you could say this phrase is
actually a person this phrase is
actually someone that lives in
California then people started using
that and basically what what happened is
semantics change from being we know
everything about this particular topic
in this phrase means one its meaning
type 869 to we have 20 kinds of entities
and this is a gene and it occurs with
this other gene so we'll say if you
search for this gene and it doesn't work
you should search for this other one and
I'll show you lots of cases where that
sort of a guilt by association really
helps and I'm not defending it
necessarily as being real semantics I'm
defending it as something that you can
do everywhere and that's usually so so
the upshot is this is an engineering
problem it's it's a it's a question of
if you could do deep parsing and say yes
this person wasn't they it's true they
said they were interested in ice cream
cones but they really meant pine cones
when they said cones then you would do
that but it's generally not possible to
do that except in very isolated
circumstances so you end up thinking
globally thinking about all possible
knowledge but acting locally I guess
this is a green building so I'm allowed
to make this kind of joke so you look at
a small narrow collection and analyze it
the context what occurs with each other
very precisely and do something there
and that creates one good situation in
other words it means now you're able to
go much deeper and I'll show you lots of
examples of going much deeper but it
creates one bad situation which is a
traditionally information retrieval
works like dialogue did in my and my era
or like Google does now you take all the
thing you can get and pile it into one
big huge server farm and then you search
it and you index it once and one big
index and you search it well the problem
is if you want to go deeper and
semantics that doesn't work because you
mix together too many things you have to
unmix them and then you have to worry
about to get from here to there so you
change you changed a a central problem
into a distributed problem with all the
hard features that go with distribution
what this is doing in terms of if you
want a physical analogy since I taught
for many years I taught at library
school the way indexes work in the real
world is for really big topics like if
you have a lecture engineering there's a
society that is big enough and and
well-defined enough to employ people to
tag every topic so they say here's an
article about Windows this one is about
operating systems here's an article
about Windows this one is about heat
conservation and a person is looking at
that and out of their selection of all
the topics they say which topics of
things are on that work fine as long as
most of the information in the world was
in these small these large but fairly
small number of well-defined databases
that's not the world we're living in now
we're mostly living in this world so
there still are a very large number of
big formal databases that are done by
hand but nearly all the databases nearly
all the collections
are these informal ones with communities
or groups or individuals and the the
advance of crawling technology that's
been able to take all these and collect
them all together into one big place has
actually made the problem worse because
now there's not only apples and origins
and pears all together but there's lots
of things that aren't fruit at all and
aren't really anything but they're in
there so there's many different things
that you don't know how to deal with and
you have to do something automatically
with them there there's it's not the
case that you can get my daughter who
keeps track of all the cats on the block
and has a website with their pictures
it's not the case that you can get her
to employ a professional curator from
the library school who will who will tag
those correctly so that someone who's a
cat fancier in the next town can see
them that's not true need some kind of
automatic support and so that's what I'm
going to talk about the automatic
support I'm doing okay for time okay so
so here's the first of the there's two
things there's entities I'm going to
talk about entities and I'm going to
talk about concepts so here entities
what entities are is trying to figure
out what type of things something is so
one way is you have hand tagged XML like
the mark-up like the Semantic Web so
they take a particular domain and they
say they're 20 types here and we'll mark
up each document correctly so if we're
in humanities that might work pretty
well this is a person this is a place
this is a type of Vaz this is a tight
this is a time period in Roman history
if you're out on the well being that in
that situation where 90% of the stuffs
informally then even if you even if
there was a systematic set of types the
people aren't going to do it so so if
you if you have well marked up and ones
you're going to use them but if you
don't then
have to do something automatic so the
thing that tends to work automatic is to
try to tag things by machine with
training sets and I'm going to say a
little bit about what that means so
first you go into the document and you
pull out the phrases so you don't do
whole words and in fact over time the
experimental system might built have
gotten better the more you can get away
from words and change them into whole
phrases that are are the equivalent
phrase that works in that particular
domain and right now search engines
don't do that that that's a big part of
the problem then you have to recognize
the part of speech is it a noun or a
verb or an object again 10 years ago you
needed a specialized grammar and only
worked in a particular subject now
there's things trained on enough of
machine learning algorithms trained on
enough things that you can get very high
accurately up in the high 90s with parts
of speech and in fact they're actually
systems and you can tell this was sort
of a secretly funded by the CIA under
some some other name that recognized
person places and things pretty
accurately and so if you want to
recognize newspaper articles and
automatically tag these correctly it
does pretty actually does a pretty good
job and again commercial search engines
can not tend not use those so here's an
here's an example of entities in biology
and these won't mean very much but
they'll give you the feeling so here's a
here's a kind of functional phrase a
gene is a type of an entity and it codes
a chemical so here's an example the
foraging gene encodes a cyclic GMP
protein kinase so this is 1 this is one
of the entities and this is the other
entity and in scientific language things
are very regular eyes so there's lots of
sentences that are that that are
actually that easy or here's another one
chemical causes behavior here's one
that's a little harder I tried to put
one little harder this one says gene
regulates behavior but that's not in the
sentence
what's actually in the sentence is this
gene which is an ortholog of this other
gene so it doesn't say directly it says
indirectly it's a gene is involved in
the regulation which is not the same
phrase it regulates so you have to do a
little bit of parsing to get to get a
phrase like gene regulates behavior but
the natural language technology is now
good enough to do that accurately and I
did do a little bit of prep and look at
some of the commercial systems that
we're doing this but if you if you want
to ask the question about those later
I'll make a comment but they're all
competitors are not Google so I didn't
want to say it up front the the last
comment i'm going to make about entities
is they come in different varieties and
that means that sometimes you'll do them
and sometimes you won't so there's some
of them and again these are biology
samples there some of them that are just
straight lift so the names of organisms
like honey bee or fruit fly are almost
always exactly those same words so those
are easy entities the tag at very
accurately things like jeans or parts of
the body vary somewhat but they're often
her tag phrases let's say this is the
part of a body and here it is it's a
wing or this is a gene and it's the
foraging gene and so they're often tags
there if you get training sets you do
pretty well then there's really hard
things like what kind of these are sort
of functional phrases what kind of
behaviors on honey bee doing what kind
of what kind of function does the
computer operate with those ones are
almost always different so you need a
really big training set to do those
accurately if you are going to try to do
entities across all the world's
knowledge you would have two problems
and I think that's the last thing I've
been saying this yeah the first is you
would have to try to make a run at the
hard ones or at least say well we're
only going to do these because that's
all we can do uniformly the second is
you have to realize that the entities
are different in each major subject area
so the biology
they're not the same as the medicine
ones which are more disease like and the
medicine ones aren't the same as the
physics wands and physics ones aren't
the same as the the grocery store ones
but my guess is there's a relatively
limited number of popular ones and if
you're back in the same style that Oh
trying to classify all the web's
knowledge like Yahoo that used to be
Yahoo's main main strategy for instance
that there are a couple hundred really
important ones and a couple of thousand
big ones and so if you had enough money
and enough expert teams and set each one
up to making training sets you could
actually do entity use all the way
across a research project can't muster
that except in one small area so that's
all I'm going to say that in these now
let me explain just a little bit about
what you do with entities and then give
a big example so what you do with
entities you know you might think you're
going to answer questions with them and
that's what the commercial systems are
doing and you can sort of answer
questions so you can say this gene seems
to affect this behavior in this organism
so you can say what are all the things
that affect foraging and insects and get
out lots of this is sort of you have a
relational table you take a document and
change it into a relational database
that you can answer that kind of
question but there's lots of kinds of
questions you can answer what you can do
is after you extract these these
entities these units is you can compute
these contacts graphs you can see in
this document how often do these two
things occur together and that one you
can get a lot of mileage from because if
you try to search for this one and it
and you can't find it you can search for
this other one or if you're trying to
search for this one and you can't find
it you can go down the list of the ones
that commonly occurs with and it's sort
of a suggestion facility people that
watch search in libraries what they
typically comment on is people don't
know what words to try they'll try all
the words they can think of and then
start searching dictionaries or looking
on other papers or asking the people
next to them so as a since you can
automatically do suggestion by making
this graph of all the words that are all
that sorry all the entities that are
related to all the other entities in
terms of how often they they occur
together in a in a collection then you
can use it for a suggestion this is my
computer engineering slide the other
unusual feature about Google that people
didn't predict is could you build a big
enough supercomputer to handle 10
billion items and dialogue would have
said no because IBM will not sell you
that many platters and that big thing
well what they had what they didn't
realize was the rise what the rise of
PCs would do if you hook things together
and you could partition the problem
enough the research people hit that same
that same curve in a decade earlier so I
was trying to do these relations this is
my sort of six or seven year history
these are all how big a collection you
can do and find these these entities in
these relations basically on
workstations so this is like a son to
and that's a son three and this is a
network of some threes about ten of them
this one is discovering supercomputers
at NCSA and you could get a thousand all
at one time that made a big difference
and it meant in fact this was a big hero
experiment it was the first
supercomputer computation in information
retrieval and for quite a while it was
the biggest computation at NCSA had ever
done they couldn't figure out why you'd
want to integrate all the world's
knowledge why would anybody want to do
that I think in 1998 Google was probably
about 10 employees so that question
hadn't come up yet the number of
articles in MEDLINE was still much
greater than number of articles on the
web and so so here here's what that
computation was like it had about 200
80 million concepts so that number was
big then it's now small however if you
fast forward to today the machines are a
lot faster so the server i just bought
for $25,000 has more memory than that
supercomputer eight years ago and these
are big memory computations you can
guess it's got a big matrix inside that
has like all the phrases versus all the
phrases and how often they occur so the
more physical RAM you have the better
and what it turns out is if you're able
to put a connection graph this so this
is a graph of which terms are related to
which other terms all in memory and it's
it's a it's a nice graph like a small
worlds graph where which which looks
kind of like this so so there's a group
here that's all sort of connected and
another group here so it comes in groups
and that tends to be true of just about
any kind of text that people have seen
then you can find all the interrelations
really fast because like you don't have
to look at this one versus this one
because you know that you can sort of
stop here so there's a way of ending the
propagation and what that means is you
can now do things on the fly while you
wait so you don't have to pre-compute
the collections anymore which is what we
had to do before you can do a search
make a new collection and then make it
semantics then make it deep you can
cluster it on the fly and the little
chunks you can you can find these
interrelated graphs while you wait and
that that's why you wait with you know a
twenty-five-thousand-dollar server if
you had something the size of Google you
could not only do all the world's
knowledge which isn't isn't that that
much proportionately bigger but you
could also do deeper and so that's why
I'm now going to show you what a real
concept space system looks like
so that you get some feeling as to how
different the interaction is so
generally there's two things in the
space system one of them is called
Federation I've been talking about that
before it's how do you go from one
collection to another and the other is
called integration it's if you have an
entity what can you go out to we're
talking about going across collections
and I didn't mean to say this was
replacing IP it's everything is life he
is under everything but what I meant is
it's replacing words so if you had this
was at all this was the first inner
space system the one darker paid for
there aren't words in this anymore when
you point to this you get not you get
that whole phrase simple analgesics and
all the things that are equivalent to it
phrase wise after you do all the
linguistic parsing so it looks like a
bunch of words but it is and it's a
bunch of interviews a idiot concepts and
those are uniformly indexed across all
the sources so you can go from simple
analgesics here to all the phrases that
all the the concepts all the phrases
that it's nearby to the ones that are
nearby there to the documents to which
little cluster it's in you can sort of
go from concept the concept the concept
across all the different sources and the
main reason I showed this was to was to
just show that words don't exist anymore
you've got this deeper level thing which
I tried to convince you earlier was
possible to do and also because this
DARPA project broke up at night in two
thousand just before 911 decided they
yanked the plug and they didn't want to
help an analyst anymore it's five
seconds and every person on the project
went to work at Microsoft so it's
entirely possible that windows 2010 is
to have all this stuff in it yes
question say which one this one it is
actually and i will let me postpone that
because i'm going to answer it better
later but basically each one of the this
it's taking the document collection and
grouping it into individual groups of
documents which are have a similar set
of phrases in them and this is just a
bad graphical representation of it but
i'll give a good a good example of it
later so yet yes it's it's quite
meaningful and you'll see in the session
what what its utility is so what i'm
actually going to talk about now in the
in the last five minutes of my talk is
this abby space system and it is about
honeybees are you allowed to have cute
pictures and cute buns yeah see the
college students don't ever laugh at
this but i always thought it was funny
behaviors all right so much for that it
must be age thing so the point of this
system is you make many many small
collections and you know something and
you want to use your terminology and
your knowledge to go somewhere else so
you want to go from molecular biology in
2 b's and de flies into neuroscience and
so i'm working with the person that
actually is the national lead on the
honeybee genome what it does inside is
basically uses the scalable semantics
technology to create and merge spaces
and you'll hear a lot about spaces in
the next five minutes so i won't explain
right now to try to find stuff so it's
complete navigation complete abstraction
but finding things when you don't know
where you what you started with and
space is a paradigm not a metaphor I
hope I'm not offending any user
interface people i'm not sure if dan is
still sitting in the back yeah in other
words there really are spaces in there
you take a collection you make it into a
space you can then
merge two of them you can pull out part
of it you can break it in two parts and
make one part of that the whole space so
it's like you have all the world's
knowledge and you're breaking it into
conceptual spaces which you can
manipulate you personally plus you can
share them with other people so it it
has quite a different character than
you're trying to do a search and you get
a set of results back this particular
one does do entities very universally
but it only does concepts and jeans
because that's all this subject area
unit so please don't criticize that
particular one it was chosen narrowly
because we we wanted to at least have
one that did those uniformly and these
are the main operations I'm now going to
show you very quickly through a session
and if you go to the be space site which
was on that bag its be space UIUC edu
you can use the system and beat it to
death assuming you can read medline
articles which you may or may not be
able to so there's extract is going to
take a space and figure out what all the
special terms that distinguish that
space and have a way of searching
mapping is going to go back the other
way it's going to take a space and break
it in two parts and then you can turn
each one into a space itself this is
space algebra and this is the
summarization if you have a finding
entity it does something with it so this
example probably you don't care but it's
looking at multi havior of maturation
it's looking at a honey bee as it grows
up it takes on different societal roles
it takes care of the babies it goes out
and forages for food and looking at that
across different species so it's a
complicated it's a complicated question
it's not one that there's a well-defined
answer to okay so now we're in the be
space system which is running right now
so you type behavioral maturation you
choose a particular space that was
already made out it's in sex it's about
a hundred thousand
and you do browse so that gets about
seven thousand articles which are here
which is too much to look at and
probably the problem the problem was
behavioral maturation wasn't the right
term so the question is the first thing
the system is doing is this extract
thing that tries to to go in and analyze
the terms that the phrase is and get out
a more detailed set so that that's
issuing extract it automatically takes
them up pulls out the most
discriminating terms in that collection
and you usually have to edit it a little
that's what I did here then you can take
those back and and browse again i'm now
not it's now not working oh did it go
yeah i'm sorry there it is ah and you
got more items 22,000 sorry
he the problem was you narrowed it down
too much you didn't actually get the
articles about behavior maturation
because a lot of them didn't say it what
you want to get is the all the things
that might be interesting and then
narrow it down so that first one was
trying to expand it a little bigger it
was doing sort of a semantic version of
query expansion now the problem is this
one is too many to actually look through
and now I'm going to go back the other
way and sort of answer the question that
was asked before so this is
automatically taking that collection and
while you wait it's breaking it into a
number of different regions here it's
about 20 some of them are off the page
and the regions tend to be there they're
sort of these small worlds regions it
tend to beat white tightly on the same
topic the topics are kind of hard to
describe but the topics are because
they're automatic they're not on some
well-defined term but they tend to
cluster together well the thing to
notice is this was done while you wait
even with this small even with this
small server so the collection was made
on the fly and this mapping was done on
the fly this is an interactive operation
there the pre-computation wasn't about
this you didn't have to can this so we
take this particular region and now
we're going to operate we that it's this
this is that that just that one cluster
now we're going to save it and see now
it's a fully fledged space just like all
the previous ones so we we are sort of
navigating through space we found this
little collection is what we want and
now we're now we're making it into a
space ourselves because we want we this
one is now well defined it's about
behavioral maturation and a large about
insects and we wanted to look at
multiple organisms so now we're going to
start doing space algebra we're going to
start taking this and merging it with up
with other things so here here I took
took the new space i just made Adam
intersecting it with an old space and
currently that's just finding the
documents in common
but we're now working on fancy or data
mining to try to find other patterns so
here's though here's the 11 that here's
that sorry the 21 that have that feature
and if you look at this article this
article is in fact about some basic
receptor about drosophila which is a the
fruit fly insect but it's about well I'm
sorry it's not fishing machine marine
crustaceans are like lobsters but it's
it's some other it's some something that
lives in the sea then since you now
found something at the intersection of
those two what you really want who was
described the genes here you can point
to this gene this was entity recognized
automatically in green and try to
summarize it and so here it summarized
you can see the summary parts however
the problem is this this this particular
intersected space has hardly any
documents in it so there's not very much
to summarize you you did get the right
gene but you didn't summarize it against
the useful space what you want to do is
go switch this term over into this other
space into the drosophila space which
has like fifty thousand articles and
then summarize it again so here's an
article that has it in it this one you
can see has more more entities
automatically selected and then here's
the gene summary against that space
again done on the fly so we this is a
general summary facility that if you
have an entity and you have a space so
you have a specific term and a
collection you want to see well what's
known about it in that collection this
is something this is the type of summer
you can do while you wait it's a
scalable one you can break it into the
well-known categories you could find the
scent rank order the sentences in those
particular categories this kind of like
a new summary but it's a semantic type
new summary and then if you went into
that you would see that there are lots
of there's lots of entities recognized
here's all the things in green were done
automatically
and if you point it to these you would
then summarize those in this space or
you could go off to another one
summarize it so each I want to just say
each one of these main features was done
dynamically on new collections while you
wait and you can basically expand the
searches you can take asserts it's too
big and break it into pieces you can
make a new space and and do algebra to
do intersection on it or if you find a
particular energy you like you can
summarize it in different ways and those
are examples of the kinds of things that
you can all do automatically so the
message is these are all general and if
you have to do biology your sort of work
up towards the interspace where you're
intersecting all the spaces using these
sets of ones by doing birds and bees and
pigs and cows and brains and behavior
and these are actually all projects i'm
working on where i work in the genome
center where this project is going on so
it is the birds and bees and pigs and
kels projects in some respect let me now
conclude to allow some time for
questions by just saying this is
actually quite a different world it's
not pile all the world's knowledge in
one big place it's have many small
little ones including ones that are sort
of dynamic communities that are made on
the fly and because of that every person
that's doing it is actually doing just
about everything here indexing it using
the system they're making new
collections there of their authoring
materials themselves and the system
itself doesn't could be occurring on one
big server and ours of course does but
it could also occur in many small places
it's a very small localized kind of
system and my guess is if you had to do
this on 10 trillion which is what's
going to be chewing a decade on the web
then you wouldn't have four or five big
servers that cover the world what you'd
have is at the end of every block or
you'd have a hierarchy like the
telephone network used to where you have
servers that actually handle
leach each set of spaces that they were
doing live manipulation against it's
quite a different world it's much more
like the virtual worlds that the kids
today wander out maybe you all are a
little bit too old to spend all your
time on neopets or even on second life
so I promised I would end with a what's
a grand project you could do and so one
grand project you can do is take a
university take take some set of people
like university is very convenient
because you can force undergraduates to
do just about anything yeah and if
you're at if you're at the University of
Illinois there's 35 thousand of them
there's quite a few of them there's a
few less cuz some of them kick here and
you capture all the text you know all
the library and the course is actually
where we've just our library has just
gone into the google books program and
all the context which tries to do the
relationships partially by live with
this kind of system and partially by and
well i guess this is actually ok to say
but if you if you gave everyone at the
university of illinois free gmail and a
free g phone i guess the gphone isn't
announced yet but there's lots of rumors
on the web that there will be one anyway
if you get if you gave everybody a free
free email and phone and said with the
proviso that we're going to capture
everything you ever do and we're going
to use it for good purposes not selling
you ads but trying to relate things
together to help you understand the
context then the the university would be
delighted because they'd like to educate
not just the people on campus but people
all over the world and make money
charging them tuition people at Google
might be might be delighted because
normally you couldn't do this experiment
because you would get sued out of
existence even with your lawyers i would
guess if you tried to like have
surreptitiously capture all the the VoIP
that was coming out at gphone that's not
proposed is it I've had people tell me
the University of Illinois might refuse
to have it done but
I mean the undergrad takes it that's the
deal right they take it as long as we're
going to record everything and you might
really be able to build a semantically
based social network so you're not
sharing a YouTube video by it's got the
same little tag on top of it but by some
some sort of real deep scalable
semantics underneath so that's all I
have to say and I did promise I would
put some bees at the end so someday we
will do hive mind and it probably will
be in your guys lifetime but not in mind
that's all i have to say thank you and a
question yes no I'm fine I just I'm just
standing right in the light so I'm just
trying to it's not you're bringing up
could use the the semantic relationships
that you've built up to debug the
language itself in other words create
some kind of metric that that detects
whether the description or the
expression of a particular concept is
coherent or incoherent and essentially
flag air places where the the
terminology is insufficiently expressive
uh the question was did the question
could you hear the question is should i
repeated okay the yeah the question was
can you regularize the language by since
you're now detecting all these patterns
and that's actually been done quite a
bit with tagging and to quite a large
degree of success so the way the reason
that our digital library project
succeeded and the one at elsevier which
was a big publisher failed is we had a
set of programs that went through and
automatically cleaned up cleaned up the
the tagging that the structured tagging
that was coming back from the publishers
that the authors had provided and then
sent corrective information to the
authors telling them what they should
should have done but the things that
went into our system were the cleaned-up
ones it's what data mining people call
cleaning cleaning the data it is true
that the more regular things are the
better they
so that if you if you try to do a chat a
chat session like a text and IM text
messaging it would work much worse than
it did with biology literature which is
much more regularize but it is possible
the general experience with these kinds
of systems is that people are much
better at hitting the mark than
computers are at handling very building
so it's kind of like those 10 writing
recognizers that you learned how to
write the digit so my guess is that yes
the users are trainable and if I tried
to do this with undergrads I would
certainly do things like fail people
that got too many you know it's like if
you if your programs don't parts
correctly then then you don't get a
passing grade it's a problem though that
the more regular the world is the better
this brand of semantics does another
question there's no no yes I'm going to
start with a simple practical question
when I go to PubMed and ask for
references including phytic acid it
knows that phytic acid is inositol hexa
phosphate is there any automation in
that process or is that just a laborious
you know transcription process on the
part of human team ok if you're asking
what pubmed does the answer is they have
a big translation table with all those
wired in and it is because there are a
large organization with a lot of
libraries and they're actually able to
provide a large set of of common
synonyms two things the if you have an
automatic system it can't do that well
actually ours is sort of a hybrid system
ours actually uses the synonyms like
that that are in that that pubmed has as
a boost to find the equivalence ones if
you're not able to do that there's a
whole set of linguistics processing that
tries to find things that are synonyms
different degrees of success you know it
looks for things that are in the same
slots and sentences it looks for
equivalent sentences that had different
subjects that were used the same it uses
ways that that acronym expansion or
commonly done there there's a set of
heuristics that work some of the time
maybe two-thirds of the time and
regulars in regular regular iced text
like this but they're they're not
perfect in the way the ones you're
saying are all human generated and
that's why they're so good you always
use human generated ones if you could
and in fact it's very likely with it
when I give this a more popular version
of this kind of talk what people point
out is even though the kids on the block
that maintain the cat the one about cats
you know the small the small specialized
collections even though they're not
willing are probably not able to do
semantic markup they are able to do lots
of other creation they are able to show
typical sentences they are able to do
synonyms and that the value added there
may be a lot of value added that comes
in at the bottom that improves each one
of these community collections I expect
that that will be a big big area when it
becomes a big commercial thing you'll
need needs they have the users helping
you helping you to provide better
information by his mutt by live better
context yes great I remember the slight
about functional phrases and it seemed
that in the three examples that run that
slide they were the form something I
might call a a template predicate in
other words a template you know relates
to be and and it is you seem to be
saying that the system automatically
drive those templates from analyzing the
text is that correct that is yeah that
is correct so they so is my question
then is this can you compare and
contrast that technique of reducing
templates to two other things number one
the system that the cyc guys did to make
combine knowledge yeah to make
predicates but starting from a different
point ending at a different point
although they have predicates that's
comparison number one person number two
is with respect to let me just call them
template predicates for lack of a better
word if you have those in you created
them solely from driving them from text
then you don't have world knowledge you
basically have knowledge that just came
from the documents and it seems to me
that that getting from the one to the
other is what sick was trying to do but
I understand that since they were doing
it by hand they abandoned that and
they're now trying to do automatic
techniques and so that thread of thought
seems to be in the same ballpark as what
you're trying to do here but with a
different approach I was wondering if
you can compare and contrast and maybe
there's a third area of endeavor trying
to get to that next step up that maybe
you could educate us about yeah yeah let
me it's a very very good comment and for
those of you that don't know website
with psych is at cyc it was a very
ambitious attempted MCC to try to encode
enough common sense knowledge about all
of the world so that it could
automatically do this this kind of thing
and as Greg said it was largely a
failure so let me let me sort of say
what the spectrum of possible things is
a longer answer am i running over my
time is it okay it's it's what it's
lunch time for a lot of these people if
we let's say another five minutes and
then we'll finally break and then people
want to hang out that's okay oh I'm
sorry we're
yeah that's okay too okay i usually get
lunch people by saying there's free food
but that doesn't work here you all work
for food so so Greg asked a very good
question about all the what where's the
line in automatic pneus well the old way
of solving this problem used to be you
had a fixed set of templates and what
that what that essentially hit a wall
with is each small subject area needed a
different set of templates and it was a
lot of work to make the templates so
then there were a set of people that
said you needed if you had a small
amount of basic world knowledge you
wouldn't need the templates you could
automatically make training examples and
the problem is that that could rarely
only in very isolated cases could do as
good even as good a tagging is what I am
showing what most of the people do now
and what most of my the examples that I
was showing our is a human comes up with
a set of training examples of wetters
typical sentences with genes in them in
this particular subject domain and then
the system in furs as exactly as you
said the system in furs what the what
the grammar is what the slots are going
to be there's a few people experimenting
with two automatic things and they don't
work at present but my belief is in the
next year or two you'll see research
systems with it and if you had a
concerted a commercial effort you could
probably do it and get away with it it
just wouldn't work all the time they're
essentially either trying to
automatically make training sets so you
start out with the collection and you
try to pull out sentences that clearly
have some slots in it and then just
infer things from that or they try to
automatically make infer tags and for
grammars so you know some things like
you know body parts and you know jeans
and the question is can you infer
behavior because
no in slots you already have slots in
the particular in the particular subject
domain and my feeling is one of those
two will work well enough so that you
can use it automatically and it will
always do some kind of tagging it won't
be as accurate as these which are
generally correct and it could either
just be left as he is so it's like a
baseline of everything is tagged and
sixty percent of them are correct and
thirty percent of them are ridiculous
but sixty percent buys you a lot or they
could be the input to humans generating
it so the curators I'm working with in
biology we already have a couple pieces
of software that do this they don't have
to look at all the sentences and all the
documents we give them a fixed set of
sentences that are sort of these are
typical sentences that might be that
might be ones you'd want to look at and
then they extract stretch things out so
there's a human step afterwards it does
a selection almost all the statistical I
went kind of fast through it but almost
all the statistical programs don't
produce correct answers we produce
ranked answers that the good ones are
the top ones they're sort of in the next
band and my expectation is the tagging
will be like that so so the practical
question is which things are good for
which kind of tests so I guess we have
time for another question if anyone had
you actually had another one because you
started with your easy one should we
take sure we take someone else let me
just just because it is getting close to
lunchtime let me suggest 11 last basic
question given all the information about
bees have you been able to figure out
why they're disappearing it turns out
actually we have a summer workshop on
exactly that topic and the answer is
like most things about bees nobody knows
so much for that idea okay well thank
you very much Bruce we appreciate the
time and those of you want to hang out
Bruce has time to stay this afternoon we
I'm generally hanging out today and
tomorrow morning and there's a lot of
stuff about the system up on the Beast
based site which you're welcome to look
at and the slides are also going to be
made available if you want to if you
want to flip through them Thank You
everyone's for saying that all day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>