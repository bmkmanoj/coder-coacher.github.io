<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Archimedes Palimpsest | Coder Coacher - Coaching Coders</title><meta content="The Archimedes Palimpsest - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Archimedes Palimpsest</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gME6fsCvonU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is carl malamud i'm chief
technology officer at the Center for
American Progress it's a think tank in
Washington DC and I'm a part of a group
of volunteers that have been working on
a document that we're here to tell you
about the Archimedes palimpsest like to
thank Dan Bloomberg who's our host from
google for inviting us in and Vint Cerf
who's the one that originally give us
the invitation to do this my role in
this project is pretty simple I'm going
to be running the ftp server and there's
not really a lot of rocket science to
that piece and so I'm going to turn it
over to three speakers from the team who
are here to talk about the work doctor
will null is a curator at the Walters
Museum in Baltimore and he's the one
that worries about old manuscripts and
what they mean and and how to work with
them Abigail kwanten is also here from
the Walters Museum and she runs their
conservation operation and as you'll
hear this document took quite a bit of
conservation following will we're going
to hear from Roger Easton who's a
professor at Rochester and is heading up
a lot of our imaging efforts Bob Morton
is also here from conocophillips he's
one of the team of imaging experts from
around the world that have been working
on this project and then Mike to--the is
going to speak last and he's the program
manager he's administered several very
large imaging projects in the past and
he's volunteered his time to keep
everything going and work with
scientists from from dozens of places
around the world and also specifically
to worry about things like metadata and
making sure that we're capturing the
right information as we create these
images so will thank you very much thank
you google it's a great pleasure to be
here I am the project director and I
have a I have a rather extraordinary
story story to tell if I can tell it and
I have about 20 minutes to tell it
there's a philosopher called a n
Whitehead who very famously said that
Western philosophy is nothing but a
series of footnotes to Plato I'm going
to make the case very briefly that
Western science is nothing but a series
of footnotes to Archimedes what do I
mean by this I mean that Archimedes was
the
guy who first got abstract mathematical
problems and attached them to the
physical world so that you could just
think entirely abstractly and find out
something that was true about the
physical external world I'll give you a
very simple example how to find the
center of gravity of a triangle well you
could do is hang a whole bunch of
triangles from the ceiling and find out
where the center of gravity is for each
individual one that's not how Archimedes
went about it he was sitting in Syracuse
in the 3rd century BC and he thought how
am I going to find the center of gravity
of a triangle I'm going to draw a
triangle in the sand I'm going to call
it a B and C and I might guess that the
center of gravity in a triangle is going
to be on the median line ad but being
Archimedes I'm not going to do this
simply I'm going to make it complicated
i'm going to an indirect proof so what
I'm going to prove to you is that it
can't lie on the line ax say at the
point t ok so let's say that the center
of gravity in this triangle is at the
point t and I'm going to prove to you
that it can't be i'm going to divide
this triangle into for individual
triangles so the sum of the center of
gravity of these four individual
triangles is going to be this should be
identical to the center of gravity of
the big one right now being similar
triangles the center of gravity should
be in roughly the same place as those
respected triangles as the point t so
they should be for the blue triangle at
the point k and the yellow triangle at
the point l ok now those other two
triangles there the center of gravity
for those two is easy it's going to be
at the point n because it's a rectangle
and it's right in the middle of the
rectangle K&amp;amp;L the center of gravity of
those two triangles should be at the
point n that's exactly halfway between
the point k and the point l so the
center of gravity for the four triangles
is going to be on the line somewhere
right in the middle of n n ok if you add
all those triangles together the center
of gravity is going to be in the middle
of the line and n but you know it isn't
because it's going to be at the point t
now those two lines the line running
through MN and the line running through
82 x
are always going to be parallel whatever
the shape of your triangle they're
always going to be parallel they're
never ever going to intersect they're
never going to intersect and while
they've known to why they don't
intersect of course you can't have a
center of gravity the only place they
will intersect is actually on that
median line so you know that the center
of gravity you have proved it without
even hanging a triangle from the ceiling
that the center of gravity is going to
be on your median line now nice thing is
you haven't got a center of gravity yet
you just know it's on the median line
but of course a triangle has three
median lines and they coincide at one
point so you know that the center of
gravity of a triangle is going to be a
third away along actually of any median
line which is going to be at that point
so if you're Archimedes you know that
you can just to simply hate working it
out entirely in your head that you can
find the center of gravity so you know
if you're a eminent historian you might
try and hang triangles from the ceiling
any old how but if you're Archimedes you
just think about it entirely abstractly
and before you know it you've got
triangles that balance perfectly on the
ceiling the application of abstract
mathematics to the physical world is
something that Archimedes was very very
good at and measuring surfaces is
something that he was very interested in
now measuring a rectilinear surface
however complicated it is is incredibly
easy you just divide it up into right
angle triangles and before you know it
it's incredibly easy to measure but
measure an incredibly simple thing like
a sphere and that's incredibly difficult
and what Archimedes did was to pack it
with triangles and he had a recipe for
packing it with an infinite number of
triangles so that way he can calculate
curves now if you can apply abstract
mathematical models to the physical
world and if you can calculate curves
eventually you can send the rocket to
the moon which is why Archimedes is the
most important scientist who ever lid ok
everything we know about Archimedes
comes from two books came from two books
they're very boring Lee called codices a
and B just two books that's how we how
we know about all of Archimedes is
treaties in the Renaissance
Leonardo got hold of copies of these two
books and with it he found this he found
equi librium of planes which is where
Archimedes starts talking about
triangles and typical of the Renaissance
he picked up on the ancient mathematics
and found the center of gravity for a
tetrahedron it's very very clever to do
this you can calculate the center of
gravity at the pyramid of cheops but
there was another manuscript codex see
and codex see Archimedes didn't know
about if he did know about it he'd have
known that Archimedes had 1,700 years
earlier already calculated the center of
gravity of a segment of an ellipse and
many more complicated curved solid
objects besides so he can calculate the
center of gravity of even as you know a
cut through one of those eggs this
manuscript codex see well let me tell
you about the fate of Courvoisier and b
codex be was last heard of in the papal
archiving Viterbo in 13 11 codex a fell
off the back of a truck in 1546 codex II
was only discovered in 1906 by a guy
called johann ludwig Heiberg in a
monastery in Constantinople and that's
what it looks like but the Archimedes
text in this manuscript is not the
Archimedes text that you can see running
down like this it's coming in two
columns across the page the other way
it's a Palin cest it was made in the in
the 10th century but in the month
shortly before April the 14th 1229
someone needed to make a prayer book and
they didn't have any parchment so they
tore up the Archimedes manuscript
scraped off the text cut up the pages
stack them in a corner rotated them 90
degrees got some parchment from other
manuscripts as well wrote over it very
very scrubbed it very hard wrote over it
very in a very black ink and turned it
into a prayer book and it survived as a
prayer book for approximately seven
hundred and seventy-seven years until it
was discovered in 1906 and that's what
it looks like now it was sold at auction
on October the 29th 1998 but when it was
sold an awful lot of things had happened
to it between when it was discovered in
1906 and when it was sold in 1998 one of
the most remarkable things that happened
to it is that sometime after 1929
someone painted over the pages with gold
ground icons we know that this is after
1929 so what you're looking at is unique
Archimedes text that was overwritten in
1229 and then someone after 1929 painted
a painting on top of it fantastic the
other thing they did was they left it in
the bottom of their garden for quite a
long time so it got very very moldy now
I can't go into this in great detail but
medieval manuscripts are made of
parchment that's the stuff your shoes
are made of it's tough stuff there are
two things that can kill it fire and
water this was left in a bucket and
that's the bit that was that that's the
page as it was in 1906 and that's the
page as it is now and you can see a big
hole a hole in Archimedes his brain
right here you don't get more written
off than this manuscript it's in a
terrible state it is the unique
surviving copy of on floating bodies in
the original Greek is the unique
surviving copy of the sturm a Kian and
it's the unique surviving copy of the
method of mechanical theorems it was
read by heiberg in 1906 but it wasn't
read very well because he didn't have
the modern technology that we have now
there it is it was bought by an
anonymous owner in 1998 sold for 2
million dollars and he gave it to me
fantastic I don't read Greek a client ad
and I do know about manuscripts and I am
in a position to find some of the people
that are going to help but it was a
major problem and we've been working on
it for eight years now and I'm going to
talk to you a bit quickly about some of
the things that we did we had an article
in The Washington Post and we got lots
of responses you know the grandson of
Rasputin said he his name could be found
in the Archimedes palimpsest if only we
looked hard enough lots of kooky things
and then a nice a nice email from Mike
to--the who's going to speak speak to us
later who said that he worked for the
government and they had some kit that
might be able to help it's a privately
owned book so we can't use government
equipment to help us but Mike's had a
great deal of experience in running in
imaging programs and that sort of thing
which of course I didn't so he works for
us as our beat oath associates and he's
the brains behind an integrated program
of imaging scholarship and conservation
that I'm briefly going to talk about
conservation of course is the most
important part of this thing the way the
palimpsest was made we had to take it
apart it's hard work taking it apart the
main reason it's hard we're taking apart
is because there's now glue on the spine
now glue is put on spying books quite a
lot but not in the Middle Ages there are
two bits of glue there you can see at
the top that it's white and at the
bottom it's black the black stars all
right for Abigail that's called high
glue it's made out of animal parts and
conservators like Abigail have been
taking this apart for time immemorial
the trouble is the Elmer's wood glue on
the top the white stuff is Elmer's wood
glue it's tougher than the parchment
support itself and that's probably been
put off on since 1970 by some nice
people called the tableau small melee in
Paris so it took four years to take
apart the book that's a rare action shot
Abigail started here on the third of
April in the year 2000 finished on the
twenty-third 26th of november 2003 i
bought her a bottle of champagne and it
was a
job abigail is a great conservator of
manuscripts but boy did she need to work
hard on this book that on the left is
the first page of the book it's on
floating bodies that has never been read
before but you can see that it's in a
really bad state and how on earth we're
going to read it and this is a typical
Abigail story you can see the Archimedes
text running vertically right and what
you're looking at is a detail of the
gutter so Abigail performs brain surgery
okay there's a before on the left and
after Abigail in the middle and then a
UV photograph very low quality low res
jpeg that we sent a rebel net to
Professor asst of ancient science at
Stanford University he circles the
circle and he comes back and he says
this is the earliest symbol of a circle
in the history of the Western
mathematical tradition great so I send
it to the owner I say here it is this is
this isn't bad work is it and he says he
sends back is ten thousand dollars go do
the same thing again that's on a good
day you know but there are lots and lots
of bad days Abigail's basic job is to
prepare the palimpsest for imaging and
my job is to and that's the imaging
stage and these are my images bill
Kristen's Barry from APL Keith knocks he
now works for the Boeing Corporation in
Hawaii lucky fellow and Roger Easton
who's the professor of imaging chance at
the Chester Carlton central imaging
science and he's going to speak to you
in a minute and he's going to talk to
you about the imaging I'm just going to
show you a product of the imaging this
is the Archimedes text running along
here and that's what and that's what it
looks like after he's done it it took a
long time to get there but there's the
images that the scholars alike and
however ugly these images are that's not
the point the point is that the scholars
can read them and we distribute them at
the moment in hard drives which is one
of the reasons we're here we have a
we're about to have a problem some of
the results of our work this is raphael
nets who's at stanford method
proposition 14 of the method is very
important because Archimedes starts
dealing with infinite numbers this is a
UV photograph revell tries to read
the q 2aq in them is a question to
abigail quant asking if the tear in the
parchment is possibly original because
if it is then Abigail and then reveal
doesn't have to try and find a letter to
put in there when he's doing his
transcription that's the method
proposition 14 page with RGB on the left
and processed on the right there's a
detail you can see how easy it is to
read with the processed image and how
difficult with normal and this is a
result dear will in a couple of months
the first intellectual fruits of our
labor will be published together with a
complete transcription of one crucial
side of one page most of which is
unknown to modern science I send you the
final lines of the article as it stands
in draft form it's understated it reads
as follows to sum up then the the new
reading from Archimedes indivisible
sprues calls for some reconsideration of
the position of Archimedes in some key
areas of mathematics notably the two
related fields of calculus and of
infinity very learning article very
obscure journal read by six people
because Natalie turn five people cause
natalie teeger net score isn't married
and published on the Sunday Times colour
supplement Eureka exclusive it's just a
few lines of scroll Greek text but new
technology has identified the hawk the
hand of Archimedes and the results a
rewriting history one of the interesting
things about this project is that on a
very very academic level we are
fundamentally transforming a landscape
of Greek mathematics but there's also a
great popular component to what we do
another example is the stomach Ian the
stomach ian is the unique in which
uniquely survives in this manuscript and
it was known as Archimedes his box in
ancient history and it's a it's just a
square and it's divided into 14 bits and
we knew that Archimedes was playing some
kind of game of these 14 bits but we had
no idea what it was and together with
our new reading from that from that page
which as you can see is is dreadful we
found out what it was Archimedes wasn't
playing a game at all he was calculating
how many ways in which those those those
bit
of that square can be recombined and
still make one square and that makes it
the earliest mathematical study in the
history of combinatorics which is
important I think to what a lot of giddy
guys do the answer anyone want to guess
17,000 152 we all thought we were
working for Archimedes but those of you
that were paying attention will noted
that I said that other manuscripts were
also used to make the prayer book and
they'd never been read at all simply
because they were so faint and we
thought just for the purposes of
completion we should study those ones to
this from Natalie charnetski at
Cambridge University we have five pages
in this book that belonged to a their
their speeches by an Athenian orator
called hyper IDs who was contemporary of
demosthenes and Aristotle from the 4th
century BC 77 speeches by written by him
and antiquity none of them survived the
rather important transition from the
role to codex that's the book form as we
know it today this is the only hyper I
these texts has ever been found in a
codex we've added thirty percent to the
to the surviving hyper IDs corpus so
people are rather excited about that
this is nigel wilson he's at Lincoln
College Oxford dear will excellent news
the hard drive in photos came safely
this week at first glance there's no
more hyper IDs but several leaves of the
philosophical text on which I read the
name Aristotle clearly enough well
clearly for clearly for nigel is not
clearly for the rest of us but I circled
it on the on the image below and you can
just see it there and there it is you
see that's Aristotle we now have we now
have seven pages of an unknown
commentary on Aristotle that must date
from the 3rd century BC now where I come
from from the world of medieval
manuscripts this is just utterly
sensational you know there are quite a
few palimpsests around a very few of
them are important the cicero's de
republica only survives in palimpsest
form but to have three unique texts and
we're hoping for a fourth from one book
is you know it makes this book the
eighth wonder of the world
and this is how the scholars reeded at
the moment through hard drives and
through copy and until about four weeks
ago we were dealing with for scholars
because you only need about for scholars
to read Archimedes text but with the
hyper IDs text on the Aristotle text we
have a major distribution problem which
is one of the reasons that we're here
because we have to address it very soon
because with these new discoveries we
have scholars you know we're talking 100
150 scholars who we want to work on this
project when they work together they can
come up with some pretty wonderful
results we have a website I'm not going
into it we are working on other
technologies to improve our pseudo color
processing including shortwave
multispectral imaging which four years
ago was very very expensive but now you
can just use with LEDs and our
provisional results for encouraging
we're also doing optical character
recognition but I'm going to leave my
part of the talk dealing with the
leaving you with the forgery problem
which is why we're here here in
California because we have two weeks of
imaging at the Stanford Linear
Accelerator Center over the next couple
of weeks we've been going for eight
years there are a lot of people involved
in this project and nearly all of them
are on this screen I'm going to hand
over you too Roger Easton who's the
choose the head of our optical imaging
effort and he's going to give you a
brief summary of the techniques that
we've been using and what we've learnt
along the way and how to image the
manuscript thank you very much Roger
thanks will so as will said I'm been
working on the imaging team for the
Archimedes for quite some time in fact
we actually started working on it Keith
knocks my colleague and I even before
will did because we did some imaging for
the auction catalog that was published
in the sep tember august/september of 98
before the auction but our original
intent and what we have been doing
subsequently with significant
modifications as I'll show you was to do
multispectral imaging of the palimpsest
and the reason is because the two winks
the overwritten ink that came later and
the original link are different colors
and the slide here shows images at a
bunch of different wavelengths which
illustrates that the bow thinks tend to
get fainter as you go to longer
wavelengths because the penetration
depth of the of the light gets longer
but the Archimedes ink that changes
significantly more quickly so we're
going to try to take advantage of that
here's the one of our early graphs that
we took made in the summer of the year
2000 when we first started to image this
for will and you can see they are the
prayer-book text the is the upper line
and it's significantly flatter than the
lower line which is the Archimedes text
and sorry I got that backwards the
prayer-book text is the lower line the
Archimedes text is significantly
brighter in the red wavelengths which is
the reason why the difference that we're
going to take advantage of so the
original imaging plan was to take
advantage of this look at the image and
30 different wavelengths in the visible
and then do subsequent image processing
to try to recover to extract the
Archimedes text to literally segment it
from the original tax and this is taking
advantage of techniques that are well
known they've been done in environmental
remote sensing for years so we weren't
actually doing too much that was very
new when we did this the camera we had
at the time and we still use on occasion
was just marginally capable to do this
it was a relatively small sensor 1536 x
1024 so one point five megapixels and
these days when you can go down to your
neighborhood store and buy a 88 or even
a 12 megapixel camera
it this is relatively small potatoes
this was a monochrome camera it was
cooled which allowed us to image more
great levels we got 12 bits of data
rather than the eight or ten that you
get from most normal cameras but because
it was a monochrome sensor to be able to
get the spectral recognition we had to
put a color filter over the front of it
and we used a liquid crystal tunable
filter which again at the time was
relatively new technology but is much
better known now which allows you to
literally tune an electrical knob and
change the wavelength of transmission
and so this camera which was about 25k
when I bought it in 1999 you can get
that capability for considerably less
money now so we're going to use these
techniques we derived from environmental
remote sensing where we assumed a linear
mixing model we assume that the the
pixel values or linear combinations of
the different constituents and then we
tried to extract that undo that by doing
a unmixing model using a sua inverse
matrix which is again relatively
straightforward simple stuff that many
people here are probably snoozing right
now because it's so obvious so here's a
diagram of what that model would be we
take the images in the different
wavelengths and what we're trying to do
is construct the inverse of the matrix e
which is the matrix as describing how
the combinations of constituents get
matched into the different combinations
of wavelengths at each pixel one other
little detail that we had to deal with
was of course in real life in here we've
got a multiplicative model where the the
different combinations actually are
combined multiplicatively and the in the
calculation we want to do the assume an
additive combination so we simply had to
take the logarithm to do that and then
we went ahead and did a least square
solution of the matrix real
straightforward stuff more penrose
pseudoinverse and then we could
construct images of each constituent
based on that and this was a the first
images that we got doing this we did
this in our phase one sec phase one
imaging which happened in the summer of
the year 2000 and so the original
appearance of this one leaf seven TV is
on the left
and then the the channel that shows the
Archimedes text is on the right where
the level of whiteness is associated
with how the algorithm how much the
algorithm recognize that text to be
Archimedes so if it's white it says it
is Archimedes if it's black it says it
isn't and if it's mid gray there's some
mixture and so there we were actually we
felt we'd actually solved the problem so
there's a magnified view of that the but
it turns out that that was not this a
successful result in the minds of the
scholars the images look very good to us
the imagers but it didn't look good to
the scholars and the other problem was
it was a very time intensive process
both collecting and processing the data
and part of that was we had to do custom
stitching at the time we didn't have a
algorithm that we could use but it turns
out even with the the fact that there
was significant improvements in the
visibility of the text which I think you
can see in the center there there's a
diagram of Archimedes that if you look
on the original page I don't my memory
is you couldn't even recognize that it
was there but it turned out that the
scholars didn't think so so our reaction
to the scholars reaction was one of
shame and shock I mean we figured we had
the problem licked but it turned out we
didn't but but there were a couple of
simple reasons why we we hadn't done it
for them and one thing they really
wanted was finer spatial resolution and
that was the problem again with it with
that particular camera being only one
point five megapixels we took the images
of those leaves in two shots and then
stitch them together and so we only got
images that were about 1.5 megapixels x
2 x sorry one point five fifteen hundred
pixels by two thousand and so it worked
out to be about eight pixels per
millimeter which is certainly sufficient
if you're just trying to recognize the
text but when you're trying to extract
text from other text it turned out it
wasn't and again we clearly also need a
more efficient imaging and processing to
be able to do this much more readily
because it took us virtually all summer
to process those those five
leaves that we did in that original
phase so then we adopted the technique
that was well known to scholars for many
years to read palimpsest which is to use
ultraviolet fluorescence imaging where
you illuminate the page with a
fluorescent ultraviolet fluorescent
light and that makes the parchment glow
and that improve enhances the visibility
of the text and why is that well it's
because you get a double absorption the
ultraviolet light is absorbed by the ink
going in and then the visible
fluorescence is absorbed by the ink
coming out and that double absorption
gives you an enhancement in the contrast
of the text and makes it much more
rental much more readable so this was
something that we had known about but we
figured that with the Technion technique
that we had up before we didn't need the
ultraviolet fluorescence turned out we
were wrong so we also went to a simpler
digital camera which gave us a
significantly better resolution and
again compared to what you can get now
this is relatively small potatoes but at
the time we got it it was the limit of
technology so we use the kodak dcs 760
which is a digital camera based on an
icon body single lens reflex kodak
doesn't even sell it anymore they don't
have any comparable camera at this time
but it gave us six megapixels 3k by 2k
and it did give us images that over from
400 nanometers through the infrared and
again we illuminate now pages with
ultraviolet fluorescent light but we
look at the visible fluorescence so the
400 nanometers is sufficient the other
point is of course this is a color
camera gives you a color image but again
technology is probably well known to
everybody sitting in this room you've
got over the 3k by 2k sensor you've got
green red and blue filters so in fact
you have to do interpolation so we wind
up getting slightly poor resolution than
in fact you would have expected perhaps
so the technique that we finally evolved
into we image now the pages and three
illuminations so we use a xenon strobe
that's strictly we don't process that
that is just for the visible appearance
then we use a low
wattage tungsten light which it gives
you a very reddish illumination and I'll
show you the reason for that in a second
and then we also illuminate with a long
way of ultraviolet which is where we get
the enhanced visibility of the under
text and with this camera we set it up
so we image 600 pixels per inch or 25
pixels per millimeter roughly and that
gives us an image size over the whole
page of about 7,500 by five thousand
pixels but so to do this we have to
image the page in sections so we imaged
it now in ten sections to do the the
image of a by folio which is a double
page spread of the original double page
spread of the UK Logan a single praised
spread of the original Archimedes and
then we have to digitally stitch those
together and again technology has
evolved quite a bit from when we first
started to do this our stitching
algorithm was pretty poor and what we've
adapted to get a new and significantly
better one so here's an illustration of
the enhancement of the under text using
the floor eltra violet fluorescent and
the image on the right the Archimedes
text is running vertically and that's of
course as the texts were interested in
so then we now we have these three color
images so in effect we have nine bands
the the strobe RGB the tungsten RGB and
the ultraviolet RGB even though in the
ultraviolet image there really is almost
no signal at all in the red channel in
the green channel it's almost all in the
blue but then we wanted to come up with
a simple method for doing the image
processing and this was sort of a mutual
effort with my colleague Keith knocks
and myself and it was based on the
observations that the tungsten red
channel the red channel of the light of
the image viewed under tungsten this
reddish tungsten illumination shows
almost no evidence of the Archimedes
text and the reason is because the
Archimedes text is reddish so you you
illuminate something reddish on a
neutral background with a red light it
will tend to disappear whereas the
ultraviolet blue channel shows both
writings for the reason that we've
already mentioned so we came up with
this processing strategy where we would
encode the spectral differences of those
texts in color to create these pseudo
color images that will are
showed you a couple of examples up and
these images as we all absolutely
readily admit are hideously ugly but
they are useful and they are quick and
easy to generate so here's the
illustration of the steps so the same
leaf this is 92 V 93r and this is a
Archimedes on spiral lines and you can
see the diagram right there in the
gutter this is the page that we use for
our reference we imaged this every
imaging session but in the image on the
left that's the full color tungsten
where you can really see the Archimedes
text is virtually invisible whereas the
image on the right it's actually pretty
apparent though the certainly it's still
overshadowed by the over text so then we
just go to the separations and there's
the red channel the tungsten on the left
and the Archimedes text is virtually
gone and the blue channel of the
ultraviolet the two texts are at least
of comparable contrast so then we have
to go and process those and this is
using the software that Keith knocks
wrote what we call Archie is now Archie
1.1 where do we take the red channel and
the blue the red channel tungsten and
the blue channel the ultraviolet and
normalize them by using a moving window
and then we balance the mean and
variance inside that window so we get a
significant enhancement of the contrast
and also it removes a lot of the shading
variations that are apparent in in many
of the images and Keith did this in a
very efficient way so it winds up being
able to run in 15 seconds for a whole
image rather than days and so we we now
have it set up rather than having to
haul all the images back to Rochester
was what we originally did Keith sets up
his mac laptop and runs it in this hotel
room in the evening so we have the
images by the next step so then the how
do we display these to the scholars well
we want to take advantage of the pseudo
color the eyes ability to distinguish
the text so we put the blue channel in
the green and blue channels of a pseudo
color image and we put the tungsten red
image in the red Channel and again the
Archimedes text does is not visible or
almost not visible and the tongues
red channel so it shows up as bright
whereas it shows up as dark and the
green and blue and the over text shows
up as dark and all three so as a result
the over text comes out neutral and the
under text the Archimedes text comes out
with a reddish tint and that gives you a
color Q and so there's another example
like the one will showed you earlier the
visible appearance on the top and the
pseudo color on the bottom and now you
can do a comparison the top is the
visible appearance the middle is the
appearance using that multispectral
segmentation with the pseudo-inverse and
then the bottom is the pseudo color and
you certainly get similar kinds of
visibility of the Archimedes text but
the advantage of the bottom one is you
also see the over text and that allows
the scholars to be able to tell if a
character has a break in it they can see
that that break was caused by the the
over text covering obscuring the the
original Archimedes writing which in the
middle image we were more successful
than we probably wanted to be though we
didn't know that at the fact at the time
we've been able to significantly make
that over text disappear into the
background and becomes difficult for the
scholar to tell if that break was caused
by obscuration from the from the over
text so in these pseudo color images
both texts are visible and this was the
scholars request we get that reddish
tint and we assume or we we have found
that this method is a useful to
recognize about eighty percent of the
text and so there is a large image of
one of the sections there's the
ultraviolet and then there's the pseudo
code so we went into production imaging
there's Abigail putting the putting one
of the pages this is one of the pages
with the forgery on the bottom into our
system which has a computer-controlled
XY stage so we can readily drive the
page to the particular section that we
want to image and we this setup actually
holds both the Kodak camera and the
earlier census multispectral camera so
we can do both kinds of imaging and the
same setup
and but even with that the scholars tell
us as some of the text is still not
readable it's either underneath the
forgeries which is what why again why
we're here why we're up at the stanford
synchrotron because we're trying to do
x-ray fluorescence imaging or it's been
eaten by mold or it's scorched so we're
now trying to figure out ways to image
these difficult sections and one of the
ways will already hinted at we want to
do a little more sophisticated
multispectral with more wavelengths or
we're going to try this x-ray
fluorescence and here's our team of
x-ray fluorescence imagers Bob Morton on
the Left who's sitting in the front row
and gene hall from Rutgers in the middle
and of a Bergman from the stanford
synchrotron up on the right and again
it's with because of of a that we're
here so an x-ray fluorescence the
technique here is very similar to
regular fluorescence you bring in an
x-ray to Adam and that Adam that x-ray
kicks out an electron from one of the
inner shells and by cut and then by
consequence one of the electrons from
one of the next couple of outer shells
drops into that to fill a hole in the
inner shell and emits a photon an x-ray
photon at a wavelength characteristic of
the particular material so this allows
us to do spectroscopy on the the inks at
a particular point at the same time so
this was a test image that was actually
done with a test system not using the
synchrotron so this is one of the
forgeries and then in that particular
section do an average spectrum and you
can see a variety of x-ray peaks there
and those are characteristic of all the
materials including the iron this ink is
iron gall ink and so it has traces of
iron in it and so we're that's what we
are counting on using to try to recover
that text so here a bunch of different
images from using wavelengths
characteristic of different materials to
try to extract that if you look at the
calcium image in the lower right there's
a lot of calcium present in this because
that's how they treated the parchment
and there you can see the text through
the
the pain so our first test images and
Bob and will were spent quite a few
sleepless nights putting these together
last last year I fortunately had to
teach so I wasn't available to go and
spend my nights working on this but
there's a small section and there is an
image using an e tax system which is a
commercial system and the one of the
interests and things about it is you can
see both writings on both sides in the
same image and here's an illustration of
trying to indicate that a little more
clearly the face 16 the page 163 verso
on the left and then 163 recto the back
side of it on the right but it's been
digitally flipped to give you the mirror
image and you can see that those
writings you can match the writings in
the e-tax image in the middle with the
different writings on the different
sides in the same image so again we've
mentioned it a few times that's the
reason why we're here we're at the
stanford synchrotron radiation lab just
up the road and taking advantage of that
and here's one of the pages in the set
up this was when we did the first tests
of this last year and so the x-rays come
in through that tube on the right and
then are measured by the sensors both
behind and at the bottom and use that
those signals to try to recover the
different wavelengths and so here is the
the first examples of writings from that
and again I didn't have the pleasure of
being here but that image on the the
right took how many days to put the 30
hours to put together so now I will turn
it that's the imaging section so now I'm
going to turn it over to Mike to--the
who's going to tell you a little more
about what the management and some of
the data issues event
as both Roger and will have noted we've
got a good team here and we've been
doing we've got a good process in place
starting with the conservation and the
imaging and working our way through to
ultimately gaining knowledge about the
Archimedes and now is a point where
where you all come in and we're
particularly interested in your thoughts
on this because we're looking at the
data and we've been looking at the data
throughout this process but we've been
working with a closed system we've had a
given set of scholars we've had a given
set of image processors now we want to
make this more broadly available for
people who may want to try different
imaging techniques who may see different
things in the Greek text and they want
to get back to these original images so
the question for us is how do we make
these original images available to a
broader audience in wherever they may be
around the world now early on as we we
said hey we're going to collect large
amounts of data here we created a
metadata standard part of that's basic
dublin core basically what is it
intellectual property rights all the
images or copyright the owner of the our
communities pollen cysts we have a range
of information there but one range of
information that i think is truly unique
for manuscript imaging is this spatial
information because when we looked at
this we said hey this is the equivalent
of having a satellite over the globe and
we're looking at at coordinates on this
globe in fact just the other day as
we're looking at the XRF we're saying
we're going to be imaging from the back
which way is our world going to spin
what's 90 degrees and what's 270 degrees
so we're trying to address all these
we're trying to create a standard here
so part of this was creating a standard
for our imaging so that you could go
back to those original images honor
coordinate system and pick any point in
this coordinate system and we back in in
two thousand when we're starting this we
went back to the content standard for
digital geospatial metadata extensions
for remote sensing metadata following
with our analogy to the satellite over
the earth and so we created this where
we have an exposition a y position and
various coordinates there so we have a
spatial capability here now does this
help Google does how would Google work
with this you've got google maps you can
search for Archimedes and you can look
all around the US and people can do
mashups and and find locations on Google
Maps you also have google books we have
reveal Nets is booked there the the
works of Archimedes translation and
commentary we have Heath's early
translation the works of Archimedes
which actually use the hyper I ities now
how do we bring those together is our
question and can we use the same type of
method the same methodology that you're
using for google maps can we do this on
a script of spatial scale if you will
instead of a geospatial scale can we
apply this to our manuscript is there at
one question for us is is there enough
information there and then the question
for you is how can you use that
information how can you make this
available to scholars who are saying ok
I want to know where the word whatever
that word is the the starting with the
epsilon there or reveals input or
Nigel's common can I find us now it's
pretty straightforward as we go through
the the various images here the UV and
the natural light and then the pseudo
color bigger challenges when we get to
the xrf we've got registration issues
here we've got to address those and
we've been we spent I think all of a
full day to an afternoon in a full
morning trying to make sure we've got
the metadata squared away for upcoming
XRF imaging session so that ultimately
you can correlate this information with
the the the visual information here
that's fairly straightforward
the real question is the transcriptions
this is a transcription by reveal Nets
of that same page that we were looking
at earlier and these are the same points
that I pointed out earlier and the real
challenge for us is going to be to bring
it back to the original image we
frequently you will see transcriptions
or translations and books and in google
books or whatever it may be you'll
relate to those but how do you get back
to that original image and that's what
the academics want to look at or a
processor it says hey I think I've got
Archie 3.7 let me try to crank this
through these images okay how can I
apply the the same type of thought to
the original image not just to the
transcription not just the translation
and how can I relate these together how
can I relate it to references in various
books can I relate that to the specific
image can I go back to that thought on
sphere and cylinder or whatever in the
original image there from a book can I
do it from a transcription and and
relate my notes to that that if I have
the word mastin for example I can find
that in the original note if I have the
word and info can I put that into the
book and so can we relate it to to the
information an index for example this is
reveal net TSA's book can I relate back
to those original images and that's our
question for you really is do we have
enough information here how do we make
our data available there's going to be
distribution questions on the data i
mean i just got a terabyte of archimedes
data at home very quickly the FedEx box
arrived sat on my front doorstep and
there's that there's that information of
the hard drives in it but we're going to
have to move this around by internet and
we're going to have to move around good
quality images there so what we're going
our plan currently is to make the data
available sometime this year we're going
to make it available in a very simple
flat file we're going to use our our
metadata standard and we want this
available to the broadest range possible
of students scholars educators and the
general public so this is getting beyond
our narrow circle of the scholars the
imagers the the image scientists and we
want them to be able to link to the
information they need to be able to
search across this search across the
original images not just the
transcription not just the notes not
just the books and then we're going to
make this available to anyone including
Google and what do you do with it what
type of GUI do you develop for what what
front end goes on this so that's the
kind of a heads up here as to what's
going to be coming and then what do you
do with it and who is it good what is a
good for there's more than just this I'm
not I do not believe the others any the
other imaging projects currently capture
the spatial information but there are a
number of other projects the Herculaneum
Herculaneum papyri the oxyrhynchus
papyri codex I atticus that efforts just
starting up with the British Library
international done Hong project also
with the British Library all of them are
collecting large amounts of images large
amounts of metadata how do we
standardize across this and it may be an
organization such as Google that that
gives us the impetus to standard
standardized across our various various
efforts so a question for you is what
are your thoughts on this I kind of get
skewed over to the right there or the
left thing what are your thoughts with
regard to what we're doing what are your
thoughts in terms of making this
available what are your thoughts with
regard to how do we make these images
available to the broadest group possible
and make it available for them to work
with it as as they need to or is they
they can make it available to others so
there's a question back here
which one that's basket but what we've
what we've said is that right now the
TIFF image we have different versions of
images really we have the original what
is that a 12-bit or 16-bit tiff okay and
then we have the processed images and
those are all TIFF images we then push
around JPEGs but those are not our
standard images we want to make those
available and ascii so that you're not
dependent on on any other standard we're
doing the same with the x-ray
fluorescence where we're going with the
ascii we're then converting those in the
tiffs so the original the original image
as shot by the imagers which are the 10
images per page and then the the TIFF
image of each page question the question
was which are the original images and
and that's what I was saying it's it's
that that TIFF and then the the app
we're going to make those into a ski
images as well other questions or
comments for any of us here how would
you use this you just host it on google
books as a a book or do you use it on
Google Maps or Google Archie or what do
you do
we welcome your thoughts on it you
mentioned that the manuscript was
copyright of the owner of manuscript I
gathered from what you're saying now
that he's not restricted
he's protectively copywriting it so that
someone else can not claim the
intellectual property from that that he
wants to make it available but these so
that no one else can claim it
propriÃ©taire alee for their
organization or for themselves he does
not want this to become a dead sea
scrolls with these scholars held on for
50 years to these skulls he wants to
make it available and that's why we're
here really because he he feels that you
offer opportunity for us to make this
available we welcome your comments one
suggesting the files directly look at
computer solutions like especially a big
time
large file distribution
where's more scalable impress miss
talisman
okay appreciating the problem there is
that would work well for pushing it
around amongst our our peer group but we
really there's others this has really
developed as a project as people who
have gained insight into it like you all
and who then say hey I think I can help
now many people come up well well is
it's easy it's obvious I can just use
Photoshop and they then find it's more
complex but all the people here who are
working on this project have gotten some
visibility into it and then said hey I
can I can help the question I'm sorry
the question was with regard to
peer-to-peer networks and you appear to
be intact but the and that's where we
want to make this more broadly available
so that people who may not be as part of
this peer group can access it and there
are a lot of people out there both
imaging scientists and mathematicians
who are very interested in this and give
them opportunity they've had no insight
into this or limited in sight give them
the full information allow them to work
with that in any way they want to you
don't necessarily have to dispute your
entire data set
you everybody
you it seems to me that representative
samples would be useful for people that
just want to play around with so you
make the statement was representative
samples alone would be useful for people
to play around with and somebody has an
imaging idea that they want to try out
that don't they don't need your entire
data set they'll try it out of one or
two sample pieces and if that works then
they did they contact you to get the
whole thing don't go here to peer and
send them okay it's goodbye yeah with
respect to copyright and distribution
you may wish to look into the creative
comments or there's two other licenses
that allow you to retain some measure of
Nicole's allowing for public use within
certain areas
you will have to take that up with the
owner and how does that the how does
that restrict you or enhance I mean
suggestion basically we're looking at a
Berkeley style license which is you can
do whatever the hell you are with it
please don't sue us in terms of
distribution we're just starting you
know we'll put a terabyte a disc up and
in a Colo BitTorrent HTTP FTP you name
it and the the core underlying strategy
is massive replication of either small
parts or large parts so I'm naming the
files using an ISBN number and then
identifying you know where within the
document you are so that you have at
least some ability to self identify
these things the hard part though is
once the data is out there you know how
do people start building the gooeys and
that the scholars want how do people
begin applying to different imaging
technologies and and feeding those
results back in because we hope that in
addition to our core images there's
gonna be additional images generated by
other people they look at this and say
well I've got some DSP algorithms I can
add to this and in recovery even more of
the text
does that provide an absolute coordinate
system so
talk about yeah that word yes it does in
fact the question is does the metadata
provide an absolute coordinate system
and yes we have the absolute coordinate
system and then the offset because these
are the leaves are mounted so there's
some offset there and where is 0 0 where
is our prime meridian and our equator so
we define that in terms of the bounding
coordinates and then you can work across
that you look like that didn't quite
answer ok ok are some of the
translations already yeah the Ravel net
yeah the question is are some of the
translations already available yeah Rev
VL Nets is published sphere and cylinder
one with Cambridge University Press and
sphere and cylinder was already in
courtesies a and B but one of the things
that I didn't say is that the Panem says
there's also the unique source of the
diagrams that Archimedes true and that's
that's that's really important because
mathematicians thinking diagrams they
don't think in text and so the diagrams
in the palimpsest a very very important
for that edition Heath translation isn't
really a translation at all it's a it's
a modern interpretation of what
Archimedes was saying so actually
Archimedes is you know a truly
foundational figure in the history of
western philosophy and science that has
never been translated into English
before there are in those learning
articles that I was showing you there
aren't translations but there are
expositions of the things that we found
and the journal was ski Armas for those
that are interested volumes 1 3 and 5
actually so and we want to make this
available as quickly as as quickly as
possible so you know we're hoping for
hoping for transcriptions we've got
we've now got a transcription of the
whole of codex see the whole of the
original Archimedes text except for the
forgeries
and that will be completed by the end of
the year and we're hoping to have it up
on a website together with the images
upon which those upon which those
transcriptions were based and this is a
very important point because of course
you know when you're thinking about what
the original images are you're not
working from a manuscript you're working
from processed photographs which in
which are man-made things and sometimes
you're having to go back to the
photographs that Heiberg made in 1906
because they are now the only source for
the images so it's a rather complicated
set of data to put together and and the
other thing is that in any edited text
there's always an always an awful lot of
guesswork so you know as you know
there's a lot of editing to be done yeah
why do I call them for jurors because
because they're trying to look Byzantine
they're trying to look like their 12th
century and we know that they were done
after 1929 because they copied on a
one-to-one scale from only animals
manuscript to let bibliothÃ¨que
nationale which is an album of pictures
taken from byzantine manuscripts a bit
of a reduced scale but Abigail measured
them and they're just played copied from
it we've also done some pigment analysis
and there's a particular type of green
that only became commercially available
in Germany in 1938 so we actually know
that they were done after 1938 that's
why there for juris the interesting
question is why don't we take them off
and there are two reasons one is that we
might damage the text while we're trying
to take them off and the other reason is
that even if we haven't got the
technology to read under them now and as
you can see we're beginning to get there
in 50 years time someone can someone can
have another crack with more modern
technology and at least we haven't
destroyed the book you know one of the
things about palimpsests is that in the
nineteenth and early twentieth century
people to try and read the text they
used to put all sorts of acidic
paints on them really to paint them over
with iron gall or with a group with a
gala king or even with hydrochloric acid
which would temporarily make the under
text more visible but in the long term
destroyed that destroyed the book and we
could be very glad that grateful that
Heiberg didn't actually do that because
then would be an even deeper trouble
yeah just put that oh that's a good
question yeah yeah the question was who
the soul that you use a really nice
seeing base or what they just printed
out and we our images tried very very
hard to make very very wonderful
pictures and nigel wilson is a scholar
of 60 and he does his transcriptions in
the summer month using a magnifying
glass from a printout but other of the
scholars a very very computer literate
and they they they do use the hard drive
now our interface that we've developed
so far is effective but clunky very
clunky and they would love a better in
the face last question who got the high
sign here in time why why not use a PNG
for the for the images
because it's lossless works in all the
browsers and then maybe have some
JavaScript on top of that too to let let
you see what the translations or
possible translations are over it p any
question was first of all why not use
PNG and instead of tiff well you know
that's a no-brainer we just happened a
tiff is how we capture and transcoding
the PNG is easy second part of the
question is why not build some
JavaScript pull up the pngs lay the text
on top and that's the great beginnings
of a user interface and love to talk to
you more about it yeah what one of the
things we're trying to focus on here is
we think there's going to be lots of you
eyes out there different ways of people
working with this data and similar data
and so part of what we're focusing on is
making sure we got the metadata right
the the transmission method we're
getting this stuff on the net nice and
solid and so rather than spend all our
time doing you know Ruby on Rails
sitting on top of a MySQL database that
does this and that we think a lot of
people will do that level and kind of
our prime mission is making sure that we
get the core data out there but we're
also very interested in how to build the
UI's on top is one other as far as the
the actual image whether it's PNG or
tiff or jpeg one of our key
considerations is the archival
availability this information it's got
to be available thousand years hence
however many years hence we want we it's
a very fragile object we don't know what
its future maybe this may be the only
history of the object and we've got to
preserve that for future generations why
we're actually going back to the basic
ascii with you know basic flat file
there so that anyone in future can put
it into whatever they want they don't
have to worry about whatever version of
the software and maybe and so that it'll
be available for a generation sense so
i'm told that this sends the formal
discussion but we're available for
another half hour if you want to chat
informally so thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>