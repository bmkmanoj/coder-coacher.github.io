<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introduction to the Java Memory Model | Coder Coacher - Coaching Coders</title><meta content="Introduction to the Java Memory Model - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Introduction to the Java Memory Model</b></h2><h5 class="post__date">2017-11-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CTU8XShgorE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone
name is eager mirage can i work on art
we're a java language runtime and
compiler team for android so recently
i've been working a lot on compiler
optimizations in art to reduced amount
of offense instructions and that to
learn a lot about the java memory model
in that time and i thought well why not
share the knowledge sort of everyone
else suggested a little bit make it
easier to understand so in our modern an
ecosystem there can be a lot of
reordering that happens all over the
stack and one way to reason about it is
we can sort of learn about every one of
these tools and try to understand in
detail like what exactly each tool does
and how it does the reorderings and if
it does interview organs at all
so in soon Android in particular just
quite a deep stack so it goes all the
way from that Java source code to class
the Dex to machine code and then to
microbes and the hardware and you're
usually running in at least three
different environments because you can
be run could be starting out in the host
machine and cross compile it onto your
target then your target can compile it
down to actual machine code and you
could actually be executing it on some
hardware and the number of combinations
here can be potentially quite daunting
so rather than trying to learn where
every single of your drink could
possibly happen and and how that works
instead there's a much simpler approach
a java memory model allows us to
understand abstract concepts that every
single one of these items and the the
layers have to follow so if we know what
the Java memory model then we can be
sure we correct regardless of what layer
were operating on
so today I'll be talking about a few
fundamentals concepts of the memory
models hyneman general and then go into
the detail of the Java semantics and how
they apply to those concepts and then
give a couple of optimization examples
so there's also gonna be a Q&amp;amp;A at the
end so if you're not in this room you
can always just use the story link and
we can go over that at the end all right
so the first thing to talk about is a
memory model that's lacks order so
starting out with this very simple
message passing example the initial
state is all 0 and in fact the Java the
initial State
it's always all zeros or notes whenever
we start out with a blank class or you
just allocate an object so if you have
these two threads and then you do the
reads in the rights and opposite order
is it possible that thread two reads the
the B value of 2 and ay value of 0 and
it's a question for the audience anybody
wants to tackle it yes ok right so the
answer is yes that's a little bit
counterintuitive since you would think
that by reading them in opposite order
you're essentially ensuring that if you
latch these two then a is 1 C so to
explain that let's define a couple of
terms first so an action is the term
onnum you're using throughout these
slides
it means it's a small unit of work that
can be done atomically and if you start
out with source code you have these
large expressions they get broken down
into actions but you filed an evaluation
order so in real sort of files it looks
a lot like bytecode instructions on word
size memory and all of the examples like
later on are just single actions
another term is memory locations that's
the largest unit of memory that can be
modified or read through a single action
and in all of our examples the accesses
are atomic so what that means if it's
not atomic then you could actually end
up observing a partial write from
another thread so for example we're
tearing or you see part 32-bit half of a
64-bit value so in the Java language
specification most of the primitives are
guaranteed to be always atomic remember
exs except for long and double now on
the other hand if you're using like code
that's compiled for arm 64 it's always
going to time with no matter what off
for these primitives if you're using an
arm 32 is I mean likely atomic like
ninety percent of time on all the pixels
and all Nexus device will be always
atomic however like in reality it's an
optional specification army seven to
make them atomic so you get in trouble
if you want your code to work correctly
on other devices out there and of course
references and volatiles are always
atomic and so you have to worry about
that and when I say atomic for those of
you see plus plus background thinking
more like relax atomic alright so order
what about order so if you have a bunch
of source code and there's an evaluation
order for that that order is called the
program order so you can reorder that
those actions arbitrarily provided that
same thread does not observe that
reordering so we write this as P otherö
and in this example if you like right to
aid twice and then read it in between
each time you could easily reorder that
or you end up writing the store to the a
ends up being the earlier one rather
than later one and but as you can see
it's not observable by that threads
because no matter what it still reads
the same values in either case and of
course in this example we're assuming
that a you might be overridden at some
later point in time or maybe summer
access at some point in time
so having to find sort of those basic
concepts we can now talk about what
happens across multiple threads so the
most important thing to understand is
that unless there's some kind of
ordering in between these threads
they're into thread or during any action
on any given thread if it looks like
it's executed concurrently from another
thread so I write that down as a or B
essentially and in this example there
can be two ways that reorderings can can
change the expected behavior here so
either thread one is reordered you could
reorder the two actions there or thread
two could actually use speculative data
dependent memory access and you could
predict that the value of a and then
read and then do it or read C earlier
and then later on they would confirm
what a was and then validate those
results but in essence in either either
of these two reorderings would mean that
while thread one observes a to have one
in it the other thread will observe to
have a with 0 in it which is which is
quite strange because in this case
actually intuitively you would think
that the data dependency in thread 2
would save you from the reordering and
so another thing is the access to the
memory locations it's incoherent without
any infinite ordering so in other words
that's coarsely consistent so even the
same like reads here and thread 2 they
could just be arbitrarily reordered and
you could see that it looks like it goes
backwards in time for the value of a
that can happen in practice from a
compiler optimization for example that
doesn't use alias information
okay so with all of these types of
examples there's this the reason I'm
giving them is because the normal
temptation is to think of memory as
having this sort of global state and if
you know anything my hardware at all you
would know that on all the modern
architectures we have cache coherency to
make sure that the captions are
consistent across all the CPU cores and
you could even snoop on the memory bus
with a logic analyzer or use memory
mapped i/o so you can get like the true
state of memory right as possible but
the fact of that matter doesn't really
apply to the Java memory model because
only the code that's being executed on
those threads that it itself observes is
what matters and the hardware itself can
have store buffers or speculative memory
accesses to appear out of order so in
this example of independent reason
penetrates the most complicated example
with four threads of trellis the initial
state is all zeros and then you have
these two threads which write to a and B
respectively and then the thread 3 and
then breath four reads in Reverse so the
question that is assuming that actions
in thread 3 and thread for somehow not
reordered so the magical arrow there
this means are not reordered as it
possible to see the inconsistent state
of the one that's down there this one
any one yes yes right so assuming if you
if you try to think of it as global
memory it would not it would seem like
it's not possible because you either go
down like this left side or this right
side but that's not really the truth and
sort of here's why if in this example if
you execute each two threads on the same
TPU then it could appear the stores
could appear to arrive in different
order so in this
prick Euler example the load could be
forwarded from the store buffer from one
threat to the other and meanwhile the
other store would have to go all the way
to memory and so you would not you would
get this weird inconsistent behavior
that is completely unexpected and again
the important point here is that each
thread observes this memory
independently and by the way this is
actually only happens on some
architectures so for example like power
and army 7 this this could happen but on
x86 or on v8 like this cannot happen so
depending on which like machine you're
running on you you it might look like
you're getting different behavior
alright so how do we like start solving
some of these like ordering problems the
first relation to understand has
happened before and before we can define
that we have talked about synchronizing
with so we have this interpret ordering
between two actions and one of them want
an action that's the sort is called the
release and the other action that's
destination is called in the choir so in
this case in this example that the bee
is the release and the read of it is the
choir and the other catch is that the
action that's the choir has to actually
execute subsequently after the release
action in order to like latch on and
observe the synchronization effects so
this example like this action happens
prior to this one but this action
executes sequence so it guesses and in
Java there's sort of these
synchronization actions are defined
reads are always the choirs and the rice
are always their releases if they're
specified as volatile or monitor or
thread see all right so knowing that we
can define synchronize with it's
essentially taking the program order we
take it synchronize with order and then
everything that's sort of happens in
program order X's re-execute some
program order prior to the release will
appear to happen before everything that
executes after the acquire on the other
thread and in that sense a really easy
way to think about it is you just simply
follow along with the arrows right so
you can follow the arrows to this other
thread just like that then you have this
in Detroit ordinary and you can't follow
the arrow as well then it's unordered
respect to each other and we write this
with a HB arrow and subsequent examples
there's also this nice sort of green
trapezoid here and this means that if
it's angled upwards the instructions
cannot pass the release and if they're
above the release and if they're angled
downwards instructions cannot pass the
acquire if they're below the choir so
this is a one-way sort of a barrier if
you're on the other side of it you can
still execute feel this equals 3 this
could still get moved up to before the B
equals 2 and then if you're over here is
simply 1 equals B could get moved down
to be after the TMP 2 equals B so it's a
one-way one-way won't my blocker alright
so now to restore the ordering from the
initial example all the introduced add
the volatile keyword and this adds the
its adds a synchronizes with relation
between the right and the read and so
transitively we get this happens before
on the other one and so now it's
impossible to get this weird weird state
okay but what if it's unpaired what if
only one of these is a release and the
other one is not an acquire and this
example by the way this bar handles but
don't worry about that
the said release
basically the same thing in the C++
release and it gets to the set just like
a regular memory access that's program
or drive so does anyone have any ideas
sir undefined
I said I'm defined but I guess you're
saying it's possible okay yes yes so it
is possible and next the explanation is
quite simple because there is no acquire
on the read
there's no synchronized with and there's
no happily before so you need you need
those inter thread orderings so another
way to look at it is that the if each
thread observed its own memory then
thread one can only see the memory going
to 1/2 but threat to can see the memory
going to this weird state that's 0-2 so
this is the order you could observe the
changes in here so that's if you don't
want to think about it from the
interpret orderings you can think about
it as each start observing this number
independently yep and so the fix here is
to make the read and acquire and now
it's impossible again and so the insight
here is that acquiring release should
always be in pairs if you want
correctness it's not enough to just put
an acquire or a release and hope for the
best it doesn't work out see all right
so what about sequential consistency
let's see this example code becker's if
you write equals 1 and then you read B
and another throw does basically the
opposite would be is it possible that
you read zeroes for both the values
we're getting some nods in the audience
yes yes it is possible and that's of
course because you can reorder either
either of those two actions there and
simply in program order nothing special
going on there well what if we learn
what if we use what we learned earlier
and use these acquired and releases as I
help because some people are saying yes
maybe more consensus on yes is anybody
disagree they may want to say no no in
the room nobody wants to say no okay can
there be I'd like there was no deadlock
here because there's no locks yeah so
the answer is actually yes surprisingly
enough the reordering is possible and
you could actually even tell that from
the from the trapezoids right because
they're only angling in one direction
and you can reorder them with respect to
each other so even though there's these
synchronized with the relationships
there it doesn't actually help you with
the reorder in that same thread and this
is a kind of a problem because because
you don't you want to prevent this
sometimes so there's this concept of
sequential consistency and it also
happens that pretty much all of the
synchronous
synchronizing actions in the Java
language are sequentially consistent and
so what this means is that there's a
total order for all of the sequentially
consistent actions here and a total
order means that if you have like all of
the possible into leaving this up only
the synchronizing actions that are
sequentially consistent then it has to
look like those interleavings are
totally ordered so in this example the
these are the three possible
interleavings
and the order of execution has to be one
of those so in other words all the
sequentially consistent actions they
cannot appear to execute concurrently
and as for which actual interleaving
happens it doesn't matter you could
always pick like always pick one or
always pick two always victory so the
other actions that are not sequentially
consistent so like the regular program
order actions they do not participate in
its total order and of course like the
there's some bar handle on Tomic
operations which are not sequentially
consistent if you're using Java 9 or
otherwise you got to worry about that
and the other thing to note here is that
kind of all of the all of the rights are
always most accordingly consistent and
release and all of the reaso almost
according to the consistent and acquire
so these are two separate orders you
have to think of so what is a bias it
biases data race freedom because if you
have access that's conflict as in you
access the memory location for multiple
threads and at least one is the right
then if those axes are not ordered why
it happens before then you get a data
race but your program is data race free
if all of the conflicting accesses occur
from these synchronizing actions so in
this example like the you can race with
the rights in the reads but if you have
the synchronized with there then it
doesn't race so if you want to have no
bugs in your code don't have releases in
your code all right so fixing this
example here with Decker's by making
these fields volatile it also makes them
as a question consistent so now they
cannot be reordered with respect to each
other because this SC
prohibits that there and so this strange
result is no longer possible and again
if you're like non-volatile accesses
between two volatiles they can still be
reordered within themselves but the
volatiles themselves access to sort of
like a barrier for non-volatile
actions alright so sort of knowing these
concepts how do we apply it to Java
here's this example of message passing
using volatile so you start out with
this class everything is initially all
zeros the red one can write some data
out they can store an array and then
when it's ready to set this true
that's because volatile it can be you
get a synchronizes with with the read of
it on the other thread and then
everything that's lower afterwards will
happen before everything that happens
here and this is guaranteed to work it's
not reordered so everything is great and
by the way these examples are
intentionally inefficient don't actually
you know code like this with that busy
loop if you wanted to use locks you
could also do something very similar the
locks the monitor enter acts as an
acquire the Minor exit X has a release
so in this case the only thing that
really turns out the matter is the
unlock and the lock so you do the same
thing there the unlock synchronizes with
block here and this also all gropes
correctly so double check locking oh so
if you guys saw my lighting talk that I
gave in Java Singleton's recently I had
performance benchmarks of this and other
ways of doing single tune so now we can
actually explain it with a synchronize
with if you start out with all the
values of zeros or turns out to be a lot
of problems here like the first problem
is that when you write the single time
there's actually no synchronizing with
than any of the reads here so all of
these reads are missing to synchronize
with right and then on the reader thread
you're also missing the synchronize with
from the from the unlock you're missing
the synchronize with
you're missing happens before on the
read of the data and so you get a data
race when you read the I field and also
when you read a data field and so
there's no different ordering whatsoever
I just doesn't work so the way to fix
this is to make the field I volatile and
then all of a sudden get this nice
synchronize with between the right of I
and you'll notice lead lock itself
doesn't even matter how much for this
case it's making a volatile does most of
the job so the this will synchronize
with the reader by and then therefore
the right of the data will happen for
the read of the data and so later yes
actually you yes well you should look at
my slides or the dumbest thing aside go
Java dash singleton stashed liking talk
it has all the performance data there
see alright so I talked about acquiring
release but I also want to talk about
final fields and turns out they also
have their own set of rules that are
subtly different in the choir release
and perhaps most surprisingly they give
you interpret ordering and allow you to
write concurrent code without writing
explicit synchronization so in this
example let's say we want a message pass
that's back plastic cross so you write
out the back you put it into global you
don't xsv afterwards and the other
thread that's reading out the vector see
any partially initialized values yes yes
hopefully this should be this much
should be obvious from the previous
slides it's absolutely zero sort of
interested ordering here but it turns
out if we make these two fields final
then all of a sudden if it prints
anything at all it will always print the
values that were written by thread 1
that being said it's quite hard to be
correct at this data that's being shared
is immutable
so maybe don't do that before I can
define the semantics finals I have to
talk about a couple more sort of more
basic concepts this first one is called
occurs before it can be considered the
least specific into threat ordering and
it simply means that if it just so
happens that an action such as this one
I pierced executes before another action
that would observe that read then you
can say that the in this case the right
will occur before the read and it's
completely different that happens before
it doesn't compose a program order to
forget about that and all of the other
actions in this example they're
completely unordered and they're
concurrent with each other and it
doesn't compose and synchronize with so
it's a separate relation so the other
thing is consumer ordering so I said if
you have two actions sort of with a data
dependency in between them so you can
see that like this C will be read out of
B which is right out of a so you're
basically a deadbeat I see their data
dependent on each other then we can give
that a consume order and what happens is
that if the writer thread could somehow
make sure that the rights were well
ordered with respect to each other then
in that case the consumed ordering will
give us this transitive occurs before
relationship so any anything that is
sort of reachable to this memory
location here will appear to be
up-to-date with ordered reads and in
Hardware turned is essentially
preventing load load reordering on the
other
right okay so well that makes sense in
two more slides from now yeah so freeze
ordering okay when you want to freeze
the memory location with it basically
guys it forces all of the all of the
rights that are freeze ordered all of
the rights to that memory location
become freeze ordered and that gives it
a transitive occurs before relation so
if you follow sort of the arrows here
the freeze all these like rights to Z
will be freeze ordered with these reads
of Z and what you get is like this is
occurring before this so you follow the
arrows and you can see that it's sort of
the freeze order and occurs before and
the consumer order they all kind of come
together ordering here essentially
preventing the store story ordering in
that thread for any sort of accesses
that are affected by the freeze see okay
so putting those together we can now
define final fill semantics so if you
freeze all of the final fields at the
end of the invoke constructor then what
happens is that all of the rights that
are reachable from that frozen field
will be observed by all the reads that
emanate from those memory locations on
the other thread so you essentially get
this recursive all the rights on the
field are ordered on the right of thread
and all of the reads that are coming
from that field occur slowly are ordered
on the reader thread and we call this
into third or during the frozen of
ordering so it's kind of like
synchronize instead of synchronizing
what's called frozen worth
well then you don't execute the I mean
you don't actually the freeze then right
so the freeze always happens at the end
of the endo constructor so if you have a
throw prior to the freeze and obviously
the freezes not get executed yeah but if
you have like several nested
constructors then the previous
constructor could if it still freeze it
that's the trick here yes sort of
actually an example for that which might
answer your question okay so this
example now that we sort understand
freeze ordering and frozen words and
occurs before it should be possible to
explain this so all of the writes on the
thread are freeze ordered with respect
to the freeze and in the freeze itself
is frozen with so all of the reads of
that data and all of the data dependent
accesses are consumed ordered so you can
this occurs before relation and all of
these sort of actions here with all of
the read actions here and so in this
case you'll always print either one and
three or you'll all you'll hang in an
infinite loop so the way to think of it
and just like practice is that as long
as you safely publish the object if you
write it out to shared memory after the
constructor is over then all of the
final field values will always be angels
red visible it'll always be observable
up to date on the read of threads cash
flows
it's well caches have nothing to do with
this are you asking how it happens in
hardware yeah okay so the readers side
uses a star star barrier it's using a
DMV is H and arm and that prevents all
the stores from being reordered so this
this here is called like the publish so
this is what allows the other threat to
potentially see it and then on the
reader side you don't need to do
anything special in arm because all of
the data dependent accesses on arm d7
are non reorder Abul so we just make
sure the generate code that is using
data dependent accesses so there's no
like sort of with us is a store buffers
I think it doesn't flush the cache
alright so what if you try to be like
clever and licks finals and not finals
what happens then well you get this
freeze ordering on the final field so
that's great but the non final fields
are missing any kind of ordering store
as you can see so there's no occurs
before the read of the non final and the
right of the non final so even though
you'll always observe the final field to
be correctly up to date you could still
observe the non final field to be not up
to date so any memory that's reachable
from the non final field in fact you
could even have the same memory location
both in the final field and in the non
final field if you access it through the
non final field you don't get any of the
guarantees so you don't get consumed
ordering so try not to mix and match
because then things will get really
hairy alright so the single Sun example
way I guess it doesn't even need to use
double check locking here you simply use
it use the regular field here the static
global here so the thread one can end up
creating it and then publishing it and a
threat to if you print it it will work
you will get the up-to-date values there
so the general case is
like this lazy yet the way you construct
the single stone has to be idempotent
because what you could end up could end
up happening is you create multiple
instances of the singleton of this or of
this lazy value but you won't know which
one you actually got but as long as you
don't care about object identity which
is very rarely the case
sorry referential identity rather then
this is good to go so there's no actual
racist here if it actually does in the
shot is successfully and everything
still works so if these types of
immutable values were if you make a copy
of an immutable value it's still the
same value it doesn't actually matter if
there's a copy and 99.9% of time only
one of these will get created anyway so
this turns out to be a way to safely of
sharing between different threads
they're actually having any explicit
synchronization all has to be done here
making this final and then making sure
it's immutable that's it it's all very
easy
see all right so what about some
examples of optimizations where can
things get hairy okay so I kept saying a
couple times how you don't always have
loops that could terminate this is one
example with a very simple we could just
write to a and this thread one forever
right so it totally it'll be too
eventually right I don't think and
thread two if you first write to a then
you just keep looping forever until it's
printing to like one would think it
eventually prints done but because
there's no synchronized with here
between the right and the read the
threat to can say well look this is not
observable from other threads so I saw
that one was written up here earlier so
it must always be one forever and ever
so I can just read it out once don't
bother reading it out again just look
forever the friend that will never
happen and because this is Java infinite
loops are well-defined behavior so it's
not gonna you know you're not gonna get
some like clever like it prints it done
anyway type of optimization you'll just
get stuck and it can happen quite easily
with the loop and marién
code motion just like a sort of very
standard optimization all right so what
if you try to also share this immutable
list without a final so what can happen
here so I just said earlier like if you
actually do read it out then everything
is good it prints out the right values
but and there's even a race to this
array which is actually benign it's fine
but the problem here is that since
frozen wood is weaker than happens
before you know this thread doesn't
actually need to ensure that this really
happens you don't get that sort of
eventually guarantee because this read
itself is just program ordered right
it's not in a special ordering to it and
the program ordered like the program
order to read could essentially get
moved out of the loop same thing as the
previous slide loop invariant code
motion and then you can also see that
this also could get moved out of the
loop because why would you do it more
than once like clearly if it's either no
the first thing we're it's not in all
the first time and why would you redo it
and then you end up with this like
infinite loop forever and that was case
so oops get stuck again
probably doesn't really happen in
practice but it could happen it's a lot
so in other words don't put infinite
loops if you're gonna do like immutable
data sharing okay what about this what
if you have also no finals no volatiles
what can happen here so thread two tries
to make J it pushes it over to thread
one alright so you push it over by
writing the global thread one patiently
waits until J
is ready then it takes K writes K but as
this writing K else updates J and it
pushes to the back so a threat to
patiently wait until K is ready then
tries to read the J value from K if it
sees that that J value is the same thing
as it had earlier which is this one that
will actually print the value otherwise
it doesn't do anything
so either this could print three which
works as intended or cut print zero
because you had a data race or prints
one because you could optimize and how
does optimize that they shouldn't happen
well it sees that the value you read is
J but you already know that J had one in
it so why would you ever do this lower
just a waste of memory access you just
print one instead this is called a must
elias type of optimization so this can
also trip people up and by the way this
could not happen in finals and the final
is you're guaranteed to get the memory
access so the fix here is to make it
finals and so now you have this nice
frozen rid of the relation and this is
consumed ordered and when it's consumed
ordered you can do most alias
optimizations so that's how you save
yourself all right so I have some bonus
slides here you guys can read this
offline
it's talks about class initialization
fuck stupid how did you enter class
Singleton's finalization so rather than
going over that now it gets complicated
offline if you want there's some further
reading here so if you want to know sort
of more about this hopefully now the
language is less mystical now that being
said all of these documents tend to use
completely different terms for the same
set concepts so they might not always
call it happens before they might always
call the synchronize with and one thing
to note here the consume ordering that's
a C++ term it does not really exist in
Java but I repurposed it to make it
easier to understand the other final
field orderings the occurs before and
for
it's also terms I made up for this talk
so freeze is actually jail s term you'll
find it in the JLS but the other
orderings are not and that's because it
was very very complicated to understand
our final field works without these two
orderings there's also jt9 if you want
to use the memory ordering modes there
it turns out you get the same exact c++
memory orderings with jdk nine more
handles as you would get in c++ and yeah
that's so I I want to say big thanks to
Huns Boehm he's helped me learn a lot of
this he also reviewed these slides so
Korean I've done this with autumn and
there's it sorry yes so the slides are
available at go Java memory model you
can put them on this Dory or IX are you
asking about direct byte buffer yeah if
you obviously in fact what I would say
is officially there's no memory ordering
when you're going to J night but if
you're asking how you want to coordinate
the access to that we could use like an
acquire and the Java for example and the
release in C++ saw and they'll happen to
work together they did the choir music
offense to you don't have to use a
volatile yeah
that question no I don't know this is
all program or Bert yeah yes okay so
volatile reads volatile rice and x86 are
completely free because x86 all the
loads and stores are basically
automatically acquire release and on
well okay so it's not quite sure that
they're completely free because you
still have to go to memory for that so
you can't like optimize it out can
optimize out the memory access but in
terms of instructions yes they're
basically free on arm you need to have
like an arm be a unit have a LD AR which
is a load plus and acquire or STL are of
the store plus a release or if you're an
army seven you need like the load and
then a DM B and then the store and then
the two GMB so you actually get three
DMVs then in that case if you're using
army seven so yeah it's way more
expensive to use volatiles on arm than
it is on x86 I mean you don't really
need that the general I mean a general
rule of thumb is that you want to avoid
too many atomic actions that's about
what's a bad term to use too many
lock-free operations repeatedly because
if you're doing too many of those then
all of the sort of the retry times all
the contention and all of the
all of them reordering inhibitors will
sort of add up and they'll cost you a
lot so the rule of thumb is actually
that I even had for example in my other
talk is to try to use logs whenever
possible because the locks
they'll very rarely contend with each
other and so they'll give you the very
fast speeds that are only a couple of
nanoseconds like slower than regular
volatiles and the locks are also just
acquiring releases so they don't have
actually the the unlock operation for
example a simply release star on on most
locks because you don't need to do a
compare and swap on the unlock you only
need to do the compare and swap on the
lock so that any kind of any kind of
like locks including synchronizes oh
yeah yeah yeah so yes I guess I mean I
guess you could but x86 is basically a
superset in terms of the memory model of
arm right so you could just write the
code as if it was forearm and then I'll
work just as well in the next day of sex
that answers your question yeah all
right any more questions in the room or
all right well thank you all very much
for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>