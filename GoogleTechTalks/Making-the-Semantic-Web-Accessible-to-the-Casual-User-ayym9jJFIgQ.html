<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making the Semantic Web Accessible to the Casual User | Coder Coacher - Coaching Coders</title><meta content="Making the Semantic Web Accessible to the Casual User - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making the Semantic Web Accessible to the Casual User</b></h2><h5 class="post__date">2008-07-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ayym9jJFIgQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to the Tech Talk today it's a
pleasure to introduce professor
Bernstein from University of Zurich he's
a professor at we were chefs Eric since
six years and before did a PhD at MIT
and since about three years he's looking
into exploring natural language also in
the context of doing web search using
natural language and so the tech talk
today is about how to use this language
and how to make it really accessible to
everybody and it's a great pleasure to
have you here okay thank you Thomas
thank you very much it is a great
pleasure to be here
the last time I spent a significant
amount of time in this general area
campus this was still a beer brewery so
I guess we're changing over from a
fountain of beer to a fountain of
knowledge as Google has moved here or a
fountain of information on the web what
I'm going to try and do today is talk a
little bit about one of these studies
that my PhD student who just graduated
ester Kaufmann mainly did which was
looking into language and how people are
able are not able to put together
certain things that they're trying to
find out into language and it's in
specific natural language and I'll be
telling you more about the study
essentially throughout the whole time
actually I was never told how long this
should be about an hour okay before
before jumping into this maybe let me
just quickly tell you what I'm doing I'm
doing essentially two things I'm looking
on the one side of machine learning
different errors in within machine
learning that I'm looking at is
relational machine learning so trying to
extract knowledge from relationships
between entities rather than just
attributes or features of entities and
I'm glad to talk about that more we're
doing stuff with banks where we're
trying to do some fraud detection we're
looking at temporal data mining and some
of the stuff with that we're also
looking at probabilistic reasoning to do
NMR analysis nuclear magnetic resonance
spectrum spectrometers analysis on the
other side I'm doing stuff in the
Semantic Web and that's much more what's
what's prominent to this talk here where
as I take the Semantic Web as
very open specification so I don't say
it has to be description law logic but
it's actually the attempt of putting
semi-structured information out there
that can be processed in a machine in a
machine way there's essentially three
areas where we have been focusing on one
as we've been trying to use a
combination of inductive and deductive
reasoning to get somewhere this is our
eye sparkle or work that we've been
doing Sparkle as the general query
language to query Semantic Web data we
have been doing some stuff on query
optimization where we have a recent
paper and just now and vldb where we
show how sparkle queries can be
optimized much better if you have the
appropriate storage structures and last
but not least we've been interested in
finding out how people can actually get
access to this information now just to
kind of set the stage how many people
here know what the Semantic Web
supposedly is I mean ok I see some
people let me just give you just a very
short kind of idea or a notion of this
this is another slide that I wanted to
pulled out because I thought you guys
definitely know what the web-based I
don't need to tell you guys the idea
behind the Semantic Web where the
original idea was that rather than
putting out pages of information what
you do is you put out different
assertions at different places so
different statements about whatever you
want to make statements about so you
know the easy thing is you know you have
a penguin called pingu I don't know
whether you know Pingu Pingu is a very
popular children's show TV show
character here in Switzerland and I see
there is a font problem here this should
be in exists and existential so there
exists an ax where penguin X that
implies that X is a bird and then we may
have a second knowledge base which
brings up another thing that doesn't
seem to work with the fonts so there
exists a Y where a bird Y implies that
the bird can fly and obviously what you
see is you have two different knowledge
base two different places you get
conflicts etc etc but that's the general
idea of the Semantic Web you have
assertions out there rather than just
text or rather than just
HTML and you're trying to exploit that
take that data together and make some
statements okay so the logic of the
Semantic Web or at least a proclaimed
logic of the Semantic Web is this thing
up here which is something called owl in
it's absolutely unreadable XML iteration
or for human purposes almost unreadable
so it's a description logic you have
classes you have relationship between
classes you have properties of classes
and relationships between these things
so what you have up here is you have a
city a class city it has a subclass
capital it has which is a subclass of a
city you have a city population which is
a property that has a domain of city and
a range in this case of a float which is
probably not quite necessarily correct
it probably should be some type of
integer rather than a floating point you
really have a point three inhabitants in
the inner city but anyhow you have this
model which very much looks like a
object-oriented model and you can do
some reasoning about it and there is a
query language that goes along with it
which is you know your standard sequel
like query language only that it doesn't
have a Fromme statement because you
don't query from a database but you
query from the collection of asserted
statements that you have people are not
really good at looking that way people
who seek information or try to
accomplish something are not really good
at putting together these statements
down here right so sequel is not their
game or said differently and that's
essentially what was driving our
research here how can we bridge this
huge gap between what Semantic Web
researchers are actually any kind of
database has namely this logic based
knowledge base or database on one side
and people who are at least ill-at-ease
but usually incapable of putting
together formal logic statements
actually there is plenty of research in
psychology and other areas that
shows that we are really not good at
putting together logic there is a study
by what's-his-name
on some Sperry early 90s who used MIT
undergraduates he had a an information
retrieval system where he had people
either assemble boolean logic or use
some graphical based query system that
uses Venn diagrams and even you know MIT
undergrads are supposed to be
brainwashed with logic were not able to
do this you know well with you gave them
the bulgy boolean logic statement as
compared to when you gave them kind of
Venn diagram like graphical
representations so we can assume that if
MIT undergraduate students are not good
at this and I guess I can do a little
bit of MIT bashing since I'm an alum
even you know if they are not
comfortable of doing this why should the
general public so how can we bridge this
gap and that's kind of the underlying
question that we're that we're trying to
look at so what are possible answers
well one possible answer is natural
language it might not be the first
possible answer that you have been
thinking about other possible answers
man what do people do with databases
today I mean the disdain a thing that
people do with databases today is you
know query by example where by example
is relatively straightforward right you
have these forms these forms kind of
represent in somewhere your database
structure people fill out whatever they
know they hit return and they see what
kind of results they get so query by
example doesn't work if you have large
or semi structured databases because the
structure is not in first normal form
so first normal form would be that every
attribute is a primitive data type right
and if you have the attributes not being
primitive data types but aggregated data
type suddenly your career by example
statement has to refer to objects which
are again complex objects which are
again aggregated objects etc etc and
query by example suddenly becomes a very
complex and complicated proposition so
other things you could do
is graphical user interfaces and this is
actually something that we compare
against later so that you would have
objects and you have relationships
between objects you have people draw in
Oh boxes and arrows and stuff like that
although I want to say that we as
computer scientists or at least I'm
assuming you're at least computer
science you know related or somewhat
have been heard something about computer
science in the past we have been all
kind of a gently brainwashed into this
idea that these boxes and arrows have
certain semantics and they have a
certain meaning and it's not necessarily
true that the general public is actually
comfortable with dealing with boxes and
arrows there is a nice paper by David
Karger and MC Scheffel about the fallacy
the pathetic fallacy of using graphs to
represent data because they are a good K
are a good knowledge representation but
they're actually not a good
representation of that data for human
consumption for average human
consumption okay so one alternative
would be natural language natural
language is an alternative because we
have all been learning it for the last
you know whatever however many years
you're here we have been learning
natural language rights it's something
that you've been using day by day it's
something that most of us are plus-minus
comfortable of expressing our desires in
I saying
plus-minus but since this is not a
psychology talk I'm not going to focus
on the minuses as a matter of fact there
is an argument by somebody named turtle
who developed a system to actually
front-end to some of these legal
databases that have legal cases in it
for the u.s. that lawyers and people who
do research for lawyers are more ill s
or are more comfortable at putting
together natural language queries then
then boolean queries I have to say that
turtle that the study in 94 you know you
could argue time as passed since people
people have learned differently the web
and definitely querying on the web
has not been as prominent in 94 as it is
today so people may have changed their
habits
however natural language is a mess
it is linguistically ambiguous and
variable oftentimes we develop whole
protocols in conversations around how to
actually make clear what we actually
mean the it is often seen that there is
a certain adaptivity barrier and NLP
systems are usually tied to certain
domains and in order to work well there
is a whole lot of work that needs to go
in if you want to have them work on
another domain there is a number of
quality of performance issue be it a
speed be it also quality of answers and
and in addition to that we're not yet
done there is this thing called the
habitability problem so the worst thing
you can do is somebody is put them in
front of an empty profit while granted
you know when you put somebody in front
of a Google search screen they have been
socialized into knowing what to put in
there if you put someone in front of a
prompt and say there is a knowledge base
behind a query they'll go well what can
I ask what can I not ask what is it
actually that I can type and there has
to be a certain understanding in their
mind as to what the system can do and
what the system cannot do so users need
to understand what's possible in order
to actually know what's - right last but
not least there is obviously this
question as to is analyze this whole
field of natural language interfacing -
- knowledge bases or - databases
completely redundant given that we you
know where we have been in a generation
of you know search by keyword and
clicking start it by that we started off
with this question that is it really
this way and is natural language useful
or in do casual end users and we put a
big emphasis on that casual end users
find natural language query systems -
and this specific case ontology based
data repository is useful although you
could probably draw
the ontology base away I don't think
it's actually necessary to their
experiments that I'm going to show you
so how do we go about doing this so this
is this is the point where I'm going to
try to tell you a little bit about the
setup what we did first is we were
thinking of how can you think of query
languages and of structures of query
language that people may want to use and
we came about this theory that comes
from sociology called structuration
theory structuration theory is offered
by anthony giddens
says that in order to be able to act
people need a structure in order to be
able to make meaning of things we need
some type of structure without that
structure you know everything we
encounter is just symbols that have no
meaning it's the structure that lets us
put relationships between those signals
and actually make us understand what
these relationships between those
signals and what the signals mean so
that's one end on one side of the
structure structure also has another
side which is whilst that enables us to
make meaning it also prevents us from
seeing other aspects in the data so it's
also constraining right if I happen to
look at my laptop and what I see is a
computer I will most probably not use it
you know to to swat flies if I want to
if a fly bothers me it's because it's
not in this set of concept and all of
those who've seen this movie the gods
must be crazy where coca-cola bottle is
being thrown out of an airplane over the
over the Namibia desert and a tribe of
Bushmen picks up this coca-cola bottle
and they put this coca-cola bottles to
lots of users
none of them which is fill it up with a
fluid
you know our structures and our
knowledge structures in our
understanding actually form what we see
in things and how we use those things
they enable our action but they're also
constrain the actions that we can do
so structure is good because it allows
us to do stuff but structures are so bad
because it prevents us from doing other
things so how can we use this to
operationalize our question that we have
before and what we did is we said we
should look at languages or query
languages of different degrees of
structure or formality and so what we
said is in innocent in essence there is
this kind of spectrum between highly
formal language on one side and I just
put Sparkle here put first or the logic
here puts equal here put put boolean
logic here put whatever your favorite
formal language is here and on the other
side you know somewhere is natural
language natural language has structure
you know if I would say it doesn't any
linguist who would come by with wood you
know would come and shoot me there is
definite structure in natural language
but it's some other end there would be a
completely unstructured language query
language that we did not look at but
what we try to do is we try to imagine
what our different query languages on
the spectrum between highly structured
formal logic which we have a strong
feeling about that your casual user
would not use it and on the other side
as a query language with as little
structure as possible by the way I have
a strong feeling about that this doesn't
work you guys have real data on this we
don't the last publication that I know
off that kind of characterizes search
query engine data gathered by search
engine is by Spink at all it's a what is
it 2001 or 2002 publication and they I
think looked at query or real queries
gathered from either like a sir or one
of these query engines and they saw that
only one percent of all queries actually
had boolean statements in them and of
those about half the boolean statements
were incorrect yes
yes so I may want to point out that this
is this is not this is not good here so
there the natural language is not the
right and oh sorry I should I should
repeat the question so the question was
he wants to point out that web queries
or web searches are actually off to
scale and my answer would be yes you're
right
the rince nomer there is that I put
natural language at one extreme which it
is not I would I would say you know you
guys are or keyword search let's let's
call it keyword search is somewhere here
and then there is something that doesn't
have structure at all which I don't know
what it means but you know you there
could be something that doesn't have
structure at all there is a certain
structure in the way you guys interpret
when I enter keywords or any search
engine interprets it so there is
structure there there is an assumed
structure there at least from all the
users when they tell me oh I do this and
that and sometimes I don't understand
what that would actually mean the way
search engines process this stuff but
there is definitely structure that there
is less structure there than not your
language absolutely and you'll see that
what we're actually going to do is we
developed four different search engines
which have different degrees of
structure based on the same data set we
gave people the same tasks the same
people the same tasks using all four
systems and different orders and we
looked at which the systems did they
perform best and the system on the far
left here this thing called NLP reduce
is the least structured system it will
actually take whatever you enter in
terms of words so for example if I'm
staying with this u.s. geography dataset
which is actually the one we use to do
our experiments you can put things in
like cities size Georgia or size of
cities in Georgia or what are the
population size sizes of cities in
Georgia and it will process whatever and
we'll try to make best guesses about
what you're actually doing
so that's NLP reduce and we called it
NLP reduce because we try to use as
little
LP is possible we actually try to use
actually we didn't use any NLP would be
the right word so and we try to just to
do a best guess on what the answer was
the next system over is called queries
because it actually expected correct
English sentences so it was parsed with
a NLP parser the stanford parser and i'm
going to explain how each of the systems
works in the next few slides just this
is just kind of to get to give you an
overview so here you'd have to enter
things like give me the population sizes
of cities in georgia or what are the
population sizes of cities enjoy here
you need full sentences otherwise
queries will come back and say sorry
does not compute we also had a system
called ginzan ginseng is a system that
actually only or was only able to
interpret a small subset of english
language so it looks English it's
actually a formal query language and
last but not least because we did not
want to confront our end users with real
natural language I started with real
formal queries or boolean queries or any
type of formal logic we confronted them
with boxes and arrows and we had them
draw relationships within things with
something we call semantic crystal so
let me do the following let me walk you
through each of these systems and then
afterwards I'll explain you what kind of
experiments with it and to see what so
how did people actually react to this
because I think that's the interesting
part so the systems are throwaway
systems right we just build them to run
this experiment who they are by no means
the best NLP system spared they're by no
means the best query systems they're
really throwaway prototypes to run this
experiment they were specifically
developed for their for for these
experiments so NLP reduce takes keywords
in any sequence in any form will
absolutely ignore whatever order these
keywords are being used
and have been entered and we'll try to
make the best out of just taking these
keywords what it will do it will do a
stemming of the of the input questions
it will then try and sort of input words
it will then try to take each of the
words and find them in the knowledge
base so if you have cities it will try
and find cities in the knowledge base
and it will probably find it in a class
that's called cities as we saw before
there is a class called cities it will
look for Georgia it will not find
Georgia in the class hierarchy but it
will find Georgia as an instance of
state and that way it will try and find
each of the words that he can find there
after it will try and find connections
between those BIR words within the
knowledge base and it will try to do
that by having those connections being
the shortest possible in the graph
that's essentially being put up by the
knowledge base and then it will try to
take these connections and turn those
into a logic query so how does this look
like you enter your question and you get
the answer below and some type of
logical query is being generated
specifically the user enters the
question on the top left sorry that even
before you take the knowledge base you
index it so that you know where all the
words are in the knowledge base you then
reason about that so you can get to the
closure to the logical closure using a
reasoner you take all the words that you
have you build up all the synonym sets
so you have all the synonyms and and so
forth using wordnet so we have town
urban center metropolis municipal etc
and that way we have a lexicon which is
the lexicon of words that we know that
we can use that we can interpret when
the user now enters a question on the
top left we use that question that
queries for example how big are the
cities in Georgia report the stem
big B City Georgia and we now try to
find those in the triple store which is
enriched with the synonyms and the
inferred statements based on the logic
we match them against these we try to
find some type of minimum spanning trees
that connects all the properties that I
found put together the logic query in
this case select star where city has
population some value and city is city
of Georgia so it's in the state of
Georgia and then we run this query and
we return to the results okay so this is
very simple very simplistic this is
nothing your eye phd's about you
probably don't even write bachelors
about this okay what's the next system
the next system is queries and what we
found when building NLP reduce is that
in many cases those connections are
quite ambiguous or the relationships
between the words that get entered in a
query and which word in a knowledgebase
it should be or ambiguous it's not clear
what you actually mean so give me the
biggest city in the u.s. well what do
you mean do you mean by area do you mean
by population
what's biggest me okay so we build a
system that's a little bit smarter in
terms of linguistics it parses full
english sentences it does also do if a
synonym expansion of the knowledge base
it does full question parsing and then
tries to find the triple patterns he can
find in the parse sentence in the
knowledge base to generate the sequel
the sparkle query and when it hits
ambiguous ambiguous questions so like
what is the biggest state in the US in
the u.s. it will come up with a question
box that will say and I'm sorry this is
probably too small to read biggest state
means highest value of the property
state population density or means
highest value of the property state area
in which case it will be Alaska etc etc
cetera
would ask you back and that's why we
call the query 'xh because it's a little
bit like get effects I don't know how
many of you know Asterix and Obelix
which is this droid that all the
villagers of that village go to whenever
they have a problem and he gives them an
answer okay so let's see how this works
just very quickly again from the bottom
I'm not sure this is nicely no this is
not as nicely animated so I'll have to
step in here so we take the knowledge
basis that we have we take a reasoner we
read it in we reason about it we do a
wordnet expansion again on the synonyms
etc and store everything in this
extended knowledge base then what we do
is we take the query that's entered and
we analyze it using a full NLP parser in
this case the Stanford parser and then
what we have is a sentence structure let
me show you in detail what that means so
we take again a similar question as we
had before what are the population sizes
of the cities that are located in
California we get a parse tree that
looks something like this right what our
verb the population sizes of the cities
that are located in California we only
take the Leafs with the types what type
of word it is and we throw away two tree
structure and we end up with this thing
what we now do is we take the different
words and we expand them with their
synonyms so population sizes inhabitants
citizen number magnitude measurement to
set our cities town metropolis urban
center municipal etc so that's what we
do one the one Sun what we also do is we
try and find certain triple patterns so
patterns are three things that are in
relationship to each other that are
often found in questions so we have
something like a work verb pattern
that's the green one here
what are the population sizes we have a
preposition pattern population sizes off
cities and we have a wh patterns and I
got a question like that one of the W
words right that are located in
California what we're now trying to do
is we're trying to construct all the
triple based relationships that we can
construct from these things that we
found here and we're trying to match
them against the triples which we found
so the relationships that we found in
the knowledge base that have these words
in them so let's go to the knowledge
base and we found all these
relationships that have at least one of
those words in them that are in the
query so we have are something like the
relationship between a domain which is a
city is city off there is a relationship
between is city often are an arranged
state we have the word population size
which actually shows off in a synonym of
has population that's another property
that connects a state or a city with
some type of number we have cities which
actually shows up in two contacts like a
city is a city of a state and a state
has a city which is a certain city and
are allocated etc and now what we're
trying to do is we're actually trying to
match the callers above with the
statements below and the way this looks
like is as follows you take for example
the screen statement and you see that it
fits very well with this domain state or
a city has population and a range number
and that's what we do with each of those
bubbles that we found above the possible
triple patterns ended in the question
while the red pattern actually matches
the same triple the same relationship
between a thing so having a certain
property and another thing and the blue
one actually matches against those two
as a next step
we throw away the ones we couldn't match
and we're saying okay if these are the
remaining triples they need to be if we
need to be able to hook them up in some
way right we need to be able to join
them otherwise we're getting you know
all the states that have a certain
population so we need to be able to hook
them up in some way so we're looking at
the domains and ranges that match so we
can do joins and in this specific case
we're ending up with this relatively
simple query that says we have a city
that has a certain population and we can
join this city with is located in
California and we get the population
size okay so that is a system that is a
bit more elaborate it is the closest
what we build to a full-on LP system
still a very simple system if you
compare to other NLP systems okay the
next thing is ginseng ginseng is a
system that essentially takes the KB the
knowledge base or the set of assertions
that you have and compiles all the
possible questions that you could ask I
mean this sounds odd but in some sense
it is doing that it takes the knowledge
base it extends it again with synonyms
and antonyms and then compiles a grammar
from the knowledge base and combined it
with a simple question and asking
grammar to put together the grammar of
all possible logical questions that the
simple system could answer and in that
case once you enter the question all you
do is incremental parsing through your
constructed grammar to construct the
query that you have to answer so it's a
very limited system it can only answer
the questions that the people who built
the original question grammars actually
thought of as a question that could be
possible to be asked but it is being
enriched by the knowledge base that's in
terms of answer so what happens is you
type along and you get these dropdowns
that tell you how it works what what the
possible things are
that you can enter so the system again
as a diagram is very simple you have a
simple static question grammar which is
just what is a standard form of a
question
you take the knowledge base and you
compile your actual grammar which you
then use to interpret incrementally s
people type what is entered so this is
like you're in Eclipse and you get these
drop-down boxes of what the possible you
know
methods are that you can call ok last
system the last system is semantic
crystal it's essentially a system that
allows you to drag and drop together
concepts from the knowledge base and
draw arrows between them to do these
boxes and arrows thing and essentially
what you're doing is you're putting
together logical queries semantic
crystal looks somewhat like that so here
you have the things that you have in
your knowledge base and you drag them
over and then you have something like
this up here kind of I'm just enlarging
what you have here so question mark
States that's a variable you'd like to
have back you have a state in a river
they're connected through runs through
it's the Rio Grande and what states does
the Rio Grande run through ok so far so
good I don't think those systems are
very exciting in themselves they're
exciting when they put together in one
usability study so what did we do we
took a bunch of subjects and we gave
each of them the four systems to use we
gave each of them a set of questions and
each of them use the four systems in
different orders so we get the
statistical cleanliness of such a
usability study and we looked how well
they performed and we asked them what
they liked and let me go through that
for a moment so again four systems the
task was they were given four questions
and I'll show you in a moment what those
questions are they need to need to
reformulate them and enter them into the
system find answers we did a promotion
on websites and billboards or answering
we got 48 real people meaning we got
almost any profession we think we
excluded psychologists because
psychologists make offer awful subjects
the reason if psychologists get there is
a real reason to talk to any
experimental economists the
psychologists have been trained with so
many experiments in their training that
usually when they're being put in an
experimental situation they're trying to
find out where they're being tricked and
they're used so many mental cycles on
finding out how they're being tricked
that their results are influenced by
that fact and therefore they're don't
make for good subject so we don't you
didn't use that card I think that was
the only exclusion criteria we had we
have completely evenly distributed its
backgrounds bankers sorry we're in
Zurich so they come first but all just
housewives musicians teachers we had
some unemployed people it's amazing how
many unemployed people actually do you
know experiment hopping because it's a
way to get some additional income we we
made sure we didn't just have unemployed
people because that would skew our our
results as well we had aged between 90
and 52 with an average at about twenty
seven point six years we took a dataset
that was given to us by Ray Mooney down
in UT Austin it is this kind of simple
database of us geography it has states
capital cities rivers lakes mountains
lowest points highest points and
relationships between each of those
things and we ask them questions like
what is the area of Alaska what are the
number of lakes in Florida what states
have a city named Springfield there is
many states in the US that have cities
named Springfield rivers that run
through the state that has the largest
city in the US and things like that so
it's an increase in complexity and we
essentially gave him all these questions
which each with each of the systems
obviously the questions were different
for each of the system so it wasn't like
area of Alaska was area of Alaska was
you know population size of
New York but the questions were of the
similar type we observe the people using
Marais Marais is a wonderful tool the
person sits in another room you
essentially see mirrored what they do
and every click events that they get so
this is a picture of what the what the
actual the subject gets you get the
event you know the person moves the
mouse you can see how the mouse being
moved etc you see you can observe
everything and we annotated whatever
they did the experimental procedure was
essentially as follows they got a piece
of paper describing the overall
experiment and for each query interface
in varying order they got some
instructions a one-pager how does this
work the system work they got the four
questions they have to work on and they
executed them then they filled in a soos
questionnaire the sooz is what's being
often called the quick and dirty
usability test it's a test with I think
ten question on on the five-point Likert
scale that people answer how much how
much did you like the system as suitable
did you think was your system to this
use blah blah blah etc then they filled
out a comparison questionnaire between
the systems and at the end they provided
an answer to a demographic questionnaire
so we would have data about them so now
it becomes interesting first of all
average time to fill out the queries the
average time to fill out the queries has
a structure that I think is something
that we would all expect it essentially
tells us the more structure you impose
on people the longer they will have to
fill in a query right so we go from NLP
reduce which is your keyword based thing
on one side down to semantic crystal and
you see the more structure you impose on
people the longer it takes them to fill
out the query and this is a signet
highly significant with the usual
t-tests that you would do on such a
thing
it is especially interesting that the
time between the shortest which is NLP
reduce and the longest is is huge I mean
you know this is almost four times as
long that people take when you impose a
logical structure on their careers now
again this is time it doesn't mean how
good the answers were that they got let
me go on here second how happy were they
with the system so that's the soos
questionnaire essentially is the higher
the number the happier people with the
system and what comes out here is that
interestingly enough they were happiest
with critics remember query exists a
system that requires you to put in full
English
you cannot put any keywords actually
they were significantly happier with
queries then with the keywords right
this is a the year 2007 this is not 1994
like turtle they were happy they felt
much more comfortable with the system
entering full sentences this is not what
I would have expected I would have
expected their happiest with you know
keywords because it's the least work
they were least happy we're semantic
crystal again because it puts the burden
of the structure on them but it seems
sorry one more thing the difference
between Jane Zhang and NLP reduce is
actually not significant so it seems as
if structure makes them happy to a
certain degree
now now Giddens you know would be happy
and dance around here right he would say
sure because we all love structure we
have been tossed to you structure and
we've been all taught to use language
structure since the age of 1 or whatever
it is
so the question or yeah I just have one
question
it seems to Kirks though you have a
the dimension it has interaction in it
yes I mean to me that could be an
explanation for this yes it actually to
a certain degree is and I'll get to this
further down but oh I can the
qualitative answers that we got was or
one of the qualitative answer was they
trusted the system more that was having
an interaction with him and since
queries had this type of is this what
you mean they trusted it but that was an
element of trust the Suze questionnaire
was was was fidgeting apart the trust
issue though from which system were you
the happiest with kind of which did you
find the most comfortable and easy to
use and and I would argue keywords are
easier to enter than full sentences I
mean I I know how it hurts my hurts
myself when I yes but when the users
filled out the question is they already
knew the answers or they were happier
with results from one system as opposed
to another system so that's what usually
you take into account or what the users
take into account no they actually did
not know the answer so they had each
system and off to the system they filled
immediately out that the Suze
questionnaire so not all so some of the
subjects had had queries before they had
NLP reviews and some not so there are
different orders here so that that
effect gets gets equalized the users had
some sort of an idea about the results
what my results once they used the
system that is correct they did not just
answer the question they got an answer
from the system and so they were may or
may not have been happy with some of the
systems or not because of the results
because of the results so yes
we also put out a pure comparison
questionnaire you know which which
interfaces you like best which interface
did you like least and there you have
the queries again that was winning and
there they actually so this is this is
why I didn't hear to you know because I
said the question will come later it was
very clear here that the what they liked
best about queries was the fact that
they were having an interaction it
wasn't the one-shot deal so here I would
say yes you're completely right I'm not
really sure on the other thing on the
user bill on the pure which system did
you know which kind of query language
did you like best actually we did ask
them about the query language itself as
well so this will come out in a minute
oh here's the query language sorry it's
on the same slide I should look at my
own slide so that will also ask them
about the query language now you could
argue it is not completely orthogonal
from the interaction experience they
were having since they were using this
language in an interaction experience
but again I mean the difference between
you know the the 60% that we have here
and the 18% who liked the other one
based there there is a certain strength
here people seem to like natural
language or casual people seem to like
natural language I don't know why but
they seem to like it there seems to be
something in it that people like a lot
and it would be dangerous to just
discard this as you know you're you you
had nicer icons on one system versus the
other they really genuinely seems to
like the fact that they work could they
could enter full sentences obviously the
one they liked least was the formal one
even though some of them really liked it
I mean I was surprised at this number
that 14% okay roughly fifteen percent
actually like the formal language most
this is not the computer scientists we
had in the test and it is not the
computer linguist we had in the test I'm
not looking
I'm use this as a singular I think we
have one computer scientist in the test
and with one computer linguist so people
actually some people actually liked the
formality of putting together boxes and
arrows so this is right this is the
interface but they like the fact that
they could put your drag and drop things
together yeah if you look at the
language it falls to a very very low
number and obviously almost everybody
dislikes this most okay let me look at
some of the dependencies that we got if
you looked at the dependencies between
the other variables that we gathered
between the su score and what the
relationship was each additional second
spent actually decrease their happiness
by 0.06 right there there su scores so
you know that will tell you you want to
be quick better knowledge of Informatics
computer signs or whatever you want to
call it make them happier it's
interesting you know I never associated
knowledge with computer science to make
people nicer in terms of how much they
like a user interface but it seemed that
they were feeling more with us as this
is a difficult task to I I don't know
the system that was tested last always
obtained a slightly higher su score geez
I'm done right
I can now be happy anything else that we
could know did not factor in
significantly so it wasn't the success
and failure rates
it wasn't the order of the queries it
was not it wasn't how much you knew
about linguistics where didn't you
English what your gender was age nothing
of that influenced your kind of
assessment of the SU score you know what
how happy were you with with with the
system which surprised us
let me go into the qualitative
statements and that was I think very
interesting because it kind of
highlights some of the things that are a
little bit more salient but obviously
there are there qualitative answers they
like simplicity in both NLP reduce and
critics they didn't like the
presentation of the results in some of
the systems yes
we should probably control for this if
it would run this again we would make
every system look exactly the same down
to the last pixel as far as we can they
found in Zhang's simple because of the
drop downs because they didn't have to
guess so how can I enter things what can
I enter but they found it too
restrictive so this is again
structuration theory at its work and so
showing up as at best they like the
graphical display they like to the the
fact that they could actually see what
they were querying so this don't know
where they recall this this picture of
NLP reduce where you could kind of get a
picture of the domain you were querying
here it is right the fact that you could
see what the what was in that what's in
the box that you're querying they really
like that the question is how much does
this scale obviously and this is a very
small knowledge base probably wouldn't
scale very well to very large ones
but obviously they didn't like the logic
because it was too laborious and it was
too much work now coming back to the
languages rather than on the to the
interfaces let me just point out a few
things that are of interest they like to
use keywords and they like the fact that
they didn't need to think when they were
doing that on the other end they
complained that the query language was
unclear again if I think the
structuration theory message kind of
comes back up here I can use my language
it's simple to use it's clear language
again they like the fact that they could
put together natural language they
didn't like the fact that they had to
put in full sentences right and nobody
said that people are consistent in their
answers yeah like in Zhang the drop
downs because it was assisting the
suggestions that they would get but it
was too restrictive
they liked the playfulness of the of the
you know boxes and arrows but it was too
much work okay now what I talked to you
so far was people's personal impression
what's almost as interesting if not more
interesting is actually how good were
there were they in terms of fulfilling
the task and there is two things there
is how good did they think they were
fulfilling the task and how good did
they actually fulfill the task so they
perceived their perceived success rate
was actually lowest with semantic
crystal with the logic based and highest
with the language based probably
strongly influenced sorry probably
strongly influenced by the fact that
they perceived the fact that I'm having
an interaction with the system as a
signal that I'm doing right on the other
hand when you look at the real rates so
this is not when we asked them did you
get the answer yes now right they could
they could check it we looked at whether
they actually got the right answers and
I'll pre reduce the keywords were
actually best
now right this is this is this is
striking so this is the perceived one
where NLP reduced clearly and
significantly wins losses against queer
weeks and the real one where NLP reduce
not quite as significantly wins against
the full sentences now no something that
happened you and that's why it's non
significant jin-sang which is this
formal language hiding out there's
natural language actually won over
queries here and the reason is when you
fired off a question it was answered
correctly because you couldn't enter an
incorrect I mean you could enter a
question that would get a wrong answer
because you asked for the wrong thing
but whatever you would compose if it
looked right to you in most cases would
actually produce the right answer you
couldn't enter a nonsensical query that
wouldn't be interpreted right so at
least a step from the interpretation
step from English to the logic question
there was no ambiguity in that yes I
talked about that now these results are
not quite as significant as the rest
okay
so let me summarize this findings
because I think there are some quite
interesting stuff there casual end users
seems to have preferred natural language
interfaces with some full English
elements so you know don't don't throw
away the idea of natural language people
are comfortable with it full sentences
were perceived to provide more freedom
and are more natural than keywords which
is which is mind-boggling to me that
somebody would say something like that
but that that was a perception animal
seems to be leading to a perception of
correctness especially if it is put up
into a conversation is this the answer
you were looking for I mean we didn't
have this in but I'm sure if you would
have a conversational interface people
would rate it even higher
graphical display of what's available or
some type of notion of what's available
is helpful because it allows you to
understand what is searchable and what's
probably best is would be to develop
some type of combined interface that
allows you to use fragments of natural
language with fragments of keywords to
actually exploit the advantages of both
both those elements now I'm this is the
point where I'm starting to hypothesize
ok I'm done thank you very much and I
would be very very happy to entertain
questions yes what of what a priori
knowledge did the users have about them
mentioned systems before doing the
experiment a one-page write-up which
essentially explained what do you need
to enter ok so they knew that they might
construct certain queries I've the
natural language and the others with
their so for example for nm for queries
it would say you can only enter full
English questions and it has to be a
question so it needs to I start with one
of the W words right where what or H
right how much or how and the system
will only accept questions like that for
NLP reduce it was you can do whatever
you want you can enter full sentences
you can enter keywords and you hit
return for jin-sang it was you can only
enter what the dropdowns
allow you to enter etc it was a one page
page maximum per system in most cases it
was like half a page thank you ok so
let's thank to the speaker and we will
take more questions afterwards those who
want to stay longer here's another full
hour to take questions in a smaller
group good I thank the speaker
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>