<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DocEng 2011: A Versatile Model for Web Page Representation | Coder Coacher - Coaching Coders</title><meta content="DocEng 2011: A Versatile Model for Web Page Representation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DocEng 2011: A Versatile Model for Web Page Representation</b></h2><h5 class="post__date">2011-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tPrg6U0yljs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Ben hot cocoa soupy and I say
it again for just a recap it is your
deep Bernard and please tell me if I
step too far away from the microphone
because I maybe I don't realize it let's
good as you too so what is this all
about what's what I'm going to talk
about so what we are what we did is we
created a semantic model that unifies
access to content visual and functional
aspects of a web page so the idea was to
come up with some other methods for
encoding web pages to have a an easier
way to work with them for what we do and
in this model we we thought about this
model and we imagine this model for
tasks in information extraction and
accessibility as i'm going to show you
shortly and the modeling is car has
visual objects so and this what what
makes it different from the currents all
the most me predominant methods you do
it now on the Dom tree and on the web so
this talk is our first time shortly
going to show you what the current
issues are with current dome based
approaches and and which are the
challenges we we can possibly face in
here then I'm going to shortly introduce
our versatile model I'm going to talk
about how we put data into the model
then I will talk about how these gift I
to Theory concepts inspired us for some
aspects of the model and I'm going to
show you how we work with data in the
model how we're going to use it so okay
first issues why are we not happy with
with Dom approaches as we all know and
I'm okay that's that might be too easy
for you but of course within thumb HTML
models we're talking about trees and
still most information extraction on the
web is that has been done on the Dom
tree but it's important to know and keep
in mind that HTML self is is not self
contained you need external so
losses in addition to that to make a
rendering might be CSS standards but
there are also some conceptual ways that
are built into browsers how they render
stuff so basically it's the way the
standards are defined so and what's also
interesting while CSS is being meant to
separate content from presentation many
websites just don't work if you just
look at the content in in HTML code
because the layout is essential for
understanding them so if we start if we
look at them some some some snippet of
an HTML tree obviously we havin well
it's it's a tree yeah and what
information extraction does right now is
it works an expat like this so if you
want to drill down to some some
particular element in some on some web
page you have to construct basically if
to construct paths like this and the
problem with these paths is they are
pretty page specific and they are not
raw oysters at all and what we thought
is why why are we still working on this
level I mean when we like what is the
correct way to consider visual hints
when you look at pages so because for in
some way you could say that HTML and CSS
i actually just transport protocols so
what designers do when they envision a
web page they usually fire up photoshop
to create a web page and after that they
hire someone who does the pagent and
encodes them in HTML and CSS and so on
and why do we then struggle to try to
interpret HTML and CSS when the visual
content is meant to be understood so
this was our main reasoning behind
behind trying to do something different
in the information extraction stuff and
then we are also working in
accessibility so if you look at any web
page we as you all know it sits with
saccadic eye movements and whatever it's
extremely fast to pass for us what it's
about what it is all about and
as the content west navigation and so on
but what you also know is that for blind
users it's a lot more problematic
because everything is being serialized
into a one dimensional representation
might it be on the prior line like this
or in the voice representation and what
they do now because visually impaired
and blind users are smart is they find
quick ways how to travel through web
pages and alternate ways and many times
they have to step back onto the HTML
level because only there they can find
hints where how to navigate of course
there are web accessibility standards
many of them but they are slowly adopted
and they will we guess they will never
be adopted for all web pages because
many times publishes just don't have
time to include them or just don't care
whatever so it would be fine to have
something that also makes it makes it
easier to work in this domain it's
something that's good to make it
accessible to those users so okay here
it is this is our motivation we wanted
to come up with a better model than the
Dom for information and extraction and
accessibility and this should be some
kind of versatile model in which we can
throw in all kinds of information and
somehow get it out back again by
clearing and the information extraction
so this should be something that we
could play around with this is not to
solve some particular task and
information extraction accessibility but
more like a playground and a model where
we can tap dump everything into it and
get it out later and what helped us in
understanding its and again I mean we
had talked engine on this might be all
so trivial for you but was not for me
it's it was thinking about the phone
right what happens if I am somewhere in
a remote place and I don't have internet
access but I do have my phone and I need
some important information from a web
page and a call home I called my mother
and ask her so please can you look up
that web page and tell me what what's
where's this venue I have need to go to
then she will probably explain me
somehow what she sees sees on the
h and CC I yeah please okay can you see
this whites there's some white box
somewhere that I could it go to this i
think this information that i need is
down there so this is what inspired us
as well that there's some kind of visual
language that you use on the phone and
and what we would like to strive for and
it's don't say that we accomplished it
but of course yeah but what would you
like to strive for is to come closer to
this kind of language that they speak on
the phone so how can we formalize it so
what we came up with is a model that's
grouped into nine layers and there's an
increasing amount of information from
bottom to top that's being added to the
model when we work with it and the basic
element that this slide is going to come
back again once once again the basic
elements in this model is a visual
object so what we consider visual
objects from a web page are words and
images and the first part is crucial so
it's words we're not going for text
nodes because texts not text nodes of
knots of not of sufficient granularity
because there can be line breaks are and
the way a browser layouts those text
nodes is you can differ so we're looking
for words and basically we are
extracting the basic properties of this
opposition sizes content all the usual
stuff and also we extract images but we
don't analyze the images in title so it
just extracts plain images as black
boxes so and what now how do we store it
coming from this from the web area it's
was natural for us to choose a semantic
storage format so basically RDF so what
we did is we store every visual object
we find on a page in a form of its
ripple so we have I don't know if you
are familiar most of you are familiar
with that who is familiar with with
yeah ok so we've subjects predicates and
objects and all subjects are the visual
objects so how we do it for example in a
visual object here it's named I 67 say
that some comes from from somewhere
phone from now it's being annotated with
additional information that we find
about it so for example we know it has
this content string but there's more and
more information about about the object
that's getting into it so getting back
into this model we start on the on the
lower level or by employing a component
that i'm going to show you right now in
on level 1 so what you see here in
certain level 1 we have the source code
which we also also still have available
on level 2 of the model we have hints of
da Mansi in the CSS and from JavaScript
and of course we're not so stupid that
we throw this information of a way
because it's it is very useful in the
later processing but which somehow want
to have it together with all the
geometric and other information that we
can get so that's why we have on on the
upper layers on level 3 we have a row
geometric layer where the information
about visual objects and that reports is
thought and after that this information
is increasingly enriched by some small
processes that are being deployed on to
this model and I'm going to show what
kind of information is going to be so
but how do we get the information into
the model in the first place so we
created a mozilla based component which
does the rendition with a gecko engine
and then stores it into stores its
findings into the model we have
something that we call in rich's so
these are little programs in different
languages so we can have them in Java in
Ruby in other languages that just
and additional facts into the model so
they try to find so they retrieve some
visual objects from the model find some
relationships between them and right
additional information backgrounds into
the model and since this is being a
triple store we can do some automatic
reasoning that can help us so the first
step is this mozilla component of course
we decided to rely on something that
that's available already because we
didn't want to replicate their own web
browser and it doesn't awful complex CSS
and javascript stuff and javascript is
important because an increasing number
of web pages is only rendered correctly
or how it's meant to be consumed when
you also apply javascript to them so
because there's Ajax and and all this
more modern stuff that actually makes
loads some parts and of the webpage
dynamically we implemented this as in
tcp/ip servers so basically as a web
service where you can connect to you
supply an URL and you will get out back
a list of visual objects with all the
basic properties the visual objects are
tokenized from the text nodes into word
ranges by using the get bounding client
directs methods which is now exposed by
CSS object model view and this is the
way how we get the data it's quite fast
I mean that the talk before talked about
performance I have to say that in our
problem that we have now performance is
not that big issue because we are
dealing with single pages and we are
dealing with accessibility users who
actually want to read one particular
page so we have no scalability issues in
so and sample outputs can look like this
so when we deploy our prize a component
on to a particular URL this is what you
get back in notation three formats I'm
showing you a notation three because of
gravity because it's clearer so a visual
element would be an HTML element here
which is in particular document index
so that we can back onto the original
HTML sauce if we want to do so and we
derive some information from the web
page so this is here the geometry code
which is the position and width and
height X means that it's being tokenized
so it's a sub-element on sub element
level and there are some HTML
dependencies so we can of course have
the rape somehow replicate the HTML tree
in here by including the HTML childish
and sibling stuff and we can get some
color and font and some rain that
information about this visual element so
how it really looked like but this is
only the first step and what this is far
away from what I've told you before
about what we talked about on the phone
so how can we can get closer to all of
this information so we went in as I said
before we were inspired by the key style
theory which was a movement which which
was established in the late nineteenth
and early sent 20th century by by these
two Austrian porn people who basically
talked about his diet which is a German
word that does not translate exactly to
one particular English word but it's
something between shape form pattern
figure something something like that so
it's it's something that's that that
helped is an understanding and most of
you at least the faces I'm looking into
it completely aware of so you know these
laws I mean that there's something you
can establish relationships and grouping
based on proximity on similarity and
closure and continuity and and what can
we do about that for example you have
the distinction between figgins ground
so this is actually if you do it on a
superficial level it's quite easy and we
wanted to be pragmatic everywhere where
we could on a superficial level you just
have to consider the set index often of
a document
and consider all the elements which are
basically under on the first level as
for grounds and the other elements on
the background and so you just write
this back into the visual objects this
does not of course this does not include
any nesting or part or partly covered
covered stuff this is just a very naive
way of looking into that for proximity
we can look at adjacency we can look at
neighbors and distance and what we will
do is we will just right for each visual
object in our model will just write
these adjacency information if
neighborhood information so an element
particular element is north of another
element or the south of another element
it has a particular margin like this
margin south of 29 pixels to another
element which is written on the bottom
for similarity when we don't look at the
content which we don't do we have to
look at color size and font properties
so basically all the stuff that browser
gives us and for that we have we can
look on to color code and geometry code
font codes just write this back into the
model continuity closure something
interesting because i think it's it's
when you think about the table that's
for example that's been interrupted by
some banner ad orders or something like
that it's quite easy to to immediately
realize this just by looking at the
alignment so if you can what we do is we
deploy a process in our model and we
establish in a left aligned right
aligned top align the Citra relations
between all visual elements that share
something share this this particular
alignment so it helps us recognizing
these models and since the web is
becoming more and more dynamic also this
common fate concepts make some sense now
because what we have is what we'd like
to know ideally is that we if we click
on a particular element or move our
mouse over a particular element that
something happens of course we cannot
pass what what in detail happens but at
least what we can
say is something happens because there's
a JavaScript hook and there's some event
handler edge to it and we can at least
say that okay there's the same
JavaScript event handler attached to a
particular class of elements so they
share something in common they have some
common fate and they might have some
something together like the navigation
menu or whatever the saline sees is
which about outstanding some items are
can be calculated in in a related way
just by looking at font sizes and and
weights and colors and looking at the
frequency of these font sizes so we have
a very straightforward way to encode
this and we come up just with a number
that's also depending on Colin entropy
which is basically looking at in a color
space on the kalos based distance
between two colors that tells us how how
large the contrast between four grand
the background is and also as I said
looks at these font values of an element
so we have some how come we're up with a
number that says okay this text is
somehow more outstanding than some other
text so how do we do all this and how do
we write this back into the model as I
said we have these in riches which are
little programs that augment the model
with additional facts we do this in
rich's these can range from like three
lines to to a couple of hundred lines of
programs but most of them in like twenty
liners we implemented some of them in
Ruby some of them in Java for example
using the Gina library you can down
there you can see what it would look
like in Gina if you want to write back a
tight literally into the model and we
use sparkle and sparkle updates and
that's interesting because are having
this triple store this now gives us a
completely different way of interacting
with our with our pages
and I've give you an example of such a
sparkled thing a bit later and what you
also can do is this automatic reasoning
since we have in modified in owl and we
have relations between the model we can
use a palette reasoner for jacking
validity in the model which is important
in during development because we help
make a lot of mistakes and we it's it
makes our life easier if we can identify
these problems very early and we can
generalize so we can save something is
waste of something then it's it's a
neighbor and we don't have to write
particular rules for that we can find
out about inversion so that if a is west
of B then B is also east of a and if you
are that we come up for an visual
element are we come up with in a lot of
triples actually and this might be too
small for you to read but but there's a
lot of that in here so how do we get it
back three ways basically we want to
explore it so somehow gets in feeling of
what what's in there this is being
helped by it by statistics which are
mostly based on the frequency of
properties i'm going to show you that
right now and we can get our data pack
by writing queries and these queries are
written in sparkle on some own language
that we that we did for that
distribution graphs so if it just the
fonts alien see that I said you before
if you just put this into a graph and
you put on the this particular saliency
value on the x-axis and the frequency of
how many items on the page have this
particular value on the y-axis you can
you can very quickly get an overview of
how this these items are distributed
the page but how many of them are you
can get this all of you because as you
can see we did a tool where you can send
just can select area ranges in this
graph and these ranges will then be
highlighted directly on the webpage to
give you two to mark exactly those
visual elements that match this property
and what we can then do is we can a
large additional distribute distribution
graphs like these display additional
distribution curves like this and make
additional selections by defining
additional ranges combining these ranges
with boolean operators and we can pretty
much trade down very quickly to some
interesting elements on the page if
there is time I can show you this after
probably after the talk we can also
query for web patterns and the visual
queries I told you before become Sparkle
queries in our model so if we remember
the phone metaphor basically it's about
that one person on the phone should
become a robot we can I already told you
these queries are defined in different
languages and what they should identify
basically is web patterns that all web
designers thinking so this is an example
of a pagination web pattern and then
foreign for not like an article teaser
it's exactly what the talk before mine
has been all about and this methodology
gives us in a way to describe these
extractors in an alternative way so this
is a sparkle query that will extract
exactly the stuff on the page before so
this one you have an image you have an a
header and give some text underneath so
this is the spark query it basically
selects from our triple store it selects
three elements T 1 T
to IMG where the first one T 1 is an
HTML text we know that from our Mozilla
component t 2 is also text and EMG is an
image we know that and that all we
require is that we want that a t1 is
north of t2 image is west of T to the T
1 should be the larger text so it has
some fun to the salience II that should
be larger than the fonts a lens you have
text above below and that's it that's a
very primitive rule this is charged i
just showing this to you because it's
it's it's so easy to understand but even
with this very basic and primitive role
we're able to identify many of these
article teasers that are spread out on
web pages so since i'm running out of
time i'm skipping the idea that what you
can read in the paper but another way
how to formulate queries and i'm just
finishing by saying what this means for
accessibility because we are writing we
have these queries and can identify web
patterns and objects in in our in our
model we will augment also these
findings of these queries back in our
model and provides these elements as as
possible paths for for visually impaired
users what we actually do so if you have
serialization of the document which is
on this black axis and we have in richer
processes that defines some found out
something about some news elements on
the blue axis we will just provide an
additional way by putting it on on a
certain keystroke for blind users to
quickly jumped from one part of the
element to another model so to wrap it
up what we did is a versatile model
basically to play around with and this
model is done in and semantic web
implementation which gives us the
advantage of using Spartan queries for
for queering actually clearing visual
documents in a Semantic Web way
we we think we of course it has nothing
to do with the with digitized vision
based approaches where it can come up
with a huge model of understanding from
how you compose things together but we
think that the state laws given good
inspiration of what what tasks and what
what types of information you are
looking for and elements we did that and
he created several ways to enrich
explore and query the model and yeah
that's it thank you for your time
there's a drumbeat of enthusiasm outside
the are there any questions for our
speaker I thought it was really
interesting have you tried it with blind
users yes and what was their feedback
well David they were very i thought was
enthusiastic they were very interested
because this is not a finished product
that we have but it's a proof of concept
and prototype so they were only able to
play around with it in its common form
but they certainly told us that they
would like to have this in in a way they
could use this on a daily basis
why didn't you use XHTML plus I'll gfa
in order to inject inside the webpage
your model information because here your
model is completely the description so
politically flat our model is now
completely flat and we just didn't want
to bother with the original Dom tree
because we could not see any use for for
these three information in our queries
after that okay perfectly you use a
spark of 1.1 yeah which are a RQ yaki is
processing is processing a sparker 141 k
RQ one I mention okay let's thank our
speaker</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>