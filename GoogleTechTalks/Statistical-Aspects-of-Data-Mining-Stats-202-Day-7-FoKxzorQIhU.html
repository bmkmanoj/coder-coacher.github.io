<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Statistical Aspects of Data Mining (Stats 202) Day 7 | Coder Coacher - Coaching Coders</title><meta content="Statistical Aspects of Data Mining (Stats 202) Day 7 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Statistical Aspects of Data Mining (Stats 202) Day 7</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FoKxzorQIhU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome to lecture seven of data
mining at Google I have up here to
remind you about the midterm exam which
you don't care about but that probably
means that we won't have class next
Friday but I'll give you more details
about that once I make a decision
there's another homework posted if
you're interested in seeing sort of
those problems and I might go over some
of the solutions next Tuesday so
basically that the plan though is today
to get through the rest of chapter three
there's not too much left just some
summary statistics and then I want to
start getting into chapter six which is
about Association analysis which is sort
of one of the classical problems and
data mining so it'll be good to sort of
get out of some basic stat stuff into
some more classical data mining stuff in
fact it's probably the two extremes
right because everything we've seen so
far you probably could have in an
elementary stats class everything about
Association rules you probably never see
if you're coming from a stat background
so we're sort of go from one extreme to
the other okay so you don't care about
the midterm exam you don't care about
homework but you do care about chapter
three so we did visualization last time
in fact actually we finished off all the
visualization so that left us with
section three point two which was
summary statistics so I talked about
this last time so yeah three point two
is left so I always said you know we
like to do visualization first and then
we do summary statistics after we've at
least taken a look at the data and so
we're going to talk about different
summary statistics so the classic
example I would give you a visualization
you can make a scatterplot right but how
many scatter plots can you really look
at at one time maybe you also want to
just compute correlations and then where
you see large correlations then you look
at those scatter plots so the two of
these things work well together
visualization gives you the whole
picture but if you're comfortable that
you know what the data is doing then you
could first do some summary statistics
or maybe you do the summary statistics
first just to pull out the ones with the
largest correlation then you look at the
scatter plots so those two things would
go together just like things like the
mean and the median would correspond to
looking at box plots but you don't want
to look at a box plot for everything
maybe want to pull out the means and
medians first and then look at those box
plots so they sort of work together I do
encourage you to do a visualization
first though if it's if it's possible if
it's scalable so your book talks about
some sort of the classic measures of
location measures have spread and
measures of Association so you know
measures of location are basically where
does the distribution live if I'm trying
to compare two sets of exam scores for
example I might compare the two mean so
one mean is higher than the other
compare the two medians one meeting is
higher than another I might compare the
percentiles I might say Oh the 75th
percentile this distribution is higher
than the 75th percentile that
distribution and these are talked about
on pages 100 through 101 of the book and
I'll just go through and say a little
bit about those but of course you're
probably all familiar with those
measures have spread you've probably
seen these before
you probably remember from some
elementary stat class doing the standard
deviation calculation and if you want to
see it I'll go through sort of the
sample the calculation today but it's
pretty simple and then finally measures
of Association we talk about covariance
and than a rescaled version of that
which is correlation so what does your
book say about measures of location well
the one thing that's interesting is they
don't group the percentiles with the
mean and median although arguably these
are all measures of location and the the
percentiles are not measures of center
right those could be measures of any
part of the distribution where is mean
and median are both measures of center
some terminology that I should mention
this is probably intuitive but I'll just
say it first second and third quartiles
correspond to 25th 50th and 75th
percentiles respectively so you'll hear
some sometimes we use these sort of
interchangeably the other thing that's
sort of curious someone asked me this
one time which is actually an
intelligent question they said you know
what do you how do you differentiate if
I say someone is in the fourth quartile
that means and they're in the upper 20
50 percent of the data but we also refer
to the first second and third quartile
as being the divisions and that that's
true and if you sort of think about the
data we'd say this is the first quartile
second quartile third quartile whereas
the fourth quartile there is none right
just like there's four quarters in the
basketball games but only three breaks
between quarters right so what the point
I'm trying to say is we interchangeably
refer to the division here as being the
third quartile and this group here as
being the third quartile and you have to
use the context to know what people are
talking about usually if people say the
first quartile they mean the division
between the first 25 percent in the
second 25 percent the second quartile is
the division between this 25 percent in
this 20 percent and a third quartile is
this division but sometimes if someone
says I'm in the third quartile then they
mean they're in this group of 25 percent
so the language is a little bit sloppy
and someone asked me one time for
clarification on that and I said
there is no clarification it depends on
whether you're saying I'm in the third
quartile or this is the third quartile
but they use the terms interchangeably
oh let's see what else do I need to say
on this slide I think I don't need to
say anything else on this slide the one
thing I will tell you about though is
that if both the mean and median are
used to measure Center you know which is
better when should I prefer one over the
other well the thing to appreciate is
that the they both measure Center but
sometimes the meaning is preferred
because sorry sometimes the median is
preferred over the mean because it's
more robust to outliers or extreme
observations and skewness and the way to
think about this is if you imagine
starting with a it's symmetric
distribution so you know I drew a nice
symmetric distribution here at the
bottom and looks sort of like the normal
distribution you start with a symmetric
distribution well obviously for
symmetric distribution everything
symmetric the mean and median are going
to be equal doesn't matter which one you
use and when you see people reporting
you know one or the other only it
probably means it's not symmetric and
there's some reason to differentiate but
for symmetric that are both the same now
you start adding like you know take the
largest guy here and add like a million
to him well the median is still in the
same place right it's still the middle
number but the mean is going to be
influenced right because the mean you
add up all the numbers and divide by the
total so if I take the largest guy and I
add a million to him the medians gonna
stay put but the means gonna follow him
out and as you get something that's sort
of like general right skewness like that
that's what's called right skewed and to
me I always looked at these and saw
these backwards this one always looked
left to me and this one always look
right to me so I just had this to figure
out some way to remember it because
everyone uses this terminology and this
is the common one I always remember this
is the common one and this one's called
right skewed why is this one common
because you see it all the time you see
it with incomes right most people make a
fair amount of money but then there's a
few really rich people why are there no
really poor people well you can't make
less than 0 right you see it with house
prices you see it with x right how long
does it take someone to do something
takes most people reasonable amount of
time but then there's a few people to
take a really long amount of time and no
one takes it really short amount of time
because you can't take less than 0 so
this this type of data is called right
skewed and with this data
the
ian is gonna be here you know 50% is
below it 50% is above it but the mean is
going to sort of chase out with the
large guys so this is the median for the
right skewed data and this is the mean
so the point is that the mean is
affected by the really large values
whereas the median isn't and sometimes
one one fix people will use with this
data sometimes take like a log transform
and make it more symmetric but in
general you have this problem where the
mean and the median are gonna be
different and for that reason people
will often report the median with this
data and then of course the left skewed
is the opposite case where you have most
the data is here and a few really really
small observations and an example I
could give you on that as something like
I had this example of basketball players
free-throw percentage most people shoot
like 70 80 or 90 but then you have a few
people that are sort of like really bad
you don't have anyone who's super great
because you can't get over a hundred
percent so that would be an example of
left skewed and in that case the mean is
actually smaller than the median and
again of course if it's symmetric it
doesn't matter and so what you'll see
sometimes as you'll see people using the
median because they don't want to have
the influenced by these extreme large or
extreme small observations or they don't
be influenced by the outliers and so
like even here this is just a random
story that showed up in the news a
couple years ago says the San Francisco
median home price top 600,000 it's
actually from 2005 I think which was
right when we moved here so you um this
will be a in ten years right this will
be funny to put up here I guess
hopefully so the thing is you know they
risk they take a risk when they report
the median home price because there's
gonna be people reading this on this is
NF MSNBC right a pretty general audience
that have no idea what the word median
means in this context but you know no
one is interested in talking about the
mean home price saying mean home price
going up by a lot because the mean is
going to be unstable and it's largely
gonna be a function of whether or not
you know the few you know really famous
or really expensive homes happen to sell
that year so really what you're
interested in is the median home price
the price of the home where 50% of
people have a cheaper home and 50% have
a more expensive home because you know
that the house prices are going to be
right skewed and so you're really not
interested in reporting the mean so you
go out of your way and repo
the median on something like that
because that's really what you're
interested in and I'm just curious if
they explain it anywhere in there
no they just say median price right so
they just sort of hope that people know
what it means so that's I think all I
wanted to say by that the point is that
when you have right skewness or left
skewness or outliers it's often better
to report the median because it's much
more stable and you can you know you can
take the top 50% of your data and add a
million to it and you're not going to
change the median but the mean would
change a lot and that's really important
when you even not just outliers but you
have like bogus data sitting in there
it's not going to be it's not going to
be affected by that okay so that's all I
want to say about me and median any
questions comments on mean versus median
right so the comment is you know one
reason for using the mean is it's easy
to compute because if you know the total
you know how many people you have it and
it's also computationally more efficient
am I saying all you guys know this
better than I do but that's true right I
mean the median involves sorting a list
where is the mean I just have to average
okay so I'm wrong but anyway it's easier
for me to compute the mean it's just
average numbers the other thing to say
though an argument for the mean over the
median is the following right so we're
talking bad about the mean so it's the
following if you if the data is
symmetric right then they're the same
thing
okay if the data is symmetric they're
the same thing so you're you're trying
to get the same number either case it
turns out the mean there's actually more
efficient statistically so we're talking
about how the algorithm scales that if
you talk about how you're sampling and
our scales it scales at the same rate
but the constant is smaller for the mean
and you can you can show that if you
sort of do the stats and so there is
there is argument if they're the same
thing you're better off to use the mean
it's more efficient statistically but if
they're not the same the median tends to
be preferable just because it's not
influenced as much
okay any other comments on that okay so
the measures of spread right how do we
measure how much spread there is to a
distribution quantity
well the naive thing would be the range
which is the max minus the min of course
you don't want to use that because
that's going to be extremely sensitive
to outliers of course it depends on two
values right the largest and the
smallest both of which could be outliers
so that might be useless and you know if
you get a lot of data either the range
blows up or the range you know is one
because the data lives on zero to one
it's just not that useful a variance and
standard deviation are the two most
common measures that you'll see usually
a standard deviation which is just the
square root of the variance so I asked
this on an interview question the other
day what's the formula for variance and
they didn't get it right so I don't
think it's too trivial then well we
didn't hire them so but it's like not
too trivial to write this on the board
and maybe do one example basically
you're just taking each number right
subtracting the mean okay how far is
each thing from the mean that's going to
be assigned distance so you square it
that becomes positive you add it up and
then you divide by n minus 1 why not n
well it doesn't really make a big
difference this is sort of again some
theoretical property that makes it what
we call in bias but you can imagine it
doesn't really change things too much
where they use n or n minus 1 and you'll
see some people use one or the other so
this is the variance and in the standard
deviation is simply the square root of
that now this is the most common measure
of spread you know people report the
mean in the standard deviation of course
the problem with this is that it's very
sensitive to outliers if you get a
really large really small number it's
gonna be really far from the mean when
you square it that has an even bigger
impact so this is very sensitive to
outliers so you'll see people do
modifications of this to make it less
sensitive one real simple thing people
will use is what's called the
interquartile range which is basically
just people will call this IQR
interquartile range just the third
quartile minus the first quartile and
this is a nice robust measure of spread
because you can add something to the top
25% of the bottom 25% and it won't you
know 50% of your data could be corrupt
in this as long as the middle 50% is
right that's what this is computing
right it's if you think about the box
plot from before basically this is the
distance from q3 to q1
it's the how wide is the middle 50% of
your data so that's a nice way and if
you remember the outlier algorithm in R
actually uses this value to detect
outliers
it's a nice robust measure of spread but
that being said the variance is the
variance and the standard deviation are
the most common now you say when do I
use variance when do I use standard
deviation standard deviation which is
the square root of the variance is the
preferred thing because it's on the
scale the original data right if your if
your data is in minutes variances
squared minutes where a standard
deviation is back in minutes so standard
deviation is preferred
however the variance is nice because
sometimes you can add and add variances
right if things are independent the
variance of the sum is the sum of the
variance where is that's not true of a
standard deviation so sometimes you want
to use one or the other but generally a
standard deviation is don't want any
reports it's on the scale that original
data so I think I said everything I
wanted to say on this slide any comments
about any of these guys so let me just
do a simple calculation here this sort
of might be insulting to you but it just
says compute the standard deviation for
these numbers so so the standard
deviation you know I just erased it but
again you just take each number subtract
the mean square it add it up divide by n
minus 1 and take the square root so
these guys would be 210 210 22 43 18
okay so those are your X's those are
your numbers from these guys for 715 no
sorry what's that for 715 carry the one
that's right 495 so my mean is simply 95
over 5 which is 19 right okay so from
each one of these I'm going to subtract
19 so this is negative 17 this is
negative 9 this is positive 3 this is 24
this is negative one okay then I just
square each of those guys this is what's
17 squared you know no 81 9 it's what's
24 squared I don't know wait 24 is what
496 what's 17 squared - wait what what's
17 squared 289
let's 24 squared 496 496 okay we'll see
let's see 10 10 16 carry the 2
right 1018 hang on just 10 26 carry the
2 18 + 9 is 27 carry the 2
that doesn't look right 5 5
what's wrong 496 sisters you guys I give
up
I thought this was a here we go
technology ok work there we go
17 times 17 289 that's right 496 24
times 24 576 576 all right 576 okay 10
20 26 carry the 2 18 + 7 is 25 carry the
2 956 satlak right 956 over 4 let's try
that 9 5 6 over 4 - 39 so 239 is your
variance and you see what I'm saying
about it being sort of not sensitive to
outliers right the 576 sort of dominates
the calculation because of the 1 large
number so it's not very sensitive
outliers something like the
interquartile range is more stable more
robust to outliers anyway variance is
239 question asks for standard deviation
so it's simply a square root of 239
where root of 239 which is something
like 15 I think
where's the Sun
there it is 2 3 9 square root 15 point 4
or 6 okay and if you do it once then you
never have to do it again if you were
doing this in something like our you
could just get these guys here and read
them in and there's a SD function right
so this is data store as I need commas C
to 10 22 43 18 and I say SD of data oops
caps lock is right there data and it
says 15 point 4 6 right and if you don't
believe that you can see the variance is
the square root of 2 39 which is what we
got after we got our arithmetic straight
so that's this calculation that you
probably remember from elementary stats
class and you can check the same value
in Excel and Excel it's stdev that gives
the standard deviation and var that
gives the variance okay so I think
that's all I want to say about measures
of spread any questions about measures
of spread question so the comment is you
know whether a standard deviation makes
sense if the distribution is a normal
people use it all the time and even you
know you could argue even for like a
discrete distribution with you know
binary you know you arguably it makes
sense right I'll talk about the standard
deviation of the binomial distribution
right which you know so that's discrete
distribution doesn't look at all
symmetric or anything like that but I
think the thing that you want to watch
out for though is that like you know if
you're comparing two distributions and
this one is sort of like this and then
this one is sort of like a point mass
but then it has like some really large
values and you say like which one has a
bigger spread you know well the second
one is gonna wind up you know having a
few large values blowing up the standard
deviation because of that Square and
things like that whereas the first one
you know arguably you know the if you
look at maybe the IQR the first one is
larger so it's okay to apply this
notation you just have to be careful
that it is sensitive to outliers and if
you have one or two
large values that can blow it up because
there's taking the square to some people
will you know get rid of the square and
just take an absolute value here and do
like an l1 measure which is also more
robust so there's more robust measures
and I think that's the concern that
people might tell you be careful if it's
if it's an unbounded support and there's
some really large outliers you should be
careful about it okay other comments
about standardization or variance or any
of these measures at range
okay so whoops last thing to talk about
is correlation and covariance these are
measures of Association so if I have two
numeric variables the question is how
strong is the association between them
now of all these I think this is the one
you probably have to be the most careful
about outliers and I'll show you some
pictures of what can happen with these
just beware of anyone who says oh the
correlation was 0.999 right you it could
be because of one point and I'll show
you why so basically both of these
measure the strength of the linear
relationship between two at two numeric
attributes x and y and the way it works
is you take each number right for ax and
subtract the mean take each number for Y
and subtract the mean and take the
product right so you're just resetting
them at their mean so imagine mm-hmm
imagine their mean is zero and then
you're taking the small to multiple so
when am I gonna get a big correlation
I'm gonna get a big positive correlation
if when X is positive Y is also positive
and when X is negative Y is also
negative hmm excuse me because then the
product will always be a big positive
number right so this will be the
positive linear relationship that you're
thinking of that's going to correspond
to a positive value for the covariance
up at the top and likewise when is it
going to be negative well when X is
negative if Y is positive right so it's
basically looking for positive would
mean they agree in sign negative would
mean they disagree in sign and then the
magnitude corresponds to how strong it
is now the magnitude of the covariance
is not that meaningful because you don't
really know what scale this number lives
on so what's often you know I'd say like
90% of the time you know reported at
least is instead as the correlation
which is a rescaled version of this
which is sometimes too
at our and it's so this up here that I
wrote down this is the covariance the
correlation is simply the covariance
rescaled by the standard deviation 4x
times the standard deviation for y and
so I said your correlation is covariance
divided by the product of the two
standard deviations and this has a nice
property that it rescales it to live on
negative 1 to 1 so this thing here lives
on negative 1 to 1 and then sort of the
absolute numbers become meaningful if
someone says I found the correlation to
be 0.9 or apparently correlation to be
negative point-eight you should have you
sort of know what that means and even if
you don't you can relatively compare two
things that are on different scales by
looking at their correlation say the
correlation between you know and
intelligence and time to complete the
task was this but the correlation
between intelligence and income was this
even though all the variables are
measured on different scales you've
measured the staying to the linear
relationship with the correlation which
lives on negative 1 to 1 again it's
often denoted by our sometimes it's
called the coefficient of correlation
now what I was saying is that both of
these are very sensitive to outliers and
let me sort of show you why that's the
case so whenever someone reports a high
value of correlation you should be
careful of it and also you should also
note that that these are not invariant -
monotone transformations so it depends a
lot how you measure the things when
someone says intelligence is correlated
with income well it depends sort of how
you measured intelligence right if you
took the log of intelligence the
correlation would change so what is
intelligence it's not you know it's a
qualitative thing it's not really a
quantitative thing okay but that aside
how are these sensitive to outliers so
suppose I have data right no
relationship at all okay just no
relationship at all between x and y
that's my data no relationship at all
our correlation should be about zero
however if I add one guy right here
correlation be like 0.9 0.999 right just
one point can drive the correlation and
that happens right because if you happen
to get some really large X outlier and
he's a really large Y outlier one point
can drive the correlation and so what
will drive people crazy is like one day
they'll have data like this you know
that looks like a huge correlation and
the next day they'll have data like this
that actually does show a nice pattern
but that big guy is gone
and that actually has lower correlation
so the correlation can be really
influenced by one point and it can also
actually like reduce the or sorry
reverse the correlation right if you
have something that's let's say like you
have a strong negative correlation in
your data okay but then you get one
point right so this would be right this
would be a strong negative correlation
but then as soon as you get one point
right here it's gonna go the other way
it's going to look like it's positive so
there's a relationship between the
correlation and simple least squares
regression which is when you have the
simple least squares regression you have
R squared
this R is exactly the square root of R
squared now when you have multiple
variables R squared still make sense if
you designate want to be your response
but correlation is necessarily between
two predictors so anyway people always
love to report correlations right the
correlation between this and this is
really high so I've found a strong
relationship okay but if it's just two
attributes right so you should probably
look at a scatterplot and make sure that
it's not just a few strange observations
that are influencing things and of
course again we talked about before the
correlation does not imply the causation
it really implies the linear
relationship also it doesn't measure
nonlinear relationships right if you if
you throw the ball up in the air and
record how long it takes to come down
you get a parabola correlation of zero
right there's no linear relationship
these squares line goes right through
that okay I think that's all I wanted to
say on this slide any comments on this
slide okay so here's a you know the
story right if if the slope of the least
squares line determines the sign only
right so if the line is going up it's
positive if the line is going down it's
negative right so both of these have
negative correlation abilities high
positive correlation slope determines
the sign how close the points are to the
line determines the magnitude the closer
the points are to the line the closer it
is to negative 1 or positive 1 so this
is negative point 6 because the points
are pretty close to the line this is
positive point 3 because the points are
pretty spread out the slope doesn't
determine the magnitude the slope only
determines the sign how close the points
are to the line determines the magnitude
so sort of as an exercise to sort of get
that here I did kind of a
multiple-choice match the
correlation to the picture and these are
all correct I actually computed these
five correlations for each one of these
pictures and I have them labeled as a B
C D and E and then I give like you know
some possible values some possible
choices and so like right off the bat
right you can throw out negative 3.20
and positive 1.20 right because the
correlation is always living on negative
1 to 1 so those aren't even even there
and then I have I guess 1 2 1 2 3
negative guys and 2 positive guys so we
can do the 2 positive guys first so
those must be a and B and if you compare
a and B arguably an a the points are
closer to the least squares regression
line than they are B so a must be a
picture of point a six point eight six
and B must be a picture of point nine
five so if you want to know what is
point eight six correlation what oh yeah
they are well when you get really close
you can't see sorry did I say it
backwards to I don't know what I said
so a they're closer to the line B either
further from the line okay so what is
our gonna say so if you want to know
what a picture point eight-six looks
like there it is if you want know what a
picture of 0.9
whatever it is 0.95 looks like there it
is of course like I said point nine five
can also look like a whole cluster of
points and then one up there too but if
things are good and there really is a
linear relationship this is a point nine
five strength this is a point eight six
string okay so then it leaves the
negative guys C D and E they're all
negative now the strongest one is
actually C even though the slope is not
as steep as the other slopes and you
probably can't even see the scale which
of course would be relevant but it
doesn't matter the slope it matters how
close the points are to line so C is the
strongest one so that becomes negative
0.98 which is the smallest number up
here 0.98 and then D right this is the
most spread out from the line so that's
got to be the negative 0.40 and then e
is the middle one he is a picture of
negative 0.9
they're still pretty close to the line
but not as close to the negative 0.98
okay so this you know the correlation on
an absolute scale isn't that meaningful
to you until you see a lot of examples
but you know here's five examples that
you've seen and then even if it still
doesn't really you always forget on an
absolute scale what it means
still the relative values are important
right if I say the correlation between
exam one and exam two is 0.9 but the
correlation between exam 2 and exam 3
was only 0.7 then somehow those two
exams are more different than exam 1
into ok that's that here's a interesting
thing to do if I generate a million
numbers from the uniform distribution in
R and call it X and I do the same thing
again and call it Y what should the
correlation between these be 0 right
there should be no linear relationship
between these so you can check
correlation between x and y and of
course it's very close to your your zero
and if you did more you would get it
even closer to zero right because the
random number generator is generating
these things supposedly independently
and so there should be no relationship
at all and that includes no linear
relationship right and you can sort of
converged here machine 0 if you keep
pumping up your your sample size and of
course if you were to plot these well
actually you can get in trouble if you
plot these because I told you about
scatter plots don't really work when the
data is too big right because you just
basically color in the whole picture so
this would be a case where you'd want a
sample but believe me there's no linear
relationship between these right you can
you can sort of bump it down a little
bit and see that right with a thousand
you should be able to see there you go
right no linear relationship at all
which is what you want from a random
number generator right no but I have
heard like people get into trouble with
these things when you get into high
dimensions they can wind up living on
hyper planes and if you don't do things
right ok so that was 24 this question
says what value of r would you expect
for the two exam scores which are
plotted below I should have put a
question right there compute the value
and check your intuition so who says 0.7
which says point eight who says 0.9 0.9
SR closest it's actually 0.89 on this
one okay
that's uh don't be fooled though that
line is not the least squares line it's
the diagonal line we drew before now if
you want to if you don't believe me why
the point nine people want on this one
you can take a look at this it's cute
sort of that Excel does not complain and
R does it does complain and I'll just
mention that so insert function
cor arielle in excel does the trick what
if I give it these two does it complain
yeah it probably doesn't like that okay
so what if I give it this one than this
one doesn't like that either okay so
it's bothered by the fact that those
names are there so I'll just give it
these guys and then give it these guys
and it should compute the right value
let's see there we go positive point
eight nine so we'll round it off to
point and I know unless you thought it
was closest without going over then the
point one's okay if you do the same
thing in our doesn't it doesn't like it
right so let me change let's see where's
a file no that's something file change
directory where do I have this thing
somewhere well let me put on my desktop
and it'll be on my desktop okay let's
see where's this data so it's right here
so put it on my desktop and the reason
our is going to complain well I'll just
show you so let's say say data stored as
read CSV this is called exams and
name's dot CSV and had R equals true by
default okay so that's good so you can
see the data here looks good okay so I'm
gonna say an R the function is cor for
correlation and I'll say let's see data
column two with data column three oops
and remember plot did not complain but
correlation does complain right missing
observations is an error whereas in plot
it wasn't even a warning so you get
different behavior for different
functions and are based on the missing
data and this one the fix is something
different than it is another thing
sometimes you'd there's this n/a dot RM
which is very common in a correlation
though it's use equals all observations
is the default when in fact you would
want to have use equals complete
observations to get it to not complain
so correlation use equals complete dot
observations there you go
same value as Excel so default behavior
there is to complain and give you an
error sometimes the default is to give
you a warning sometimes it's to not do
anything so it's interesting to note the
different behavior for missing values
probably you know it's open source so
probably depends on who wrote the
function the first time and then after
that it's stuck okay so that's that's
that question
I think that's a good question so the
point is that if the pair has one
missing you can't compute the product
but you can still compute the mean and I
think on that one what it's doing is
it's ignoring it for the mean also but
you can read the documentation on that
because you know that's the point with
missing data sometimes you can still
compute some of the statistics and I'm
not too sure what R does anyone know off
the top of their head I think it just
ignores everything that has at least one
of them missing but both approaches have
been suggested okay so I think that's
all I want to say about Chapter three
any last comments questions on Chapter
three okay so like I said we're going
from one extreme to the other chapter
two and three arguably you could get
these things in a basic stat class
chapter six Association analysis you
kind of have to take a data mining class
or something fairly modern to see this
type of thing and I'm not gonna get into
it too heavily I really kind of want to
introduce the type of data that's that
motivates this problem and I want to
show you one formulation of the problem
which has a lot of drawbacks to it but
it's probably the first formulation of
the problem and it's the one that your
textbook sort of gets into the most but
it's a simple formulation of the problem
it's you know you'll see what it is but
it's not the most obvious and it's
probably not the best so what's going on
with Association analysis basically it's
coming from the supermarket data right
the classic data mining example did all
these people buy things at my
supermarket maybe I can learn something
from them so it uses a set of
transactions to discover rules that
indicate the likely occurrence of an
item based on the occurrences of other
items so for example if I know someone
bought diapers does that mean that
they're more likely to buy beer if
someone bought milk and bread and I
shouldn't even say more likely I'm
already saying too much if someone
bought diapers does that mean they're
likely to buy beer okay and that's
actually more likely versus likely as an
important distinction but we're just
there someone bought diapers does that
mean they're likely to buy beer if
someone brought milk and bread does that
mean they're likely to buy eggs and
cocoa someone bought beer and bread does
that mean they're likely to buy milk so
these are the examples of association
rules and we can sort of quantify the
strength of these rules and I'll show
you a couple metrics for doing that
there for de thing here again
implication means co-occur
it's not causality now you know you hear
a lot of people badmouth you know these
things so this is just you know
co-occurrence this is just correlation
it's not caused ality but it's important
to think I mean in some cases that's
okay right like when your insurance my
insurance company charges me more money
to drive because I'm a male versus than
I'm a female okay if they're not saying
that being a male causes me to drive
faster just look at their data the males
get more accidents we're gonna charge
them more okay it doesn't really matter
what the causation is in fact the
causation question doesn't even make
sense they're right because if you if
you ask the question of causation you
have to say well what would be the
natural experiment to refute that well
they would have to say take everyone
who's a male now change a random portion
of them into females and see if they get
a more this doesn't even make sense
right there's too many other things that
are that are correlated with it that you
can't even really isolate the causation
question but there's just the point of
this last bullet is that we're not
really looking for a causation we're not
even trying to infer the reason you know
oh maybe they have you know a baby and
then they'd like to drink you know
you're not trying to do that you're just
trying to look for the strong
association and and just you know it's a
descriptive exercise what's in your data
what associations exist in your data so
there's a whole bunch of definitions up
here this morning when I went through
this I wrote all these down but I think
you know I don't need to and we only
have 20 minutes so I'm not going to
write them all down but they're
important I don't write them down the
ref here so the book talks about item
set now the book is really sloppy it's
always borrowing notation from the set
theory whenever it's convenient but it's
not very formal about it so you sort of
have to be forgiving of that and I'll
probably be equally sloppily sloppy so
an item set you know they're making it
look like a set but it's basically a
collection of one or more items so this
is kind of like a market basket right
like milk bread and diaper would be an
example of an item set and the K items
sense simply means it's a set that
contains K and let's say unique items
probably okay support count which is
different from support usually we'll
just say what is the support but they're
gonna start with support count which is
the frequency of occurrence okay
so for example the support count for the
item set milk bread diaper is two
because if you look in this data you see
milk bread diaper and one milk bread
diaper too and then there's no bread
here there's no milk here and there's no
diapers here so only two so two is the
support count the two out of the five
total is what we call the support and
that's usually what we refer to the
support of the item set milk bread
diaper is two out of five because two
fifths of the transactions included a
purchase of all three of those items so
that's the support of milk bread diaper
and that's probably the most important
definition up here so when we say
support just what fraction of the item
sets contained those items milk bread
and diaper and then frequent items set
sometimes we're looking for item sets
who have support greater than or equal
to some minimum support threshold okay
so if I were looking for all item sets
that had support greater than greater
than or equal to 0.4 I would include
this one as one of the frequent itemsets
so frequent of course is determined by
our threshold okay another definition
that didn't fit on that slide is what is
an association rule so they write it as
you know X implies Y right write it like
an implication so for example one item
set implies another milk diaper implies
beer that's what it is x and y are both
item sets and you write it as one
implies another that's I think that's
what an association rule is okay how do
we evaluate association rules well
there's two metrics that your book uses
and they use these in conjunction with
each other one is the support and the
other is the confidence now you can
argue a lot about both of these and say
that they're not really the right thing
I want to measure you can come up with
other metrics that might be more
meaningful it depends a little bit on
the application and I'll spend some time
on Friday criticizing these but this is
the formulation that your book starts
with in section 6.1 and so I'll sort of
go through it and then we can sort of
criticize it later so support basically
fractions of transactions that contain
both x and y so the association rule you
know starts off like this right X
implies Y but when you're figuring out
the support of x and y you sort of
ignore the arrow right so for the
example here milk diaper implies beer so
let's go with that example
milk comma diaper implies that I buy
beer okay oops
dear the support of the association also
the previous slide to find the support
of the item set this is the support of
the Association rule the support of the
Association rule ignores where the arrow
is it just takes everything and puts it
together take milk diaper and beer and
put it together so the support I guess
all right here the support of this
association rule is nothing more than
the support of the item set I'll just
keep them in order beer milk diaper okay
so what is that how many how many
transactions contain beer milk diaper
let's see not that one this one does one
two two those two right so these two
three or milk diaper so this is two out
of five
okay so that is the support of the
association rule is simply the support
of all items on both sides okay two out
of five now why do I want an association
rule to have large support well even if
it has strong confidence which I'll
define in a second you still want to
know that these items are occurring
frequently together so two fifths of the
transactions involved a purchase of milk
beer and diapers okay that's all the
support of the Association one is okay
the other thing to talk about the other
metric is the confidence of the
association rule so the confidence of
the rule milk diaper implies beer milk
diaper implies beer the confidence of
the association rule it's simply the
following right of all the people that
bought milk and diapers how many of
those people also bought beer that's
what it is of all the people that got
what's on the left side how many people
also got what's on the right side so
this you could define them you move this
here I know I'm probably not spot okay
whatever let's see this would be on the
top I would put the support of milk
diaper diaper and dear how many items
have how many item sets contain milk
diaper and beer and on the bottom I
would put the support of just the milk
in the diaper milk diaper ok so then the
top okay milk diaper beer that's exactly
this number the top is exactly the two
fists but the bottom is how many people
bought milk and diaper well how many
people bought milk and diaper one two
three no milk no diaper three so the
bottom is 3/5 and so you notice your
book I use support they use support
count it doesn't matter because the
denominator is the same it comes out to
the two thirds so that is what we call
the two thirds is what we call the
confidence of the rule and what that
means is that among the people that
bought milk and diapers two thirds of
them also bought beer that's sort of the
strength of the implication that's the
confidence of the rule okay of all the
people that bought milk and diaper two
thirds also bought beer if I know you
bought milk and diapers there's a
sixty-seven percent chance you also
bought beer that's the confidence so it
really tells you how strong the rule is
the support just tells you sort of how
frequent this thing is right because
even if this were a hundred percent if
it only happened like you know one time
in the data set you know then it doesn't
have much support it's kind of like you
know the coverage how popular are these
items co-occurring together so these are
sort of the two metrics that your book
talks about is measuring as measuring
association rules you can talk about a
lot of other ones and there's a lot of
drawbacks to these in particular there's
actually a problem with the confidence
that you can probably see coming is that
you're really not comparing it to a
baseline right so you'd say like if I
bought milk and diaper there's a
sixty-seven percent chance I also bought
beer but the curious question is well
what's the chance you bought beer anyway
right it's not being compared to a
baseline so
that's one problem with confidence so
anyway we'll talk a little bit more
about that next time but this is sort of
the definitions of support and
confidence and to sort of make these
more clear I have have an example
question yeah it looks an awful lot like
conditional probability yeah yes they do
that too right so this is this is sort
of like you know something that lives
outside of statistics kind of reinvents
conditional probability with new
notation and the notation is actually
kind of backwards from the notation from
conditional probability right because
you have like a implies B is really be
given a and things like that so it is
basically you know this is a conditional
probability right this is the
probability that I bought beer given I
bought milk and diaper right so it is a
conditional probability and then you
might want to compare that to the
marginal probability and see if it's an
increase or decrease so you're right
there we are really looking with
conditional probabilities it's different
notation and sort of we're not
acknowledging that and if you look in
the book in section 67 they go through a
whole bunch of other metrics and they
get into some probability based ones and
just sort of do metrics that compare
probabilities okay so let me let me give
one example here so this again is I
stole this one from one of the exercises
but I changed some of the letters so it
says computes the support for these item
sets a B D and a B D by treating each
transaction ID as a Market Basket so
there is a there is a question right do
you want to treat the customers as the
Market Basket or do you want to treat
the transaction idea as a market basket
and both of them might be meaningful
right if you're trying to do discover
rules at the customer level then you
might want to collapse and use customers
so you know combine these guys into one
combine these guys into one but if you
want to do it at the transaction level
then you look and you say oh these are
10 unique transactions so I'm going to
treat each one separately and sort of
make the denominator 10 and not
acknowledge the fact that I actually
know that the first two guys are the
same customer because they have the same
Safeway card right so this one says just
use each transaction ID as the the
Market Basket so we'll do that so let's
see support for each item set is simply
the count divided by the total so
support for item set a how many things
have a one two three four
five six seven so supportive items set a
is seven out of ten
support for items set BD let's see one
two two so BD and you notice my notation
is sloppy here I'm not using the
brackets or anything two out of ten and
then as they get bigger it can only get
smaller right it's and now this is it's
like the intersection in probability
right as you keep intersecting sets they
get smaller so abd has to be a subset of
these biddies and so abd is here the one
out of ten right because the other BD
doesn't have a so that's one out of ten
so those are the support for the item
sets right those aren't association
rules or support for item sets and then
we can use those numbers to calculate
the following Association rules
calculate the confidence and support for
the following Association rolls BD
implies a and a implies B D so if we do
that this is number 27 the support for
BD implies a write the support for that
Association rule is simply the support
for the item set a BD right that's what
it is and we already figured that out
that's one out of ten
okay so again the support for the
Association role is just the support for
the item set that contains the items on
both sides okay and then the confidence
for the Association role BD implies a on
the top it's the support of a BD so that
number one out of ten and on the bottom
its how many people bought B and D so
it's the support for BD okay so on the
top is one out of ten how many people
bought BD two out of ten so this rule
has confidence 50% - okay what does the
50% mean and I actually asked that here
I said state what these values mean in
plain English so in plain English I
would say something like fifty percent
of the people that bought B and
he also bought a okay so you save
someone BOTS B and D buys me and E your
50% confident that it also gonna buy a
okay
how many of the transactions is this
relevant to this is relevant to 10% of
the transactions where someone actually
did buy all three of these things that's
called the support the latter number is
called the confident and then you can do
the same thing with the other rule which
is a implies B D so the support for a
implies B D well that's just going to be
the support of a B D again and so of
course it's the same support one out of
ten right it doesn't matter where the
arrow is or where do they come in the
support is basically how many
transactions have all three things which
is still one out of ten however you
should ask yourself is the confidence
going to be symmetric and of course it's
not going to be right because this is a
now implies B D and so on the top I've
got to put the support of a B D again
and the denominator I'm sorry the
numerator is the same but now the
denominator is the support of a so now I
have one out of ten on top and a is
seven out of ten on the bottom so this
becomes one out of seven one out of
seven is the support so they both had
sorry one out of ten is the confidence
one out of 7 is accountants they both
had I'm ahead of myself they both had
support one out of ten right because
they both involve a BD so they both have
support one out of ten but the first
rule has 50% confidence in the second
rule only the confidence is only one out
of seven which means that of all the
people that bought being of all the
people that bought a only one out of
seven of those bought B and D also and
actually I shouldn't say people right
because we're doing it at the
transaction level not at the person
level so I should say of all the
transactions that bought a one out of
seven of those also bought B and D
that's what this one out of seven means
for the confidence okay so the the first
sort of problem formulation that the
people came at this one with it's
discussed in your book is basically give
me all of the association rules and
there's a lot of Association rules right
you can see how that thing is going
scale really really poorly with the
number of items give me all the
Association rules that have a support
above a certain threshold and a
confidence above a certain threshold and
I'm gonna look at those as possibly
interesting things okay so you see the
problem formulation it's not a
predictive task it's just a descriptive
task I'm just looking to see if I see
interesting relationships and so this is
sort of the first problem formulation
that's discussed in the book I'll go
through a few more examples of it but
there's sort of more intelligent problem
formulations you can make in particular
you know this problem with confidence is
like you know so the confidence is high
but how much higher is it you know if I
didn't know that they bought a okay so
you can talk about that I think that
probably yeah we're up to five minutes
so I think I'll probably stop there and
do the next few examples next time and
next time I'll also talk about sort of
other problem formulations difficulties
with this formulation and also talk
about what they call Simpsons paradox
which isn't really a paradox so much as
it is a problem with not formulating
your question clearly any questions
before we take off okay so I'll see you
on Friday and we'll finish up chapter
six</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>