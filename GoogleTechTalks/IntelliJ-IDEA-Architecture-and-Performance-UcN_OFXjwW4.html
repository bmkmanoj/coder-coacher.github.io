<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>IntelliJ IDEA Architecture and Performance | Coder Coacher - Coaching Coders</title><meta content="IntelliJ IDEA Architecture and Performance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>IntelliJ IDEA Architecture and Performance</b></h2><h5 class="post__date">2008-05-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UcN_OFXjwW4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everyone so my name is me tree and I
work for jetbrains I'm one of the
gelatin lead 444 IntelliJ IDEA and
remember for my today's talk is called
internet di di performance and
architecture and with that all I have to
may go so the first of them is to let
you understand how the DJ idea actually
works inside from the performance point
of view what are the main components
what is it doing in background and how
things work inside and the second is to
give some just a little bit of practical
tips for configuring your projects to in
order to avoid the performance problems
now of course I'm not really where I'm I
won't be talking about stuff that is
specific to google and to Google's
Project integration site which is giving
some general tips that are applicable to
everyone so let's start with the
architecture part so basically what is
IntelliJ IDEA inside and energy idea is
a a bigger or actually several big
bigger containers where everything is
put around so in a 10g idea there are
actually three levels of components such
as 11 pick a container for the
application level to stuff which exists
in one instance per application then the
rest roderick level so there's one
instance of that for every project that
you have open at the same time and there
are also multi level components and so
basically when IntelliJ IDEA starts this
loads loads the company's configuration
from the XML files and then it
instantiates all the components and out
of that you get your your ID now for
companies there is a student defied life
cycles so every company is guaranteed to
be initialized and startup then for
example if it's a project company that
it then it gets a notification that the
project is being opened and when
everything is closed it gets the project
closed notification and
then the application disposing
notification and as I've already said
it's usually configured through XML
files so it's possible to wire up
everything problematical about in both
the plug-in sending IntelliJ ID itself
most of stuff is configured through XML
now basically this was how things were
in versions before delegate idea 7 so
I'm going to talk a lot a lot about
improvements that we have done in
version 7 and also about the stuff that
will that we are working now in version
8 so I'll tell about all the
optimizations that we have been have
been doing previous and that we are
working on now so what are the services
services are a very simple extension of
the components idea so instead of a
sweet defined life cycle that company
has had services are initialized on
demand so for example of course there is
some stuff that you need that you do
need to initialize a start-up for
example the editors the editor provider
it has to be there on the very first
moment but many others too many other
things they are created the first time
they are requested for example is the
there are services for some refactoring
for example they they have some state
decatur carry around so they they are in
shower they need to be initialized once
and then to stay but the first initial
initialization hand can happen only when
the services initially requested and
basically the key to request loading a
service is the full qualified name of
the service interface and that's getting
looked up and the xml file and only when
the services actually has been has
actually been requested the class file
for the service implementation and all
of its dependencies are loaded only when
someone has requested the servers so it
helps to start our performance a lot so
we load on only those classes which are
actually used for that I actually must
below that during the startup sequence
and not all the stuff that might be
needed when some action is called
sometime later in the future and also
services like components they can have
persistent settings which are
automatically saved and loaded either in
the configuration files or in the
project or workspace file depending on
whether this is an application or
project level component and force both
for components and services these
settings are automatically loaded when
the the corresponding component is
initialized now we also have some
special support for shutting things down
for for disposing for example if you
have some UI component for example if
you have it like a dialogue or two
window which when it's initialized it
fires up a lot of stuff it can it
connects event listeners it can set up
some timers or the ground threads for
updating it can register some actions
and so on and the disposal framework
lets us shut down all of these things
cleanly cleanly when the dialogue or the
window is closed so basically we set up
a hierarchy so at the top level there is
the there is the component which is the
2v no dialogue and below it are all this
is all the stuff that it has pulled up
in order to work so that listeners the
background threads and so on and in
order to shut you know when the dialogue
is closed you just dispose the top level
component and it pulls all the other
things together with it so that
everything goes away automatically and
the night thing about it is that we do
not require a common base class for this
so just the dependency hyrek is stored
outside of the
components itself is just in this in a
separate dispose it three so the base
class of the component can be anything
you need okay now let's talk about a bit
how we work with the with the data with
the with so source code and everything
about it so at the lowest level of of
our data model is our persistent file
system so again this is one of the
things which are you for version 7 of
IntelliJ and here's what it is so
basically the virtual file system level
allows you to allows us to abstract
working with the files for example with
files on the local file system files in
the job inside jar files files inside a
version control system and so on and
this has been in IntelliJ IDEA forever
and the persistent file system is an
layer built on top of that that lets
that lets us catch the entire contents
of the of all the files on the project
in our repository now why would we do
that the main reason why we implemented
this is to improve startup performance
particularly on windows because in
versions before seven we had to do a
walk of the entire directory tree on
start absolute where to build a director
38 that we would need to show the
project view and we we need to have
index for all sorts of all sorts of
operations and it turns out that simply
walking the entire hierarchy of
directories can take a very long time so
now instead of that we have this big
single file storage which is very which
is much quicker to to get a hierarchy
from the den the entire file system and
another nice thing that we have we get
from that is the it always prove it
when when some files are changed either
externally or IntelliJ ID itself
particularly in the former case when the
changes are have been done externally
when we have we always have both the old
content and the new content of the file
and it helps us a lot for example to
reindex stuff to update the indexes so
we know what to remove and what to add
because we have both the old and new
content and another nice thing is that
this supports custom persistent
attributes for example if you are using
perforce then we store the latest
version of the file that you had that
you got from the perforce server in a
persistent attribute so that for example
we use that for displaying the change
markers and for defections and so on so
with subversion it's always stored in
your working copy and perforce doesn't
does not do that so we do it for for
them using our persistent file system
and of course we make some other uses of
these features of it for example we
store in Dixon timestamps and such
attributes and so on now how do files
actually get into this persistent file
system so on startup we run a background
a complete background synchronization of
the entire tree under the project so we
we do walk all the directories but it is
done in background it's not it does not
block the project from loading so we
immediately synchronized like the
project files the key stuff that you
need to load the project and we
immediately synchronize the files that
you have open in the editor and the rest
of stuff it's being scanned in the
background and so we get the new content
as gradually step by step now of course
for example this does not affect
compilation because the compiler does
not know about our virtual file system
it gets the files from disk so you the
the worst thing you can have with this
synchronization isn't complete is some
inconsistent error highlighting but in
practice it is not really a problem it
works quite well in our settings
and when IntelliJ IDEA is running we
watched the changes that are happening
in the file system so on Windows and on
Mac there is easy to do because there is
a there is not on Windows there has been
a nice API for this forever on Mac we
used a new fast events interface that
was introduced in tiger and which has
become official do pad on Linux it's a
bit of a problem because actually the at
the there is an API for tracking
directly changed on Linux there is like
the file access monitor i think it's
called but the problem is that it
requires having a file an open file
handle for each for each director and
abroad under a project it does not
support a curse word watching and that's
the main reason why we don't do not use
this because we cannot afford to have
some so magnified handles open so on
Linux we use on the we do not watch for
events we just synchronize particular
pieces of the director three years
requests for example you can trigger
then trigger the synchronization from
the user interface by clicking the
synchronized action so moving up in the
hierarchy from the file system how do we
index the content of the files now this
indexing framework that I'm talking
about now it has been just added in
version 8 and the main motivation for
that was to have a unified the solution
for building all kinds of indexes
because we had a lot of different
indexes in version 7 like starting from
the simple things like index of java
files we had a quite complicated
repository system for storing the the
classes and stuff like that and now we
as the product was developed further we
added all sorts of different indexes
after that so we built especially for
javascript especially nice for web
services especially nice for JSP pages
and so on and so forth and we found that
the developer of each index went through
the same steps and went through all the
same bugs in their implementation and
that became quite tiresome and so
unified framework was a great help to
get rid of those problems once in
forever so basically what an interpreter
is we took the Google Map Reduce and and
the inspiration for our design so basic
so just it transformed into some
something much simpler of course because
we do not have any server road and it
distributed where you're building in
aces but basically there is an index of
that gives an list of key value pairs
for from the content of a virtual file
and then we can access the we can get
the list of all files which contain a
particular key and the list of all
values which are have been found in
those files now keys and values are
arbitrary javabeans which need to be
which need to have equals and hashcode
of course and which need which can be
serialized in binary format so all these
inner is our application level which is
important because if the same file is if
there are if you have many projects
which have the same files and other
content they will be only indexed once
and the index that will data will be
used for all of the projects so how do
you be use that the main thing for that
is like the single most important index
is the word in the word index for the
project so the key is the hash code of
the identifier or any word and the value
is the mask telling it in what context
it occurs so we have three main contacts
which there are identifiers there are
comments and there are swing literals
and this is used for everything this is
used for find usages full find and pass
for for all sorts of navigation
operations in the project
also we have a similar index is used to
build their to-do list so we index all
the occurrences of to do patterns in the
source code the go to file feature uses
also similar indexes which simply
indexes the file names the non-lead
content and so on there are a number of
different indexes for for like 4 CSS
files there is an index for don't files
and so on now this is a actually only
one of the new indexing frames that we
have in version aight i will tell about
the second one about stab indexes a bit
a little bit later the second framework
is what we use for the semantic
innocence of source code now let's talk
about the PSI is the key like the key
semantic part of IntelliJ IDEA the piece
I stands for program source interface
and it's basically a set of a ps2 for
read/write manipulation of syntax trees
of the source code so we build a PSI for
the entire for the entire hierarchy of
your project on starting from the
directories then files then classes then
function function methods in the class
then statements in a method then down to
the level of individual targets and then
important thing about the PSI is that is
it works across all languages so there
are some elements that are reused
between all the languages and there are
of course language independent LMS like
directories and we have a number of deep
and on top of that beside the PSI can be
built for any language and we have a
different we have several ways of mixing
PSI for different languages in a single
file so for example in a JSP file they
have us in a separate 34 HTML we have a
separate dsi tree for java and we have a
knack separately for JSP as a whole with
all the directives and
stuff like that so how do we build a PSI
from the source code it actually exists
three step process so the first step is
simply a lecturer so we just can the
source code and basically usually use a
simple table driven Lexus developed a
bit reflex we just break the source code
into target tokens and actually if you
have a multiple language source file
like a JSP it's on this level that we
are dividing different languages
separate images from each other so the
lecture is responsible for finding the
tokens that for example separate Java
code in a JSP from HTML code and it
returns different streams of tokens for
each language now when we have a the
stream of tokens we build a syntax tree
from that for this would usually do not
use generated parsers because the most
of parsers developed with tools like
Aunt Eller they do not produce adequate
error recovery so you can afford that if
you have a compiler because normal the
normal state of input files for a
compiler is good code and with an ID
because you are ready editing code all
the time and changing stuff all the time
the normal state of the code is invalid
and so we need to have very very good
recovery from Citrix errors so whatever
whatever code you have right now
whatever code you are typing right now
whatever whatever state it is in we need
to parse the rest of the file after the
place you are editing correctly in order
to give you like completion and stuff we
cannot break thing we cannot have
everything broken after a single seat
etc so we just write a recursive and we
just write recursive descent parsers by
hand and it's quite it's a bit tedious
but it's quite easy to write and quite
easy to maintain so that's what we do
now actually there are in fact there are
two different syntax Twitter there is a
free there is a syntax tree and there is
a PSI and the syntax tree care care is
no semantic so just it's a it's a
hierarchy of nodes every every node is
either a token or a higher level
semantic construct and the syntax tree
has nothing but higher ranking and on
top of that we build a PSI tree which
has all sorts of semantic operations
like for example if it's a class D psi
psi counterpart of the class little
class let us get the methods the fields
of class and so on and the conversion
from the syntax tree to the PSI is
driven by a particular language so for
example the Java language has a
generator that builds Java psi elements
from individual syntax tree nodes now
how does the PSI get updated after the
initial parsing so for example so what
happens when they editor then the user
is typing code in the editor for example
now first of all we need to hug to do
syntax highlighting for what the user is
typing for example to hella string
literals and comments and so on and it
turns out that in order to do that you
do not need to do much parsing so all
you need is a all you need is a lecture
so just to know where where the comment
okie lens and the wearer identifier can
be given song and the lesser the lecture
14 text highlighting runs synchronously
as the user is typing code and it's
incremental so we are just relaxing the
part of the file from where the user is
typing up to some boat in the view later
that that does not affect future
highlighting of the code and the actual
building of the piece of the complete
psi3 is done asynchronously
after some in activity period so as you
if you are typing code like very quickly
then we do not update the PSI to be read
for for some idle time like it's 300
milliseconds by default by you but you
can configure that and when there is
this decided period starts we start the
background highlighting pass so we
highlight all the do all the semantic
highlighting do all the arrow
highlighting my unresolved symbols and
so on then we run inspections and so on
and as soon as the user starts typing
again we just aboard this process and
let the user type and restart the
analysis once the typing is finished I
will tell more later about how this
background analysis works but just let's
just meet adduction now the this
background parsing it's actually not
incremental so we reverse the entire
file with one important note that we
have the possibility to parse to stop
parsing at some level for example for a
job for a java class we can parse only
the declarations and we can skip parsing
the bodies of methods until someone
require requests that so we just know
that here's the method starts here is
his name he writes parameters he was an
opening back and then there is method
body which we do not bars and then the
method ends and the Falcon genius and as
soon as as soon as someone for example
in sheet set beside we walk that goes
inside the method we report we parse
that chunk of code and build the rest of
the 34 for the method
now let's talk about the semantic
indexes that I mentioned previously so
this is again one of the news things for
version eat so basically for most of the
files for profiles in Muslim is there
are there is code inside the file and
there are references to code in other
files there are import statements in
Java there are like imports in Python
and so on for JavaScript it's simplistic
but anyway you could your code can
reference good in other files and when
we analyze some source file we want to
be able to avoid touching the avoid
completely parsing these imported files
for example if your Java class imports
some like java.lang.string we want to
vote we do not want to parse
java.lang.string every time you you do
something in your food since so instead
of doing the complete parts we just load
the so-called stubs which are binary
serialization of the external visible
interface of some file so for example
for a Java class the stubs contain in
the name of the class the names of the
super classes need names of fields and
methods inside the class the parameters
of the methods the throws clauses of
them and that's it so we do not it
doesn't store any information about the
content of the methods and of course
such tubs are much faster to load and
then parson it's much faster to load the
stuff to parse the file so it's quite
efficient and main using in version 8
that is that that that framework can be
now used for any language because of
course we had a similar system
specifically for java since version seen
some criteria version but as we are
expanding to support to provide deep
support for more more
just like Python and Ruby we need to
have a unified system just for all of
these languages and so we have built
this this stops framework that can be
used for any language so yes that's the
main requirement for stubs so to stop
three must disappear so when a file is
imported it must be sufficient to load
the subtree and not to parse the
complete file and actually all this all
these stubs are very are completely
transparent for the client of the code
so when you when for example in your
plug-in you access a class you do not
know whether this class has been loaded
from a stub or whether it's backed by an
actual syntax tree so initially we load
the stub and when you perform some
operation that needs to have the
complete syntax tree will perform the
parsing and we hope to gather the tree
loaded from the stops and then you
divorced its index 3 and this happens
transparently without invalidating the
piece I elements so it's respect for the
client and another important feature of
the stuff is that we can build indexes
on top of them so for each tab element
we can provide a number of index keys
and values corresponding for these keys
and then we can use these keys to
retrieve corresponding dsi elements for
example for a Java class we provide
indexes we index the name of the class
of course which is used for the go to
class feature we index the names of all
these methods and fields which is used
by go to symbol and we we index the
names of its superclasses which is used
for example for by go to implementations
and so on so for example so for example
how does go to implementations actually
work so it fetches the it fetches all
classes where the names of the super the
short name of their super class is equal
to the name of the class on which go to
implementations was involved
then it performs actual parts for all
those classes and checks to see if the
superclass named results to the correct
class given all the import statements
and all the module dependencies and so
on so basically we pull a bit too many
things from the index and then we check
if all the things that we pulled from
the index are actually what we need by
performing the complete actual parts and
result and because the index constrains
us sufficiently enough so it's this
operation can be performed fast enough
in almost all cases so let's go back to
the background analysis and speak in
more detail about how it actually works
so the background analysis actually
consists of a number of different passes
we did with the different priorities so
for example there is one pass that
relies the perform the semantics hint of
highlighting and highlights the syntax
errors there is another pass the trance
inspections there is another path that
runs for example external validation for
XML and so on and these passes are
ordered by drug priority depends
depending on which information is faster
to faster to retrieve and more important
for the user to serve so one trick that
we do here is that we we have separate
high priority passes for highlighting
the visible the area that you see on on
the screen now so we highlight the
syntax errors in the visible area before
building the complete list of syntax
errors for the entire file and the same
applies to inspections so inspect the
area you see right now before scanning
rest of the file and of course we are
trying to be smart and to determine the
minimum affected scope that needs to be
reversed after every change so if you
are changing something that starts
something inside the method we do not
need to run all inspections on the
entire file because most of the stuff
will not be affected by the changes you
do inside this method
method and again as I've already said
before this is automatically
transparently canceled when the user
starts doing something again so there
are many low level operations like most
of low-level psi stuff they check the
cancellation flag and the cancellation
flag is set the thoroughness and
unchecked exception of the call stack
and so for example every inspection can
be cancelled automatically and the every
inspection writer does not have to worry
about making his inspection cancellable
it will happen automatically for him now
one of the other big one of other big
themes in version 7 from the performance
point of view was multi-core support so
we looked at what operations take a lot
of CPU and what beach of them can be
parallelized and one of the things that
we found is that inspections are quite
easy to run in parallel so because every
inspection is based is essentially a
first visitor of the p.s.i tree and most
of its most inspections are not
dependent on each other so or almost all
of the specials are independent so it's
very easy to paralyze paralyze them so
you just get the entire set of
inspections that you have for a file you
divide them in chunks and you run some
eat junk on a separate core and this all
happens in parallel another things that
can be done in background is in parallel
is find usages so essentially what find
usages does is for it gets all the
occurrences of the opening of the word
that you are searching for in all the
files and your product and then it
checks whether every occurrence of the
world is actually the usage of the
element that you were searching for and
again this checking it involves parsing
and result and involves parsing the file
and checking if the reference resolves
the correct place and this also can be
done in parallel so
for so all the founder identifiers are
divided again into chunks and every
challenge is checked on a separate core
and in order to build that we did not
find the abstractions available in the
GDK 56 sufficient for us so of course we
are using most of the stuff in Java util
concurrent but we needed more than that
and we have built our own frame with
that we call job scheduler and which the
which is also can be called fork joint
and actually something like that is
going to be integrated in Java util
concurrent in jdk 7 as i have recently
found so basically takes care of the
matical of starting the as many threads
as you have course of this building
different units of work between those
threads and tracking when they complete
and finishing the entire operation when
all the work units have been processed
now of course this is all this is all
far from gville because otherwise
everything would be running in tiles as
nicely but it isn't so of course one of
the first challenges that we ran into
while implementing this multi-core
processing is deadlocks so there are no
different levels of locking in IntelliJ
IDEA so there is a basically there is a
big read/write lock for the entire piece
I structure and there are individual
locks for smaller pieces of it that are
checked during a sub low-level
operations and we needed to make sure
that always take the high level lock
first before all the lower level locks
another thing is lock contention so we
need to make sure that this big single
big read write read write off for
example that we do not take a right
right lock for significant amount of
time in a single part of the operation
because if you do that then of course
the stuff does not run in parallel so
it's divided into multi
of course but all the course are waiting
for the single one that has taken the
lock so we need to make sure that the
locks are fine grained enough and we
used your kit to make sure that to check
for methods that take excess it a long
time which is usually caused by them
waiting on some lock rather than doing
useful work and another thing is the
quite an interesting problem so with
these low-level synchronization
primitives we with the synchronization
on low levels of design elements we have
found that we were creating too many
synchronization objects for example if
every PSI token has a it has its
separate synchronization object then
allocate all of these synchronization
objects and takes a lot of memory and a
lot of time and having one single log
for all these elements it causes
contention so we have found an
intermediate solution created a fixed
size pool of synchronization objects and
we distribute them evenly between all of
the low-level psi elements so we
basically just take the hashcode modular
some the size of the pool and that gets
us the inclination object that a
particular instance should be using
so that concludes the architectural
overview so there are some questions on
that part you can ask them now okay so
now just a quick rundown of sound
performance tips for configuring
intellij idea to make to make it work
better for for real good product now the
first thing that needs band the studio
running intellij idea is that it is a
very much i owe bound so in general it's
much more useful to have a fast hard
disk rather than sorry rather than a
fast cpu so for example we have found
that just 10,000 RPM hard drives helped
a lot and improving IntelliJ IDEA
performance and now of course there are
a lot of things that can kill the
performance of input/output operations
the first of them is storing source code
or an index files on the network so this
in fact should be alleviated to beat
with our persistent file system because
from unity for at least during initial
startup we do not load content from the
network source synchronously reload them
from our local cached the system file
system storage but anyway the
performance of the synchronization is
very much negatively affected if you
store sources on the network and of
course are the things that are most
important for Windows users not so much
for names and that his antivirus
antivirus says then fragmentation and
the windows system restore now all of
these things they perform additional
operations on every file access and the
overhead of these operations is very
significant for our performance
now regarding the Java Virtual Machine
first of all if possible you need to be
using the latest version of the JDK so
we still have a distribution that runs
on GTA 5 which is for a Linux and until
recently it wasn't for Mac but because
son has done a lot of performance
improvements in the latest version of
the JDK it's very important to use jdk
six if it's available on your system now
in general it is not so much important
to assign a lot of memory to IntelliJ
IDEA because for a recent a reasonable
size project it should be enough to have
a like 300 to 500 megabytes of net of
memory and more than that should not be
necessary unless you perform some very
logical operations like running code
inspections on the die project or
something similar but there is a
particular peculiarity of the Java
Virtual Machine that ends if you run it
in server mode then the lifetime of soft
references directly depends on the
maximum amount of memory that you have
and so even if IntelliJ IDEA does not
use all of the memory that you assigned
to you for example if you assign a
gigabyte or more than that then simply
having this memory available makes soft
references live longer and because we
use a lot of cat but we catch a lot of
data on software occurrences this helps
these references live longer and not to
be revalidated self so it's another nice
to know now another thing that people
are playing with these different garbage
collector settings and of course there
is no magical garbage collector setting
that will make into a je run fast on at
a particular hardware but anyway in some
in most cases it help if you have a
multi-core machine it helps to use
parallel garbage collection because it
runs better and reduces the occurrence
of GC pauses however we have run into a
number of program reports where the
users have experienced vm crashes
because of the non-standard garbage
collector settings so you just can try
this for yourself and see if it helps
you or not now some specific tips for
the ID first of all it's very important
to you always use the latest version or
or the latest bug fix update of IntelliJ
ID because in every version we we fix
the number of performance issues and
some of them are very important for
daily work and if you are able to update
the latest version do so all the time
rather another helpful tip is disabling
unused plugins because even though we
try to reduce the impact of the plugin
of plugins you are not using on the
performance there is still some impact
in many cases and if you are not using
some for example if you are not using
like spring or hibernate or some are
java ee frameworks then you can just
disable those plugins and it will help
your idea run a bit faster now this is
also very important to exclude stuff
that you don't do not need to be indexed
by the ID from the scanning because all
the scanning the experiments simply
excluding hiding files from the IDE
makes this scanning go faster another
another helpful tip is that you have a
lot of generated code which is lost or
in particular directories it's very
helpful to set version control to none
for these directors because the den
IntelliJ IntelliJ IDEA will not spend
time on updating the file the VCS file
status status for these files to check
out our own versions or modified or not
modified and this also helps performance
and in general if you have a large
number of inversion files in your
IntelliJ IDEA
project you should take steps to reduce
this number by ignoring files or by
hiding them from the center top nurses
some additional tips for example it's
very popular it's a if you search for
IntelliJ IDEA performance tips on the
Internet it's very many people recommend
to turn off the synchronize files on
Fame activation option and now actually
this was needed in some time long ago
but inversions 602 so more than one and
a half years ago if we fix the problem
that caused this option to have a
negative performance impact and so in
current versions it should be just as
easy to run with this oxen enabled and
not to worry with about manual
synchronization of files now this one is
silly but it's still helpful to know
that the updating of project view
happens faster if it's in project mode
rather than packages and of course it's
a problem that we need to fix but in the
meantime it's helpful to have this mode
set project now some inspections are
rules can also be expensive
unfortunately there is no easy way to
find out which of the effect inspections
take a lot of time short of sending this
snapshot to us and letting us look at
that but anyway you have been
recommended to disable some inspection
things usually helpful now this is not
really does not really apply to your
projects as far as I understand but
still if you are using screen for
example or Java EE then we can perform
additional validation of your model on
compilation so for example if you have
some embedded code in your web dot XML
files we can spot these do they make and
of course this validation takes extra
time and if you are not using that just
down the top
and this last problem is the more fault
of the GDK than a fast but it's very
important to know that method
breakpoints kill the performance of
IntelliJ IDEA quite efficiently so if
you're experiencing very slow debugging
then it's you need to check if you have
accidentally set a mental break point
somewhere because it's hurts a lot now
what to do if you have run into some
performance problem first of all as I've
already said upgrade to the latest
version and to see if it's probably the
problem has already been fixed and if it
has not by all means report the problem
to us so its impact quite easy to do so
first of all we need to built in the to
enable their built-in profiling agent by
adding this line to the virtual machine
options so you can find this information
now notice if you don't remember this
down and if you are running an EP build
an early access bill then it's enabled
by default there so you can just grab to
build them it's already there and it's
enabled when this option is is enabled
to get two buttons on the toolbar for
capturing a cpu snapshot or remember
snapshot so your experience if you are
experiencing it says a memory uses then
you take a leathery snapshot and if some
operations run slowly then you start
recording CPU snapshot perform that
operation and then finish recorded the
snapshot and send it to us to send sauce
just create an issue in our dinner and
attach the steps at file to eat and
we'll see it and we'll be happy to move
to do it and fix the problem possible
and if some operations if you need some
operations are slow that you cannot
profile Judith so they this user
interface for example because because of
some modal dialogues that do not let you
press the button then you can use the
standalone your key to a filer to
connect to the running instance of
IntelliJ IDEA and use it to capture the
snapshot so some that's it for the
performance tips some usual useful links
for its related information
and you have any questions then I'll be
happy to answer them at the beginning
you mentioned the virtual file system
and sort of it can represent things in
jar files or in version control or
actual files on the disk is there a way
for plug-in developers to extend that
like if we happen to have our own type
of file system there lived somewhere
else would we be able to write a BFS
module for that yes this is all
pluggable you can write your own virtual
file system implementation for accessing
files anywhere interesting and then a
performance related question I've
noticed often when I'm opening a project
or have made a huge number of changes on
disk and then want to intellij wants to
reparse a lot of things often in that
case on my multi core system it seems to
be sort of pegging one core but not
doing much more do you think there's a
bottleneck there or could i be i/o bound
or what do you think's going on well
actually this particular operation in
version 7 it was not paralyzed so it
does actually run on the one on one core
core but with a new indexing framework
that we have in version 8 should be much
easier to distribute this work between
different CPUs now of course it's a one
problem is related to memory so that we
we cannot like build a huge backlog of
requests because or each request towards
the older new content of the file and we
cannot store the contents of to
manufacture never because we would run
out of it but anyway it's was it's
possible to parallel utilize this
indexing okay and one more question do
you have a rough timeline for version 8
yet well the usual release cycle is one
year so given that version 7 was
released in in october two thousand
seven then version eight should be
I mean oldham this year so you mentioned
using your kit to report performance
problems a lot of the performance
problems that I see are actually hangs
and I'm not sure whether your kit
reports would be appropriate for that at
one point I managed while it was hanging
to switch over to a terminal and run J
stack on the PID of the process but
sometimes I'm not quick enough to do
that and I was wondering if you had any
advice or and or if you would want to
see that J stack you know one of one of
a thousand times that I actually it
happened that I actually managed to
catch it yes dumps like this are indeed
very helpful so if you can capture those
then send them to us okay um I'll let
someone else asked I've got more but um
so for a long time now and IntelliJ is
required a reboot every time you saw the
plug-in and that's always confused mr.
why that's necessary action for the main
reason for that is actually the life
cycle that I have mentioned because if a
plugin expects to be invoked when the
when the project is being opened and if
you install the plugin when you already
have a project open then it's too later
than this callback and the plug-in will
probably not work properly without so we
do not know whether the plug-in works
properly with that without so if you
could solve that one at least for some
plugins will be a big differentiator
between you and eclipse uh I think we
should be able to make some progress on
decent version 8 this reindex in
operation that world hood like maybe
produces a great result but it kicks in
at random like while the user may be
typing like and be very active is there
a way to actually observe the user
activity and like slowed down this back
end operations while the user is active
well actually there are no specific
operation that a trick is simply by
typing so so on one point this this
indexing process should be run in more
more predictable times in version 8 so
most changes done by the user now they
do not cause any r indexing they simply
invalidate the indexes to mark the data
that that some the dating some index is
out of date and the array indexing will
run no only when the user requests some
operation I go to a class for example so
it should work much cleaner in the new
version I'll ask another one okay you um
so one of the neat things about the the
Google plugin I'm not sure if this is in
the blaze plugin or in some other aspect
of the Google setup is that it's got
this sort of tune up checklist where hmm
okay so it that shouldn't be there's
nothing proprietary about that it it
goes through and it just checked certain
miskin misconfigurations that are common
and i was wondering with this great list
that you had if you would think about
doing something like that like french
for instance if there's some way to
check whether a file system is on the
network or to check whether certain file
operations are taking longer than they
should relative to other operations we
actually have thought of doing that
because within when you have an
antivirus running then the operations
that takes long is the clothes operation
on the file handle and of course it's in
normal usage it should take no time at
all and if you an antivirus is running
then the file is candle close and so the
clothes operation can take like half a
second or something like that so it's
it's for it is possible to detect the
text such kind of problems automatically
but we haven't implemented this yet and
a question during your presentation you
mentioned looking a binary you mentioned
that the only thing you need to handle
managing imports and stuff
oh sorry how do you have Oh during a
presentation you mentioned 500 Meg of
memory for large projects what is your
definition of large projects like in
terms of lines of code or things like
that sorry I couldn't hear the question
well could you please repeat it yeah
during a presentation you mentioned 500
Meg of memory for large projects what is
your definition of arts projects like in
terms of lines of code can you get that
yep so will we consider in Jenny's idea
to be quite a large project it has like
I do not remember the exact lines of
code but it has like fifty thousand
classes or something like that and of
course I guess the your code base is
much larger than that but actually the
memory consumption should not depend on
the size of the project or at least
should increase by a very small amount
with the increase of product size so
even your on your code bases like three
to five hundred megabytes should be
enough so can I have any number that I I
run in server mode and I've noticed when
I do that I just give it a huge heap
like one and a half gigs and it rarely
uses all of that although occasionally
it does but you know on a machine with
enough physical ram it costs almost
nothing and if you turn on the
concurrent mark and sweep garbage
collector and the parallel new collector
it's pretty painless and you don't get
many pauses and it just works okay so
you mentioned that psi stub is to the
compact binary representation are what's
used to do all of the import
declarations in the rest of it so in
theory isn't all you need for a large
code base that you don't actually want
to import into the application but you
might depend on the PSI stubs could you
not import the source code or the binary
and just import the PSI stubs on their
own actually at least
this could be possible in fact to share
only the dsi stops for for libraries
that you import so we do not have direct
direct way to support this now for
example to point to point out to point
at elegy ideas where your pre bill stops
are but I guess it should be possible to
implement that now of course you would
get failures if some operation needs to
access some output is something that is
not available in the stubs and it can be
hard for users to explain and to let
them see what's happening but in general
it should be possible
so any more questions okay I guess not
Thanks to everyone for coming and bio me
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>