<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Don Norman and Mick McManus on &quot;Design in the Age of AI: A design debate&quot; | Coder Coacher - Coaching Coders</title><meta content="Don Norman and Mick McManus on &quot;Design in the Age of AI: A design debate&quot; - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Don Norman and Mick McManus on &quot;Design in the Age of AI: A design debate&quot;</b></h2><h5 class="post__date">2017-01-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lDIBG8C2aOU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">
DAN RUSSELL: So welcome to this
edition of the User Experience
Workshop.
This is a special
cage match edition
between Don Norman and
Mickey McManus here.
And we're going to have an
interesting kind of debate
today.
Before we do that, I wanted
to start with an introduction.
I'm going to start with me.
My name's Dan Russell.
I'm a user experience
researcher in Search.
I've been here for 11 years.
But it was in 2000--
1982, actually,
when I was working at
Xerox PARC that I first
had my interaction
between AI and HCI.
Because I was a dyed
in the wool AI guy,
PhD in AI, classical, simple
system, processing stuff.
And I went to Xerox
PARC to work on an AI
system which would
help you use a very
complex piece of equipment.
Right?
And it totally flopped.
AUDIENCE: Xerox copier.
DAN RUSSELL: Exactly, right.
The Xerox copier.
The system is called
Bluebonnet and I worked on it
with Richard Fikes.
And we brought in people to
actually do a field study.
What a radical idea.
It turned out Lucy
Suchman suggested this,
and she was working
there at the time.
And I said, oh,
that's ridiculous.
Why would you want to do that?
Obviously it's going to work.
Well, her book, &quot;Plans
and Situated Actions,&quot;
is basically documentation
of how badly I failed.
So her book went on
to fame and fortune,
and I went on to realize that
in my sort of Saul on the road
to Damascus moment,
that I needed to do HCI.
That was 34 years ago.
I'm still doing HCI.
And AI.
So it's nice to see this sort
of come full circle here.
Not long after that
experience I went to Apple,
and I started working for
Don, which is how I know Don.
So he was my boss at Apple
Research many years ago.
But we also have
Mickey McManus here,
who has been working for
years in sort of innovation
areas and collaboration.
And he is the
President of MAYA--
he was the President of MAYA,
and now a principal, right?
Of MAYA design.
That's right.
And he's been working
and thinking a lot
about what are we
going to do when we've
got a trillion machines online.
So this internet of things?
That's just the beginning.
That's just the beginning.
How are we going to
build, design, live,
and be humane in a world where
everything is computational?
Every surface is computational?
And Don, of course, is
a university professor
at UC San Diego now, corporate
advisor, board member,
and well-known
author and speaker.
Of course he's a co-founder
of Nielsen Norman Group.
He most recently helped set up
the design lab at UC San Diego,
where I get to teach once
a year, which is great fun.
And he's an IDEO fellow
member, et cetera, et cetera.
More good stuff.
His latest books are &quot;Living
With Complexity and the Design
of Everyday Things, Version Two,
Newly Expanded and Updated.&quot;
So if you haven't read those
books you really should.
And I'll also give a plug for
Mickey's book, &quot;Trillions,&quot;
which is-- &quot;Trillions, Thriving
in the Emerging Information
Ecology.&quot;
So our plan for
today is that we're
going to do is
basically-- Mickey
is going to give a kind of
intro to this whole thing,
and then we're going to start
the celebrity death match.
Oh, I was told not to say that.
Cage match.
Where these guys are
going to debate aspects
of this fundamental question
that we're facing, which is,
how do we design in a world
where machine learning and AI
are so important?
I, obviously, started my
career by failing at that.
We've got to do better now.
So let me start off.
Mickey, come tell
us what you know.
MICKEY MCMANUS: Thanks Dan.
Well, I thought it
might be kind of fun
to do some maybe just
provocations or some things
that I discovered
as I was trying
to think about this stuff.
And one or two things
that Don and I ended up
really thinking on and
starting to go whoa,
wait, if you see that, it makes
you think very differently
about design, and led us both
down an interesting path maybe
almost a year ago or something
like that in a conversation.
So on the one side
you have humans.
Yay, humans.
Come on, everybody.
Woo, yay.
So on the one side
you've got humans.
And there's some really amazing
things going on right now,
like we're entering this golden
era of cognitive neuroscience
and things like that.
This is Adam Gazzaley's work.
He runs a lab called
The Glass Lab.
And he posited that there
are these different networks
in your brain, you know, the
one that deals with distraction,
and the one that deals with
working memory and things.
And he was able to prove pretty
resiliently that about 20, 25
years old is your peak for
dealing with distractions
and for having working memory.
And around 70 it's pretty bad.
And he was invited
to go speak at AARP,
and he mostly was just
the bearer of bad news,
and they somehow relished this.
And he felt really bad.
And so he decided to build--
but they kept inviting him back.
AUDIENCE: [INAUDIBLE]
MICKEY MCMANUS: Yeah.
DON NORMAN: 20 is the peak.
MICKEY MCMANUS: Yeah, 20
is something, is the peak,
and it then goes down.
DON NORMAN: Except
for knowledge.
Basically your speed goes down.
And your ability to do multiple
things at the same time
goes down.
But you wisdom goes up.
So there's hope.
MICKEY MCMANUS: It's sort
of almost like we have--
DON NORMAN: And I say
this as an 80-year-old.
MICKEY MCMANUS: They
call it silver moments.
So they call it silver moments.
What was interesting
though, was he
decided to build a
video game system
based on an idea about a flow.
It was desirable difficulties.
And he basically
used MRI-- FMRI, EEG,
and some other
advanced stuff to look
at the fast movement
of the connections,
as well as the three dimensional
movement of the connections.
And he was able to prove in
a double blind clinical trial
with placebo based
stuff-- so he's actually
pushing to get
this game actually
FDA certified so it can
be prescribed for things
like ADHD.
He was able to take
70-year-olds and actually
get them to have
the neuroplasticity
and performance for
distraction and working
memory of 20-year-olds.
And it was playing it
basically an hour a day
for about a month, and
he was able to show
a six month lasting effect.
And so it's a really
interesting thing.
A few years ago we didn't
have a way to sense this.
He's putting together
cognitive psychologists
and neuroscientists, kind of
working from both directions,
and thinking about this.
So anyway, yay humans.
I think we haven't
seen anything yet.
Maybe we could actually
still be relevant
when we're my age or Don's age.
I was surprised Don was
still alive, actually,
when I first met him.
And we both started
talking about, oh my gosh,
we're still here.
DON NORMAN: I've had
that happen to me before.
Gee, I thought you were dead.
MICKEY MCMANUS:
His legend status.
But the other thing
is-- so I put this up
actually under humans.
So you guys are probably
pretty familiar with AlphaGo
and this notion
of having Go that
has a lot of moves, more
than atoms in the universe,
and could humans beat it.
And I could put this
up to defend machines.
It's kind of
amazing that AlphaGo
is able to beat a human,
the best human in the world.
But the funny thing was, if
you think of the bell curve,
a good way to learn things
is reinforcement learning.
Like Serena plays against
Venus, somebody a little more
amateur, to kind of push her
up in skills, and also plays
against a real pro,
and pull her up
that skill chart from sort
of amateur to virtuoso.
And so that's what
AlphaGo was doing.
They actually played
against someone, maybe here,
played against the 1000th best
player in the world, and then
the 900th, and then the
800th, and then the 700th.
But what I think
is interesting is
there's an article
in Wired where
the 633rd third player in the
world basically said, you know,
I have drawn the line.
Nobody's getting past me.
Because it was an open
question at the time,
could you do better
than the top 1,000?
And he kept winning and winning,
and then he lost one day.
And he went home and he
thought, I just had a bad day.
And he came back and he
won, and then he lost,
and he never won again.
And so imagine you
spent a decade honing
your craft, decades,
maybe, honing you craft,
getting to the top 1,000.
And then suddenly in an
afternoon your passion is dead.
Like, oh my gosh.
And he went home and
actually had nightmares.
He had dreams, bad
dreams, nightmares,
he started actually thinking
very seriously about what
life was going to be like.
And this article documents it.
It's kind of interesting.
It's called &quot;The Sadness and
the Beauty of Watching Google's
Alpha Play Go.&quot;
So here's the thing.
After a few days, he actually
started having dreams.
And he actually started
thinking about all the moves
the machine did.
And he started thinking
about entire new pathways,
whole landscapes he had
never thought about before,
and no human had ever
actually explored before.
And he came back in and he said,
could I join the bell curve,
but I'm going to be
over on the amateur side
and maybe you can pull me up.
And by the time AlphaGo
won against the best player
in the world, number
633 was number 300.
And it was only
four months later.
So this gives me a
little bit of hope.
There's something
there that maybe we
shouldn't be counted out yet.
And then on the machine
side-- a little while
ago Qualcomm premiered a chip.
It doesn't connect to
the internet or anything.
It's called the zeroth chip.
And it was just one
of many experiments
out there where you don't
write any code at all.
You just give it
carrots and sticks.
You basically raise the
product, in this case a robot,
like a child.
So as a designer your job is
basically to raise a child.
I'm not very good
at raising a child.
I only have one and
I gave up after that.
But basically, it goes
over the white square,
you give it a carrot.
And over time it basically
uses biologically realistic
neural networks to
learn how to be.
So what percentage
of our products
will really be raised, instead
of designed from the top down?
Well, we have to design
for more loss of control,
the same way we try
our best with our kids,
and then we kind of lose
control when they become 18.
Carnegie Mellon did
an experiment recently
that I thought was
kind of interesting.
It turns out that about
90,000 people crash at night
during the rain,
and a lot of times
it's the internal reflection of
the raindrops reflecting back
in your eyes.
It's very hard to see.
So they said, well,
why don't we just make
headlights that are fast enough
that they could actually turn
on and off with each raindrop?
And just be able to put black
wherever the raindrop was,
and then just project white.
So it's always
high beams for you.
And they were able to
actually demonstrate this.
They basically put a DLP
projector with a camera,
with a machine
learning engine in it,
and connected it to all
the other headlights.
And by the time I got this
video, it's now 600% faster.
And so they actually
have tested this
with 100 cars driving at them.
And they actually
project a black pixel
over the eyes of
the oncoming driver
so that the driver
never sees high beams,
and also illuminates the
deer walking across the road,
or the bicyclists, and things.
So you never turn on high
beams or low beams again.
Now as a human, I
thought that was
a pretty cool job,
remembering to turn
the high beams on
and low beams on.
But it is interesting to see
the most boring prosaic thing
in the world suddenly changed,
because you have this ability
to do computation at
speed and prediction,
prediction at speed,
which is really
an interesting part of this.

I've been working on a
little project for cars,
and I thought it would be
kind of neat to see what
would happen if three
kids in a garage
could start a car company.
So we started ripping,
using reality computing,
physical cars.
In fact, all the cars
of the 20th century.
We started kind of
getting the guys who
designed some of the most fun
hot rods and high performance
cars that raced Baja
1000 and Pikes Peak.
And we started ripping them
using new kinds of sensors.
Just like you used
to rip CDs, you
can rip physical things now.
It's called reality computing.
And we brought it in
and used the sensors
on the actual
vehicle itself, too.
This was a bunch of
20-year-old kids wired this up,
and we ended up capturing
about four billion data points
in the first afternoon.
And so what happens when
reality is so cheap to capture
that we have a lot more
data than a user study,
or a lot more data than
all that-- in fact,
we actually had it
on his head as well.
We were doing EEG to look
at his stress, his valence,
his performance, and his flow.
So that's a contributor to
this machine learning, which
I think is kind of interesting.
But then what
happened is we put it
into this tool called
Generative Design, which
uses, again, genetic
algorithms to be
a collaborator in some ways.
Basically you give it all the
forces, you set your goals,
and then it generates
thousands of children
based on those goals.
So they call this
form follows forces.
And one of the senior
designers that I
worked with who had designed and
shipped hundreds of millions,
actually, of products-- this
is running through millions
of simulations looking
at the forces hitting it.
So you don't design anything.
You just put in the forces,
the ports, the obstacles,
and it designs the
chassis for you-- ended up
reducing about 20% to 30% of
the weight off the vehicle
after it had been based on some
of the guys who've spent 40
years designing these vehicles.
And they weren't able to
get that weight off of it.
So we're taking that back
out to the desert actually.
I think now it's not even humans
making the fabrication stuff.
It's actually all just laser
cut, laser automatically bent,
completely autonomous
sort of robotic stuff,
because that kind of
structure is really complex.
And so this is what the
structure looks like.
It was all kind of bent, cut,
numbered like a tinker toy.
So people that weren't as versed
in building high performance
chassis could basically
put it together in a week.
So again, I mean, machines are
doing some pretty interesting
stuff.
And it's not just
the design part,
but it's actually getting it out
into the world and coming back.
So could three kids in a
garage start a car company
and have effectively the
energy of 10,000 engineers
behind them?
I don't know.
It's a possibility.
This notion of just defining
the forces-- this thing
is a motorcycle swing arm.
There's an axle and
some other things.
And this thing has so many
newtons on it pushing on it.
And then just having the
product evolve itself.
Just the same way like your
horse's hips on a horse,
probably they were
formed by the forces
that the muscles pulled out over
a really long period of time.
And then the last
thing I wanted to show,
and this was something
that was-- these two
things were very provocative
when Don and I started
talking-- is, I'm a fellow
at a place called Autodesk
in the office the CTO.
And we've been playing
around with consuming
all of the actual point clouds
and geometry of the world.
And if you think about, like
if you want to learn German,
you could do Rosetta Stone.
And you could learn
the vocabulary,
and learn some test phrases,
and you will never learn German.
Or you can just go to
Germany and be immersed
in the information
of living there,
and all this stuff that
we can't really detect,
and you will learn
German like a pro.
So they said, could
we immerse ourselves
in all the physical things that
have been built in the world?
And 90% of the buildings
and half the products
and all the movies
and stuff have all
been built in Autodesk software,
so we have a lot of things.
And so this is what
that looks like.
It started chewing on
things like car parts.
And if you type in
car it finds the parts
that you've been working on.
And you raise it like a child.
It says most cars
are made of axles.
They've got other things,
but a lot of things pivot.
It automatically builds in
ontology with part groups.
It automatically says these
gears go with these gears,
and it's the social
graph of things.
And it assembles
it automatically,
so as you're drawing
a physical object,
it auto completes on the side.
And again, it makes you
think about, OK, well what's
the role of designer
when this is actually
consuming all the
things that have ever
been built in the world, and
starting to actually suggest
things?
I have one last
one that I thought
was kind of provocative.
How many people
have seen Ostagram,
or played with Ostagram?
This is-- a Russian
researcher decided
to take Google's
TensorFlow and goof around
with some algorithms around art.
And a lot of people have
seen the Rembrandt thing,
but I thought this was
actually more provocative.
So let me come over here.
So this has Ostagram, and
here's the output photo.
Here's the person's input
photo, and here's just
some random other photo.
And Ostagram is
actually a German word.
It came out of this notion
ostranenie, or something.
I can't pronounce it properly.
But it was this notion
of taking the familiar
and make it strange.
And that's really
what's been driving
art in the 20th century.
If I give you a fact-based
piece of literature,
you should communicate-- you
should get my communication.
If I give you a
poem, you actually
have to work really
hard to figure out
what I'm trying to communicate.
So I'm taking
something that I think
I understand and I'm
making it strange so
that you have to work at it.
And the act of working
at the perception
is what is so
rewarding about art.
You have to figure out
what's going on there.
So if you look at
these, it turns out
he also used some algorithms
to make it very hard for you
to delete stuff.
He set up an economy
where if you really
didn't like something, you had
to go to the end of the queue,
and the queue might
be 1,200 hours long
or something at some times.
And so I think what
he was really doing
was studying human fascination.
And if you look at this, it's
not sort of a normal filter.
It's actually something more.
There's something
else going on there.
Because it's figuring
out where eyes are,
it's figuring out where
the light should be,
and it's figuring
out these things.
This is a really,
really interesting one.
It's not just a filter, but
it's a new kind of filter.
And it's exploring
novelty, I think.
Now, if you look at
that design graph
I showed you a minute ago, and
you design a lot of baseball
stadiums-- so you've raised
the child, a design graph that
understands baseball teams,
the diamond and the concession
stand and all that-- and then
you also had another team that
was raising a child machine
learner that actually learned
everything about how to build
physical structures in Sao
Paulo, and you merge the
two of them together,
you could have like
maybe 80% or 90%
of a baseball stadium
that knows how
to be built with
local construction
materials, methods, and
aesthetics in Sao Paulo.
What does that mean?
So I want to leave us with those
two sort of sides of the coin.
I think there's something
big happening here,
and I'm not sure that any
of us know the answer.
Which is why we
kind of thought it
might be fun to debate
and leave it at that.
So if I can ever find my mouse,
I'll just go back to black
here.
Thanks, everybody.

DAN RUSSELL: Thank you, Mickey.
So for the second act
of today's performance,
we're going to have a debate.
But it's going to be
based on this notion
that Mickey was
trying to articulate,
about the role of
machine learning
and AI in design process.
And so we have two propositions,
and we're going to toss a coin.
You want to call it, Don?
MICKEY MCMANUS: Don,
you get to call it.
DAN RUSSELL: OK.
Call it.
DON NORMAN: Tails.
DAN RUSSELL: And the
answer is, heads.
So Don's assignment is,
machine learning will herald
the golden age of designers.
And Mickey's proposition
for this debate
will be, no, no,
no, design is dead.
And just as he was
showing us, it's
going to fall out like residue
from the actions of machine
learning.
So Don, you want to give us
your beginning of the debate?
Machine learning will herald
the golden age of design.

DON NORMAN: So Mick gave us
a whole bunch of examples.
Notice anything strange
about those examples?
No people.
None of this stuff
was actually designed
to interact with people,
designed with people in mind.
Yeah, the automobile
was driven by a person,
but they didn't design
it for the driver.
There was absolutely
nothing in there
about what the driver needed.
It was all about what the
framework needed so it
would be rugged and light.
And the same with
our last example
of all those
wonderful paintings.
Yeah, it was just
automatic, right?
It had nothing to do with-- it's
just going to be intriguing,
it's going to send a
message to the observer.
So now let's think
about what the role
is that a person might do.
So in fact, by the way, I
realized just an hour ago
that we shouldn't
have designed--
we shouldn't have
named this Design
Machines Against Designers, but
against all creative people.
So actually, all
of Mick's examples
are replacing engineers,
not replacing designers.
It's the engineers who
do the mechanical stuff.
What we do is the hard stuff,
make it work for people.
Now, next issue.
Where did the idea come from?
What made you think of designing
a car in the first place?
What made you think of making it
more rugged and more reliable,
et cetera?
That's the designers' role.
So what this is going to
do is relieve designers
of the tedium of drawing
every little line
and every little component.
But allow us, in fact,
to step back and say, oh,
what is it we're
trying to accomplish?
And so if you look
at the program which
is called Dreamcatcher
by Autodesk, what you do
is you present it with the
goals and the constraints.
The goals that you'd
like to achieve,
and the constraints
in the design.
And then you sit
back and you watch,
and you say, that's no good,
don't do any more of that.
Or, that's a good
direction, keep doing that.
That requires great
human abilities, right?
Judgment qualities.
I mean most of the
tedious work in design
is drawing those little
details, thousands of them.
And we don't need to do that.
It's the same with
the calculator.
Did the calculator teach us
not to be mathematicians?
No, it made us more powerful.
We don't have to worry
about making mistakes
in the calculations and doing
all those tedious calculations.
We can think about what
the real problem is.
So I think this
is going to herald
in a great new era,
where we can actually
use our aesthetic sense, our
imagination, our creativity,
and then let the hard little
dull stuff that we're not
very interested in, let
that be done by the machine.
MICKEY MCMANUS: Oh, Don.
I feel like somehow I brought
a knife to a gun fight.
I'm a little in trouble here.
DON NORMAN: My mic is on.
So I was just told
my mic is off.
I was carefully
vetted by the experts
who told me my mic was on.
MICKEY MCMANUS: So I think--
DON NORMAN: Hello,
hello, just a minute.
This is a machine
problem, right?
Or is it a Google problem?
How do I know whether
my mic is on or not?
What makes you think it's off?
SPEAKER: I'm getting
told by the--
DON NORMAN: Well then, I
need a person to fix it.
MICKEY MCMANUS:
Might be a switch.

See, this is why,
actually, humans
shouldn't be allowed
even near these things.
A machine would have
just turned it on by now.
DAN RUSSELL: So while
we debug Don's audio--
MICKEY MCMANUS: Yeah,
so it's interesting.
So Don's claims, I think, where
there are no people involved,
that was very much about
replacing engineers
and that sort of tedium
but not necessarily
the artistry of the people.
And where did the
idea come from?
But it's really
interesting if we
look at what Margaret Mead
says, what we say we do
and what we actually do are
often very different things.
I'm not sure we really
understand people.
And I'm not sure
that we always do
the right thing for ourselves,
let alone anybody else.
About two or three
years ago NPR put out
an April Fool's Day article
that said 70% of people
will not read the rest of this
article before they share it.
And it was all Greek, or lorem
ipsum, all the way to the end.
At the very bottom
it said April Fools.
And that was sort of
silly and it was fun.
And then this summer, Columbia
University with the London
School of Economics,
decided to test it for real,
and they found it
was actually 59%.
So we amplify our blind
spots in some ways.
And you think about things like
self-driving cars, the reason
that we think
self-driving cars might
be a good idea is we are
horrible at paying attention
all the time.
And we're pretty bad
at actually managing
that kind of weird lull
as you drive to work.
And a lot of people die.
And so I wonder in
some ways if saying
that the idea should come
from people and anything else,
maybe not.
Maybe we need to be
protected from ourselves.
And maybe the ideas,
like Ostagram,
are somewhere in the
middle or somewhere else,
where they're actually
helping us see
things in a very different way.
So I just wonder about that.
And I'm not
convinced necessarily
that creativity is
the lone purview,
or even action is the
lone purview, of humans.
I think we are meat machines.
And it's very likely that the
difference between machines
and humans is that if a
machine learn something
new and insightful, maybe
about your emotions--
they've now demonstrated that
machines looking at pictures
are able to better
guess emotions
than people at this point.
They're starting to
excel at that empathy.
So it might be that
in some future state
they are helping us,
but every time they
learn something they can
open up a network connection
and everybody else learns it
too, every other machine learns
it too.
So I just think the
thing is that this
is going to have such
a rapid pace that all
of the things that we do in
this precious world of capturing
a few interviews, or doing
a little bit of shadowing,
or doing think aloud
activities, where we get almost
no data at all and we make
a lot of leaps of faith,
mostly based on
our own hobbyhorses
at times-- this is
how we were taught,
this is the school we went
to for design or for UX
or something, this is the
religion that we believe today,
creative spaces should
all have PlayDoh.
Really?
Or beanbags?
I don't know.
You know, they feel good.
And I think we fall for
shamans in the design world
very easily, but
science is really neat.
And I think with
the rise of sensing,
and the rise of
multimodal sensing,
where the point where
we actually may be able
to detect empathy better
by robots than by humans.
And maybe protect ourselves
from our blind spots,
and help us amplify the delight,
the passions, that we do
want to have-- it might be
that design precipitates out.
That really, music used
to be something you
could have a good career with.
And now everybody does it
but nobody gets paid for it.
You do it as a passion.
It's just not an economic thing.
I don't think design will be
in the corner office, ever.
I think it'll just slowly fade
away as being an irrelevance,
just like a horse
and buggy driver.
DAN RUSSELL: The segue
to music reminds me
that I know Don has got
some thoughts about empathy
in this context.
DON NORMAN: Don't worry.
I'll do it.
DAN RUSSELL: OK, good.
DON NORMAN: I told him
to pick up on that one.
DAN RUSSELL: I did my job.
DON NORMAN: So Mickey says
we don't understand people.
It's true, we don't.
Because people are among the
most complex things around,
and we also respond
continually to the surrounding,
to the environment,
to the activity.
So yeah, psychology
is really hard.
Cognitive science
is really hard.
But I'm not sure what
the implication was,
that machines will
understand people better
than people understand people?
MICKEY MCMANUS: Yeah.
I think we should
be pets, like cats.
DON NORMAN: Not obvious.
Not easy at all.
That was Marvin
Minsky's comment.
Marvin Minsky, one of the
founders of the field of AI.
Recently died.
He said, was he worried?
He was asked, wasn't he
worried that machines
would get smarter and smarter
and soon take over and be
smarter than humans?
And Marvin said, no.
It's nothing to worry about.
Are you worried about your dog?
If we treat our dogs well, the
machines will treat us well.
Same way.
Well, that's not the
future that I envision.
I think that actually, we
don't understand people, which
is why in our designs, we
don't just design something
and throw it out.
We make sure it works for you.
We test it.
The testing is-- it
isn't user testing.
User testing is
to find the bugs.
Part of the design process
is iteration, right?
We try to understand, what is
the fundamental problem we're
trying to solve?
We then try to figure out
what we might do to solve it.
But then, as we are
working our way through,
we're always testing it with
people we're designing for
to make sure it works because we
don't really understand people,
and we may not ever, because
everybody is different.
Medicine is learning
that, by the way.
That now, when you get
sick, or you get cancer,
or you get whatever, there
is no single prescription
that fits everybody.
You have to actually know
that person, not just
their genomic structure,
but their microbiome,
and also the environment
in which they live.
And those will determine
how we prescribe.
And we're still a
long way from that.
And machines will
help us do that.
So let's take a look at
where machines are helpful.
Machines are
helpful when there's
a huge amount of
information required
machines are helpful when you
require continual attention
to a dull, boring task.
Machines are helpful when
you require extreme precision
and accuracy.
Those are stuff
that we're bad at.
And yeah, because it's
pretty dull stuff.
And the reason that we--
driving is an activity
that people should not be doing
because driving, first of all,
it's incredibly hard to learn.
You may remember that it can
take a year before you're
comfortable driving.
But after you've learned it,
it seems incredibly easy.
Nothing happens for
long periods of time.
The average amount you must
drive before there's a death
is 100 million miles.
So driving seems quite easy.
We've taken pictures
of people driving.
They drop things on the floor
and they bend over and pick it
up while they're driving.
Or even tuning a radio station
can take 10 or 15 seconds.
At 60 miles an hour,
one second is 90 feet.
It's crazy.
This is a thing we should turn
over to machines, absolutely.
It's a mechanical device.
They can do a better
job than we can.
Right now, a million people are
injured in the United States
every year, and 35,000 die
in automobile accidents.
So even a machine
that's imperfect
could cut that in half.

Empathy.

I don't believe in empathy.

I don't believe machines can
do empathy better than we can.
Or maybe they can because
we can't do it at all.
Look, empathy means
putting yourself--
understanding the other person.

But we don't
understand ourselves.
And I think it's wrong, anyway,
to design for the other person,
because it's the rare case
that we are designing something
for one person.
We're designing things that will
be used by millions of people,
ideally.
Google, you don't want
to design for one people.
You want the whole
world to use it.
And so I don't
think that we should
design for empathy because I
think that's an impossibility.

We should start over again.
MICKEY MCMANUS: I
feel like this room
is trying to prove that machines
are always going to suck.
What's going on here?
I don't appreciate it, Google.
DON NORMAN: I can give some
Google stories if you want,
but I won't.
I'll save you that.
MICKEY MCMANUS: So if you
don't believe in empathy,
what do you believe in?
What are humans good at?
What's the point?
DON NORMAN: I believe that
we design for the activity.
If we really understand
the activity,
if we design something
that people think, yeah,
that's the way the
activity should be done,
it will be wonderful.
Because, I mean, take a
look at the automobile.
It's the same all
across the world.
How come?
Drivers are different.
And they drive very differently.
But they use the same tool.
Look at a violin or a guitar.
They're horrible.
Any human factors
professional would say, no,
they should be prohibited.
Take the violin, right?
The way you have to turn
your hand around, et cetera,
that's really harmful.
And it is harmful.
Lots of violinists have
to give up their career.
They get tendinitis and they
can't play anymore because
of that horrible position.
But nobody complains
because if you look at it,
it's five strings, and it
makes two different sounds.
And it has frets, or
non-frets, depending
upon the instrument
that determines
the note that comes out.
And you pluck it.
And yeah, that seems
like a sensible machine.
And I have to hold it this way.
But yeah, that's the way it is.
And so when you do something
that fits the activity,
it works well.
Forget empathy.
MICKEY MCMANUS:
Fit the activity.
So I think this is interesting.
But, I mean, the claim
there is a violin
is a well-designed product.
I'm not convinced it's
a well-designed product.
I mean, it's really
painful and complicated.
You just told me it
actually causes actually
physical harm to people.
And today, now people
can scrub music and have
a whole section of violins.
People can make
music that have never
been able to make
music in their lives.
It's been democratized.
Google doesn't actually make
one product for everybody.
They make one product
for every single person
because it's constantly
tuning for that individual.
It's n equals 1.
There's this rise of
the notion that there
might be these activities
or a few different things
that we can design for
this general purpose tool.
I'm not sure it
exists in the future.
I think it's all going
to be n equals 1.
And it's going to
be tuned for us
to either make it
more difficult for us
so that we feel a
sense of striving--
that desirable difficulty--
or easier for the dumb stuff
to get it out of the
way or protect us
from our own blind spots.
DON NORMAN: Yeah, but
what you mentioned--
you said it's going
to be a tool that's
designed for each of us which
allows each us to expand
our creativity.
MICKEY MCMANUS: Yeah.
I think creativity
is going to flourish.
DON NORMAN: And
one of the things
that we used our
creativity to design
was that tool that designed
itself for each person.
MICKEY MCMANUS: Yeah.
I'm a little worried, actually,
that designers might actually
herald in a denial
of novelty attack.
Because we love
creativity so much,
I suspect that we're
going to end up
getting overwhelmed
with creativity
to the point where we just
want nice, gray boxes.
Just give us a little
chillout space.
I think I'm going back to
that cat metaphor somewhere.
DON NORMAN: Actually, you're
correct in the following sense,
that--
SPEAKER: They can't hear you.
DON NORMAN: Who's they?
SPEAKER: This is live streamed.
DON NORMAN: This
is live streamed?
There's nobody
left because we've
been going on for
25, 35 minutes,
and nobody has heard us, right?
So no one's left.
MICKEY MCMANUS: It's them.
AUDIENCE: Machines.

DON NORMAN: And that
caused me to lose my place.
MICKEY MCMANUS: It's gone.
DON NORMAN: It's gone.
MICKEY MCMANUS: See, and
if it were a machine,
it would remember
where it was right now.
It would totally pick up.
DON NORMAN: And that's
the problem with machines
is they never give up.
They're [INAUDIBLE]
minded, right?
MICKEY MCMANUS:
But also, I mean,
we're fooled by randomness.
You've got the
black swan events.
Science is hard.
And I don't think
designers, as a profession,
UX-- figure out whatever
you want to call yourself--
researchers, et cetera.
I don't think that
they've committed
enough as a profession
to take this seriously.
We don't have licensing
in this world.
If you're an architect, a
bridge could fall and kill you.
If you're a designer, I guess
you could just wave your hands
and learn some code, and
plug some APIs together.
I'm a designer.
And there's some
rigor in some places.
But frankly, it's rigor based
on the scientific methods that
didn't have machine learning.
DON NORMAN: Wait a minute.
We're not going to have
architects and bridge
builders anymore, remember?
MICKEY MCMANUS:
Yeah, I hope not.
DON NORMAN: It's going
to be done by machines.
MICKEY MCMANUS: I don't
really want somebody
deciding to make a new bridge.
I want to dream about
going to Alpha Centauri.
I just don't.
I'm not interested
in that stuff.
DON NORMAN: Well, you dream
about going to Alpha Centauri,
but I've got to visit
my family, which is
on the other side of the river.
So it doesn't do me
any good that you're
going to Alpha Centauri.
I need to cross.
I need a bridge.
But the bridge design, there
are two components of design.
Let's take bridge design.
One of them is
the actual drawing
of all of the struts
and the whatever,
et cetera, of the bridge.
And that can be done by
a machine, absolutely.
We don't need an engineer.
Those aren't designers.
Those are engineers, right?
We don't need engineers
and civil engineers
to do that because the
program designs it.
And the program does all the
calculations about the stresses
and strains and wind
resistance and all that stuff.
But it took a person to
say, we need a bridge here.
It took a person to figure out
where the bridge should go.
It took a person to
convince the city
to allow that to happen
because when you start
to put the bridges there,
everybody says we need
a new bridge across the river.
But what do you mean?
Wait a minute.
You're going to demolish my
house so the bridge can go?
No.
Put it someplace else.
So the political issues
are really critical.
And they impact people.
And it's only people who
can solve those problems.
The creative part is deciding
what to do in the first place.
The doing?
Yeah, I'll let your
programs do it.
MICKEY MCMANUS: But that
means your whole claim
is that humans are the only
ones that can provide agency.
I'm not sure I believe that.
I mean, when you use
Waze on the road,
it's continually
deciding what you
should do to try to get
you to a particular goal.
It's not you deciding.
DON NORMAN: It's deciding
based upon human inputs, right?
MICKEY MCMANUS: Maybe
a long time ago, yeah.
Now it's just machines.
DON NORMAN: That is the
problem I've noticed.
Waze often detours
around accidents
that have been cleaned up a
long time ago because people are
really good about entering
the issues into Waze,
but they're really bad
about taking them out
when they're solved.
And you also know that Waze
now automatically routes you
through the quiet
neighborhood streets.
So the people in
the neighborhood
are putting in false Waze
reports to try to prevent that.
MICKEY MCMANUS:
Well, now I think
you're just saying that
this is an arms race.
I just don't think--
DON NORMAN: Yeah,
people against machines.
But why is it an arms race?
Who started it?
MICKEY MCMANUS: It's
a good question.
Well, probably the market.
I want you to win so badly.
But there's a part of me that
actually is worried about this,
like deeply concerned
that we will
be the handmaidens
for our own demise.
We will shout at the pinnacles
that design and designing
and all this stuff is
more important than ever.
And then one day,
we'll just wake up,
like that that guy
playing Alpha Go.
And he'll be like, ah, crap.
DON NORMAN: You want to take
over and do the next phase?
DAN RUSSELL: So part
of what I'm hearing
is this distinction
between Don and Mickey
about how much of the
designer's role is taken over.
Don wants the crufty
stuff to go away.
Just automate that.
Mickey is taking a
radical position.
No, no, no, no.
Let's do design
completely by machine.
So the next question we
had here, actually, was,
is this a new utopia
for designers?
Or are designers going to
be like buggy whip makers?
Are they just gone
in the future?
What would you say, Don?
Are designers-- is it
going to be utopian,
or is it just all dystopian?
DON NORMAN: I gave the example--
it's sort of a made up example,
but is sort of the idealized
dream catcher in which you give
it the issue you're
trying to solve,
and then you are a
critic, basically.
You're critiquing it.
You're saying, that's good.
Do more of that.
And no, that's no good.
I want to ask the audience
who's here, how many of you
think that would really
empower you and unleash
your creativity?
How many of you think
that would sap it away,
and you'd hate to do that?
So how many think it's
a good, exciting thing?
How many think it's kind
of dangerous and scary?
And it's interesting.
DAN RUSSELL: Wait.
How many people raised
their hand for both?
Yeah, that's what I thought.
DON NORMAN: But the
interesting thing
is that the way you raise
your hand, the exciting one
did that.
And the creepy did like that.
Yeah.
MICKEY MCMANUS: Well,
that might be-- you know,
part of the reason we decided we
wanted to do this is we really
don't-- I think we're
grappling with this right now.
And you've mentioned a few
times the sort of middle ground,
I think, a little
bit, which is sort
of treating a machine as a
teammate or a collaborator.
Get this stuff out of my way.
But you're going to augment me.
And I'll be able to
be more powerful.
I do think that might
be the third way.
I think there is some
space there that I
would be willing to argue.
And I don't I
think there's going
to be a whole class of
designer, UX researchers,
et cetera that are going to
precipitate out no matter what.
Anytime something
that's incredibly rare
suddenly becomes incredibly
cheap-- and in this case,
it's prediction.
Anytime that happens,
you get things
that are complimentary
to it, and they
get amplified, and things
that it just collapses the job
position, and those disappear.
But I think the people who are
really hungry, that actually
dig in and actually engage
and play, and think of it
not only as raising an AI
that's my own teammate,
but raising the product,
or raising the experience,
or raising the room, I
think that has potential.
Because I've seen this ability
for it to open up your mind
about what happens.
And I think humans have maybe
a three billion year advantage
on machines.
So hopefully, we can take
advantage of that too.

DAN RUSSELL: So there
was a Dory put up.
And I'm going to merge a
couple of the questions
together and ask
both of you guys.
And then, after you're
done answering this,
we'll open it up
for live questions.
And at the very end, we'll
give each of these folks
a couple of minutes to sort
of summarize their position
and why, of course, the
other guy is totally wrong.
So integrating a couple of the
questions we had on the Dory,
one of the themes that comes
out from the questions that
were online is, how do we
design with AI components?
You've been talking about design
systems that have guidance,
you say.
No, no, bad robot, good
robot, whatever, right?
But the folks in
the audience have
to design with machine
translation components.
They have to design
with automatic image
labeling systems.
They have to design with
things that may be different
the next time you use them,
because it got smarter,
or because it decided you
don't need to see that anymore.
So how do you
think, as designers,
that you should be thinking
about design with AI ML
components?

DON NORMAN: Well,
in our lab, we call
it human technology teamwork,
which is sort of the framing
that we give.
But it's easy to say and
very difficult to do.
So with today's technology,
it's easy to do.
And we argue that,
basically-- in fact,
I wrote a whole book about this.
I called it &quot;Things
That Make Us Smart.&quot;
That it is things,
artifacts that we
have invented and built and
designed that make us smarter.
Actually, we aren't any smarter.
It's we plus the
artifact that's smarter.
And so we're smarter than either
the artifact alone or us alone.
And the calculator
is a great example.
But almost every
technology we can think of
makes us more powerful, makes
us faster, makes us smarter.
Again, an automobile
doesn't make me
as an individual faster.
But me plus the
automobile is faster.
So that's the argument.
But it's harder to do.
For example, we're looking
at a physician's diagnosis.
And we're trying to figure
out what tools we can give
to make the physician better.
And we're working on that.
And we're actually succeeding.
But the real question
for this debate
especially is,
when will the tool
will be actually good enough
that it takes over and replaces
the physician?
And that's already happening.
If you're diagnosing
tumors, for example, it
turns out that we can do
better pattern recognition
and better diagnosis using
the MRIs and x-rays and CT
scans by machine then by
a trained radiologist.
So the radiologist
jobs are now changing.
So they are not necessarily
detecting the tumor.
They're trying to
interpret it and trying
to decide what should
be done about it,
or whether other
views are required.
I just took part
in an operation--
watched the operation.
My boss had an
operation, Larry Smarr.
But Larry, given
Larry, he turned it
into a research project.
So he spent all day in the
MRI machine getting scans.
And then we transformed that
into a virtual reality walk
through of his colon.
And we had a major
two-hour meeting.
It's going to be
operated on by the--
MICKEY MCMANUS: Was the
meeting in his colon?
DON NORMAN: In his
colon, virtually.
Intuitive Surgical, making the
machine, [INAUDIBLE] machine.
And so the chief engineer of
Intuitive Surgical was there.
And the computer
scientists were there.
And the radiologists were there.
And the surgeon was there, et
cetera, et cetera, et cetera.
But it's a combination.
It was really interesting
that you needed both.
And the reason I discovered
you needed both is it
looked neat on the
virtual reality.
And Larry even pulls
out of his pocket
a 3D printed image of his colon.
And we can see where
it should be done.
OK.
It was wonderful until we
saw the actual operation.
And now you look inside
his stomach, if you will,
or abdominal cavity, really--
I couldn't recognize anything.
It was just a mass of pulsing,
moving, changing shapes
all over the place.
It turns out the colon
is not stationary.
It's peristalsis.
It's moving all the time.
And there's this other thing.
What is that?
Oh, that's fat.
Or what is that?
That's the liver.
What is that?
That's a blood vessel.
That transformation
machines can't do yet.
It's really a mess.
So the combination is powerful.

We're going to get
to the conclusion.
By the way, the
conclusion is going
to be, I don't know
how it's going to--
MICKEY MCMANUS:
Hey, wait a second.
I've got to answer
the question too.
What's going on over here?
So how do you design
with AI components?
How many people
have taken a class--
or actually not
just taken a class,
but like a whole
semester, or maybe spent
a year doing improvisation?
How many people?
Maybe about-- yeah.
There's actually a
pretty good number.
That's excellent.
Why did you take improvisation?
AUDIENCE: Because I
wanted to be funnier.
MICKEY MCMANUS: To be funnier.
OK.
Greg, I saw you
in the back there.
Why did you take improvisation?
AUDIENCE: Because
it's a skill set
that you are-- it's actually
a very disciplined skill set
around helping another person--
always giving something
to someone to build with.
So one rule of
improv is that you
have to have hand-off that the
other person can take and build
something with.
And that skill is
great for teambuilding.
So that's why I was
interested in it.
MICKEY MCMANUS: You always
are trying to hand something
to the next person.
You're trying to be
fun to play with,
which is really an
interesting thing.
At Carnegie Mellon,
where my lab came out of,
there's a master's
program called
Entertainment Technology.
And it's the Entertainment
Technology Center.
And it's a wonderful program.
I see a little
clapping over there.
Wonderful program.
But what's interesting is that
every single incoming freshman
has to take a full
semester of improvisation
because they want you to
actually be fun to play with.
And the reason I mention
that in the context of how
do we design with
AI components is we
probably have to design
AI components that
are fun to play with.
And we probably, as designers,
have to invest in ourselves
to actually learn improvisation.
Because high performance
teams are probably
going to be the currency.
It's not the lone inventor,
the lone designer,
the lone researcher.
And there was some research
out of, again, Carnegie Mellon,
around seeing the mind
and the eyes of others.
And looking at high
performance teams
and how successful
they were when
they were interdisciplinary.
So think of one
discipline as this machine
that's trying to make guesses.
And it's a black box.
It's very hard for you to tell
what the heck this machine
is going to do.
And it might change tomorrow,
just like another teammate,
because they had
a bad experience
or a good experience, or
they learned something new.
And seeing the eyes
and the mind of others
was that if you had
a few people who
could kind of see if the other
teammates were keeping up,
and pay attention and
kind of guide them up,
the team itself actually
worked as a higher performing
organism.
So I suspect, A, I'd like to
see some automation of that.
I'd love to see some way
that we could actually
build better high performance
teams and help us grow.
But the AI components
themselves are probably
going to have to
expose something to us
or be taught a little bit
more about how to improvise,
to be taught about how to be
fun to play with, I think.
And I think we, as designers,
owe it to our teams in general
to learn that, too.
The other thing that
happens in improv
is you learn status play.
It's the silliness
where I said, oh, Don,
I thought you were dead.
I'm in awe of Don, right?
I read his book when
I was in school,
going to school for product
design and everything.
But you have to be playful
because playful turns out
to be a way that you
can get into more
interesting conversations and
solve things, and poke around
at the edges on things, and find
out where the edges really are.
And I think, as we
work with components--
and they're not just going
to be digital components.
A few million IP cameras,
Panasonic printers,
HP speakers were taken
over a few weeks ago
and did a denial
of service attack
on the entire internet's
phone directory.
So it's not only going to
be good actors on your team.
It's going to be probably
bad actors in your team, too,
who have been
co-opted or something.
DON NORMAN: I want
to build on that.
Switching the rules of the
game now because-- no, no.
You want me-- switching
the rules of the game.
Actually, Greg, I
thought you gave the best
description of why we
should learn improv
than I've ever heard.
I've had these arguments--
I mean these discussions--
for a long time.
But that was a really
good description.
And so let me build on that.
And I think that's actually
the best answer to how
we might do human technology
teamwork, which is actually
better than the answer
I've been giving before,
which is we want each one to
provide something and hand it
off to the other person
to be able to continue it.
And here's what I think.
We're no longer
debating, by the way.
We're now agreeing.
MICKEY MCMANUS: We're
violently agreeing, though.
DON NORMAN: And I think
that we do need AI
because you can't have just
a dumb machine hand it off.
A calculator, sure.
I can give it the problem
and it gives me the answer.
That isn't the kind of
hand-off that leads me
to more creative things.
It should hand me
off with a puzzle.
It should hand me off something
that I have to build on
and them to work with.
And that's really great.
I think that's the
direction we need to move.

DAN RUSSELL: All right.
MICKEY MCMANUS: I agree.
DAN RUSSELL: We have time for
a couple of live questions.
Does anybody have a
question that they would
love to ask our speakers today?
Go.
I'll repeat.
AUDIENCE: [INAUDIBLE]
a good one to ask.
But something that you guys
were actually just talking about
with designing AI to be playful.
I've seen a lot of really
wonderful work coming
from artists who are
already doing this.
And what do you think
of the industry working
with people who--
artists are typically
people who will already be
pushing those boundaries
and finding those edges.
And so there's a lot of
really cool projects out there
like autocomplete
chatbots, people
who are writing novels
with autocomplete chatbots,
things like this.
Should we do more, going
into learning about AI,
of looking into
that as the industry
and partnering with
artists to do that?
DAN RUSSELL: So let me repeat
the question for the microphone
and the audience.
So what do you guys think
about artists working with AI
to explore that
space-- for example,
autocomplete chatbots, or
automatic writing for novels?
Artists and AI.
What do you think?

DON NORMAN: I've always
thought it was artists
who push the boundaries.
All of us can learn a
lot from the creative.
Look, artists always take
whatever new technology exists
and push it to its limit.
And quite often, the
technologists look at it
and say, wow, I didn't
know what that-- gee,
let me try to understand it.
A lot of good science
comes out of taking
what some great
artists have done
and then trying to figure
out what it is they did
and how it was accomplished.
So yeah.
I would argue that
yes, we should.
That's where the
creative spirit is.
It's the artists who are trying
to express and experiment.
MICKEY MCMANUS: I would
say there's a philosophy so
at MAYA, at our lab,
for the last 27 years
or so, our philosophy was
R&amp;amp;D. We did a part of our work
was R&amp;amp;D. What does R&amp;amp;D mean?
Anybody know?
AUDIENCE: Research and design.
MICKEY MCMANUS: Research
and development.
Actually, we don't do that.
Actually, MAYA doesn't
do much R&amp;amp;D like that.
What we think of it as
risk and determinism.
And so risk and determinism
is slightly different.
Risk is saying, R&amp;amp;D, the
research and development side,
will do forward chaining
for a few years.
You can see what
people are doing.
They can demand new features.
You can kind of pay
attention to squeaky wheels.
And you'll kind of slowly
forward chain in the future.
Risk and determinism is saying,
some people are fanatics.
Some people are wild cards.
Some people are crazy.
Some people are virtuosos.
It's like Jimi Hendrix bending
a guitar to make it talk.
That's actually
pretty cool, right?
So they bend and break tools.
They do things that
weren't expected of tools.
They make them harder to
understand, like that Ostagram,
where you take the familiar
and make it strange.
So when the first
set of automation
started coming up in the
Industrial Revolution,
one of the big ones
was the Jacquard loom.
Has anyone heard
of a Jacquard loom?
So this guy, Hollerith, actually
saw the Jacquard loom one day,
and he started this company
called International Business
Machines.
Because the Jacquard
loom took punch cards.
And it would play
the punch cards
and basically weave a carpet.
And there was actually a selfie
of Jacquard done on a Jacquard
loom in the 1600s or 1700s.
So we're not new with
selfies, by the way.
Artists were doing
it a long time ago.
But here's the thing.

French workers got
really pissed off
that automation was
taking their jobs.
And so they started
throwing their wooden shoes
into the Jacquard looms.
And that was called sabotage.
So if you take all
these artists and you
put them in the center
of your business
where shareholder value,
quarterly reports,
all that stuff really important.
They could throw wrenches.
They could show throw sabots
all in your system and break it.
So you don't necessarily
want to invite the artists
into the core.
But you may want
to wander with them
because they're
going to go somewhere
whether you like it or not.
Their passion is going
to take them somewhere.
They're going to
bend and break tools.
And we don't teach
literacies and fluencies
around bending and breaking
things and fitting in between.
But maybe we should.
And so I think it's
actually huge do this.
Risk is absorbing the risk and
wandering over the horizon.
Arthur C. Clarke said if you
want to push past the future,
one of his laws was you
have to walk to the horizon
and then keep walking.
And those people are
going to go there.
And you can't
predict the future.
But what you could do is you
could find really neat futures.
James Cameron is going to put
cameras all over people's faces
and try to invent a new
way of doing storytelling.
GoPro people are going to
just glue stuff to their heads
and jump out of planes.
And Sony never saw that.
They didn't play with fanatics
and people on the edges.
They were like, ah, who
cares about those guys?
It's 5%.
Same thing with the square.
So it was embracing
them to wander way
in the future-- explore caves,
exploit rocks you find there,
come back and maybe explain to
ourselves what the heck they
mean.
That's the risk part.
Aggregate the risk in a way
that you can wonder with them.
They'll pick you up
when you fall down.
You'll pick them up
when they fall down.
It's an interesting model.
Determinism is once you
find an interesting future--
because you can't
predict it, but you
could find some neat ones.
How do you backward chain
to put the things in place
to make that future
more slippery?
What could you put in place
today that would actually make
that a more likely future?
And so I think, in terms of
deep research and development--
the work that I've had to
do with DARPA and others--
most of the things that
have really paid off
have been pretty radical
because we've engaged artists
or fanatics or virtuosos.
And sometimes
they're just crazy.
And they're just
exorcizing demons.
But sometimes, they're finding
really interesting places.
DON NORMAN: I just can't
let-- first of all,
I agree completely with the
spirit of what you said.
But I want the
audience to know that
your historical information
is completely inaccurate.
The Jacquard loom did,
in fact, give rise
to these great big wooden slats
with punched holes in them
that say where the
weave should go,
which led eventually
to the punch cards that
were the forerunner of our
modern computation used
for counting the census
and things like that.
But Hollerith did not
start IBM, et cetera.
MICKEY MCMANUS: No.
We actually did the
census, I guess.
And he was later doing things.
But I play fast and loose
because I'm a human.
And humans are cool.
Like, we don't need facts.
First of all, it's post-fact.
This is a post-fact world.
DON NORMAN: I happen to be--
by the way, I'm in agreement.
The spirit is what
matters because that's
how things happen.
And for facts?
Well hell.
I go to Google and
I type in, &quot;What
really was the history of IBM?&quot;
And it will tell me.
That's what I use it for.

DAN RUSSELL: We have time for
one more live human question.
MICKEY MCMANUS: Human question.
DAN RUSSELL: I know we have
multiple human questions.
I think we only have time
for one, but we'll see.
Is it really tiny?
AUDIENCE: No, it's not.
It's huge.
DAN RUSSELL: OK.
Go.
AUDIENCE: So I was wondering.
You were talking about
the value of humans
as kind of deciding what
to do and the goals.
But couldn't you meta
chain that all the way up,
that machine
learning or AI would
be able to pick those out too?
DON NORMAN: I will say
no and he will say yes.

DAN RUSSELL: Continue
the question.
MICKEY MCMANUS: It's
an open question.
I mean, I think my comment
would be that it might be--
DAN RUSSELL: Hold on.
Let me repeat.
So I want to make sure I
understand the question.
You're talking about
chaining actions together
in order to make it more--
AUDIENCE: No, I'm saying Don was
saying the value of the human
is the initial input
for figuring out
what the goals are.
I mean, if it were true
intelligence and learning,
couldn't you eventually
teach the machine
to know what that
is, and eventually--
DAN RUSSELL: OK.
So couldn't you
teach the machine
what it meant to be human?
DON NORMAN: No.
No, no, no, no.
DAN RUSSELL: OK.
You say the question.
DON NORMAN: Here's
my understanding
of the question, which is I
said the power of the person
is figuring out what the need
is that we're trying to solve.
And we are the ones who decide
what it is we want to do.
Some of that can be done by the
machine but we do the decision.
And you are saying,
I think, well yeah,
but as our machines get
smarter and smarter,
they can also do the need
finding and the analysis.
Yeah.
And for the purposes of
this debate, I'll say no.
Not at all.
And he will probably
say of course.
And then actually,
in the end, when
I tell you what I
really believe-- well,
I'll wait till I'm asked.

MICKEY MCMANUS:
I'm not sure I have
a lot of thought about that.
But I would say that I think
that what I have been noticing
in just my career has been a
shift from designing things
to designing systems, and
realizing that nothing's
isolated anymore.
And understanding
systems is really hard
because there are all these
weird emergent things.
Sometimes they're
really dependent
on initial conditions.
Sometimes they're not.
One initial condition set
wrong, and suddenly you're
off over there
instead of over there.
And so yes, I think
you could do that.
I think we also could have just
a few wrong initial conditions
and have a hell.
We could have that
we literally just
echo all of our bad
behaviors and we amplify them
with technology.
And then we believe
that those are norms.
And we reset our norms
continually downward.
So I think of generative
systems, which
have feedback loops and
you know wicked problems,
that whole space.
And you can have a generative
system that starts here
and it spirals
inward to nothing.
Or you could have a generative
system that starts here
and spirals outward to
really interesting spaces.
I'm not sure we know enough
to start that process.
So I suspect that
the role of design
might also be more to
create fertile soil,
put some seeds down, bring
the rain and the sun,
and maybe become more gardeners.
And actively engage
in what are the laws
or the physics of this thing,
the policies, the architecture?
And then dynamically
pull out the weeds
and say, oh, I don't know.
I'm not so sure.
So maybe I'm almost agreeing
with Don in that regard,
because I think it's
going to be the people who
are kind of thinking
about what do
we want to have in the future.
And our wants are something that
I think we are probably pretty
good at at least exploring.
So turn wildflowers
into sun, et cetera.
DAN RUSSELL: So our debate
is working wonderfully.
We're getting all
kinds of metaphors--
forward backward chaining,
gardening, empathy, art,
you name it.
It's great.
I think we have time
for one last question,
unless we can squeeze you in.
Go.
AUDIENCE: You
mentioned medicine,
so I'm going to go with that.
That's not one of those
wild and crazy places.
There are people
doing some of that.
But we have higher stakes.
So in a higher
stakes world, what
is the nature of
expertise in an AI world,
especially if you're giving
them networked information,
or you're now designing
items for them
to use in surgical or on a
clinical floor, or whatever?
DAN RUSSELL: OK.
So if I could repeat
the question correctly,
in a high stakes
medical world, what's
the nature of
expertise and machine
learning or AI system
you want to build?

DON NORMAN: I think
it's, in some sense,
what it is today except
that our expertise will
be even more expert than today.
Because again, it's going to
be this combination of machine
knowledge.
So let's take
medicine, but I think
this applies to every
domain, not just medicine.
But I can't maintain
in my head all
of the findings from all
of the recent journals.
A computer can.
But I can look at the patient.
And I can get insights
that the computer can't do.
One of my friends, a physician
who we're working with,
points out that a
patient often comes
in with some complaint about
their stomach or something
hurts, who take the patient's
hand and holds the hand
and feels the hand.
And the patient says,
what are you doing that?
It's my stomach that hurts.
But no.
It turns out there's
valuable information
that you get that way.
But you combine that now with
the encyclopedic knowledge
of the computer, and its
ability to also remind
you of some rare phenomena
that you might not
have thought about.
But you add your own expertise.
And so we're super experts.
That's my goal.

MICKEY MCMANUS: I'm worried
I have a really long answer.
But in the work that
I've done, sometimes
in medical spaces and medical
devices and things, which
are pretty serious, sometimes
in clearing roadside bombs
and trying to make
sure that people
don't get hurt by friendly
fire in the military.
In both of those
kind of situations,
a lot of times, what
happens-- if you've ever
heard the parable
of the elephant.
The king said, please
describe this thing to me.
And five wise blind men--
one pounded on the leg
and said it's a column.
Another one pounded on the
belly and said it's a wall.
Another one grabbed the tail
and said it was a snake.
I think we have
imperfect information.
And most of our systems
today in some ways
reinforce that imperfect
information in some ways.
And also, you have to
continually keep it
all maintained.
In CAD, there's like
having a top view
of a drawing of my house,
and I have a garage.
Then I have to draw a side view.
And then-- oh, I want
a two car garage.
Oh, I've got to go back
up and erase the top view.
Oh, I broke the side view.
I've got to go back
down and do that.
I'm constantly trying to
maintain these assertions
about the house because I
don't have what would be called
in CAD a parametric model.
I don't have an actual,
phenomenal model of this.
And so what we
ended up realizing
is we had to have
phenomenal models where
you could have multiple
assertions and then set trust.
You had to let people set trust.
Why do I bring this up?
I think it turns out that there
are some interesting studies
around experts and
how groups of experts
are the worst at predicting the
accuracy of their prediction,
and tend to
self-reinforce each other.
And this is just a human thing.
And having a non-expert,
having someone
that pokes a question a
different way, is important.
But if you all have your own set
of facts, it's not parametric,
but it's like the old book
by Edwin Abbott, &quot;Flatland,&quot;
where there are three
separate individuals.
And everyone's trying
to guess at why
they're able to dance so
beautifully without talking.
And it turned out it was just
a table that had been set down
in a two dimensional world.
And the two dimensional
people couldn't see it.
If you don't have some model
that you can all actually
accrete and start
setting levels of trust,
you're just going to
fight over opinion.
And so expertise,
I think, turns out
to be more important,
but probably augmented
by fixing our blind
spots, or metacognition--
being able to give us some way,
whether it's through processes.
In the medical field,
there are a lot
of checklist
manifestos and things
to help us with our blind spots.
DAN RUSSELL: If I could
jump in for a second.
One thing that
sort of synthesizes
both of your
perspectives it's what
sometimes is known as
centaur systems, which
is combined AI and human.
And for example, the best chess
players in the world right
now are centaurs.
They're humans
that are augmented
by a machine that explores the
space of possible next moves.
And I think that's a
lovely sort of vision
to have that we could
actually augment
our expertise, our human
expertise, especially
in high stakes situations
by building these--
MICKEY MCMANUS: Well, in some
of these decision systems,
the idea is that
there's a little bit
of an automated
system that goes,
oh, by the way, the last
five times people looked
at stack probability,
they got them wrong
because humans are terrible
at stack probability.
Here's what we really think
it will be based on fact.
And playing back and
forth that way I think
is a powerful way
to kind of help us
see the thinking
about our thinking.
DAN RUSSELL: Sherman, you get
the honor of the last question,
as long as it's
relatively short.
AUDIENCE: First, I
apologize that I was late.
So I might be asking something
that was already covered.
It seems to me that there's
little needed to be debated,
that AI is the future and
is what we need to embrace,
we need to do.
There's no doubt about that.
But it seems to be the
challenge to AI is really
what shape, form of this uncanny
valley would bring-- what cost
and what benefit,
and how do we manage?
I really love the
notion of hand-off,
like in the sense of improv.
And you can see real
products designed,
like Siri, that's already
trying to be playful
and trying to give
turns to humans.
But these are also very hard
because those are hard skills,
even for humans to develop.
And then let's say in the
case of self-driving car,
you don't want the
car to hand you
when it's really in trouble
because you're prepared.
And even to understand the
situation being handed off
may maybe actually
much more difficult
than you start from scratch.
So this combination, before AI
becomes perfect or complete,
if ever be, that really is the
challenge, how you manage that
and design that process
to have the benefit
outweigh the costs for
the entire process.
That seems to be
more of the question.
I don't know.
Maybe you already covered this.
DAN RUSSELL: So my summary
for the video folks
is, how do we design intelligent
or smart or effective hand-offs
without going through the
uncanny valley where everything
is really weird because
it's really high quality
simulation but not good enough?
So how do you design
for good hand-offs?
DON NORMAN: First
of all, Sherman,
you had the wrong question.
We weren't debating
whether AI mattered.
We were debating
whether people mattered,
whether AI would become
so perfect that we
didn't need people anymore.
That was the issue.
Now, I feel that there are
certain things that people are
doing that we're not good at.
We're forced to do it.
It's actually the
machine world that
has forced us to
behave like machines.
And we're not good
at being machines.
Look, 75% of all accidents
are blamed on people.
And I say no.
It's because people are
being asked to do things
that people are bad at.
And then when we're
bad at, we're blamed.
Yuck.
So driving is not
something we're good at.
I know you all think you're
above average drivers,
and I know you love driving.
But you don't love driving
in crowded streets, do you?
101 at rush hour.
And on top of that,
it's really a skill
that requires quick
responses occasionally-- once
every 100 million
miles or something.
And so here's how we
can handle the hand-off.
We won't.
When something goes wrong with
the automated car, we die.
That's what happens
with an airplane when
something goes wrong.
You die.
The pilots do their best,
but occasionally, we die.
But I repeat, 35,000 people a
year die in the United States
alone, a million in the world.
And so if we cut that
way, way, way down,
there will still be deaths.
There's not going to be
ever a perfect system.
But it would be
way, way reduced.
So I don't think the
hand-off is possible.
But it would still be a
benefit to society nonetheless.
MICKEY MCMANUS: Oh man.
I wanted to answer
your question.
I love this uncanny
valley metaphor
from the computer
graphics thing.
DON NORMAN: The uncanny
valley is a myth.
It was made up by a Japanese
roboticist with no data
whatsoever.
And no one's ever
been able to get
any data that substantiates it.
MICKEY MCMANUS:
Oh, wait a second.
Just watch the movie &quot;Beowulf.&quot;
And you notice that those things
are not even good cartoons.
It's Kenneth Branagh
looking off over there.
No, I mean the uncanny valley
metaphor, just this notion
of computer animation.
But I just like it as a question
because it forces you to say,
what happens when
they haven't gotten
to the point where we don't
know the difference maybe?
But Don said you're going to
die in a self-driving car.
And I totally think that's true.
I'm really
interested-- I'm going
to agree with them on that.
DON NORMAN: Not that
you are going to die.
MICKEY MCMANUS: Yeah.
You are going to-- I'm sorry.
DON NORMAN: People will die.
MICKEY MCMANUS: We've
selected you today.
But actually, it's
the selection.
It's the selection that I
think is kind of interesting
because some designer,
some lawyer, some engineer,
some insurance company
had to do what Spock maybe
I think is the only person
who's ever been able to do.
If you ever watch
any &quot;Star Trek.&quot;
Anybody watch &quot;Star Trek?&quot;
There's always that
needs of the few
versus the needs of the
many, the needs of the one.
And he's always the one who
has to try to figure that out.
But if you're driving
down the road,
it's a self-driving car, and a
school bus full of children--
you're like me.
You're 51 years old.
DON NORMAN: Not the Philosophy
101 question, please no.
MICKEY MCMANUS: Yeah.
But a school bus
pulls in front of you,
are you the one who dies?
I mean, I've got a
pretty good life.
I think it's OK.
That's fine.
Or is the school bus--
is it OK for the car
to take you off the cliff?
And I'm not saying all the
great philosophy stuff there.
I'm just saying someone
is choosing that.
Are you the designer that
chooses where that slider is?
Who is the designer?
Is it the user?
Because probably,
along some dimensions,
it's Philosophy 101.
DON NORMAN: I know the answer
to that question, though.
It's going to be
decided by lawyers.
And I'm serious.
MICKEY MCMANUS: I just read
that AIs are replacing lawyers.
DON NORMAN: Well,
it doesn't matter.
MICKEY MCMANUS: So it's going
to be machines all the way down.
DON NORMAN: It could be an
AI lawyer, but it's a lawyer.
Because look.
If you are in an accident
and you get hit from behind,
it's not your fault, even though
it may have been your fault.
You may have done something
stupid, which caused
the car behind you to hit you.
But the law has
decided, by definition,
if you're hit from behind,
it's that person's fault.
And that's what's going
to happen in this case
because this is too
complex to be left
to the whim of the
individual engineers
or each individual car company.
It will be regulated.
Maybe it is a combination
of lawyers and legislators
who will decide.
MICKEY MCMANUS: I would
agree with that too.
DAN RUSSELL: Wait, wait.
I'm going to suggest that we
move this discussion to lunch
because we're
running out of time.
And I still want our speakers
to give their two minute
summaries.
It is an excellent question.
MICKEY MCMANUS: Oh my gosh.
DON NORMAN: I can go
first if you want.
DAN RUSSELL: But
can you, gentlemen,
summarize in two minutes
what's come out of this today?
MICKEY MCMANUS: I'm going
to start actually, Don,
because I'll let you
have the last word.
It's always just more fun to
listen to where you come from,
because I'm not worthy.
So I think on the
debate side, I won
the coin toss to defend
humans, as designers,
will become irrelevant.
And it will precipitate
out of all the sensing
and all the machine
learning and all the stuff.
It will probably
be better for us
because they'll protect
us from ourselves.
You know, I worry about
that because there's always
that stuff you worry about.
I worry about Bernard
Avishay, who was
the editor of HBR for a while.
He said it wasn't that he didn't
expect the machines to someday
meet us.
It was that we would actually
go meet them halfway.
I really worry about us getting
dumbed down, or amplifying
or lesser selves,
instead of striving
to amplify a better self.
And so while I think it
might happen because we just
don't know what we're
doing sometimes,
and we're muddling through
as humans, I think,
I hope it doesn't happen.
In 2008, there
was a flash crash.
Anybody hear about the
flash crash on Wall Street?
Does anybody remember
what that actually was?
Do you remember what that
was, like what happened?
AUDIENCE: I don't think
I understood [INAUDIBLE].
AUDIENCE: A trader had
put in a low amount.
And the computer basically
saw that low amount
and kept trading down
and down and down until--
MICKEY MICMACS: Yeah.
It was actually a social
network of algorithms
fighting against each other.
So they basically, in
about three seconds,
took a third of the
value off the entire Dow
before it was shut off.
And so that's the thing that
maybe worries me the most
is that when I go
to sleep tonight,
I feel pretty confident.
And then around three seconds
into 3 o'clock in the morning,
there's a battle between AIs.
And it was set from one
bad set point over there.
And we lose an awful
lot of value in society.
And we unset some
norms that we've spent
a long time trying to build.
Or we basically believe now that
this is as good as it can be.
And I think it's more about
the lost opportunities
that I'm excited about.
So if I were to really
tell you what I think,
I'm looking at what happens
if we could-- like all tools,
like all things-- if we could
make ourselves super powered.
If we can do things
we couldn't do
before in amplifying
and helping our better
selves, a more interesting
world, a more rich
and lively world for
a lot more people.
So that sounds very platonic
or whatever-- you know,
platitudes-- but I've
seen a designer who
spent 30 years designing
products and doing things
and was amazing.
And I've seen him play
with these systems and go,
that's it.
My job's over.
I've got no life.
He's from Bristol.
And then I've seen him play
with it a little bit and say,
I can't believe it.
I can't go back.
I don't ever want to go back.
And now his whole brain is
on fire and he is loving it.
But it took this kind of--
almost the most skeptical
person in the room to really
push and prod and find
their own way.
And I'd like to see
that happen more.
I'd like to see everyone
here just engage more
get into the flow instead
of standing on the outskirts
and think about these questions.
I think the reason
we even wanted
to have this debate
or this discussion
is we believe that this is a
really important thing for all
of us.
And I think designers
have a role to play.
So that's where
I'm going to end.

DON NORMAN: It's
hard to summarize.
In part, it's hard to
summarize because we
were told the rules
of improv, which
was you have to give a
hand-off for the other person
so they can build
on what you've said.
That's not the rule
of a good debater.
The rule of a good
debater is I want
to leave you hanging with
no response and no ability
to build on what I've
said, but dumbfounded.
So the very notion
of a debate is just
the opposite of building.
But I don't know what I believe
because I can argue both sides.
That's why we were
able to flip a coin
and decide which side
we were going to take.
It's a really complex issue.
Now, as a cognitive
scientist, I like
to believe that we
can come to understand
the human, the brain, the mind,
the body, and put it together.
And therefore, that
kind of belief means,
yeah, we could build
a machine someday
that will be superior to people.
I don't know when
that someday might be.
So let me tell you where
the hardest problem is.
And this is well-known to
people at AI, by the way.
The stuff that
people consider hard
is where everybody said
that's the challenge.
Chess is hard.
Go is hard.
Solving mathematics is
hard, et cetera, et cetera.
Well, gee.
Machines have solved all those.
The stuff that people
find is-- well, look.
Here's my standard story.
I spent hours shooting
the basketball
to try to figure out how to make
it get through the hoop, right?
A machine, it just does it.
No matter what angle, it
does it, always there.
I don't spend any time
trying to see the hoop.
The machine actually has
great trouble seeing it.
So the things that we
find easy and trivial
turn out to be really hard.
Anything physical is really
hard for the machine.
Perception is hard.
Manipulation is hard.
Picking up an egg is hard.
The same hand that can
turn a mechanical nut
and screw it in it
with great force
can also pick up an egg
without breaking it,
and also can break the
egg and scramble it,
and do those dexterous things.
That's hard for machines.
A lot of our knowledge
comes from interacting
with the world, the real world.
And if we don't
know how to do any
of that, what are the
implications of what I've just
said?
I don't know.
That's why it's actually an
interesting debate because we
really don't know the answer.
This is a really
interesting place in time
because the machine power
has gotten so great.
By the way, deep learning,
which is very powerful and doing
all sorts of things we
never imagined, it's
a really elementary system.
Actually, part of that
was invented in the office
next to mine at UC San Diego.
David Rumelhart and our
post-doc, Geoff Hinton,
put together the basic
modern neural network.
It was the old perceptrons, but
with a hidden, special middle
layer.
And Geoff, who is
brilliant, and actually
now works here at Google,
I asked him the other day.
I said, this deep
learning is brilliant.
And we've done things
we never dreamed of.
So what were the major
knowledge advances that
allowed that to be possible?
And he said nothing.
There is nothing in there
that we didn't know earlier.
It's just that the machines
weren't powerful enough.
AUDIENCE: I was there
and that wasn't true.
He said 2%.
DON NORMAN: Oh, that's right.
Thank you.
He said 98% is the stuff, and
we have 2% of new knowledge.
And it's because the machines
have gotten so powerful,
they can now have 1,000
hidden layers, not just one.
And that gives me pause,
because it's really interesting
that even our limited
knowledge, when
faced with this modern,
massive computational ability,
does things we never
would have dreamed of.
So I don't know where I stand.
And that's why we decided,
actually, to have this debate.
Because actually, it was
interesting listening
to the opposite arguments.
It caused me to think
better and deeper.
And actually, the
improv statement
was really very valuable.
That was an outlier.
But it was a good
way of stating what
I hope we can
actually manage to do,
which is a kind of
hand-off and collaboration.

DAN RUSSELL: All right.
Join me in thanking
our speakers for today.
Thank you, Mickey.
Thank you, Don.
[APPLAUSE]
[MUSIC PLAYING]
</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>