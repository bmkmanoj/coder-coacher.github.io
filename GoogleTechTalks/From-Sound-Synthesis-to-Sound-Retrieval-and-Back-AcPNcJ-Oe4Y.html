<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From Sound Synthesis to Sound Retrieval and Back | Coder Coacher - Coaching Coders</title><meta content="From Sound Synthesis to Sound Retrieval and Back - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From Sound Synthesis to Sound Retrieval and Back</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AcPNcJ-Oe4Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today we're very happy to have visiting
from barcelona dr javaid Sarah who's the
director of the music technology group
at the pump poo Fabra University in
Barcelona and he's also a native of
Barcelona and he comes out every summer
teaches some computer music and sound
processing at at Stanford taking away
with happy honey thank you okay so thank
you very much and it's a pleasure to be
here and what I will talk about today if
it's not clear enough from the title is
the idea of sound synthesis and some of
the techniques that historically in the
field of computer music we have been
using and developing and basically the
idea that how out of that a lot of the
sound retrieval work and music
information retrieval work sort of
developed and then in fact out of that
how in sound synthesis we benefit again
and how nowadays a lot of the sound
retrieval techniques and music
information retrieval techniques are
being used creatively in some synthesis
but basically the excuse of all this
talk is to also present one one side one
side that we have been developing for a
couple of years now which is the free
sound website which is a project of its
a database of sounds for under Creative
Commons license that are used for
research and creative applications and
basically that site and that project is
a unified a little bit this idea of how
nowadays large databases like free sound
can be of very interesting can be of a
lot of use to both the creative people
the musicians the the people that want
to play around with sounds and recording
people and also the research
is doing work in sound retrieval and
music information retrieval okay so so
the idea is that I will go first i will
present a lil bit the group i am in so
that you see a little bit the context
why we are interested in these things
and what kind of thing we are we are
doing then i will go sort of a livid
back historically sort of two three
techniques that are have been used for
some some years now some very storica
land some more actual like music
concrete granular synthesis and sampling
and then the work on on sound modeling
on spectral processing that basically
has allowed to take to take a step
further all the work on sound processing
and and the work on some synthesis and
then basically how out of all that we
have all these work on sound retrieval
and what is the state of the art what
are the things that they're being worked
on now and that there are of interested
are of interest and then sort of taking
advantage of all this work the the new
sound synthesis paradigms and especially
I will talk about to DD of no psyching
in sound synthesis and the idea of
concatenate syntheses how it takes
advantage of all that and it has taken
sort of the work of sound producing into
new very interesting areas and finally
sort of i will present the free sound
project which is a very needed platform
and environment in fact to make some of
these possible because that's one of the
major problems or major roadblocks both
creatively and research is to have
access to large databases of sound well
label that can be used freely and
without all the restrictions the legal
restrictions and nowadays especially
music and sounds are very strong much
stronger than in many other of the
content areas and i will give you some
conclusion
so okay so in the in the music
technology group but the Pompeu Fabra
University in Barcelona we are basically
working a lot on audio and from the
sound and doing applications and
technologies based on that and hear some
of the lines that we have been worrying
about lately the the main one and
originally and the one that I started
with I did my PhD here at Stanford and
then I went back and my PhD was on a
spectral processing and spectral based
modeling and synthesis so I started the
group basically on the on the tradition
of audio processing and how to use
spectral analysis for analysis and
synthesis then out of that came the work
on music description and understanding
and these this is a sound retrieval
music information retrieval area and how
to extract automatically meet the data
from the signal from sound signals and
music signals also we have a group that
is that is developing interactive music
systems and we have recently developed
an instrument that has become quite
popular which is the reactable will just
briefly mention it and then we have been
doing more basic research areas in music
admission and computer models for music
ignition on performance music
performance understanding and modeling
performance so i will just very briefly
just mention three topics or three
projects that we have been doing so that
you can get an idea of the kind of
things we did one of the first projects
i got involved when i went back to to
barcelona and it was together with the
with yamaha we have been collaborating
with yama for for quite a while now in
fact i work for yamaha for also for a
while doing research and we develop
these karaoke days impersonation system
in which in real time using and you can
sort of modify your own voice to a
target voice or to the voice of some
professional singer
so that it's based on a spectral
processing and is basically the idea of
morphing in the sound domain and that
has was quite successful then sort of a
continuation of that we develop
basically the first singing voice
synthesizer that exists which now
commercially is called Vocaloid that is
also it was a project in collaboration
with Yamaha that we develop we call it
the daisy project in honor of the first
singing synthesizer that ever the first
song that was produced by a computer at
Bell Labs in the in the 50s so this is
just a synthesizer which is the first
one that can handle sort of singing boys
until now all the synthesizers have been
basically instrumental sounds so you
type in the melody the lyrics and and
then you can hear I will later I will
just play one example in the area of
content processing sort of going towards
the sound retrieval aspect and coming
from all these audio analyses we have
been working a lot on the idea of
extracting features and descriptors
higher and higher up in the sort of
semantic layer so we started from these
sort of extracting the low-level
descriptors of a signal sinusoid the
harmonics the residual the Foreman's
sort of signal based scriptures and we
have been going higher up and now we are
working about things identifying the
harmony the ribbon identifying the
structure of the piece of music
identifying different identifying the
instruments so for example this is a
just a video of some work that is
identifies the the court so you see the
signal on top and and underneath the red
is the sort of proposed court
one strand of good
the probability of wonderful stares at
the other so we share morning
sexual analysis based techniques get
this top of it
matches this is
when the mission
I was taking
so having this type of signal level
techniques you can of course start
developing some interesting application
and quite a number of companies and
research labs doing this type of thing
that has been evolving a lot lately so
we are also developing sort of music
recommendation systems sound surge sound
retrieval systems so that based on these
descriptors you can look for songs that
have the same harmonic structure or
songs that may have the same rhythm so
you can then recommend or organize or
navigate through a collection of music
with this type of tools okay so that's a
sort of the retrieval aspect and then
just finally to put another example we
have been developing some interfaces
tangible interfaces and lately the the
one that we are concentrating on is
called the reactable and it in the last
few months has been quite on the media
because Bjork is using it in on her tour
that in fact started here a couple of
months ago on the volta tour and there
is a lot of interest for musicians to
use this type of tools so it is a tool
that recognizes objects recognized
out of that many did you reach out
I need gives you some visual feedback
and that's one of the things that people
are attracted to because you get some
sort of visual representation of the
sound that is being generated
so that's a table but these regular
table height of course apart from music
applications it has it's not that
different from the surface of Microsoft
and in terms of the technology is much
cheaper but we have we're interested in
the musical instrument application so it
has all kinds of objects that you can do
all kinds of musical things anyway so
that gives you an idea of the kinds of
things we do and where we come from so
now if we concentrate on the topic of
the talk which is we start with sound
synthesis we start from the 40s and 50s
and one of the first sort of work that
was done in sort of this electronic
media first analog and then it evolved
into the digital world was music
concrete and the inventor was Pierre
ship here and the idea was to from
actual recordings and first was in LPS
and then it was with analog tape and by
cutting splicing and doing some
processing you were able to make a piece
of music from existing material and that
term musical credit comes from from that
so for example this is a piece from 48
so in fact is even I think this was done
with LPS and with a very very crude
technology putting together a piece of
music out of train sounds
can we the sound is not loud enough
on some of the idea behind this type of
work is to start from existing material
take it out of context and put it into a
creative context that changes the
meaning brings new meaning for the this
material so this tradition of the
concrete has been basically continuing
for four years started in Paris and he
has a balls for many years okay so
that's when the computers came into into
use and one of the two take the music
concrete into the digital world of
course the major advantage was the
accuracy and of being able to cut splice
and combine and algorithmically combine
these pieces of sound so most granular
synthesis is this idea of starting again
from grains in this case we could go
down to smaller grains and put together
new material out of existing material
and I would say that this is one of the
major sort of kind of idiomatic and sort
of music sound making techniques that
defer from the tradition of of
traditional instruments there is a it's
impossible to think of traditional
interfaces and traditional musical
instruments to control this type of
thinking so for example well this just
this is a piece of music from an
American composer
so these are just tiny grains
algorithmically sort of put together and
basically there is not much
transformation the grains are left as
they are there is some children may be
there is a little bit of teaching
so this has been very much in the
tradition of computer music and electro
acoustic music that's very much at the
core of a lot of the music that happen
in the commercial world this idea became
the sampling and so the first sampler
was fairlight from 1980 and that was the
first sort of instrument basically
targeting to the commercial world they
are expensive at that time that of
course also target the more than art
music type world and the idea is that
with the right control with the right
software by adding sequencing by adding
some transformations like like sampling
rate conversion and some some filtering
you can sort of record samples from an
instrument record samples from anything
and then make sort of music out of it
with a keyboard so for example there is
some of the samples original from the
Fairlight that have become quite then
used later on
so these started from a single voice
sample of course these were talking 8
beats we are talking something raid then
maybe was 11 k something rate so that
the quality there is quantization all
over but some of these sounds have
become quite quite used later on and for
example of course you can just record a
dark sound and then just map it into the
keyboard so anyway so that's sort of the
commercial version of all that okay so
so that's that's that for sort of the
syntheses base on existing material the
idea of a spectral processing and sound
processing in general sort of focus on
how can we process these sounds more
than just by cutting and splicing how
can we change the sound in a more
flexible way so the spectral processing
idea is that you start from an original
sound using spectral analysis then you
extract some features the features that
you want to process or identify or
characterize like in this case the peach
of the or the frequency of the sound
then you apply the transformations and
then you do the inverse you do the
inverse Fourier transform or whatever
transform you're using to go back to the
original sound that gives you much more
power over the control and the
transformation of the sound we are not
talking about time domain all what I
have been talking until now is time
domain frequency domain with these
feature analyses and the techniques that
in the past 15-20 years have been
developed has really taken sound to a
much more powerful sort of flexible
material that can be used so for example
this is from one sound like this this is
just a tiny blow of a flute in fact this
was a student in my class at Stanford
like 10 or 15 years ago the first day of
class I gave them this sound and I told
them okay make some transformations out
of that without even understanding the
signal processing behind it so out of
that
he came up with this so now this sound
has we can very easily change it
completely and drastically in too many
different ways so the potential to
combine these with that I was just
mentioning is incredible so this is just
a representation of the sort of some of
the data that is behind the harmonics
the residual and some of the
transformations that you can do from
these spectral data so out of that then
a lot of the of the music information
retrieval work came about music
information retrieval of course didn't
aim to make sounds to the synthesis
aspect it won't it just stayed with the
idea what can we do with the sound
analysis that can can be able to
describe it so these are very
complicated diagram that I i I'm not
going to go through but at least I want
to show you some of these things of
course in music information retrieval we
are not just interesting sound we're
interested in scores in editorial data
in any kind of data that relates with
music and so here at the bottom you have
this information that is attached to the
physical objects that music is the like
the CD or like or the record or whatever
then you have all these out of these the
digital information that you can extract
the text the lyrics the sound digital
sound data and then out of that that's
what you have and that's what you
normally in libraries in digital
archives what you have access to one out
of that you try to to make the best of
it to search to do recommendations so in
the music information retrieval the idea
has has been to go up the semantic
ladder so obtained symbolic semantic
information automatically from these the
information you have at hand so by doing
signal processing you're able to go to
these low-level features like the big
the ratio
temper intensity whatever you can go
higher up and go to these more musical
context like the one I just mention
about the harmonies so you can identify
the chords segments a piece of music
identified the freedom and then
hopefully and this is basically state of
the art right now reaches this level but
ideally you want to go higher and
identify more musically meaningful
descriptors and what type what type of
music it is what key what to identify
the melody within a variable phonic
piece of music etc etc and even ideally
you want to go to more cognitive aspects
and and breach this semantic gap in some
way or another so in fact the semantic
gap of course is one of the heart and
sort of the challenges that in an audio
so these sort of represents the sort of
the the music plane in which apart from
audio you have text you have image so
all the information that surrounds music
and these different levels of
abstraction the signal features that
sort of can be extracted automatically
content object features or mid-level
features that are starting to be
extracted automatically and of course
these more human knowledge which in
music I believe we are a little bit more
ahead than with other content areas in
which we are starting to be able to to
to bridge a little bit disseminated gap
until now most of the techniques that
have been using our sort of signal
processing of course that was original
sort of methodology approach then with
the statistical modeling machine
learning the music theory models and web
mining we have been able in the last few
years many projects are pushing that and
the next wave is to go higher up and
incorporating computational neuroscience
models to try to go at higher music
commission competition musicology text
understanding reason
rules anthologies multimodal processing
combining image text and music in a more
unified way so that's sort of what the
current research is aiming at and is
trying to push and I believe that in
some very narrow areas we are really
crossing the semantic gap in music
especially so we are getting to be able
to have these these applications that
are starting to be very interesting so
anyway so that's the sound retrieval
work and what is being worked on so now
combining that plus oh no I just like
this slide out this is about sound
retrieval in sound effects and sound the
music information retrieval hasn't
focused so much on sounds in general
they have been focused mainly on on
music sound is a completely specific
world very complex in which again you
have very different areas of description
representation of the sound you have the
perceptual world you have the sort of
the source the real world origin of the
sounds you have all these recordings and
this post production and format tools
and of course ideally you would like out
of the data that you have to be able to
generate as much of the all these data
possible to do some search retrieval
processing generation music making etc
so given that in synthesis now we are in
synthesis too so we are sort of now we
have all these techniques in sound
synthesis sound processing techniques in
in in information retrieval what can we
do so and of course this is before all
this work but I use these these
reference because i think it triggers
quite a bit of the issues that are now
not technologically but also in socially
legally are coming up
because of these new technologies
because of the potential that we
currently have you might know Joe knows
whoa he has been know basically making
music out of existing music but not just
samples not just snippets of a piece of
sound like in sampling like in music
concrete like in granular synthesis by
the existing music material cutting out
splicing it and making new piece of
music as you can imagine one of the main
road blocks was the legal aspect so he
hasn't been able to release any of his
music legally and it's on the web and
you can find it and it's it's nice I
mean if you like this type of music so
this is based on Michael Jackson
so of course this is very much at the
core of all the DJing and DJ music
making and nowadays that's a very big
part of our music provision and music
making in the world the idea of starting
from existing material manipulating it
and making new one so that has of course
from the socially and has triggered a
lot of debate and interesting things and
so the idea of really in the history of
music that has never happened before
people were able to borrow without any
problem and there has been a long
tradition of music built on existing
music now with all these record
companies and behind it's very difficult
to do that but but again creatively and
that's what people are doing now and
that's why in fact I think that's that's
having some strong consequences in the
other creative world are not being able
to to promote certain kind of creative
thinking and creative process so in now
in this field of in the computer music
sound digital music world one of the
inspiring ideas were from mo psyching
that the image have been done for some
years now the idea of starting from an
existing picture and filling it with
tiny pictures that match certain parts
of the image so you recreate the image
by mo psyching by a personal type of
thing what does it mean in in music so
there has been some work on that and the
idea is that well there are several
approaches you can do exactly what we
just saw so you have a piece of music
either score or an audio so that would
be sort of on that side so you start
from a symbolic score
or from an existing piece of music and
you analyze it and that's your target
and then you have pieces of sounds other
piece of music samples whatever that the
source sound you store in a database and
that can be as large as you want and
then basically what you do is a matching
you you do a unit selection of this
database based on the target information
and then out of that you put it together
and of course as part of these there is
all these transformations that are being
used more sophisticated than in the
previous times we had for granular
synthesis or sampling so here we are now
able to do more interesting things in
this example is not so much the
transformation this is from a thesis
from the media lab from MIT by Tristan
yahan and that's this it's a piece of
music that started from an audio score
and then slowly as you will hear it
keeps replacing elements with others
automatically
Oh
and maintaining sort of the temple the
bead and some of the structure of this
okay so that's the idea of most hiking
another type of concept in this
synthesis tool is what is we can call it
concatenate synthesis in fact cause in
speech that's a common technique and the
term is also used like that concatenate
synthesis and the idea is again start
from large databases of spoken words
large databases of music material or of
recorded sound from an existing
instruments and then put it together but
now with these tools that we have of
sound retrieval of spectral processing
we can do a much better work
concatenating and transforming to make
it smoother all these transitions so for
example this is an example of that they
will show later of the singing voice
that we have developed that went into
Vocaloid and the idea is that you start
from two samples of voice and of course
in the voice is very clear that just by
splicing the two it won't sound any good
or even cross fading there is no way
that we can get a sort of singing voice
a smooth transition by just
concatenating like that in speech is
easier still not ideal but the speech
there is not so much pitch variation or
tamper variation between the sound so so
you can sort of fake it by concatenating
in a very crude way in singing voice
that's clearly not the case so you need
to worry about tambor evolution I'm not
going to explain these but basically you
do all these spectral analyses in one
side spectral analysis and the other
side features
selection feature analyses and then you
are trying to interpolate whatever
parameters are needed to make a smooth
transition and also of course in in in
singing voice it's impossible to record
every possible luan so you have to
transform all these recorded material to
make it appropriate for whatever context
you are and even just something that may
not sound too important like the phase
of the signal has to be match and that's
not an obvious thing to do to worry
about so that you can supply so that you
smoothly make a transition so well let
me just first play you so this is the
singing voice vocaloid sake
mozzarella Louie
what I day
00
your knee gee honey
Oh looky our buddy
who know i gotchu
of course it's not perfect but
definitely is much better than anything
that existed before and it's smooth I
mean it's it's it's sort of holes there
is sometimes you hear some tember that
is not sound that natural but it works
so what is the problem what is the issue
so basically well with this diagram it
explains a live with the problem the big
circle the a circle is basically all
sounds that a given instrument the voice
person can produce of course in a
musical context you don't use all the
sounds that you can produce you use a
subset so that's the circle be you sort
of the sounds that you are interested to
in reproducing in a specific context to
make music but your recordings the kind
of things you can sample it's impossible
to sample everything and on top of that
we are talking about time varying
material very things that evolves so
what you're going to record is these
Wiggles these trajectories within this
space either being melodies evening
phrases either being spoken phrases
whatever and that's what you have that's
what you're sampling that your database
that the kind of things that you have
access to and of course the idea of
making music or creating some new sounds
out of that means to be able to draw any
trajectory within this space so in a
synthesizer context like in the Vocaloid
you start from a score a performance
score then you have some model of
performances that you can add some sort
of vibrato some offsetting of some of
the timing some small transformations
that a performer does to the existing
notated score and of course you look
also that is under under your database
there is some information about
performance aspects and then out of that
you sort of generate the trajectories
that you are interested in obtaining the
trajectories within that space like this
one that you want to be able to generate
okay so you're proposing a trajectory
within that sonica space and then the
sound rendering by and of course in here
what you need is search on these
database for the best samples you need
to I do spectral processing to to
transform them you need to do the select
which ones and how to concatenate them
the sample so then you have the sound
rendering and therefore you have the
sound output okay so the sound you heard
is basically based on this idea this
could be called sort of performance
sampling or some kind of thing like that
so that's more for again like like
before I talk about granular synthesis
for more the art tradition and the
contemporary music time of tradition and
then the sampling became more the
commercial thing now most hiking is sort
of more the artistic type of tradition
very free without any boundaries and
this type of competitive synthesis is
more sort of for more commercial type of
application so that you can make music
with with this existing material okay so
that's basically in terms of synthesis
retrieval synthesis and then a very
important needed tool for making all
that possible is to have access to
databases and databases especially for
normal users that that they are free and
that they can access to so we started
this free sound project this free sound
project started as part of the
international computer music conference
that we organized in Barcelona a couple
of years ago and so that was the excuse
to to promote this idea and originally
the idea was just to just put it online
and ask people to contribute with their
sounds sounds that they made sound that
they recorded so that they they own it
so that they could be put under Creative
Commons I'm so that other people could
share
and in these two years he has evolved
very much and it has gone beyond our
expectations and basically has become a
social network of some kind is a network
of freaks of sound much wider than we
ever expected we thought that we would
be sort of targeting the
electro-acoustic music the computer
music type of crazy guys and and sort of
the mir music information retrieval guys
so that they would need some of that and
it definitely has gone beyond that and
there is well many people downloading
ringtones that's obvious but also from
all kinds of applications some recording
people and has gone also to Hollywood
and there has been some of the some
movies from Hollywood using them and so
there is a lot of good feedback and a
lot of usage in different ways and of
course we definitely want to mean it has
gone beyond our sort of small resources
so we are trying to rethink a little bit
the whole thing and make it really a
much more powerful tool so basically
some of the numbers that it was created
in 2005 in April right now there is
35,000 sound bites of different lens we
have some sort of filtering manual
filtering so that so that the sounds
that go in there they are not from some
preparatory or some records or something
like that so we don't aim at music we
aim at sound material some are small
music excerpts that can be used to make
something out of that or can be used for
research purposes so so out of these
35,000 well there's all kinds of things
basically we could say there's two big
communities one that they did not expect
to grow that much one is the sound
environment and soundscape type people
people that go around when they travel
with a mic and with a with a small
handheld recording system and they they
keep recording everything and that's
amazing there is all these people and
because of free sound some people some
people have been gotten into into that
so when they travel apart from their
camera they take their some recording
they record things from all over and
then they put it in the free zone the
interesting thing is that there is a 370
something thousand registered users and
the interesting thing is that the the
growth of users is enormous is really
growing exponentially but the grow of
sounds is linear it has an in the last
two years he has steadily growing into
this straight line but the access and
the user and the downloads of it is is
growing exponentially in some countries
and Spain is one of them people are very
much use internet to to get stuff but
they're not so much into the the idea of
participating and blogging and doing
collaborative work so we have to change
that somehow and we are interested in
exploring some some new things so that
people there's so many people out there
with sounds and especially positions
that they could contribute them but they
are not contributing as much as we would
have liked so there is 15,000 visitors
per day but most of them are just simply
getting sounds using them and having fun
navigating through the database which is
another interesting thing people are not
just they're accessing the sounds and
using somewhere but they are just having
fun navigating playing around with them
even just they just click different play
buttons and they have it all the time on
so that they can have some sonic
environment constantly changing and
there is so there is a stable sort of
community of people with the day Chad
they do things and there is a lot of
people requesting for a sound and people
recording the sound and putting it back
etc etc so some of the main features is
again the Creative Commons license we
are still we started with Creative
Commons sampling plus and now
we're thinking whether to open it a
little more and explore other licenses
so that people are freer to choose what
license they want there is some social
network features like the forums and the
chats and the sort of the profiles of
people etcetera but it could be could be
much more and people are really asking
for much more and that can help build a
better community the the tagging the
false wanna meet Oksana me tagging that
has worked very well so people put tags
and you can visualize the bags and the
weights and in quite different ways
since we are working on the sound
retrievals stuff and sort of surge by
similarity based on tambor and rhythm
and things like this there is a
functionality which has been disabled
for a while and now it's back in and we
are sort of promoting it again which you
can search once you have these large
databases the tax and especially in
sounds sometimes they don't mean that
much especially when you are in sound
post-production activities some sounds
that can have the origin completely
different might be appropriate for a
given application so you can you can
search organize things by similarity of
the audio signal and that gives you some
nice organization of the of the audit
opt out of the sound geo tax that's a
nice feature and that's that that so
that's because of all these soundscape
and people recording things all over the
world has been being used quite a bit
and there is a quite a few thousand
sounds geo tags and you can navigate
through with the geomap or the google
earth through them and of course our
interest is to really support these
communities and especially this creative
community and music research community
and that has been going quite well in
terms of research there is many places
that are being used these sounds for
setting up test benches and comparing
can
and we want to promote that we need to
add a few more api's and things like
these so that people can can take more
advantage of searching certain sound and
the creative community that's something
there have been so many people coming up
with records and DJ's doing things with
these sounds and doing installations are
all kinds of things so that's that's
going quite well so so what do we want
to out of these free sound and sort of
related with all these well basically
just mentioned some of that well this is
just as sort of a little joke they just
last year they just open a
supercomputing center in a in a church
in Barcelona it's too bad for the church
because it was very nice but anyway and
honey they offer asked to use it but we
still don't have enough sounds and
enough things to be able to take
advantage of that so we would like to be
able to take advantage of we have a
small cluster that is sufficient for for
this database so ideally we would like
to take advantage of that in order to
take advantage of that we need to grow
the database quite a bit more so we
definitely need to increase this linear
we have to change this linear evolution
into exponential evolution and we have
some initiatives to sort of promote that
and the software of course we're
thinking of a small scale type of thing
so we need to the subways holding up
pretty well and there is some great
students improving it but we need to
definitely make sure that you can scale
up we have implemented would have been
implementing also mirroring and
different ways so that we have now two
servers to handle different things and
so that's that's going on right but we
have to rethink some of the core
software that is behind it and
definitely we need to add functionality
to to help people access in different
ways to sort of API is that then can
people use it and so for example some of
the Most High King work has been very
much using this free sound for the more
concatenate synthesis the sophisticated
the Vocaloid acting requires very
special
recording so that's more difficult but
for these communities as into djing more
psyching creative that that has been
going quite well so people can download
according to some criteria there are
sample packs there is a whole bunch of
tools to select set of sounds put it
into your instrument into your setup and
then making music out of that so so
anyway so that's basically what i wanted
to tell and then sort of as a conclusion
well I just sort of some idea as well of
course free sound we believe it's
becoming a great tool for the research
community and for the creation and the
mix of the two which I believe it's a
very fruitful combination and that's
very much relate to the second point
that we tend to see sort of sound
retrieval syntheses the creative
community together with the research
community quite separate in our field in
computer music they have been quite tied
together for 4 from the very beginning
and in these areas it's very nice to see
them that is maintained and the kind of
things i have been talking shows very
well the the need to to to exchange and
to cross feet most of these work because
i believe it's beneficial for both types
of activities and then again this idea
and free sound is an example that by
adding some interaction too many of
these sound listening tools or sound
sort of searching tools you are bridging
a very interesting the sort of the more
passive listening approach to the
creative active music making type of
approach we in the computer music field
basically when we started we basically
were targeting at professional musicians
those were the people that were using
these tools now has changed completely
and
we are targeting general users too so we
have tools that basically breach these
users standard users with musicians with
professionals and we are seeing all this
application this potential to be to have
music listening sound listening sound
interaction into something very creative
very fun people are using the login to
free sound not just to access a specific
sound to just have fun to interact and
22 the things anyway land just to finish
I have been involved in a as part of an
era pian project to sort of write a road
map of our feel of what are the
challenges for the future what is the
state of they are what is the context
industrial context and the social and
the research context so I believe it's a
nice document to sort of get an idea of
how what I just have been talking and
some other things fit into into the
overall picture of what we call the
sound of music computing feel the
research in sound of music computing and
how the current context the current
technologies are really reshaping a lot
of the goals and research directions
that are being established for all these
years anyway so that's all I wanted to
say so thank you very much and maybe
even some questions
yes maybe you can take this I guess is
that right down with another handbag
nothing you have to make that work no
right I was just wondering if you had
any book Lloyd samples in English just
so it could have better understanding of
like how that sounds the Beaufort
English yeah are the Vocaloid yeah if I
can play more yeah in English ok
japanese better let me just see if I
believe ok let me all right come on let
me see maybe I i don't know if i have a
recent ones but let's fly me to the moon
fly me to the who
let me like wow that's hard and let me
see what spring is like on Jupiter and
learn then learn words hold my hand
in other words darling kiss me fill my
life myth song and that meeting
forevermore
you are
lucky you see that problems out of it
okay thanks a lot are there any other
questions so well that goes reading
documentation on something called pure
data you may have heard of it what pure
later people like kind of like Max on
the space um and I came across someone
talking about how he didn't think that
we should be using samples anymore at
all we should be doing using synthesis
to create all of our sounds like in
video games and movies and stuff and so
what do you think about that do you
think it's feasible do you think it's
worth pursuing you think it's been
pursuing okay basically right now there
is two big sort of approaches to sound
synthesis one which is basically a very
synthesis approach based on physical
modeling of having models of the
instruments or the objects that have
been producing those sounds and sort of
this more sampling spectral based type
of approach sincerely by far believe
this approach has taken over and as this
pure synthesis except on art music very
experimental type of thing in terms of
commercial products they have completely
vanished I mean it's a nowadays sampling
release taking over and if you add all
these possibilities to to transform
sound I don't think there is a question
that synthesis pure synthesis it has a
very tough luck it's a it's really
difficult yeah
let's finish up but let's take one more
as far as performance in interaction
with the synthesizer that was the
reactable you would shown us earlier yes
I noticed that we didn't talk too much
about the sound generation used by that
particular device it sounded subtractive
it looked like you had a square wave and
a filter and the LFO yeah that was the
example it was a very simple synthesis
strategy and in fact both synthesis you
can mean the sound is a pv in fact
underneath there is pd and you can do
anything this pure data stuff we can put
anything you want like Bjork what she
does is puts all her drum loops and her
samples from recording and then
manipulates the recordings from the
device so these device was is not
particularly dozen is attached to any
synthesis strategy in particular it can
be used for anything so in fact we are
working on sort of djing type of
applications sampling type of
applications but the basic one is sound
synthesis that it has social eaters and
all the typical thing what's the sound
source
yesterday that was a real scientist but
he was PTSD software synthesizer that
it's a neat ideas for demonstration just
on oscillators and very simple filters
and things like that okay thanks again
hey thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>