<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Challenges in Causality | Coder Coacher - Coaching Coders</title><meta content="Challenges in Causality - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Challenges in Causality</b></h2><h5 class="post__date">2008-02-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eL7gO-rUlDY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so it's my pleasure to introduce you
Isabel griot isabel has been a very
early adopter of machine learning
research she's one of the co-inventors
of support vector machines which you
pretty all know about and she was in the
early glory years of AT&amp;amp;T Labs and
afterwards she decided to work they are
as a consultant and she's these days
working a lot in presenting challenges
to the research community to help
research in values machine learning
fields so today's she's going to talk
about one particular challenge about
causality thanks Isabel thank you very
much Sammy and thank you for your giving
this opportunity of talking here today
about these challenges in quiz ality
that we are organizing I think the
slides are going to show on this side so
maybe people might want to move on that
side to see better the slides
the title of my talk today challenges in
credulity reflects two types of
challenges one of them are the
competition's that we are organizing and
the other one the challenges that us
organizers are facing in trying to find
means of assessing causal discovery
algorithms which is far from a trivial
task my collaborators in this endeavor
are Constantine ala fairies on the ready
chef Gregory Cooper and Pierre spiritus
so what in the first place is cause of
discovery well what affects your health
the economy climate changes there are
some of the questions that are central
in today's world and also which actions
will have beneficial effects so as soon
as we're talking about actions in the
prediction setting we cannot ignore any
more causal relationships but what in
the first place is causality causality
has many different meanings depending on
the field that you're looking at for
example in science it is well admitted
that one event might cause another if it
occurs in at a time which is
sufficiently closed that information can
circulate and the limitation here is the
speed of light but even that is
currently being challenged in philosophy
causality might have to do with the
problem of free will so free will is
very hot in causality or matter
determining or actions or not in low
cause idea has to do with relay
responsibility in psychology maybe sub
consciousness in history which leader is
responsible for a particular turn in
story or you know would some other
leader have made a difference in
religion who is you know responsible for
the creation of the of the world or etc
we adopt in this presentation a more
engineering point of view of causality
that I will develop in the next few
slides and there is one of my favorite
definition of causality from Hindu
philosophy because is the effect
concealed effect is the cause revealed I
find this very poetic and interesting
however you know from the engineering
point of view we need to get down to
something more concrete that we can
evaluate in some way and you also get on
this slide and artistic rendering of
causality in science so now an
engineering point of view of causality
so at the risk of being reductionist
we're going down to something which is
more measurable in order to define this
notion of systemic causality we need to
assume that there are systems that can
be isolated from the rest of the world
and I made a small example to illustrate
that so imagine that you have a
one-year-old who is very fond of
televisions and cartoons and you would
like you know to have some control over
what your child is is watching so you
purchased a very fancy remote controller
and that remote controller works only
with very complex combinations of keys
so that you don't run a trace that your
one year old will turn up the TV by
chance now unfortunately the
manufacturer sent you the remote
controller without the manual so you're
here and you really don't know how this
thing works and you're in you know
desperate and put it on the table but
you're one year year old grabs it and
she starts playing with the remote
controller and eventually she figures it
out so you're like quite desperate
you're looking over her shoulder and she
won't let go of this system and the only
thing you can do is to watch what she's
doing and eventually you're the external
agent on that system when you're when
you're all
no falls asleep that's your chance now
to turn off your TV set have you been
able to learn from watching her which
button or which combinations of buttons
you need to press to turn off your TV
set without waking her up so that's the
setting in which we're thinking of
having a system which is in that case
the one-year-old and the remote
controller which has some dynamics of
its own which we don't know about which
we are able to observe and we want to
perform a particular action to have a
desired effect you want to predict what
will be the effect of this action before
we actually perform it so in quality
usually people think you know that it is
not possible to infer what causal
relationships exist before you do
yourself some experimentation so if you
know before you actually play with your
remote control you shouldn't be able to
know what's going to be the effect of
you know dialing your particular
combination of keys but in this setting
you're not allowed to perform the
experiments you can only observe the
system and then you need to predict what
will happen when you do something we
come from the feature selection
background which is common in machine
learning where you have a target of
interest which is called Y and this is
our outcome and you have many features
that we call X here and these are
predictive variables in feature
selection what you want to do is to find
a combination of predictive variables
that will allow you to predict as well
as possible the desired outcome why and
there are some you know economical
reasons for that usually it costs you to
measure those variables so this is a
motivation for selecting the smallest
possible number of variables to make
your predictions now if you are in this
machine learning setting you don't care
about whether your variables are causes
or consequences of your desired outcome
so for example in the medical domain
smoking might be a cause of lung cancer
and coughing might be a consequence
and both could be productive but only
acting on smoking might have you know an
effect on lung cancer distributing cough
medicine wouldn't really help so when we
get into this field of causation we are
interested in the results of actions
that are performed by external agents on
the system so we don't we no longer want
to just predict what will happen when we
let the system evolve according to its
own dynamics we want to predict what
will happen if we interfere with the
system by doing so called manipulations
by an external agent and in that setting
some of the features that would have
been predictive you know in the natural
prediction setting will no longer be
predictive so we need to understand
something of the inside of the system in
order to do a good job in this causation
where acquisition means using crude
allottee to predict action and in our
particular view of causation we are
interested in one particular outcome so
one particular variable Y that is what
we want to what we want to measure the
results on so for example we're
interested in measuring the benefits on
on health or on the economy and we have
one particular metric of interest is the
GNP going to grow or is you know the
mortality of the population going to be
improved so what's out there we have a
lot of available data continuously day
by day you know there are lots of
recordings that are being performed
around the world and data accumulates
them unfortunately those data are what
we call observational data they're just
being measured without doing any
intervention on the system of interest
them and the inconvenient here with
respect to determining causal
relationships is that there
no real distinction that can be made
between correlation and causality in
observational data in most of the cases
so for example you might be observing
that there is a correlation between
smoking and the incidence of lung cancer
however are you sure that smoking causes
lung cancer you will need to perform
actual experiments like forcing people
to smoke or forbidding them to smoke and
randomize all the other variables in
order to be sure that smoking is a cause
of lung cancer and that actually is an
argument that has been used during the
tobacco settlement the some lawyers put
forward the argument that well there
might be a common cause to both smoking
and getting lung cancer what about for
example a genetic factor that will cause
you to crave for nicotine and also cause
lung cancer in that case you could not
distinguish just from observing some for
some the data just from analyzing some
recorded data on populations that happen
where there hasn't been a controlled
experiment unfortunately control
experiments which are often needed to
determine causality or costly and
unethical or infeasible so organizing
campaign to discourage people to smoke
or forbidding smoking in public places
is costly forcing people to smoke would
be unethical and completely preventing
them from soaking would be almost
infeasible so in many cases you can't
perform experiments so on this little
crow tune I'm illustrating also the fact
that we have you know this very hot
problem right now about global warming
we can't put the earth in a test tube
and warm it up right so on this new
slide I'm trying to illustrate the fact
that there are now algorithms that allow
you to
extend to discover causal relationships
in data and in observational data so
without performing actual experiments so
that is you know the real value here
because we have a lot of observational
data so I'm showing you here
prototypical algorithm and this is the
only algebra you will see in my talk but
it's just you know to convince you that
this is real and this algorithm is
called the PC algorithm was introduced
by spiritus and glimmer in 1999 so
consider three random variables a B and
C which belong to a universe x of random
variables and v is a subset of x first
you initialize a graph that is
completely fully connected and earn
oriented so arrows in the graph will
mean causal relationships and then
you're going to perform a number of
steps to organize that graph into a
causal graph to the first kind of steps
you're performing our tests of
conditional independence if two
variables are conditionally independent
condition on any subset of other
variables from this universe x then
you're going to cut the connection
between the two variables then you
perform an additional step which has to
do with colliders here this little bar
here should be crossing here in this
Collider step I consider any triplets a
B and C of variables that are connected
a connected to see see connected to be
but a not connected to be okay so if
there is any subset V that each such
that a is independent of B given V then
you don't consider that rule but if
there is no subset V considering that
satisfy this independence criterion then
you conclude that you should be
orienting the arrows in this way so in
essence this says that if you
you have this conditional dependency
that happens between B and and and a
conditional dependency on using a subset
containing C imposes that there is arrow
pointing towards C so this these two
conditions are the basis for a lot of
causal discovery algorithms and then
afterwards you have still many
connections in the graph that are not
oriented and you try to complete the
connections with some hora sticks that
are based on these rules of constraint
propagation if you have you know a chain
of causal relationships like that and
there is a link between a and C then you
orient the arrow in this way and if you
have a chain and then there is a missing
link here then you add the arrow that is
pointing in that direction so there are
other types of algorithms of course I
was just trying to illustrate here the
type of things that people are doing in
this field and there are quite a number
of difficulties that people are facing
in developing a useful and efficient
algorithms first of all people need to
make a number of assumptions for these
algorithms to be valid and some of these
assumptions are generally violated one
of the assumptions is causal sufficiency
as can be shown depending on the set of
variables that you're considering the
causal relationships that you are trying
to establish might change so if you
remove one variable or add one variable
in your universe this might change
completely the relationship between the
other variables that you can infer from
this algorithm ism so this is costco
sufficiency you need to have enough
variables so that you're sure that you
can infer properly the right
relationships within variable hidden
variables are the nightmare of causality
algorithm the other assumptions that are
very often made are these assumptions of
Markov graphs and also of faithfulness
but basically say that there is
correspondence between the graphical
representation of your causal
relationships and the underlying
distributions and all the dependencies
or in dependencies that can be derived
from analyzing your underlying
distribution then other hypotheses are
you know very common such as linear
relationships with variables or go see
Anna T of some of the distributions so
even if you have you know overcome all
these difficulties you still face with
some more problems some problems include
overfitting so assume now that you don't
have anymore an infinite amount of
training data and many of the algorithms
they make the assumption that you have
an infinite amount of training data and
even then they have you know a number of
problems but in reality you have a
limited amount of training data and
because of that you need to take into
account some error some confidence on
the causal relationship that you find so
this is what I call here a statistical
complexity taking into account finite
sample sizes and last but not least we
have algorithm efficiency problems so
this is what I refer to as computational
complexity you often have now thousands
of variables and terms of thousands of
examples and many of the algorithms do
not survive you know do not scale up to
these large problems so this is you know
point of start in organizing a challenge
in causality we want to see which
algorithms survived all these difficult
conditions on some on some sizable data
sets so we started this project which we
call causality workbench which is
introducing a number of challenging
problems in causal discovery and we
think of it as a causality laboratory
what we ultimately want to achieve is
that we want people to be able to
experiment on
some model problems because researchers
in this field of causal discovery and in
machine learning usually don't have the
luxury of having their own wet lab or
having you know a laboratory to really
experiment on on real systems so we're
going to make available to them
artificial systems that are modeling
real problems and they'll be able to
perform experiments on them and see how
efficient their causal discovery
algorithms are to start you know reading
the the problems we have organized the
first challenge and it's not yet a cause
of discovery lab it's still problems
that are not in completely interactive
but we have a shop for a number of
problems in our approach is to find
problems that pose a real causal
question problems that are of real
interest economic or societal problems
problems that are hard to solve from the
point of view of the algorithms but yet
are solvable so we have some baseline
methods that do better than chance and
problems that are good benchmarks in the
sense that we can get error bars that
are small enough that we can distinguish
between the performance of two different
algorithms and taking advantage here to
introduce my collaborators so Peter
spiritus which is a which has done a lot
of work in coastal discovery is
interested in the fundamental aspects of
causality Andre NSF who is more on the
application side right now is working at
IBM konstantina referees who has been
working a lot on causal discovery
algorithms and making them efficient
gregory cooper who is an expert on
medical applications of causality and
myself who has been organizing several
benchmarks already on machine learning
we came up now with three initial data
sets which are far over first because I
challenge so let me introduce you this
data set which will illustrate the kind
of things we're interested in each one
has a given training set from which
people are supposed to learn the causal
relationships between variable and three
different test set which have number 0 1
2 and the test set correspond to
different types of manipulations that
external agents have been making in our
setting people need to learn only from
observational data that is from the
natural distribution of the system but
then they are going to be tested on a
different distribution which is an
unusual setting in machine learning in
machine learning people usually think
you know of data as being iid
independently and identically
distributed here we violate this we give
them test data which are which are drawn
from a different distribution
corresponding to some manipulations by
an external agent so in the ragged data
set for example we have data which is
genomic data we have variables that
correspond to gene expression
coefficients so for example measuring
the activity of genes in serum and what
we want to predict is whether people
have lung cancer or not so it's a
classification problem with for many
variables which are all these gene
expression coefficients and the goal is
to find whether there are causal
relationships between the gene
expression coefficients and lung cancer
either as drug targets so some of the
genes might be the end drug targets or
to monitor the activity of drugs so some
of the genes might be interesting
biomarkers that allow you to monitor the
activity of some drug that has been
administered to patients in this case we
have so-called we simulated data so one
of my colleagues Constantine olivares
built models we've been working for many
years on a model of these genomic causes
of lung cancer using real data and then
the models been used to generate
artificial data so we know
the truth values of causal relationships
which are embedded in the model and we
propose to people some data from which
they have to reconstruct the causal
relationships of the model in the second
data set called Seidel we have a
different problem which is a
pharmacology pharmacology problem here
the features or variables are our
features of molecules pharmaceutical
molecules that might be good drugs and
so people in pharmacology have huge
libraries of small molecules which have
you been using the fastest drugs and
these molecules have been tested against
the HIV virus in that case and I've been
tagged as active or inactive and the
question is that the chemical engineers
would like to know which of the molecule
features are interesting in order to get
this activity so that when they designed
the next molecule they will get the
desired activity so here we want these
causal relationships between features of
the molecule and activity and
distinguish them from mere correlations
for example is solubility really a cause
of activity or is it just collected with
the activity but the real cause might be
the presence of some group of atoms in a
particular arrangement in the third
problem we are looking at now we are not
looking at a biomedical application but
an application in in econometrics we
would like to know which attributes are
important to earn more money so we have
census data and we have a variable that
says whether people earn more or less
than fifty thousand dollars per year and
we would like to know whether variables
like marital status number of children
number of years of university studies
are affecting or not the earnings and
potential actions that you know would
follow if we knew the answer to those
questions would be are you going to send
few more years your children to college
but we don't want to experiment with
that we can't or you know it's too
difficult and we would like to know
these causal relationships using only
these observational data we have a
couple more data sets that are toy data
sets that are generated by small
artificial models so that people can
practice in the challenge and people are
getting online feedback from a website
that we have been setting up we do not
give them the performance on the test
set so right now they have on the XXX as
answer to the different metrics that we
are computing but we give them partial
feedback in terms of whether or not they
are you know top ranking or average or
bottom ranking so we give them quartile
information if they are in the top 25
percent of the people the the box is
colored in green then you know it gets a
grading of color and if they are in the
worst models then they get a redbox and
this is sufficient motivation so that
they keep making entries into the
challenge and they can get details of
the various data sets by pointing on one
of the bars here then they get some more
details so in the remaining of the talk
now that I've you know laid the basis of
what we want to do I'm going to talk
about what our own challenges why is it
difficult to a benchmark causal
discovery and what innovations we've
done to address these problems so
challenges are finding good problems
good data good metrics challenge
protocols and implementation and i'll be
talking about the first three items here
we have a couple of upcoming data sets
that we are working on one of them is
conceptual and is a artificially
generating data that has some particular
difficulties that are often overlooked
by most algorithms I mentioned to you
some of the assumptions that are usually
made by
regular causal discovery algorithm so
this data set will make these algorithm
fails so it's we have other real
datasets one of them is another health
care data set and this one is
introducing another type of difficulty
that usually people don't take into
account in modeling causal relationships
and that difficulty is that anything we
can measure we measure it via an
instrument and instruments are not
perfect so in essence we never or rarely
we rarely have accessed causes of of
outcomes of interest what we have access
to is measurements that are derived from
these causes so in essence we always see
effects right because measurements are
effects of what we are interested in and
because of that we might draw the wrong
conclusions so we are setting up this
data set in which there are instrument
measurement artifacts that people have
to take into account to their to draw
the real the good conclusions we have
another data set that looks into the
importance of taking into account the
timing of events so in that case we are
looking at a marketing problem in which
product sales are being monitored over a
period of time and you have seasonality
effects and many other effects that need
to be taken into account and we're
looking into introducing more and more
data sets in in a wide variety of
applications psychology epidemiology
neuroscience security sociology climate
ology the internet and ecology and we
would like very much that you know
people like you helped us identifying
good new applications of these
algorithms and if you want to contribute
data what characteristics the car Texas
will be seeking in good data sets are
that the data need to be not
confidential we need to have a large
number of samples a lot number of
variables the data preferably
need to contain both observational and
experimental samples but if you can't
meet all these conditions we can still
have yes question the one that we have
presented it wrong modifications so let
me go back and then show you get the
tables in the data sets we presently
have we've been looking at numbers of
examples and here we're mostly
interested in the number of test
examples in order to be able to really
benchmark the algorithm and they're in
the tens of thousands so the more the
better here we leave it a little bit
because we get then huge volumes of data
and some people would be limited by just
manipulating for no data and those
numbers of examples give us reasonable
error bars so tens of thousands right
and in numbers of variables is the
reason why we want a large number of
variables is because if we have say for
example one of two variables then you're
assessing causal relationships only
among one of two trials right so you
can't get error bars good era but in
that respect so we have in the at least
hundreds of variables now what I wanted
to to say next is that even if your data
does not satisfy all these requirements
we have means of generating some
artificial data so we welcome also data
that has fewer number of variables or
not as many samples if we don't have
enough samples we can make models that
will then generate samples and if we
don't have enough variables we can add
extra artificial variables that will be
plunging the real system into a larger
some artificial system okay so we've
been doing both in in this challenge
we're presently organizing and in the
next few slides I'm going to explain how
we assess the performance of causal
discovery algorithms with with all new
methods
so we have two types of ways of
assessing cause of discovery algorithms
one is very goal-oriented and that is
via the fulfillment of an objective so
the objectives can be to fall they can
be of making prediction of actions in
the future or they can be looking back
in the past explaining what happens so
what if we had not launched this
advertisement campaign would we have
also gained these ten percent in sales
or not so this is what people refer to
as counterfactual and the second type of
matrix we're having are directly
assessing causal relationships with
respect to their existence their
strengths and their degrees so to you
know put that again in context a lot of
what's being done in the causal
discovery algorithm domain there's only
the first type of assessment people
assume that they can define in some way
what causal relationships are and they
have some truth value that they found in
some way right and so they for example
they generate data with a Bayesian
network and then they try to reconstruct
the network from which the data has been
drawn right that's typical of what
people do in in this field here we have
a different view because we don't want
to be biased by a particular way of
generating data that I could have been
generated by a system which is not a
directed acyclic graph that like what
you know people usually assume real
systems are very complex full of
feedback loops full of variables that
you never observe right and we've seen
we think that this is the real power of
causal modeling the real power cause
modeling is not to reconstruct an
invasion network it is to take a real
system with all its complexity of these
hidden variables all you know it's
feedback loops all it's you know
non-stationary behavior and be able to
build
causal model that will allow you to
perform actions that will have desired
effects and this is what we as human
we're facing with you know in our
everyday life we are interacting with
complex systems for example or fellows
or friends right we are not able to
model them perfectly but still to some
extent we're able to predict what will
happen if we do this or that so we have
an internal causal model or virtually
everything we are interacting with and
so we have these metrics that are
indirect that assess how well we are
doing with respect to modeling causality
via the fulfillment of an objective
because we know that there is
necessarily a tie between causality and
the prediction of actions between being
performed if there is an external agent
that who is tweaking the system the only
way you can predict what will happen is
by having some notion of causality so
what are examples of objectives well in
medicine and epidemiology maximize life
expectancy maximize drug efficacy
minimize contagion in economy and
marketing maximize the gross gross
national product minimize maximize sales
sorry and I don't minimize churn rate
which is a very popular application for
the cell phone companies who constantly
have you know people switching from one
company to the other and they need to
modify their marketing policies so
everything has to do with issuing a new
policy in order to influence some target
is an example of what we're interested
in so in the next phase line I'm going
over some examples that are just two
examples to illustrate how things work
so here we made a small causal graph
that illustrates this problem of lung
cancer and we have a number of variables
in green that I in the neighborhood of
lung cancer
and in the jargon of the field people
referred to these variables as the
market Markov blanket those are does
include the dye causes the direct
effects and some dye causes of the
direct effects the reason for having you
know these other variables like allergy
which is neither a cause nor consequence
in that set of variables that are in the
neighborhood here is because allergy
helps you drawing conclusions from
cuffing if you see somebody cuffing you
can't really conclude anything about
whether another person has lung cancer
unless you know whether the person is
coughing because of an allergy if it's
during hay fever and people are coughing
you can't really rely on that variable
to predict lung cancer okay so you need
to know something about algae so if you
know these variables in green what those
variables in green they screen you from
the other variables here in the sense
that lung cancer is independent of all
the variables in yellow here given the
variables in Grain given this Markov
blanket so if you do prediction in a
usual iid setting you know in a usual
predictive matter where you don't have
intervention of your on your system a
pretty reasonable way of proceeding is
to use those variables in ring and green
as predictors for your target variable
well not so anymore if you're performing
interventions on your system so here I'm
circling in red a number of variables on
which we're acting so assume that there
is an external agent that can you know
force people to wash their hands for
people or prevent people from smoking
you know force people to lie in bed to
get rested right perform these actions
that that forced the system to behave in
a certain way now because of these
actions of this external agent these
variables in red they are now
disconnected from their natural causes
so if I go back to the previous graph
you know there were more arrows here
there are some errors that
gone because since we're manipulating
those variables they are disconnected
from their natural causes as a result
the markov blanket is now changed this
variable here is no longer part of the
mark of blanket so what we're asking
people to do is to learn from the
training data these are relationships
and then we're telling them well now
we're going to be manipulating these
variables in red tell us which ones are
still going to be predictive in the test
data well in that case the right answer
is that this variable that remain green
will still be predictive but this one
will not now see there is here subtlety
that the variable smoking which is a
cause of lung cancer is still predictive
whereas this one which is a consequence
is no longer productive so in doing
these manipulations we always make sure
that we don't manipulate the target
variable so the target variable always
remains connected to its natural causes
right that part of the system never gets
changed or you know messed up with hence
in particular if we would manipulate all
the variables then none of them would be
predicted except for the direct causes
okay so if I tell you we manipulated all
the variables then the natural thing to
for you to do is to take into account
only the direct causes to make your
predictions of the outcome now how do we
then assess how well people are doing
with respect to discovering these causal
relationships without having to give
them a definition of causality so this
has been your exercise because since
it's almost impossible to give a
definition of causality that encompasses
all the notions that people have been
you know proposing in the literature we
want to have this goal driven causality
that's only defined via the
manipulations or via dxd interventions
of external agents so what we do is that
the
cause we have access to the system that
generated the data in that particular
case we can define the variables that we
know are going to be predictive of the
target but we don't really ask people to
tell us which are causes or effects or
whatever we just you know select those
variables that are going to be
predictive and we ask people to return a
subset of variables which are used by
the system to make predictions so
hopefully if they have optimized their
objective then the subset of variables
that they have selected are going to
contain a large number of the most
predictive variables right so we ask
them to either order them or not order
them but anyways we want to find whether
they have in the top ranking variables
those variables that are of interest
them and then we compute a score which
is a function of the subset they've
returned and the subset of variables
that we know are you know the truth
values of the good variables that they
needed to find and then we'll be able to
correlate these causal relevance with
the performance on predicting the target
right the target variable so you
remember for example we wanted to
predict lung cancer and so when one
thing we might want them to optimize is
the air raid on classifying patients
into healthy or having cancer that would
be the objective now they need to
perform this task now in manipulated
data and we have to see whether they
perform the feature selection correctly
so they you know discard variables that
are no longer productive because of
manipulation and we'll be able then to
correlate how well they're how good
their feature set is compared to how
well they're predicting the target
variable lung cancer in the context of
these manipulations so that's our
approach the ties causality to pursuing
a given objective now unfortunately
a lot of the data we have is purely
observational data so everything I've
been talking to you you know before
works only if we have artificial data
sets that are generated by models for
which we know the truth value of the
causal relationships any real system
that we can just observe but don't you
know it cannot open and look you know
inside what are really the connections
between the different variables in a
real system does not give us the truth
values of the causal relationships and
in that case the only thing we can you
know do is to have observational data
and we can't perform real manipulations
so if we come perform real manipulations
we can't provide to people manipulated
test data then therefore everything
breaks down everything I've been talking
to you about before breaks down so we
found a new means of using purely
observational data and still assess
causal relationships so with all the
limitation that this new method has it
is very powerful because we have a lot
of situations like that a lot of
situations in which we will never be
able to perform experiments right so and
we still would like to uncover causal
relationships because we want to know
for example if we limit the emissions of
co2 will that have an effect on global
warming our methodology plunges or real
system into a larger auto fuel system so
now assume that the small system that
have been talking to you about this this
graph here is a real system it's not you
know this artificial system that have
been mentioning but we don't know it
right its cadence so what we're going to
do is that we're going to add more
variables and those variables we call
them probes and they are derived from
the real variables and the links here
they are known to us we have you know
created these artificial variables using
some artificial system
and because of that because we have
control over that we're going to be able
to to manipulate these probes and thanks
to this particular setting we're going
to be able to draw some conclusions
about how well the acozil discovery of
algorithms are performing without having
to manipulate the rail system here in
particular what we can do is to
manipulate all the probes and if we
manipulate all the probe we disconnect
them from their causes that are drawn
from the real system and so if causal
discovery algorithms you use you know
such relationships between real
variables the target variable and ender
probes to make predictions this will
fail when we when we manipulate the
probes so here is the way we use this we
take real data we add probes and then we
let the participants of the challenge
know that we have manipulated all the
probes so they should conclude that they
cannot rely on the probes to make
predictions of the target variable and
because all the probes are non causes of
the target right the arrows they always
go in this direction from some of the
real variables to the probes the probes
are never causing any of these variables
because of that a reasonable strategy is
to exclude from the set of predicate
variables all the variables that might
be called by the consequences of the
target so you need to adopt this
worst-case scenario in which you can't
rely on any consequences of the target
because all the probes are consequences
of the target in this way we are using
these artificial manipulations to assess
how well the causal discovery algorithms
discover causes of the target and it can
be shown that when we use you know the
score and using the probes what we can
compute is an F score that uses an egg
as negative class the probes which are
all non causes
and are all manipulated and as positive
class the other variables which may or
may not include causes or non causes so
the XCore you know assesses how well you
separate the pros from the other
variables and what we really would want
to compute is an R score that separates
the causes from the non causes and it
can be shown that asymptotically for an
infinite number of probes the F score is
linearly related to the our score so it
gives us a good model selection
criterion to assess the performance of
causal discovery algorithms so I've
reached you know the end of this story
and in conclusion at please you know
play with this try our first challenge
learn and win we're going to have a
workshop travel grants from the top
ranking participants and some
proceedings in the Journal of machine
learning research best paper award some
prizes and the price you win is going to
be multiplied by the number of data sets
on which you have one so there is an
incentive to try many of these datasets
and one of the reasons for me to be here
is both to encourage you to try to enter
this challenge and learn about causality
and also try the best ideas you have but
also to contribute new problems because
these challenges are a great opportunity
to have your problem solved and even
working on creating a data set and on
phrasing your problem in putting it into
the set of the challenge is a big step
towards solving it so if you join us you
know and try to contribute new problems
I think this is a great opportunity for
us to have your problem solved by dozens
of Richard groups for free essentially
thank you very much for attention
do we have questions is this the first
such challenge that you guys have
managed or have you already learned
something new from previous challenge no
this is actually the first challenge
that that you're organizing the elements
were a lot easier than than this one
because here the problems are very
difficult to to put in a setup in which
we can actually benchmark the algorithms
right particularly this non iid data is
is difficult let me give you an example
in one of the first challenges we
organized on future selection we had a
setup in which people could provide the
results online for a small subset of the
test data conn validation set and we
would give them results on this
validation said then the final
benchmarking was done on a much larger
test set but because the data were iid
we could give them you know test data
that was distributed similarly as the
validation data here we can't do that
because we would inform people a lot
about the distribution on test data if
you would give them information about
how well they're doing on the subset of
the test data so here we had unit to
modify or protocol and give them this
quartile information about the real test
data or rather so we have to work a lot
on protocols so there are many other
aspects and I want to bore you with that
but we can have a discussion about it
afterwards we learned a lot of things
from past challenges and which keeps you
know us to want to organize more
challenges often the conclusions are
counterintuitive in the feature
selection challenge we thought that
space space dimensionality reduction is
a big element in improving
classification performance or prediction
performance as it turns out this is not
true today's algorithms are very
powerful
in dealing with large dimensional energy
data days regularization that harnesses
the you know the problem of overfitting
and most often algorithms perform better
if you take the entire future set as an
input if you don't prune first the
feature set pruning first the feature
set is costly in number of examples that
you used to do that in training right so
that was one of the outcomes of the
first feature selection challenge if you
don't need to do feature selection for
some other reason like for some economic
reason for example because it's costly
to measure pictures then probably you
don't want to do it in other challenge
we've been organizing we've had also
interesting conclusions so for example
people have been wondering for many
years whether cross-validation is the
best way of doing model selection and if
you you know pool people and ask them
you know if you had the gun on your head
and needed to answer are you going to
use cross-validation or are you going to
use structural risk minimization or
statistical testing or whatever other
method to do a model selection everybody
will say well i'll be using
cross-validation well as it turns out
it's true that this is this is the best
way of going but there isn't even even
better way of doing mall selection then
you know the usual k means of kk k false
cross-validation and it is to regularize
cross-validation so you can go to the
next level and do regular eyes
cross-validation so that it's one of the
hot topic now in in model selection and
has been verified in your challenge now
the last challenge that we organized was
were a lot of fun we called it agnostic
learning versus prior knowledge and we
gave people datasets in several
representations to see how much they
could win by adding domain expert
knowledge to their system in order to
solve given tasks and there the
interesting thing is that real domain
expert knowledge usually is more harmful
and useful so real experts usually don't
do a very good job because they're kind
of opinionated in a way they have you
know too strong prior but what they
think is going to work and they don't
rely enough on data and so they often go
the wrong way and don't you know
recuperate from head on the other hand
completely agnostic learning is not as
good as a little bit of natural domain
knowledge but some common sense
knowledge that you can can put in based
on you know the type of data that you
have so things like you know removing
some variables because you know they
would be useless or using or not
choosing some higher order interactions
or if used to know that you have images
using the the fact that you have two
dimensional relationship between
variables so very you know simple high
level kind of you know knowledge that
can help but true domain knowledge
usually hurts more than then then helps
so we hope in this particular challenge
also to have some surprises and discover
some interesting things the setup is new
both to machine learning people and to
cause of discovery knowledge people both
communities haven't been talking that
much together so we hope by having this
new setup that people would be working
on you know on that problem in a more
unified way but there is opportunity for
both community to contribute you know
without that much background
knowledge already there's a lot to learn
for both community because this setup is
kind of novel so you asked for us to
Ford I don't know ideas for new domains
to add to epidemiology climate ology
ecology etc so one of them which is
obviously worked on a lot but would be
interesting and for which there is
plenty of data is spam spam filter so
you have did these two sets the next one
I guess would be sort of statistical
machine translation so you have let's
say in Canada French every everything's
in French and in English so given a
training set can you then turn this
English into some French so translation
basically so the first problem that you
mentioned I've been thinking of and and
I can think of one way that's we think
we were interesting i discussed to semi
ability he thinks that you know i'm
being the devil there because the time
would be not not to work for spam
filtering but to discover how spam
filters behave so this is this is a
problem of the spammers they want to
know they want to reverse engineer the
spam filters and find what what set of
variables make it that my message is
going to be discarded well they're
pretty good right if you see some of the
stuff at the bottom of your messages so
who knows where these guys are right
right so i do think it's a very good
model problem because there we can the
device experiments that we can actually
carry out it for real on systems that
are out there and that we don't you know
there is no moral or you know ethical
problem with performing with experiments
the other problem at the second frame
you mention i don't really understand
where the causal question is so
basically an english word causes a
French word if you have the parallel
text or you can think of it in this way
why would the English or cross the
French fertile so instead of the
opposite this looks like it well we
equivalent relationship or other than a
quota relationship uh it's not really
because it's not one-to-one but so yeah
but you can take it you can take it both
ways but let's say that my problem is
then too
turn some other English into French then
I think about it this way and when you
do do statistical machine translation
you will run it in both directions you
can't run it you can't think of it as
one to one okay I'd be very interested
in talking to you about it and then the
final thing which is less germane to
Google but more fun is something like
Saddam futures so when Saddam Hussein
was still alive you could go bet on
online places like in Ireland they say
okay the chance that Saddam will be
killed by this date and then crunch that
with oil price spikes or oil future
spikes or anything like this this is a
ton of fun absolutely we've been we've
been actually thinking about that in the
European community has a program that is
extracting from text events so whenever
we have you know stream of events and
they have it you know in in XML format
we can then try to figure out whether we
have cause effect relationships between
events that have been extracted google
trends or Google News right they have
the word on every spike like a an event
that happened yeah that I would be
extremely interested in in working on
those kind of applications the other
data do we have other questions so the
other you know I've been playing with
google apps before before I came here
and from the user point of view I see
google ads as this complex system with
which I would like to have an
understanding of what cause effect
relationships are so from the user point
of view would be helpful for me to have
a simple causal model that will help me
getting more efficient campaigns they
are already existing wizards that are
made available to people who place ads
but they're kind of opaque and they
don't allow you to very quickly figure
out a strategy on how to optimize your
ads so thinking you know maybe that that
we also an avenue for causal discovery
systems but you know think about it in
you know the back of your mind
and send me email if you have other
ideas you can work on okay thanks Isabel</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>