<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AQC 2016 - Driving Spin Systems with Noisy Control Fields: Limits to Adiabatic Protocol | Coder Coacher - Coaching Coders</title><meta content="AQC 2016 - Driving Spin Systems with Noisy Control Fields: Limits to Adiabatic Protocol - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AQC 2016 - Driving Spin Systems with Noisy Control Fields: Limits to Adiabatic Protocol</b></h2><h5 class="post__date">2016-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tzZ3TXw5NAM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">[MUSIC PLAYING]

ADOLFO DEL CAMPO: So
yes, my job is very easy
because already this afternoon
we saw talks about noise,
optimal stopping,
and related issues.
So I'm going to focus on what's,
essentially, the law that noise
plays in adiabatic protocols.
And the talk is going to
be divided in two parts.
In the first one,
noise will be perceived
as something that is
a bit of a hassle,
and in the second
part, something
that is actually a benefit,
something you can use.

So I guess this is a
common perspective.
We all know adiabatic
dynamics is pretty good.
It gives a good
control of a system,
and there is low driving.
It allows us to
suppress excitations,
and it also allows us to
find the ground state.
So why bother about
anything else?
And the point I'm going
to make is-- well,
I guess perceived by
everyone in the audience--
is that there is a
fundamental breakdown
of adiabatic dynamics
in any system which
has a critical point.
And a well-known example
is the phase transition
between a paramagnet
and a ferromagnet.

So this is essentially,
why anything else,
well, because the
adiabaticity gets broken.
This is typical.
It was already alluded
before in the talk by Emile.
So when you have
multiple ground states,
we have the same energy.
And you are starting
a given phase,
say you fix annealing protocol.
You reduce the
temperature, and you
force the system to choose one
of the different ground states.
And then, of course, if
you do this in finite time,
what happens is that the system
just cannot make a uniform
choice, so domains form.
And how many domains you get
and the size of the domain
depends on our questions,
which are fairly natural.
And they are ones
where, to some extent,
by the so-called Kibble-Zurek
mechanism, which was introduced
by the gentleman over here-- so
Tom Kibble who, you might have
heard, he passed away
a couple of weeks ago,
and Wojciech Zurek
who is at Los Alamos.
So the key ingredient for
the Kibble-Zurek mechanism
is the divergence of both
the correlation length
and the relaxation time
at the critical point.
So as you approach
a phase transition,
then it turns out that, as
a function of the distance
to the critical point,
both the correlation length
and the relaxation
time become large.
And in particular, if the
relaxation time becomes very
large, that means that
you cannot stay adiabatic.
It doesn't matter
how slowly you go.
Near the critical point, your
dynamics will be non-adiabatic.

What the Kibble-Zurek
mechanism does
is to assume that you
fix the rate at which you
approach the critical point.
So the distance to
the critical point
varies in time at
some given function,
with that characteristic
time scale,
which is the quench time.
And you start, say, in
a high-symmetry phase,
and you want to go to a
broken-symmetry phase.
And I plot here the equilibrium
instantaneous relaxation time.
And the critical point is
reached at time equals 0.
So it just have
some time before.
I get close to it.
The relaxation time
becomes very large.
I will be non-adiabatic here,
in particular, sort of frozen.
And then, once I
cross the transition,
I stay adiabatic again.
So the Kibble-Zurek
mechanism just tells you
that this time scale, in which
the equilibrium instantaneous
relaxation time matches the
time elapse after crossing
the critical point--
at this time, the scale
is crucial to determining all
the known adiabatic properties.
In particular, it fixes
the size of the domains.
The size of the domains can just
be estimated by the equilibrium
value of the correlation
length, evaluated
at this freeze-out time.
We also heard about
freeze-out times
before, a bit different though.
So this leads to
a universal power
law dependent-- so the domain
size, as a function of rate--
well, actually the
quench time, at which
you cross the transition.
And exponents are
universal, so if you
know that universally the
class of your system, then you
just plug them and
you get the prediction
for the size of the domains.
Now, you can also use the
Kibble-Zurek mechanism
to estimate the
density of excitations.
And this just, essentially,
I followed here, minus 1
is just the inverse of
the correlation length
in one dimension of the size
of the domain in one dimension.
And it will have a
power law dependence
sequence, with a quench
time, with a quench rate.

Things that we know about
the Kibble-Zurek mechanism
is that it's broadly applicable.
So pretty much,
it has been tested
in lots of numerical
experiments with [INAUDIBLE]
and [INAUDIBLE] numbers.
And it has, as well, this
whole range-- a whole bunch
of experiments, which
have demonstrated
aspects of the mechanism.
There is no, still,
uniform, I guess,
proof that the Kibble-Zurek
mechanism holds.
There are many difficulties
to test it in the laboratory.
You have to know the critical
exponents, the relaxation time,
to measure defects
reliably, and so on.
Still, we also know-- this
was some recent results--
that the Kibble-Zurek
mechanism holds,
even when you do not
expect it to hold.
So we tested some
models [INAUDIBLE],
but essentially, the
point is that they
are so strongly coupled
that they don't even
have partial particles.
And it was not obvious a priori
that the Kibble-Zurek mechanism
should hold in this regime.
However, a couple
of works showed it,
that that is actually the case.
And so for the purpose
of quantum annealing,
I guess we are more interested
in the implications which
manifest in this type of loads.
So essentially,
the residual energy
of the density of
excitations [INAUDIBLE]
exceed with the power law
dependence on the annealing
time, which depends on the
dimensionality of the system,
the correlation and
critical exponent,
and the dynamic
critical exponent.
Now, in this instance,
it takes a simpler form.
It's just 1 over the square
root of the annealing time.
And in the presence of this
solver, it's quite different.
It actually becomes a
logarithmic dependence,
which tells you that if you
want to suppress excitations,
you need exponentially
long annealing times.
So ultimately, for the
purpose of annealing,
I would say that the
Kibble-Zurek mechanism
is bad news,
because it tells you
you have to stick to
long annealing times
if you want to
suppress excitations.
One possibility, which
I discussed last year
at ETH in Zurich,
in AQC, was the use
of circuits to adiabaticity,
which essentially are fast
non-adiabatic processes
that suppress excitations.
I'm not going to
discuss it today.
I just want to
mention that there
is some good progress
in the laboratory,
to realize that in
very simple systems
this idea,
counterdiabatic driving,
is very similar to the
first adiabatic iteration
that Sergei introduced
in the previous talk.
And these are very
simple demonstrations
for sort of
[INAUDIBLE] crossings,
two and three-level systems, and
also for continuous variables.
But if you want to go further,
well, it becomes difficult.
But I want to mention as
well that in the other room,
[INAUDIBLE] presented
some works, which
appear in the
archive today, on how
to suppress excitations
in the server system
by inhomogeneous driving.
In this talk, I want
to put the emphasis
on this type of
Kibble-Zurek scaling,
and essentially revisit them
in the presence of noise.
Here, we always assume that
the control field is perfect,
so we lower the temperature of a
magnetic field at a given rate.
But there is no
fluctuations, no noise.
So I want to consider the
effect of noise in the controls.
So this is work with Anirban
Dutta, a postdoc in our group,
and Armin Rahmani,
who is in Vancouver.
And this work was
actually motivated
because when it was analyzing
previous experiments devoted
to test the
Kibble-Zurek mechanism,
we always saw that there
are stochastic fluctuations
in the noise in
the control field.
So this is an example.
This was just one
of such experiments
that I alluded before, to test
the Kibble-Zurek mechanism,
where they used an ion
chain, compress it-- they
form defects.
And the question is, what
was the effect of this noise?
In the context of
annealing, I will
say that this is the standard
scale where you're starting
with some simple Hamiltonian.
You want to go to a
different one, which
is somewhat more complex.
I'm just going to focus on
this example, which essentially
is the transverse-field
Ising model in one dimension.
But I'm going to modify
the standard protocol
and include the effect of
some stochastic fluctuations
along the process.
So I want to see what's
the effect of this.
So instead of just
a linear ramp,
I'm going to add a
stochastic variable.
And I do not need to focus
on the white noise limit,
but let's just assume that this
is the case-- that the noise is
correlated as a white noise,
and it has some strength.
Well, so this is
something which is
well-known-- for these
numerical methods,
there is a whole field known
as stochastic Hamiltonians.
And this is-- if you want the
[INAUDIBLE] counterpart of it,
where you have a
Hamiltonian, which
has a deterministic part
and a stochastic part--
so not a Gaussian, say,
real process, which
is coupled to an operator, b.
In the annealing
schedule, it turns out
that this b, this
stochastic part,
includes both one-body
and two-body operators.
And [INAUDIBLE],
essentially it just
comes from the fluctuations of
the noise in the control field.
And you are left to consider
this stochastic Schrodinger
equation, which in
principle you can just
solve by running trajectories
and stochastic unravelling.
Now, I want to introduce an
alternative approach, which
focuses on the mean
density matrix, which
is the noise average dynamics.
So you run lots of
trajectories and you
construct these
stochastic pure vectors,
that you get by solving
the Schrodinger equation.
You can take the average
over many realizations,
and you get a density matrix.
Well, it's known that
the master equation
that these effective noise
average density matrix obeys
looks like a-- well, it
has a Heisenberg part.
And then you have a relatively
complicated open-system part.
Yeah, so there's a
dissipative part, if you want.
But now, in the white-nose case,
one can just simplify this.
This is just a delta
function, and one
can do the exact average over
a stochastic realizations.
And one gets a very
simple master equation,
which includes the deterministic
part of the Hamiltonian,
and sort of a pure
defacing term, where
b, remember, includes both
one and two-body operators.
So with this, one can
just set the numerics
and try to prioritize the
dynamics-- how successful is
the annealing protocol--
by looking either
at the density of excitations
or the [INAUDIBLE] energy,
which is just the energy with
respect to the ground state.
And what you see is that
in the absence of noise,
or for very weak
noise, you have,
essentially, the Kibble-Zurek
prediction holds.
So the density of excitations
decreases with the annealing
time, so long annealing
times are always good.
But in the presence
of noise, there's
sort of another
contribution, which
kicks in and eventually
gives to sort
of anti-Kibble-Zurek behavior.
This, by the way, [INAUDIBLE]
in some experiments,
no one has an
explanation for that.
And here is a very
simple explanation,
which is just the effect of
the noise in the controls.
But you see that it pays off
to anneal for longer times,
only until some time
before the dissipative part
start to govern the
dynamics, and leads
to this anti-Kibble-Zurek
scaling.
So we can actually extract
this universal optimal time.
So this is essentially,
in some sense,
related to some of
the previous results.
And just when should you
stop the annealing process?
Well, it depends on the
strength of the noise.
But it scales as a power law,
which again, it's universal.
This beta is nothing but
the Kibble-Zurek exponent,
and we got the perfect matching
with a power law behavior.
And funnily enough, the
[INAUDIBLE] excitations
can be well-approximated
by a Kibble-Zurek
term, times an additive term.
So essentially, the
dissipative part
is just providing a heating
with a very well-defined rate.
Which, again, we can
match the rate of this r,
which is the heating
rate, is just
essentially proportional to
the strength of the noise.

All right, so I guess this was
the first part of the talk,
where noise is maybe perceived
as something [INAUDIBLE]
limit adiabatic protocols.
Now I want to give
a twist to the story
and say, if I am
interested in quantum
simulation of many-body
decoherence, well,
let's think of noise
as something good
that you can use.
So this is work, actually, with
my wife-- already, as you know,
[INAUDIBLE] at MIT-- and my
postdoc Matthew [INAUDIBLE],
and myself.
So this will be
soon in the archive.
And the idea is, while I just
review briefly the theory
of open quantum
systems, we always
consider a system, which is
embedded in an environment.
So the [INAUDIBLE] space is the
potential product of the two.
The Hamiltonian is the sum
of the system Hamiltonian
and the environment Hamiltonian.
And it includes coupling,
which generally you
can diagonalize and write as
the sum of system operators
times environment operators.
If you just care
about the system,
then you derive
reduced dynamics--
so essentially, a
master equation.
And what is known is, of
course, if it's Markovian,
it has a universal
form-- something
that we've known since the
'70s, thanks to Lindblad.
Now, what I want to
consider here is, well,
the case of many-body
dissipators,
essentially, many-body
Lindblad operators.
So whenever the system
operators are Hermitian,
you can think that the
environment is actually
measuring these observables.
You can think of the system
operators as observables.
And what I have
in mind is a place
where the system is actually
composed of many particles.
So there are many
constituent particles--
say qubits, cold atoms, ion
traps, ion chains, and so on.
And the system will be able,
not just to act locally
on its constituent
particles, but it's
going to have the
chance to look either
at, for instance, two-body
non-local observables-- or you
know, k-body observables-- so
these type of system operators.
Now, it's hard to
justify, generally,
these type of master
equations, because if you think
of the system
environment Hamiltonian,
this is already two bodies.
So these will be acting on
the system-- something acting
on the environment.
And typically, we know
that interactions in nature
are well-described by
[INAUDIBLE] interactions.
So in order to have a
system operator which
is two-body, or
three-body, or k-body,
then you need
higher-body interactions.

So the idea is, why
is this important?
Well, there are proposals of
how to do quantum computation
using dissipation,
and then calling
the ground state in the fixed
point of the master equation.
Of course, it's
just good to develop
a many-body theory
of open systems,
as there is for
isolated systems.
Essentially, [INAUDIBLE],
to a [INAUDIBLE] extent,
is based on that.
And then you can use a
particular type of baths
for either the [INAUDIBLE]
quantum computation, quantum
thermodynamics, and so on.
I just want to mention that
Alireza Shabani and Hartmut
Neven in particular
are working hard
to get a given type of baths.
So this is another approach.
So how to simulate this type
of many-body decoherence?
So the idea is to use,
now, the technique
of stochastic Hamiltonians.
Again, the idea is
to do-- essentially,
yes, rely on the techniques for
quantum simulation of isolated
process of unitary
Hamiltonians, and then add noise
to make the Hamiltonian
astochastic.
And include, essentially, the
Lindblad terms to reconsider--
to include them as
Hamiltonian terms,
which are modulated by
some astochastic forces,
which where eta is just a
process with [INAUDIBLE],
and perhaps some correlations.
So if you are able to
engineer this Hamiltonian,
the claim is that you will be
able to do many-body quantum
simulation of decoherence,
of many-body dissipators.
And the process follows
a similar procedure.
You consider the stochastic
density matrix, which
obeys a Heisenberg equation.
You [INAUDIBLE] the noise, so
you've got a density matrix.
And then the noise
average dynamics
obeys this general type
of master equation, which
resembles the structure of
the general master equations.
In particular, you
can get the Markov
limit, the Markovian
dynamics, for whenever
the noise is white.
Now, here is the sum over
all Lindblad operators,
which in principle now can
be k-body Hamiltonians.
And as just examples to
illustrate the point,
just consider one of
the typical systems
for quantum simulation--
analog quantum simulation--
with cold atoms.
[INAUDIBLE]
Hamiltonian where you
have a bunch of
particles, [INAUDIBLE],
jumping around an
optical lattice.
And they can have
on-site interactions.
Well, there are
well-known techniques
to change the on-site
interactions in time.
And what I'm proposing here
is to make them fluctuate,
according to a Gaussian
stochastic process,
to engineer these type of
dissipators, which becomes,
already, non-local,
despite the fact
that these
interactions are local.
Another example which is
readily available to technology
in quantum simulation is
the [INAUDIBLE] model.
There are several
platforms to engineer it,
but one could just add,
again, stochastic fluctuations
to the spin and
spin interactions,
and get a many-body
dissipator, in this case
with two-body terms
or even four-body--
depending on how you define
it-- but two-body Lindblad
operators.
Now, if you are interested even
in more exotic Hamiltonians,
there is ways to engineer
k-body Lindbladians.
And the idea relies
on the scheme
for digital quantum simulation
of k-body Hamiltonians.
So you will have some
given Hamiltonian,
which is the sum of
some k-body operators.
We know about Trotter
formula, which
allows us to express
this unitary, in terms
of unitaries of its term.
And now, there are
ways in the laboratory
to implement k-body
Hamiltonians.
Essentially, a technique which
has already been demonstrated
is the use of
Molmer-Sorensen gates, which
is an entangling gate, and
allow us to-- for instance,
if you want to realize a
Hamiltonian of this type,
then you can just do
it using the action
of this Molmer-Sorensen gate,
then a one-body, one local spin
rotation, and then reverse,
inverse Molmer-Sorensen gate.
So this is what you do
for ions, for instance.
And by adding just noise to this
one-body local rotation, which
is actually very
easy, you can engineer
this type of n-body dissipator.
So in principle, this provides
a very versatile technique
to engineer master open quantum
systems, and master equations,
with Lindblad operators,
which need not be one body,
but actually can be k-body.
Going beyond the Markovian
cases is actually very easy.
Actually, it's probably
the easiest part,
because you don't need to make
white noise in the laboratory,
which is kind of difficult.
That, for free, gives you
no Markovian effects.

So with this, I
close with a summary.
So I make the point that the
Kibble-Zurek mechanism dictates
long times for
annealing and that,
as I discussed before
[INAUDIBLE], shortcuts
to the [INAUDIBLE] are one way
of preventing the Kibble-Zurek
mechanism running the
process in a short time.
Here, I focused, essentially,
on the role of noise,
either are a source of the
anti-Kibble-Zurek behavior
and a limit to the
adiabatic protocols,
and would suggest
the existence of
a universal optimal annealing
time-- and then a second part,
which is like making
use of noise--
essentially harnessing noise
as a resource for the quantum
simulation of
many-body decoherence.
So with this, I just want
to close and thank my group
and collaborators again.
And thank you as well.
[APPLAUSE]

SPEAKER: Any
questions for Adolfo?

AUDIENCE: So regarding the
Kibble-Zurek mechanism--
so in many problems
that we are interested
in in adiabatic
quantum computation,
typically they are described on
expander graphs-- things which
are-- in these kind of
systems, when you cross a phase
transition, you do not have
a diverging correlation act.
So do you expect the
Kibble-Zurek mechanism
to occur?
ADOLFO DEL CAMPO: Generally,
the answer would be no.
However, at least if there
is a modulation of it,
like in a weekly first-order
phase transition--
something which
resembles, in some sense,
a second-order phase transition,
then similar arguments
can be used.
You don't have to be in
the thermodynamic limit,
for instance.
You can actually, with
very moderate system sizes,
you can already see
signatures or scalings
that agree well with the
Kibble-Zurek mechanism.
But you do need-- the
relaxation time has a bump.
Otherwise, you cannot use this
idea of the dynamics being
split into a sequence
of adiabatic,
sort of non-adiabatic frozen
states-- and adiabatic again.

AUDIENCE: Just to specify
one thing-- so you can also
have second-order
phase transition,
like ferromagnetic,
simple ferromagnetic model
on the beta lattice.
This does not have a
diverging correlation length.
Correlation length is--
ADOLFO DEL CAMPO: Maybe
the correlation length
is sort of secondary.
The key ingredient
is the divergence
of the relaxation time.
If something funny happens
to the relaxation time,
then you can make use of
this impulse approximation.
AUDIENCE: There is no
relation between the exponents
or the divergence of
the correlation end,
because the correlation
end does not diverge.
But still, you have--
ADOLFO DEL CAMPO: Yeah, I guess
that something happens in BKT
phase transitions as well.
Yes?
So the correlation behaves
in a very different way,
but at least you know
that you have a divergence
of the relaxation time.
And then you can modify
the Kibble-Zurek argument
to somehow come out with
similar predictions.
AUDIENCE: OK, thanks.
SPEAKER: One last question?

AUDIENCE: Maybe you
said this, but is there
some kind of universality result
in the last section about-- can
you simulate all
kinds of Lindbladians,
or some very general
family of Lindbladians,
for some noise processes--
or stochastic Hamiltonians,
I should say?
Thanks.
ADOLFO DEL CAMPO: Right,
so I haven't pushed it
to full universality.
Actually, what I have
shown is that if you
are interested in a
Markovian master equation,
where the Lindblad operators
are Hermitian, then that's it,
and it's actually very simple.
You can go beyond and
add color to your noise,
and then you will get a family
of no Markovian equations,
which also look
like pure defacing.
But really, there is
a no Markovian term.

And in principle, one
could go to the full set
of Markovian cases.
That requires to add
both a complex Gaussian
and stochastic process-- so a
noise which has complex value--
as well as Lindblad
operators, which will
be included in the Hamiltonian.
But there would be no
Hermitian, so perhaps
by embedding into a
larger [INAUDIBLE] space,
you can do something like this.
So I'm thinking about it.
SPEAKER: Let's
thank Adolfo again.
[APPLAUSE]
[MUSIC PLAYING]
</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>