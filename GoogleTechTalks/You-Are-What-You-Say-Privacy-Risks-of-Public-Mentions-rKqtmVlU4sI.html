<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>You Are What You Say: Privacy Risks of Public Mentions | Coder Coacher - Coaching Coders</title><meta content="You Are What You Say: Privacy Risks of Public Mentions - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>You Are What You Say: Privacy Risks of Public Mentions</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rKqtmVlU4sI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming I'm Dan Frankowski and
I'm an intern this summer with google
groups in my other life i'm also a
research fellow with group lens research
at the university of minnesota and i did
this work with some colleagues there dan
cause Leisha lotsa and lore intervene
and john riedl oh and I guess the title
of the talk is you are what you say
privacy risks of public mentions so I'd
like to start with a story in January of
this year Tom oh add downloaded hundreds
of thousands of wish lists from amazon
com he looked for people who read
dangerous books like on liberty critical
thinking in 1984 and he used the name
city and state on those wish lists to
look them up on yahoo people search and
find their home address and then he took
that home address and he put them on a
map with google maps so I find that
story kind of creepy and I'll tell you
why people have always been judged by
their preferences by the books they read
or the books they want to read but
technology nowadays has allowed us to
identify them more closely than ever
before so ah hi you say don't put your
name city and state on a wish list
that's in public on the web if you want
to maintain your privacy but what if you
could identify those people even if they
didn't put their name city and state on
it what if you could identify them just
by the books they had on the wish list
so that's what this talk is about here's
the whole talk in one slide if you have
to go here's you and a public data set
that's the green can on the left there
and a public data set might be you put
in your books on a wish list or posting
on a blog in a forum and say you're in
some other data set here I've called it
the private data set it doesn't actually
have to be private but you've rated some
books somewhere maybe rated some
movies and suppose some company decides
that they want to anonymize that data
and share it with others say they sell
it or they're a research group and they
anonymize it and release it if you're in
those two datasets with a few
information retrieval algorithms we can
link your data together and that seems
bad so we also ask how can privacy be
preserved in the face of these linking
or RIA denti fication algorithms so
here's a brief outline I'm going to try
to motivate the problem talk about some
privacy risks talk about preserving
privacy in a few concluding words so
this is a talk i'm going to give at sig
I our next week for those of you don't
know that's an academic conference on
information retrieval so I threw the
slide in for those people I'm an
information retrieval why do I care
about this privacy crap well identifying
a user in two data sets is information
retrieval the query is given a user from
one data set which is the corresponding
user and another data set and this query
is increasingly likely as our personal
data becomes more and more
electronically available and I our
researchers should be leading the
discussion of how to preserve privacy in
the face of these potentially invasive
technologies so let me introduce you to
some concrete background that we studied
here's movie lens this is a movie
recommender site you sign up for it and
you go rate some movies you can see some
movies here 2001 a Space Odyssey alien I
hope you can see them and you can see
the ratings on the side there all these
are rated five stars and there's a whole
bunch of other stuff there that I won't
talk about so it started in about
nineteen ninety-five and users rate
movies a half to five stars and they'd
get recommendations and the data is
private no one outside group lens can
see users ratings here's another data
set this one is anonymized it was
released in 2003 it has ratings in some
demographic data but no identifiers and
it's intended for research its public
anyone can download it from the group
lens website
and here's a third data set this is the
movie lens forums you can see here that
I'm Jack's username is posting about
some movies in his post text or her post
text is Citizen Kane the kid Sin City
and we have some technology that looks
through the post text for movies
identifies them up puts underline links
on them and puts him on the side with
some junk some ratings widgets and
recommendations so this these movie
lines forums were started in june two
thousand five and users just talked
about movies and this is public it's on
the web and there's no login required to
read this so we started to wonder can
the forum users who are posting on this
be identified in the anonymized data set
that we released in the last slide so
here concretely are the research
questions because that's what academics
want what are risks to user privacy when
releasing a data set how can data set
owners alter the data set they released
a preserve user privacy and how can
users protect their own privacy we were
motivated because movie lines forum
users didn't agree to reveal their
ratings but the anonymize rating set
that we released in combination with the
form data that they were starting to
provide may have added up to a privacy
risk or violation and more generally if
you had two data sets you might be able
to add them together to some sort of
privacy risk and the question some
natural questions are what kinds of data
sets are subject to these and what kinds
of risks are there so here the data sets
that we're talking about in this talk
we're talking about data sets from a
sparse relation space relates people to
items you can imagine this as a matrix
with people down the side and items
across the top and an ex and the matrix
whenever a person is related to an item
it's relatively sparse that is their few
x's per row and has a large space of
items that means the rows are long so
here's some examples of such spaces
customer purchase data from target
songs played from itunes articles edited
in wikipedia books albums or beers
mentioned by bloggers around forums
research papers cited in a paper Googler
reminded me groceries bought at safeway
friend relationships on orkut or myspace
so we look at movie ratings and foreign
mentions here but we believe that there
are many of these such spaces and here's
here the risks that we're talking about
Rhea Denton is matching a user and two
data sets by using some linking
information so name an address or in
this case movie mentions and I'll just
note that read enta fying it to an
identified data set like one with social
security number can result in severe
privacy loss in 2002 dr. Latonya Sweeney
got some medical records that had been
anonymized for use by industry and
researchers she spent 20 bucks to get
voter registration data for the state of
Massachusetts and she linked those two
data sets together to find a former
governor of Massachusetts so just for
fun let me say that again in Reba's form
20 bucks a little bit of thought and she
got the governor's medical records but
we're just talking about movies who
cares about movies well in 1987 US
Supreme Court nominee Robert Bork's
video rental history was leaked to the
press and although there was nothing
scandalous in the rental history there
must have been enough of a political
brouhaha the Congress spat out the video
privacy protection act in 1988 in 1991
US Supreme Court nominee now judge
Clarence Thomas was asked if he referred
to an actor in a pornographic film to
harass his colleague Anita Hill if
someone had been able to find the
Clarence Thomas rented pornography
concretely that may have adversely
affected his nomination to say the least
the point of these stories is that
people are judged by their preferences
and us laws and
systems I would say or that these
preferences should be private so since
I'm going to be in an academic talk I
have to throw in some related work
people have looked at anonymizing data
sets and Sweeney that I mentioned before
looked at can't anonymity people have
looked at privacy-preserving data mining
and recommender systems and also text
mining of user comments and opinions
which is a technology that we rely on
for this stuff so let's talk about the
risks in more detail we're going to
let's look at the data sets that we
examined and some algorithms that we use
to read n tify I'm talking about two
data sets one of ratings and one of
movie mentions in our forums the ratings
data set is large at least by research
standards it has about 13 million
ratings and the forum mentions data set
is pretty small because the forum's just
started it has a 133 users in a few
thousand mentions and I put up a graph
of the distribution of ratings among
items to show that it's very skewed
there are a few items that have been
rated a lot like Star Wars has been
rated 40 or 50,000 times and there are a
lot of movies that have been rated very
few times like gori gori hallelujah my
personal favorite which has been rated
once the forum mentioned set you've seen
gori gori half star
the forum mentions data set is also
skewed I didn't put up a graph but this
hockey stick the skew we believe is
important for ria denta fication we'll
see why later so let's look at read n
tification algorithms what is such an
algorithm how do we create one and how
well do they do here's a schematic so on
the right side the right can we have a
forum data set and we take from that
form data set a target user t who's
mentioned some movies m1 m2 m3 and so on
we also have a ratings data set the
green can on the left and we pour into
the algorithm the ratings data set and
the target user t and the algorithm
produces a likely list a list of users
in this case u1 u2 u3 with associated
scores and the scores are higher and the
users are higher on the list if they're
more likely to be the target user so in
our case we have both datasets and we
know who the target user is and we can
evaluate these algorithms by where the
target user shows up on the likely list
so to your right there's a likely list
and if T is hanging out at the third
spot on the likely list then we say that
T is three identified and to judge the
algorithms we look at the identification
rate the fraction of users that have
been k identified that are at least on
position K on the list and there's some
fiddling for ties and I won't get into
it and in the paper we look at a bunch
of different values of K but i'll just
talk about k equals 1 in this case one
identification so here's our glorious
linking assumption here's the assumption
we use to tie the two data sets together
people mostly talk about things they
know that is people tend to have rated
what they mentioned and when we measured
this probability and averaged it across
our forum users it was point eight so by
and large true so here's an idea for an
algorithm to read n tify people
the blue circle that represents a user
who's rated one of the forum mentions of
a target and the green circle represents
another one but when you take the
intersection it's a lot smaller only the
users who have rated two mentions of the
target user so here's our first
algorithm just find users who have rated
every movie the target user mentioned
that is ratings users who have rated
every movie that a forum user mentioned
and just give them all the same
likeliness score ignore rating value
entirely the stars half start a
five-star just pitch it this results in
a one identification rate of seven
percent what that means is seven percent
of the time you crank the algorithm and
there's one user and they're at the top
of the likely list and it's the target
user but we noted some room for
improvement for a target user that has
mentioned a lot of movies if they've
mentioned at least one movie they
haven't rated they can't show up on the
list and if they've mentioned a lot of
movies usually no one's on the likely
list so we'd like to loosen the
requirement that a user rate every movie
mentioned and instead score ratings
users by similarity to the target user
we score them more highly if you users
rated more mentions of the target user
and if the ratings user has rated
mentions of rarely rated movies the
intuition here is that Star Wars doesn't
give you nearly as much information as
gori gori hallelujah so here's an
algorithm that all the IR researchers
would be a familiar with so I don't go
into it in great depth it's called
tf-idf and it's a fairly standard way to
search through a sparse vector space
it's often used for text mining we're
not using it for text mining here we're
just searching a sparse vector space and
it emphasizes rarely rated movies for us
if you know tf-idf a word is a movie and
a document or a bag of words as a user
the scores cosine similarity to the
target user and this results in a one
identification rated twenty percent
compared to seven percent from before
but again we noticed some room for
improvement because it seemed to
overweight any mentions for ratings user
who had very few ratings that is when
you looked at the likely list of ratings
users people the top would have maybe 4
ratings as long as one of those ratings
was a mention of the target user well in
our case for ratings means you probably
haven't even completed the signup
process no you haven't completed the
signup process and you're not posting on
the forums anyway so we wanted to
de-emphasize the importance of rareness
of few ratings on the ratings user side
so here's another algorithm the scoring
algorithm it emphasizes mentions of
rarely rated movies d emphasizes the
number of ratings a user has given the
mentions of a target user t-score
ratings users by mentions they've raided
and a user who's rated a mention as 10
to 20 times more likely to be the target
user and there a couple more tweaks you
can see the paper for the mathy types I
put up a few equations you have a sub
score for a user mentioned pair and it's
point 05 if the user hasn't rated to
mention and it's close to 1 if they have
rated dimension and you take the product
of it over all the mentions so here's an
example you have a target user t from
the forums and they've mentioned three
movies column a B and C and you have two
ratings users u1 and u2 they've raided
the user you one is rated a and you tues
rated B and C and I put up their scores
here and you can see that you one has
three terms the first term is high
because they rated a and you to score
the second third terms are high because
they rated B and C and you ones first
score is higher because the movie a is
more rarely rated it's only been rated
20 times you calculate all these scores
multiply them through and in this case
user you two is more likely to be the
target T so in general rating a mention
is good and rating a rare mention is
even better the scoring algorithm
results in a one identification rate of
thirty one percent compared
to twenty percent for tf-idf and notice
we were still ignoring the rating values
entirely so in the paper we look at some
algorithms that try to guess from the
text that you wrote in a movie forum
what you rated the movie we don't
actually build the algorithms we just
simulate them that's what i call them
magic in this slide and knowing the
rating helps even if you're off by plus
or minus one star of 5 stars so even if
you're off quite a bit i'll skip the
details of it for lack of time so here's
the one identification rate of five
algorithms the first three we've talked
about and the next two are these ones
that magically analyze text i'll just
point out the scoring one identification
rate the one in the middle is thirty-one
percent like i said before using ratings
is better but it requires magic text
analysis that we didn't fully implement
and so will use scoring for the rest of
the top here's one more graph for you
along the x-axis is the number of
mentions of a movie in a forum and along
the y-axis is one identification rate in
each line represents a different
algorithm that we've talked about if you
have at least 16 mentions we can often
want to identify you so the probability
goes up 2.6 or point 7 really getting in
there and in general more mentions
results in better identification so what
have we learned re identification is a
privacy risk with simple assumptions we
can read n tify users the scoring
algorithm is good even without any
rating values just with mentions but
knowing the rating value helps rare
items are more identifying and more data
per user results in better
identification so let's try to preserve
privacy by defeating the scoring
algorithm
so research question two is how can data
set owners alter the data set they
released to preserve user privacy so
here are three things the researchers
have tried perturbation generalization
suppression perturbation just means
changing the rating values well scoring
doesn't need rating values that's not
interesting to us generalization is
releasing a data set where users rate
genres instead of movies and you can
perhaps see that that would make the
data set quite different and perhaps
less useful so we decided to look at
suppression in other words don't release
the whole data set hide some of it we
won't modify the form data we think
would annoy people if we went in and
modified their posts on forums so we
focus on ratings data we don't know
which movies a user will rate but we
know that rarely rated items are
identifying so let's try releasing a
ratings data set suppressing all rarely
rated items we're rarely rated as rated
fewer than n times and we look at
different values of N here's a result so
along the x-axis is the fraction of
items we suppress along the y-axis is
the one identification rate if we don't
suppress any items scoring guts this
thirty-one percent one identification
rate you have to drop eighty-eight
percent of the items to protect our
current forum users against one
identification now since we're dropping
rarely rated items first eighty-eight
percent of the items is twenty-eight
percent of the ratings still seems like
a lot of items we also look at how can
users protect their own privacy in this
case is similar to the previous question
but now per user suppose a user can
change their ratings or mentions what
should they do so they won't be
identified we chose to focus on mentions
they control what they say in public as
before users can perturb generalized or
suppress and we studied suppression so
from the previous slide if users chose
not to mention rarely rated movies
they'd want to stick to the 22% most
popular movies that seems kind of goofy
users want to talk about movies and not
just Star Wars so what if a user chooses
to drop certain mentions maybe there's a
forum advisor interface that says you
might not want to mention that or you
might want to mention this other movie
so the idea here is each user suppresses
some of their own mentions and they
start with rarely rated movies because
they're identifying they probably won't
want to suppress very many mentions
because they're there to talk about
movies here's a result again along the
x-axis the fraction of user mentions
suppressed and along the y-axis is one
identification rate suppressing twenty
percent of your mentions drop one
identification rate some looks like to
thirteen percent or something but not
all and suppressing more than one of
five movies that you mentioned it
informs seems impractical so here's
another strategy what if users mention
items they didn't rate that might
misdirect a read n tification algorithm
to look at the users who did rate that
item so let's do that we create a
misdirection list of items each user
takes an unrated item from the list and
mentions it repeat until not identified
so what are good misdirection lists
remember rarely rated items are
identifying here are five lists we tried
the blue line is the most rarely rated
movies the line with the pink squares is
rarely rated but at least 16 times then
we have rarely rated but at least a
thousand times at least 8,000 times and
just popular the most popular movies
first well what we see here is rarely
rated items don't misdirect at all you
could rate 20 of them and you were still
one identified that same rate popular
items do better although this rate
doesn't drop 20 even if you mentioned 15
movies you didn't rate we can still find
some of you so in general it's better to
misdirect to a large crowd you want to
mention a movie
that falsely implicates at least a
thousand or eight thousand other people
in summary rarely rated items are
identifying but popular items are
misdirecting few concluding words what
have we learned well first there's a
real risk RIA denta fication can lead to
loss of privacy we've found substantial
risk of RIA Denton in our sparse
relation space we think there are a lot
of them and we're probably in more and
more of them available electronically
and it's hard to preserve your privacy
the data set owner had to suppress a lot
of their data set users had to suppress
a lot of their data set and users could
misdirect somewhat using popular items
so for future work we'd like to look at
other data sets we'd like to model model
these read n tification processes
mathematically rigorously and we'd like
to look at more algorithms both
re-identification and privacy preserving
algorithms and there might be an arms
race here between read enta fires and
privacy protectors in the same way as
there's an arms race between spammers
and spam detectors questions
have you looked at addressing this by
creating fake users
so the question is have we looked at the
spy dressing fake users we have herb by
creating fake users we have not we do
have an awful lot of users but I suppose
if we created the fake users in a
particular way to hide people right now
that might destroy the data set for
other purposes right if you're using the
data set for recommendations and you
know that if someone likes movie a they
also like movie be but then you decide
to destroy that relationship for the
purposes of privacy preserving then it's
not very good for recommendations either
it's an interesting idea an aggregation
for instead of releasing a list of
anonymous user ID
punch together users so anywhere on say
two to ten you aggregate all the ratings
say this group of people rid of these
movies possibly even have a list of
different three combinations of users
such that it would be very difficult to
reconstruct individual entries from it
with this from client service division
information glory so I'll just repeat
the question for the video and all the
crazy people the the question was could
you aggregate users before releasing a
data set so we so I mentioned in the
talk that people have a strategy called
generalization where the aggregate items
into genres but what about aggregating
users and it seems like maybe you could
I find that an interesting idea we
haven't looked at it other questions if
not well thank you very much for coming
and this is my practice talk for sig I
are so give me please give me feedback
for next week</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>