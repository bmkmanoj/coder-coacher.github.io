<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Verifying Industrial Control Software | Coder Coacher - Coaching Coders</title><meta content="Verifying Industrial Control Software - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Verifying Industrial Control Software</b></h2><h5 class="post__date">2008-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UzGGJWPwi8g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">our first speaker is Colin O'Halloran
and he works at kinetic in the UK and
he's going to talk about verifying
control software ok all right so thank
you John and why am I talking about
industrial control software of all
places in Google what why is it relevant
well control software pays everywhere in
the card that you dry your central
heating system is a very simple
controller aerospace and is there as
best i'm going to principally be talking
about it's in particular flight control
i should say this is work i'm presenting
jointly in my colleagues current
stevenson and phil clayton who can't be
here today but it's it's the culmination
of work that's of a lot of people that's
gone on in kinetic so close verification
will clause stands for control laws in
Zed Zed being a mathematical
specification language what's clause
verification about well put simply at
the moment it's a form of Code
walkthrough but with tool supports to
generate what we call a witness script
now the witness script is basically a
record of how you've stepped through the
diagram and related it to the code heads
the Code walkthrough but the witness
script then itself becomes an input into
another tool which generates if a
refinement conjecture so it's like
faking formal refinement with existing
code in existing specification so that's
why I say it's of conjecture this is
where you're saying the code we
conjecture the code refines a
specification now the task is to
actually prove that the refinement is
correct I'll talk a little bit more
about that so the proofs that will come
out of the refinement conjecture which
will be important to our tool set are
for free that's largely automated
and hence the purpose of this is to find
discrepancy between specification and
code now the specification itself might
be incorrect and we have the examples of
that where we're looking at third party
software so it's not always that the
code is is wrong sometimes bizarrely the
code can be right and the specification
is wrong especially when you get into
industrial development processes which
are multi-nation and say we provide
formal verification but it's we've
largely concentrated on d skilling this
activity so that it can be done by
recent graduates or indeed
undergraduates where we've used sandwich
students who take a between a year
between their academic courses worked at
kinetic and have used this and another
important aspect is it's not about just
the first time you develop the code from
a specification it's also about when you
make changes iterations to the
specification and hence to the code as
well you can largely reuse a lot of the
work that has been done before and
that's very important in this area
because control laws are often subject
to iteration so because it's about
controlling your physical process it's
not until you get behind the wheel of
the car try it out you feel more
actually doesn't feel quite right the
handling of the car and you'd start
tweaking the the controller or indeed in
terms of an aircraft how it handles so
the clause method it verifies code as
implementing a simulink specification so
simulink is kind of a de facto standard
in this area of control systems and it's
a product of the the math works
and the analysis of the specification
and the code is done by procedure by
procedure and then line by line and the
essence of the kind of walkthrough part
the witnessing activity is really
relating specifications signals to code
variables it's very simple activity you
have a diagram like block diagram with
wires between the blocks those have
names and you should say well what name
does this correspond to in terms of a
variable in the code so it doesn't get
much more simpler than that and the
reason why you might think we'll can't
that be done automatically and the
reason why we have this manual facility
to do that is because we look at not
just code that's being produced
generated automatically but also code
that's been produced by people and
people have a lot of variability and so
you need to be able to take that
flexibility into account and that's why
there's a human element to this when
people have reduced the code so it's
very flexible I said the tools support
that we have supports comparison and
those checks for correctness now of
course it doesn't do everything so we
have to make some constraints one thing
is and the very important simplification
is it compares a single model model
iteration of the simulink with a single
code iteration our control system is
basically a loop which continues forever
so you're looking at the code that's
inside that loop and you're comparing it
with a single iteration in the model
doesn't you don't lose any generality by
doing that but it's a quite an important
aspect in point of view of loops we
don't largely don't have to deal with we
do have to to a certain extent but it
simplifies the task quite considerably
we can optionally check initialization
and currently we're looking at a subset
aveda called spark I save not loops
plus a little bit more but if you think
of a spark subset aveda for those are
you familiar with that that is
essentially the code language that we we
deal with we also have to subset the
simulink language as well because
simulink is as a name implies just based
really based upon simulation and you can
transform your simulation for a
continuous real-time control system down
to the point where it's discreet it's
not until you get to that discrete
representation that you can actually use
automatic code generation so again it's
it's natural sort of a restriction to
make when you're looking at verifying
code against the simulink simile
diagrams sa described dynamical systems
and they have block diagrams which
define a function f so the the
functioning input to the function there
is over time as as the output but we
abstract time away so we're looking at
logical correctness and continuous
sampling is the means of providing the
input into the control system so in a in
a simulation-based part of simulink uses
numerical methods to give approximations
good approximations you go to a discrete
version where you're actually going to
actually implement this on an embedded
system in a car or in an aircraft may we
have to be a restricted version over
this numerical approximation for
efficiency sake especially if when you
have hard real-time systems but if you
if you sample the inputs sufficiently
often you get a good enough
approximation good enough to control an
aircraft even an unstable aircraft so
I'm going to launch in now I haven't
talked very much about the technical
details about Klaus us the second part
of my talk
if we have time I'll talk about the
evidence that we generated from a
experiment I was done back in 2001 so
this work he came from assessment of
third-party software for eurofighter now
the requirement for the control system
the flight control system for
eurofighter is expressed in Fortran and
that's the kind of because of the the
how long it's taken to develop the
aircraft so it's a legacy situation so
in like late 80s the experimental data
and model was expressed in Fortran and
that's the stuff that was the starting
point and continued to be the thing
which is maintained as the specification
and from that Fortran you then develop
sa code in this subset of ADA called
spark which is then implemented on
distributed system so it the requirement
is about simulation and getting the the
requirements right for the the control
system the implementation has to deal
with real-time aspects the demands and
because of the the processors that were
used at that time it couldn't be done on
a single processors who had to
distribute it over several processes now
as part of the development process of
course you are point you do a unit test
and you find maybe some coding errors
and you do an iteration and you continue
around that as part of our third party
assessment so we're doing producing
additional evidence from point of view
safety certification the requirement
that was in Fortran was translated into
simulink so that has an advantage in
itself in a sense that the simulate is a
nice paradigm for control engineers to
actually understand what the control
system is doing probably fortune of
course is he mixes software engineering
issues with simulation issues so you
you're kind of moving these getting rid
of the
the software engineering issues about
efficiency of the running the Fortran so
forth and expressing liat directly into
the kind of nomenclature which a control
engineer will be familiar with like
gains integrators delays and so forth
now part of our work is about confirming
equivalence between the manual code and
this simulink representation now most of
discrepancies that we found were to do
with the incorrect translation of the
fortress the simulink unsurprisingly
that's that's a informal or best semi
formal process so when we found a
discrepancy it was most often in the
simulink had not correctly captured what
was in Fortran originally whereas the
code had because that was carefully
developed but we got to the point where
the simulink was more and more faithful
to the Fortran representation until we
started actually finding occasional
errors in the code I say occasional it's
like one potential issue for every
10,000 lines of code that's extremely
good software developments but it was
extremely expensive to do as well this
is for an aircraft where it's unstable
and any sort of error in the code
potentially could lead to loss of the
aircraft so it needs to be done very
carefully it's a very highly dependable
piece of software however we did find
occasional issues so now in 2003 we have
this kind of baseline simulink
representation
and we used the automatic cogeneration
facilities that are available from the
mathworks to generate ADA code in the
spark subset and then perform the same
unit tests after we can after we had
used our techniques to show that verify
the the automatically generated code and
essentially we got a hundred percent
unit test pass now what that means is
that in principle it the software that
we had generated automatically and
verified so there were mistakes in the
automatic code generation that took
place it wasn't perfect it was pretty
good we were able to correct the
automatic code generator in order to
eliminate those those errors by passing
the unit tests its kind of first hurdle
in order to get flight clearance so
that's important hurdle now emphasize
this because what we're trying to do is
not sure that the in this experiment of
the software is perfect what we're
trying to show is as good as the
criteria use for the manually develop
code
so as well as doing this work we took
measurements of the activities that
we're going through and we also have
access well actually an independent
party from outside of kinetic had access
to the data in terms of developments the
manual development process so we're able
to do a comparison against the use of
clause and the automatic cogeneration
facility the cook for the commercial
automatic code generator to be able to
compare the time and hence the cost of
using the traditional conventional sort
of careful development process poor the
flight control system as well as clause
and as you can see as quite as saving to
be made I think sorry yes that's right
yes yes so total person hours so the
question was is the y-axis to do the
number of hours that people take to
develop code and that's that's correct
now we did a repeat of experiment but
also we've extended the technique
somewhat to state flow which is a kind
of sister notation to simulink for
state-based descriptions and again the
verification techniques you use for
state flow is less mature and so it
costs and in terms of time and money a
bit more than clause but it still stands
good comparison so the point here is
that looking at the use of formal
verification form efforts not from point
of view of getting perfect software and
that we making claims that the software
is so much better than conventional
developed software in the sense that's
meaningless in a quantitative way
because you can't possibly measure the
fault density or the failure rate for
software that has such a criticality
there's a certain level about 10 to the
minus 3 10 to minus 4
failures per hour beyond which you can't
measure meaningfully aspect especially
which you're talking about before the
deployment of the aircraft or the car or
whatever but you can meaningfully
compare the cost of using the methods to
pass the same criteria the same bar as
it were so that's what we we have done
and what we've concentrated on so the
message trying to get across here is
that the use of four methods and formula
verification actually you can you can
create a business case why it can
displace traditional methods
conventional efforts certainly in the
high dependability area so looking a bit
more detail breaking it down so for new
code for current this is average is over
a number of projects and is a non amazed
industrial data includes co-production
from symlink and the verification for
new code it's 100 man hours for amending
code it's 54 man-hours with typical
productivity rate of twenty lines of
code per person a day at a maximum now
if you're using clause and they static
analysis tool mal port which looks at
runtime exceptions and again comparing
it like for like four new code rather
than 100 man hours is 29 hours for a
mended code and remember for control
systems you're always iterating and
changing the code it's less than one man
era as opposed to 54 man hours and
that's where you get real huge savings
that's where the killer is in terms of
costs of development of control systems
especially for high dependability ones
and so the typical productivity rate is
40 to 100 lines of code per person per
day but I say it's for the amended code
which is the real essence of the
compelling reason to use these sort of
techniques
so I'm going to give some figures about
the sort of scale of era fication and
the what we found now this is rather old
data we have recently done a flight
control system again a new version of it
but this is from februari 2007 so it's
starting november two thousand six febri
2007 so it's not much in terms of lapse
time the control system is implemented
by 353 schedules subprograms procedures
and includes sir programs called within
the subprogram it's officer procedures
calling procedures we've been the
scheduled overall system that consists
of roughly nearly best part of 34,000
lines of non blank not common ada codes
so it's real code that does stuff and we
found suspected compliance errors
intensive programs we not label them
less definitely as errors because
remember the specification even in
Fortran can get out of step with the
implementation occasionally and that's
important issue to find 305 those some
programs or procedures were completely
verified by Machine proof okay so there
was no human judgment it was sentenced
completely formally by a machine a
server 11 did require some human in
assistance because again we're talking
about manually developed code with human
variability so there were some aspects
of using code style or maybe efficient
algorithms because the hard real-time
aspect of it which we hadn't come across
before so those further 11 also assuming
certain preconditions being established
by previous procedures which were
scheduled before the procedure that we
were
now that left 14 that can say residual
verification conditions that were
discharged by a person so how good
confidence in correctness and when I say
verification edition this is something
which huge and has been hugely
simplified down to the point where the
human can actually make a look at it and
make you a formal in an informal form
will arguing to like pen and paper sort
of argument for why and remember this is
a commercial activity we're doing not we
haven't got endless resources or time
we've got to do it to a time in the
budget hence why we made some
compromises 20 sub-programs had revision
residual verification conditions that
were not provable and that's due to
insufficient information to prove
correct so that might be because the
information wasn't present in the
simunic diagram but it is an actual
assumption that you can make about the
system so we had significant conference
they were correct and for subprograms
didn't have suitable specification to
verify against it was just again another
part of kinetic of doing this
translation from the fortran again
they're doing it to a tight budget and
time constraints and they just ran at a
time i ran out of money in order to
correct this simulink that they had
produced for a silly they would produce
some see me link we try to verify find
that as a discrepancy be able to point
out well actually the simulink isn't
correct in this respect they go back
find that discrepancy correct it but at
some point because it's a time limited
budget limited project they would just
give up on that particular point and
that's reality of what's happened there
with those four subprograms so the 20
just over 20,000 verification conditions
analyzed 19,000 617 fully machine check
proofs so I represents ninety-eight
percent of the verification additions
mechanically verified by theorem prover
and the verification cost is a fraction
of a conventional verification so we get
a high degree of confidence much greater
and you would through conventional
development and verification but at a
fraction will cost and that overturns
the kind of prejudice they had for
formal verification that you n use it
for critical system safety or security
critical because it costs so much is
gold plating well I think what we can
see is that if you bound it scope it and
you automate which you should be able to
do with formal verification then
actually you can reduce the cost
tremendously and it becomes an
industrially usable technique and I say
the real benefit is during a
requirements evolution because you
reduce the time and the costs so the
adoption argument for these techniques
is based on cost not reliability now I
would maintain that you're going to get
much better software to this if you use
these sort of techniques but you can't
scientifically quantitatively show that
for this high dependable highly
dependable software what you can show
though as I say is how much cheaper it
is how much quicker it is and when
you're talking about control systems
where you're you can be iterating time
and time and time again and
time-to-market in automotive industry is
the key issue then actually that's a
powerful business argument for the
adoption or formal verification
techniques now I've talked about it in
terms of control systems but I don't see
any reason why the principal's can't
apply in different sort of areas it's
about identifying a problem domain using
the constraints that problem domain and
perhaps making further constraints but
these are the constraints are adoption
of a programmers conventions about the
sort of constructs that they use or the
modeling language these are the things
that you typically do anyway in an
industrial setting so it's not onerous
constraints like you can impose the sort
of constraints that you would do anyway
for industrial benefit so using that
sort of thing I think
sort of principen be used elsewhere to
drive down costs increase automation
increase confidence in terms of the
software and then the case for using
formal verification becomes compelling
because of the cost reasons our current
work is concerned with rather than human
generated code is automatic code
generation from simunic this is gaining
in popularity Matt the mathworks
themselves are selling more and more
auto coders and has kind of been a wave
of enthusiasm and adoption for code
automatic code generation for models
anyway applied dynamics international
have a a code generator from simulink to
spark the subset I was talking about of
aveda and I say we've been talking to
Adi um in business terms so saying well
actually we don't want to modify your
code generation we want to be able to
check it now the code generator they
have all it has to do is to give us
hints and clues about how it's gone
about generating the code automatically
so it's doing the work it's just putting
in little comments about how it's gone
about doing at what decisions it's made
from that that should be enough in order
to generate a witness script from the
whip script we can generate a refinement
conjecture from the refinement
conjecture we can automatically generate
verification conditions and then check
the correctness of the code that's been
automatically generated so they don't
think there's a lot of we're not paying
them to do this and they're doing this
because it's not a large amount of
effort and the potential return we're
still in process of doing that but we
hope to resolve bottom out there sort of
issues that we were discussing with them
in the next few weeks it's the
determinism the cogeneration that's been
done automatically and the automation
the witness
generation that makes automated
verification possible so in principle
you should be able to press one button
to generate the code from the model that
you have press another button button to
actually automatically verify that code
assuming that aren't any errors and
that's because we've shown that it can
be done largely with a very difficult
situation where you have human beings
going the way they generate code so in a
sense non-deterministic alee generating
code when it's done deterministically
you can cover all possibilities or you
can you can at least learn where you
come across cases where you haven't done
it before and increase the automation
but in principle I can't see any reason
why you can't do it completely
automatically and therefore you get
potentially huge cost and time savings
but so saying as I put up before which
represented sixty percent savings well
they just get blow blow nose because i
say it can there should be just a press
button so i say we've been able to
distill this formal automated
verification facilities to a Code
walkthrough with tool support and with
proof and it's highly dear skilled
successfully used by undergraduates not
graduates and the automation of
verification along with independent
automated cogeneration is a potential
commercial offering and I think that's
important because if we can show that
this works commercially then again it's
not an academic argument about
reliability it is about a business case
for why this should be adopted to
displace more costly and potentially
less reliable development techniques and
V&amp;amp;V techniques so we haven't got time to
go from the second part of my talk which
is talks about simulink and takes you
through an example of witnessing and how
the verification conditions are
generated goods a bit more detail but I
can take questions if you want to talk
to me offline and then be delighted to
take you through the kind of principles
where r need questions at this point
question so you said one of the main
benefits of your approach being able
maybe should we do all the question okay
we all want to hear is consign okay so
the question said you said that one of
the main benefit the approaches that you
can reuse your results as the
requirement change or is the code
changes and so on so how does that reuse
work if you have automatically generated
code suppose that I have some code I
start from some kind of spec
automatically generate the code I do
some proof which is mostly automatic I
still need to do a few things manually
now I make the change in the original
code now you know this the compiler or
the translator that generates the actual
thing can get something completely
different so how much of reuse is then
possible if you do have this translation
okay that's a good question so I think
in practice you wouldn't reuse for
automatically generated code and
automatically generated information for
the witness script but in a sense it
doesn't matter because you can just are
you're talking about manually changing
the code that's been authorizing
generators aren't you Oh in that case
then it's perfectly fine because if you
change the model which is what you
should do change the model rather than
the code then you use the automatic code
generator which will automatically
generate the witness script for you so
you're not reusing but you're not losing
any time or in terms of because it's
been done automatically
yes when you have an automatic code
generator it's just at the level of
model what I was talking about
previously was when people human beings
are developing the code and then you
because there needs to be human
intervention because of that that's
where you can take advantage of the just
modifying part of the code means you
just have to modify part of the witness
script and that's been our experience
but when you're using automatic code
generation this is why it's so great to
use it you just it just generates
everything automatically anyway sorry
Andrew was high so this is maybe
slightly at the scope but in terms of
cost so one of the costs if you move
between applications and that's what you
want to do in the future the beer a
maintenance cost in terms of your proof
infrastructure yes the infrastructure
that supports automatic proof yes could
you see something about that yes so
we're a great interest of mine is not
just about the automated verification
now it's about the expertise you would
need to maintain if the code generator
changed all and that would require new
proof strategies or tactics to be done
now again you can still see how
commercial business can be made out of
that because if you have sufficient
number of automated verification tools
out there you sell enough licenses it'll
maintain the call expertise and order to
be able to do that what I'd really like
to do is be able to use the sort of
techniques that come from AI to be able
to do proof planning and proof
maintenance so you often don't see that
the code changes that radically in terms
of the especially if you're using an
automatic code generator that will
evolve they won't make a big change you
get different versions and it'll
gradually change now what you would like
to do is to
have a approved planning facility and
there's work in Edinburgh for example on
that sort of thing which I would like to
adopt to be able to kind of track those
changes and adapt the proof of the proof
tactics and crew strategies as the code
base evolves so the proof strategies
evolve as well so I see that's that
would be a significant thing to do to
drive down the costs even further for
the future I was wondering about the
verification and validation of the
automatic code generators is that
something that that you are the code
generators things that you write or are
you buying them from third parties and
how confident are we in in those I guess
it's it would be similar to like a
compiler the amount of time the amount
that the extent to which you could be
confident of the compiler exactly right
I mean that's the beauty of it is that
we're not producing any special
automatic cogeneration facility
ourselves we're taking third-party
commercial code generators and adding
that assurance so it's like it doesn't
have to be reliable at all in in a sense
because from point of view dependability
it'll just use these techniques added in
and he'll say well the code doesn't
match the model this this automatic code
generator is rubbish so you wouldn't use
it for commercial reasons because you
know you'd never actually get to market
of course in practice companies who sell
code generators like this like the math
whiz I course do a certain amount of
validation certainly sufficient to that
it works most of the time but in their
business models of course they can't
afford to spend all that money for
specially certified code generators and
the beauty of this is it doesn't cost
them anything except for recording the
sort of steps that are taking in terms
of doing cogeneration which they're
doing anyway just recording it making
that available externally and be able to
use that information to use a facility
like
this does that answer your question okay
I have a little additional question to
that if the code generator would have
been proven correct it is it then
necessary to go through the entire
procedure as well you applied or would
it be sufficient that the court
generator is correct in principle if the
if you've proven the Chi generator to
correct then you wouldn't need this
technique but again the beauty of this
is that if you're you can produce the
information and then a very little cost
to do that then why not use this as well
it doesn't cost you anything it should
be just click of other button now my
problem with proving code generators
correct is that if you want to change it
then there's a lot of effort and cost
involved in doing that and that has
we've seen that sort of thing in the
past we've compilers so that it's been
shown that it can be done but then the
language changes because it involves
every ten years now in the in the
commercial world of simulation models
and so forth they can change every six
months and so that means that you I've
have to lock it into a particular
version of the modeling language a
cogeneration and an automatic code
generator but you're right technically
that is a viable thing from a commercial
point of view it's more difficult okay
thank you very</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>