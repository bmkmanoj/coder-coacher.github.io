<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A perceptual space that can explain the robustness of... | Coder Coacher - Coaching Coders</title><meta content="A perceptual space that can explain the robustness of... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A perceptual space that can explain the robustness of...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4KDL-Cjs6NU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">today we're very happy to have Roy
Patterson from the center for the neural
basis of hearing at Cambridge University
Roy has been a in my impression a
leading light in the hearing research
business for a very long time we've
known each other for quite a while and I
could tell you some stories but this is
not a good time for that I guess so uh
let Roy tell his stories Rory take it
away thank you like to be here I think
this microphone is is working okay well
I've given you a slight and not quite
knowing what the Google audience would
be I've given you a selection of titles
the topic is there there is size
information in sound you can tell the
difference between a child and adult and
you need to normalize for that in order
to communicate so that's the first title
the second is my aunt my description of
how the auditory system does this it
produces a scale shift covariant
auditory image and the auditory image is
just like a visual image if you open
your eyes you see an image similarly if
you just when you wake up you open your
ears and if there's sound there your
auditory system makes an image of it
automatically and that's the it's the
processing that goes from the sound to
that initial image that I'm trying to
characterize and finally for a speech
community making speech recognizers
family friendly I'm just referring to
the fact that if you trained to
recognize her on a man it won't even
understand a woman let alone a child and
it's the children that actually know how
to make the technology work so you
really want the child to train the
recognizer so that you can use it and
this is my idea of making recognizers
family-friendly ok there are a lot of
people involved in this research so I'm
representing quite a large group of
people doing research these up here are
the postdocs that are currently in my
lab all of them working on this two of
them have just got good jobs elsewhere
but we still keep them on the list
because they're working with us and
we have four students one of whom is
here Tom Walters we also have two
well-known Japanese colleagues who are
intimately involved Hideki kawahara the
father of the vocoder straight which
you're going to hear about and Tasha or
Reno who works with me on all of the
wavelets and Mellin transform and size
stuff so you may not know them but you
may want to so the overview is that
there is size information and
communication sounds in speech music and
animal calls humans can extract the
content of the communication without
being confused about the size of the
source and humans can extract the size
information without being confused by
the content auditory perception is
amazingly robust to variability in
communication sounds and these size
changes change the sound of law machine
recognition systems are not robust to
size variability even when it's a singer
single speaker in clean speech okay so
how does the auditory system do it and
can we capture in algorithms and make
them useful okay so I'm going to start
with the size information what you need
to know about the size information
communication sounds and how people
perceive it then I'm going to tell you
about we've developed a little
recognizer to equate machines and humans
on a certain task so that we can
demonstrate the robustness of humans and
to give us a measure as to how the
machines are doing and when they're
improving and then we say okay can this
auditory representation be used to
produce better features for the
recognizer and in the end I'm going to
tell you that it looks promising site
information communication sounds okay
the sounds that animals use to
communicate at a distance to declare
their territories and to attract mates
the important stuff in
lives are typically pulse resonance
sounds which means that the animal
create finds some way of producing a
pulse typically by banging too hard
parts together the pulse marks the start
of the communication the energy goes
into the body of the animal and that
object then resonates and that resonance
is attached to the back of the pulse and
that resonance tells you about the
structure and the size of the animal and
it's that simple trick that the animals
are using okay so an animal of interest
to us the human the information in
speech sounds the you have vocal cords
at the bottom of your throat they
vibrate and interrupt by interrupting
the air flow from the lungs and produced
a stream of pulses those pulses excite
resonance is in the vocal tract and the
shape of the vocal tract the place where
you put your tongue determines the
resonance and thus the vowel type and
but in addition vocal tract length
determines the rate at which those
resonances run and this is the new
variable that I need to draw your
attention to so if you have a large
person with a long vocal tract and then
you have a small verson person with a
small short vocal tract they can
actually say vowels with the same pitch
and they can put the vocal tract in the
same shape so that you hear the large
person and the small person saying the
same thing but you can still tell which
is the big one and which is the small
one because the difference in vocal
tract length produces a difference in
the rate at which the resonance is
behind the pulse run so here's an
example in this slide there are six
copies of the vowel aw and over here and
it's always the vowel aw and you can
tell that because the resonance after
the pulse is the same shape in all six
slides all six waves over here the
pulses
come at an increasing rate so over here
we have Oh can we turn that up a touch
no not that way oh so that's a pure
pitch change and that's very simple i
can do that aah over here notice that
the pulses come at the same rate in all
three of these so the voice pitch is the
same over here and the vowel is the same
it's the same shape but over here as we
go down the resonance runs faster the
peaks occur faster okay and here you get
0 and that is the sound of a pure vocal
tract length change oh ah I can't do
that one oh that's the dimension we need
to go after okay now animals typically
all modern animals communicate with what
we call communication syllables so
animals put out their pulses in bursts
and each of the pulses carries the
resonance behind it so you get lots of
coffees of the residents in a pulse
resonant sound so here's a human
communicating with pulse resonant sound
ma ma and here's a macaque and another
very successful communicator and this is
a fish and I include the fish because
they probably started doing this as much
as 500 million years ago and they do it
with very different mechanisms but
they're do using the same trick pulse it
with resonance is attached they always
seem to be at about a half-second long
as well alright so that's pulse
resonance communication so what you need
to know about communication sounds is
that in the communication sounds at the
syllable level I mean there are larger
issues there's syntax and
and semantics and prosody but just down
at the level of the individual sound the
syllable there are three kinds of
important information in communication
there's the resonance shape and that's
the message there's the glottal pulse
rate that's the pitch and there was the
resonance scale which tells you how big
the speaker was so in animals they all
grow and all animals use evolution
invariably uses parts of the body that
are already existing to make the sounds
in our case it uses the tubes from the
noses and mouths to the lungs and the
stomach and as you grow up those tubes
have to get longer to connect you to the
outside world and so there must be size
information in animal sounds and this is
true of all animals and so it's an
important problem for animals to be able
to generalize across sounds and
recognize that the new sound which is
physically different is actually just
the same message being carried on but by
a source produced by sources oh you are
very so the bush cricket is the one
animal that has learned to make a
sinusoid and it makes a 4 kilohertz
sinusoid with a patch of its wing and it
doesn't communicate till it's full size
adult so it's one animal that has very
little size information they could pick
another animal
yeah you know they have to syria's they
have one on each side but if we just
take one at the time then the syrinx
does have a vibrating source that
interrupts the airflow Oh what about the
minor bird so Burt well so the first
point is that birds are much more exotic
than us they have a voice box in each
break francium so and they actually the
songbirds have a brain that allows them
to play one play the other or play them
as a pair so all of that aside in in the
syrinx is a flapping membrane that is
producing pulses and those pulses are
exciting the vocal tract now in the
birds you have three sections of the
vocal tract just above the syrinx and
then you have the throat and then you
have the mouth but in birds the mouth
often includes the bill so it's
complicated but it is the same kind of
sound
I think the issue is just I mean there
are more variables there I'm just giving
you three of the simple ones yeah and
these apply but then there are more we
had a student project on it but I'm
trying to remember or they can't okay so
this is true of human speech that they
use pulse resonance sounds and it has
this three kinds of information of the
syllable level it's true of animal calls
mammals birds fish frogs it's true of
grasshoppers actually and shrimp it's
true of most musical instruments most
musical instruments when you look have
pulse of excitation and that resonates
in the body of the instruments so it
appears that certainly in the sustained
toned instruments of the orchestra that
we have chosen sound makers for which we
already have an analysis mechanism but
that's another another topic and of
course engines have explosive pulse of
excitation and as you know any any good
mechanic will listen to the car for a
while before he takes it apart and you
can probably tell a fair bit about
what's wrong just by listening all right
this they stand in contrast to the to
the inanimate sounds produced by
turbulent air and turbulent water in the
natural environment wind in the rain
wind in the trees rain on the roof
waterfalls and such and maybe 500
million years ago animals started using
pulse resonance sounds because they
stood out against the natural background
but that's another story another long
story alright so that's all you need to
know about the size information in
communication sounds as you as you get
bigger your pulse rate will go down
because your vocal cords get longer and
more massive and as you get bigger the
resonances will ring slower
because they have more mass essentially
and this is just a very general
principle in sound production okay now
what about the perception of
communication sounds I've said we're
robust I just want to draw your
attention to a few experiments that
we've put in the literature to prove
this all right so what I'm going to
present you here we now have thanks to
Kyle Harrison and arenas on we have a
computer application that can take my
recorded speech take it apart cycle by
cycle and then change the glottal pulse
rate and change the vocal tract length
and recent the size and this allows it
to nice control experiments where we
have very good control of glottal pulse
rate and vocal tract length while
preserving all of my individual speaker
characteristics if you want to do
experiments this is the tool so here all
of us most of the slides i'm going to
show you have glottal pulse rate on the
abscissa and vocal tract length or some
other measure of resonator size on the
ordinate and here the glove of the pitch
is going up and the and the vocal tract
length is going down so I'm going to
present you sets of three speakers who
differ in pitch and vocal tract length
and each one of them is going to say
three syllables and your task is to say
whether the three speakers are saying
the three same three syllables okay so
listen carefully mo FIFA mo hae far mo
84 mo 84 mo ba MO he saw its trivial the
change in size from a young boy to a
teenager to a large adult is absolutely
trivial for you so you may think you've
learned this because you have a lot of
experience with children and teenagers
and adults but I have some other
speakers here who which have
combinations of glottal pulse rate and
vocal tract length which you are very
unlikely to have ever
heard okay a very short vocal tract with
a low pitch and a very long vocal tract
with a high pitch same person in the
middle try this one whoo ha whoo ha whoo
ha trivial whoo ha whoo ha ha and we can
do it with a fixed vocal fixed pitch and
a changing vocal tract length ray oooo
song ray who song ray Putin song so
that's the size component of the
perception that is specific to vocal
tract length and there's a component
specific to pitch No hey Z nah hey Z nah
hey Z however the point is you are
amazingly robust to this so that's the
that's the audio demo and and you're
also very good at telling what the size
of the speaker is i'll come back to the
recognition problem in a minute well
maybe i'll do it right now ok so your
robust to changes in size we took the
five vowels are a e 0 and 0 spoken by me
and we use this magic programs straight
to scale the glottal pulse rate all the
way from my normal 110 all the way up to
640 and down to 10 hertz below the lower
limit of pitch where you're hearing
individual cycles and we scaled the size
from my size to half my stew double my
size and half my size which is an
enormous range and we said to the person
on each trial here's a bowel which of
the five vowels is the person saying and
they had to choose one of five ok five
alternative course choice task now let
me just point out these are the mean
data and this ellipse here shows you the
combinations of vocal tract length and
and pitch of ninety nine percent of the
people that you have ever heard
their combinations are all here so small
children are here and women are here and
men are here and very large men are here
so they're all in there so when we go
beyond that you really have not heard
speakers of this type before so how do
people do well this is just a very
simple task for their perform the fifty
percent chance which is d prime of
statistical measure of the fact that you
can do this reliably is this black line
which is barely in the picture and for
all of the yellow and orange and red you
can do this task well way above chance
and I think this dark color is about
ninety-five percent and you can do it
all the way down to below the lower
limit of pitch you're just amazingly
robust to changes in size now so that's
to say that you can get the information
about the message independent of the
size of the source at the same time
you're peeling off the size information
in a useful way you could Sorry Sorry
okay so we took the same set of vowels
and the very blood will pulse rate and
vocal tract length and we played single
vowels to people and said how big is the
speaker from very small one two very
large seven people are consistent if you
give them a low glottal pulse rate and
long vocal tract they say that's a very
large person and if you give them a high
blood will pulse rate and a short vocal
tract they reliably say that's a very
small person the two dimensions both
affect your perception of size in that
both of these come down and they
interact the site the surface is not
simply a plane so as you go up in pitch
it's fairly linear in in log global
pulse rate and open over for vocal tract
length in the range that you have
experience with it's fairly flat then it
goes quite steep when you go to the
normal range suddenly people start to
sound really quite small quite quickly
but it's a stable source okay and
another experiment to make it more
speech like would produce the syllable
database and this syllable has consonant
vowel syllables and has valve consonants
syllables and the consonants are the
three main groups sonorant stops and
fricatives five six of each and the five
Cardinal vowels are a e 0 and 0 and that
gives us 180 syllables plus five vowels
and we use that to do some
discrimination experiments which I'll
tell you about a minute so we will if
you take normal recorded syllables and
just play a sequence of them it will
sound irregular and so these syllables
have also been what we call p centered
to basically focused on the vowel onset
which when you play them in
sequences makes it the rhythm sound even
so then we can draw randomly from this
database and get sequences like me no.8
so who's me a car aight so boost alright
so straight produces very very high
quality vocoding and we run in
experiments like this so we do
experiment since in psychophysics and we
have to be very careful that there
aren't any extraneous cues that you can
use to do the task so if we just took
two vowels and said which of these
speakers is larger as a matter of fact
if you're using a log frequency scale
and you have three formants as the
person gets larger that spectrum moves
as a unit towards the origin so if you
could just glom on to one of the
spectral Peaks and follow that and
compare that spectral peak between the
two intervals you'd be able to do this
task that the task is sorry we're gonna
present two intervals you have to say
which speaker is larger so we make the
spectral cues we scramble the spectral
cues very badly and we do that by
choosing a selection of syllables at
random from that database for them and
we present those in interval one and we
give them a pitch contour that is
reasonable for speech which and the
pitch is also moving the spectral
components all over the place and then
in the second interval we select four
syllables again at random and we give it
a different pitch contour so there
really isn't any pitch cue that you
could or spectral cue that you could
carry and compare between these two
intervals however in the first interval
all of the syllables were constructed
with the same vocal tract length and in
the second interval all of the syllables
were constructed with that vocal tract
length plus a bit or minus a bit and you
have to say which one was larger so
ready
ma 8qu um say-on-pay hua ma 8qu mom say
ohm Katie wha which interval had the
smaller speaker one person got it wrong
but I won't say who ma aite koo um say
ohm hey wha ok that's about ten percent
change in vocal tract length and after
two minutes training most people are
close to one hundred percent on that
it's a very natural thing you just bring
people in and say the speakers are
different size tell me which one's
smaller and we do that experiment and we
do it for 55 different starting points
large male small male small child
castrato and dwarf the same ones i've
been using all along ok so now that
these are five psychometric functions
for those positions and you start off
here with a certain vocal tract length
and you compare it to vocal track links
that are longer and if soon is there a
bit longer than you go to one hundred
percent on which one smaller and if we
reduce the vocal tract size then you go
to zero percent on the smaller one
because you're choosing the larger one
all right I'm you're inverting the
choice anyway the point is that as you
change the vocal tract length away from
the starting point people rapidly can do
this task reliably this is true for all
five of these speakers doesn't seem to
matter where you start and the slope of
the psychometric function is about the
same in all cases so we can create a
statistic that psychologists call the
just noticeable difference that is the
difference you have to make on a
dimension for it to be reliably
detectable and we do that by saying
what's how much vocal tract length do
you need to raise the percent correct
from 50
275 all right and that's statistically
well defined as a B prime of 1 well it's
a little more than D prime of 1 so if we
do that what we find and now I'm showing
you the data for all six of the
different kinds of consonant vowel and
vowel consonant syllables separately but
it doesn't really matter but that's just
why there are six points on each of
these and this line the fixed this fixed
line is five percent in each of these
data plots and what you can see is that
for the small male the large male in the
castrato with the longer vocal tracks
these three you need about a four
percent change in vocal tract length in
order to reliably tell whether the
speaker is larger or smaller and for the
shorter vocal tracks you need six or
seven percent but you know on average
you need a five percent change in the
size of the of the resonators the size
of the sort of told your vocal tract
length is very highly correlated with
your height so when a five percent
change in height will produce a five
percent change and vocal tract length
and it's acoustic scale of the vocal
tract that you're detecting now why is
that important that means that so this
supports the idea that you have access
to the acoustic scale dimension in the
brain and you treat it like a dimension
the just noticeable difference for a
loudness of a sound is ten percent ten
or eleven percent the just noticeable
difference for the brightness of a
diffuse life is fourteen percent the
just noticeable difference for the
duration of a sound is ten or eleven
percent so five percent jmd is a very
good jmd for perception it's not as good
as pitch and it's not as good as visual
acuity but it's a very good J&amp;amp;D
you can also do these experiments with
musical instruments we published a paper
and jazzy on the horn strings would
woodwinds and voice but I don't really
have time for that today okay so that's
the first point so I've told you about
the form of the size information in
communication sounds and I've told you
about the perception we're amazingly
robust we seem to be able to take these
sounds apart and why is that surprising
well let's go back to these sounds and
look at their magnitude spectra so if I
take the Fourier transform with a
windowed Fourier transform and integrate
it and produce a spectrogram one these
are slices of the spectrogram or
magnitude spectra and when you change
the pitch oh you change all of the
frequency components and all other
amplitudes I mean you just move them all
over the place and when you change the
vocal tract length oh no it is actually
the case that if you really have a fixed
pitch when you do that it would be the
same frequency components in your
spectrum because they would all be
harmonics of one fundamental but all of
their amplitudes change and normally you
have a combination of these two so the
spectral components are just moving
around in a dizzying way but there's
something about the pattern of them that
the system can detect okay so really
they're being scaled in but scaled in
two dimensions glottal pulse rate and
vocal tract length and recognizes have
trouble with this now to illustrate this
humans find it hard to believe he would
believe in recognizers and they think if
you train it on one person they'll be
able to recognize another because we can
so that we needed to test that so we
took the syllable database and we did an
experiment with humans that is we we
made we took the syllables and we
produced people with all of these
different combinations of glottal pulse
rate
and vocal tract length okay loads is
Bates they've made 56 people and we
trained humans on sorry we trained
people's people on the one at the very
center of this blue spot and eight
others in this blue spot okay but
basically we trained it on train them on
people of one size and we had to train
the humans training for the humans means
learning to loot use this GUI where they
we would present them a syllable and
they had to tell us which syllable had
been presented okay and they have to
learn the funny way in which we're going
to use the civil syllables mah may mee
mo mu and they have to learn to find all
the positions and that's basically what
they're doing is learning to use the GUI
sorry on this and then without any
further ado or any further training this
is where those voices are in the normal
space so here are here's 99% of the men
you've ever heard ninety-nine percent of
the women and ninety-nine percent of the
children this is where the voices are
that we were using and we just all of a
sudden started presenting instead of the
person at the center we presented people
at the ends of these spokes so suddenly
the size of the person is changing
dramatically on every trial at random
and it makes almost no difference to
humans that doesn't surprise you but I'm
saying this is our measure of robustness
you can train on one point test on any
points in the space and it hardly makes
any difference it is the case that the
end of this spoke three and seven which
are the most unusual voices your
performance is a touch worse but that
really is a small effect and this is 20
observers with a very large number of
trials alright keep that in mind that
doesn't surprise you but maybe
should we took an hmm recognizer a
hidden Markov model recognizer and you
need about three emitting stages for
recognition of syllables and we used
mfcc features so this is a pretty much
an industry standard kind of recognizer
set up to work on our syllable database
clean speech single single syllables and
we train the recognizer on nine voices
in this blue region here and when the
recognizer was trained so that it was
producing this is error rate so that it
was producing an error rate of zero on
the syllables that had been trained on
we then started to change the vocal
tract length on the recognizer and
immediately as you go away in vocal
tract length the error rate rises
rapidly and took to a disastrous level
okay so recognizers are not robots to
extrapolation if you take this same
recognizer and train it on half of those
voices from all over that region and
then test it does very well does 95% if
it has seen all of the data that it has
to work on so it can interpolate between
data between voices that it has learned
from it can get the one in the middle
between them but it isn't any good at
extrapolation and as you saw in our
recognition experiments humans can
extrapolate way beyond anything they've
ever heard all right
so the auditory system appears to adapt
to the pulse rate of and the acoustic
scale of communication sounds
automatically as if we have a transforms
on what I'm proposing is that you have a
normalizing transform in the system
before you try and do the recognition
and the processing appears to produce a
speaker size invariant representation of
the message which is very convenient so
how might the auditory system do this
all right to explain this and I'm so
what I'm going to do is take four sounds
and take them through several stages of
the auditory system to see if we can get
them all to be the same in the sense of
the message being the same and i'm going
to start and these are all to format
vowels and in both in all cases the
formants are just damped resonances and
they are all scaled versions of one
another so it's exactly the same object
in different sizes and I'm going to
start with a long vocal tract and a low
pitch here and then I got one where you
have a long vocal tract still but you
have a higher pitch and in fact an
octave higher and then a short vocal
tract and the low pitch so the pitch is
that is the pulse rate and the vocal
tract length is the resonance rate so
this one rings faster than this one and
then finally the combination of short
for direct and high pitch so I've got a
2 by 2 in which both of these crucial
dimensions are varying now I take those
four sounds and I put them into an
auditory model this is my favorite
gamitin auditory filter Bank but you can
use almost any filter bank to do this or
any wavelet transform the auditory
system is really performing a wavelet
transform in which the colonel scales
with the carrier all right so down here
this triangular shape here is what you
get when a lottle pulse strikes a simple
resonator it rings for a while okay and
here is the second
Ormond and it rings for a while it's at
a higher frequency it happens to ring
for exactly the same number of cycles
but since you're at a higher frequency
the cycles go by faster so it dies away
quicker all right and that's the form oh
this is the form of a size change in
this representation the object moves up
and trains so if we move to if we
shorten the vocal tract and we're on a
logarithmic frequency scale here
logarithmic frequency or acoustic scale
then the the shorter vocal tract
transforms both of the formats
proportionately so they move up as a
pair on this scale and they both shrink
again they have the same number of
cycles but you're using a different
acoustic scale to represent them so
there's their shape changes they are not
sizing variant in this representation so
what can you do what could you do to fix
this well the obvious thing is to just
change the frequency dimension so that
you pull the cycles out so that you've
got the same number of cycles in each
case I just want to take this one and
pull it out to there and for these up
here and say I want to pull them to the
same point because then I know they've
got the same number of cycles in and the
question is can you do that in general
and the answer is yes mathematically you
can what you have to do is take your
time dimension and in each channel
separately multiply time times the
center frequency of the channel and
frequency is increasing as we go up so
as we go upward we're steadily expanding
the time dimension and if we do that to
this representation we get this
representation this is expanding neural
activity pattern and I probably should
have said this is the kind of
representation we think you have at the
output of the cochlea flowing up the
auditory nerve to the
their nucleus we call it a neural
activity pattern and here is an expanded
neural activity pattern as if the
auditory system treated time differently
in each channel and you can see that
that has successfully converted these
two resonances which we know are the
same kind into the same shape in this
space and it's also converted the ones
in the shoulder shorter vocal tract into
the same pattern and pitch doesn't
matter to this representation because
this is really the ringing of the vocal
tract and it doesn't matter what the
what the period of the vocal cords is
unless the period of the global pulse
period gets to be shorter than the
ringing of the formant and actually in
speech that does occur but that that's a
separate problem but I'm not trying to
hide it okay so this is very nice we now
now have representation in which the
message is the same for all four of our
different sounds the only problem is
this representation is not time shift
covariant that is when we get to the
second cycle we find that our expansion
has messed it up first of all it's it's
put the glottal pulse line it's twisted
the glottal pulse it's shifted the
glottal pulse line over and secondly
this is a log so the dimension is the
log of the number of cycles of the
impulse response and because of the log
its compressed it in the second cycles
so successive cycles don't appear in the
same form and that's not very good but
what we actually think is that the
auditory system restarts time on each
new glottal pulse so when it gets here
it really flips back and puts the next
cycle it's really measuring time from
each glottal pulse
and as long as it does that then it will
find all the floral circles there
there's not much change between
successive cycles and it's going to plot
them on top of each other and we call
that stroke temporal integration and you
have to do that little sooner if the
pitch is higher but it's it's not really
a problem so if you do that you then get
a representation where the cycles are
all falling on top of each other as long
as the sound of stationery and this we
call the scale shift covariant auditory
image it's a nice stable image it's an
image in which change occurs if you hear
a change and change does not occur if
you don't hear a change which is not
true of neural activity patterns so in
this image what happens well you have
your two formats and they are now the
same size and and you can see that it's
the same format and if the size of the
person changes this pattern just moves
vertically as a block so its scale shift
covariant because in the representation
you still have the message and you have
the size information and they are both
there they covary so you have both kinds
of information still in there but now
you've got them in a nice orthogonal
form because that pattern just moves as
a block when you change the size if you
change the pitch nothing happens to the
message it just stays where it was what
happens when you change the pitch is
that the terminating line for the
glottal period changes so actually if
you have a noise then you can have
activity and all throughout this entire
image as soon as the sound becomes
periodic in the way that speech does
with plural pulses then you can no
longer have information down here so
when a when a periodic sound comes on
suddenly you lose everything below this
diagonal and the diagonal tells you the
pitch so now you have the three elements
vocal tract length glottal pulse rate
and the message
separated and represented in an
orthogonal form all right and this I
think and a number of people do think
that this representation of what you
hear is a better representation because
here the message is our and it doesn't
change the fact that the child chooses
to say it and an adult chooses to say it
that doesn't matter it's the same
message and whether they're a child or
an adult is determined by where where
the pattern appears and where this
terminating line is okay so can we make
use of this so we remember that we train
the hmm recognizer on a syllable
database and if we have one speaker and
when we change the size it had a problem
what happens if we take features from
the scale shift covariant auditory image
so if we make spectral profiles just add
across the auditory image you get this
green line in here in behind so to that
knowing that what we were looking for is
3-4 months we fitted three gaussians two
spectra as they came along and we use
those features instead of em FCC's for
the recognizer and we did one more thing
we know that this set of three formants
will move back and forth when size
changes so we did what speech people
from kathy ama and font forward have
told us use formant ratios it's the
format ratio on a log scale that is
fixed so we gave it difference of the
galaxy ins we gave it the heights and in
total this gives you somewhat fewer
features than the mfc features that you
would normally use like about a dozen
and in this case when we take the same
recognizer operating on the same
database and have it work on mixture of
gaussian auditory image profiles then
when you train it on this speaker here
and then you change the vocal tract
length the error rate does go up a
little as you move away from the
training vocal tract length but it stays
at a reasonable rate in comparison to
going up to a hundred percent error
alright so we think that these features
are more invariant and they capture the
information in a more useful way and
from the auditory point of view we argue
that it's a better representation of how
you here so in summary there's size
information communication sounds and I
told you about the perception of
communication sounds humans are very
robust machines are not when you develop
a measure that allows you to compare
them and I've shown you how we can take
auditory models and extend them to
produce a scale shift covariant
representation and that does indeed help
recognition in this environment so
currently to finish off the databases
for recognizers currently have thousands
of hours of information in them from
many many speakers and they take
thousands of hours to train because
there's so much information in the
database to make them robust we think
what's the problem there is you're
actually having to find enough different
speakers so that the recognizer can hear
every syllable you want it to recognize
with every different combination of
glottal pulse rate and vocal tract
length so and we don't think the
auditory system has to do that and this
is the way the handler
yes
exactly the answer is we don't know the
prediction is obviously I'm sorry sorry
repeat the question what would happen in
your database you make a database of a
large number of speakers because you
want your recognizers we speaker
independent what if you took all those
speakers and then scale their speech to
a large number of different combinations
of lotto pulse rate and vocal tract
length and we think that's a great idea
and we haven't yet done it you're
actually seeing our research up to about
a month ago so that is exactly what we
want to do and we've been looking for
some laborator to do it with so the what
our prediction has to be that you can
reduce the number of speakers in your
database and get higher recognition at
the same time and it should take less
time to Train recognized so we have a
strong hypothesis and we're dying to
know whether it's right so your
representation that he did recognition
on this actually comes down to detect
informants using their ratios
do you need your auditory image as a way
to get to that or do other kinds of
forming detection just going to do as
well and the answer is we don't yet know
let's see if i could find so this was a
quick thing to do that everyone would
understand was to take the spectral
profiles of this image I know what I
want to do I've got another slide here
somewhere
or have I
so these are those same scale shift
covariant auditory images tart it up but
to publish in a trendy journal but these
are the same patterns you saw before
with the same Terminator the thing is on
this slide I've actually plotted the
profiles so that you can see that the
spec these are the spectral ones that we
use to find formants down here is a
temporal profile the temporal profile is
actually scale shift invariant and so
what we where we expect to make some
more progress is to use this one to
constrain the syllable search it appears
to contain information like the
difference between front vowels and back
vowels so the image started the answer
to your question do you need to use the
two-dimensional image we haven't proven
it yet but we think that the information
in this temporal profile which you don't
have in a spectrogram will also be
useful we have to figure out how to
comply to bring this information in the
temporal profile together with the
information in the spectral profile but
but the answer the question is we don't
yet know
I they will be I mean we can leave you a
copy to go with the talk if you like</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>