<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Crawljax - A Tool for Automating Web Application Testing | Coder Coacher - Coaching Coders</title><meta content="Crawljax - A Tool for Automating Web Application Testing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Crawljax - A Tool for Automating Web Application Testing</b></h2><h5 class="post__date">2009-12-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rYAO94GnBlY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">&amp;gt;&amp;gt; 
ROEST: Okay. Welcome everybody. My name is
Danny Roest. I'm an intern from the Delft
University of Technology in the Netherlands.
I'm an engineer and I've worked here with
my greatest--testing Crawljax on the new essence
[INDISTINCT]. Okay, wonderful. Remember this,
techno-building public, the questions after
I take the first question it should only be
general so that I can answer it with the specifics,
okay? So, what will I be talking about at
this presentation? First, I'll give you some
introduction about Crawljax, sort of what
is it, what can it do. And I'll give you a
short demo so we can actually see it working.
Then I explain why is Crawljax is useful,
give some examples how we can use it. Then
I'll talk a little bit about invariant-based
testing, how you can use Crawljax. Yes, what
the current state coverage is and, of course,
the manual effort in relating to it. And discussion
for future work, of course, and then the questions
and discussions, first general then the more
specific. So basically, what is Crawljax?
Crawljax is an automated testing tool in Java
for exploring and testing the different states
of any Ajax/GWT application. You can basically
see it as a Web crawler but then it also supports
JavaScript and Ajax/GWT. It doesn't matter,
it just crawls it like it normally would do.
Okay, it started as a PhD research by my supervisor,
Ali Mesbah, and his first idea was to create
a Web crawler to crawl at an Ajax application
and generate a mirror website of it. So it
could be indexed by normal Web crawlers like
the Google crawler. We're currently doing
a lot of research on it and working with a
team of four people so they'll be out there,
they'll be using Crawljax. So first, the user
specify what to click, the URL to get it do,
so that Crawljax knows what to crawl. Crawljax
use WebDriver to open a browser and navigate
through the application. It does it by doing
first a depth first crawl so it clicks as
far as it can go, backtracks to the beginning,
and it goes on and on. So the main power here
that you can use plug-ins and invariants to
perform tests like a user define tests. And
Crawljax generates a state-flow graph of the
application. So it's like a whole view of
the application, where [INDISTINCT] to each
other and how you get that. So when I--here
I kind of explain how its work more in detail.
So what you do when you crawl a state, you
first scan the DOM tree for clickable elements
which were specified by the user. So, for
example, anchor tags, then Crawljax scans
all these elements, and there's form values,
so you see some, it could be run values by
default or you use it again manually, specify
the values for you. Then it clicks on the
elements then it checks, getState is not a
change so how are we going to do the state?
We do it by comparing it all. So if the state
is changed, we update our state flow graph
because there's a new note and a new edge
found. Then we run the user specified plug-ins.
So, yes, which are the most that the test
will be run. We could also test for invariants.
We can define the variants with the DOM tree
or a JavaScript invariants so it should always
hold. And if the state--if the new state is
allowed to be crawled, we must crawl that
again so it's kind of a regression thing as
opposed to it's called in it. And on a little
note, plug-ins, you could also use plug-ins
before and after the crawling, for example,
to log in to a certain page or after the crawling
to generate a report or the manifest. So,
I talked about comparing states and about
states with the rest of the new states. How
can we detect it? So you should know, is there
a new state? Are we now in the new state,
with previously visited state so how do we
do it? And we do it by comparing the DOM trees
above--yes, there's a little problem over
there because they're often--maybe not relevant,
the differences. For example, see here the
anchor tag, it's a random ID which changes,
or maybe it's not--doesn't have any other
meaning so we could use Oracle comparators
to ignore stuff like that. So, that's our
solution, the Oracle comparators. This is
going to be quite flexible where you can say
we want to apply Oracle comparators only to
these pages or to get pages so 
you can, 
you know, we need a flexible solution. Okay,
we'll now give a short demo about Crawljax
so you can see it in action and see what it
actually does. Here, you can see some codes
about what's used for the demo. I will get
to a more clear example in the slides later.
So if you start running Crawljax it will now
run on the real essence content. Good. And
you can see it loading now. It takes some
time. See, it's indicating--exploring the
web application.
&amp;gt;&amp;gt; It wants to crush that state.
&amp;gt;&amp;gt; ROEST: That's the impression today. So
this is all explored by all these specifying
click anchor tags, click Google buttons, and
so on. So, you have Google basically repeat.
The crawling demo, it will take about five
minutes so we'll go back to the presentation.
And, of course, as you know, there are [INDISTINCT].
&amp;gt;&amp;gt; How do you know not to click the sign-out
or other things that you shouldn't click?
&amp;gt;&amp;gt; ROEST: Yes. You can also specify that.
I'll show on the slides how you can specify
on some things you don't want to click so
it'll click like a lot of things but not everything.
&amp;gt;&amp;gt; Okay.
&amp;gt;&amp;gt; ROEST: So why is Crawljax useful? Maybe
Crawljax can be very useful because it's--you
can use it for a lot of different types of
testing. So, what makes Crawljax powerful?
Power--what Crawljax makes powerful is that
it can automatically discover like the various
different states of your application and you
don't have to specify like a manual configuration,
like click this, click this, click that, like
when you're using the WebDriver or Selenium.
It's always about automation. The other one
is Crawljax supports any type of Web application,
and it doesn't matter if you have an Ajax
Web application and uses GWT, or it's just
on APHP and normal link, it doesn't matter.
Another big advantage, there's no need to
update your tests because, for example, when
things are changed, IDs are changed, Crawljax,
of course, updates them dynamically so you
don't need to update your tests at the Windows
application. Another one is that Crawljax
supports multiple browsers. This is going
to be via WebDriver--thank you. So, let's
give good examples of plug-ins that you can
do under this. So one of this--one of them
is security testing. So you can set up a proxy,
a security proxy server, run Crawljax and,
yes, it reads all the RPC requests and, so.
Accessibility testing can mean a lot of things.
You can visit a lot of the states. So, again,
there's all the states for it, right or left.
And things for example, like Arabic text formatting
variances and numbers. It can also take broken
links or images, or if they're old, introduce
a set of images and so on. You can also use
it, for example, in regression testing. But
when you crawl the application, you don't
want it crawled to the different paths that
you crawled in the application and it creates
a test suite from that and replay a test suite
and use DOM comparison to see if there if
anything's fixed for the application. It also
do app performance testing, so you run Crawljax
and you look for all the SQLs that are made
and you can make it do some analysis on that--any
of those projects. Of course, the applications
are wide, you have a lot of data to do a performance
testing on. It can also do a cross-browser
testing. For example, yes, if the--your applications
works under Linux and on the Firefox, it doesn't
always have to work on Internet Explorer.
So what you can do is run projects and replay
what you just crawled in another browser and
then you compare the states. Did you find
the same elements? Are states the same? Does
it contain the same [INDISTINCT]? And there
are probably lots more applications.
&amp;gt;&amp;gt; In practice, will you expect the Chromes
to be--I mean, there might be some different
pattern differences?
&amp;gt;&amp;gt; ROEST: Yes.
&amp;gt;&amp;gt; And [INDISTINCT].
&amp;gt;&amp;gt; ROEST: You're now comparing on the DOM
tree?
&amp;gt;&amp;gt; Yes.
&amp;gt;&amp;gt; ROEST: It isn't. Why, because there are
a lot of many differences and, yes, it probably
knows where it's effective, too. You solve
that with one of the comparisons. So what
we've have done now, basically at the moment,
is getting which GWT pages are there in the
zone and comparing many or so at this stage,
at the same widgets, the same order, and then
you can have a quite a good idea to go, does
it contain the same pages or is a link broken,
because the end state isn't reached. So we
also created an example, the Tooltip Validator
on the essence of the project here. It'll
will have a lot of help buttons which shows
some more information about the current page
or the current extension. So what Crawljax
did, at least to create, that Crawljax is
scanned in every state of the DOM. With the
help buttons, click on it, check, is there
really a message shown? And is this a fill
up message? So for example here, the Tooltip
article is not found in the message so you
can save that and [INDISTINCT] for it or so
on. So, what we also--because when we explore
the applications are wide. We also do invariant-based
testing, which tests for every state so they
should always [INDISTINCT]. So we did a little
example and we set--when you have no field
that's specified, so you should use like old
platform apps--all apps with any platform,
it doesn't really matter, should always be
items [INDISTINCT]. So the example you see
here, there are three items it tests. So when
we started crawling, what happens? If unchecked,
the website filters so it doesn't show any
website apps. But later when we came back,
left from worst old, so all that units should
be this safe but it wasn't the case. This
is an example of a variant that you can test
on your application, especially with highly
interactive user interfaces and see everything
still at once. So everything's successful.
So, now about you--how you can use Crawljax
specification. The first thing is you specify
how you control the application. So you can
create a crawl. Specification, like I said,
&quot;Click all anchor tags.&quot; For example, click
all the buttons and it's quite general because
most applications will have anchor tags on
them. On the essence front ends, we also have
like Google buttons, the GWT buttons, that
we should also click those. But as we just
mentioned some things you don't want to click.
So, for example, we can say to the programming,
don't clink anchor tags which are under a
certain A paths or in those certain elements.
For example, in the header when you log out
from the main page or in the footer so that
you see some--be leaving things are also like
mobile and stuff. And what we also did, because
we don't want to crawl any other websites
besides AdSense, is add a crawl condition,
it only crawl URLs with the name &quot;adsense&quot;
in it. So specify this more specific but this
shows how to do it. So form data is a [INDISTINCT]
with random--randomly generated and able to
change the fields but sometimes it's necessary
to enter and then you will sort of [INDISTINCT]
some specific value. So, here this shows an
example of how you could save to the field,
which is a name or an ID. So, you add--set
it always to the value of Crawljax. So there
is a newsletter field like a check box so
I just always go through &quot;buff.&quot; For example,
sometimes you want to fill in, like, notebook
values in a form because--and use in different
states, so you could create a form at the
same time or a field name. First step is fill
the value [INDISTINCT] and then you set balance
rates and the second time you encounter it,
it's the same line. So what it basically does
is you--then you specify which button is the
submit button for this field. You know, because
one button is like the real submit button
but you can at least say the link which affects
the form. So you say here, you set this value
in this form before you click the next anchor
element then pick the text to save. So first,
you can set up the form with the setValues
then you--at google.com and then it will fill
later and comes back to the state, it will
fill in &quot;Mike&quot; and &quot;mikedavis@google.com&quot;
and then click &quot;save.&quot; So in that way, it
specifies [INDISTINCT] a new form. So--and
how can you use your plug-ins? There's a--there
are interfaces for plug-ins for different
times which it can be called. The most common
with this type, I guess, is probably [INDISTINCT]
but every time you find a new state you can
execute some test on that state. Are there
any violations in this state or is there anything
that will go wrong or anything? So, and it's
also important to know what do you crawl with
Crawljax and how well does it crawl. So when
we get--we compare current driver tests with
Crawljax and see what little manual effort
has--or what improve--influences for manual
effort. So, for example, the blue bar is the
current code coverage of WebDriver and the
red bar is a project with a random form data
and the orange bar is a specified form data
as it shows in the [INDISTINCT]. So as you
can see, in general, the [INDISTINCT] means
like the--they compare the total of the coverage.
So you see that the coverage of the WebDriver
and the random form data is about the same
and the specified form data is just higher.
So we have three different packages here,
so you can see the difference between Crawljax
and WebDriver. And what is very interesting
to see here is just where they get almost
no coverage and WebDriver has a lot of Web
browser. Then you see a form. There was a
form that needed a valid URL and somewhere
in that data it wasn't good enough for it
so it has to go. It wasn't reached. So what
we did we filled in some--a simple URL and
you instantly see the difference in coverage.
So this is also really the tool to see what
you have crawled and you specified a good
crawl configuration. So, it basically shows
you what's visited by Crawljax and hopefully
the demo is finished now so I can show you
our scrolls because we also created another
plug-in which shows what it crawled. So here,
you'll see the screenshot again. This is the
essence page that we just crawled. And the
green links, the elements that are highlighted
in green, are the one that causes a new state,
add a new state for them. And the orange one
didn't cause a new state transition. So, for
example--and you would click &quot;zoom&quot; and then
you go right in home, based, boom, and checked.
There's also a light-blue pieces on this page
that will tell the [INDISTINCT] that you already
visited the state. So, for example, you see
here they've integrated GWT analytics now.
This thing normally opens another window and
another URL, so we don't want Crawljax to
crawl it and this is why it will condition
the [INDISTINCT] effect in those crawl or
anything you don't want to. So, for example,
when you click on the elements, you know,
for the new state, so you get overview. This
is light blue, that we were already been there.
And then here, this is the initial state.
And what is also interesting, for example,
if we would go to &quot;my ads,&quot; and my &quot;go&quot; and
&quot;clear&quot; are orange. So [INDISTINCT] on orange,
you click and nothing changes because if you
don't do any form value there it doesn't change.
For example, you would click right here, you
see the page, this would change. And let me
go back to initial state, which you also can
see here, you see all the--any activity. You
can do that thing in messages, for example,
down settings. So when you go to messages,
you don't click again on &quot;overview,&quot; &quot;payments,&quot;
for example, because we give the memory what
we want it to click so we don't click it again
in the other states. So what it generates
is--it also generates a graph of the whole
application. You can see here, this is an
image base. It's now quite small but you see
here how everything is crawled and what crawl
that you see is not so you can expect. So
what did Crawljax really do with my application,
what page it visited, so what am I testing
if I use plug-ins [INDISTINCT]. So this is
a really good, cool way to, you know, to browse
through what is clicked. It gives us a varied
index to row configuration for the demos,
it shouldn't take too long. So you can imagine
that for the whole application to be much
more state and there's also search engines
[INDISTINCT] expect the--expect the limit
there. So some future work and we are going
to work on, parallel crawling. This would
take some time to be active on multi-parallel
multiple computers from multiple threads.
One computer related to things that this from
the state space reduction less states that
are impossible than those or more on this.
For example, this is certain states like,
for example, for a lay output. And then a
slight thing changes in [INDISTINCT] isn't
interesting. You shouldn't test all those
layout within [INDISTINCT] it can be very
slow and you get same errors multiple times
so it's not interesting. So we're trying to
do this by improving our Oracle comparators,
give you more a general Oracle comparators.
And another thing we're working on and doing
research on is automated detections of invariants,
the automatic you could get across [INDISTINCT]
to your application. Thank you very much.</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>