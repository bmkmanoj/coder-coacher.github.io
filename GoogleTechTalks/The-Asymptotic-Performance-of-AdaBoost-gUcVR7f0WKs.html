<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Asymptotic Performance of AdaBoost | Coder Coacher - Coaching Coders</title><meta content="The Asymptotic Performance of AdaBoost - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Asymptotic Performance of AdaBoost</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gUcVR7f0WKs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Peter give us PhD at
that went to the Australian National
University for a while it was part of
the green team at Iowa and after that he
quickly and myself were paid out and
today on Peter talked to us about
another large market alright thanks Phil
thanks for inviting me so this is joint
work the the main results me I'll tell
you about a joint work with mikhail
koshkin who's going to be here over the
summer but also be reviewing some
results with mike jordan and and john
McAuliffe that's all those out at the
time alright so I'm talking about
pattern classification but in particular
large margin algorithms let's start by
by defining the pattern classification
problem we do that in a probabilistic
setting we assume that we have some
joint distribution over this product
space X by Y so the excise our patterns
in some in some space X and the Y's
labels and where we're interested in
classification here i'll restrict our
attention to the two class case so the
labels are either plus or minus one and
the Joint Distribution is intended to
model you know the relative frequency of
different patterns and the and the
conditional probability that a label
might be one given a particular pattern
ok so this assumption that there I ID is
is is crucial in what we do in the aim
is to use this data so n XY pairs to
choose some mapping from the space X to
the reels that we're going to use as a
classifier will use the sign of that of
that real valued mapping to predict the
labels for for a particular X and the
aim is to to come up with small risk so
our classifier here the risk for a
classifier is the probability of
misclassification when we threshold it
at zero right so if the if the real
value is greater than zero we predict a
plus one and we suffer a penalty of one
when we when we get the sign wrong so
we're interested in minimizing this
probability of misclassification we
define this loss function
l as just getting the sign wrong here
right sorry soon in minimizing that
expected loss so a natural approach is
to to choose a function f from from some
class to minimize the empirical risk
that is the sample average of losses
that's typically computationally
intractable and it's common to replace
this discrete indicator of making a
mistake of getting the sign wrong with
some kind of a convex surrogate right
and that's the approach taken with large
margin classifiers all right so we
replace the the indicator for a mistake
with some some convex loss function and
work with that so here the idea is where
we're interested in the probability of
misclassification we're using this real
valued function f so y times f of X is a
variable that we'd like to be positive
right if it's positive we're making the
right the right prediction we define
some cost function of these margins
these these variables Y times f of X and
it's something that you would expect to
be small when when its argument is is
nice and positive and and and should be
penalizing negative values and then we
can define analogous to the risk the
fire risk is the expectation of this
cost function evaluated at the margin y
times f of X and we're now choosing a
function from some class to minimize the
fire risk the the the empirical fire
risk let's say so the average over the
data of this cost function of the of the
margin evaluated these data points or
maybe we'll work with a regular eyes
version so let's look at a bunch of
examples of that kind of thing adaboost
is the one I'm going to concentrate on
in this talk so here the the class that
we're working with the class of real
valued functions is the set of linear
combinations of some class of basis
functions and let's say they're plus or
minus one valued functions we take we
take linear combinations of those and
work with that the cost function here is
the decreasing exponential all right so
so you know it's quite natural for large
positive values of the of the margin we
have a diminished cost and adaboost
works by some kind of green
the basis selection where at each step
we have some linear combination of our
basis functions already and we add in a
new one right with some weight and the
the choice of the new function and the
weight is such such that we minimize the
empirical risk with this with this
surrogate cost the decreasing
exponential right so adaboost you know I
guess doesn't doesn't need any more
advertising it's been very effective in
a bunch of applications including
real-time face detection systems and
spoken dialogue systems and many other
success stories but adaboost of course
is not the only algorithm fits in this
category support vector machines can be
viewed in this way where the the margin
cost function is is decreasing linearly
until one and then and then zero so it's
this hinge loss the class of functions
is some ball in the you know in a
certain reproducing kernel hilbert space
and the algorithm works to minimize the
empirical fire risk with this Phi
together with some complexity
regularization that's a penalty for
having large norm in the arc HS neural
net classifiers similar story with a
quadratic loss or truncated quadratic
loss all sorts of other examples
logistic regression can also be viewed
in in this kind of a way
so the first part is reviewing these
these ideas that look at the
relationship between this risk right the
Miss classification probability which is
the quantity we care about and the fire
risk the quantity that these algorithms
are actually minimizing and this is
joint work with mike jordan and and john
McAuliffe so we'll see that there is a
nice a nice tight relationship between
between these two quantities and we can
come up with simple conditions on the on
the convex function Phi that ensure that
we get a useful relationship between
those two when the second part of the
talk will be looking at applying these
results as a as a tool in understanding
what's the asymptotic behavior of
adaboost right does it lead to optimal
decisions as we see more and more data
okay so let's start with a bit of a bit
of notation so so we're interested in
this probability of making a mistake
when we threshold out our function will
call that that the risk r of f there's
an optimal value for that that's the
bays risk it's the infimum over all
measurable functions right of this
probability of making mistake so this is
the best we can we can hope for what
we're doing is driving the fire risk
down we're minimizing some sample
average or you know regularize or
something where we're doing something to
make this this surrogate cost function
small in expectation will call that our
thigh right the fire risk and and
there's an analogous optimal thing here
that is the infimum over all measurable
functions of the fire risk okay so
whatever our algorithm is doing to drive
this down over some class of functions
we can't hope to have it get any smaller
than that all right that's what the
algorithm is working towards its fire
risk close to this thing what we'd like
is to have its risk get close to the
optimal so we're making optimal
decisions okay so we can understand that
the the the behavior of a classifier
depends on the conditional probability
that that y equals one given a
particular X right we can define an
optimal classifier in terms of this
conditional probability i'll use the
notation eater of x for that conditional
probability and that defines an optimal
classifier when we threshold this thing
at a half if the conditional probability
is greater than half we should predict
plus 1 is less than a half we should
predict minus 1 and the risk
that and the bays risk up here is is the
risk of such a classifier okay so one
thing to notice this is this is kind of
trivial right the fire risk can be
written as the expectation of the
conditional expectation of this of this
variable when we look at a particular
value of x right so if we conditioned on
an X then this thing takes values plus
or minus one what is that expected
what's the conditional expectation of
that thing you know this is another way
of writing the fire risk and and then
you can view that as you know this is
the probability that y equals one and we
get this this component phi of f of X
this is the conditional probability that
Y is minus one and we get this component
to our fire risk so now we can use that
to understand what what minimizing the
fire risk is doing for us so we're
splitting things up looking pointwise at
a single X right and worrying about the
conditional expectation of this of this
variable 5y times f of X okay so one
maybe two more pieces of notation before
we get to some some substance so the if
we fix a particular X or fix a
particular conditional probability that
y equals one and then look at the
smallest value that the conditional fire
risk that can take right so this is this
is choosing our f of X in here right to
optimize this conditional expectation
right let's call that H of aveda that's
the best we can do when the conditional
problem at a particular X when the
conditional probability cause one is
equal to two this value eater okay so if
we do this point wise optimization
everywhere then we get the optimal fire
risk alright that's just minimizing for
every X the conditional expectation of
the fire risk take the expectation of
that and you know modulo some question
marks about measurability here which are
easy just easy to answer this is the
this is the optimal fire risk
okay so so we're going to be using this
this quantity the optimal conditional
fire risk so let's look at an example
here the black line is is the function
Phi let's think about think about the
case of a truncated quadratic it's 0 0
here and then quadratic up there the
blue line is is it turned around with
the argument negated and then when we
can look at the conditional expectation
of this thing for a particular value of
the conditional probability like point
seven right is that variable leader and
that's the curve as we look at different
values of the of the margin okay so when
we go and minimize the the conditional
expectation of that of that quantity Phi
looking across different values of the
conditional probability all right this
is the optimal value this this line here
is the optimal value for the argument
the one that minimizes it right at point
seven it's it's out here at point two
five or something right so that's up
here and the the blue one is this is
this H curve that's the optimal
conditional fire risk that we can
achieve the different values of the
conditional probability all right so so
so a couple more pieces of notation so
we've seen h what happens when we do the
optimization but but we're forced to get
the sign wrong right so we're minimizing
now not over all values of f of X but
minimizing over values that have the
sign wrong right because the conditional
probability here if it's greater than a
half we should be predicting in a
positive way and we're forced to predict
in a negative way all right that's the
so it's just a constrained version of
this where we get the sign wrong this
defines some other function you know
this is maybe a complication but you can
observe that if if the we can simplify
this thing in the case where Phi is
convex the optimal thing to choose with
the wrong sign is always 0 right so you
know this thing is just 50 in the case
of convex
bex cost functions all right and of
course we're we're increasing out our
conditional fire risk when we're forced
to make the wrong side okay so we say
that that the cost function Phi is is
classification calibrated if whenever we
don't our conditional probability is
different from a half getting the sign
wrong forces it forces us to have a
bigger value of the conditional fire
risk right so the optimum with the sign
wrong is strictly worse than the optimum
okay so this is just a point wise
condition it's obviously necessary for
for a function fire to satisfy this
condition in order to get optimal
behavior asymptotically right if
pointwise you can't you can't do well
you're in trouble when you look across
the whole space I just think about a
domain that has a single point and and
for some value of the conditional
probability you can do just as well by
getting a sign wrong as you can when
you're allowed complete freedom right so
you're in trouble if you don't have this
condition satisfy it's obviously
necessary we'll see in fact that it's
also sufficient for for for a cost
function Phi to be suitable for for
classification okay last last definition
is is this transform and I've restricted
it to the case of convex phi so this
thing which would have been h- is just
fired zero so this is this is some kind
of transformed version is some kind of a
function that map's here from from a 01
value a variable that takes takes values
in the range 0 to 1 right and it looks
at the difference between the best
conditional fire risk when we have the
sign wrong and the best conditional fire
risk for transformed value of the
argument okay so and that's the red line
up here right we're just taking this guy
and subtracting the value of H
subtracting it from the value of H and a
half alright so that's its this
quadratic thing in this in this simple
example we looked at before all right so
the theorem is that
for any probability distribution and any
function this function sigh of the
excess risk is an upper bound on the
access fire risk okay so let's think
about that for a moment this is the
thing that we want to make small right
we'd like to choose a function that has
risked close to the optimal risk the
best the best that we can hope for for
that probability distribution what we're
doing is making this thing small all
right where we're choosing a function
that has small expect small a small
value of the expectation of this convex
cost Phi so we're driving that thing
close to its optimal value you know
that's the best we can hope for the when
does that give an upper bound on this on
this excess risk so it gives it up a
bound in terms of this in terms of this
function sigh okay so so we get some
kind of an upper bound it turns out that
you can't do any better in the sense
that this thing is is pointwise the best
you can hope for right so for every
value of the argument there is a
distribution and a function and and you
know we don't have to look at more than
two points in the domain to exhibit this
where the excess fire risk is as close
as you like to this function sigh of the
excess risk okay so this is a tight
relationship in general between the
excess fire risk the thing that these
algorithms are minimizing and the excess
risk right the thing that we care about
and the third point is a question about
is answering the question of when this
kind of a bound is is worthwhile right
because so this is certainly always
always convex the the question is when
does driving this side 20 ensure that
the argument is 0 well that happens
precisely when this cost function Phi
satisfies this classification calibrated
condition all right so precisely when we
have this this condition involving the
h h- and h right this obviously
necessary condition is also sufficient
to have minimal fire risk implying
minimal risk okay so this is true in
fact I only stated the definition of
this thing for for convex functions you
can there's a slight wrinkle on that to
come up with a definition for non convex
functions and everything else follows
through in the case of skipped that in
the care okay so we can skip over the
the proof so the proof is once you have
the definitions the proof is Jensen's
inequality that's really at least of the
first part of the theorem is Jensen's
inequality it's really very simple in
the case of convex cost functions it
turns out that this classification
calibration condition is very easy to to
verify all that matters is that the cost
function is differentiable at zero and
it decreases at zero right so all of
these things that we saw all of these
cost functions that we saw trivially
satisfy that that condition right there
differentiable at zero and they're
decreasing there so the convex case it's
it's particularly easy to easy to check
one other thing that I pointed out
earlier hear about these functions is
that they all form appropriately scaled
I guess they all form upper bounds on
the the indicator of making a mistake
and that's no accident it turns out that
that's that's necessary right so if you
have a classification calibrated
function then you can scale it to get an
upper bound on the on the indicator for
making mistakes so they all have this
this property okay so that's that's a
key tool in in the main part of the talk
which is looking at the behavior of
adaboost as the amount of data increases
all right so now that we we've seen
there's this this nice relationship
between the excess risk which we'd like
to drive 20 and the excess fire risk
which our algorithms are working with
we'll use that as a tool in
understanding how this particular
algorithm which uses
Phi is the decreasing exponential how it
behaves asymptotically in the in the
sample size in the amount of data all
right so let me let me start by defining
universal consistency what precisely we
mean there and then we'll look at kind
of the standard approaches to proving
these sorts of asymptotic properties
which which fail in the adaboost case
right so there's there's there's more
work that we need to do alright so the
universal consistency question is we
have you know just as before I ID data
and we've got some method that is a
function that takes us from from a
sample to a to a function and we say
it's universally consistent if no matter
what probability distribution were
presented with the risk of this sequence
of functions approaches the the Bayes
risk in the limit as the sample size
grows all right so we're just interested
in what happens asymptotically in the
sample size and the universally is
because we're worrying about all
probability distributions there's no
model here right there's just whatever
whatever Joint Distribution we have can
we cope with that can we make optimal
predictions as the sample gets large
okay so the standard approach to proving
this kind of property involves an
approximation estimation sort of
decomposition right so you you let's
suppose for instance that we were
working with minimizing an empirical
empirical risk across across some set
together with a regularization term all
right there's one kind of algorithm that
we could consider this is the regular
roast form or another approach is like a
method of sibs where we take a class f
of functions and we split it up into
simple ones and more complex ones and so
on and as the sample size grows we allow
more and more complex functions so
there's two different ways that that
people look at regularizing right either
having a regularization term that
enforces smooth functions less and less
as the sample grows or having having a
sequence of function classes that gets
bigger and bigger so we're being more
and more relaxed about the complexity of
our functions
the sample size grows okay so for these
kinds of algorithms and let's consider
the latter case a little simpler to to
demonstrate here for these kinds of
algorithms we have a we have an obvious
a line of attack to try to show that our
excess risk is going to zero so we have
this relationship between the excess
risk in the excess fire risk so we work
with the the excess fire is can split it
up into this is the fire risk of the
function that we chose let's look at the
difference between that and the best
over the over this class of functions FN
and then look at this other term so
we're just introducing these these two
terms look at this other term which is
how how close to the optimum can we get
within that class ok so this is an
approximation estimation decomposition
right if we restricted to the class FN
that's the best we can do right and you
know obviously we'd want our class our
class FN to be nice and big in order to
get this approximation there are small
but the the cost of that is a
statistical one we have a finite sample
and as we look over richer and richer
classes it becomes harder to choose
something based on that finite sample
that gets close to the best in that big
big class right so there's this
trade-off between the approximation and
the estimation errors and the usual
argument for these kinds of things is to
say well if we've got a rich class and
we let these guys get large right these
these subclasses get large sufficiently
slowly then we'll be ok right
sufficiently slowly means this term is
under control and if they're nice and
large that asymptotically you know this
this approximation error is going to go
away so you know this is the the usual
approach and then of course we can use
this this relationship between the
excess risk in the excess fire risk to
to say well then we've got our our
excess risk going to zero provided we're
working with a sensible convex cost ok
so one thing to point out this is these
approximation and estimation errors is a
little different from the normal
analysis of the
of classifiers because we're working in
terms of the fire risk so this is more
like a regression kind of a problem
right then a than a classification
problem okay so that's that's how things
work in the that's the approximation
estimation decomposition for adaboost
things are a little complicated and the
difficulty is this statistical term
right the estimation error in the
adaboost case we're working with the
space of linear combinations of
functions all right and there's nothing
about the algorithm that keeps us in
some small set of functions here in
particular the range of values of the
functions is not constrained so you know
the statistical part that keep keeping
control of the estimation error is a is
a difficult thing okay so just to remind
you the adaboost algorithm takes this
sample of size n and starts off with a
linear combination that's just the zero
function and adds in at each step
another function from our class of basis
functions scaled by some some real
number and it adds in that that scaled
classifier that optimizes this empirical
fire risk right this the sample average
of these decreasing Exponential's you're
on
hey that's right right the difficulty so
this one here in fact I'm working just
with classifiers right so the H here are
plus or minus one okay so if these were
convex coefficients would be fine but
the point is they're not right there
there we're working with the linear span
of these functions the alphas here can
be as big as we like right whatever it
is that drives this down is is whatever
we take so we can take arbitrarily big
steps right you you keep control of the
size of the of the combination that you
work with that's right so so that's the
difficulty of working with the
estimation error term for adaboost okay
so okay so one way of dealing with with
that issue is to work with a regularized
version of the of the criteria right to
either add in an explicit regularization
term that penalizes big big functions in
some sense or to make sure that the
steps we take a small you know these
alphas are small right or something so
so there are there are a bunch of
analyses of regularize versions of
adaboost of this kind I mean I guess one
thing that you have to point out that i
should point out is that you know if
we're working with some sensible class
of basis functions we can drive this
criterion down to zero right the span if
the class is rich enough that the span
is dense in in I don't know you know
some some big space then then we can
drive this criterion down to zero and we
don't want to do that so we don't really
want to optimize this thing over the
span we're going to have to do some
regularization and and the question is
what what sort of regularization do we
need to do so one approach where we
explicitly impose regularization by
saying look let's penalize big
coefficients let's make sure that our
let's work with right up here let's work
with the convex hull of functions from
our basis class
scaled up by some number gamma sub N and
we'll let gamma grow as the sample size
grows right so then we're working with
bigger and bigger functions another
approach the this is like a method of
service this is like a regular eyes
version and other approaches to work
with the empirical fire risk plus a
regularization term that pen Eliza's the
one norm of the coefficients right of
our combination so rather than working
with explicitly with with restricting
ourselves to a a one ball in parameter
space we could penalize by the the one
norm of the parameters both of these
cases you know the analysis is really
very standard right and follows the the
lines that i showed earlier and and and
you know you can show that these
algorithms behave nicely as the as the
sample size grows and and you get miss
classification probability approaching
the the optimum another approach is to
is to bound the step size so we look at
the optimum the optimal value of the
optimal real value of a step to me we
might want to take and we constrain it
to be smaller than some number epsilon
okay and if we choose the number of
steps to be not too large as a function
of the sample size and the step size to
be not too large will then we're
constraining the parameters again right
so this is analogous to working with the
method of service except that you know
when we're not doing an optimized and
explicit optimization over the classes
as these algorithms whoops yes as these
algorithms were right we're using the
adaboost approach of just greedily
stepping through the space you know a
coordinate at a time and it turns out
that that again this works well so this
is a little more involved than the than
the approach that I the generic approach
I described earlier but you know a stool
can you still can show that that when
you impose these kinds of constraints
you get a good asymptotic performance
okay but but how is adaboost used in
practice it's it's with early stopping
all right you take a bunch of steps and
you stop at some point
alright it's not you're not imposing
regularization you're not not keeping
the step to the individual steps small
you're just taking the steps that
adaboost wants to take adding in the
functions until you get to a combination
that that is appropriate maybe through
cross validation or maybe through some
fixed schedule you know there's a
restricted number of steps so let's
suppose that we have a fixed schedule
all right kind of simplest simplest case
how should we choose that that schedule
well you know obviously we can't let it
get arbitrarily large because as I
pointed out this criterion can can go to
zero so there is a result of this form
with a bunch of conditions so so so for
certain basis classes and and
probability distributions that satisfy
some some strong smoothness assumptions
then there there is some sequence of a
number of steps or size of combinations
so that the the risk approaches the base
risk so there's a result due to Shang
the difficulty here is that they're
really very strong conditions on the
probability distribution you you the the
argument involves doing Taylor series
expansions of log odds and and you know
it's it's really keeping everything
close to conditional probabilities you
need you need the distribution on X to
be continuous there are all sorts of
conditions here that that we can't check
the other thing that's not very
satisfying is that there's no indication
how the stopping time should grow with
the sample size and in particular
whether it needs to grow with the
whether it needs to depend on the
particular probability distribution that
we have so it turns out that that we can
get rates on how this sample size needs
to grow on how the number of steps needs
to grow with the sample size and that's
the the key result that I want to tell
you about now all right so first of all
there are a couple of assumptions that
we need
they're they're really mild in the sense
that you know it's it's hard to imagine
getting by without them right so so we
need that the basis functions that we
work with have finite vapnik germany
anchors dimension so you know there's
this combinatorial constraint that we
can't have an arbitrarily rich class of
basis functions and if we don't have
that then you can construct distribution
so that adaboost will stop after one
step and fail right it'll match the data
after one step and and have a bad
classifier so so you know there's
nothing you can do to avoid this if you
want to work with all if you want a
universal result that works with all
distributions the other requirement is
that that the approximation error in the
in the sense of this fire risk should be
zero asymptotically right so when we
work with the span of when we work with
all linear combinations we can drive our
fire risk down to the optimal value okay
so it's essential that you know again
this is this is not unreasonable that we
need to have this approximation error
goto 0 and there are you know plenty of
basis function classes simple basis
function classes that ensure this right
for all probability distributions so you
know again it's not a it's not a strong
constraint and then the result says
under these conditions as the as long as
the stopping time as a function of
sample size goes to infinity and goes to
infinity not too fast so it's anything
slower than linear in the sample size
then we get our risk approaching the
bays risk we get this Universal
consistency result so as the sample size
grows where we're making optimal
asymptotically making optimal
predictions with with adaboost and and
we get an explicit rate for the number
of steps that were allowed to take its
sub linear in the in the sample size
okay so i will tell you very quickly
about the idea of the of the proof and
in particular how we get around this
this business that that adaboost can
take very large steps so we work with
one one of the one of the key ideas is
to work with a clipped version of the of
the functions right so if this is our
the function that we have after after
we've formed a combination of t of these
basis functions we're going to consider
not that function and it's fire risk but
a clipped version right we clip it at
some value and we're going to relax the
clipping as the sample size grows if the
if the fire risk of the clipped version
goes to the optimal value this implies
that the risk is going to go to the
optimal value right and it's clipped it
and we were going to threshold at 0
anyway so the clipping has no influence
over here right so so you know this is
what we're shooting for all right now
now we're looking at these functions as
combinations of not too many functions
from a basis class and they're clipped
it's a very straightforward relationship
between the empirical fire risk a
classical relationship between the
empirical values of these things and the
expected values right these are nice and
close as a function of the size of our
combinations and then once we're in this
domain of the of the empirical fire risk
right the clipping is only helping on
this side right this is our this is our
exponential cost function that adaboost
is working with when we clip over here
that helps us it drives that thing down
when we clip over here it hurts us but
it hurts us in an exponentially small
way as this parameter gets it's big so
you know it's no big deal when we're in
this domain of the empirical fire risk
and in that domain that's exactly where
adaboost is working right this is the
thing that adaboost is making small so
here we can apply some some ideas from
from a result of peter bikal and and
yucky r it off that i mentioned earlier
so
we can we can show using these ideas we
can show that the empirical fire risk
after T steps gets close to the best
gets close to the best empirical fire
risk of some function in a small L 1
ball okay so you know it depends on the
l1 radius of this function we're
comparing ourselves to in the number of
steps but you know this is where we're
comparing ourselves to some some scaled
convex combination of functions and this
is relying on particular properties of
the exponential cost function and the
fact that our classifiers are binary
valued all right this is what keeps the
the steps that adaboost takes from being
too large okay so that's a crucial part
of the of the of the analysis I have a
little more to say about that later and
then finally you know we're working with
this comparison this function has
empirical fire risk that's close to the
two it's true fire risk you know this is
just we're talking about one function
and saying it's it's a expectation and
sample average a not so far apart this
is not a not so hard to believe right
and so then you know as long as we let
the number of steps grow only slowly
with the sample size we get the
empirical the the fire risk approaching
the optimum and we have the result so in
pictures alright this is the domain
where we're talking about this should be
fire risk over here and this is
empirical fire risk we we Thresh we clip
our functions that we get off the t
steps we look at how the true risk
compares to the the empirical we look at
how the the clipping has little impact
on us and then there's this numerical
result that says when we take when
adaboost takes these steps because of
the other nice properties of the
exponential function taking T many steps
puts as close to some some guy that has
a small l1 radius and is the optimal
within that L one ball and that guy's
empirical risk is close to his true risk
and you know over here as this l1 ball
gets big we're getting
to the optimal thing so you know it's
quite a roundabout kind of an argument
and and and the crucial step has to be
has to be taken the crucial step in the
argument is this performance of the
adaboost algorithm as a numerical
procedure for minimizing this empirical
fo risk and it's how that how that
behaves as a function of the number of
steps and the radius of the old one ball
in which our comparison function wise
all right so that's that's the key idea
there so there are some natural natural
extensions that you would you would
think of here there are these other
algorithms that work with slightly
different loss functions right but you
know it's been argued have have nice
properties also does does this argument
tell us anything about their behavior
asymptotically and in fact it doesn't
the difficulty is that we don't have we
don't have this this information about
the second derivative of the empirical
fire risk in the direction of a basis
function and and that's what and that's
what we need we need a nice lower bound
on this on the second derivative so you
know this is problematic for these other
functions exponential seems to be seems
to be nice the same problem arises when
we consider real valued basis functions
this is kind of surprising right when
you when you look at plus minus one
value basis functions we're combining
classifiers everything's fine and we
know that when we move in the direction
of a basis function we have this nice
log down on the second derivative this
is not the case when you allow real
valued basis functions so you know the
other things don't go through here which
is its kind of striking I think it could
be just a an artifact of the technique
of course and one other direction the
the rates that we get when we look at
the look at everything altogether what's
the convergence rate that we get the
rate of decrease of the fire risk to the
the optimal and hence of the risk to the
optimal may be under some approximation
assumption and the bottleneck here is
the numerical result right although we
know you know from
the behavior of this exponential
function we know that where we're
approaching the best in some l1 ball the
the numerical result just tells us that
we get close to it at this terrible rate
right it's 1 over the square root of a
log of the number of steps that we take
so this is atrocious right it seems it
seems incredibly pessimistic so that's
the that's the kind of bottleneck there
if we wanted to get explicit rates on
the on the rate of convergence to the to
the optimum okay so the two key points
are that we we can you know the one of
the main ingredients here is we can
relate the the excess risk to the the
excess fire risk right which is what our
our algorithms are minimizing and and
this is you know one of the key tools in
in showing that as the sample size grows
adaboost with a number of steps that's
allowed to grow sub linearly in the
sample size has risk that approaches the
the optimum asymptotically alright
yep
generalization error rate Sian vs.
involved describing yes right yeah so so
the question is when when we consider
the relationship between the excess risk
in the excess fire risk there's this
function sigh or say in verse that
appears there and this seems to affect
the rates if you have a certain rate of
convergence of the of the fire risk to
its optimal value then that gets
transformed through this site function
to give you a potentially worse actually
it's always a convex function so it's
always no better rate of convergence of
the risk to the optimal risk so yeah
that's a good point and it turns out
that the the best relationship is a
linear one and the best relationship is
obtained when the when the cost function
is is least convex right so the hinge
loss for instance has a linear
relationship between the two the
quadratic has a square root relationship
alright so you get your rate gets worse
in that case so is that real does it
does it mean that you know you should be
using a hinge loss and not a quadratic
so that's not that's not clear if you
consider for instance cases where we can
work out explicit rates and look at
what's going on there one example there
is when you have explicit information
like see bakov kind of conditions on the
conditional probability answer turns out
the easy case in classification is when
the conditional probability that y
equals one given X is moves through a
half rather quickly right if it spends a
lot of time near a half that is harder
to make the decisions and the rates are
worse if it moves through a half quickly
then then it's easier the rates of
better so there it turns out that this
better relationship in the SVM k so the
hinge loss case doesn't help you write
that that that you get at the end of it
all you get exactly the same rate as as
having having a worse relationship right
so
do you know it's really unclear what's
the these are cases where we can get an
explicit handle on the right so it's
unclear that that that that is any basis
for for differentiating between one cost
function and another right I mean there
are other there are other issues of play
of course right when you put things
through this cost function then you're
interested in approaching the this are
fiestar the optimal fire risk what's
that going to look like as you change
fire right for a particular class of
functions you know the approximation
properties are going to be very
different all right so this is another
issue that you know really is just
hidden away in all these analyses
because you know that's like an
approximation rate and something that's
very hard to to get a handle on any in
any concrete situation right but yeah
good it's a good question what what what
differentiates these these cost
functions
thank you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>