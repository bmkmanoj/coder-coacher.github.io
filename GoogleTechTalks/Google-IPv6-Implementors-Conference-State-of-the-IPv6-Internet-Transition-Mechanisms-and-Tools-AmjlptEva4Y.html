<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Google IPv6 Implementors Conference: State of the IPv6 Internet &amp; Transition Mechanisms and Tools | Coder Coacher - Coaching Coders</title><meta content="Google IPv6 Implementors Conference: State of the IPv6 Internet &amp; Transition Mechanisms and Tools - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Google IPv6 Implementors Conference: State of the IPv6 Internet &amp; Transition Mechanisms and Tools</b></h2><h5 class="post__date">2010-06-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AmjlptEva4Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this section is broadly about the
state of the ipv6 internet and
brokenness and things like that actually
I'm wearing two hats but the Manhattan
wearing today actually is the you know
I'm chair also of the Belgian ipv6
council so just like you know we saw
yesterday in one of those flash talks
also in Belgium the ip64 has been
reinvented again and we're trying to you
know get some things done hopefully
hopefully in about the year two years
time actually it will not be needed
anymore actually I even doubts right now
it could be too late and they know the
use could be very you know minimal
actually so still thinking about those
things so what I'm going to speak about
is sort of like I'm going to be trying
to set the scenery for the next three
slots actually which will come you know
in the rest of this particular section
so the next things are going to be like
measurements for v6 you know in
different environments are we going to
speak about the brokenness of out of
ipv6 and we also going to speak about
whitelisting and some of these things
actually have a cause you know by the
non-managed tunnels and the reflection I
want to go to you know the key message
of this slight we're actually is you
know is are these tunnels actually the
future of the Internet can we actually
live on the internet with the use of
non-managed tunnels so by the way you
know just to wake everybody up again
also because we have like a 95 male
population if I put the face of Anjali
Angelina Jolie so hopefully it will draw
some attention happy eyeballs to the
slides so its content you know its
content so now some of these things also
tend to be a little bit controversial so
what I've done I've created this
particular slide here yeah which will
help people to jump up and down on their
seats when you see a written yeah so I
have like a things feature like highly
controversial medium controversial
whatever that means and not really
controversial so I have very little
green points here hmm so i hope i will
really satisfy your 15 minutes actually
so how this thing is carved up so first
before i start speaking about some of
the artifacts of non-managed tunnels i
would like to give you an understanding
of what is managed tunnel and once you
understand that yeah it's much easier to
actually explain what is it managed
then everything else I considered
actually is a non managed tunnel next
thing is also so some people actually
are happy with what these non-managed
tunnels things do so I'm going to give
you some reflections from different
angles coming from you know the user
case the enterprise case and from the
service provider case then a little bit
of philosophy is one of my probably one
of my red things like what is the goal
of the internet and how do these
non-managed tunnels fit into it followed
by you know some of these negative
properties of non-managed tunnels and
what you will see also is about trying
to gauge sometimes and actually we try
to give a balanced overview which
actually means i will tell some good
things about non-managed tunnels and I
have the unfortunate luck Lorenzo
sitting very close so you actually might
strike out and it will tell some
negative things about non-managed
tunnels and now we're going to conclude
and basically an outlet you'll actually
draw the conclusion of you know of some
of the content I've been telling you
about so basically what is a managed
tunnel now a managed tunnel actually is
what I consider at thing for which you
can contact somebody heroes somebody has
set it up for you you have like an
agreed SLA level agreements it works
perfectly and the way actually it works
is just as you current ipv4 negative
connectivity works it should actually
even be working you know as good almost
as you native ipv6 connectivity if you
would have it now of course if you would
have native ipv6 you probably wouldn't
need these kind of tons it also means
you know that you actually have like you
know reliable set of security
performance and integrity parameters
attached to the tunnel itself and also
the administration rail I'm actually is
you know is something you can actually
contact somebody you trust somebody you
know you'll pay for for delivering this
particular kind of service and so
basically when I'm trying to say it's
like anything which doesn't fall into
these categories actually an account as
a non managed tunnel so some tunnel
experiences so so when I speak you know
two people and I know and I tell them
like a six to four is maybe not the best
thing to do now the often the answer I
get back it's like yeah but it works
really really well for me you know i
have no problems it's my only way to go
to the internet
may be true you know if you like you
know 10 or 20 or 100 users or so you
know technologists but imagine if you've
like 1 million of them you know it could
be a potential issue that all the
comments are here is like oh I didn't
know what using ipv6 that's funny good
that you tell me but that would really
care too much then also the enterprise
view is another thing so when you look
into 624 then often you know what people
say is like a 624 kiss me like you know
very a symmetric traffic parts and
perverse traffic you know directions and
so on words now that is actually true in
some cases but not in all of them
because sometimes actually you know 624
for example can follow you the four
traffic part through the network if you
go from six to four site to another six
to four site it's our only on the
certain circumstances we actually have
the potential of a symmetric traffic
pots now for the story is provided so
what do I hear they're actually often
say about these non-managed tunnels so
so some of them you know so the good
service providers they actually get
about their customers and what they do
is I want to give the internet
experience you know the best possible
angle so what you actually do is they
actually provide like six to formulate
in the network and they either make it
available for everybody over the whole
world but it just really restrict it to
their own customer base now one of these
elements that of course is you know that
will cost money and the question is you
know how much money is the search
provider willing to invest to help other
casting known customers basically so
that's always a question you know
they're taking apart and then the other
thing about these non-managed tunnels
you know what I hear from content
service providers it's like yeah
whatever you know but what I do see on
the internet it's like you know with
these tunnels I see like you know a
measurable difference in my you know
round trip time and in the quality i get
from these guys and as a result you know
i cannot really enable all my v6 content
right now just yet and as a result you
know they will have to use in two
different measures and all different
techniques in enabling v6 for the
community actually you know in a
different kind of a way but more not
later on words so so
the way I see actually you know how
these things fall into the internet
actually as such so the internet when it
is growing it should actually be a
platform you know which can grow beyond
what it is right now and should be a
services platform it should so it should
be a service platform actually and it
should be providing a simple control
plane for end-to-end connectivity and
the idea should also be that you know
all men all machines should be able to
connect to the internet now the question
is here you know do manage non-managed
Turner's actually follow this
fundamental that's a big question and
especially going on further the one
which is probably going to break it most
is you know the v6 Internet connectivity
should be as good or better as a
perceived quality of the v4 internet and
right now there is not a case and I
believe you will see some measurements
later on words but that actually is not
the case so now going further on the
question why people actually initially
invented non-nationals and the main
thing is actually you know in the
beginning it was for early adopters
everybody's connecting to ipv4 some
people actually want to have ipv6
connectivity and then these tunnels bit
perfectly at the same time it also
provided for example a decoupling
between the infrastructural readiness
for ipv6 and the application readiness
of ipv6 so by using these tunnels the
applications could potentially
experience some v6 connectivity there
then of course you also have like no if
implemented if you sitting in an
infrastructure if you want to do it in
control steps then these tunnels
actually might help also a little bitter
now going further to the properties so
one of the first things what we often
see with non-managed tunnels they tend
to use well-known IP addresses now an
artifact of that is that it creates
actually lots of potential for a
symmetric Turtles and now the same thing
actually could potentially be happening
with ipv4 but with ipv6 with non-managed
tunnels the probability for that is
actually much higher and so
I put like a little drawing in there for
example you see on the bottom so you
know the laptop with two routers you
know it probably will salute like
you know for the well-known tunnel relay
or something the first track on the top
there and then the other one will take
the router and all on the other side of
the slide here not the tickets
performance so there is like a series
decoupling of what the guy using the
tunnel actually expects from the tunnel
and the guy delivering the elements to
create a tunnel with no direct
correlation between them and one of the
questions you can actually ask yourself
is like you know do you actually want to
provide a managed service of the
internet over an unmanaged
infrastructure element so that's a
question you have to think about so
another element is also like you know if
the tunnel is not working perfectly
correct then how does the end user
actually how can I complain to the guy
providing the relay router for example
that is not working correctly you know
how does it actually even know who's to
relate out who owns that particular real
a router I'll just be in flag to have
one more minute so okay so just two more
slides and this is a red one actually so
one of the things also is the realm of
control so what is very important here
is that a non-managed tunnels from the
artifact that you actually use third
party involvement to actually create you
know your ipv6 productivity and the same
thing actually is also happening you
know we need before well of course if
you send the packet from one end to the
other end of the internet but that is
just forwarding traffic in this case you
actually use third-party middleware
which is complete different equation and
a whole new set of parameters and
variables which actually are in you know
yet to take into account that results
actually annoying things like you know
suboptimal flows if you middleweight is
not working perfectly correct which will
increase your round trip time and packet
loss if you have a low performance like
real a router the whole thing could be
screwed up actually because you
experience suddenly you know with each
tunnel over
experience much worse experience than
you actually are seeing with ipv4 and
then the other question is like you know
who is going to be responsible for this
degraded you know service you actually
are getting of the internet then a few
words about security so as we have seen
also earlier doing things in tunnels
creates problems so it creates issues
with firewalls it creates issues for
deep packet inspection there is like a
particular draft also like you know the
external security concerns and they're
valid for both managed and non-managed
tunnels but the importance of the
security elements actually is actually
higher for non-managed tunnels because
you don't have control of all the
different elements playing and
generating these these tunnels actually
as such and then of course sticks to for
the special case and it also has its own
security considerations sections
actually in there so now going to the
conclusion so so what I've seen actually
is that yeah early adopters you know
they have been working very fine with
non-managed tunnels you know in the
beginning like if you see if you speak
to Tony hain it's like super happy with
is 624 connection but imagine if they
would be like in a 1 million Tony hands
it's going to be a small issue because
then both right EF and for many other
things so and also for the Internet in
that case because they will all go to
the relays and the relational crash and
burn which may be good equal Cisco
because you will buy more of these if
you want to invest but that's maybe not
a good way to build up the internet
infrastructure and so if you go from
mainstream usage then and all the things
but I can see actually as a result of
these non-managed ability you know this
tunnel is like no black holing perverse
traffic parts you know nope nobody
really wants to invest in relays you
know hard to manage you know difficult
security model and the consequence what
I see how that is directly is that
content providers cannot just switched
on ipv6 right now just yet for everybody
we just sort of earlier with the
previous talk google also is you know
having some issues David switching on
for everybody and at the same time it
you know one of the consequences also is
that we are now starting to discuss all
these things all day
legitly with whitelisting you know good
citizens in the internet to actually
have proper ipv6 connectivity so if it
would be up to me I would just you know
deprecated all these non-managed tunnels
things going forward but it's maybe too
much of a high ambition but you know we
can only try so that's what actually
yeah negative connectivity you know just
native yeah so any questions okay oh
yeah lunch 12 points of light you make
the first one about 62 for the tunneling
is a symmetric by nature and even if a
service provider wants to offer relay it
can offer a relay on the outbound path
from the 62 for customers to the native
Internet the real problem is when a
packet comes back yes because it has to
go to somebody who is going to advertise
2002 colon chrome / 16 essentially
acting as an open relay for the entire
internet and there's absolutely no way
to restrict it to your own customers so
you essentially rely on somebody on the
internet offering free transit then you
have no way of knowing who is going to
be the one that is selected by the
packet on it sweetened patterns and
we're really really serious issue so
this stuff is fine for early adopters
I'm not sure this is a question about do
we need to duplicate it or not but it's
create problem when home gateways turn
this thing on by default and the
customer is not aware of it yes and
maybe a recommendation should be this is
fine if you want to use it but don't
make this on by default yes that is
toward I think also next to that there
is a degree of control element you can
have you know you could potentially you
know announced in internet like 2002 and
then a set of the pre fictional of that
particular service provided and limited
a little bit there but as maybe not very
allowed you know had some procedures
against said in the RFC for a really
good reason because if you start that
path you import the entire before
parting table in v6 yep
but it's a way out there are possible
things content providers can do too for
instance you know we've for a long time
investigated trying to and cap six to
four responses directly to users but
that sort of fraught with peril to but
you know it's not totally uncontrolled
on the return path but yes it it's it's
quite problematic that's what I'm fine
I'm probably Kiyosaki from the ripe NCC
I lead the science group there and I'm
actually just going to present the work
of my colleague Emil Abin and for those
of you who don't know ripe NCC is the
regional internet registry in the
European and surrounding regions so just
like Aaron around here first of all we
would like to have more insight into the
into the v6 deployment and and how many
clients are there really using v6 and
basically most of you are interested in
how this goes but especially that's true
for an IR IR because we are in the we
are the numbers business so it's really
important for us it is also true that we
have heard a couple of different numbers
about how much v6 is deployed really out
there for example if we look at our
statistics roughly twenty five percent
of our members have actually v6
allocations but if you look at the
routing table you see that roughly six
six two point six point one percent or
so of the actually announce any
kind of physics prefix we also hear
different numbers between well today
between point twenty five percent and
two percent of web clients actually
connecting over 36 22 different services
so that made us wonder so where is the
difference between the twenty-five
percent and the six percent and the two
percent or one percent or whatever that
number is today we kind of devised a
method to try to make a distinction
between the clients themselves and the
infrastructure that they are using and
we were hoping that that actually
we'll explain some of the details so how
does that work this is the good old
methodology everyone knows that the end
users connect to some participate in
website and they actually fetch some
kind of a JavaScript or embedded code
there that actually redirects them to
some measurement network in some of the
cases that's actually the participating
website itself but it could be a
different network that's that's all fine
and well most of the time what happens
is some background image and object
fetches or on v4 v6 and on dual stack so
that you can actually check which one
makes it there and which one doesn't
they added twist that we try to put in
here is to measure the provider in
infrastructure and a one way of doing it
is to try to provide the DNS queries
that the users are themselves are
actually making while doing the queries
to the measurement network so what we
provide here is we built up a really
small DNS server as well behind this
measurement and we force the clients to
do special named object check object
fetches and those names actually include
a unique domain name as well for each
and every request and also the as you
can see the URLs the URLs also contains
some unique ID so that we can make a
difference between two different clients
so we can try different combinations of
forcing the user to go through on v4 v6
and dual stack HTTP and providing
different responses on DNS v4 v6 and
dual stack so if you draw up a matrix of
what is possible to do here this you
have this matrix of 9 cells and actually
if you really want to go for the full
experience you can do all of them but
most of the time it's just not worth it
it's just too much these are they
actually the four measurements that we
do it's easy to understand the v 4v four
that's kind of a baseline measurement we
can assume at least for today that that
is actually going to work for all of the
clients so we only take measurements
that where the v4 before actually made
it through and then we can do that we
only provide the NS responses over v6
but
require the client to connect over 3 4
and so on and so forth and finally on
the lower right hand we do the the dual
stack dual stack response that actually
covers most of the missing parts so
there's not really much point in doing
over line okay what we did was started
to measure a dub dub dub road i dot
right dotnet that but ever since then we
have expand it to other sizes well we
know that there is an operator skew
there this is a technical audience
somewhat and we also know that this is a
ripe regions queue which is kind of
intentional so we don't really want to
expand to the whole world there we also
know that not all of the clients
actually use their own default dns
resolver that's that's fine some of them
are using opendns some of them are using
cool so that's okay we also know that
not all of the clients have JavaScript
turned on now you can say that there is
some relation between the clients that
actually turn off JavaScript versus how
ipv6 capable they are because most of
the time those are the techie people but
we can leave that with that assumption
so as long as we are aware that that
might be there it's okay so results well
you cannot really see the lines there
but that's the good news here is that
you no longer have to use a microscope
it's perfectly enough to use a looking
glass so if we lose the looking glass
yeah that's good news i believe okay so
this is what you see for again dub dub
dub right that net that this actually
excludes the ripe NCC its own internal
infrastructure so we don't want to screw
the measurements there because then v6
would be much higher but what you can
see here the different colored lines
mean of course different things as you
can see on the right hand side I would
like to draw your attention to the blue
line that actually means clients with
ipv6 capable resolver so that's the one
that actually shows more or less the
infrastructure component that the
clients are using the blue line is VC
capability so when the clients can
actually connect to over v6 and the red
one is preference so given the choice
they actually use v6 you can see a bump
roughly in early May that's because of
the right meeting that we had
in Prague and we provide native physics
connectivity there so yeah there you go
now if we filter out the non-managed
tunnels thank you for the term we
sometimes we internally be called auto
tunneling but it doesn't matter what you
say the picture changes differently just
decide if I go back and forth you can
see that they are almost exactly the
same the interesting thing here is if
you download the presentation you can
actually check it out yourself is that
the clients with v6 capable resolver
line changes as well strange because
that means that the resolver the DNS
resolvers themselves sometimes very not
very often but very rarely but that
sometimes they do auto tunneling as well
strange for comparison this is a weblog
analysis on dub dub dub again on a
longer time scale and you can actually
see the peaks those are right meetings
as well and yeah one interesting thing
to see here these are roughly the same
numbers but one interesting thing to see
here is the change of behavior roughly
in march this year and that is probably
because Oprah changing behavior it's 10
dot five or so ever since then they
don't prefer 64 anymore okay a different
we view it's the weekend effect you can
actually see that on the weekends the
client ipv6 capability goes up one would
think that it goes down because in the
office you might have more v6
connectivity but it turns out that
probably due to all the tunneling at
home more people have the capability to
actually use v6 the other numbers don't
really change I'm not really going to go
through this but some people would love
this especially slovenians and Sony ins
they are really really high above the
average in terms of basic usage some
pockets of native v6 we picked some
places where we actually see much more
native physics than anywhere else and of
course Slovenia is on the top that's
good yet a different view and this this
might be interesting so we have seen
roughly 12,000 a s numbers that actually
had resolvers in them roughly almost 4
that had what clients in them and you
can actually see the ipv6 differences
that we still have more ases relatively
more ases with v6 capable resolvers than
clients and so if i also add the two
other numbers like that roughly one
percent of the clients actually use v6
and roughly twenty-five percent of the
ISPs have v6 allocation that you can
actually make this hierarchy so
twenty-five percent have basics
allocations four point nine percent have
actual v6 resolvers roughly four percent
have web client but v6 capable that web
clients and roughly one percent actually
use it random facts that we have
discovered google boat actually does
java script so that was surprising at
the first sight but then we realized you
know actually that that makes sense in
some of the measurements we see that the
client is is not the same as the
resolver AS so we take the IP address of
the resolver we take the IP address of
the client and we compare whether they
are in the same AS or not this is due to
google dns and open dns most of the time
we try to drop instrument interesting RT
graphs about this where we had blobs of
a SS and arrows between them if they use
another aes for resolving stuff and it's
really really cool to see that there is
a huge crowd and in the middle there is
Google and the people are just pointing
at it because many many many of the SS
are actually using google and it's also
true that in many cases we do see that
the client v4 resolver Reyes is not the
same as the v6 resolver Reyes which is
also kind of a but why and that is
according to our understanding that is
mostly because of tunnel broker things
so on v6 you end up somewhere completely
different than up before it's fine
what's next we want to keep this running
especially because of the v4 ran out and
we really really want to change and see
the changes that would be really fun we
also the something that's not mentioned
here is we want to introduce more
precise timing so that we can actually
know if there are delayed if urance is
between before
basics but many other people are
measuring that already so it's not
really in our focus and finally we know
that the dub dub dub reply the net and
connecting we're satellite websites are
really skewed to the techie crowd so we
really want to measure average users and
we started up a program especially in
Europe where you can just join in and
you only have to host this tiny bit of
JavaScript and we will give you the site
statistics about your v4 and v6 and
that's it I hope I'm in time the
questions questions okay thank you
right so again this slice was on the
last minute so and this is some of the
data that we've just recently started
collecting literally over the last few
weeks about brokenness in the internet
we have had this running for a long time
and there have been several challenges
to this summon the methodology some of
the sheer volume of data that we were
able to collect previously so this is
more recent data than we've presented so
far but so first of all let's let's
start to you know look at the problem
what is the problem so the problem is
that the way this is all supposed to
work it was was laid down by it adjourn
and I think 1998 and it's basically you
you're a dual stack application you make
a DNS request you get all the riddle you
get all the addresses that you want to
connect to in order and you try to
connect to them in order right you take
the first one that comes back and then
the idea was well if you if you have a
local failure and it's fast and you
don't have any connectivity you'll just
try them it will fail immediately and
you'll just go to the next one that
works so um and that's a you know that's
the way applications are written because
it provides a sort of a seamless upgrade
path for you know when 1b6 becomes
available you just start to use it so to
that end get a dream fo is which is the
sort of function that you use to most
browsers used to or applications used to
look up names to IP addresses usually
usually returns ipv6 first there's the
RFC 344 says what it actually does but
if you typically have both of you for
dress in a v6 address it'll return
before first and the application would
try before it would fall back to IP it
is we'll try pv6 would fall back to ipv4
and so you basically try all that all of
these six addresses one by one if and
then one day and if they all fail you
start trying to be for rest as one by
one if they all fail you give up so what
what really is the problem how bad can
this get so there's very failure moti
right there's there's a host local error
if you if your host attempts to connect
to a be 6 verse and has no b6 address
configured it'll fail
the colonel will give you a sort of
destination unreachable message and
we'll just say okay and that that's
essentially instant it's a micro seconds
or however fast the system call
completes enid on reach right so that
that's no problem if the application
does fall back the way they were here to
join intended it but oh but some
applications notably Java do not do this
they have the concept of an inet address
and the socket may only connect to one
address and if you in the canonical
implementations of Java not the Android
implementations do connect only one
address and if it fails then it fails
and it gives up so but most applications
you know the exception of Java and the
personally put this down with the fact
that java the java api's were designed
so much it's so early on in the in the
v6 transition that they didn't
anticipate this the good news is that
you can fairly easily fudge this in Java
by making a connect by name connect to
all the addresses in sequence although
that's not compatible with with other
implementations so so okay so but this
case is usually easy you get a nice fast
failure you know it happened and you can
try again you can also get a network
error for example your Rooter could
could could be telling you look there's
I'm your default route oh but you can't
get there from here that there's no way
you can get there and the way you the
canonical way to do this really is to
send on I unreachable back right say no
ICMP unreachable a lot of applications a
lot of implementation actually
completely ignore unreachable they just
say okay well unreachable well i'm going
to try anyway because somebody might be
spoofing me unreachable or whatever or
so so what what we've seen happen in the
past with networks that have v6
addresses but no connectivity is that
some element inside the network will
fake rst packets and you'll say no
nothing here yeah actually i'm i'm close
poor try the next dress so by and large
this actually works and it's it's a
reasonably fast failure in the sense
that the right that the time of the
failure is only the packet getting to
whatever
spoofing your packets and then the
packet coming back with the reset I
don't know I'm you I think the people
that run these networks in this room I I
don't know where it's done presumably
it's done pretty close the important
thing is that it's not done at the
server side right it's not very far away
I would expect to be less than that so
it's reasonably fast compared to what
we're seeing with compare the numbers
you'll see the next slides it's yo
golden so there's also black holing
right so the Rueter could be advertising
a default route and it could then be
proceeding to black hole the packet so
either locally because it's bad
implementation or assemblyman to the
void or sending them to some really
that's not working or they could be
black holing and you are in the network
right packet loss in the core or
whatever and then there's mpu holes
typically misconfigured firewalls
dropping a cmp but Mars has presented a
whole slew of cases where this can
happen so masses compilation is much
more comprehensive this than this but
anyway so MTU holes are particularly bad
because either you never either tcp
never recovers and I say that it never
recovers but already feel my son
corrects me it does recover but it takes
a long time because it sort of has to
you know away from various timeout so
anyway so what do OS is do in this case
is i did some testing I actually managed
to obtain a windows laptop under the
duress and them and try to and and try
to see what it does because they know
ultimately they our users are using
windows so so we need to understand what
happens so in in most cases and I was
testing browsers because our main our
main motivation for making as fast as
HTTP right and because smtp if you get a
20-second delay failure well maybe
that's still okay but if you're trying
to wait 20 seconds for google search
then it's not ok so for local fellows
are fast unreachable at the time it
really depends on the u.s. if you're on
Windows it'll take you 20 seconds and
this is per quod a record remember so
per every record that you try will take
you 20 seconds Mac takes
four seconds and Linux just says Oh
unreachable let me try the next address
and it just bang goes there black
calling a cylinder except Linux has a
three minute connection timeout so I
actually saw my when I black hold my
Rooter by screwing with my v6
connectivity I saw my linux box
faithfully trying to connect to google
com for 19 minutes before finally
connecting over before and it just stay
it just SAT there spinning so there's a
lot of we could have I mean this was
chrome in hindsight we could sort of
improve that but I'm tu holes again tcp
never cover is not true it probably I
would have thought that it would recover
in the order of seconds I don't have
data on this so this is incorrect even
if fair user fast and this thanks thanks
again to mass for pointing this out to
me applications may have other limits
for example IE 7 and above gives up
completely tries five times it says well
you know there's nobody here I don't
want to waste my time and so it failed
it just gives up so that's not good
right so so in our in our current
initial and current implementation job w
google com may have up to six squad a
records and this is for various details
of our internal load balancing and
because we wanted to have exactly the
same number of quad a records as we did
a records because we want everything to
look the same well it turns out that
this is not a good idea if you're
considering brokenness so on a Mac this
means 24 seconds on windows it means two
minutes and on Linux it's either by the
gets there it takes again in 19 minutes
if you are on ie7 and you're trying to
connect it will not work it'll just fail
it'll take a long time it'll just give
up it'll say page can't be displayed the
nice thing is that if it tries again it
remembers that those three addresses
failed and it goes through the other
three and then it connects again but you
have to reload the page so needless to
say I mean this is broken we can't
accept that right so so we are going to
mitigate this damage by publishing one
quad a record um we haven't rolled the
code rolled out the code to do that
quite yet but
where we're going to do it that's still
20 seconds right so you know would you
like to wait 20 seconds when you go to
Google would you like and so and sure
the impact is over plain HTTP the impact
is only on the first connection but if
there is XML HTTP requests or things
like that each one will be counted as a
new connection each one will each map
tile will take 20 seconds to load again
would you like that no neither would we
okay so so what what's going wrong we
have we have some indications some data
point some samples of things that are
broken so typically and this is there
may be just me seeing 624 you know
bogeyman and bogeymen all over the place
I mean Reuters will you know what what
I've seen happen of what had both seen
and have first-hand reports of it
Reuters will turn off 64 and go through
broken relays and at best you'll you'll
see a latency increase and or the relay
might drop okay packets or might refuse
to drop your to root your packets if
you're coming from native address so
even if you have native connectivity at
the same time there's six to four real a
root this 64 rueter will impact your
connectivity and at best introduce only
latency increase reuters have been known
various from various vendors have been
known to turn on 64 with private
addresses guess what that will work it
really won't so some implementations do
it anyway and and the host has no idea
right so well I suppose it could there's
stuff in the host it could be fixed as
well I mean that the host might prefer
again this the 64 root or / the native
rota as before example if the 6402 sense
sends RA is more frequently or if it
sends a higher priority for example all
right so we might be able to fix this by
by setting ra still high in native
reuters but that's the only hammer we've
got and we probably there's nothing
higher than high i think so we might
think carefully about that host may
prefer the 624 so this is which route or
I send my packet to and again and
there's another thing that the host may
do it might decide to use the 64 address
to send the query instead of for example
before it probably wouldn't prefer 64
address overnight
because the RFC says explicitly not to
do that but it might prefer 624 address
over an ipv4 address as a source address
so it might prefer you 64 over ipv4
either if it's not using a properly RFC
compliant gather info or if it's using
private addresses who uses public
addresses these days and this is known
issue in RFC 344 it's it's being fixed
but the implementations that are out
there some of them actually and notably
one notably the Mac implementation now
that opera has been fixed still do this
and similar considerations for Torito
torito's a absolute nightmare for short
lived you know requests there's a high
set up times it might or might not work
it pro it cycles through the various
possibilities that it can have and most
implementations don't do this they know
that Torito is to be used only for v6
only and this is my favorite so um I
please don't look at the MAC addresses
and try to find out which implementation
it is I didn't have time to blur it out
in the slides but anyway so we have this
home gateway that's sending out a Rooter
advertisement that's obviously of the
prefix 0000 / 64 now that that is just
beautiful to me so it's sending out a
null prefix the host is accepting it
saying this is my RA this is my address
so it's forming a nice a nice address
here that's it it's not even a v4
compatible address it's it's it's a
broken address it's not a unicast
address because it's not in two thousand
it's just broken the host is happily
confirming this address on its interface
it's trying to use it and the route was
saying no you can't get them from here I
don't have a root and the host is saying
sin and the root of sync no sin nope sin
and then after four times it tries it
says oh well okay I'll tried it actually
oh let me do neighbor and reach ability
to figure out if that Rueter is actually
still here and it says sin to another
address you'll note that the that the
first is trying to connect to chronic or
93 and then 263 so this took 24 seconds
because you know each of these takes
four seconds and so yeah so these are
the problems and later on we'll talk
about how we can fix them so what do we
do to measure them first of all we don't
know how many there are so
Robert talked about how how this type of
connectivity measurement is done we
we've done it before others have done it
before we basically try ask the browser
connectivity for energy or stack website
and see what happens we made a few
tweaks with respect to our initial
implementation we use long-lived
websites where people stay for longer
periods of time so we can actually check
you know after 30 seconds or whatever
are you still here and for example
youtube or gmail we use javascript to
make multiple measurements in one
session so we can actually group these
measurements for a single session so we
know who what a user was doing and that
also allows us to multiple measurements
like add like add a few checks or checks
with four hosts with with v6 own glue
and so on and we have the central again
after after a given amount of time say
are you still there and this is useful
because if if in a knave measurement if
you connect over for example say you
asked to connect to dual stack first and
then the user disconnects and then would
have come in over before we just
disconnected you ignore that you can
ignore that measurement other one other
than instead of interpreting it as
broken we also used one time host names
because it sort of dynamically generated
new host names because you can associate
measurements you can find out if
browsers if browsers ask for quoi days
and a s hopefully you can find out if it
took them 30 seconds to resolve a quad a
if they ask in sequence and so on and we
improve prevents caching we have about
10 million samples per day at the moment
it all depends on which frequency you
want to run this experiment only web
requests we our analysis is in the
initial phase still before also has non
non zero failure rates we see the 30 we
see a request after that scheduled after
30 seconds show up before the request
that was scheduled immediately so I just
ran this number i don't even know
exactly which data it's on this number
is but again that the number is scarily
high right that's that's that's really
still not acceptable it's it's one of
our out of a thousand users and this is
a whole of the whole of the internet and
there's also stuff them on before that's
broken as well so we we need to factor
that out but this is the wrong
what is the effect on network so there's
a large isp sample large is p 0.06
forces residential SP with sort of
whatever home gateway they have 0.06
four percent that's you know if it's 10
million people that's you know six
thousand users do we you know that's
kind of not acceptable still whitelist i
listed isp given our current measurement
models we can't really we don't have a
really good handle on that we need to be
able to measure on or not one on white
listed website but in this case that the
spread with these four is is is sorry
less significant than the above it's
much closer to v4 and that's because
whitelisting must the brokenness so we
still have some somewhat to do their
different os's have different numbers
for the larger HP above if you take out
if you take out mark which is a smaller
person certainly not the majority of the
accesses from this is p you see a
dramatic drop in the level of brokenness
so maybe this can be addressed in the
implementations and that's why it's
probably because Mike prefers 64 so how
do we fix this you can't fix the home
gateway well you could in theory you
could upgrade it users don't upgrade it
they don't know what to do they don't
know it's broken and the firmware
upgrades aren't available anyway so
that's a non-starter really from my
point of view you can't wait for them to
be fixed because we don't have time the
shelf life of these things is the story
the life of these things is multiple
years so to me that's a non-starter and
this problem is not going to go away and
so we need to find a fix one thing we
can do is ship all these users new CPS
maybe that would work we'd have to know
who they were and so on those problems
we can we can work around in
applications for example we could put
you know fixes in chrome which is open
source you could put four fixes and
firefox only mark schlumpf can fix
internet explorer on the apple can fix
Afari so this is a sort of limited scope
solution to fix all the applications you
need an OS upgrade and that will also
fix your root of problems and so what do
we do on the first side there's Dan's
draft of happy apples that's a general
and perhaps
little more complex than we need to fix
a specific problem and it also needs to
be implemented or as a shared library or
into a pre-application OS X from I OS X
I think apples plan a record is to do
parallel connects that won't fix MTU
holes unless it also recovers but it's
it'll get most of the way there and one
thing that that actually yeah Igor oh
and I were discussing at where was it
the ITF was to have implementations
probe the networking on attached when
you do dhcp I think windows already do
does check for captive portals and takes
an HTTP request sees it if if it gets
what it's what it expected to get and if
it doesn't it says you may be behind a
captive portal click here to find out or
log into your internet and do something
so you could do this and you could pop
up put up a little bubble of the user
saying your v6 is broken please please
fix or please hold your ISP or please
disable because given the numbers that
we have disabling v6 is a perfect
solution for me if 0.05 percent of users
disable v6 sure the native users will
get there that's not a problem so so
yeah this is this is one thing that I
definitely see but this all these
solutions require OS vendor buying and
unfortunately they're not in this room
even though we did try to contact them
and yeah that's it so any questions have
one I think it would be highly useful if
you could actually track these numbers
the brokenness numbers over time and it
would be even more useful if you can
publish them we know um maybe I I
um I know you know littered so so so so
first things first we haven't really
even got off the ground these are
preliminary numbers I fully appreciate
the value of these numbers and I think
that it would do there it would be
useful for isps to to do this it of
course depends on you know what level
abrogation you want to publish the data
for how do you allow only ice piece to
see their own numbers you know you
certainly don't want to publish
individual user numbers for privacy so
that it needs to be a balance there but
I I agree and and there's also a certain
amount of infrastructural work that
needs to be done to actually get this
data published in a reliable way and and
and it's sort of it takes time I think
that we completely agree the scary part
of it is that i have seen a couple of
presentations in the last two two and a
half years and all of them mentioned a
single number that you presented like
three years ago in Berlin or something
and then I asked the course so and they
said this is the amount of brokenness
and we don't want to lose these guys and
then I had the questions like so what's
that number oh wow that's the number
from Lorenzo okay and this is this is
our network right we you know I so I
completely agree that you know you have
a big network you know your numbers but
it is Carrie that those numbers are
quoted and used and business decisions
are made based on those numbers and
people don't know what the numbers mean
they just know the numbers vulnerable
yes so and so the reason so we have
published a paper on v6 adoption as you
may know the reason why we didn't
include these numbers and not these
actual numbers the numbers that we had
earlier is because we didn't have we
didn't have space in the paper we also
didn't have a sort of complete faith in
the litter so we also didn't have
complete faith in the inn in the quality
of these numbers in these Memphis and
the methodology that we had at the time
I personally think and others may
disagree that this that these numbers
are more solid than the ones we had and
we could think about publishing these it
would be more useful to
publish them on the web than to write
them in a paper huh Dara but there are
but the point is also that there are no
numbers right there's there's tour
Anderson who publishes a monthly
newsletter of brokenness and what he
sees there so did that answer all your
questions oh and of course I mean did
every it's only fair to expect that you
know every isp makes her own business
decisions based on their own numbers if
they have them right well okay all right
so two part question number one with the
brokenness do you have any feeling as to
what percentage is effectively inside
the home versus brokenness outside the
home the reason is is obviously as an
ISP I'm trying to do native connectivity
what I'm just what I was thinking about
was if it's outside the home it's
possible to effectively build your own
64 gateway and teredo gateway and put a
captive portal behind it and in fact
suck in all those requests and
effectively be able to tell your
customers how you've got broken
connectivity but if it's inside the home
there's nothing I can do about it so is
it I'm just rated like that's an
interesting thing for me can I fix it
for people and tell them because I'm not
content so I don't get them connecting
to me so I can't see as a nice p because
people hate it when I look at their
packets uh yeah so I can't I don't have
an answer for that because from from our
perspective right we were at the very
end right it's hard to tell I'm if you
if you were able to connect anonymized
anonymized packets of ipv4 of sorry of
624 coming from private source addresses
which will never work right then that
would be one way it occurred to me that
you can do that and in sort of an almost
you know like a voice SBC kind of way
where because you know that the it's
probably come through an app and the
outside has been translated you can
actually guess where to send it back to
so I'm just trying to think is by
this is why I'm asking is there some way
of effectively as an isp being out to
tell people they're broken I don't know
okay ah suresh krisshnan I had like
question number one of your slides it
looked correct me if I'm wrong but it
looked like you're endorsing the Austin
solution of actually doing connects
parallely right I would have thought
like you would like really hated as
Google but um is that your opinion or so
um to us I mean if I mean if a user
can't get to us that's a bigger problem
then if they use a census in and we then
close the connection I think we can work
with that so I mean one of these is a
scaling issue the other one is an
impossible problem right so because
because we we you know we might not like
it if we get double the double number of
syn packets and I haven't run any math
because because we could do whatever it
takes right to know to get out it's not
really imposing any sort of either front
end server load or back in server load
really it's it's all load balance the
load we can we can scale to that what we
can't scale to is fixing people's home
Reuters because we have no access to the
right but like does Matt go Matt like
last time I saw like mac OS are actually
not completing the connection there's
kind of like letting you like just hang
there on your side right no I don't know
I I don't take it I think it does and I
think it resets the connection once it's
done yeah well I would hope so otherwise
they have to keep they have to maintain
status right last time I saw they're
doomed so and would only League file
descriptors I mean I'm not oh yeah okay
well that yeah that sounds like a bug
well so there was a books just curious
um who else is like look trying to to
conducting measurement stuff like this
anyone Wow nobody cares c 2 i'll buy you
guys beer i will gladly buy you guys
beer later great fantastic cheap it'll
be cheap night for me but I mean so
seriously I mean like anybody who runs a
network here
I mean we've talked about this in a
while but we're going to we're going to
do some of the same try to do some the
same stuff and you know having a data
available is really important right i
mean this is this is a pretty big
problem I'm kind of wondering why nobody
is else's I mean I was kind of hoping
like have the room and raise our hand
that there are people not in this room
that have that that have done that as
well I think Nathan Ward has a script
that's publicly available that you can
use to do this you put it on your
website and then there's tour Anderson
right it has two more people yes you're
more people yeah but I guess I guess
that it was my so but you know if our
network some somehow you know turns one
in 10,000 packets into smoke on the
backbone then you know you're trusting
our number is it sure it you know will
trust our own numbers but you know your
mileage may vary yeah but but Tony the
Tony Tony the thing is i mean like to
this gentleman's point over here I mean
there there Lorenzo's numbers they're
not you know insert company names here I
mean you don't you figure that you care
enough about it to go generate your
information naive I am depends where you
are and lived on the long tail of it in
fact that was my point yesterday was
that we need a common set of tools for
how these measurements get made so that
we don't have you doing a set of
measurements and your numbers don't
correlate with what he's doing because
if you all go off and build your own
tool set to do this monitoring the
numbers won't match and people get
confused if everybody's got a common
tool suite that was where I got it
yesterday it's like you know we need to
think about how we come up with a common
metric for how we do this measurement
and what it means but you know I was
saying earlier anybody that directly
peers in with Lorenzo and has control
over the endpoints mobile carriers right
will not see any of this brokenness they
will have absolutely zero yes they're
not gonna be doing I'll any of these
things behind that thanks Tony and now i
can sit down at my only point no in fact
that was well as I say it's like if he's
got complete control over the endpoint
and he's directly peered he's not going
to see the brokenness that you're going
to see because you don't have control
the entire system and so where the
measurement gets made gives you
completely different answers and we need
consistent measurement process not this
is all this is all based on assumptions
you're based on is basing it on
assumptions that the host tax work fine
that everything in the chain works fine
this is sort of end-to-end data which
could be affected by if you install if
you're a tethered machine if you're you
tether and you go to firewall in your
laptop doesn't do v6 your shop is broken
so let's make that a goal then that's a
good what let's make ipv6 end-to-end the
goal it is the goal we have to get there
somehow but there's a new idea we're
done hmm nice couple questions nice
couple quick savings okay I'll be quick
here here but but it's also true that we
don't need 10,000 sets of measurements
right I mean if we have 10 sets of
measurements and they all point the same
way then perhaps there is a problem and
we need to fix it right I'm not sure to
agree with that I think it's valuable to
have multiple sets of measurements
because the body of users hitting a
given website can be different and the
level of capability the level of
brokenness may be different for
different types of applications I think
the question aren't close to you two
things first with regards to the
measurements that you detailed here um
is it proprietary enough to google that
you wouldn't be willing to share that
make it publicly available so more
people could use it because it looks
like you kind of talked to share what
the methodology or the implementation
the actual implementation that the code
for something is not specific to your
implementation but more specific to
something that people could put on their
website and use this the code is the
code is the implementation it's by
definition specifics of the
implementation we can share the
methodology probably and I'm not the
person who would mean to prove such a
thing but we did share the methodology
for measuring adoption so I don't think
you know person I don't think they'll be
controversial but the cut you wouldn't
be able to do much with the code i can
tell you well and that's gonna
where I was going with this is that it
may be it may it ends up having to be an
offshoot where you have the methodology
getting implemented in a more generic
code form that people that the community
could use and you can kind of pop and
publish that as look this is out on
google code go download it go put it on
your websites you can get that
information I think such a thing already
exists right nice and wads toolkit
already a bunch of stuff is public and
also it's it's the JavaScript right you
could get it and like you know right me
to yourself the problem is that this is
this is a measurement between two
endpoints right and nothing in the
middle can really snoop and know that
this is a measurement and I should be
watching it and that's an example of
brokenness right right we know that that
we didn't see this or we it's sort of a
web web content specific thing at the
moment but it's still something that
could be valuable sure it's definitely
application-specific we're not measuring
like they have an SMTP yet or anything
like that the other thing I was going to
bring up was just curiosity about your
your your methodology if you're looking
at this on a day-by-day slice you're
gonna have some end number of users that
are going to be broken based on your
your review are you doing anything to
try and correlate between one day in
another you know if we've got the same
set of broken users and they're hitting
your website the same same amount of
times multiple days you basically have
it's sort of skews your percentage
because it's not actually multiple
discrete broken users it's a single
discrete broken user that hits the same
website every day to check his gmail and
therefore you know your question is then
you know if there's a user or an IP
address right that hits you hundred
times day and one that hits you one time
they'd which one you care about the most
do you care you might care different you
might care the same yeah I'm not trying
to necessarily say that it's 11 is more
important than the other I'm saying that
it's a valuable point of data to have
when you're looking at how broken it
actually is you're into a fuzzy area
we're talking about identifying users
yes yes you exactly in it and I fully
understand the ground of treading I'm
just making the point yeah okay um yeah
I'd be quick um I have one quickly John
about the broken DNS servers about
quadri resource record some years ago
we've seen with DNS servers returning in
extra manual just beside until
incorporated and have you seen this kind
of service
I'm gonna have today we don't measure
for that we only count we're only
looking at people trying to get to us
who are asking argue a service I've seen
it anecdotally yes there are certain
domains that do that I remember
implementing in two thousand something
the ipv4 only domains preference in
Firefox that I think that trade was
mentioned and I'm wondering without any
evidence about the improvement in this
video but that you don't know that i
think is getting better but i have no
data my name is Eric fine I obviously do
some ipv6 stuff for google I was just
gonna talk briefly about so my list
potentially samad the idea was to talk
about wireless automation but there or
the discussion that I'm trying to have
around it except that there's not a lot
of operational experience with it
outside of our own experience per se and
anyway I'd like some feedback and also
just to discuss sort of white listing
practice in general and what it is and
see what the discussion goes so there is
sort of you know a fundamental
difficulty the you know dns resolution
of quad days is the one and only control
knob right 42 / v6 traffic you add a
quad a for youtube v6 traffic you turn
it off it goes away that's it they're
really you know for fur fur for HTTP
there aren't any other control knobs and
I RFC 3596 says that you know the DNS
database has to be consistent whatever
protocol you ask it for you have to get
the answer and that makes sense I think
it's obviously fundamentally required
especially for a transition but it you
know it does break the sort of faith
sharing thing where you can have someone
asking for a quad a who has absolutely
no guarantee of actually having v6 at
all so there's been some some discussion
about how to restore some semblance of
faith sharing and there's Igor Grishin
skis work and some other stuff about
disabled quad-a on V for transport and
bind which you can do the concept being
to turn that on at the first level
resolver so that near the near the
clients so that if they don't ask if
they ask for a quad a over V for you
just don't even don't even resolve you
just don't even pass that up our own
film revenge against and Carlo
kandivali have been and some others have
been working on a neediness extension to
pass the client IP as well so you can
pass that up through all the resolvers
so that Geographic load balance the DNS
servers can receive this information
from resolver so if you go through
several chains of resolvers you can
still know where the client is and try
to route them to the right data center
and then there's also this sort of white
listing concept so why whitelist when
you can still get this other faith
sharing signal because faith sharing
isn't really enough right that just sort
of proves that you can get a 512 byte
packet through and that's really a low
bar for network operations right and
sadly it's a bar that some networks
don't meet but it's still not quite good
enough especially you know I forget
about not even reaching the site what
about people who have you know seconds
minutes worth of latency and not all I
think v6 connectivity is equal right the
default preference to prefer ipv6 means
that if we see if we refer for example
period with some AS we have 10 exchange
points with them and then they don't
they duel stack one of their appearing
links well all of a sudden all the v6
traffic is going to slip over onto that
one link that's not redundant and
clearly we would rather serve them over
the redundant links for basic
operational necessity and sometimes so
we've contacted some Network saying hey
would you like to be whitelisted they
say no please god don't and then some
sort of discussion in zoos but you know
they don't necessarily want the surprise
they want it they want to there or
they're working on v6 and then it's very
tender it's almost like some sort of egg
that needs to be sat on some more before
it hatches right if we turned on v6 and
be a flood of e6 traffic there their
operation staff would just be very upset
and then they would turn off v6 and so
we could actually potentially damage
some network some ipv6 deployments that
are in progress by attempting to serve
than v6 so if we have the idea being
that we have white list we can you know
we can we can take all of this into
account more than we can do in any sort
of application sense this is I you know
from google.com / p6 you can see sort of
roughly how it is basically you know if
a1 when our dns server receives a
request we just it's for quad a we just
check
whitelist if they're resolvers in the
whitelist then we return qua days if we
actually have them and if not we just
pretend like there aren't anything we
turn no air no results this is sort of
the the process that we go through and
the reason that it takes so long and all
these things just pile up my inbox and I
don't get to it we receive a list of
resolvers or prefixes we then have to
like try to verify that oh this person
they are they probably own who they're
saying is maybe does some who is work I
then take that stuff i look at i convert
all that to a SNS i get all that v4 and
v6 prefixes i look at all of our routes
between them like hike you know for
example the situation where we only have
we only see them over v6 overthrew one
through one connection we'd really
rather not do that then this maybe you
know some some PMT you testing and and
now we have the ability to do some more
sort of piraeus prefix brokenness
analysis I have to get a record in
writing an email you know you commit to
bird up in your sport when we have to
exchange not contacts and all the kind
of stuff and then some people really
request can we get like a really
specific goal I've time at 7am in some
bizarre time zone that is not Pacific so
that you know we have to be up for we
have to you know or something like this
and then you have to deal with in
emergency rollback or revert there's a
problem I think we've only had one
actual revert and it lasted like a day
or two but everyone and then you have to
sort of you know iterate on all this
right and this a long time this takes a
long time and there's just not a lot of
this is the obviously distance scale is
a huge amount of human effort involved
here I was think about how we can get
around this and I couldn't really think
of a whole lot to obviate some of the
stuff because you still need to perform
some of these checks but i thought well
rather than having everybody send me
email why don't they just signal their
readiness somehow and i'll just scrape
my logs they can just put this magic txt
record on their reverse for their
resolvers and obviously works 46 I'll
scrape these every once in a while by
looking through the resolver logs and
doing an offline lookups and actually
describe this process every mm-hmm
anyway so that they would add this I
would pick this up that would go into
the whitelist possibly and then you
could
actively monitor we would actually be
monitored as well for traffic dips
trouble reports and continue monitoring
brokenness metrics and we consider debug
and iterate but specifically what the I
guess that slide was out of the
whitelist a lot of people like what it
is right it's really it's really just a
this proposal anyway is a method to
signal your readiness to receive qua
days that's really all it is we use
reverse DNS for sort of some loose
verification of operational ownership if
you can modify your IP 60 you're in
entered a tart but we assume that
probably you own it we could use the
TTLs to express desired lifetimes
operation already at reality may trump
this right because there could be
millions of resolvers a day that we need
to go and perform all these queries on
so now there's I'm team DNS QPS trying
to like figure out who has these txt
records and so on so verts this could be
a bad idea it's fairly simple and
involves lower communication but so what
is what is a whitelist not by the way
just because there's a lot of stuff to
people were publishing some some
position statements it's not a
membership restricted club you know this
whole this proposal is not a home person
automated it's not maintenance free I'd
not necessarily guaranteed to be handled
by all providers is certainly not
perfect in it's certainly not a
long-term solution right nobody really
wants to deal with this sort of for the
long term in a long term we do expect to
have a list that the dns server must
consult we would like it to be a
blacklist right serve quoi days to the
world except for the following known
networks that are just really just never
going to work they're just bad whatever
it is and that includes like don't ask
so answer qua days if you receive a
query over 2,000 to / 16 or 2001 / 32 as
I'm not going to answer quite as for
that ah but that would be like a long
term solution here's sort of like the
syntax so we sort of became with this
expression I can go over this if it's if
it's interesting this there's a there's
a whole proposal it's documented off of
ipv6 whitelist org on the content
provider side I log all of the resolver
ip's i do these reverse lookups I
process this sort of format there's a
slightly more expressive syntax that's
documented that I didn't necessarily
want to go into it may be operationally
infeasible
I then still have to do some automated
testing sort of merge all this stuff
into white lists and black lists and so
and so forth and I just repeat this on a
daily or weekly basis now there's
clearly a lot of limitations with this
it does reduce some some communication
in the common case where everything is
working thank you but for other people
to do the same thing implementation
software processes it's not some
non-trivial effort there's definitely
some development here as possible that
timeliness is not necessarily going to
be respected if you if we tried to use
ttls and you said I want this only white
listed for one day that would mean I'd
have to sort of expire it in today and
then recrawl it that might be more than
I want to do for crawling hundreds of
thousands or millions of resolvers and
if I do an impact analysis and you
aren't automatically added to the
whitelist you still have to have some
sort of personal communication figure
out what's wrong and privacy
requirements actually hamper helping
right if I could if I could say these
users these IP addresses if I was even
allowed to do that analysis I certainly
probably couldn't share that right so
this is this is difficult and there's a
sort of a syntax attempt for for a
pairwise often opt out but that again
may not be operationally feasible um
that was really really fast and possibly
incoherent so can you comment erica is
this a ok txt a proposal or is it
operationally already implemented oh
it's a proposal I have some code that
does this and either so one or two
friends out there who've put these up
actually i think jason has done it as
well i have some some code to running
script this stuff but i'm not i'm not
actually running against any of our our
resolver logs that would be quite a lot
um who besides google's currently doing
the whitelist approach well this is
indeed the problem right there this is
what i said when there's no operational
experience besides ours ok so there's
nobody there's no diversity yes other
than articles about maybe it happening
oh you know of several of us have been
together at various meetings we've had
discussions about it and people are
interested in it as a as a method to get
around the brokenness right because you
can't necessarily express the quality of
someone's
p v6 connection through a regular DNS
request right you might be able to
express featuring boutique emissary for
us to put on a show that a Wikipedia
actually has a very small white list for
a few hosts rule wikipedia Oh Wikipedia
so I'm just curious on the content
providers here who would be interested
in following this type of approach
anybody well that on the access side
would you actually put reverse pointers
in for this where you need to worry game
oh really thanks to follow up question
for the room would you do this nobody
else nobody raises their hands would you
not do this nobody raises their hands if
you wouldn't do this if you didn't
wouldn't want to do this what would you
do do you expect us to you like to
expect to be able to email us and have
us do it do you think that'll scale do
you have any other suggestions I think
it's clear that this problem is not
going to go away right and and it's also
clear that if we want to make progress
we have to find a compromise so what
would you like to do yep let me
strengthen that a bit so I'm the NAD guy
and I uh I wear my flame retardant suit
all the time and i gave the prefix
delish oh yeah I get it I get it as long
as it preserves the intent for maybe
anyway go ahead this is a we have a
choice of the lesser of two evils do we
want no v6 do we want everyone to have
to beg the content providers that I'm
good enough to get a quad a really I've
done my homework and we're going to lose
a couple users but you know I'm trying
my best or would something like this be
okay they're still going to be a
blacklist behind something like this but
this may be it seems from what I've seen
the best proposal yet well also yeah you
know to thee to the emotional argument
it's not necessarily about whether or
not even an ISP has done their homework
right we can have fully redundant links
they're monitoring drop queues for
various qos levels for ipv6
before and they're all the same and so
on and so forth it could just be that
they have a bunch of users who have all
they have been joking gear right they
have a crappy it's just tap and it's
nothing they can necessarily do about
that unless they want to go and find
them and replace them and fix them so
you're kind of held hostage by your
customer base sure sure Cameron burn
t-mobile so just answer the question I
think it's easy I think it's a good idea
I support it number two for folks that
don't release claw days the DNS 64 which
we'll talk about the next presentation
will produce a quad a record for your
domain you probably want to produce the
quad a record yourself and host the
traffic yourself rather than have the
DNS 64 net 642 a 40-day offense is see
arm I'm concerned about the whitelist
approach the way the approach you're
talking about an OP folks opting in by
setting a reverse PTR that's because
well we already have a behavior that's
that's default in the clients out there
which is asking for the qualities to
begin with and that's a problem now
there's going to be this new behavior
people are going to throw that into
their their products as something that
is done by default they'll they'll
update this new thing in the reverse as
part of installing the product but this
is the access network signaling to the
content Network we're ready to move
forward within so access we're going to
take hot ups that perform this will say
oh we're a PBX ready we'll we'll set
this for you and you're going to have
you have hands off this even if not in
that then later on where the access
networks you know it changes over time
maybe they're ipv6 breaks maybe that guy
quit and nobody knows about it and
that's still Indian SG there's going to
be a problem maintaining those are
nothing obviates the ND the impact
analysis you have to do I think as a
strategy you're a little better off
doing something a little more passive
something a lot more like a stability
what do you call we do it we do it for
spam I'm blanking on the word now
reputation yes an ipv6 stability
reputation trash so we could just over
automatic automatically do it right
because they look at resolvers and say
oh yeah this is pretty clean we'll just
turn it on except that we're in the
situation where I could be harming
someone's ipv6 deployment that may be
very fragile at the moment
well maybe the connectivity is good
enough but maybe they are operational
staff is there they have another roller
procedures they're not taking a pager
for this stuff it's not monitored all
that kind of stuff okay that's an issue
we got isolation sit down last last
thing before I sit down and kind of
capitalizing not cure it more if you do
go forward to the PTR idea I'd suggest
you prepend an underscore ipv6 opt-in
dot reverse just so that when people are
seeing these queries and wondering what
they are they don't know first of all
and second because of some silly
requirements about PT are being kind of
like CNN but not and that it's just it
would work out better that way for me
Thank You Alan Johnson ebah you put up
in this slide some statistics but I'm
much broken Ezra is and I single stats
like many places but I have not seen is
really a detail dive into what is really
working and I think that until we see
what is really broken nobody's going to
fix it well the plans I have a
presentation about a variety of
brokenness types keep going it's not
it's not it's not like broken out with
statistics like this percentage is 624
and net percentages is broken ie6 and or
whatever actually I you six is fine for
ipv6 but because it never even tries
it's a it's my larger point is this is
just like the bags in implementation
they will be I one out when the code
will be exercised not before so this is
something as since she is a
self-correcting problem and I'm really
concerned but almost subtype of approach
essentially taking a big gun to kill a
little fly possible possibly it's just
wanna respond mr. Hankins the reverse
pointer on that would be a signal it
would be a complete boolean at least in
my case I would take it as advisement it
would be coupled with our own actual
metrics from testing the users what
resolvers they're coming through what
percentage are good or bad if they're
you know if they're borderline
this can sway me to yes let's go do it
if they're really bad maybe I still hold
back can we can we just get to the next
presentation or comment yes sorry we
haven't we like we're like way behind
time we have like lunch in like 25
minutes and I have to get like two
presentations in here at mark pleased to
talk about her do you want this we're
just be friend with it alright thank you
for watching okay thanks Eric I've been
working trying to vie pv6 end-to-end
nice many of you probably know I've been
in the business of selling some products
that try to v62 v6 over the current v4
well now where I mean the thing of doing
the ugliest ugliest thing I thought was
dns and nat64 anyway we've been doing
experiments over the the ITF and other
conferences if you want to try it right
now it's that's the information which is
a sin she turn off v4 and then put your
dns server address as this address we
try to try to a coordinate with the eric
to try to have a better setup ear but
there was some issues so this kind of an
ugly act right now that i installed this
morning so it might not work or it might
be slow might be related to either the
setup or your OS implementations which
you know as you have seen as some issues
it actually includes a really ugly act
for mac OS so to help Mac with machines
that are pretty popular so having said
that try it out if it's you know send me
email and we'll see if it works or not
it usually pretty works in real you know
environments where we had time to set it
up correctly we run it over the last ITF
the whole week okay presentation I use
case why not 64 DNS 64 basic
architecture the components
implementation some words about our
experiments in real networks
improvements so here's today we have a
lot of V for a few jewels draw stacks
and a very few ipv6 only networks or
devices and that's the problem we have
which is many operating systems and
applications do not necessarily behave
right in ipv6 only environments when you
fill a bug or you talk to the vendors
they say you know that's because no not
enough money right now there's not
enough users however tomorrow because of
the ipv4 address going out then we will
have ipv6 single stack users and they
will need to come access the content of
the v4 internet so that's roughly the
biggest use case for dns 64 nat64 so
it's to connect v6 only to v4 only
together however when you talk about
that as was well described in the behave
work is you have the location of the
initiator in the direction and the
number of servers on each side have an
importance on the solution and
deployment scenario so what I wrote here
is that nat64 DNS 64 is mostly for from
v6 only to v4 only and where most
servers on are on the v4 only side you
can add things you know mostly most is
important which is you know where they
use case for not 64 DNS 64 is the right
thing
so I'll take two cases access network so
provider provisions only v6 addresses to
end users on its access network for
different reasons ipv6 only end users
need to access content and services on
the ipv4 only internet or on the
provider you know specific services that
are only v4r an ESP or something as
you've seen since it has two years last
two days a few examples of these ipv6
only end users are clients for
connections they don't add advertiser
service so it's a typical net
environment so here's the drawing where
the computer is on ipv6 only access
network you know connect to v6 content
no problem and but cannot access the v4
internet and obviously the answer is the
nat64 to fill out that problem content
network use case we've been talking to
few content providers for using our the
software we wrote so this is an example
where essentially who is doing the
weasel ping the other on the previous
slide or the use case it's the provider
that you know helps the is and users to
connect to v4 on the other side is the
content provider that as v4 only content
because their service is not converted
yet to v6 or they will never be
converted to v6 so therefore they want
to offer that content to the v6 internet
and so that's the use case so you see
the difference is the nat64 is then on
the other side so the architecture
there's two components DNS 64 is DNS
server that answers quad a wreck
requests from ipv6 only client
and it does that by it synthesizes and I
quad a reply using the a answer received
from the ipv4 side the nat64 translates
IP packets between ipv4 and ipv6 the two
components do not share state or need
synchronization they can be on different
and you will see in the slides that
there are in different you know places
they could be at the same divisor it's
completely separate but they need to be
configured with same special prefects
the ipv6 only client is unaware of nat64
dns 64 sun change the ipv4 only server
is unaware so this is an example you
know very basic components where the
client do dns queries to the dns 64 get
an answer and that answer it contains a
special prefix which is synthesized and
then and then add some part which is
from the a record on the internet and
then essentially sends the packet to the
request or the TCP syn to the nat64
which actually translate the packet
there's an example with a flow diagram
so you'll see a bit more so this is the
v6 network is is 2001 db8 and that's 64
is 12 yo don't get the thing the key
here is that you the special prefix that
you use for those you know Quoddy
synthesis are actually either a special
it's actually there's a typo here but
it's actually either special prefix or
your own part of your own provider
prefix both case were so here's the flow
example where the ipv6 client requests a
DNS query for example com a quality
record ghost he has to go through the
DNS 64 the DNS 64
you know ask that same question just
pass through if it gets a quality answer
then it just pass back to the ipv6
client same thing no no problem if it
doesn't get any response then it tries
the a record it could be done in
parallel then receive the Aaron answer
and then synthesized DNS response and
then de client connect and then connect
through the net 64 so our project open
source implementations funded by NL net
and ourselves actresses is refers to the
melting of a particular in arthropods
which is an analogy of ipv4 molting to
ipv6 so after molten the arthropod is
fresh and ready to grow we did actually
many implementations adina 64 in Perl a
patch against the bone and patch against
unbound nat64 was done on a user space
linux module netfilter and then PF patch
so you have your choices pretty simple
for unbound because i'm done is modular
so you just write another module and
then you see the configuration be on you
just need to add the special prefix for
dns 64 bind well it's a patch it's not a
module and we added a confirmation
variable DNS 64 and then their prefix
that's pretty straightforward nat64 in
Linux its kernel space you know there is
a module what is good with the
integration with Nell filter and then PF
is the fact that you can apply security
policies as you want it's all integrated
nat64 and openbsd PF you know another
configuration command we don't do our
direction right now
I network experiments we did an I'm ITF
the whole week was with a specific SSID
we presented some slides behaved working
group about this and now today and we
plan for mass rich too and what we found
surprisingly work well for typical and
user traffic because essentially
internet is over HTTP as we all know
however as you have seen there's many
things that works and doesn't work but
roughly speaking I was pretty surprised
that you know we we've been running it
in our network and you know for the
typical end-user connecting to a few
typical website it works fine network
managers think you're offline ipv4 only
apps don't work obviously but and IP
address literals are not good and we do
have one OS that is really picky about
about ipv6 only networks which affects
not 64 deployments I'll leave this
because time is over and we will have
more work to do and will be obviously
open-source conclusion it's a solution
for connecting v6 only to v4 only useful
for access network content network
providers source code is available
please try it and thank you very much
for your attention
you did a great job explaining how DNS
64 nat64 works but I think it's also
important to explain how it doesn't work
it's not needed for the cases where
there's ipv6 and end so if you live in
like the mobile provider world like I
yeah where there's lots please do not
use it if you don't mean it if you live
in a world with a lot of nat and people
throw on the words like CGN a lot
there's no light at the end of the
tunnel you know within ipv4 it's very
scary it's very daunting you see your
expenses go up and up every year you see
state go up and up every year there's
new alg issues dns 64 not 64 is
beautiful in the sense that it goes away
over time is an architecture it's very
elegant in that it drops out of the
network as the ipv6 content comes online
that's why I really want to see a lot of
ipv6 content so it doesn't have to go
through this even though this works
pretty good thank you one of our users
thank you Mark thank you very much all
right so talking about experiences
around ipv6 only and not 64 basically me
and freidrich and a few other people
going to the bleeding edge and then
coming back here to report what we found
what we learned so what did we do and
why so for background our sites had been
into wall stock for ages basically the
office had been in bostock for like over
10 years and it all worked very well so
clearly we had to try something else and
you know of course eventually people
will have to go to ipv6 only or go
beyond dual-stack it's just a question
of time and I'm choosing a suitable
network where that this can be done and
as you've heard during the two days
there are some of these mobile players
that are considering this very seriously
so we wanted to know what what does this
mean and we wanted to find out what it
means for the for the end user report
back to the community on on what
actually happened we're also building in
that 64 device of our own at ericsson so
we wanted to obviously test an early
version of that and a little bit more
generally wanting to build an
understanding of when can we recommend
this mode of operation as opposed to
regular dual-stack so what did we do on
it's a really I mean I can't boast you
know hundreds of millions of users it's
just a handful of people really but it's
our research lab in my home it's a it's
a small group of users that were all
obtained this probably like 10 people
who have been in the network and maybe
five of them are are are there in in a
permanent sense and we be built an
alternate alternate network alongside
that the existing one that has its own
wireless has its nat64 for access to the
ipv4 intent has routing
um routing whitelist thing all kinds of
things like that are already in place so
we didn't have to deal with that so that
was already working quite well and
experiences it is possible I mean I mean
speaking from personal experience I
don't need to go back I am permanently
in ipv6 only yes I've said goodbye the
ipv4 internet but some pain is involved
so I don't necessarily recommend this to
everyone just yet in more detail many
things do break there's a mostly about
lack of ipv6 support in applications and
some types of devices there's lots of
bugs that you know people just haven't
tested this in in a network that has
happy for as well and some of our users
went back because of these issues
because we couldn't really ask them to
you know be without whatever they needed
and overall I felt that the key issue or
that the one thing that we need to
address is this ipv6 support rather than
some some things in the nat64 part which
generally seem to be working relatively
ok on so what what does actually work
and what does break so many of many
things work well obviously browsing
works yesterday we talked about ipv4
literals I only seen two instances of
that in my personal browsing in the last
two months so it's not a huge issue of
course depends on where you go and so
forth email software updates many jet
system streaming lots of things do work
and then this interesting thing if you
compare those general purpose computing
environment and the mobile environment
if you get to choose the terminals that
that you use then you can actually get
everything working in v6 only and you
don't lose anything but that's not
necessarily true in the journal
computing environment and then this
issues there this host operating system
issues the lack of testing sup some
applications fail
many appliances support during out
support ipv6 to some issues with
firewalls particularly with
fragmentation support in v6 I mean I
actually had to change our nat64 kodel
with do this example issues with
operating systems are a in face not aged
or removed as you move from one network
to the other without going through the
sleep state in your bundu for instance
you have to tell several rating systems
that you shall not expect before that's
like a manual action that is needed dns
discovery continues to be an issue and
for several types of manual things you
have to do for that example issues with
applications in our particular user
group the biggest problem was skype and
i actually sent the message to Jonathan
Rosenberg about that and said that they
do have a plan to fix this but not a
specific timeline one that actually
happened so it you know maybe if all of
us call him tonight it will change his
mind and do it quickly some chat
accounts fail msn n icq but some other
stuff works second life doesn't work and
that's about problem for me because the
iht has decided to have some of its
meetings in Second Life many games
failing their network or land version
messaging this is the I want you to go
through the details but these are the
things that we tested on anything on the
web works anything over XMPP works that
that's great some other other stuff
doesn't work then I also enroll my kids
in this exercise and you know move their
computers to ipv6 only and ask them to
test the games that they had on their
table and it's not pretty it doesn't
work even
even some things that are supposed to
work like underwear and stuff on the web
it it doesn't doesn't work this some
ipv4 leader also something like that
nat64 generally works relatively well on
some needs to use perhaps we leave that
to the lack of time on we did run
through some experiments actually we
compared like looked at the Alexa top
website lists and try to compare what
happens a regular ipv4 only network and
then ipv6 only and in ipv6 only plus not
64 obviously with ipv6 only lots of
things fail because it's like Google and
few others on the list that are v6 so
nothing else works but with the nat64
it's basically the same error rate as
with the regular v4 but then you lose
the sites that have ipv4 literals and
that that's pretty much the the issue
that there aren't too many but some and
if you look at that it's point two
percent on the first thousand and then
if you go to the first ten thousand and
there's two percent we haven't tested
beyond that we will continue this test
but it's really hard to tell whether
this is an issue or neither it wasn't an
issue for me personally but it could be
and just having an error it could mean
some advertisement was not displayed and
big deal for me at least so conclusions
recommendations are I think this
confirms that the wall stock should
still be our preferred mode of operation
for the general public or networks in
general may be possible to do ipv6 only
in special environments such as mobile
networks particularly if you have
control of the terminals that's that's
really key and you know enthusiast
networks and special things like that
and with effort I mean this this will of
course change in time maybe in two years
this will be possible for everyone and
we actually do you have to work I have a
list of things here that we need to do
in order to
make things better we have to improve
DNS discovery we're doing some things
about that in the ITF some
implementation things also have to be
done about it I have to fix box we have
to add ipv6 support to scribe messaging
gaming we need to do more measurements
there actually do understand what's
going on at what breaks and we actually
turn on any a LG's in this particular
test or proxies so there are things you
can do manually or operationally to
remove some of these brackets that we
saw but we just want to be pure in our
test here so that's it I my plan is to
report in more detail right
internet-draft about this so hopefully
I'll have even more informations you in
the future thank you real quick question
so as a sophisticated user have you
noticed your user habits changing I mean
you take around with the network you
type in ipv4 addresses you type in ipv6
addresses I'm just wondering as a
sophisticated user do you find yourself
typing in ipv6 addresses and avoid it
because they're long and hard to read or
do you just use the same expert mode
that you've always have well mostly I
use DNS obviously but but now I do
remember my ipv6 address so that that's
a change but you forgot your social
security number so have you noticed any
difference about the user experience in
terms of service quality for example the
response time our body that download
time or something that's an excellent
question and and and I don't have any
data about that there's like anecdotal
evidence that you know one of our users
felt that this was slower but it can
really be quantified and we didn't
really see it in ping times on
this is definitely something that needs
to be measured not just for this nat64
stuff but also for the general
dual-stack use it something global
Internet I can answer from our
experience it really depends on the
operating system you're using very
different if you know some wording
system you know timeouts and problems
but some are are better for the same you
know connecting to the same sites
exactly the same size I think your list
of games might be sort of a tad bit too
negative if you add at least you want to
go to like older games if you want to
see bay quake Quinton's that's open
source it's been supported for like 10
years or if you would like to play come
on and concrete pipe earnest and I have
a binary patch for that that's good we
really need to fix the games my
selection of games was however very
random it was exactly the games that
were on the table on top of the table
I've time to ask this to be done and you
know remove the ones that don't do
network mode so quick response to the
max comment I I understand that one ah
the aspect of the dish experience would
be to depend on the operating system
implementation but I also think that
would depend on the the disability or
that network status or stability or
things like that so as my question is
about the overall experience taking into
account the order yeah and I think we
need to separate the error cases where
things fail or timeout and then the the
usual case when that when it works but
it takes a little bit or millisecond
longer and that's the one that I really
want to measure but I haven't done it
done it kid thank you Gary thank you
very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>