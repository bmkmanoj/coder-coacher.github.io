<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Open Source Developers @ Google Speaker Series: Lessons... | Coder Coacher - Coaching Coders</title><meta content="Open Source Developers @ Google Speaker Series: Lessons... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Open Source Developers @ Google Speaker Series: Lessons...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/d9gjy1OsTGQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good evening ladies and gentlemen and
welcome to the open source developers at
Google speaker series it is my pleasure
this evening to introduce Raph Levien
who will be talking to us about lessons
for mod we got him ruff thank you thank
you so kindly I am now at Google
incorporated I have been here about a
month so I guess I should have brought
my little propeller hat thing which is a
sign that I'm a new blur I did advogado
about eight years ago in 1999 and so I'm
going to do something of a post-mortem
in this talk I'm going to talk about
what advogado is what it was about you
know some of the goals how well it met
some of those goals in some ways it
didn't do as well as I had hoped and you
know as I go through what advogado is
I'm going to talk about some of the
lessons that I've learned some of the
kind of take home things that hopefully
you can apply to other systems that do
this kind of trust and reputation and
these slides are going to be online
there's also video I'm hoping some
people will be watching so there's lots
of notes in the online version that you
can refer to later um so what what is
advogado it really was motivated as a
platform for testing out ideas on trust
metrics or kind of distributed
reputation the original motivation in
fact wasn't to build a blog type
community website system at all it was
to build a better DNS it turned out that
was a pretty hard problem and I kind of
got distracted by just the sub issue of
if you've got like a lot of users that
are out there on the internet and you
don't really know who they are how can
you how can you define you know the
edges of who belongs to the community
and who doesn't so I built the site
around I guess the first launch of it
was in November of 1999 I done some
theoretical work before then and needed
to test it out on real users and what
what the actual site is is pretty
blogs and articles kind of a clone of
slashdot in some ways one of the things
that made a very different than slashdot
is that you have this social network
graph which is constructed with explicit
you I interaction so when you go to the
site then you when you click on somebody
else's profile you get to certify them
to say how much of a free software
developer are they these days it has
about 13,000 users sort of a modest
success and as I said it was it was
really designed as a testbed for the
trust metric ideas so the whole
motivation for building the site was
this concept that I was exploring back
in the late 90s of what I call attack
resistant trust metrics and they're
really two aspects of that as the name
would suggest you've gotta trust metric
which is about using the social network
information to compute some information
some score of whether a person is
trustworthy in some sense and the thing
that makes it I think unique compared
with other systems in the same basic
genre is the attack resistance that you
want to build a system that you can't
just sign up and create a gazillion
phony accounts and have those phony
accounts influence the result of this
trust metric computation very much so
you want to put some kind of bound on
what a spammer can do Microsoft had a
paper basically saying with different
assumptions you can't do this that's the
civil paper but it depends on what your
assumptions are there aren't that many
systems out there that are attack
resistor I mean if you just add up votes
or something you know simple like that
then it's not it's not attack resistant
at all one of the things that's not
exactly the same as advogado in terms of
the goals the scope but does have this
attack resistance property is the
PageRank algorithm that Google's you
know used since the beginning to rank
web pages and that's worked out pretty
well and
it's actually again one of the
surprising things of you know why why
are people not more interested in this I
mean here you have an example a research
project that's modestly successful you
have a commercial implementation of a
similar concept that's at least modestly
successful I think Google's most people
with degrees there's pretty good system
and attack resistance maybe sounds more
exciting than it is you know that that
it makes it sound like it's this
fortress this this wall that cannot be
scaled no matter how you know how how
strongly you want to scale it and it's
possible that the kind of the name has
brought on some unrealistic expectations
and in fact i'm going to show kind of
the lesson slides in green here one of
the problems is that trust metric is a
poor name i mean you say trust metric
and you know i really have some very
technical meanings that are behind it
trust is a very fuzzy concept when you
say trust in ordinary English you know
meaning yeah you know conversation it
can mean in 5-10 different things so
when I took on the word I was really
using the existing literature PGP tried
to create this thing again with the sort
of original goals of building a better
dns try to build this thing called the
web of trust and that was really only
modestly successful but it certainly
brought this idea of trust as something
that can be computed you know into
people's mind and there were also a
couple of important academic
publications that we're also using this
word of trust to talk about you know
some quantity that could be computed so
you had the really one of the first
papers that kicked this this line of
research off the valuation of trust and
open networks by bet borcherding and
climb back in 94 turned out that trust
metric was completely broken and not
attack resistant at all but it
kick-started the the field I think
and then you had Matt blazes work on
policy maker and a couple of other
related systems that he put under the
rubric of trust management no he pointed
out you know that he was pitching these
ideas to a lot of financial you know
types of applications and he'd give this
talk he'd give a talk on trust
management at a bank and everybody would
say but I thought this was supposed to
be about administration of trust funds
you know but these days you can these
days if you do a Google search on trust
management you you find a couple of
those but mostly things on on the
computational concept of trust and you
know as I said I mean what what are you
actually measuring I mean a few examples
you might trust a user to not spam you
might feel that their blog is worth
reading you might trust them with more
things like your wallet or your car keys
or something like that advogado you know
just to kind of define the scope of this
that what actually got implemented
really deals with exactly the first two
questions on this list do you think the
person's a spammer and even if they're
not a spammer even if they're a real
person do you really want to spend your
time reading their blog and I really
didn't get into the financial stuff at
all the word metric is also something
with very specific technical meanings
and you know like the exists the the
original work on this was a lot of it
about monotonicity that if you add more
certificates that you only increased
trust and that's that monotonicity is
something that you find in metric spaces
and so on and so forth and again that
the term was really borrowed from the
academic literature writer and
Stubblebine did a pretty good work on
trust metric called metrics of
authentication these days you wouldn't
really call it this authentication
authentication is more about you know
what open ID does does this user
correspond there to their credentials so
they're actually when you go a little
deeper into the skin and avocado one of
the things is that there are two
different trust metrics that got
implemented and it's kind of important
to understand the difference between
these two and I will be going into a lot
more detail about that so the original
one
is based on network flow as the
underlying mathematics and it has the
this very visible you I display that
every user gets ranked as either
apprentice journey or master or perhaps
no certification whatsoever and then
there's another one that's a little bit
more subtle that you don't even see it
unless you're logged in that's based on
eigenvectors which is the same kind of
underlying technology that page rank and
clever use and that computes something
different that computes this how
interesting is this blog measure so
they're both attack resistant they have
some characteristics in common including
the attack resistance some things
different based on the underlying math
now one of the big differences is that
the original one only does positive
information I believe this person is a
free software developer that's the
community that I'm defining in the
original trust metric there is no way to
say this person is not for their a
spammer or what they write is
uninteresting and in the second
eigenvector base trust metric that does
exist this question so eigen vector is a
very fancy mathematical term that really
talks about if you have a matrix that
represents some kind of system like
traversing webpages that it really
speaks to that system reaching a steady
state so it's it's it's talking about
the underlying mathematics so I'm not
going to go into the details there's
there are more details in the papers but
kind of the takeaway thing is that there
is a class of these things that's really
been motivated by a web search like the
PageRank that Google uses like the
clever algorithm out of out of IBM
they're all based on this eigenvector
underlying mathematics and really that's
what I'm saying that that the second
trust metric is is sharing some of that
mathematical underpinnings I actually
did do an experiment where I tried to do
a negative reputation system in avocado
and it was an unmitigated disaster III
called the reading in addition to these
three i called it dimwit and it it
turned out that there were a lot of hurt
feelings
and you know it just didn't it just
didn't meet its goals but later on it
really became clear that you needed some
some negative reputation so this gives
you a little bit of an idea I didn't
make this figure this is actually out of
a PhD thesis worth reading by a guy
named I Chi Nicholas Ziegler I believe
is his name and he actually did his own
trust metric that was sort of a
follow-on to this work and kind of
compares the two but you know just to
give you a little bit of an idea that
there's there's some pretty complex
sophisticated math under it but I won't
go into too much detail on that instead
I'm going to try and introduce these
concepts by telling a story and this is
what you're seeing here is actually the
original motivating story behind this
trust metric and this story happened
first and then the site kind of got
built second so let's say that it's the
middle of the Linux revolution Linux is
going to take over the world and you're
a book publisher and you got a very
specific problem that you've got this
book that every free software developer
should have and you also want to sell a
lot of copies so you don't want to give
it away to everybody in the world so you
just want to give it to the people who
are free software developers and you you
want to draw this line of who is a
member of this community fairly
accurately you can't do it by manual
review you can't have a you know you
know some person whose job it is to go
out there and find all of the people in
the free software community or something
that would be too expensive and there's
always people i mean the free software
world is so diverse so impossible to
really put your finger on that you're
always going to miss some people in this
story under these assumptions and
getting the assumptions right is really
important we're going to be okay with
being a little too generous we might say
you know what it's totally fine if ten
percent of the people who sign up for
this it could be a book it could be a
little bit of free money could be
conference pass whatever we're going to
say as long as it's a bounded as long as
it's a relatively small fraction of what
we're doing that we're going to be okay
with that we're just going to say that's
going to cost less then
you know however much it would cost to
get this information exactly per perfect
but on the other hand we're going to
really try not to exclude people because
if we do then they're going to write
extremely angry blog postings about how
the book publisher is not really as open
inclusive and so on and so forth is
they'd like to be so let's say for the
sake of the next few slides that these
are your assumptions now I'm basically
going to tell you how you can solve this
problem so the first step is that you
get a social network built so really you
you you go out there to the free
software developers and you convince
them all to sign up for accounts and put
in their social network data of
essentially an arrow says I know this
person and I trust them and step 2 I'm
not so sure about step 3 is of course
profit so because we're giving away free
ebooks or free money or whatever it is I
mean that's that's an assumption that we
can make that we're also going to make
the assumption that there's going to be
an attacker out there that is trying to
break the system and the theoretical
work behind this really is based on sort
of over the space of all possible
attacks how can you make a system that
will still you know resist these kind of
attacks still not give away you know a
million books or whatever while I was
making the slide you can't like draw a
picture of all possible attacks that's
just too complicated to think about to
reason about so one of the things that I
found you know in the in the research
phase of this is that the attacks that
work the attacks that are really
difficult to protect yourself against
are the ones in which you take the
existing data that's good and you copy
it you make your own shadow copy of it
and and then you know you basically put
that into the system now surprisingly
spammers have kind of learned that trick
and so it's quite common if you look at
spam this or that that you'll often see
bits of copy text bits of copied link
structure and so as the example that
we're going to work through again
a high level I'm not going to go into
the detailed map but just to give you
the flavor of where this attack
resistance property comes from we'll
just use this example where I've taken
the graph of mate copy and then I've
relied on a small number of gullible
users who we will somehow trick into
creating an edge saying that they trust
one of these copy notes if you don't
have any gullible users then you're fine
also you know the Easter Bunny and Santa
Claus and all that so what are some of
the metrics that we can compute I mean
there's lots of metric so metric is
anything that you measure basically so
you've got a lot of metrics that you
could easily calculate over this thing
and and and some of which people have
you know done some work to try and
actually do so you could count edges you
could say ah this person must be really
trusted because they have three edges
coming in they must be a very highly
respected member of the community the
problem is this guy also has three three
edges coming in there's no way that you
can look at cat excuse me counting the
number of edges or any kind of local
statistic that you can compute on the
graph because if you have a local
statistic that you're competing on the
graph then the copy the Shadow Copy
attack is going to look exactly like the
real thing there's no way to tell the
difference another thing you can do
that's a little different that's global
is reach ability are we reachable from
the seed well in this particular case
not so great because you know maybe I
didn't draw all the arrows the right
direction but you know in general once
you get one gullible user then then the
whole thing is is considered reachable
now when I say kills you I actually mean
something very specific like that what
I'm talking about is the relationship
between the cost of the attack so I'm
saying in order to get a gullible user
to create an edge from the bad user to
the good user is something that has a
certain cost to it and if I kill you I
mean that you do a certain amount of
work with a certain amount of cost
and then you fall off the cliff in terms
of how much damage that you can create
that that you can create you can go in
and sign in with your millions BAM notes
and you can get your million free books
given away so a better metric and one
that you see for example all the time in
social networking systems today is this
concept of distance from the seed how
many steps do I have to walk down this
graph and again if you go back to the
example that you see we're going to do
pretty well that is a matter of fact if
you if you only do things that are the
seed one step away from the seed or two
steps of the way from the seed that will
avoid getting the bad you know node all
together will also exclude this guy too
bad and then if we you know take that
reach ability out one step further so
that it's you know three degrees instead
of just the two then in fact we'll get
everybody but we won't and we'll also
get this guy the problem is then with
this reach ability Stella metric matchup
not reach ability sorry that the
distance away from the seed metric that
you can then clone that one node and get
unbounded number of nodes accepted so in
the story of the original assumptions of
giving away free books that's not good
so all you need is a gullible user that
is near the seed and you have the same
falling off the cliff behavior we're a
relatively small amount of cost in the
attack creating a millions BAM nodes is
not considered costly having that edge
from the gullible user is the part
that's costly so the answer not
surprisingly is network flow so this is
the same graph as last time it sorted to
be a little bit easier to figure out
what's going on perhaps especially if
you're colorblind I kind of considered
making that graph in black and white
first and then making it in color but I
didn't want to be too mean so again I'm
not going to go into the math here it's
very complicated which is one of the
reasons I guess why so few people have
adopted this but the the inspiration
here is really the sort of
mene mene cotton max-flow theorem out of
network flow theory which which says
that you know that that if you compute
the maximum flow over some network that
the the quantity of that flow is equal
to the to the minimal cut across the
network so you're really making the
assumption that you can tag this network
and cut it across a fairly small number
of edges from your good notes to your
bad notes and then you can you can
actually prove very tight bound on the
number of bad knows that your trust
metric is going to accept that it is
bounded by the amount of flow across
that note so a the amount of flow across
the edge from the gullible user to the
bad users so as long as you can keep
that bounded as long as you can you know
keep the number of gullible users
certifying bad users low you can
actually succeed and make this thing
attack resistant in the sense that you
can't just get your million free books
given away so I took this idea and I
implemented it for something that wasn't
at all in the same set of assumptions
you know it's avocado is not a book
publisher that is trying to give away a
lot of free books it's this kind of
slashdot like community blog site with
articles and blogs and so on and so
forth so what the actual implementation
does is that it runs this trust metric
that I just described with a network
slow and it uses the results as access
control if you get accepted by the by
the by the trust metric then you can
post articles and you get you know other
other you can edit anybody's project
descriptions so it has kind of like a
wiki like functionality within within
this so there are a couple of problems i
mean the the assumptions now are not
quite matching what does what the
architecture the site does that you know
once you get a bad note once you get
accepted you can post an unbounded
number of articles and another problem
is well i have this this thing where you
can create a new account and even
without being certified you can do lots
and lots of span
we'll get back to these so the take-home
lesson from this story is that you have
to apply them correctly your assumptions
need to match what the actual use of
that trust metric is so ideally you've
got I mean when I started this the the
space of trust metrics known was pretty
small and you know that I was kind of
blazing new trails in terms of coming up
with ones that were attack resistant and
I proofs of that these days you've got
more work on it hopefully you have this
big giant tool kit this bag of trust
metrics and you can say they're
different ones with different trade-offs
and different amounts of being
probabilistic or whatever you can just
pick the one that matches your
assumptions if you can do that then your
chance of of successes is much better
you have to be thinking of like you know
I gave that story about the relative
cost of not giving a book to somebody
who thought they deserve one versus
giving too many way depending on the you
know the cost of false positives and
false negatives you know totally depends
on the application and it's not you know
just some mathematical thing giving yes
or no access control you know basically
saying mod + w you know when somebody
gets access it's a bad thing what you
really want to do if you can is have the
trust metric somehow correlated with the
amount of damage that a person can do so
you want to make it so that there is no
falling off of a cliff behavior that if
a person wants to post spam they have to
do a lot more you know if they want to
post a million messages they have to do
a lot more in terms of creating that
attack than if they just did one another
problem that I ran into is that
especially when you get people that are
explicitly putting in their social
network information people don't read
the people don't read the instructions a
lot of people are reluctant they don't
want to make many notes at all so you
actually get a fairly noisy graph you
can't make the assumption that this
graph is going to be a high quality
piece of data so you have to be aware of
that and I think you know these days
there's kind of recognition in this fact
so avocado is a dramatic success the
reviews are in bugs in advogado the
trust metric systems seems to be chock
full of bugs lately as a matter of fact
that is the top story on the site and it
happens fairly frequently how much we
trust the judgment of this might have
might be you know you might take into
account how well they can spell but in
fact there are a lot of comments that
came in you know does everyone not agree
that the trust metric is compromised
it's completely vulnerable to spamming
the system seems to be broken so one of
the take-home lessons here is that I
didn't do a very good job of
communicating what the trust metric was
about what the avocado site was about of
you know the expectation a lot of when
you read these complaints a lot of them
basically are that they don't really
understand you know what this marvelous
attack resistant trust metric is
supposed to do and you know another
consequence of that is that you know
people people don't just immediately say
oh I want to deploy that on my site
because you know and if they ask me for
advice you know I won't say oh yeah just
plug it in and go because you have to do
this kind of complex matching of what
the trust metric actually does with the
assumptions of the site a matching that
I didn't at least in the early days do
very well in advogado itself and another
thing that I think really heard is that
I didn't do as much academic publication
on these ideas as I should have because
people really do look look to that
literature so hardly in response to the
shortcomings of the first trust metric
of advogado I built a second trust
metric and at heart this is actually a
very generic metadata engine that you
can use to do music reviews and so on
and so forth and I wrote how to and you
know I said you know I've been thinking
about this more you know I know what the
limitations of advogado are
I know the problems you need something
that can do these negative ratings you
know somebody's blog is not interesting
worth reading you know here's here's my
here's my intellectual property you know
go forth and implement it and by the way
it's based on eigenvector so it's
similar technologies PageRank different
enough it probably doesn't violate the
patent that's not my official legal
decision that's just what I said in my
paper that I wrote before I started
working at Google and I got almost no
interest to almost no take up on the
idea so I said well I have to go and
implement it myself so this thing
another it has a lot of interesting
features it computes both the value and
a confidence and another interesting
feature that differs from the original
one is that it's a local view that if
you rank somebody's blog is really
interesting and somebody else says that
blog is very uninteresting well you each
get the the benefit of your own view of
that and in fact the people in the sort
of clouds around you yet their their
their values of this weighted based on
sort of closeness in the social network
so this thing works and in this
particular case the the assumptions you
know really match reality very closely
that what you were what you were putting
into the metadata ranking system was how
interesting is this blog and what was
coming out was a rating of how
interesting is this blog so I'll go to
the demo now we'll go into a little bit
more detail will test this and see you
know what I'm not logged in so we'll do
that and okay one consequence of this is
that or one specific feature of the
implementation is that you really only
see these rating values when you're
logged in so here's one it's a one to
ten scale and just looking looking at it
you know at the top that here's one that
has a value 3.7 and we see that he's
writing about stuff that doesn't have a
lot to do with free software he's not a
spammer and
Thank but he's certainly not writing
about free software a lot and as you as
you go through this you know I encourage
everybody to to to look for themselves
but you'll see unfortunately this this
gray is kind of it's very hard it's
impossible to read yeah apologies for
that it that actually am trying to do
that control a what doesn't do this yeah
yeah so this is yeah yeah you know this
is actually supposed to be a feature
rather than a bug that it displays the
the really low confidence values you
know in very faded language it is chock
full of books quite rang I should have
done the demo on a blackboard obviously
is so I I should probably I kind of
jumped into this a little bit into the
second trust metric a little bit too
quickly that the color coding reflects
the rating of the user by the first
trust metric so purple is a master level
blue as journeyer level and green is
apprentice level and then if you see
gray then that's no certification at all
and in fact people when those
certification can still post on the
recent Diaries list and you don't see
very much of that most of the most of
the users are people who certainly the
frequent posters are people who have
certifications so in in my experience
the the people who get high values like
there's a threshold value here that's
said at three sort of anybody under
three is probably a spammer or you know
not not doing what they ought to do
no it's just sorted by day so there's a
lot of features that are not actually
implemented in the site I have to do a
lot with you know my bandwidth for
implementing this stuff and those are
all things that are marvelous and the
code is out there and you're more than
welcome to implement that but it's not
done it this is not I'm not I'm not
really you know advertising that the
site itself is worth emulating I'm
trying to get the point across that it's
about the trust metrics that are in it
and I filtered it here with a very high
threshold of 9 and you'll find I think
when you look at it that mostly now
you're looking at blog posts that have
to do with the the programming and
generally people that are pretty highly
regarded in the community robo gato is
the new maintainer of the site you see
you have less sites but it's perhaps a
worthwhile way to to read the site and
again I encourage so of the ones that
you saw it suppressed 87 entries as
being below the threshold and then if we
look at him without the threshold then
you'll probably see someone's a very low
you know if you look at the ones that
are sort of below three you know like
this one is not an English it maybe he's
a free software developer but he just
hasn't convinced the rest of the
community of that fact and this guy
again 1.6 and again i have no idea i can
click on him and see what he's about but
he hasn't he just mostly click you know
clicks links he doesn't talk about
programming so that's a case where if
you have your threshold set above that
then you're not going to see him at all
so I kind of gave a little demo that
this this second trust metric uses a
creates a filtered view and I probably
should have been more aggressive in
implementing this thing that you
actually have to be logged in because it
has this local you know everybody has
their own seed you see your own view of
the universe there isn't a global
concept
as in the first trust metric and you
know the hardcore uses of the site get a
lot out of this the people who are not
you know casual users and they're
they're really just as important don't
get the don't get the benefit of this
trust metric so again how the details of
the implant of the implementation really
matter so a couple of years ago new
problems started coming up and this is
very common problem you see this you see
this all of the time insights now that
when I when I first built the site I
really wanted to be open i wanted
everybody who was a real free software
developer to be able to sign up create
an account get noticed from the writing
of their Diaries their blogs get the
certifications have a low barrier to
entry so i made it very open that you
can sign up and create an account and
post without needing any of this trust
metric sophisticated stuff at all and i
kind of knew that that was you know that
that was a problem that that was that
the thing was to open and you know I
always had the intent of closing that up
as soon as it started getting abused and
in fact in the early days because it
wasn't getting abused then that kind of
brought up this really strange question
of you know is does this attack
resistant trust metric really work at
all or are people just not attacking the
site so thankfully finally people came
along and started testing this so these
days you don't even have to ask that
question that if you have anything
that's worth anything then it will it
will attract the spammers and the
attackers and the abusers but in the
early days it wasn't quite so clear so
you know the motivations behind the
original design were to create openness
because a lot of people thought that
even having a yes no decision was too
elitist that it didn't match the fos of
the free software community so that
that's what motivated the design and
it's now fixed in fact I didn't do this
I handed it over the site about a year
ago to Stephen rainwater who's the
current overlord
hi Steven if you're watching a video and
he what he did is that he basically
added a flag this account as spam so
maybe I can do an online demo of this
that we go into NYADA got our members of
whom yeah okay suggestion from the
audience of okay mi ke el excellent
cheap viagra online links so did you um
well I thought you I see how long is
this oh my gosh yeah it's a popular name
so I don't know why this person is still
in the system but they flagged no
accounts so so one of the things that
you can see here is that he has this
link but he hasn't been doing posting if
he were to post new Diaries if he were
to post Diaries then his account would
come to people's attention and then it
would get a flagged as spam not often
enough apparently so I just clicked on
the flag this is spam and I increased
the score from three to six and I got to
do that because I'm certified as master
the actual amount of bump that I do to
this BAM rating depends on the level of
certification and so if they go if
another couple of people do this three
or four maybe then it'll bump the score
to 15 and then their account will be
automatically deleted and maybe I can
big party well he was he was one of the
one of the original you know wave of
spammers so we'll look at these people
it's fairly common I don't understand it
why people mmm
go back okay go back oh yes right
another another excellent review yes it
proves that advogados trust metric
system as a failure and it is absolutely
true I mean under under the assumptions
that this user you know brings to the
system of what he expects this distress
metric to do it doesn't do what he wants
to do he expected it to keep out cranks
and very explicitly that was not the
goal I mean if you go back to that book
example that you know I'm totally okay
with with with passing a few books out
and you know another thing is that you
know in terms of the mismatch of the
assumptions of the trust metric with the
implementation is once you get your
certification once enough people say
well maybe you're a little cranky maybe
your ideas are pretty good that's the
case in this particular example that you
can post as many articles as you like
and in fact he was posted in quite a few
so you know it all has to do with you
know if I had come in and said the
purpose of this trust metric is to keep
out cranks then I would have had a the
way I would have implemented that is
very simple I would have had a metadata
of this user is a crank rate 1 to 10 and
i guarantee you that he that the
particular user that he linked here
would have scored extremely highly on
that score it's an experiment that's
well worth doing for future researchers
that are out there so you know again I
can look in here that you get people
there's no links there's nothing there's
nothing actually bad that this person
has done except occupy space you know on
the on the new user list if they did
post you know your typical spam link
then they're spams you know scores would
have been increased so basically there's
no way for me the question is is there
any way to undo what you just did I
don't have user interface for undoing
that the idea is that if one or two
people do it by accident
really hurt anything that's the
threshold and then if too many people do
it then yes there's a manual process
that the administrator confession
account out of purgatory but that's only
been required you know like once or
twice and in fact the cases where that's
happened you can look at the account and
you can kind of you can kind of
understand why why the account got
clicked on you know I think there's
there's more than one person with
Asperger's who uses the site if we had
an Asperger's metric then I'm sure that
user would have scored extremely high on
it as well so you know again you kind of
have to fish through to find you know
somebody who's doing really egregious
spammy behavior and if you look at the
recent blog entries list there's maybe
maybe one spammer on it maybe not it's
an incredibly tiny amount of abuse
considering how considering two
parameters how open the system is and
how little admin work goes in so yeah I
mean there were a few cases of the
overly zealous deletion but it wasn't a
big problem and again that the this was
a good case of the assumption it's
pretty much matching the usage of the
site that the amount of damage that you
can do by falsely flagging a spam is
somehow related I mean you know if you
get one or two people to come in and
then want to poison the you know get get
their certificate and then when a poison
the spam scores they could but you know
it probably wouldn't bring it over
threshold it wouldn't really bring the
whole system down so this is really
something that's worked question so the
question is how many spams can one
person mark as this blog is spam and at
the moment there's no bound on that so
the question is can you go in and mark
the same person as spam in the answer
that is know that that okay I thought
you were saying how many different
people can you mark as spam right so you
so so you do have this kind of limiting
behavior where your ability to do damage
you know where you can say I want to
mark this person and spam because i
don't like them that your ability to do
that is
fairly limited and we haven't seen that
particular abuse happen so the question
is if you can coerce other people to do
that and that's absolutely true so the
idea is we're not this is what attack
resistance means attack resistance does
not mean that the system is completely
proof against any attack that there's an
impossible to make these things happen
it means if you want to do that you have
to do more work you have to increase the
cost of your attack where you're doing
stuff like convincing other people to
send in those flags once you've reached
that that that level of being able to
pull off that attack then there's no
hope fortunately we're not seeing that
in the real world just yet we're in good
shape so one of the other one of the
other take-home lessons that I want to
get across because I think I think this
one has a lot more relevance in terms of
you know other people employing these
kind of systems is that transparency and
openness really works or at least this
is an instance of transparency and
openness really working all of the
details all of the secrets of how spam
how the system keeps out spam you know
if you're thinking like how would I go
into the system and make it except my
spam and you know the page rank is very
high very worthwhile to get spam into
this system are completely public you
can just go in read the code figure it
out and you know the system is also very
open almost as open as the day that it
was created there is really isn't about
creating barriers and saying it's going
to be very difficult because of all of
our spam filters that you need to get
around and also you know a very small
amount of manual work which is not
something that you see when you look at
the site it's kind of hard to tell the
difference between something that's
inherently spam resistant and an army of
deletion monkeys behind the behind the
scenes so insecurity in cryptography you
know a lot of companies try and achieve
security through obscurity and in the
security world in the cryptography world
that gets you laughed out of the room
and
and I think without you know I again
I've got it was one data point that
that's probably true in in the world of
these of these reputation systems as
well that ultimately if you have to keep
the details secret to think that you're
secure it probably isn't so again you
know I forgot I was a modest success it
did it did some things well other things
not so well it didn't really catch on
you didn't really catch people's
attention on fire so why you know if it
works so well as well as I'm saying why
isn't everybody using it and like you
know everything else there's probably a
combination of lots of different reasons
the the code base itself I'm programmer
so when I wrote this I wrote it in my
most comfortable language which is C and
you would never do that you know please
if you write something like this then
please write it in Python um I didn't
publish enough I didn't do enough self
promotion I'm here doing this talk I
think that helps but I in retrospect if
I really wanted to push these ideas out
there you know I could have done a lot
more of that work and then as I say that
you know if you just look at the site
it's it's very difficult to tell how
much of it is really the inherent
properties of this site and how much of
it is you know somebody sitting behind
the scenes making it look a lot better
than it really is but the good news is
that people are starting to care now I
mean this talk is one of maybe a half
dozen that you know some internal some
external at Google on reputation social
networks etc it seems to be that people
understand that the social network is
powerful and spammers are powerful and
hopefully the social network is more
powerful but that's where the battle is
is taking place and I'm fortunate that
I'm a member of the comment abuse tools
team here i'm working on these things
and i'm really happy because you know i
think a lot of people's goals are now
align i'm interested in solving these
problems users are interested in not
having to fight spam and of course you
know there's real bottom line impact for
google
as a money-making entity in terms of
whether these are well-functioning
products or whether they're infested
with with spam and abuse so I think
that's my talk musi yes that's it so I'm
really happy to take questions or from
the back
so the question is that I built this as
a closed system that really you know
everything working on a single server
and could I have deployed it as a highly
decentralized system and the answer to
that is absolutely that that was really
the original goal the original goal was
to build a something that wasn't a
broken DNS that wasn't depending on kind
of the verisign at the top of the
hierarchy and the reason that I built it
as a single closed site is that it was
it was much simpler to do that and that
I kind of wanted to separate out the
possibilities of failure that it's
entirely possible that all of the ideas
were really good but I just didn't know
how to build a widely distributed system
well these days you know I mean have
distributed authentication mechanisms as
opposed to distributed trust like the
open ID talk that was earlier today
again one of the one of the series and
you know I I think that that making this
thing scale up is one of the more
interesting you know sort of future
research directions to take it Monica
so that absolutely so the question was
does the fact that this work have to do
with the particular domain that i picked
of the discussion of being open source
programmers which may be according to
the kind of implicit assumption of the
question are not as contentious as other
i'm not sure that's true and i think the
answer to that is that that when you
look at the the population of the
spammers and abusers you know they're
they're posting links on on viagra so I
think you're going to see more or less
the same spam and abuse no matter which
population of legitimate users that you
pick so it's hard to know the answer for
sure until you actually do it but my gut
feeling is that that the the success you
know as so much as you've seen it is not
just to do to the to the nature of the
of the domain
or something
so so I'm supposed to repeat the
questions and that was a little
complicated but it basically let me see
if I can get the gist of it across that
you know if you had a domain that was
more contentious would you want to have
multiple different kinds of metrics that
were being ranked other than just how
interesting is this person's blog is
that is that the gist of the question or
right yes okay publicity attack from
being contentious so advocate so I guess
the answer to that question is that
advogado does not because of the because
it's just not in one of these
politically contentious you know spaces
that as an experiment it doesn't really
answer that question that said there is
a lot of really interesting work out
there that if you look at the clever
algorithms that were done by Joe
Kleinberg at IBM research that later
became part of the tail MA search engine
that they actually started looking at
the second eigen vectors and third eigen
vectors of the matrix so that you know
sort of link adjacency matrix of the web
and one of the examples out of their
paper that I thought was really
fascinating is that if you look at the
second eigenvector on a search of
abortion that you'll see this really
clean separation into sort of you know
pro-life pro-choice camps that you could
just by looking at the link structure
without doing any kind of semantic
analysis or any kind of you know
self-identification as one camp or the
other that just looking at the link
structure you can extract that so my gut
feeling is that if that data is
interesting if that is what you're
trying to extract out of a social
network that that that the data is there
that the tools the techniques actually
can bring a great deal of power to that
question but as far as did advogado
answer any of those questions then no it
did not it that was not part of the
scope of the experiment
how often do I update the eigenvectors I
believe that that calculation is every
four hours but it sort of depends on
load and so on and so forth its it
that's an implementation detail that
it's kind of less interesting to me
personally the question is is it
computationally expensive so um the
answer is that in the implementation as
it exists now it's it's not so much
computationally expensive that the
bottlenecks happen to be getting the
data in and out of the database which
because I sort of drank too much of the
xml Kool Aid is all XML files and a flat
file system and that's very inefficient
and the other thing that makes that more
expensive than it should be is that it's
actually calculating the local view of
all 13 thousand users in the system that
it's computing different scores you know
if I see something that's a 9.3 then
somebody else might see it as a 4.1 and
actually in response to an earlier
question that if you do have something
that's contentious if you do have a
thing with with kind of wars of people
within one cluster ranking down somebody
in the other cluster then what you would
expect to see is you would expect to see
this local you know this locally
relevant score which again is relatively
expensive in as the system scales up
then the cost of computing that becomes
unrealistically large and you would need
to do things like figured out clusters
and so on and so forth but again you
know that was one of the nice things
about this that I had a modestly
successful I was supposed to run away
successful system so it was very
practical for me to do this experiment
on us on a site with only 13,000 you
know nodes I won't have that luxury here
at Google any other questions ok well
thanks very much for coming out i really
appreciated being able to give this talk
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>