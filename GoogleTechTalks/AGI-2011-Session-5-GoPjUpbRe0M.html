<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AGI 2011: Session 5 | Coder Coacher - Coaching Coders</title><meta content="AGI 2011: Session 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AGI 2011: Session 5</b></h2><h5 class="post__date">2011-09-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GoPjUpbRe0M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody I'm really happy to be here
this is my talk on information theoretic
representations of agent dynamics as set
intersections it's kind of a long title
but I will be very concise in my
definitions I'm based out of boston
university and we have funding from NSF
grant than that number so the take-home
message I want everybody to know is that
this is a new model for agent
environment dynamics and buy new model I
mean pretty much a new proof system um
this is in algorithmic information
theory and I guess the central theorem
that we proved was that agent
complexities has an exponential
distribution and I'm happy to say that
this resulted in a a IT paper with
Leonard Levin who did 11 search and a
lot of the complexity variance that we
talked about and that's um that was
released at earning early August so if
everybody can look at that and so it's
very exciting to have an ad out of paper
that um kind of gets exported in and
helps out this other field which is AIT
so I think that's a really exciting
thing is that there's a lot of theorems
out here and a lot of some people are
doing and I feel like it's very minable
and can be exported into other areas so
now I'm going to talk a little bit about
agent environment interactions and
hooters model and then how that can be
changed around into and into a different
structure to create different types of
proofs so this is an agent agent
environment interaction there's a night
and there's a dragon and then this is
hooters a universal artificial
intelligence model so on on one hand you
have the agent who is the night in the
other hand you have this environment
which is the dragon and you have this
interaction going between them and one
of the interactions is the perceptions
which is a reward and an observation and
then the other is an action which the
agent does and hooters brilliant
innovation was that the agent in the
environment can be represented as Turing
machines and then the yet so here are
the rewards and observations here the
actions so um and then he used Salman
offs Universal prior or the sawn-off
Levin
universal prior and he was able to
create this the singular formula and
this is probably the most exciting thing
i have read as my PhD career because i
feel it incorporates all of the theory
that's interesting in artificial general
intelligence and it's a simple formula
but the complexities of it are very
fascinating and again it resulted in a
paper in traditional AIT theory so what
is this saying well they each
environment is going to be weighted by
its kolmogorov complexity and that's
Leonard's variant which is the prefix
free version of that so if you just sort
of do kind of a beige in summation over
all of the environments you get this
Universal environment sigh and that
Universal environment if you have an
agent that's optimal to that then you
get all sorts of interesting
possibilities so ki you mentioned before
this is the size of the description of X
I use capital K because it's Leonard's
variant which is prefixed free so it can
converge but that's about as much as the
math that I want to talk about and now
let me talk about a general conjecture I
have sort of about about where I think
things are we going so we have these two
measures people have been using them and
really exciting in creative ways
throughout the conference and one is a
discrete measure which is coma graph
complexity in that dis maps to a code
and that say that's an integer value and
the other one is the universal prior
which is Solomon offs measure and that's
that's sort of a combined that's sort of
a combination of the two and then uh you
know with the coding theorem there
they're actually equivalent in there
they're the same thing really you can do
in many papers you actually define k of
x in terms of log of X so they're
basically the same thing and there are
two different types of information
measures now now we have interaction and
I don't want to encapsulate Hooters
model it but I have to make some sort of
generalization so this is universal
artificial intelligence Hooters model
uses a lot of the proof techniques um
derived through Solomon off and
universal induction so the question is
is there a discrete version of Internet
section where you can develop a whole
new field in in leverage all of the
interesting combinatorial and
algorithmic proofs of K of X and apply
them to interaction so I I actually
believe that there's a there's actually
a symmetry that is related to Universal
artificial intelligence and that is
univer- games and in Nash equilibriums
and I was able to take the universal
artificial intelligence model and put it
into this discrete structure and I can
prove some very simple theorems about it
so I feel like it's been a very
successful endeavor so what am I talking
about so let's let's translate these
agent environments which have
probabilities and that's fractions and
fractions are sort of hard to use so
let's just put them into a
non-cooperative game let's squash time
into a simple strategy space and all the
interactions are now pure Nash
equilibriums um so let me give you an
example of an interaction between two to
two players so now we have two players
and your player a and player B and
player a plays rock and rock and player
B plays paper and then he copies A's
move um so what you do is that you
encode this into a Nash equilibrium game
so a so you you list all of a spa ssible
games and you list all of bees possible
games so these are all the games that a
can play and these are all the games
that be can play and you look for the
intersection of these two lists and the
intersection of these two lists is the
set of pure Nash equilibriums that's
basically the only game that a and B can
play um if there's uncertainty then they
can play different types of games but in
this case it's only a single
intersection so another way to look at
it is through a Venn diagram you have a
and B that's the list of their possible
moves that's B's list of possible moves
and the intersection is the intersection
is the set of games that they play so
these are these values represent text
and strings so the natural thing is that
you can apply a complexity theory to it
and
the sense that now you can derive
interesting properties of it based on
the fact that you have this encoding you
have so basically what I'm doing is I'm
taking all interactions and I have two
sets of strings the intersection of the
two sets of strings are the interactions
and you develop a lot of interesting
properties of it so a and B are Turing
machines and they have an interaction X
and the information revelation between
them will be less than the coma war of
complexity and this is um coma graphs
variant notnot leonards so um how did
the how does the paper work out well
basically you encode all all this
complicated dynamics into two sets of
strings and B then I basically develop a
series of definitions um in terms of the
learning capacity of a player and kind
of then you talk about conditional
complexities and then you import
something called the randomness
deficiency so basically I'm building up
definitions and then i'm importing
combinatorial proof techniques from very
recent literature in algorithmic
information theory by vitani and very
shaken and from these proof techniques
you can develop you can derive some very
simple theorems so I'm going to go
through a couple of theorems this one's
sort of boring so um theorem 2 is
superfluous information if you have a
and B they have some sort of interaction
then there exists a B prime that can
interact with a and whose complexity is
less than the mutual information of a
and B arm so it's very simple it's just
saying that if I interact with somebody
I can develop an approximation of that
of that person and still have the same
interaction and all of their information
is contained within me so this one has a
little bit better interpretation and
that is is that you have multiple agents
and this is probably the easiest one to
understand is that if you have 2 to the
K agents who can interact in some sort
of way with be or have 2 to the K
National equilibriums with B then there
exists a oh and they all have a certain
complexity then there exists an a prime
can interact with be that has coma barf
complexity less than or equal to R minus
K so that's so basically when we're
thinking about all these agents in
environments we now know that they
basically have an exponential
distribution in terms of of the
complexity um there does exist
environments where this doesn't occur
and in London that I proved that if if
this does in case happen then B has a
lot of information with the halting
sequence and in this case it's a very
unnatural thing and there's no there's
no halting sequence string that's been
produced in the history of the universe
so that's it in a nutshell thank you
very much don't mean to be quick but I
guess that's my nature so that's it yes
so we'll have the questions for him
right now any questions No okay thank
you very much thank you very much let me
tell you first about my work of several
years I was initially motivated by a
refactoring of software the refactoring
case happens to be universal because
what we refer to action is our faults so
that just in case my my interest my
purchase computational experiments in
the course of that kind of research of
ultra factoring I have found a number of
things for example i noticed that
partially ordered sets are a very good
knowledge base base prism most of all
because any system can be converted to
knowledge to partially ordered sets
representation quite easy i will say i
also found a new type of
that I named emergent influence which in
fact had been predicted by Helmholtz in
1850 experimentally by studies of vision
and he said it was happen in the in the
brain and now I have found the
mathematics of it and I named it
emergent inference I proposed that as an
explanation for emergence and
self-organization in complex and
dynamical systems and also for
intelligence and emotions in the in the
brain here's one of my computational
experiments i call them brain
experimental so the brain is not
involved I start on the left with some
body of knowledge for example it could
be a a problem statement of for an
object-oriented project and I give it to
an analyst on the upper row which is the
brain and the analyst creates for me
some structures that are I call the
natural structures natural because they
have been created by the brain which in
this case would be the object oriented
design course it does not have to be
that but there are many possibilities
but that's an example and then
separately from that I convert the
knowledge base knowledge the body to
partially ordered set representation
apply the emergent inference to it and I
get some structure that I call predicted
structure because they are
mathematically predicted by the by the
procedure I compare the two and I did a
number of experiments and they to
compare pretty well I was surprised
myself how well they compare so
apparently i can reproduce the work of
the human analyst by using emergent
inference here is my first experiment
that's what I discolored how it with him
the influence itself on the left is a
very simple program
which I scrambled in a bad way so it
doesn't have any organization or any
visible structure all the exits are
input data they are given on the Left we
have variables that have to be
initialized by the program that's all
there is on the right hand side you have
the corresponding canonical matrix
corresponding to that program and I have
listed in the diagonal that matrix the
variables you can see the diagonal ABCD
etc those are the variables to be
initialized and in the longer triangle
of the matrix I have listed the
arguments of each function indicated we
not a for example the variable l is
equal a plus B zor-el is a function of a
plus B and you can see that there are 2
a's under a and b in the row of L that
indicates a dependency which is
precisely a predecessor relationship in
the partial order the red lines are
called flux lines they indicate the flow
of information in the question if I say
L equal a function of a and B a and B
then there is a flow of information from
the variables a and B to the variable l
and that flow is indicated by by the
flux lines that I have indicated in red
now I started refactoring the problem
using my brain for that so I did it in
very small steps each step consisting of
reversing the order of two adjacent
statements in the program in my brain
that's me I will select which pair of
statements to to to reverse the order it
will tell me ok that pair looks nice
let's do that one I will do that one
then I would look at the agency so I
refactor manually the problem
I thought it was two of me is how long
have I been talking okay well I can
manage with that here is the refactor
program what I notice is that the flux
lines become a lot shorter and that you
see how sure they are e on the right the
matrix on the right has some structures
and one wonders what the structures are
they are intelligence critical they may
be architectures for the system that is
represented here in complex system
science we work with complex dynamical
and dissipative systems this system is
complex it is dynamical because the
emergent inference provides the dynamics
and it is dissipative because it
dissipates the length of the flux lines
in this system intelligence is a side
effect of the dissipative dynamics a
side effect I did not write one single
line of code to do that the brain seems
to behave in the same way where the
connections between the neurons
correspond to the flux lines one
important questions are the structures
observed while yes they are in the neuro
section just yesterday the
neuroscientists spoke about or presented
about observation that the that that
they observed hierarchies of structures
exactly as predicted in in by this
mathematics there is a lot more to the
law there is a lot more to say I do not
have time unfortunately but we can
somehow communicate and talk or I can
answer questions sometimes in the panel
I thank you very much to the organizers
because of the very nice excellent
confidence that we have
and I thank you all for being here thank
you very much okay so this is a
conceptual presentation and a conceptual
talk about the relation between
rationality on the one hand and general
intelligence on the other here's an
overview what I'm going to talk about it
we will start with a very short
introduction after that I will say
something about rationality and tool
relatively famous challenges that were
proposed from psychologists from the
psychological literature some
experiments the first is the way
so-called ways and selection tasks the
second one is the famous Linda problem
from truski and Cain man and then we
will draw some consequences after that I
will propose that an energy making and
coherence maximization could be good
candidates for using them as cognitive
mechanisms in order to explain the
seemingly irrational behavior of
subjects and these experiments and then
i will give some remarks on future
research and we'll finish with some
conclusions now first of all as a matter
of fact theories of rationality are
often linked to disciplines like
economics like philosophy like
psychology in economics you get Nobel
prizes if you are really good in this
field and psychology you become
potentially a director of a max planck
institute so you can become the gather
get a lot of owners I think if you do
this the situation seems to be a little
bit different in classical artificial
intelligence because usually I think
only little attention has been paid to
rationality issues in classical AI and
not so much different also to artificial
general intelligence I do not claim that
this is absolutely never but was never
mentioned also so for example one could
perhaps Marcus widows ike Ã§ or
algorithm or P once NARAS could be
perhaps strongly related also to
rationality issues but usually these
people to talk about other things I talk
about universal intelligence for example
not so much about harassment
I think that hei would do a good thing
if they move towards rationality issues
in a more direct and more concrete way
such a theory should not only explain
what within which tasks and win which
respected agents act rationally or
behave rationally but it should also be
able to explain to a certain extent why
such so-called rationality puzzles can
occur and why seemingly subjects do
something that according to some
normative theories are not in accordance
to some rationality theory here's the
first example the so-called waves at
ways in selection task the following
situation is given so four cards are
presented to subjects on one side there
is a number on the other side there is a
letter printed there's a rule that must
be checked by the subject the rule is an
if Sun condition stayed it can be stated
as if there is a vowel on one side of
the card then there will be an even
number on the other side of the card a
clear if then condition and implication
and then subjects are presented a
certain situation for example the
following that is depicted you see aucd
you see for you see seven the task to
the subject is now turn as few as cards
as possible in order to prove the rule
or to falsify alright so and the
minimality cook because you kill you can
change it or turn every card but that's
not the idea so do it minimally so
what's the right solution if you apply
the laws of classical logic you should
probably turn a in order to check
whether if a is of our then on the other
side there should be an even number
probably but there is also something in
the classical logic which is true so if
a implies B is and from not be not a
should be implied so you should also
turn seven because if there is not an
even number on one side there should not
be a vowel on the other so the correct
logically correct solution is to an A
and seven and here is our some results
from arbitrary experimental subjects
behave so
for example forty-six percent turned a
and for which is not the intended
solution thirty-three percent turned a
which is not only a which is not the
intended solution three percent
performed good well so so to speak made
the right thing and eighteen percent did
something else so they were seemingly
not able to perform this modus tollens a
law rule now the interesting thing is
that you put these subjects in to differ
a different situation where this is more
concrete and somehow in accordance to
what you what you what you experience
every day then they behooves it behaves
significantly better for example if the
new rule is only people over 80 now are
allowed to drink alcohol meaning
something like if for someone it is
allowed to drink alcohol him he or she
must be over 80 includes if completely
the same structure completely different
content but a real-world situation in a
certain sense and then you get such a
thing that you see a card 15 water beer
and 22 then in principle if you behave
as what you would do if you will police
officer checking a bar in the u.s. you
ask for example by human it probably to
change 18 to 21 or so but but what I
however then then then you do the right
thing so what are you doing if there are
some very young persons over 15 year old
you check whether this person is
drinking beer and if there is someone
drinking beer you check whether this
person is 20 hour 18 or older and if you
do this it's perfectly fine you solve
this problem now in such nice the setups
subjects perform significantly better
that's the first part of the second
puzzle I want to mention is the famous
Linda problem proposed by drewski and
caneman 1983 there's a profile given for
Linda which can be stated as follows
suppose Linda as a 31 year old single
outspoken and very bright woman she
majored in philosophy as a student she
was deeply concerned with issues of
discrimination and social justice and
also participated in the anti-nuclear
demonstrations so there's a certain
particular profile that was somehow
given to the subject and then subjects
get some
propositions or some statements about
Linda right so for example in de as a
teacher in elementary school Linda books
in the bookstore and so on and so on the
important one of these aid is number six
and number eight number 6 s Linda as a
bank teller number aiders Linda as a
bank teller and she is active in the
feminist movement subjects should rank
according to probability what is more
probable that fits to the profile to
Linda and the interesting thing is that
eighty-three five percent rate eight
more as more probable than 68 was a
conjunction of two things Linda is a
bank teller and active in the feminist
movement six was one content of these
two statements Linda is just a bank
teller this is according to probability
theory and the kolmogorov axioms not
possible because the possibility of a
conjunction of two events cannot be
bigger than the positive as if the
probability of a single contract of it
so again they seem to be a rational so
what does this what does these two
examples show well it seems to be in the
case at least in a relatively weak
formal formulation that sometimes
subjects have problems to think in
classical logic and sometimes subject
their problems to decide according to
the laws of probability theory okay now
nevertheless I don't think that these
subjects are irrational in a strong
sense i think that subjects and we all
together as human beings are extremely
smart it is only that we are no
deduction machines and according to
classical logic we do not think it only
are exclusively in terms of coal makarov
axioms and nevertheless we have let's
say we have other strategies as well to
address these problems there are many
attempts that exists to for resolving
these things in particular very special
logic system that are proposed to model
this reasoning and models instead of
reasoning was influenced calculi taking
into account context effects and so on I
want to propose to relatively general
cognitive mechanisms named the analogy
and coherence that
are somehow can be used as different
mechanisms that are applicable in
particular situation in these situations
in order to address such problems our
proposal is to explain these puzzles
with general versus general mechanisms I
think that Boas are relatively important
in the psychological literature and
cognitive science of an allergy making
seems to be crucial for human cognition
it may be also a reason why humans are
so smart and coherence maximization a
theory that originated from work by
Paul's eggert is a theory that models
the connection of propositions and sub
theories that make something more
coherent than some others of fear now
what is the reason why in the abstract k
so where we were talking about numbers
and letters in the ways and selection
task subjects perform badly well maybe
the reason is they were not able to
perform an appropriate or to establish
an appropriate analogy this was a
completely abstract thing there was no
possibility to relate the somehow
meaningful to a situation where that
fits to the structure and therefore they
need some other strategies and these
were not so successful the reason why
subjects perform significantly better in
the beer case in this concrete cases
because they were able to establish some
kind of an analogical only one okay they
were they were able to establish an
analogical relation namely they somehow
it did what they would do in an everyday
and a logical situation but when they
are for example this Polly police
officer that our just needs to check
whether people younger than 18 are
drinking beer or not and then they are
perfectly fine actually just as a
recital mark Caesar experiments will
also perform this children in their
world and significant what is very
interesting even children perform better
in some setups and adults right
structurally because it fits too there
is the experiments of design in a way
that it fits to their world in the Linda
Kay's coherence maximization can be used
so the idea here is that a statement
life is like Linda as a bank teller and
she is active in the feminist
movement is in a stronger than screw
here into the overall profile of Linda
because that the feminist movement
activity is somehow strongly related and
coherent with the profile that was
somehow given for for Linda in the in
the introduction of this experiment in
comparison to Linda is just a bank
teller because in disaster bank teller
seems to be a puke plane crash some are
to the profile right because usually
people with this profile will not become
bankers and now to make a long story
relatively sure there's there are
computational models for analogy that
that can be implemented and then that
were proposed an example is a something
we developed in what's now poke namely
heuristic proven theory projection and
for the extraction of sub theories for
source and target domains in order to
establish an illogical relations and a
reasonable thing to do is to relate this
to coherence measures and to use
coherence matters in order to get better
sub theories for source and target
remarks for future on future research
what would be desirable in general to
integrate cognitively inspired
frameworks for modeling rational belief
into a GI system also addressing such
particular problems and giving some
reasonable explanations what this how
this should be modeled in such an hei
system clearly also a variety of
mechanisms should be used dependent on
the information say it's the agent nor
the program or the system is in
background knowledge available resources
contextual embedding time restriction
and so on and so on those a usual thing
that I invited by the way usually pop
psychologists quite of not are not
sufficiently taking into account what
would be desirable in particular for our
approaches that Gautam coherence
measures for the extraction of source
and target theories would be a good
thing good coherence measures for
mapping and representation another cheap
process is a necessary thing and there
are some tension they are little bit
specified in the paper between classical
theories of coherence and HTTP they need
to be resolved but I don't think that
they are not solvable here's a final
slide conclusions
take-home message magic messages
rationality did not get sufficient
attention in AI and AJ I would like to
to change that rationality puzzles seem
to show that humans use a variety of
reasoning mechanism and not just one
computational models for analogy and
coherence exist and are good candidates
for that and in particular heuristic
prevents your projection is an example
of a computational theory that can be
used for implementing this thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>