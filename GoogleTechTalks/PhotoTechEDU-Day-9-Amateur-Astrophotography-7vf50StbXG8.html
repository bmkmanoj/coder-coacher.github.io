<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PhotoTechEDU Day 9:  Amateur Astrophotography | Coder Coacher - Coaching Coders</title><meta content="PhotoTechEDU Day 9:  Amateur Astrophotography - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PhotoTechEDU Day 9:  Amateur Astrophotography</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7vf50StbXG8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome to photographic technology
gday number nine today we have guest
lecturer been lunch I get that right
much who's going to talk to us about
astrophotography then has a computer
science degree from Stanford he was one
of the founders of excite and he comes
to Google by way of jot spot then take
it away Thanks alright this is working
if we can hear me alright so my my talk
is on astrophotography and
astrophotography is naturally the
techniques used to photograph things
that are not on this planet and it's
also sort of one of the primary ways
that we use to learn about the rest of
the universe so I like to do master
photography because I like the pictures
don't they look pretty but there's also
sort of a vast amount of science you can
do with it as well so my first slide if
it comes up here is an animation which
is currently not animating but this is a
this is sort of a fisheye view of the
sky and what do you need to do do you
want to make an astro photograph first
thing need to do is you need to
compensate for the fact that you're
doing sort of the ultimate pan you're on
the earth and you're taking these long
exposures 1020 minutes and the earth is
moving and so you have to make sure that
your target stays inside your field of
view the whole time this can be very
challenging not only does there a sort
of you know obviously move continuously
but the atmosphere will play tricks on
how fast things appear to move and
there's a also a lot of problems with
trying to make sure all your equipment
sort of follows the star as well there's
lots of little things they can happen
where mirrors sag or tubes flex things
like that that I'll talk about later so
you need you need long exposures one
thing I sort of like about this picture
and you can't tell us much the animation
but when it's not animating it but you
can really kind of get the feeling that
from this thing a big fish I that you're
really sort of someone on some planet
that's sort of spinning out there and
you can see the galaxy and so it gives
sort of the feeling of the
I like about astrophotography so the
next the next slide is again a non
animating supposed to animate picture of
light pollution this is supposed to be
three slides of light pollution at
different times in United States this is
sort of a projection of what it's
supposed to look like in 2025 and it's a
little bit less now but as you can see
there's a lot of light pollution and
light pollution makes astrophotography
hard because all the light that goes up
into the sky illuminates it and affects
our ability to see faint things even if
we stack exposures if there's a certain
amount of just light pollution in the
sky and it's just stuff you can't see um
this is also just bad from sort of a
conservation perspective right this this
picture shows light that's not going on
the ground this light isn't really
helping anyone this light is just going
up into space this is all totally wasted
energy that's sort of diminishing this
natural resource which is the sky in
here sort of a global view it's just
taken by NASA's as a mosaic and you can
kind of see in the United States if you
want to go find a place with us a really
dark sky to do some science or some good
astrophotography it's hard you gotta
drive aways same with Europe so so it's
tough to actually find a good place to
do astrophotography and there's a whole
sort of science behind finding good
sites if you read about how they choose
to put or where that used to put really
large telescopes there's a lot of a lot
of thought that goes into it and one of
the biggest factors is a place where
it's dark but will stay dark or they can
place where they can put in light
ordinance I should also mention here
back on this slide this the slide comes
from the international dark sky
association and the mission is to
preserve and protect the nighttime
environment and our heritage of dark
skies through quality outdoor lighting
so they'll help you or your community
find lighting fixtures that will sort of
ensure all the light that you use sort
of falls on the ground or falls on the
things you need to delight up and didn't
spill up into the sky now if you've
driven down I guess it's 580 or 680 seen
all that sort of the car the car sales
places where this light is just sort of
barfs on to the sky all the time
okay so the next thing you need is that
is look so good the next thing you need
is to realize that you're you're trying
to image through through the atmosphere
and the atmosphere is mildly refractive
so this actually shows a picture of Mars
through an eight inch telescope and what
you can't really tell is that Mars are
sort of dancing and jumping around and
bits of it are coming in and out of
focus and and it's not due to any sort
of problems with the mound to the
telescope and this is this is actually
captured with a webcam and if you look
at the the PowerPoint which I can post
later you actually see the animation is
pretty smooth and it's all due to seeing
right so the atmosphere is pretty thick
I don't know a couple hundred thousand
feet thick and it's it's mildly
refractive and it's moving around a lot
or it's sort of compressing and it's
moving and the net effect is you have
this week lens that's sort of moving
over your image and it blurs things and
so this is this is a huge problem for
astronomy because you want to make a
really big telescope so you can you can
gather a lot of light but also so you
can have very good resolution right as
Ramos sang in the earlier lectures so
the bigger the aperture the the smaller
your your area disk and the better
you're able to resolve things but if you
have this atmosphere this week lens
moving and blurring everything it sets
sort of a lower limit to your liver your
resolution so the general rule of thumb
is that after about point five arc
seconds the atmosphere will sort of take
over and will blur anything more than
that so you could have some massive
telescope and there are massive
telescopes whose theoretical resolving
power is you know a hundredth of a
millisecond practically speaking without
playing tricks the atmosphere we're
really sort of limit you to about half
an hour ago
ah thanks man I'm not really sure I
don't I don't I don't know why it
wouldn't be the same I know that a lot
of the pioneering adaptive optics that
were done word actually done by the
military in the 70s on in Maui and mount
haleakala and so I assume that it's the
same and actually interestingly enough
the way it was the reason was developed
is because they wanted to be able to
identify a satellite as it went up on
its first orbit and so they had all
these sort of early adaptive optic
systems to try to unglue the image but
the short answer is I'm not really sure
though I think so and so in order to
combat this right there sort of a pretty
big spectrum of things you can do to try
to make your telescope perform optimally
and achieve its optimum resolution one
is you can use a web camera like I'm
using here and you can actually run a
program through all the individual
frames and look for the ones where that
your image is the roundest and you have
the most high frequency information this
means it's probably pretty sharp and
then you stack those up I'll show some
images at the end of the talk some very
very impressive images of Saturn and
Jupiter these are actually taken with
sort of a normal celestron telescope and
high-speed web camera and the gentleman
in Crisco in the Philippines who takes
these runs ease through a program and
literally just pulls out you know
two-thirds of the the blurry images and
just keeps the good one so the idea
being that as you have sort of this blur
that the atmosphere induces there's also
moments where things are pretty clear
pretty good and you just sort of pull
those frames out your image many times
per second yeah
ha
Beatrice all
okay so he basically just it was it was
sensitive enough that would just sort of
take only expose the things that were
we're not moving basically Matt okay
that's interesting and so the the sort
of sort of modern equivalent is to use
adaptive optics and this is sort of what
you'll find on any really large
telescope now an adaptive optics
basically changes the surface of a
mirror to account for the bending of the
light by the atmosphere so you can sort
of imagine that you have some distant
source say in this case it's Mars and
the light is the sort of spherical wave
form coming in and it's bent a little
bit by the atmosphere so what ends up
happening is that pieces of the waveform
will hit your primary mirror it's
slightly different times so they use a
modified sort of Shaq Hartman sensor and
they can tell how the waveform is bent
and there's a little pistons underneath
the main mirror that deform it nearly in
real time to basically zero out the
effects of the atmosphere this way a lot
of these really large telescopes can try
to zero out the blur from the atmosphere
so that's a good question and the
question is how large of a frequency
spectrum is that valid for I'm not sure
about the adaptive optic systems that
I'm more familiar with the there's a
tilt system which is sort of basically
shamir that tips and tilts and doesn't
deform and those typically are good at
about ten Hertz faster than that and
they they don't really end up working
very well so I'm not actually sure how
how fast the adaptive optics systems are
changing is that is that what's the
question
right yeah I don't know I know that
these the the instruments they use the
sensors that use definitely go from you
know sort of deep infrared all the way
through and are nine hundred nanometers
or so so I'm assuming that it works for
that range but I really don't know yeah
yeah that's right so the question is
isn't there an image by the way that
they can shoot a laser up into the
atmosphere and watch its image wiggle
and sort of use that as their guide and
that's they do that I think it's a
sodium laser I'm not exactly sure how it
works but it you can see pictures of
giant observatories with this sort of
finger of light sticking out and the
idea is to is to use that really bright
with a lot of signal noise source as
it's right next to the target where
you're moving where you're looking and
observe the way it undulates and sort of
use that to reverse your adaptive your
the blur that's also a nice technique
because one of the problems you have
with a huge telescope and a long focal
length is that your field of view is
really really really small and you're
often looking at things which are not in
the plane of the galaxy right so you get
the galaxy and you're looking at
something sort of up you're looking at a
distant quasar something that's not sort
of occluded by the dust in the galactic
plane and so it's really handy to have a
bright star nearby so you can actually
kind of have a really good
signal-to-noise and understand what's
happening in the atmosphere and people
to counteract it and the further away
from the galactic plane you are the less
probable you are to actually have a nice
bright star there so they do shoot this
laser up that they can sort of track
right next to their their image okay all
right so so what do you need a faster
photography you need long focal length
because stuffs far away and you need big
a big aperture together light this is
sort of it the small end of things these
are two hundred millimeter f 1.8 lenses
reason why I chose this picture is
because there was some discussion on the
photo tech board about about these
lenses they're not made by canon but
they're sort of over the shelf and get
money you may lenses and these are very
good lenses and have a nice flat field
and this particular program is
interesting because it is a survey of
the night sky there's these sort of
copper level ingots or actually weights
where they're going to put more of these
cameras and what this does is this looks
for um extrasolar planets and what it
does is it takes frames of just massive
number of stars every night and it looks
for my new changes in their bright
and it looks for periodic changes in
their brightness which correspond to a
planet it's got to be pretty large
jupiter-sized it actually passes in
front of a star so you can imagine
you're looking at a star you can measure
its brightness very accurately because
you've got a very linear CCD and as the
planet passes in front essentially sort
of eclipses some of the star's light and
we'll do this periodically and you can
measure some things about the extrasolar
planet that way as you can see there's
not a conventional camera on the back of
their these are special cameras these
are I believe 2000 by 2000 pixel back
thinned I don't know who makes a sensor
but they're 13 a half micron sensors and
they're cooled like negative 50 degrees
and I'll talk about the cooling in a
moment and you can ask to see that sort
of a y-shaped amount it's not coming up
very well on the slide but these are all
sort of set on a mount that we'll talk
about in a minute that the traxxas guy
very accurately
right well first so the question was you
know why would you use a longer lens for
this and the reason is because the
longer the lens is to be the longer the
focal length the short smaller field of
view so if you really want to cover a
lot of ground you need a pretty wide
field of view so you need a shorter
focal length lens or a bigger detector
so since there's sort of a practical
limit on how big of a detector you can
have you try to get shorter folk long as
possible with enough sampling and that's
sort of pixels per hour second of sky
that you can really do the science you
need to and it turns out for their
purposes that this is this is sufficient
it's a very wide field of view you can
they say some there's fifty thousand
stars on a one minute exposure and they
can measure the magnitudes of all those
stars accurately enough for for their
science so back thinned has to do with
the way that the CCD is built so there's
two ways which I'm aware to make CCGs
one is the normal Kodak level with the
Kodak say CDs have the the face of the
CCD and then there's pixels on it but on
the face of the CCD as well there's the
electronic so the little gates that suck
out the electrons so you can you can do
your reading of them now these gates
take up some of the surface area excuse
me and they lower the quantum efficiency
because your pixel has a certain amount
of area but for that piece of area
there's a little bit of you know stuff
on there that has to read it out back
thinned is actually when you take a chip
like that and then you flip it over and
youth in it they've sort of thin it by
etching it so it's extremely thin and
then what happens is you're actually
able to get a much higher QE because
you're not blocking any of the photons
with the with the front illuminated ones
they actually have what are called micro
lenses now so you have a rare very small
lenses which essentially kind of are
over the part of the gate structure that
might otherwise block a photon a little
little lens sort of directs that light
into the well and that boosts the QE by
about ten or fifteen percent on these
the problem with the back illuminated is
just their part of the mate because they
have to be very flat and precise and
typically they have a smaller well depth
so you can fit fewer electrons in there
which can be disadvantageous in some
applications okay so from the small ends
to be very large this is the Keck
primary excuse me this is a 10-meter
primary mirror so large role in the
world there's a couple different light
paths f25 is the longest so it's 250
meters of focal length so you can
imagine eight a very steady amount and
some good adaptive optics to make sure
things don't wiggle around this also has
the advantage of being on mauna kea
which is 14,000 feet in the middle
pacific the very sort of laminar air
flow which is sort of polite to the sing
actually the way this one was made was
kind of interesting that 10 meter mirror
is actually made of it's 36 hexagonal
segments and the mirror is parabolic so
there's no spherical aberration and in
order to make to make all these segments
the correct shape this guy Jerry Nelson
and use it santa cruz rainham took the
hexagonal segments and then stress them
and you figure out how much you can kind
of stress the glass and then make sort
of a very easy spherical polish to it
then when you let go of it to kind of
snap back into a parabolic shape and
then you can fit them all together this
is the only really large one I know of
that's made that way there's actually
the cake twins there's two of these side
by side now other large mirrors actually
made by what's called spin casting which
is kind of an interesting technique
which was inspired by spinning mercury
around it used to be that to make a
really large mirror sometimes people
would just take a big sort of dish of
mercury and just spin it around it had
the disadvantage that you couldn't
really move it very much but you could
do time to let integration and some
interesting is strongly with it as well
yeah the spin casting is you're
basically heat up the glass and you spin
it and it gets pretty close to the shape
you need you need to do a little
polishing but that's it's an easy way to
to get most of the way there ok so
that's the kick and you need a mount so
I'm pointed out the mounts on a couple
of the other setups this is a more
modest mount this mount is made by
American company called astrophysics and
having a very stable tracking mount is
really really really important people
often say that you should spend sort of
as least as much on your mount is you do
on your telescope this mountain is a
robotic mount so
kind of program it look into your
planetarium programs it tracks this guy
very accurately do within 5 arc seconds
of periodic air so that means that if
you have a star that's not moving at all
and you pull the rely on your mount
perfectly the star will wiggle under
sort of five arc seconds based on sort
of the mechanical vagaries of the mount
that being said five arc seconds isn't
going to be enough right if you if you
know that the atmosphere limits you to
about half an hour second now I'm you're
going to have to to improve on that
there's a bunch of ways to improve on
that but it turns out that's a really
good start 5 arc seconds okay and the
other thing you'll need of course for
astrophotography is a camera this is the
camera I'm going to use for my examples
later on this is this camera is made by
company in santa barbara at santa
barbara instrument group and this uses a
k AI 11,000 ccd this is 11 megapixel
full-frame 36 x 24 millimeter ccd with
nine micron pixels it's cooled you can
cool it up down maybe 30 degrees celsius
there's a desiccant in here to keep the
chamber nice and cool and start to keep
it nice and dry so when you cool it off
you don't have do forming and frost form
the line the inside of the the mirror of
the window the shutter you can see is
not very sophisticated when you're
taking a 20 minute exposure you don't
need a very sophisticated shutter this
is just a little thing that kind of
spins around what you can't scene here
is or you can barely see it as Cyril
right up the laser here right here
there's actually a little prism that is
a pickoff prism I what it does it takes
a bit of starlight and it shoots it off
to the side but there's a very small CCD
that can be read out very frequently
independent of the big one and this is
used for auto guiding what auto guiding
is is it's a way of trying to overcome
some of the issues with the mountain not
being as precise as it needs to be so
what happens is as you're taking a long
exposure with a big with the big chip
you can place a star and this is
particularly easy with a wider field of
view it's harder when you have fewer
choices of stars or the narrow field of
view but you find out what's called a
guide star and you place it on
on that secondary CCD right here
sticking out to the side then what you
do is you read out the centroid of that
star you know every couple seconds or
half second and as the centroid of the
star moves you can send a pulse to your
mount to correct for the drift that's
the second place so you can imagine that
due to refraction of the atmosphere or
maybe you're not aligned correctly
there's going to be some drift over 20
minutes posure and so what you can do is
every second or two teens and a little
my new pulse to the mound to overcome of
that now it's a pretty good way of
getting stuff you know less than 3,000
meter two thousand millimeters to keep
things really well centered but you know
you'll realize it's sort of a reactive
thing yet you'll have notice that the
stars moving you will sort of move it
back and you know you're also sort of
moving this pretty big momentum you can
imagine you have a telescope and you
have to sort of wiggle the whole thing
around to overcome whatever drift you've
known it so well it's a pretty good
solution for most sort of amateur you
know up to I don't know 34 meters if you
go further if you have a longer focal on
that and you're magnifying more you're
going to need a slightly better solution
but this actually turns out to be really
good and these are kind of you can kind
of get these off the shelf and they're
actually less expensive than you think
oh and I should mention too that the
sensor is monochrome it's very rare that
you find a color sensor just because the
QE is is so affected by having that
bayer filter do the question
so the question is is possible use a
pizzo server on the CCD itself the
answer is sort of so there's a little
tilt thing you can use the same company
makes a mirror that goes into the light
path it's sort of a little diagonal
mirror and it has little speaker coils
on it and you can use that and it's not
really adaptive optics but it can go
maybe 10 15 Hertz and it can actually do
a lot more in terms of keeping the star
on the image without having to move the
whole telescope and it can be read at a
higher rate did that answer your
question and then you'll need your
filters since we're using a monochrome
sensor for the QE and also you want a
monochrome sensor because often you'll
want to do some some some narrowband
imaging and it's hard to get a sort of a
color sensor that's really first time
you know that's it doesn't have some
weird cut off some places where you
might want it so it's nice to step in
monochrome sensor typically what you
find least for amateurs is an RGB L
filter set that will filter wheel and
see the red green blue in there and the
clear one the reason why there's a clear
filter there's two reasons one is
they're typically made so they're par
focal so you can switch filters around
by having to focus and the other is that
often the clear filters are coded so
that when you look at sort of the band
pass of all of the sort of the some of
the band pass or the intersection of the
bandpass of your RGB filters you want to
sort of cut off your luminance at the
ends of that so the monochrome sensors
is sensitive sort of past you know where
you know I don't know it's got a little
sensitivity up will see the Kiwi in a
second but it's got sensitive e past
where you'd want it to make a normal RGB
picture so sometimes if you're making
just a pretty picture you want to
actually kind of cut things off right
after your red and blue filters tail off
you can also put in narrow band filters
so I have a picture little later where
there's a hydrogen alpha narrowband it's
a six nanometer band pass the spike sort
of at six nanometers sorry the spike is
the width is about 60 animators and the
narrow band stuff is nice because it
cuts out a lot of the sky noise you or
you can pick a band that you know
there's a lot of a mission in the sky
but street lights you know don't admit
you know in that range so while you're
cutting out on a lot of the light that
you let in you're cutting out even more
drastically on the line that you don't
want so you can get some nice contrast
two shots with them okay so no your
senses so the first thing you really
want to do when you start doing
astrophotography is you want to profile
your sensor and know it really really
well at keck they have sensors that they
essentially sort of do run this whole
profile on almost every time they fire
up the camera they have sort of over
scan and they check the bias and all the
sort of stuff which you know isn't as
this refine amateur I don't do as often
but it's important to know other stuff
so this this is the QB curve for the
cameras talking about for the ki I
11,000 based camera you can see it Peaks
here at about fifty percent QE at 500
nanometers so what that means of course
is that for every you know two photons
you kind of get one electric you got it
you get basically one electron out of it
and you can see again it's sort of
sensitive you still your Q is still five
percent up here at nine hundred
nanometers so if you try to make a
balance color image that light can be
problematic because either there's no
way to surf a California RGB or if
you're using a telescope has a
refractive elements chances are it's
only corrected in the visual right only
corrected between unit 450 and 700 and
so you may actually find out that you
have some sort of fuzzy looking stars
because your sensor is actually
sensitive to the D focused part of the
spectrum where the refractive element
simply aren't haven't been tuned to to
focus not a problem with reflecting
telescopes which is why all essentially
big professional telescopes are
reflecting you know if the worry about
not romantic aberration so that's so
mine I think I mission is about nine
electrons have read on noise electrons
per ad you is the gains or a point eight
so you know point eight electrons end up
being sort of one count and the full
well depth is about four thousand
electrons and knowing the full well
depth is good because the cameras become
nonlinear and do funny things depending
on whether they're they have Anna
blooming or non in a blooming sensors so
it's nice to to understand your full
well depth and how many sort of how much
light you need to stay in the linear
range as you get in the nonlinear range
first of all it's bad for doing science
because you can't measure magnitudes and
things like that accurately and also
it's hard to
your color because you're going to have
you're going to clip one of your color
channels okay so another part of having
our so we're going to talk about how you
would process an Astra photo and the
first thing you just make sure that your
setup is fully tuned and working it's
sort of one lime to like you know a
year's worth of work so the first thing
you want to make sure is that your
mountain is perfectly polar aligned with
the axis of the earth in other words as
your mountain is rotating it needs to
rotate at the exact same rate that the
earth is but it also needs to be aligned
with the North Pole and there are a
number of ways to do this probably the
best way is to actually have a actually
set up your mount get a pretty close
bead on where you think North is and
then actually put a star on your sensor
and read it out and your star will drift
put some cross hairs on your Start will
drift based on how much you miss align
and you can sort of continuously to in
your mouth over the course of 10 20 30
minutes so you can zero out that drift
and essentially you know the start may
move a little bit back and forth to do
to periodic error the gears or do to
sing but if you can kind of get to stay
in the same place for a chunk of time
than you know you're very well polar
aligned so if here on the right have a
screenshot from this program called PEM
pro by a fellow who lives on here
actually named Ray Ray lack and what
this does is this actually profiles the
mechanical error in your mound so what
happens is you know the the air is
usually pretty predictable you know it's
sort of a mechanical system and you can
sort of roll through your gears a few
times and you can graph out and you can
say all right how much does a star move
based on sir the mechanical error and it
sort of smooth it out and then what it
does is this program will will program
your mount and then your mount will know
where it is on the worm cycle then it
will sort of proactively playback pulses
so for instance right here can say oh
you know i know i'm sort of i'm too much
in one direction so i'm going to play
back a little pulse to the mount to
counteract that and this can account for
a lot of that five arc seconds so you
can really profile your mount you can
see that the mount here this one is
Mount starting at it you know plus three
minus 4.6 and you can smooth it out to
you know half an arcsecond in either
direction just by doing this periodic
air this is nice to write because this
isn't reactive you're not looking at a
star and your sensor and your guy
in your readout that's moved and then
trying to move the whole mount
accordingly you're actually sort of know
where you are in the cycle and you can
try to account for them so this is sort
of one of the many things you can do to
tune your setup also i mention t point
here t points also used by sort of big
professional observatories and this
actually sort of profiles a little bit
of the things that i was talking about
earlier where there's like for instance
there's flexure in your system if you
have a really long telescope
particularly the older telescopes the
older refractors where you had a giant
lens kind of 40 feet in the air there's
a lot of kind of bending and sort of
wheezing of all things going on and it's
important to be able to point very
accurately especially when you have a
very long focal length and you feel the
view is very small so T point actually
can profile a two point is sort of made
to profile you're pointing so you
basically point all over the sky it sees
how much things are off and it makes a
very complicated mechanical model and
enabled and sort of correct for the the
pointing errors you might have and is a
really good job of making sure that no
matter where you point in the sky your
target is going to be dead on the next
thing is focus so focus doesn't sound
like a really hard problem but focus
with a telescope is really sort of the
bane of a photographer's existence it's
really hard to do perfectly and there's
not much tolerance for having anything
defocused and the reason is because
you're working sort of at the very limit
of your resolution any lack of focus
will sort of rob you of all the sort of
high-frequency details the things that
make an image good or scientifically
interesting for the most part so there's
a really interesting program which a lot
of people use to to focus and it's
called focus max here and it interacts
with your CCD control program and what
you do is you essentially profile the
size of a defocused star and understand
what that looks like in your optical
system and then you move your sort of
automated focuser the correct amount so
what you do is first of all you have to
understand what the full width half
maximum measurement is this is just sort
of a way to measure a pulse and it's the
you measure the width at the half
maximum right so here's the maximum half
maximum and then you've just read
measure this and so what you do is you
go through and you take a star that's D
focused and you move through focus now
you'd probably know just intuitively if
you fish and you know put
camera on a light and then kind of move
in and out of focus the the light would
get really big when it's out of focus
then I'll go down to a sort of minimum
size and then we'll pass through focus
again and on the other side of focus the
D focused image will increase in size so
so what focus max does is it essentially
profiles that it moves your your your
focuser a predictable amount and it
looks at the size of the D focused image
and then it can put you know you and you
do a bunch of these you run through a
bunch of these graphs and you can
actually understand okay this is this
right here this this long this is where
I'm perfectly focused and so you you can
really sort of characterize your optical
system and then when you look at it be
focused star all you need to do is know
what side of focus you're on and then
the focus or can say okay well i know
that 17 steps or however many steps from
perfect focus and it can crank it back
this is really useful because you know
there's a lot of metal and telescopes
they contract and shrink a lot with heat
and whenever you change filters predict
with the fast optical system your focus
changes as well so it's really nice to
have this automated method and in fact
there's even more complicated programs
that will move your telescope slightly
so that you always have a bright start
to focus on so for instance suppose
you're making you know 20 exposures of a
very faint galaxies and there's no
bright stars around there too much to
really focus you can sort of program
your your your control program to
actually flew a little bit to a bright
star focus on it take an exposure slough
back focus and sort of continually
focusing doesn't take very long but it
really ensures that you don't lose any
20-minute frames right which are pretty
valuable to to blur
right so it's not so the question is in
the middle of exposure do you take a
picture or something else so you're kind
of locked in for the length of the
exposure that is actually some stuff you
can do to actually tune the focus during
the exposure itself but typically you
know 20 30 minutes isn't quite enough to
really ruining so if you focus at the
beginning of exposure and then folks
again for the neck every time you take
an exposure if you focus the beginning
turns out that's that's usually
sufficient there are some temperature
sensing things that you can put on your
telescope which are actually which you
can train which will adjust the focus
continuously throughout the exposure as
well to answer your question oh so I'm
saying that sometimes on if you have a
field of view a picture of something
you're taking that's very faint there's
nothing really to focus on maybe there's
a fuzzy galaxy and there's no actually
well resolved star and you need some
reasonable signal noise to be able to
actually focus so so you can actually
after after you're done taking a picture
of this fuzzy object you can actually
move the telescope a little bit and then
take something bright and focus on that
and then move back to your object in
between individual yeah right exactly
okay and then I'm kind of glossing over
a lot of sort of big points here but you
have to get your planetarium software
working which means that the the
software and computer has to understand
where your mount is pointing CCD control
software which controls the temperature
and interacts with all these other
automated things I've mentioned like the
focuser interactions the planetarium
program focus control so get that all
configured and then we have to get the
guiding done guiding is pretty hard to
this is so this is just I took the shot
last night you can see that I'm guiding
on you can't see the guide star but this
is a 700 second frame m100 and you can
see that you camp but these are about
point two pixels of guiding error so I'm
barely guiding so if you have things
really well aligned in your mat really
well tuned you don't have to nudge stuff
that much to really sort of have things
stay spot on but it's important to get a
sharp image and the way that the way
that you set up your guiding is you
actually put put a star on your sensor
and then you send a little pulse
in each to each access and you should
have measure how much it moves and then
you should understand how much pulse you
need to get the amount to move what
distance and then as you see things
drift you can based on that calibration
you can send through the opposite poles
to the mount to make sure that that the
star your object stays exactly centered
yeah what is the typical resolution of
the staff in terms of pixel percentage
of kitchen
site you were voting for instance pixel
French rag just wonder what the
resolution was or individual requests
going it depends a lot on the Mount I
don't know the minimum width I did at
one point yeah I'm there's a point right
at which if you're sending these little
tiny pulses that doesn't move things at
all i don't know the minimum but it's
sort of on the order of a tenth of a
pixel or less well i guess a I guess the
the the Acura sponsors it depends on the
focal length of which you're working
right so you're working too real on
focal if you know it could be a picking
up so it's really arc seconds per pixel
is really sort of the the measurement
but I don't still know the answer your
question okay so processing astro photo
in order to do a good job processing
astra photo you're going to need to make
three calibration frames a dark master
which sounds evil but it's not a bias
master and a flat master and then of
course we'll need our signal frames
which which are the the frames of the
actual object that we're interested in
and you know any color frames as well so
what's in an 80-year this is sort of
covered in earlier photo tech sessions
but in the case of a national for camera
there's this thing called bias and what
bias is is it's just a count that's
added when you start reading out your
sensor so you start out with a hundred
then the reason why they do that is just
because they don't wanna go- and use up
some of their bits there a 2d bits using
signed worry about negative stuff so
they say okay say they say that the the
sensor has a hundred read out everywhere
and the reason is because the noise you
can get you get shot noise from the
readout and the noise can kind of go in
either direction you just want to make
sure that that you have sort of enough
of a little buffer so that you never
actually go negative have to worry about
about using it the assignments so but
you won't understand how much would your
bias is and you can either sort of take
the manufacturers word for it or you can
measure dark current which is a
relatively predictable thermal signal
readout noise so just we don't know is
just noise you get
can do much about from from the actual
actor reading out the sensor and then
the signal so dark frames dark frames
are pretty interesting people say it's
dark noise sometimes but I don't I don't
think its noise it's actually a
predictable signal so here we have a
graph of temperature versus dark current
so the first thing to understand about
dark current is sort of what it is you
can imagine a lattice of silicon atoms
and they're sort of jiggling around and
if they're hot right there jigme pretty
fast and if they're pretty cold there
jiggling much more slowly and when
jigging atoms bump into each other
there's a chance that they'll knock on
electron loose that will get sucked into
the well of the pixel now there's no way
of distinguishing that electron from an
electron that's produced from a photon
coming in from the sky and hitting the
sensor so as you can see the sort of the
quicker you're jiggling your atoms your
silicon atoms the more probability there
is that you're going to be generating
sort of erroneous signal right going to
be dropping electrons into the welds
because Adams happen to collide so you
want to cool your sensors you know big
Observatory cameras take this to a
extreme these these you know doers with
you know liquid hydrogen in them and
they really cool the the sensor as much
as they possibly can but as you can see
with the sensor that i'm using my
example after about you know minus 22
degrees there's not a lot of gain to be
had by cooling your sensor more and it
takes a lot of energy particularly if
you have a portable set up you don't to
be draining your batteries cooling
things off and so this the axis here
degrees celsius and the dark current and
electrons per pixels per second in other
words how many electrons would you
expect to accumulate in a well in a
pixel in any given second based on the
heat so that sort of short answers is
just sort of cool cool your sensor as
much as possible and you want to you
want to subtract this away from your
light frames right so you've got a frame
with some galaxy on that you're
interested in imaging and you've got
this other count to which you just comes
from dark current you want to know what
that dark current count is so you can
subtract it away so you're just left
with the signal that you're interested
in so what you can do is you can you
basically profile this for the dark
signature of your camera each pixel will
accumulate dark current at a different
rate and so you can take a bunch of
these dark frames you get the sensor to
be the same
is it would be when you're actually
taking your photos and when you take a
picture that's the same length of your
photos but you take it with a thing
covered ready but the shutter over it
you're just accumulating dark current do
that a bunch of times and average them
up and as your average them up your
signal to noise increases your signal
increases more than your noise and
banette you have a more equal to noise
and you have sort of a smoother more
efficient dark frame and then you
subtract the master dark from each light
frame pixel by pixel and you're just
left with the readout noise and the
signal basically after you after you
calibrate all your light frames yeah
yeah yeah and you find that does that
things called hot pixels which you know
forever reason maybe there's a bunch of
you know silicon times closer together
and they happen to bumping into each
other more but you can definitely see
that there's a variation in fact another
reason you need to do it is if you have
a big sensor that takes a while to read
out so CCD sensors for astronomy are
typically read very slowly because the
slower you read them the less noise
there is and so you can actually see a
gradient we're the ones you read it at
the bottom have accumulated fewer dark
pixels and the one you get 2 30 seconds
later as you finish reading the array ok
bias frames are just this added in to
read out they're not it's not signal
often in this and manufacturers were to
pick a number I just sort of add it to
every count so you can calculate if you
want to or you can just subtract 100
many people to sort of subtract 100
because it sort of programmed in there
in the electronics by the manufacturer
flat frames so flat frames are really
interesting because they can really help
to fight allow the problems that you
might find in your imaging train so let
me talk about how you acquire them first
then a little make make a little more
sense about what they are so the ideal
goal and making a flat frame is to
uniformly illuminate each pixel so you
for every pixel in your array you want
to give it you want to be outside of
your your sensor and outside and you
want to make sure all the photons go
through your entire imaging train and
send the same number of pics
out in a very flat way it's going to be
hard because finding a really really
really uniform source of light it's
actually harder than you think it turns
out that the twilight sky is a pretty
good source particularly if you don't
have a very wide field if you have a
narrow field a few degrees off Twilight
right after the sunset is pretty uniform
and I also has the advantage that has
sort of the same spectral response as
you're close to the same spectral
responses the night sky so you have a
pretty representative frat flat frame
some observatories just sort of paint a
reflective white on the inside of their
dome some people have like boxes that
are they have much the lights in there
and some diffusers and utricle APIs on
the Indian telescope so you take so you
make sure your light sources very is
very flat very uniform you take a bunch
of these flat frames you want to get
good signal to noise so you want about
two-thirds well depth where you're still
in a linear range of the sensor and you
want to normalize these right because if
one flat frame has a lot more where I
guess yeah I mean you want it's ideally
you normalize these so they all sort of
have the same weight then your average
them up and what you end up with it's
sort of a signature of what happens to
the flat light as it goes through your
system so if there's been getting in
your system you'll see Vinny adding on
the flat frame if there's dust in your
system to see a dust mote on your flat
frame know what you can do is you
basically divide your resulting signal
image by the flat frame and it boosts or
sort of retards the signal and each
pixel based on you know whatever
whatever issues they might be in your
optical system or even QE changes
between pixels for instance one pixel
might just be less sensitive than
another you want to sort of boost them
up so that were your light source
uniform your resolve the uniform and
I'll kind of give an example which will
which you can see which makes it makes a
little more sense so it takes care of in
getting and you can do this actually on
terrestrial photos too it said the parts
that are dark it makes them lighter if
you have dust on your cover slip which
is very often the case you can it's sort
of a the shadow you can sort of multiply
by the inverse of your shadow and it
boosts up the darkness where the shadow
would be pixel of pixel Q
inconsistencies and it's sort of
critical for scientific astrophotography
because you can be fooled and thinking
that you know heyo the star is dimmer
maybe there's a something going in front
of it where well it was just just a
piece of crud on your sensor so you can
actually I said you can also try flat
framing terrestrial photos because I'm
sure you guys have all seen if you have
a very fast optical system you know the
corners are dark from your vin yelling
okay i'm going to start hurrying a
little bit because we're almost at a
time so signal frames this is just the
the signal from the actual image that
you're taking and the basic the basic
story is here is that signal ads and
noise ads with the square root of signal
so up to a point you just if you keep
adding more exposures and stacking them
up you'll just keep getting more signal
by the end group goes up by the square
root now there's a couple things you can
do to which actually help make your
frames better one thing is dithering
which I mentioned your frame back and
dipping is when you take an exposure of
an object what you can do in your next
exposure is move the telescope very
slightly so that when you combine our
average your frames together any
correlated noise that's because of the
sensor will get averaged away you can
imagine there'd be some some funny spot
on the sensor that's a little more or
less sensitive and a lot of your flat
frame should take care of that but
there's a lot of correlated readout
noise and things like that so that if
you actually kind of move your sensor on
a little bit and then sort of average
your images stack them all up align them
and stack them you'll actually end up
smashing down a lot of the correlated
noise on your sensor so the sort of the
takeaway from this is take a lot so the
more certainly you get the more you
stack it smoother your images and the
higher signal-to-noise so this is sort
of what you get if you stack a lot of
signal so this is actually interesting
photo this is taken by gentleman in
elua's in Texas named Russ chrome and it
takes fantastic astrophotos he has a
remote Observatory in New Mexico and you
can see here he spent twenty 8.5 hours
of exposure and for example the Hubble
Deep Field was 42 hours of exposure and
you can lessen see here that he combined
both some narrow band filters with some
more broadband feathers and even
illuminance frame
and you can do this because no one
really knows what the color of stuff is
in space right if you go out and look at
a nebula with your naked eye it's green
because that's the only place you're
sort of sensitive enough to see it
because it's faint and even if you were
to rush right up to it the amount of
light / sort of square foot still would
prevent you from seeing any color so a
lot of the color is sort of an
interpretation or sort of maybe
scientifically correct over whatever set
of wavelengths you want to represent
color but that's really up to up to you
if you're trying to show something or
show a structure sort of combine
whatever sort of set of exposures and
wavelengths you want and so here you
know there's a lot of very interesting
stuff going on in the in these narrow
band ranges and those were sort of used
as part of the luminance to bring up the
contrast of the picture and this this
shows what I was referring to earlier
about the flat frame this is again this
is the superb loss program with these
these these Canon lenses in the reason
why this is a good example is because
those Canon lenses were really fast
there were f 1.8 so you can see there's
a lot of any ending up here this is your
raw image he sees a bright spot on the
Centers you'd imagine here's your flat
field as you can see it shows the
vignetting and when we divide through by
your flat field the fields flat to all
the stuff the dark stuff has been
boosted your bias as you can imagine is
pretty uniform and the dark current you
can see here maybe it looks like looks
like there's some heat generated here by
an amplifier off-chip and it's warming
things up a little bit that's typically
what you can see from that so so the
dark frame is removing all the
additionally accumulated dark current
from from that warm piece on the on the
chip they're off chip I should say so
here's your final image which is nice
and flat looks like a nice healthy
starfield combining color frames so this
is this is sort of analogous to doing a
white balance you have you know your RGB
and maybe L and you what you want in the
reason why i put this hurt sprung
russell diagram up here it was to show
you that there are some some white stars
there's a lot of light stars and you can
actually just find a white star
somewhere that's near your target do you
focus it a little bit and you can
actually use that to white balance your
r g and b frames together we have to
make sure again not to clip these too
much because if you do and your color
will be skewed right if you
if your luminance is clipped or your RGB
is clipped your they get funny colors
and it's very often when people start
doing astrophotography like well why
does my thing look like pink or orange
or yellow and it's because you know they
were like oh I need a bunch of signal so
they stack things up and they ended up
clipping one or two or all of their
channels so this looks this is the image
of a band pass filter of the set of the
band pass filters that you might use so
the here's the blue the green is a
little more spiky here and the red and
the takeaway from this is really that
these filter designed so that some of
the the wavelengths in the universe that
which are most common are passed so
hydrogen alpha that's a big one oxygen
three and that's sort of at the
intersection of these and there's a lot
of caretaking the design of filters to
make sure that you cover the whole range
but you also don't have some some
emission sort of where your filters
cross okay so what do you get this is a
somewhat washed out picture this is the
horsehead nebula in Orion this is really
wide frame this is taken with that
example camera and this is a sixth
animator band-pass hydrogen alpha filter
this is a very pretty thin filter and
needed 20 hours of exposure because
we're not letting in very much light
with that narrow bandpass and the camera
school to minus 22 degrees so this this
image is really interesting you can't
see this galaxy very well here but it's
interesting for a couple reasons first
of all the resolution between these four
little dots is really the distance is
very very small it's this is extremely
high resolution this is taken by a
fellow named Roland Christian who makes
mounts and telescopes and runs
astrophysics it's a neat guy and he took
this photo as well and this actually
shows gravitational lensing these four
bright spots are actually the image of a
quasar that's directly behind this fuzzy
galaxy and what's happening is light is
getting bent by the massive galaxies and
coming back around through the other
side this is the sort of lensing that
Einstein predicted that's why it's
called ensigns cross because there's
four images of the quasar that are
behind the galaxy that you can actually
see for a front of it it's a pretty
impressive accomplishment for
such a small instrument and this is a
animation here this is the fella is
referring to earlier Chris go you can
see these shadows here on Jupiter
surface this is a transit a double
transit two of its satellites are
crossing past its face and this is sort
of a off-the-shelf 11 its telescope and
he's using a high-speed web camera
monochrome with a color filter wheel
he's taken a thousand however many
thousand shots and he's pitch and most
of them just keeping the clear ones he
also happens to live in the philippines
in cebu city where he's discovered that
the scene is very good he also
coincidentally Indus covered red jr.
this white spot on Jupiter that turn red
was sort of a lot of interest in the
astronomical community and he was the
guy first notice it because he every
night sort of roles and stuff out and
take these amazing images this is a
another image by Russ chrome this is m51
and this is kind of cool you can see how
a lot of these stars have been sort of
flung out into space by the collision of
these two galaxies and again this is
from his you know 20 inch telescope in
New Mexico and this is a last picture
this is taken by gentleman in New York
named Alan Friedman who is using a very
narrow bandpass hydrogen alpha filter
again but this time on the Sun and this
is the the solar chromosphere you can
see some activity happen here on this
this dark spot so we're almost out of
time like we are out of time any
questions
oh sure so I have I have a my telescope
set up at this place called New Mexico
skies which is a remote observatory and
they host a bunch of telescopes there
there's I don't know 30 maybe telescopes
and some schools and some individuals
have telescopes there and what they do
is there some people were very
knowledgeable who maintain your
telescope essentially this fellow named
Mike Rice he's a whiz just sets up your
whole system you can kind of set it up
at home and tune it ship it out to him
and he essentially and ship it out with
the computer he'll essentially kind of
throw a DSL onto your computer and if
you're well enough versed and all the
software you can actually sort of just
fire it up on any clear night there's a
little weather console any clear night
from my home I I can use all the stuff
that I sort of mentioned here but
totally remotely there's no real reason
to be in front of your scope this is all
control with software and you know
cameras and stuff so doesn't it you know
once your mount is set up there's really
no you know no need to physically be
touching it it's nice to be with your
equipment sometimes but it's even nicer
to have it to set up so yeah so almost
most clear nights in New Mexico I have a
little image I have a little you know
well vm you know a little you know
window of my setup down there where I'm
controlling it and taking photos as well
the question is a 20 hour photo how many
nights was that that was about over six
nights and it will vary a lot based on
how low you won't let you let your
target get or a lot of stuff but so the
one the the one that I took was was was
over about about a week sometimes people
take stuff over the course of a couple
years they just sort of keep adding to
it right they you know and one guy Rob
Hendler is sort of notorious that's the
right word but he'll take stuff with
different focal lengths over the course
of years and this sort of smash them all
together once they're calibrated and
bring up the signal tonight yeah
so the question is are there any
adaptive optics available to the amateur
there's that tip taupe thing that I was
talking about which isn't really
adaptive optics there used to be at one
guy named Don Parker I believe who made
an on-axis AO system which is really
just for planets but it's not available
anymore so the short answer is no but
the long answer is I hope so and people
have been working on different ways to
do it cheaply yeah spent a lot of effort
in individual pieces of the pipeline
tuning out air or accounting or issues
either in the physics and the objects
right does anybody build a global model
and then do global in the end
optimization where for instance you use
the fact that your stepper motors
certain characteristics to actually
induce the dithering that you would then
be picking up an account yeah yeah
that's a great question so the question
is are there any sort of programs that
do allow the end to end tuning since all
the individual components seem to
require so much sort of care and
precision the answer is yes there's a
there's a couple out there and what they
tend to do is they'll they'll take sort
of exactly as you described the end to
end you need to really get things set up
pretty well first there's no there's no
shortcut to like sitting front of your
scope and get everything tuned and
balanced perfectly but once you do
there's there's a bunch of programs that
will you kind of say I want to use this
target and I wanted to focus every five
minutes and do a bunch of color filters
and wake me if the if it gets cloudy
kind of thing so they're beginning their
there a few now that do that any other
questions all right finish up Sam Rose
wants to say a few words about some
astronomy stuff he's working on thanks a
lot ben appreciate the time just going
to take one minute and tell you about my
twenty percent project which is a
project it won't help you take a photo
but if you have a photo oh you want me
to use this okay if you have a photo it
will help you find exactly where it is
on the sky do you have a web browser
then I'll let you do it so anyway Chris
ooh look who is here and I see Lance at
the back these guys know about this
project but yeah if you just find me in
MoMA row ace ro w/e is if you're
interested in you know amateur astronomy
and locating your photos yeah we can we
can put a link but I'll show you a demo
of it just so you get an idea of what
it's all about it looks at where the
stars are relative to each other and it
does essentially massive geometric
hashing and then some statistical
pattern recognition and it slaps you up
on the sky so it solves the it solves
the sort of Strama tree problem very
very accurately and the nice thing about
it is you don't need to give it an
initial guess so there are the systems
like pinpoint and stuff which will tweak
up your image you're pointing for you
but here you can
just you don't need to tell anything
about where you are so i'll show you if
we get if we get up here i'll show you a
quick demo of it
okay so we've been using the strongly
picture of the day here under the test
bed
so this is a site run by NASA and they
just okay thanks they just post a
different picture every day so here's
today's picture I guess it's of one of
barnard nebulas so basically I just need
to grab this link here and then I'll
show you a demo of the the service so
this is in collaboration with some
astronomers at NYU and so it's all in in
alpha testing now but i'll just give you
a quick thing quick demo of it so
basically we're going to try and we're
going to try and make this a service let
me get rid of this and use a smaller
version of it they usually have a
low-res version which'll so you just
need to tell it's something about the
scale of your image so that that thing
is probably about five or six arc
minutes in size so maybe I don't know
six times that or something so i'll open
in some estimate of how wide it is this
just speeds it up if you if you do if
you give it a wide range or you give it
no guest at all it will just search all
all the scales anyway so then it goes
and grabs that image off the web and it
does source extraction on the image so
you can see the red circles are where it
found objects and this is all very very
trivial computer vision it's not doing
any hardcore sub-pixel localization or
anything and and then it cranks away on
your image and it looks for patterns of
stars in the in the image that it
recognizes and then boom it tells you
where you are in the sky so here you are
it tells you at the top the RA in dec of
your field and then it takes all the
known stars from the USNO catalog and it
reprojection them into your image and
and then on the bottom it actually gives
you
a WCS file this is the astronomical it's
called world coordinate system so it's a
very precise way of specifying you're
pointing in your tangential distortion
so the plan is to put up a service for
Google to put up a service where any
amateur astronomer anywhere in the world
can upload their image and then we'll
tell you exactly where on the sky your
image and if you check the box that says
yes I volunteered to donate my image to
a global database of astronomical
observing then we can lock the image
down on the sky and we can build a
structured global observatory instead of
just having people upload images with no
information about where they are will
actually solve for the position of the
image and then because we know so much
about the sky we can actually back
compute all kinds of things about the
distortion of your camera and what
bandpass you're looking in and
everything so we could get thousands of
images cranking through this thing
pretty soon so if you want to help out
please send me email lanes yeah so Lance
is just asking me to point out the way
we actually solve the image is we look
for four stars that are thanks dick we
look for four stars that form a
quadrilateral and the exact angles of
this quadrilateral I used as a geometric
hash key into a huge database of
millions of hash keys and so as soon as
we find two quads in the image both of
which hash to the same position and
rotation in the sky then we decide we
think we have a pretty good hypothesis
and then we test the hypothesis and the
way we test the hypothesis is we shear
and rotate your image according to the
transformation implied by this and we
look for coincidences so here you'll see
there's a green circle and a red circle
that means there's a source in your
image that's the red and a USNO object
that lie exactly on top of each other
after the transformation and that
happened like 1 2 3 4 5 6 7 8 9 10 11
you know it happened like 30 or 40 times
in this image so the chance of that
happening by accident is you know one in
several billion so we just dial in a
false positive rate of you know 10 to
the minus 10 or something and then
we're absolutely sure that we know where
you are on the sky so yeah so so send me
e-mail if or i guess the dick invent are
going to put a link to that some to the
pdb page</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>