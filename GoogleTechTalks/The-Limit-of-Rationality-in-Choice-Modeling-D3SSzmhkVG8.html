<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Limit of Rationality in Choice Modeling | Coder Coacher - Coaching Coders</title><meta content="The Limit of Rationality in Choice Modeling - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>The Limit of Rationality in Choice Modeling</b></h2><h5 class="post__date">2017-10-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/D3SSzmhkVG8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so it's with a special excitement that
pleased to welcome dr. Patrick switching
down to our weekly meetings seminars at
school so part is a professor in the
Marshall is business at the University
of Southern California being a very
delighted to have as my PhD quiet myself
so Pattinson a banker is a great work in
data mining and stochastic optimization
and then for that he won several awards
including dancing dissertation award in
a second carrier one and in from a
junior faculty paper competition of one
not only he's a great researcher he is
also a great and outstanding teacher he
has been chosen as a teacher of the year
and when he was when he was a faculty at
corner and then as you see also won a
Golden Apple Awards for teaching
undergrad students and also teaching MBA
students and then so yeah so today path
is gonna talk about the limit of
rationality in choice modeling so please
join me to welcome thank you again so
this is a joint word with my colleague
professor Srikant Jacob aqua NYU Stern
but now before I begin I really want to
thank Megan here for inviting me here
first have Google and while you need to
show me some of might work wonderful
visit thank you thank you very much so
the focus of today's talk is on discrete
choice models and it's been really very
popular both in academia and industries
or demand predictions or cast and again
the reason for that is because they can
capture complex substitution patterns
and now there are thousands if not tens
of thousands of papers that have in
economics marketing psychology and
operations that have applied discrete
choice models in variety of different
contexts transportation is read
anything involving choices and listen
here are just a few of the tens of
thousands of papers and that topic but
what I want to do is before I end I just
want to make sure that we all sort of
set a context of what is the discrete
choice model so we have typically a
universe of any product index I wanted
to give up to an e and essentially the
one thing that we want to understand is
what's the probability that a customer
will choose a particular product when
assortment is that it has been observed
inherently and experimentally that the
probability that the customer will
choose any one item is not exogenous it
is contingent on the assortment that you
offer alongside him or her when you go
to a store there probably was choosing a
particular brand of conflict is
contingent on what other brands of
conflicts or what other brands of
cereals it is present and this is the
quantity that we want to understand so
notice I design a function of product
what is a functional product and the
assortment that accompanies it which is
offered and that's what we want to try
to estimate so Wow and later on I'll
talk about the data set that we
typically get that we use to estimate
that but the entire talk revolves around
this one that's what about we want to
understand and discrete choice models
okay so these in it one of the most
popular discrete choice model that we
can use to try to estimate this
probability is what we call a random
utility maximization class discrete
choice models all are um incheol okay
and this is a very popular again
virtually every single paper that has
used discrete choice model that a lot of
balls in his classic tens of thousands
of papers written on and it really
assumes a very simple assumption it says
that when a customers walk in and see
different choices he or she draw a
random sample of the utilities of the
different products and whatever the
distribution you like and then once he
or she observed those sample utility he
or she picks the item with the highest
utility that's how he slept
with no order no it's not kind of
Ordinances that yeah so they don't water
it's not water it just like a subset and
of course you know this is not real no
but you have to kill these nobody has
rendered or around it's all modeling
assumptions but surprisingly is simple
assumption encompasses a very rich and
broad class of choice model including
the multinomial logit the nested logit
the mixture of logics which i use
virtually like in every papers and
choice modeling marketing so they use
the mixture of logit and so that's sort
of the set up so we want to understand
the power of this our um class and this
is the quarter and the question that i
that motivate all this research two or
three years ago is really sort of
something i face all the time as i work
in this area is how to select a good
choice models and typically you start
with data sets and for this particular
talk we'll be focusing on grocery sales
data from a chain of supermarkets in the
US and we'll have single transactions
from multiple product categories so what
we would do we separate them into
different categories and work with each
one separately from each product
category the data set that we have can
be represented by this vector F but it's
top script M what is this this M here is
a collection of different offer set that
the customers see now why do we have
different opposites
okay so here's the one example different
stores within our supermarket chain can
carry different assortment of the say
sued brands to cave in to the local
tastes when your different brands some
people would say and Wisconsin but even
within the same store for example since
these super ads have to be stopped
say honest a on a weekly basis during
the course of the week between
replenishment town items get solo
weapons so when that happened when the
customers goes to the store is an actual
brand a suit that he or she sees on the
show would be different depending
in the stock that's why we have a
different offer set and each offers that
a pass let's use my finger then ask in
the collection M the data we observe is
this M is with the fraction of times
that a product I has purchase been
purchased when the assortment s is
offered and the sum of M I asked by an
ass is equal to one so that's the data
sets that we work with and again we can
then use given this data set we can
estimate the parameter of the choice
model it could be the multinomial logit
weiss mono or whatever is specification
of the model that you interested in hey
they've got the details of which is not
germane this particular table here and
I've done that here for six different
product categories in our data set and
ranging from shampoo mayonnaise diapers
up to sugar substitute either for each
of the product category I fitted a
multinomial logit
choice model it's a very popular choice
model within the are you in class i
evaluate its performance using this
metric called the mean absolute
percentage error which is the difference
I mean the actual observed percentage F
is and the prediction F is hat and
divided by the truth out and this is
what it looks like now of course we can
fit a more complex choice model such as
the 15 class mixture of objects which
has 15 times the number of parameters of
the multinomial logit and when you
evaluate its error is looking like this
green bars here at this simple graph
here races out a whole host of
interesting questions i think the one
thing one can ask what did I fit ability
class mixture blocks fifty classmates
your profits is it possible to drive
this error by all the way down to zero
okay and if not zero what is the minimum
achievable lost and one can obtain or an
arbitrary discrete choice models on a
random utility maximization class
testing these are not there works on
unseen data right Oh
actually you can put it on CD I'm just
talking one in Sam where it just just on
in Sam where can you drive this to zero
that's questions oh if not what is the
minimum achievable and and of course
both of these moms know me about it and
mix your logic clones is our um class so
one way to state this a lower limit
apparently you can write them as well we
pick your favorite convex loss function
it can be anything it can be the mean
absolute percentage error it can be your
KL divergent which is your maximum
likelihood estimate arterian it could be
no one to norm Pino and whatever you
like any of your convex loss functions
whatever I think your applications we're
gonna measure the distance between the
observed choice fraction which is our
data set fjs and the predicted choice
fraction XJS that is consistent with our
um one and so XJS is the probability of
choosing product j from an assortment s
under an argument and we yes because you
can actually get a perfect person
population to create the preference that
he book prefers what he bought no
possible because our um motto imposes
very restrictive constraint the
probability if i add the probability if
I add an assault if I add an item to
assortment the probably in choosing a
single product has to go down and that's
not that does not always happen there
could be situations there in our dataset
where some items when you add it to the
assortment the probably fusing two guys
is go up and so it it's not always true
or it's not always true I guess and you
verify that that is actually what's
happening on the data yes that's part of
the that's exactly what we are trying
about trying to do you want because the
problems like this one is you can verify
it for particular choice not it but we
don't do very high for all arguing for
is not at lots and that's part of the
that's what we are trying to do here
whether or not we want one of the one
way to frame our question is is the data
complete
explainable by an argument or solid
that's that's one about it okay so this
is one way to formulate this limit of
rationality now what this is not a
precise mathematical statement because
it's not clear how one would optimize
over X ranging over all possible
audiences uncountably infinitely many
are um choice on but to do that what we
want to do is take advantage of one very
important and very special property of
the argument clock see every choice
model within the are you in class
correspond to a probability mass
function over the set of rankings and
the reason for that that we didn't argue
in class I said that the customers
choose product with the highest utility
what that immediately mean that the
magnitude of the utility doesn't matter
what matters is the ranking of the
utilities across all the part and
therefore the probability mass function
over the rankings so what I can do then
to make this the precise mathematical
object that we want to study I can
introduce auxiliary variable lambda sub
Sigma one variable for each ranking
Sigma Y is non-negative and it's some
some one so this is a bona fide
probability mass functions over the set
of rankings then we can replace this
sort of fuzzy constraint XJS by a
precise mathematical statement saying
well what's the problem
choosing product J for myself set ass
well we simply sum over all n factorial
ranking Sigma and for that ranking of
item we check whether or not J is the
top ranked item in ass under Sigma if it
is you pick up a one and you pick up
that weight of lambda sub sing this now
is the precise mathematical statement of
what we mean by the limit of rationality
and it's not my useful however because
this is the convex optimization or any
factorial variables in fact or just
explodes you know collect any lieutenant
not what to do with it at the moment and
so but this is the precise mathematical
statement okay now in the next stop but
wait 30 minutes or so it's going to
answer two questions the first questions
is that what I call the Sawat question
let's suppose that we can compute this
value exactly or anything cares so what
how does that help us select a good
choice model which was the very first
question I motivate in the very
beginning that's the first question and
I'm hoping to answer that and be
affirmative that there is some use in
knowing this value of limited
rationality and anybody I get that out
of the way then the next question is how
can we go about and compute this now to
try to figure out how we use this limit
of rationality
he's one sort of this house a cartoonish
or pictorial representation of what
we're doing if I represent all discrete
choice models within the argument class
and his big rule then inside out we have
this small of gray circle which is a
subclass of all the multinomial logit
choice model and this dot here is our
observed choice for R this is the data
set that we work with then I can compute
the distance between the red God and the
red dot and the black dot here with the
red dot E is the best fitted model when
V are you in class tested it under your
 your favorite convex loss function
so that distance is really called the
limit of rationality now of course you
can also compute the distance between
the black dot and the green dot which is
the best fitted M&amp;amp;L and that is the
total loss under dama now so in every
data set that you work with you have two
numbers total loss on the Emma now and
the limit of rationality and you can pop
them on this two-dimensional run the
x-axis being a total loss on the Damned
and Al and the y-axis being the limit of
rationality depends on the convex
function which shows right yes that also
depends on the methodologies or how you
go about that in general that is correct
depending off a lot of people use
maximum likelihood estimate which is the
KL divergence that's also somewhat some
people prefer a different metric so
really depending on the application
absolutely no no you can't do that right
because I con mean we dis
always possible because saying yes come
up with yes well typically what we want
to do is you want convex functions that
is sort of strictly convex and if only
at zero if you have your prediction is
exactly the holes with your observe
choice fraction so what for the six data
sets that we have shown you earlier you
can plot those two pieces of information
on this here on the scatter plot and you
can see here that this pot is consistent
with the pictures that we have here that
the total loss on the DL is larger than
the limit of rationality this is so fall
below the 45-degree line now so the
question that you say okay what do I do
when you stick scatter dots on this
ground now typically what happened is
when you work in a particular
application the user oven has in my what
he or she considered as what he called
acceptable loss threshold and so I think
this is good enough
now again of course there's nothing
magical about those is really user
dependence and context dependent but
it's supposed to users specify a
threshold 30% for example let's get the
other numbers depending on the objective
you use and criteria you have it
immediately partition the lower half
regions into three different parts the
first part here as highlighted in green
all those data sets or product
categories for which to total loss on
the dama now is already below the
threshold okay so if this is really your
threshold then you'll need to go further
yeah Mao is good at optimism but we also
created another segment which is
highlighting carpool here which your
total loss under the EMA now exceeds the
threshold but the limit of rationality
is below the threshold so you couldn't
sort of consider fitting more complex
choice model within the arguing box but
makes your logits nested logit and
thinks of such sort and of course they
left with the region which is what
called highlighted in red he said that
we have our data set for which the limit
of rationality is above the threshold
that's good
you know it is because what that mean is
don't bother the fitting mixture and
fitting make sure it takes a lot of work
you don't just throw it in have to tune
them look at them so that's a so for
these data set the arguing class will
not be able to allow you to low have an
error of a little depression in order
for you to have the error below the
threshold you'd have to go beyond are
you mom yes I'm so this is one simple
way that you can use this quantity limit
Raja and term I'm trying to figure out
which data set which model to use for
different data sets and again in our
paper we have much more extensive
discussion you can use his metric for
model selection this is this is one way
to do it
so hopefully give you a sense that that
it is it's not useful to compute this
number yes
why can't I just why can I just go to
the more the most complex model all the
time and then what is the most complex
novel that's a question most complex
Nardo is not 100 the one that little
scientists are you a model that you have
oh but that is that is not Prasad that
is no such good you're saying right now
like for the cortical region like you
should be fitting you can you can fit
more complex are you know so currently
one one but right now the current the
most complex fanciest model within the
argument class is the probably the mass
function over ranking now there are some
drawbacks with those because currently
as of now today fitting we have no way
to incorporate features
prices average user reviews and all
those contextual information when
fitting a probability mass function
already there's an open active research
questions that people are spending time
doing so you can fitting the more
complex for it's not what may be
marketers or the people we are in that
application they want something
interpret they want to understand how
prices how average user reviews how the
contextual information influence these
probabilities and for those unique
parametric models parametric models are
not the most sort of complicated exactly
so here I'm going to learn
I mean I own this lets your you have a
universe of model so you can create a
scrap that have some restrictions let's
say because you wanted to be
interpretable out of all these universe
why can I just choose the most
complicated well you can't exactly would
be a lot to do knows I might not be very
predictive you don't always want my
point is why do you need like what what
are you getting from the other water
right well are you what is the loss that
you get fitting the most complex region
I don't lose anything from you in the
red region yeah so it's super useful in
the red region what are you in the red
region in the red region says it don't
bother you need to go beyond the arguing
class this is the heart that I'm and
again I'm obviously in now papers we
look at more than six five categories
I'm gonna show you here for the spy
contracts
okay so now let me turn also talk about
literature on stochastic rationality and
there's a really a lot of literature's
in economics and computer science that I
really study this issue is all
stochastic rationality and in it the
economics in economics research there's
something about really beautiful
characterizations it's necessary and
sufficient condition when the data set
can be completely explained by our um
our so we haven't when the limit of X is
exactly equal zero there's a really
beautiful graph from the late 70s upon
large mature as recently as lutely 2000
by professor McFadden now it was
unfortunately don't address the
important questions of what happened
when these necessary and sufficient
conditions are not satisfied so when the
limit of rationality is not zero and
when you go figure out what that is and
what is that number
okay so that has not been addressed in
the economics literature but in the CF
villagers didn't have look at computing
this limit of rationality for a very
specific collection of subsets
consisting of pairs of products things
is also synthesized to
and this even prepares computing the Lin
rationality is provably npy and is the
beautiful light lots and lots of works
here in the early 2000s and there
recently to come up with approximation
algorithm happy approximates that
balance this is np-hard to compute but
they don't really look at general
collection of subsets so our goal in
today's talk is we want to study this
object limit of rationality for an
arbitrary collection of subset M and I
think what really what is important to
us I think for me from for me personally
is really understand what about this
collection of subset M that makes
computing limit of rationality hard we
know it's hard when it's paired but when
we started this project three or four
years ago
like burning questions like okay but I
work in operations
I don't really encounter care as a
product they often encounter different
kind of subsets such as grocery stores
where items of stock always encounter
nested collection when airlines close
all open different backgrounds I know it
sounds that easy computer right so that
sort of really the driving force that we
are gonna go after it but an X let's say
15 20 minutes or so okay so that's
really what are we going to be going
after so again this is listed in blue
here is the formal definition of the
limit of rationality of describe to you
a couple of slides ago now I want to try
to find a way to get a handle on it's a
very complicated object here at this
point so the first thing I want to do is
try to is trying to find a way to
rewrite this feasible region in a more
compact way and the first observation on
the make here is that this XJ has the
probably of choosing product j from an
assortment ass it's really nothing more
than a convex combination these indicate
there's all the lambda sigma sums to 1
ok so you can then write this vector ax
as being in a convex hull
span by n factorial vector 1 vector ease
of Sigma from each ranking Sigma and
this vector each have Sigma is that
vector of indicators so it has the
binary vector of dimension equal to the
total carnality of every set in the
collection
and again if you look at typical coach
Jas component of this piece of Sigma is
simply one the product J is a top ranked
item in the set s under the ranking C
and 0 otherwise okay so that's star get
haven't done anything I'm just rewriting
the copies of regions so it's a convex
hull it's still equally hard this convex
hull has in fact her extreme points one
extreme point for each right extreme
point to visit so then the next thing I
want to do is deal with this very convex
function because right now you could use
whatever convex functions you will
that's 50 applications that have it's a
little difficult to deal with arbitrary
convex functions so what we will do then
we will appeal to the rank of algorithm
or conditional gradient methods which
allow us to solve any convex
minimization problem by transforming
them into a series of linear programs
okay so what it does is it generate the
sequence of feasible solution in each
other it it looks at the objective
function at that point and you linearize
it so instead of looking at the convex
you linearize if I think the gradient
the gradient at that point and then what
you do when you solve the corresponding
optimization problem which is now a
linear program you linearize is the
objective function so the CJ asses be
the gradient of the objective function
of the current dinner if I give you a
distribution over it I give you a
distribution over ranking yes can you
give me like yeah and are you are you a
model
it isn't that corresponds to that
particular distribution Oh what is it
there but once you give one to tell me a
distribution or world ranking it is
already an AR ùl model it is already in
our UL model so can I cope with it again
after you say become a perhaps a
different question second some wasn't
give you a parametric model like an ml
or nested logit can you come up with a
probably of this regional ranking is
very difficult
yes that is correct ranking is
automatically an R um one by definition
because Mom you don't need that
utilities
so together we essentially again sold
there's a lot of experts in this rooms
who work with Frank move and conditional
gradients on a daily basis multi-billion
dollar a multi-billion variable so I
will leave this here's what essentially
we have gotten is we have convert the
complexity of computing the limiter
rationality under this contact loss
objective with the complexity of solving
this linear program now again this is
still hardly a program because this
feasible region is a convex hall when in
fact her extreme point that's a lot of
extreme point for the simplex algorithm
to visit my lease is a linear program
and the first thing we can do with a
linear program is that you can write
this continuous optimization problem as
an equivalent discrete optimization
problem cuz we know that the optimal
solution of a linear program occur at
extreme points an extreme point of this
feasible region is just a ranking Sigma
each ranking Sigma give us a factory
lease of Sigma so we simply replace his
yjs by the jas coordinate of that vector
E sub Sigma which is the indicator to
check with a J is a top ranked item and
asked under the state under the rent
it's a mega this is also called the rank
aggregation problem which has been
extensively studied in to the science in
the early 2000s and even now but and
that typically occurs the name occurs
because it arises in setting when you
have rankings of website phone different
search engines and you want to aggravate
them and pick out the best way now quit
sense that we only have now one search
engine so this problem so long exists
but it's great but this problem is of
course in Tihar even when you have
collections of pairs so what I want to
try to understand is why is it difficult
what what about this problem that is
difficult I mean is it always difficult
this is difficult or pairs only so
here's an example involving three
subsets Sun a set B and set C set a has
products one two three four set B has
product two three four sets the yes part
three and four and for each product in
each set
we have the cost coefficient X s CJ s so
now we want to write out what this rent
aggregation problem looks like for this
example of three cents and by the way I
do want to highlight you that this set
collection of subsets is what we call a
nested collection a contains B and C and
that appears all of the time especially
in revenue management context or an
airline open or closed different fair
profit so you're curious nested
offerings of fare classes so then now
what the brightness right
aggregation problem for this example so
the one I want to make an observation
here if you look at the inner sound in
this optimization I claim that will be
exactly one term in that inner sound is
nonzero because for every ranking Sigma
for every subset s exactly one product J
in that set that is the top ranked item
and that is the table which just
indicate it would be one and you pick up
that CJ s so we can write the writing
aggregation problem as this seemingly
simple optimization problem right I just
need to pick the top ranked item X from
a excellent a the top ranked item Y from
B and a copyright item set from see that
minimizes subjective zxa a see YP plus C
set C subjected to constrain to x y&amp;amp;z a
consistent under some rank the seen
almost like a simple optimization
problem you can just sort of really want
to separate each of em and optimize them
separately you can't do that because of
this constraint you cannot just
arbitrarily pick x y&amp;amp;z for example
here's not example a triplet of X equal
to y equal 3 and said you cool pretty
that a claim is never a feasible
solution can never be because in order
for X to be equal to who is the top
ranked item in a so to must be preferred
to 3 but in order for y equal 3 that
mean 3 is a top ranked item in a set B
so a three must be preferred to two so
our situation 2 is preferred to 3 and 3
is referred to and that can never happen
under any rank because the ranking is
always a linear order you can I'm psycho
sir so yeah this simple example here
illustrate that table choices from
different sets are not independent
just independently choose them and
that's why the problems in this voice
cases NPR when you have collections of
pairs but then what can you do
so turns out that even though o'clock
toys is up not independent conditional
choices can be very independent it can
be very very useful and will so what I
mean by conditional choices state we
examples now let's start with pick
suppose that I set the top choice y DB
TV and I asked this very naive question
I said well given my contours y equal to
what are the choices of X in the set a
that are pairwise consistent with X so
if y equal to is the top choices here
that me to is preferred to three or four
also the only other comprises in the set
a that's pairwise consistent with y
would be either one that you okay and
the same thing here happened that given
y equal to the top choice that that is
pairwise consistent with y as 3 it's
okay I'm done is ask these two simple
questions but the most remarkable thing
that happens for this example pairwise
consistency between x and y y&amp;amp;z implied
global consistency across XYZ and that's
not always true in general
here's any guy and the reason for that
is if you look at all the possible
triplets and that will befall them 1 2 3
2 2 3 1 2 2 2 3 and then 1 2 4 &amp;amp; 2 2 for
each of these full triplet is consistent
with some round so for example I look at
the triplet 2 2 3 that is consistent
with in the ordering that put product -
as the most preferred product okay
follow why product 1 following part 3
and follow product for this of course it
could be mini ranking it's consistent
with this so now this is not to none for
y equal to ax same observation also to
Hawaii go 3 it's also for y equal
always and so what we have observed in
this simple example that we have shown
you is really a remarkable property was
that whenever for every choice X in a y
and B and ZAPPIN see whenever you have
pairwise consider
Cinci between x and y and y&amp;amp;z the
triplet x why's that
also globally consistent and that's true
here and these properties that we found
here's what we call rational separation
whatever we have such a property okay we
say that the set B actually separates a
from C and we write this as a and C
being orthogonal to each other
no in the back it makes sense but in the
decision making sense condition on this
set B so this is sort of what I mean by
conditional independence again it's not
related to conditional independence of
random variable because there's no
randomness you is that choice making and
of course we can extend these notions of
rational separation to not just priest
upset but any three collection of
subsets for a is for being script C so
this is a property of one probably of a
collection of the collection of subsets
so that is a property of collection and
for this collection of nested sets its
we have this rational separations so now
the next questions you want to ask is
okay good that's interesting observation
so what do I do with it how does that
help me solve the right aggregation
problem which is how we could compute
the limit of rationality now in order to
take this abstract concept of rational
separation and solved or limit of
rationality we need a graphical
representation of rational separation
because they can do is a continuous
collection of subsets translate into a
graph which encapsulate is rational
separation property and then whatever we
want to solve just run it on that class
and that graph that has a property is
what we call a choice crime given a
collection of subsets of script M an
undirected graph G is a choice graph of
M if and only if the final condition is
true one the notes of GE correspond to
the subset in the collection and so
that's the second one is that whenever
we have collections of node whenever a
collection of node which is the
collection of subsets D separates
collection a and C in the graph G so
this is a graphical separation meaning
that every path from a node in a journo
didn't you must go through some being
we must also have that be rational
separate a from see now please note that
choice grab is not uniquely defined go
exam or given a collection of subsets I
can just give you a complete drop that's
a choice drop something useful however
alright because a complete crime is
always a choice car because this
condition is never satisfied what are
the engines all the edges are created so
that they are satisfied so let me give
you an example this is the same three
collections that have earlier we know
that being separates a from C so a
choice graph for this context would be
this one it's a line drive well this
line graph satisfied irrational
separation property right because be
separated so this be separate this a
from see in the graph and we also have
the beer actually separated from see no
that's why the complete grab step that's
right yes so now and again you can
always show that whenever you have a
nested collection of subsets the choice
problem a line graph is always a line
graph is the choice bad for that such
okay so that's that's an example of a
choice right now we'll give you a few
more as we get through as we go through
the rest of the talks here so the
question is that how do you use this
what does it do so again here's the
writing aggregation problem that we want
to solve and then we have a line graph I
mean a natural thing to do at this point
is to set up some sort of dynamic
programming
so you set up a value function at each
node in this race car but no one here is
now asset so a value function and asset
define for every element in that set
it's simply sort of the national
objective okay and when you do this we
defined a valid function at the node B
and now what we need to do is to show
that there's a way to link the value
function and note a with the valid
function unknown B let's look at that so
what I do now is to show you that this
can be done easily I'm just gonna copy
everything described and put them up
here okay so now I'm just gonna go
through a few moves like algebra in fact
out the CXA then instead minimizing a
y&amp;amp;z
continiously we minimize them
sequentially and we have this constraint
X Y Z a consistent so they put that here
but then since you're minimizing Alban
said the other constraints and x1 are
consistent and now we just explore
actual separation because now by
rational separation in order for X Y is
that to be consistent
it suffices that X and YS are consistent
and Y and sets a consistent that's
rational separation pairwise consistency
is implying in Global's and systems
among triples it would just replace that
and then we doesn't remove move all the
stuff back again we have that resolved
and that's something more than the bowel
functions that will be now a little bit
of work will show you that for this
minimum for every choice of F this
minimum can be computing the old one
okay so it doesn't require you to search
of all the Y's and B again and what that
means is you can show that when you have
a line choice grab so when if you have a
nested collection of subsets the limit
of rationality can be computed linear
time it's very very fast so that's
that's one thing to say now I think it
works for my choice profit also must
work for three choices crime so when the
treaty choice craft you can have a set
of a when I showed early B 1 B 2 of the
p.m. you defined a battle function that
each node in the tree and here's how it
relates thanks so the value function at
the parent a with the speed at costco
efficient adapt no class now you can
treat each of the child nodes separately
so you take the minimum over to the wise
and sharpener so and again we would run
designer programming from the leaf nodes
of the tree and a leaf node and the
leave node s the value function would
simply be the cost coefficient CSS and
you take that in terminal conditions and
you roll them up using the simple data
program once you get the root node what
you want now one of the problems with
this formulation has stated here is that
for each X in the parent node a here
I might have to research a wall
otherwise again because for each ax the
set of all the Y's and they are
consistent with it could be different so
that could give you that's quadratic
time over so we want a linear time over
so what we don't
I don't have to research this all all
the white about be endless and square so
I just want any so I just want to show
you that this can be done quickly right
suppose that you have computed the value
function all the way up to this note do
you want up to be emesis then we can do
is let's do some pre computation
let's pick a node of BI and I compute
two numbers alpha bi and gamma B I so
our bi is the minimum of the value
functions of all the elements in a set
bi and gamma bi is the same thing but
you exclude those element that's in a in
the parent node now computing this
requires Big O of n little n the number
of poppy search through all but you're
gonna do it only once and once only you
never have to do this again because
whenever it is compute this minimum of
each act is the lookup operation so for
every acts in an element of a it acts
belong to be a doesn't want to be out
you just report alpha bi which you have
pre computed and if that's a lotta VI
you just report the minimum gamma VI and
that's a choice Brown collection a
collection of the necessity so that's
the next time I haven't ready to show
you what are examples of collection of
subsets with tweets that's why here
after I stayed this down it's gonna be
right there so for three choice grab you
have ant Gregory's broke and also we
solve in Linnaean hat okay so it's a
total carnality of every set in the
collection there's a how many parameters
you have in your optimizations to begin
with and let me give you examples of
tweet or collection of nested that's the
collection of stuff said that results in
three choices drop so one is what we
call a laminate left
what's allowing out collection the
collection of stuff says lamina you pick
any two subsets
either disjoint or if they're not
disjoint one must contain the other two
subsets and be either a vasectomy who
empty or ace became and be obese
containment so now the question is when
would lamina
arises in practice so here's one that
might arises when customers search for
product using this illumination by
aspect process so suppose I'm searching
for I say from LAX to Toronto so by
looking at a various different criteria
suppose I want say a morning flight well
these itinerary 1 2 3 &amp;amp; 4 those are
morning flight so what I see on the
screens are 1 2 3 full was the point but
they might say I want to refine them
further I want to say well I want more
in flight with one stop so maybe it's
cheaper so then that craves the
itinerary 3 &amp;amp; 4 and you can reply them
further to get a single return so in
that case the collection of subsets that
do encounter from this process would
look something like this so you'll see
the whole swordman you narrow it down by
different features you get a smaller and
smaller subset and that choice bob is a
tree now another one that we see very
frequently is what we call it
differentiate close so we went to
looking at soup brands carried by
different stores in our chain so what
often happens there's always a core
subset the brand like healthy choice
Progresso Campbell that every store
seems to carry and then key to the store
would off men onto that core collection
with something that is same okay
location specific Detroit I have in
Pacific said it was my attic private
label or even Apple this my home El
Bravo exam ok so that's that's an
example of dog treats car now I also
want to mention one really cool thing
about rejoice car then you'll need to
understand a program if you don't need
to code down it's always better you can
actually solve but the RAM is wrong
using a linear program with very compact
I'm little barrels and constraint okay
so every discrete problem can be always
represented as binary industry
optimization ok so this is the right
navigation problem so choose C is X is
where X is is either one of 0 1 if I is
chosen from F 0 all the way and actually
subject to some constraints that is
consistent with the select all I want to
show you is that let's see what these
constraint
mean when you actually are what high
inequality is an imposed so if you look
at any two sets a and B and a point are
in the middle
if X is chosen consistently ranking if
this point R is chosen from the set a so
it is the top ranked item and a it must
also be chosen in the set a intersection
B because it must also be the top ranked
item a smaller subset so we can provide
this if then statement as the following
inequality X our a is less than equals Z
our of a intersection B so whenever x ra
is clipped to 1 plus NR a it must also
be flipped a lot so that's all and you
can do ask anything to put a set B and
we have this normalization constraint
that exactly 1 item will be chosen from
each set a a and the SEC should be on B
and it turns out that these five
constraints are now you can throw them
into your organization problem and
pretend that there are real numbers
they're not binary and you solve them
it's a linear program it's very compact
number of variables and constraint and
it's always integral you can just pick
up the answers write it and then leave
these linear programs are very small so
just take little seconds ok so that's
that I have two sides and those are the
small Truman's oh yes I see I don't know
that's good it gets you guys I'm Way
ahead but that's exactly the next
question I do the next slides coming up
exactly
the next question is what happened when
you're dealing with arbitrary choice cry
ok so here's an example of a choice grab
that is not a tree almost like a tree
cases cycles in the end so as random
Ronaldo said we what we do is perform a
tree decomposition what's a tree
decomposition so you guys know more
about this than I do so I would go fast
so a tree decomposition is essentially a
merging of nodes so that the resulting
becomes tree so for example we can merge
merge or no except a B and C into one
bath I say green bag we can click the 7b
and B into another back let's say a blue
back and then we could not de up in
another back see a red back and now
there are green blue red bags a now form
a tree like this but that's an a tree
decomposition there are many many tree
decomposition so he's a formal
definition given a choice graph g TG is
a tree decomposition if the following
happens but no
of the tree decomposition is a
collection of bags he still got a green
bag a blue bag and a red bag
so that's true here and what are these
bags so these back must have the
property that when you take the union of
all them you must get the entire
collection back it's not only true here
and for any edge in the original choice
graph okay there must be a back
containing it and that's also true here
and it most important property in the
tree decomposition is the running means
sexual problem which mean that if you
have any two bag which has a set and
column that set must always occur in
every back and the unique path
connecting the two backs so that's the
running intersection properly now one of
the most important measure of
performance measure of a tree
decomposition is the width which is a
maximum size of the back - why now you
can then take the minimum of this width
over all the possible tree decomposition
and that's the treatment of the graphs
is one of the most important actively
researched quantity in graph theory it
works on this problem computing is a way
that unfortunately is np-hard so but
what is important however for us that we
want to know is that 3d Harbhajan
preserves rational separation but that's
so what I mean we can still say here
that this blue bag separates rationally
separate the green bag from them right
back so what that really mean is that
you can death instead if you have a
choice problem that is not a tree you
can do a 3d composition and finding the
optimal tree decomposition that's
unfortunate
so something of a different answer and
many of you here have more experience in
that you can say that the renovation
problem can be solved in a choice in
tree decomposition sort of running
Hamlet's and typically with now of
course we would like to end here but
unfortunately there's one things that
one of the last slides just happened to
be important so what if the choice graph
has a large treatment and the reason why
this come up is that one of the most
important collection that we really need
to solve but he's the one I wanted to
solve start is the one that occurs in
retails and that's we call it a deletion
graph so this is where I'm gonna win had
most K items of stock so again so here's
the setup if every items and on the show
available so
suppose if one item is Takao you have n
minus 1 n minus 2 n minus 3 n minus 4
suppose you have 4 element and of course
the 2 items have stock value n minus 1 2
minus 1 3
dissenter okay the corresponding choice
graph is these things where you have
hedges between notes in consecutive
levels no edges between notes and the
inch in the same level and no edges
jumping for more than one month let's
make sense
unfortunately this particular choice
graph is has the three width of pen and
you can show that am i showing is this k
n plus 1 minor and bedding in here so
why did you start contracting edges in
this note you can make every node here
all connected of each other so that's
like their complete graph of n plus 1 no
so let's create this so that really
doesn't really work so we can't use
whatever we discussed on the previous
slide here but the problem here on this
particular problem is easy because
here's the set up all the collection all
the sets in this collection is wearing
big size n minus 2 or more and minus 2
than minus 1 ok so what this mean here
is that in order to find out what the
top-ranked item in each set is I don't
need to maintain the whole ranking Sigma
all I need to main him is top three
items of each ranking right because my
maintain top three items are beat
ranking 1 of that item we in one of
these that each set is the size n minus
2 so everything that all you really need
to do is to maintain three items but
then maintaining country items of
ranking is way easier than maintaining
every right things less and Q and I
guess so then the next thing you have to
understand we need to do is surprise my
way to abstract that and find out how to
describe that in general and you can do
that we have this notion of called toy
step so we have a pre decomposition of a
graph G we defined his concept of toy
snap to be the spread the maximum
spreading the size of the largest set -
the sizes the smallest set and you
maximize in all the bags and you find a
choice depth of the bottom same way and
again the idea is for this K deletion
graph the choice that was K so for this
particular graph which is
and choice F is exactly - okay and you
can show that you have algorithm that
runs scalars with the choice depth of
the ground key that's an in just a final
touch is that we have two performance
measures three width and twice that and
we know that the running time is
exponential in choice tap and tree with
you can also prove in our paper that the
pair is collection the one that's really
hard is np-hard both the Troy's death
and the tree width is at least n now but
that doesn't complete the answers but it
answers all the questions we and that's
I only have 14 slides so for the
motivation here right is that stuff gets
the the reason they would run our stocks
because very popular right so you could
have like a Richard generative model
right where it says the thing that gets
talked out is going to be them you know
almost surely gonna be the most popular
one right yeah so we don't we that's
correct but it could also be situation
like they could be promotions so problem
yes I see what you're saying that that
it is popular but it popular buy it
because of a promotion and we have a we
have a way to partially answer you
question in there are we know that some
item have promotions how do you account
for those and incorporate it's not as
clean as alright a remote question yes
can you say a little bit more about the
semantics of the edges in this graph in
general because you gave a lot of
examples but it wasn't clear to me
exactly what the semantics is I give you
an arbitrary set of collection of choice
books for example
yeah say that you're hitting all sort of
that good the questions we like they're
afraid he's ass and then he's that hard
question so we have I guess I'm one way
I think like we don't have like so I
think right now like these edges
encapsulate this the rational separation
property that I've defined earlier but I
think maybe one way to answer this
question is like right in for example
how would my given a color arbitrary
collection of subsets how might we go
about and construct such a choice crop
right because I'm thinking of the
analogy with graphical models or exactly
that's again what it was now in the
graphical model constructing a most
parsimonious graphical Torah random
grapple as a Bayes net that's and that's
a very hard hard questions yeah well
except there are natural ways to build a
you know sometimes you rely on causal
intuitions
I can't always construct the most
parsimonious one but I can take an
arbitrary ordering of my variables and I
can construct a Bayes net that way it is
an obvious to me how that would work
here okay so I think like it's only so
we now paper we have a detailed
discussion of like how we might go along
and constructing that now the only thing
I didn't talk about that here is because
it's like I can't really prove anything
clean about them but we certainly have
heuristic something similar to what you
just described take an arbitrary
ordering of the sexes and wind up like
doing checking between different so we
haven't we have a heuristic but doing
that the reason why I didn't talk about
here is I really don't have any clean
beautiful theorem to say that's why but
it's available in the paper yeah sorry
so that in a separate so you're saying
if I give you an arbitrary collection of
sets we have a heuristic heuristic for
constructing our choice man these are a
way of what is our way of measuring like
how accurate choice take what would be a
way of saying that this graph closely
approximates the Oh again we can check
the definition so you can take the
definitive choice you can verify
you can verify it invalid yeah what find
the most efficient one I don't know how
to do that boy example a complete crap
bro you also would you never start
removing edges and if it violates that's
a heart I mean that's one of the things
we are working on right now is but I
mean this is the problems also in
graphical models do you think it simply
is one of the poles that we have right
now we have a heuristic extended that
are appraised but well the input is an
exponentially shot that's unless it's
have an implicit way to express I mean I
agree so what we have done however yeah
like a lot of times when we work in our
data set what you can do is we have this
idea of approximating so for example in
our data set it may not be exactly like
a king deletion but it's close enough
for example and we have that use that
approximation and it turns out performs
really well test it out numerically but
again it's not thing I can say
theoretically so that's why it's a we
mention that in the paper this was about
making a family of collections that make
the problem tractable that is correct
what about the family of rankings that
take the problem tractable or anything
on those yeah we have not no we have not
look at that at all that's a good
question
yeah we have just now looking family of
subsets we have not look at that at all
thank
thank you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>