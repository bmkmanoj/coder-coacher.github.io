<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Leaders in Big Data | Coder Coacher - Coaching Coders</title><meta content="Leaders in Big Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Leaders in Big Data</b></h2><h5 class="post__date">2012-11-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8gMp0YC0_kM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good evening I am really pleased to
welcome you all to leaders in Big Data
hosted by Google and the Fung Institute
of engineering leadership at UC Berkeley
I'm Lee Fleming I'm director of the
Institute and this is a clack Sidhu
chief scientist and and co-founder the
first and most important thing is to
thank Google for for hosting the event
so thank you very very much there's a
couple people in particular Irena
Kauffman and Gail Hernandez thank you
and also our Nava Anand our entrepreneur
residents at the Fung the Fung Institute
and a huge amount of work so the Fung
Institute we were founded about two
years ago and the intent is to do
research and pedagogical development in
topics of engineering leadership we have
our a degree the masters of engineering
professional masters of engineering
image program mainly around the
Institute we also have ties though
across the campus as you as you'll see
shortly this is our intent to have a
series of talks on topics of interest to
engineering leaders as it turns out this
Wednesday we have our next talk it's
sponsored by Thai and the Fung Institute
and the topic is entrepreneurship being
an entrepreneur within your firm and
fittingly we have representatives from
Google and Cisco and sa P so that's
Wednesday consult though the Fung
website or the Thai website for details
on that
so besides enjoying a good discussion
tonight we have an ulterior motive as
you can probably tell we're trying to
advertise all of our fantastic programs
in big data at Cal now whether you're
interested in computation or inference
or application or some combination of
those things we've got the right program
for you as I mentioned the professional
masters of engineering or M ends across
all the different engineering
departments one-year degree we have
another one-year degree in the stats
Department professional degree there's a
two-year degree in the information
school and finally there's the Haas MBA
tonight we've got people from all these
programs you can find their tables ask
them questions and hopefully we'll see
you see you at Cal soon and we also have
an additional executive and other
programs associated each of those each
of those departments and schools as well
a clock now will introduce our speakers
okay thanks so let me see I just lay
this here
so welcome I want to also thank people
one is cost Nikolay who is not here at
the moment but to you in the ether or
where it's I mean he's just not in the
meeting but he's our host here and so
thank you so you guys can tell him did I
thanked him and also I so many of you
I've seen you know here are basically
friends and so thanks for coming
it's good to see you again my role here
is really to give you this is an event
on big data and so I'm going to give you
a little data on who's speaking today
who is here and and the way I think of
this is what we've got is we've got
three perspectives of big data from
leading firms from people who represent
leading firms in the area and so let's
start with NetApp we've got gustav horn
he's a senior consulting engineer 25
years of experience and he's built some
of the largest enterprise class hadoop
systems in the world in the planet and
from Google Theodore Vasa lacus and he's
a principal engineer at Google he's
headed the team that works on data
analytics and he's been responsible for
numerous contributions to Google in
terms about search and the visualization
and representation of the results and
from VMware Charles Phan who's senior VP
of strategic R&amp;amp;D he co-founded rain
Finity and was CTO of the company prior
to its acquisition by into emc in 2005
and our distinguished set of speakers is
moderated by a distinguished moderator
hal varian he is chief economist here at
Google he's
in an emeritus professor at UC Berkeley
and founding dean of the School of
Information so with that there's hardly
anything more I could possibly say come
on up how and take it away so I'm very
impressed with the turnout tonight
seeing as you're missing both the debate
and the baseball game but at least it
eliminates a difficult choice for many
people I will say that I'm going to
follow the same rules as the
presidential debate so no kicking biting
scratching or bean balls are allowed
during this performance we're going to
talk about foreign policy wasn't that
the agreement no all right in any event
what I thought we'd do is we'd have each
person talk for about five minutes lay
out their theme where they're coming
from what their perspective is big data
and I will take some notes and then ask
some questions get a conversation going
and I think well a little time at the
end for some questions from the floor so
take it away
sure so should I start hell yes all
right well hey it's a real pleasure to
be here thank you guys also and I think
she pays for coming well it's a huge
huge audience just a couple of words as
you heard my name is Theo I
I lead some of our analytical systems so
I'm responsible or actually up until two
weeks ago I was responsible for a stack
that had parallel data warehousing
components query engines pieces like
Dremel and Tenzing you know systems that
let you in query this data and kind of
visualization layers on top and you know
that's one of the many many systems at
Google that I think outside one would
kind of think of as big data type of
systems and so I'll try to kind of give
you my perspective at least on kind of
the Google view of big data and
hopefully someone will cut me off on
it's time I think probably we're going
for five minutes because this could take
a while
all right sounds good thank you so I
mean I think as you guys know I Google
Google's business is primarily about you
know taking data in and then organizing
the world's information and making it
universally accessible and useful right
so so a lot of what the company does is
really about sucking in data whether it
be the web whether it be imagery from
you know Street View or satellite
imagery or you know maps information or
you know Android pings or you name it
right and then transforming it into
usable forms so so really Google is kind
of a big data machine in some sense and
Manoah the term big data kind of came
into currency relatively recently and we
all said oh okay yeah that that that
speaks to what we do because we didn't
really have a word for it we just kind
of knew that the data was large but but
just to kind of try to put maybe a
little bit of more structure onto that I
think the Google view on a lot of what
is big data processing kind of splits up
a little bit into probably what I would
call ingestion type of processes so
things like the crawlers right things
like all those Street View cars are
running through all the streets of the
world and then goes into sort of
transaction processing systems where
perhaps we capture data through
interactions on a lot of our web
properties or a lot of the web
properties that we partner with so this
means people you know clicking on search
or people interacting with Docs or
people interacting with maps all
generate many many clicks and and many
many interactions that then become kind
of transactional big data of course that
also includes people using let's say
Google Analytics on on their sites to
measure traffic on their properties
which then generates you know huge
volumes of pings into Google you know
many tens of thousands of you know QPS
of pings so that that's kind of the
second big component and then probably
the third big component is kind of the
processing side of all of that so the
processing side includes things like
MapReduce analysis you know generating
insights from that data may be in the
form of building machine learning models
may be in the form of building for
example zeitgeist top queries that can
then be kind of served out to the world
to say hey here is what people are
searching for maybe in the form of
engrams of all the books that you know
google scanned over you know many many
years of its ingestion processes but but
really kind of baking all of that
information and then you know presenting
it in some usable form either through a
system right such as our ad system that
takes models and and decides what ads to
show or in a more direct form right such
as the engrams so so just a dig so let's
say okay here are those three broad
classes right ingestion transaction
processing and analytical processing to
kind of dig a little bit deeper into
each of those areas I would say the
ingestion processes especially the very
large-scale ingestion processes are you
know highly custom systems right so if
you think about our web crawlers if you
think about Street View cars if you
think about Maps stitching or satellite
imagery stitching those are very custom
processes that I think at least to this
date don't have kind of a clear analog
in kind of the general industry and
maybe this is something that you guys
might address or that or might see
differently than them how I see the
version right so they're they're still
highly specialized systems that you know
produce very large images and they're
you know very high-performance very
complex kind of kind of systems that
that are run like you know dedicated
engineering teams the transaction
processing systems or the storage
systems so these are things like the
Google file system these are things like
BigTable these are things like Megastore
so those are some of the ones that we've
actually published papers about and that
are now you know reasonably well known
in the industry are have evolved a
little bit past kind of the purely
custom stage where they're fairly
general purpose and there was a time at
Google where actually most people you
know did their own storage and
for more another until these GFS like
systems evolved to the point where they
were good enough that more than one team
could use them and actually that
evolution had many steps in which for
example everybody ran their own GFS and
so maybe you know the ads team had their
own GFS cells and the search team maybe
had their own GFS cells and in time the
systems you know mature to the point
where actually we could have a centrally
managed file system and I think recently
you may have seen we've now talked about
kind of this global file system called
spanner which kind of takes that to you
know yet another level of of
transactions and and global availability
so so I think and then the third step
which is I think still in a relatively
immature stage compared to kind of some
of the storage systems is sort of the
analysis and and I think a lot of people
kind of know about MapReduce and some of
the systems that have been built on top
of that so for example flume is a way of
chaining mapreduces in a in a more
programmer friendly way so that you
don't end up with you know maybe 50
MapReduce stages that are kind of
individually managed but rather you end
up with one program that can then be
pushed down into into many mapreduces
that are automatically managed but so
the process there is still very
engineering focused and essentially
requires engineering teams to kind of
process this large data and so I think
what we're seeing kind of in that area
is the same maturation that we saw in
the storage and transaction processing
systems where little by little you know
systems such as Dremel such as Tenzing
such as you know many others inside of
Google that we haven't talked about
externally are kind of aggregating a lot
of that usage and saying hey we really
should do it in a much simpler manner
and and not really require people to you
know have a full engineering team to get
the value out of all of that big data
because at the end of the day that's
that's what Google wants as a whole and
that's what you know Google's customers
want as a whole how do we get the value
out of those big pieces of information
so I would I would just leave you with
kind of those three big pieces and and
also this idea that you know this is
evolving into
a higher-level service that people can
use without necessarily being very very
low level engineering oriented and that
you know more and more value is being
derived out of that and hopefully
something that you're seeing in you know
Google's properties and Google's
services so I don't know how much if I'm
over but I can hand over here thank you
so I'm Gus Horton and thanks again for
everybody for coming tonight I know it's
a big baseball night and probably so I I
mean I come to it from a different
approach in a sense than feel because
Theo as you know Google has really been
at the forefront of big data big data
analytics and in particular Hadoop and
MapReduce so I'm not gonna go on the
premise that everybody in this room
understands what MapReduce is or what
Big Data is and what data scientists are
these are all buzzwords that are really
evolving I think what I found in my
travels globally is that we're really at
the the forefront right now of big data
analytics I have a presentation you know
that really characterizes it more like a
tsunami of data it's it's relentless and
it's coming at us it's coming at us from
our Android phones from our iPhones it's
coming at it from cameras that are
everywhere from our TiVo boxes from our
PVR boxes from everything we do and
touch in our world today we're
generating data and the question is we
have to let that data fall on the floor
and we do nothing with it or are we
gonna pick that data up and actually do
intelligent things with it and we're
finding more and more commercial
applications where you know Google I
look at from a pragmatic perspective
it's a commercial entity but they are
having a much more I think philanthropic
and broad approach to the world as well
it was great back in 2003 that they
define GFS and gave us MapReduce which
brought us back to the mainframe days of
old IBM but this is basically what it
feels like to me right because it's
batch batch oriented processing at that
time when we're talking MapReduce jobs
but basically that was the the genesis
or the beginning of what we call the
Hadoop as we know it the Facebook's the
Yahoo's the LinkedIn all of these
companies that are embracing this
technology but now we look at company
like Progressive Insurance where they're
giving you these dongles to plug into
your car you know they're generating
data they're collecting data on your
habits your driving habits healthcare
industry is looking at you know how
often you see the doctor what are your
your statistics I was at the Mayo Clinic
recently and they have a human genome
product
I'm not product a human genome
initiative where they are looking at all
of their patients and they're actually
doing a full genetic map of all of their
cancer patients and they're following
these people for their entire life
expectancy and they want to keep their
data 25 years postmortem
they want to build a repository where
they can understand exactly how does
that one genetic mutation affect your
your propensity to be getting a disease
because they recognize that diseases
aren't you know just on or off it can't
just be one mutation that gives you that
problem it's your it's your environment
the mutation and that builds a
susceptibility so they're trying to
really paint a huge picture and that's a
big data problem so I see big data
problems from health care I see big data
problems in consumer related industries
whether they be the Walmart's the
targets and and not everybody is trying
to be evil about this right so if you
think about Target or Walmart they would
much rather show you an advertisement
that you care about then to bore you to
tears with something that doesn't matter
just as Google doesn't want you to see a
pop up ad you know for baby diapers if
you're 60 years old and you're not going
to have a baby it's not gonna it doesn't
do them any good it doesn't do you any
good so there are a lot of positive
things to take away from a lot of this
big data and there's some negative
things to I'll focus on the positive in
that you know I look at what companies
like the auto manufacturers in Europe
are doing they're looking at you know
you look at BMW all of these cars are
data generating monsters and nowadays
you don't even know when you have to go
for an oil change because they're
predictively analyzing the fluids in
that car and they're determining when is
a time for you to get that oil change
it's not like oh I have to do it every
four
thousand miles your car tells you when
you need to get it done because of
viscosity changes and because of
analytical testing and they're
collecting all of this data so I think
we're very lucky that you know we're at
this forefront and I think that big data
big data scientists are going to become
more and more important and I think as
osteo said that it's going to get to the
point where you don't have to become a
MapReduce job expert you really need to
become a logical thinker and be able to
you know articulate the questions you're
asking against a data set where you
don't even care where the data came from
you just know that all the data is in
there and that's the key is to have a
repository that's able to hold all the
data and be able to allow for this kind
of processing to take place on that data
and produce results in a timely fashion
and what I've done is I'm approaching it
from more of a corporate perspective
where people are looking at enterprise
class systems versus what we call white
box or dirt-cheap and they're different
kind of cut-offs for companies and I
think as you go through your process and
at UC Berkeley and you're learning about
where you want to go you'll see that you
know you have to pick and choose your
battles when it comes to big data and
the battle you have to choose is am I
going to be setting up my data centers
in my infrastructure to support you know
commodity based platforms and this do I
want to own all the data internally do I
want to virtualize the data in the cloud
at what point do I bring that data and
internally do I want to use services
from Google they're all inflection
points that you are going to be making
decisions over the next five years to
decide how to do that and and this is
what I'm dealing with all the time so I
think hopefully we all learn a lot from
this experience
all right thank you for coming my name
is Charles and unlike presidential
debate I agree with what they just said
the you know Pig Dana is like elephants
so we were told we all want to touch
this elephant from different angles you
know from different perspectives now
first you know but before that I would
just try to repeat what Theo and the Gus
just mentioned now first I think
Internet is pretty big in terms of its
impact to our lives and not only to our
lives but also to enterprise IT and I
think what we are seeing in the last 20
years has been the repeated tidal waves
that's caused by the internet and the
leaders ignorant internet space
including Google the advances they are
making and how those are hitting the
enterprise world and I think big data is
the latest of such a tidal wave
essentially you know what the scale of
data that internet providers are dealing
with with consumers the enterprises are
facing the same and now the challenge is
how do we adopt and massage this
technology so it's consumable by the
various people inside the enterprise
walls and that's kind of what behind the
big data we're all we see and I think
like what Gus said you know enterprises
are working different sectors and there
are people doing retailing selling stuff
if you were doing manufacturing building
cars if people in healthcare the people
doing financial trading and almost every
field are generating more and more data
and almost every field have many
questions they need to ask based on
those data and they need to make
decisions based on those data and unlike
the dw/bi world which has been around
also for 20 years the amount of data the
variety of data and the speed data
coming at you going beyond the existing
infrastructure can take and that's why
you know to answer these different
questions and different verticals
everybody is seeing a need for a new
infrastructure a new database a new
storage to be created to to support the
decision making
based on all these data so what what's
different in those data besides just the
size or the volume of it you know when
people are typically refer to big data
they call it 3b which is a volume
velocity and variety of data some of
them call them 4s it's the sources there
are more data sources the size of speed
and structure of data that are very
different and I have another name for it
which is a probably less elegant but
also I think it's pretty true when we
look at the old data the small data or
the classic data they're typically
corrector based data especially those
generated by transactional applications
they'll usually have people generated
and they go through the whole life cycle
so we typically call them grunt data
that you need to create read update and
delete you know I'm sure all of you
Berkeley students have know the crud
data where you know you manage on a
storage front you also have database
design for it
but with the new de Namur modem of
machine-generated we just have more and
more devices as connected to the
Internet not all of them have a one body
sitting behind that both servers as well
as sensors RFID mobile devices cameras
and so on and there's all generation
Google cars they all change or generate
intense data without people sitting
behind them but if you need to create
them but you don't update them that much
those are usually right once and read
many type of data so there's not much
update and there not much delete you
need to return date at 25 years after
after people die and even after 20 years
25 years people don't remember to delete
them so there's not much delete not much
update there's a lot of replication so
instead of CR UD it's not now that I
create replicate append there are more
and more pen or the data in the pen only
mode and process there's a constant need
to do to to process so in real time
during ingestion or interactive so just
crap data is what what Big Data it's a
craap create replicate a pair name
process and you know when we're talking
about
the structured data versus instructor
then we say there are more and more they
that's unstructured that structure I
think it's just because the database
technology or the underlying technology
is not scalable enough to put them on a
schema or you know some kind of
structure that's why they are they're
whole crap but you still need to process
them in a more efficient way and that
cause a lot of your challenges I think
essentially whoever designed the new
data management system for crap and
makes them consumable by enterprise is
going to be the winner of this Big Data
race yes okay thank you for for starting
as I was provocative comments I wanted
to to follow up on your on your little
troika there with the ingestion
transaction and the analytical I come at
the end of that food chain so what we
get is the data it's been pulled in that
it is available to us and we're working
on the analytical side I want to ask a
you know say a few words about that when
we have these analytical systems at
Google one of the things you do is just
monitor the system and make sure
everything's running the way they
expected to and and these guys have done
a fantastic job because now you can take
almost any thing that's gathering data
at Google and create a dashboard with
about 20 minutes of work which is a
fantastic thing for for running the
business the other thing is you can
build the machine learning models he
alluded to and engage in this kind of
predictive analytics that's very in
vogue these days and it's a it's a great
thing to do but the thing that a lot of
people miss I think is you can use that
data to conduct experiments and that's
really the secret sauce at Google our
search a leader of the search team Amit
Singhal said that a couple years ago we
did over 5,000 experiments with the
search algorithm made 400 changes on the
ad side
we're running roughly 500 experiments at
any one time anytime you're in goo
logged into Google or anytime you're
accessing Google I should say you're
probably in a does
more experiments and it's having the
capability to manage that data not just
for the current incarnation of the
system but all the variations you might
contemplate is really a fantastic help
in moving the whole the whole system
forward so that experimentation role is
very very important
at at Google I wanted to raise a
question of standards and
interoperability
now you mentioned Hadoop that's really
become an industry standard here at
Google we have our own internal staff
it's a lot easier to enforce these
standards for interoperability
internally than industry-wide but to
make this system work of starting with
ingestion and then the transit
transactions and then the analysis
outside of Google or outside of other
big data companies you've got to have
this kind of standards to interconnect
the flow of data and Charles why don't
you say a few things about what's what's
going on in that area I I do think we
are at the early stage of this industry
and right now there's no standards per
se to my knowledge that has emerged
Hadoop has been a very popular
technology that's borne out of the open
sources community's effort to based on
the Google papers to create the
MapReduce and the GFS as well as the
other things they build on top of it and
I think in lieu of standards my
perspective is open source clay plays a
huge role here that in that in terms of
overall data management as I mentioned
we are going from a world that
everything in relational you basically
have your relational data model which is
the standards across all sequel being
the standard query language going to a
more chaotic world where there's many
kinds of data stores many kinds of
queries even alkyd OOP there are various
ways you can query on top of it and open
source really give people the choice and
this in this period of in this chaotic
period it is the choice
it's basic the developers then the users
who's going to decide which will become
the standard and open source really
provide this way to make it happen yes
all I just want to make one comment I
think open source actually is the best
way to to make sure that you don't get
yourself pigeon holed into anything
that's proprietary and I think that with
a dupe and Big Data as we look as I look
five or ten years down the road I think
that standards aren't going to provide
structure it'll be more of an inhibitor
then it's going to be of a benefit in
this in this area I think one of the key
attributes and and I think you can
probably you can maybe talk more about
that is the fact that you know you want
to be able to connect or stitch together
a bunch of disparate data sets you want
to be able to look at things where you
don't have to be rigidly defined from a
standards you want to be able to look at
you know you know strange queries where
you know you know weather patterns and
people's buying habits and the cars they
drive have some correlation and if you
start imposing standards on top of
something that is that robust I think
it's gonna probably stifle development
so I think the key here is open source
the key is to have published innovations
so that people are publishing their
works and I think as we get better and
better at natural language processing
and being able to get away from having
to be hard core programmers to get glean
insight into any of this data store it's
gonna be more beneficial I think in the
next decade you'll find that you'll
you'll probably be doing less and less
Java programming and and more and more
just you know natural language logic I
would think they are I hope you're gonna
say a word or two about protocol buffers
a protocol buffers yes of course I'll
plug protocol buffers for sure which
would you made as an open standard right
right there's actually an open source
system but before that I was actually
gonna say I I really agree with with
your point about experimentation and I
actually remember a time at Google where
you know if you wanted to run an
experiment for example on search there
was one engineer who's one of our
distinguished engineers now Diane and
you had to go ask her for some cookies
on which you could run your experiment
sort of like she would a lot you some
cookies and you know those days are over
but but they really do generate a lot of
this you know crap data all those
experiments accumulate over the years
you know and and and yet it's really
important to have kind of the the
historical view of hey we tried this
here's what happened then and I think
actually this plugs directly into this
problem of standards because the way
that all of the engineers you know years
back recorded their results was very
very different than you know the ways
that engineers today record their
results so maybe at the time some of
them didn't have protocol buffers which
is if you if you like a kind of XML like
format for representing data that Google
created but is sort of a much more
efficient to represent type of type of
format and so it I think the problem
comes because we want to integrate all
of this variety of data and I mean what
I would say is I I agree with I agree
with Gus that I don't see a lot of
appetite for kind of very generic
standards but I do see people having a
need to bridge all of their old data and
the new data and I would I would
basically make two analogs here is that
I think one of the things that really
helped the development of data
warehousing was fairly standard sequel
and it was never standard standard like
there existed a standard but no one
really followed the standard very
closely but if it was sort of close
enough you could get your systems to
work and I think the other aspect is
file formats you know if you can you
know take a file format and feed it into
different systems I think that will that
will really help and so until now CSV
was kind of the end-all be-all file
format for interchange I think I think
we'll see more of these as we kind of
need to trade data that's more
structured right that has protocol
buffers or XML and if I could let me add
that plug for VMware as well is that as
we mentioned I think we are agreeing
that we should allow the chaos to
continue for a little while however
there are certain parts I think we can
help people to make it easier which is
how do you stand things up now Hadoop
has great system but as Gus can probably
tell you it's not so easy
for enterprises to stand up a Hadoop
cluster and it's often the enterprise
can need to stand up many of those to do
cluster and some some of the needs to
stand up other type of data stores and
that's where you know VMware is a leader
in the virtualization software and cloud
infrastructure and we are building tools
which include some open source project
or Serengeti which is helping people to
easily stand up there subdue clusters as
well as other data stores really
automate some of those headaches or
tough tough work and so that you can
focus on the work that matters let me
put in a good word about standards
because when you look at companies how
do they grow they grow through
acquisition when they grow through
acquisition you end up with data silos
everywhere and data silos are the enemy
of big data right and the amazing thing
about Google because of the work that
Theo and his team do is we have no data
silos at Google now that's not a hundred
percent true of course but but when we
bring in acquisition and we spend a lot
of time trying to get their data
infrastructure aligned with our own
internal in the structure or what it
means is you can basically pick an
engineer off of one project and moved
into on another project completely at
the other side of the company and
they're productive in the first week
because of having that standardized
infrastructure that we have and that is
not something that most companies have
the luxury of dealing with the biggest
problem that most companies face and
data management is trying to get this
interoperation among the different
legacy systems you know there's this old
line how did God create the world in
only six days and the answer is he
didn't have a legacy system to worry
about mmm-hmm so everybody in the
business phases how's that going to be
solved that's my question how do you
solve that well I think I think you're
right there are a lot of heterogeneous
databases and a lot of things that need
to be stitched together and I think that
big data again from the Hadoop
perspective there are lots of connectors
out there from flume from scoop and I
think that's key is that you know you'll
find that a lot of these big database
companies are they're having to embrace
open source they're having to embrace a
dupe because if they don't embrace it
are gonna become roadkill right so
they're looking for ways to monetize it
from consulting services and things like
that and also how then how can they play
in this market and become leaders in
this market so they retain their
customer base because the bottom line is
the Oracles of the world's si P's these
people make money through selling
licenses Hadoop is a licensed killer
right so that's gonna in that's gonna
directly impact their ability to be
profitable from a stock market
perspective so they need to find ways to
innovate that allow them to keep that
trajectory and then the other thing I
would say is that a lot of times you
know the biggest problem I found in
industry when I go meeting with big big
customers or potential big customers is
that they don't know where to start they
have a huge data problem not just a big
data problem they have data everywhere
in silos in different corners of their
organization and they don't have one
overwhelming one one person who is
confident enough from a technical
perspective to know how to move forward
they have individual islands or teams
that are looking at how they can move
forward and the real strength in in big
data and big data analytics is to hed
origin heterogeneous nature of the data
that's one of the key strengths of this
entire industry is the fact that you
want to stitch together all of these
different data sources and then be able
to find those correlations amongst them
it doesn't do anybody any good to do a
structured database in Hadoop and you're
just doing the same old thing what's the
benefit there is no benefit the benefit
is when you're able to combine all of
these sources into one place and you
find that needle in the haystack or
you're able to better understand your
customer because fundamentally all of
these things are customer driven I don't
care whether it's Google I don't care
whether it's VMware if the customer
isn't happy they're not gonna come back
they're not gonna like your your website
they're not gonna like your product so
the bottom line is how can you find ways
to modify what you're doing to make it
better for the customer and if you're
able to find those needles because you
can stitch together all of these
different sources including social media
including global search engines and
global communities and find out what
people are doing you'll find out those
subtle differences that really become
the real game-changer and that's really
what big data is about yeah and I think
another way out ISEC the big data is
that it can be looked at as four layers
of functionalities from the very top is
the big data applications and to the
second layer which is a big data
analytics the various machine learning
and other algorithm you can apply the
third layer is the big data management
the query engines and so on that you can
query the data and the bottom layer is
the data infrastructure the storages are
where you store the data I think to the
question the more bottom the layer I
think it's closer to standardization I
think there is a you know maybe two
Theo's comment there probably can be a
unified big data store where all the
bits or the crap eventually end up
somewhere there's a sink come and sink
for all the crap and as they coming to
here they're I think right now that we
should still allow various different
ways for them to be queried even though
hadoop system there are people some
people like to use pick some people like
to use hi some people like to just do
HBase directly HDFS some people like to
you know Tremmel is another way you can
interact with it and I'm sure the new
innovations coming out of Google out of
everywhere in the ecosystem and it's
liking a period when I talk about
standardization and the chaos sometimes
they'll go back to history for me it's
Chinese history where you know for those
of you who have read the Chinese boat
called the romance of Three Kingdoms
where the first line of that novel is
after unification it's chaos after chaos
if you need unification
and it's describing how often and of the
Warlord's fighting chaos inevitably
somebody strong
emerge and unified the land and that
will be your Empress and also inevitably
whether it's after he gets old or
whether he dies and kids gets weak that
will fall back into chaos and this thing
this is a traditional dynasties that
repeat about a dozen times that's 4000
years of Chinese history and I think
that can fly to the history of anywhere
else as well I can apply to the data
processing and data management here
where we are in this period going from a
more unified Seco interface a more
unified data management query engines to
a more diversified world but I would
predict in 10 years there will be a
leading standards or ad-hoc standard you
know de facto standards S can emerge
where the majority of the big data
problem gonna be solved in that way ya
know I I agree with that I mean I think
I don't know if it'll be in the form of
a w3c standard or some something like
that but I think that's a little bit the
dynamic that hal was was referring to
inside of google that after n years of
fighting with all of the different
varieties of things right people kind of
said well we understand now that it's
not the purpose of our team here over in
maps to really build that entire stack
because now that we know what all that
entire stack entails we realize that
it's really far too big for us to do on
our own and so we're willing to kind of
concentrate further up the stack in the
parts that we really care about and and
that then led people to kind of lots of
groups at Google to kind of look around
and say okay well what is a piece of
technology that exists and is reasonably
mature and a lot of people use it and it
gives us this advantage and so that's
how some of the components right such as
Dremel and others sort of emerged as de
facto standards of how we analyze data
and I think that you know those de facto
standards will end in time you know
probably lead into some kind of more
formal standards that can be adopted
across companies and across
organizations let me switch gears and
and turn to the infrastructure the
hardware infrastructure so there's two
models out there you can buy your
infrastructure and people to maintain a
run it in-house or you can lease it on
the cloud and what are the what do you
see is the advantages and disadvantages
of those those two approaches well III
think that there's a there's a place for
both to be honest with you I think that
you'll find that the cloud is a great
place as it gets started it's a great
place for you to kick the tires I think
that you're always gonna have the open
source what I call white box commodity
based approach and a lot of groups where
you're going to be doing your sandbox
your proof of concept you're gonna be
testing out your code from an
infrastructure perspective and also I
think that there's a place even for what
what's being done over at VMware where
you know they're looking at
fundamentally providing an
infrastructure and product kind of in a
box so that people can go to service
providers and spin up map reducers and
build their file systems you know at
some point in time there's gonna be
again like I said a decision where
companies either going to embrace the
technology because that internal
leadership or their leader within the
company has has proven the value of this
and that's gonna be the tough slog that
everybody in this room is gonna have to
deal with over the next five years is
that you're gonna be battling internal
processes internal fights within every
organization that I've met where you
have the legacy data base people the
people who said this is how we do it
this is why we do it we have these
checks and balances we have these
constraints that data has to stay within
our walls and then you're gonna have the
leaders who are more aware of what's
available in technology with
virtualization with cloud-based
technology and in some cases it does
make sense they're there they're you
know regulations and laws that are gonna
dictate where data resides or where it
can reside or where it has to be and and
they're gonna be places where the cloud
is gonna be paramount and and but you're
gonna find in the next five years that
you're gonna be fighting more political
battles than doing anything else no no I
I agree with that I think I think there
will certainly be lots of ways to run
infrastructure locally as well
on the cloud I I think though that what
people will realize over time is that a
lot of the reason why it may sometimes
appear cheaper to run locally than it is
to run on the cloud these days is
because with the cloud services you get
a lot of a lot of services by default so
perhaps you would get backup by default
perhaps you would get certain compliance
you know functionality by default
whereas sort of on a reasonably bare
machine in perhaps your own data center
you wouldn't you know get these
automatically and I think over time as
as more of this computation becomes kind
of a commodity and that you just expect
it to work and and that's it you won't
be able to live without some of those
things that are today considered
value-added services and I think there
will be a crossover point where it'll
it'll start to be more expensive to
actually do all of these things on your
own on an appliance then it will be to
do it at scale in somebody's data center
and I think the the fatter and fatter
pipes that connect us to these data
centers are going to make that a
possibility so yeah sorry go ahead yeah
again in the antia present presidential
debate style I agree with both Theo and
Gus and the VMware is a view is a hybrid
cloud where that you know we want to
provide the same benefit to customers
whether they are running things in their
data centers or out of a cloud service
provider all that being said I do think
there will be an increasing amount of
infrastructure moving out of data center
over time to the cloud services meaning
the applications will be more and more
delivered as a service to the enterprise
customers as opposed to as a packaged
software today that will take time but I
think that will happen but even after
that happens even after the
infrastructure is outsourced so-called
through the cloud service providers the
ownership of the data of the big data
medium leader small data still is with
the enterprises and it's still their
responsibility to be able to make their
decisions based on the data they all
even some of the data may be
sitting at the staff provider as a cloud
provider it is still their
responsibility to analyze those data and
to make decisions based on those and
clearly security is going to be one of
those big items and so if anyone's
working on cryptography that's gonna
continue to be a pretty hot thing it's
always good to have a job where there's
an adversary you know coming back to the
elections again we say model so let's
come down to the query language we've
had we've seen sequel mentioned a few
times what about no SQL or tell me that
what's the role of that in in today's
world is sequel going to be obsolete or
are we go out we're going to continue to
rely on that as our query basis okay
I'll start I'm sure Gus and Neil have
more to add I think no SQL is so the
part of this common chaotic phenomenon
that we are seeing is driven by a few
factors you know still by far Sequoia
still the most popular query language
today but no SQL is one other the need
for people for looking for more flexible
schema as they're developing
applications sometimes they have the
data stay the same but they want to
structure them differently and they want
to do that in a more easier way and they
want to relax some of the consistency
requirement of their databases so they
can deal with scale you know much easier
and much better way and it's basically
driven through various different needs
so there are different flavors of new
query model that emerged and I think
there's no better name so the easiest
one is you call them what they are not
which is no SQL the I do see that there
is a strong trend in terms of developers
embracing them but again there is no
clear new winners in the query languages
and I think in different companies there
may be different
preferences being set up it doesn't mean
five ten years from now there won't be
one so so I I think right now it is in
the model that developers decide that
the developers of the world decide
whether there is a newer acquiring
language that can replace the poet 7uu I
would only say that its sequel is gonna
be around for a long time to come
I still run into companies that are
running COBOL of all things so I it's
it's not going anywhere anytime soon I
think what what no sequel is versus
sequel versus any of these other things
is yet another in yet yet another way of
exposing all these internal politics and
battles that happen in big industry and
that you know you're gonna have legacy
databases that that's the only way you
can talk to that and you're gonna have
next-generation things coming out and if
it wins the battle which I think it will
you'll find no sequel becoming more and
more popular and you'll find more and
more of these aggregate heterogeneous
kind of data stores becoming more
popular provided they provide the
answers that they're supposed to which
is means they have to be faster they
have to be infinite in volume and size
and they can grow and they have to never
forget anything you know that's that's
kind of the key you know these things
when we talk Big Data and it's always I
always get a laugh out of it sometimes
because they say well we only need a 200
node system I said well that's today
what are you gonna do in five years how
are you going to grow that I mean the
most important thing in Big Data it's
not the computational engines right
that's that's the most volatile thing in
your big data system you want to get rid
of that old crap anyway every two years
you don't want to have to then ream
Ã¬great all your data right the most
important thing in okay so this is a
little plug for for me from that app is
that the data is what's important the
thing that it runs on is the most
volatile or least important thing it's
the thing that you want to be able to
flush out and Rev and make faster over
and over again provided that data stays
and you don't have to move it because
moving stuff is a waste and I think
that's what in Google you don't want to
be moving data either that's wasted
energy
absolutely I mean and I agree with that
point that the systems change many many
systems have changed over the years at
Google we've migrated forward and and
the older stored systems have died but
but the data is always there you know I
think I'm pretty sure that Jim Gray who
was a Turing Award winner
I had to felt like he needed to
apologize for sequel and his in his
Turing award acceptance speech she's
sorry for sequel and you know as a
builder of sequel systems I think I
think sequel will stay it's great but
actually the only thing I would point
out about it is I think it's main and
most positive attribute is that it's a
declarative language meaning it doesn't
say how to compute what you want to
compute but it just says what you want
as the answer and I think that that's
the key characteristic that whatever the
language is be it seek will be at
something else will be important because
the bigger the computation is the more
complex the program is that you would
have to write if you were writing a real
kind of procedural program and so you're
gonna need systems to actually turn that
into computation for you so so whatever
the languages may be its sequel maybe
it's a variant maybe it's something else
if it's declarative then it gives the
maximum ability to the execution system
to actually do the right thing fast so
so we do have a few minutes for
questions from the audience we have a
hard stop at 7:00 because of a plane
leaving but questions back there speak
loudly please
sure privacy and what are we gonna do so
the question is what are we gonna do
about data privacy how we're gonna make
these systems protect people's data I
mean I you know I can give you one one
view from Google which is obviously
privacy is one of the critical critical
things that that we do here in the sense
that if if people don't trust Google
none of it works and so I mean I think I
would go back to this point about
declarative languages I think in the
early stages of the development of
analytical systems you know you wrote
things down to the metal and because you
had to write there was no other way to
do it and and that gave no safeguards
for what people did with the data they
you have to kind of give them a code of
conduct and say hey you should only
apply it like this but actually when you
go up the stack and up the abstraction
level and you say look tell me what you
want to compute and and the system will
actually compute it for you then you
have a lot of opportunity to actually
apply policy privacy policy in
particular in an automatic manner so I
think that ultimately that's kind of the
long-term answer is that there will be
mediation between the people asking the
questions and the systems that are
executing the queries that but then
apply the right policies there and I
think this question mostly applied to
the service provider the cloud analytics
big data analytics the service provider
and the VMO recently bought a company
cost ETA's and we're looking at the same
problem these customers are various
online gaming companies uploading their
data into our services and there are
various technology encryption and so on
to protect the privacy but I think more
important than technology is really the
business model it's like you're
operating an information pack similar to
a bank for money so you you can argue
that why would you give your money to
another service provider rather than
keep it in your old home but the thing
is like you know as Google as status if
you breach that that you cannot continue
exist as a business so it's in every
interest of the operating company of the
service to
the privacy of their customers so that
they can continue exist as a bank as a
service provider just like Bank due to
their money so arguably in most
countries in the world putting money in
the bank is safer we have the cheaper
come here but then putting your money
under your mattress as similar can be
argued that it's arguably better
protection of the privacy of data if you
being trusted to a service provider in
most cases so in short trust no one and
I actually mean that I mean you
shouldn't really trust the banks almost
and you shouldn't trust you shouldn't
trust service providers to any great
extent it has to be earned
right and this is always proven time and
time again I think Google has done a
very good job for better or worse people
have argued about how privacy statements
can be morphed and changed think nothing
stays consistent nothing will stay the
same it will always change so the minute
you let any of your private information
out there even if you believe it to be
private and only amongst a small circle
of people I would never make that
assumption if you want to keep something
private you keep it to yourself that's
the only way yes
well I mean I'm actually one thing I
mean you can have you can have privacy
in the data you can have control of your
data for example you can encrypt the
data on the drives so you can encrypt
the data throughout the pass but if you
hand the key to that data out to anyone
then you've already then you basically
unlock the door so I think compliance
privacy protection of data it's it's
it's a that's a very tough problem well
I think Theo's point was really an extra
one that you can build a lot of this
compliance into the system so you just
can't link this with that unless you
have some specific override from
higher-up and one of the advantage of
having those declarative languages is
exactly that that the system can enforce
compliance in ways that internal you
know humans can't right right I mean I
think I would I would sort of see
privacy as a special case of compliance
right you want the data in your
organization in your cloud to be managed
according to a set of rules now those
rules will sometimes be about you know
protecting individuals but sometimes
they'll be about financial regulations
and whether you know revenues can be
viewed by certain people or modified by
certain people or whatever it is and so
yeah well you know exactly right so I'm
actually responsible or was up until
recently for a lot of our billing or a
related computation and and those are a
lot of the questions is who gets to you
know be able to touch any of that data
along that path and I mean I think I
agree with you trust no one but I would
apply that more to people systems right
I hope that we can get the systems where
the systems are you know proven over
time to have the right behaviors right
and to the four layers I do think
compliance cuts across the entire stack
entire environment from my experience I
had more experience with the bottom two
layers compliance certainly pick with
both of those layers but I can't imagine
they're probably things on the
application layer that you
you need to pay attention to as well
okay well on that note let us thank the
group and thanks for coming
thanks to all you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>