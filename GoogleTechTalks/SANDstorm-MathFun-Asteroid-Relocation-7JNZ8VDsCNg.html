<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>SANDstorm, Math-Fun, &amp; Asteroid Relocation | Coder Coacher - Coaching Coders</title><meta content="SANDstorm, Math-Fun, &amp; Asteroid Relocation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>SANDstorm, Math-Fun, &amp; Asteroid Relocation</b></h2><h5 class="post__date">2009-08-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7JNZ8VDsCNg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everybody my name is Jason Holt
and I'm very pleased to be able to
introduce you to rich repeal he's he and
his wife Hillary are longtime friends of
mine from when I was back in grad school
they actually introduced me to the
people at Google that helped me I'd get
my job here rich riches experience in
computers go way way back look up hack
mem some time on Wikipedia and if you
want to see some of his early work but
he's here to talk to us today about
their entry for the Shah 3 competition
called sandstorm and also some
recreational mathematics and an
interesting space proposal so here's
Richard bell hi I'm rich repel i'm
presently working for sandia labs in
albuquerque and the first part of the
talk is about the sandstorm hash
function i found out this morning that
this is now a theory talk because the
the list of excessive cut down
candidates has just come out and we were
not lucky but i'll present the hash
function anyway a bunch of people helped
with this
this is what a hash function is the
basic notion is digital fingerprint you
put in your digital object of whatever
size and you get out some fixed size
called the hash value and you want that
to be unique and it can't really be
unique because the input space is bigger
than the output space so you fall back
and you say well I want it to be
extremely hard to come up with two
objects that have the same fingerprint I
don't want it to happen by accident I
don't want somebody to be able to cook
it up so we're in the case of having
engineering uniqueness okay there's some
specific ancient requirements one of
them is collision resistance which is to
say a bad guy should not be able to come
up with two things that come to the same
hash value moreover he should not be
able to if you give him something he
shouldn't be able to come up with a
forgery with the same hash value and
finally if you just give him the hash
value you shouldn't be able to come up
with anything that has the hash value
and I emphasize those are for people of
finite computational means because
mathematically you can always solve
these problems if you have a suitably
big computer the hash function that
people used for a long time is called
md5 and they actually still use it a
whole lot which is maybe not such a good
idea anymore collision through md5 have
been known for about five years what did
we get there
Burke
alright um boy I love windows I should
be talking here okay collision through
md5 had been known for a few years
theoretical collisions for sha-1 have
been known we're actually expecting a
sha-1 collision to appear real soon now
because people keep improving the
attacks and they're down to the point
where somebody with a whole lot of
computer resources could actually do it
a couple years ago and this came out one
shot to sort of an anticipation of
problems like this and shot to do is
actually for hash functions with four
different output lengths of lengths to
24 through up to 512 bits so the
fingerprints keep getting bigger they're
all based on the same design they're all
derived from actually md4 originally and
they keep beating it up and md5 with an
improved version of mt for sha-1 sort of
took some steroids and then they added
some growth hormone and got to shot to
the feeling was that maybe it'd be a
good idea to have something that was not
a derivative of the same design so they
started the contest there were
originally 64 submissions by last
Halloween 51 made the first cut which
was that the code compiles and the spec
was sort of readable about a third of
the originals have no significant
problems or I guess I should say not
even a thrown at them some of them have
actually been successfully attacked they
don't meet one of the criteria others
it's just people are saying yeah you
know whatever but you know 22 who have
come through a completely clean so far
and in late August which apparently is
right now NIST is cutting to 15
candidates they apparently just
announced they're they're caught list
last night
people have been very imaginative in
names this is the Shah 3 zoo website
that the Europeans are running red means
that there's an actual attack that
produced some violation of the
conditions usually a collision oranges
there's reason to believe that a
collision can be computed in less work
than should be yellow is there some sort
of pre image in theory although that
doesn't mean they've actually come up
with one and green means that some
reduced version of the hash function has
been attacked that doesn't necessarily
threaten the big one at all sure I'm
sorry I'm looking forward Kevin is
asking why we didn't order by speed and
the answer is this is basically taken
directly off the zoo website which is
alphabetical the other thing about speed
though is of course on what machine okay
sandstorm is slightly unusual in a
couple of respects one of them is that
we designed for parallelism from the
beginning so our parallel sandstorm is
the same as the serial sandstorm and I
believe that's different from all the
other hash functions on the other half
functions if you want to benefit from
parallel ISM you have to tweak something
and the hash values are going to be
different in our taste they'll all be
the same um we've done that with what's
called a truncated tree we'll see if
they true that later we have a very
simple padding scheme we took a one bit
on the end of whatever the message is we
have a finishing step which is necessary
to prevent something called the length
extension attack
that everything through sha-1 has been
susceptible to these are some of the
ways we differ from the mean standard
act function submission our state
variable our internal state is four
times the size of the output that's
called white pipe we have a serious
commitment to parallelism there are
about 20 different places you can choose
to put your parallel ISM all the way
down from the gate level up to high
level control on the message so whatever
is easy for you you can do and if you
can do all of them that's wonderful
you'll get 10,000 x or something if you
can do one or two of them you can get up
to a thousand x one of the other
decisions we made is that if you have a
super-sized message like you're hatching
a movie for some reason and you want to
do it because you're selling
personalized copies you want
personalized hatches you want to put a
wrapper around that movie something at
the front maybe in the middle of
something at the end we can redo the
hash without redoing most of the work we
just redo the change parts and where
they they meet up next to the movie this
is our tree mode the idea in a tree mode
is that various parts of the message get
hashed and they forward something to the
next level of the tree and then you hash
that and so on then straight tree mode
as a couple of problems one of them is
that if you have a collision somewhere
that allows you to patch you can usually
fit it into any leaf in the tree which
gives an attacker and flexibility you
prefer not to our overall philosophy has
tried to be defense in depth so we know
that even that part a is preventing a
problem we'd still like to have Part B
also prevent the problem where we can so
our tree mode is different in a couple
of ways we have a first block and that
block influences every other Block in
the message
so that first block cash has to be known
the value from that has to be known by
every other computer that's cooperating
to hash this message you either give it
another copy of block one or forward the
hash value see if my mouse works here
doesn't seem too we have a pointer no
okay all right well I'll wave my hands
okay level zero is that first block in
level one subsequent blocks of the
message are grouped together in ten
block chunks and those are hatched as
you would hatch an ordinary hash and
block after block after block then the
results of that hatch are forwarded to
level two and they're they're grouped in
units of a hundred blocks same deal
those get forwarded to level three which
is unbounded something has to be
unbounded in order to process super long
messages we've made it level three and
then finally level four takes the level
three result and does a finishing step
on it and again that prevents various
kinds of attacks now we haven't shown it
here but the block numbers get involved
in a lot of places so that the an
opponent can't play it play swap a block
on you the other thing is if a level
isn't needed it drops out so in the very
simple case of hashing a message up to
one full block long you will only use
level 0 and the finishing step so you'll
just run compressed twice and then as
you get up another 10 blocks coming in
you use level 1 and then after that
you'll use level to a little bit you
won't actually use level 3 unless you
have a thousand block message
okay this is oh one thing is we have
about a ten percent overhead for the
tree so it's you know not a big deal but
it is the present one of the advantages
of having the levels drop out is that if
you're only asking small messages like a
smart card or something you don't need a
lot of memory to remember those
intermediate levels so that's less
temporary memory to use an ordinary tree
mode just passes passes hash values up
to the next level that's not really as
big as you'd like we pass double sized
hash values to the next level so we pass
more of the internal State up again
that's a safety thing this is the
internal compression function the m1's
represent data derived from the first
block of the message the m2's are from
the next block of the message we run the
the message schedule produces different
m1 m2 s and so on this is what happens
to the internal state to the compressed
it starts out with this initial C 0
value which comes from various places
depending on your level and it gets
passed through five rounds the result of
each round is forwarded back to the
previous round in the next block so that
eventually the result of Round four if
you move ahead four blocks will be
influencing the input into round one and
that happens to be a very nice way if
you're doing hardware pipelining to
arrange things if you have a whole lot
of gates available you can get them all
working so you'd actually have five
blocks being processed at the same time
we've reused the constant tables from
shot to the importance of the constant
tables is they prevent something called
a slide attack where you pretend that
round three in one case is doing around
four
is in another case to do that you have
some constants you bring in their
supposed to be random numbers on its use
to cube roots of primes and low order
bits of course um anyway we reuse those
same constants because we figured it's
actually quite likely that shot who is
going to be in the same software package
as whatever the backup hash turns out to
be this is one step in the round
function so you can see the details on
how the data gets forwarded to the next
the next block process and so on our
individual mixing makes good use of the
multiply instruction which is an
excellent mixer we use the aes box a
little bit and we mix up arithmetic and
logical bit operations because you don't
want to just have all of one or all of
the other news desk we're a tunable
security parameter so that you could do
things like run more rounds so we have
that our overall position is you want
the least possible amount of flexibility
in your final standard you know you're
not producing a multi-tool Swiss Army
knife for people to use you're producing
something where people can say i'm using
sha-3 and the other guy knows just from
that what you're doing now they've
already said we can't really do that
you've got to have four sizes and they
also want this tunable security
parameter so that the next time around
if there's a break they can just say
everybody set your tunable security
parameter to ten now pet milk will move
on these are the arithmetic details
there's not a lot to mention here except
these small sized hashes use 32 by 32
multiply inside and the big size hashes
use 64 x 64 we want the entire result
which means it's a little hard to work
in C unfortunately
because C won't give you the whole
result of a multiply without a bunch of
special hacking and that does mean that
our portable version which is an NC
standard C runs slow we have fast
versions which have different amounts of
assembly language put in to cope with
the multiply problem this is an
unfortunate slide it really should be as
simple when there are four words of
internal state and the last thing the
round function does as part of the
mixing is that the bits are moved
between the four words in various ways
and this is the logic function that does
that this is more of our round function
we have four words of internal state for
64-bit words for the small hash and each
of those words is recomputed based on
the other three words and we do that on
each of the four words the result of
that is that after you get down to after
the bit mix everything depends on the
every bit of the input so you've got
what we call a full mix this is the
message schedule the message will come
in for the small hash as a words of 64
bits and what we do is we have a
function that computes a ninth word from
the previous age and this is a schematic
of that and we run that I think 25 times
and the first eight words are aged XOR
together and that becomes the first m1
value used in round 0 and then after
that all the other values are made by
picking words blocks of words out of the
message schedule but we have some gaps
in there so even if you know what went
into one block of four words you don't
know the next block automatically
this is a little bit about the the NIST
standard machine and you can see why
they picked that and at the same time
the this machine is it's derived from
the 886 basically and it's a mess it's
got 64-bit words in most places except
sometimes it's 128-bit words there are
different sets of registers they have
different applicable instructions to
them and so on and so on the c compiler
of course hides all this but if you're
going to do a fast assembly version you
need to know it and in fact we were able
to take advantage of this because one of
our parallel ism things is the way the
arithmetic is organized so we're able to
use most of well yeah a lot of the
special features of the 64-bit 8086
descendant these through our most recent
performance results our assembly
language version on a single core of
this machine is getting 15 clocks per
byte if we do it on dual core which then
this standard machine has to course and
we run it and see then we get 10 clocks
provide the 500 and development output
version is a little more than twice as
slow in some respects we've checked out
the parallelism most of the submissions
haven't talked about parallelism much
md6 actually is run on several different
machines though on a dual quad-core
machine which has eight processors we
get 2.1 clocks provide and on a machine
made by son called the Niagara which is
designed to some sort of server you can
get up to 128 threads although really
only 16 processors the 16 processor gets
a linear speed-up from one and then as
you get extra threads coming in without
the extra course other than speed up is
only about one and a half for each
doubling of the thread number
I emphasize that these produce the same
hash value as the serial machine I
haven't slide on how much memory we need
this isn't very interesting except if
you make smart cards but Neil's Ferguson
gave us a marked down for having using
too much internal memory so I abraded
him last week when I was visiting
Microsoft and he said oh well please
send me your correction the basic deal
is that we use a couple of hundred bites
and we're assuming usually you know what
sort of message you're going to be
sending from a smart card because most
applications have a limited vocabulary
okay this is our features list like
actually covered most of these already
um what if I need to add in truly
anything done oh one feature i didn't
mention most of the hash functions we've
seen so far md5 down through a shot to
do what I call dribbling in the message
the hash function runs a little bit of a
round maybe a full round and then it
brings in a word of message and then the
round happens another time and it brings
in another word of message we think this
is a mistake that you should actually
bringing in as much of the message as
you can whenever you bring it in and
then you should conjugate for quite a
while before you'd ring in your next
blob of message so we've taken that
approach what that means is when the
attacker is trying to break your hash
function he can do all he wants on that
one blob of message but because the
connection between that and the next
part of the message that comes in has a
whole lot of mixing in between he's kind
of stuck if he wants to do something
like compensate for a 1-bit change he
can cause it to happen at any given
place but he can't cause some
compensating change later on to make up
for it and if you look at the attacks
people have actually made against md5
sha-1 and so on they all use this
feature
okay this is a summary all the parallel
ISM stuff yes no I believe every other
entry has that feature okay so every
every entry except sandstorm will
produce a different hash in parallel
mode in most cases people haven't
actually even defined a parallel mode
they just say you can use a tree and
leave it at that md 6 has carefully
defined a parallel mode because it's
designed to run in parallel but even
there they've left some of the tree
parameters open one of the annoying
things is that a lot of the submissions
have a whole list of recommended
parameters but you can tweak them if you
want now that's actually a good thing if
what you need is the Swiss Army knife
for one reason or another you know do
you have all these options like if
you're you know the sort function has
all kinds of things you'd want to
parameterize but for a standard hash
function it's probably not a good idea
it's an invitation to security problems
because the other guy can say well I
can't do that when how these other
parameters you know or gosh I can only
use des instead of AES and you get
what's called a downgrade attack
okay one of the things we've been
questioned about is actually using
multiplication multiplication has pluses
and minuses the real justification for
it is it's an excellent mixer in terms
of bit dependencies in as the result of
a multiply the output bit depends on
pretty much all the bits beneath it in
the two inputs which means that the top
half of the multiply is depending on
everything the bottom half the
dependence is so so but it's still a lot
better than either X or add the drawback
to multiply is your parallel version
know your your portable versions which
are written in C have to go through
special tricks in order to get the
result of the whole product and that
slows you down there are a few machines
where the speed of the multiply actually
varies depending on the inputs these are
no longer common chips because it's the
designers are not going to fiddle with
their timing just to make multiply run a
teeny bit faster sometimes they're all
sorts of other timing constraints that
they don't want to play with the
argument for multiplies it does a lot of
mixing it's a little slower than add but
if you look at the total work going on
most of what the machines doing is
getting your inputs in there you've got
half a billion gates working struggling
to provide roughly a thousand bits of
arithmetic per cycle so you're spending
a whole lot of work assembling and
gathering the data doing a little bit of
actual data processing and then another
whole lot of work sending it out towards
got to go so we're saying the right
balance is to do more arithmetic where
you can so that's why the multiplies in
there um we feel parallelism has not
been sufficiently emphasized in this
competition um it looks like the way
things are headed is parallel period if
you bought a computer recently you've
noticed the advertised clock speed is
not any faster than it was last year two
years ago
what they've done instead is they're
giving you more course and those guys
have to work in parallel now in a
Microsoft Microsoft System you have
about 50 processes running all the time
doing god knows squat so those extra
cores can be independent but if you
actually want to hatch a movie fast then
you'd like these things all to be
working on your task another thing that
we're discovering is that simplicity and
a hash function is pretty and it means
maybe you can remember and understand
the whole thing in one sitting but
looking at it for a few minutes but it's
also risky everything that's been
attacked has been beautiful and simple
and we have a couple minutes for
questions and then I'll move on to the
next part of the talk
yes yeah I sent them to note a couple
months ago oh no um I was asked his miss
to wear this meeting memory requirements
and I said yes I sent them an email a
couple of months ago we haven't made
public announcements on those because
we're waiting to get the code certified
and that's a slow process it's where I
come from they actually want to make
sure you're not issuing something that's
going to cause embarrassment or legal
obligation and so on so you kind of sold
me on your hash and I looked at the nest
website and they didn't say why they had
picked the hashes that they did for
round two what's your guess as to what
their biases were in in what they
selected I don't know I haven't seen the
list what they did the last time when
that during the the cipher competition
ten years ago they picked the five
fastest on you know whatever 386 46 was
maybe he was even a Pentium at the time
and you know they swore up and down they
weren't going to do this this time so
they may not have done it I don't know
sharks this is a naive question you
talked about how multiplication is
discrete what if one of your factors is
zero aren't you creating collisions
absolutely in the case that one of the
factors in the multiplication is 0 then
the output loses all information from
the other factor so in that case you
lose 32 bits of information but on that
same pieces of data is used in a whole
bunch of other places and we have a
special thing in there to prevent a
series of multiplies by 0 of course I've
left out a lot of our internal details
because it's a short talk but we
definitely aware of that another version
of that is if one of the factors has a
few low order 0 bits and then the result
loses a few bits of fluid or information
and we have a special stuff in there to
prevent that from happening in a chain
so here is the other thing that seemed a
little weird when i briefly looked at
the nest site as they said something
about they're gonna allow the
submissions to tweak their algorithms
after round one which yeah yeah oh sure
but you try implementing on fpga to see
how fast you can get hardware on what
sort of machine fpga like a hardware
ready love no fpgas um no we've
implemented it on basically just
processors your computer's because
eventually you can expect a card that
does it for everybody yes certainly ah
bytes per second hundreds of millions
but like I I guess I'd work it from
clocks / buff or bit our clocks provide
oh now we're faster than that but md5
faster than that too in terms of where
we stack up against the other ashes were
comparable to sha-1 we're a little bit
slower on a single processor and as soon
as you put more than one processor on we
get ahead people have been talking a lot
about the importance of speed in a hash
um it turns out that for almost all
applications you just plain don't care
about the hash speed as long as it's not
awful because you're always doing
something else you know if you're
sending an email you know if you're
signing it then there's this public key
calculation you do if you're doing a
look up somewhere there's going to be a
disk are moving and that disk arm timing
is in nola seconds and not nanoseconds
about the only thing where you need a
super fast ash is if you're doing you
know you're hatching a movie something
huge
if you have a server that's doing a
Julian transactions a second so the
individual little bit sat up and if
you're trying to break a hash by hashing
random values over and over again and
you know two out of three of those
applications we figure you you want to
work fast okay I'm gonna move on to the
next part now I've got my arrow back
sort of
ok this is more fun stuff
okay this is taken from a talk I gave a
few years ago and ah another windows win
we will pause a few seconds here while
the computer thinks oh this was an
experimental math workshop and I put
together about 10 little things and a
lot of that was joint work with people
and here are some of the people i
routinely do joint work with okay these
are the little sub box I'm going to do
the one on counting poly hypercubes and
the post tagged problem
okay counting poly hypercubes everybody
here is probably played Tetris the
objects that are falling in Tetris have
area for they're called tetra Manos by
analogy with dominoes Saul solemn ghulam
Solomon ghulam invented a whole bunch of
games that you can play with pentominoes
of area 5 and there's been a lot of
study of how many of these things there
are and packing problems and so on with
various different areas and you can do
the obvious thing of going up to higher
dimensions and do cubes and tests racks
and so on so we have polyoma nose and
poly cubes and poly tesseracts and so on
you can ask all kinds of questions for
gaming people like to actually build the
physical puzzles and play with the
packings and so on and for theoretical
math we just like to know how many of
them there are or even an asymptotic
formula on the actual proved results are
surprisingly sparse the limit there it's
known that the polyol munoz have a
limiting ratio if you add one to the
area it multiplies the number of
polynomials by about four but that about
is incredibly wide it's between three
and five or something the numerical
evidence allows us to say it's 4.07 and
there are people who think they know it
the next term in the asymptotic
sequences but I'm skeptical the
situation with extra dimensions is you
know if not even that developed anyway
we've set ourselves on just the very
limited thing of getting some data are
the two parameters are the dimension and
the volume and then you get to choose
whether or not to try to remove
symmetries and removing symmetries makes
a whole lot of difference is the number
of dimensions goes up the kinds of
symmetries you can have or orientation
so that's like when you throw a dye in
the air you get a bunch of different
orientations where it can land
on if it's sitting on the table you can
rotate it four ways you could also put a
mirror next to it and get a dye that's
mathematically equivalent but looks
different you can reflect individual
dimensions and then finally there's a
symmetry in starting position you can
say I'm always going to put one of my
squares at 0 comma 0 and add to it and
in that case to any given polyoma no can
be built up in several different ways
where you'll have a different starting
one marked as the first position our
approach in this problem has been to
count everything so we don't remove any
symmetries the reason for that is
mathematically the numbers seem more
likely to make useful sets
got it okay all right this is the
numerical data and I know it's pretty
small to read so I won't actually read
these numbers to you Dan no he wrote the
program here and it's been a little bit
check by other people but mostly he gets
all the credit after we looked at some
of this data we realized there were some
useful relationships the most
interesting one probably is that if you
fix the volume V and increase the
dimension so that means a column in this
matrix you're looking at the data along
one column and asked what if I add
another dimension what happens it turns
out that the entries in that dimension
are a polynomial in the volume now
there's a certain class of combinatorial
person who would recognize that just
right off the bat for the rest of us it
actually requires some proof it's not
intuitively obvious it's exactly the
difference between a person who says Oh
chromatic polynomials make sense and
another person is as ha a chromatic
polynomial is where you've got a graph
or a map you're going to paint and the
variable is the number of colors of
paint available and the value is how
many ways can I paint the map with these
colors it turns out that's polynomial
and if you're sufficiently experienced
combinatorial list you'll say of course
and if you're not this will come as a
complete surprise same principle here
anyway we spotted this after getting the
data and worked out some of the
polynomials for the different columns
and we worked out the rules for some of
the coefficients and the polynomials and
that actually allowed us to fill in a
couple more values in the table
these are the ratios you fix the
dimension and ask suppose I increase the
volume by one how much do I multiply the
total count by and the middle column
here is the observed ratio as near as we
can tell the final column is something
called the rebound and that's an easy to
prove bound where you assume that what
you're actually doing is you just have a
tree with as many dimensions and the
appropriate connectivity but you ignore
the fact that you know if you put down
five squares going around a point the
fifth one's going to be on top of the
first that doesn't count as polyoma no
but it counts in in the tree bound so
the tree bounds an upper bound I also
filled in the data for dimension minus
one now that doesn't mean anything but
because we have this feature that the
results are polynomial in the dimension
I can say what if the dimension were
minus one just calculate the values and
there was no obvious pattern so we let
it go and this is the side thing where
we take out all symmetries so these are
related to the previous set of numbers
and smaller but you can't say exactly
how much smaller except asymptotic like
if you add rows one and two you get the
traditional counts for polyoma knows the
ratio here seems to be growing it's
probably unbounded so the ratio for
adding the increasing the volume and the
dimension by one seems to be at least
ten probably keeps growing that's what
mini talk
okay this is just a motivation for the
next problem everyone knows after
they've taken a computer science course
that there are problems that cannot be
solved usually you point to the halting
problem if you're doing if your computer
science kind of person or programmer
programmers especially are willing to
believe that there are problems that can
be solved and if your mathematician you
kind of come at it from a different
direction with girdles theorem although
it comes out to the same thing so then
the question is well what's a natural
example of an unsolvable problem because
all the examples you see in your courses
are things that are just probably should
never try to solve any way they they
they don't make sense they require
thinking long and hard to even
understand what's being solved you twist
your brain into not trying to figure out
all the quantifiers and so on it would
be nice to come up with a simple problem
you could point to and say we think this
might be unsolvable the first candidate
that comes to mind is something called
the 3n plus one problem and I rejected
that because even though we can't prove
the answer we know the answer you know
from empirical testing we're pretty sure
what the answer is it's the same way as
with Goldbach's conjecture even though
you can't prove it you look at the
numbers and it's pretty clear it's true
so here's something that where it's
really hard to say one way or the other
what the answer is this is supposed tag
problem and I worked on this in
cooperation with Ellen Wexler email post
was a logician from the 20's through the
30s and the 40's maybe even the 50s and
he almost discovered turing machines and
unsolvable ax t he danced all around it
didn't quite see it but he was 10 20
years ahead of everybody else he set
himself a number of puzzles starting I
think when he was in college or grad
school and said if I'm a mathematician I
should be able to
solve these puzzles in a mathematical
way and he found a surprising number of
them he couldn't do anything
mathematical with it all you know he'd
work on it it was obviously translatable
into a math problem but he couldn't get
an answer and this is probably his
simplest one it's called the tag problem
what it is is it's an operation on bit
strings you have a string of zeros and
ones and you look at the front of the
string and depending on what it is you
either append a double 0 or 1 1 0 1 to
it and then you'd strike off the first
three bits so on the average the length
is unchanged for random string but of
course it's not random after you've done
this a while here's a simple example of
processing us and string and it winds up
in a very simple loop alternating
between length 5 and 6 now because it's
much easier to talk in terms of these
blocks after you process through the
string once everything is built up of
these a blocks and B blocks so I think
in terms of A's and B's rather than
zeros and ones and a is a double zero
and Abby is the other one 101 pattern so
the first question that comes to mind is
what happens to a bit string now for
simpler examples post was able to solve
this problem this is the smallest
example where he couldn't say what
happens um one of the questions was does
everything either shrink to zero or fall
into a loop is there anything that grows
to infinity and it's actually not too
hard to show that if you have a more
complicated tax system you can stimulate
a Turing machine so you know that you
hit unsolvable problems but this seems
to be on the borderline it's hard to
tell I'll here are some examples of
loops it turns out if you take the
particle a B which is six bits long and
the particle B squared a squared which
is double that you can include those to
get
there any way you want with multiple
repetitions and you get a looping
pattern because the individual particles
loop those are the ohlins we know of
that work exactly that way other loops
you get reproduce themselves by having
some sort of overlap involved and this
bottom line is a very simple example of
that i wrote a grab search program that
found some more loops there longer and
don't have any obvious interesting
features other than they look like a
mess the periods make no sense
particularly they're long and what they
represent is just loops in a graph of
going from one bit string to the next I
set my computer a couple years ago to
trying all possible combinations of A's
and B's of a given length and running
all of them and seeing what happens and
the answer is they run longer and longer
periods of time and eventually I had to
give up on the long ones because it was
a million bits long and just SAT there
turning along not particularly growing
or shrinking but it looked like it might
take a very long time to get to a period
or a loop now if there's a Turing
machine simulation lurking in here
somewhere we would expect to find
something simple example where a pattern
grows linearly in length with time every
time you put you pass through its cycle
around it it adds something somewhere
and a little bit longer I didn't find
any of those maybe I didn't look long
enough ok that's the end of that one now
we go back to PowerPoint
um probably went to MIT and you know it
was in Minsky's block so
yes
right
alright next is asteroids yeah
well I just flipped through doing this
one this way it's all words I should
emphasize these last two are not
official Sandhya talks okay well start
with something simpler moving planets
somebody noticed a long time ago the Sun
was getting hotter and on a billion in
your time scale it's going to get really
hot here like maybe the oceans will boil
and that could make it an inconvenient
place to live so it would be nice if
maybe the earth could move a little bit
further away from the Sun on some sort
of gradual basis if you work out how
much energy is needed to do that it's
quite a bit I learned the notion of a
tame asteroid on the space digest
mailing list a long time ago from John
McCarthy I believe he got it from some
astronomers but I don't know the full
provenance the idea is that you have an
asteroid that swings by some noticeable
mass and it moves the asteroid a whole
lot out of its original orbit and it
changes sure orbit a little bit because
you outweigh it and because of the way
chaotic orbits work you can arrange
things so that if you move the asteroid
one centimeter a year ahead of time that
it comes out in a completely different
place after it's done that swing by the
flyby so the idea is you very you move
your asteroid by little tiny amounts and
arrange it you plan ahead for your next
17 encounters with the earth and then
you have to have some other planets
where you dump the angular momentum or
add angular momentum and you dump the
orbital energy or add orbital energy so
you need a couple of source and sink
planets probably one on either side of
the earth but not necessarily there's an
interesting analogy here with Fineman
diagrams if you've seen Fineman diagrams
you have things like two electrons repel
each other because they exchanged a
virtual proton here we have an
interaction between the Earth and Mars
or Venus where you have an actual
article in this case the team asteroid
that's literally moving angular momentum
from one planet to another and depending
on which side of the planet you go by
you you add or subtract and so on
there's an actual asteroid that's in a
kind of synchronous orbit with the Earth
and Venus it switches back and forth its
orbit is not between the Earth and Venus
it actually reaches out to about where
Mars is and moreover it's not actually
in the same plane as the Earth and Venus
it's got a noticeably tilt and it's
noticeably elliptical but it still has
this periodicity that's interesting and
the thing that it switches back and
forth between controlled by the earth
and then by Venus the sort of meat of
course it's way too small to have any
effect on our orbit but it never even
comes close the control idea which
reduces the amount of energy you need to
do this is called the butterfly effect
and the idea is that you make a very
small change far enough ahead in time
and then you have very good prediction
algorithm the problem with doing this to
predict the weather of course is that
there are million influences on the
weather but mostly speaking there aren't
a lot of influences on planetary orbits
except once you know about and can
account for
okay here are some of the problems you
run into big tides Mars is probably in
the way if we start moving the earth out
you've got to use at least two other
planets you can use Jupiter and Saturn
by doing your flybys on the correct side
you'd subtract instead of AD and so on
on the other hand Jupiter and Saturn are
in some kind of resonance that is sort
of cleared out portions of the asteroid
belt and adjusting their orbits might
actually not be a good idea and
incidentally our test particle is
nowhere near the earth which is probably
a good thing right now but sort of a
mess in the plan
okay so here's what we do to get series
where we need it or something else this
is called the gravity machine what it is
is a bunch of particles of different
sizes from meter size up to
kilometer-sized in between then and
there to squirm so they're all mutually
gravitating with each other and the idea
is you push on the small ones and you
have a really good computer and you know
the mass is very accurately and it
allows you to control the behavior of
the whole thing moreover you can absorb
things the swarm swoops down on them and
you've carefully arranged all the
gravity so that the thing you swooped
down on becomes a member of the swarm
and everything slows down to the average
orbit because you can't change the what
happens to the mechanics of the centers
of mass of your swarm and the particle
you're seizing
one actually possible useful thing to do
with this is to put another small moon
in Earth orbit we'd like something that
has a more favorable composition than
the moon we have with useful things like
water we'd like something that's a
little easier to reach than the moon we
have we don't necessarily want it to be
super large because of the tidal effects
um but it's something we could actually
do in somebody's life time if you live
really long this is going to change the
appearance of the night sky okay the
propulsion in the gravity machine the
internal control is by manipulating the
smallest pieces on there are a lot of
other influences besides gravity that
you need to think about if you're trying
to do 16 decimal predictions there's
thermal expansion that's going to change
angular Momentum's and so on they're
shadowing a lot of problems moreover you
can't change the berry center of the
object of your swarm the center of mass
is always the same so for that part of
it you've got to manipulate it and use
the flybys of major large objects as
your control I'm not your control
mechanism that is your amplifier the
other thing is your control has to
exceed your unknown influences you need
to be the biggest butterfly on the block
your advantage is you can look ahead but
you have a very weak push and so
surprised pushes are a problem
some of the things you need to think
about real asteroids are not spheres
which means they have interesting
gravity fields more seriously they're
not solid in many cases and whatever
shape they've adopted is according to
their particular gravity environment and
if you change that much things might
shift in your asteroid in ways you're
not prepared to deal with and internal
heat diffusion is not too hard to
compute for a solid object of known
composition but of course if you don't
have a solid object and if you aren't
pretty sure about the composition in
particular the hidden parts inside could
be other kinds of rocks and you don't
know what's touching and so on the the
heat becomes a puzzle um one of the big
things is a lot of the stuff you'd like
to bring home to earth as volatile sin
it like water and you know ammonia
methane carbon things and you can't use
comets because comets out gas and
produce noticeable thrust as a result um
there's also a lot of stuff we don't
know about wandering around the solar
system normally you don't care but if
we're trying to do 16 digit calculations
then small stuff begins to matter and if
you've been watching the news the last
couple days do you see the Jupiter just
got hit by something that nobody knew
what was what we see is a big black hole
in Jupiter's atmosphere and you know
people are guessing it was a comet but
you know not a known compet other things
that solar wind varies and potentially
magnetic fields could be a problem if
you've got a an iron asteroid there are
some safety issues
and the other thing is if you bring
something home you probably need a bag
um you want to hold on to your water of
course but also you can't have little
bits about leaking off into other nearby
orbits we've already got a space junk
problem from stuff we've put up there
these are some of the things we might do
to push this idea you know it's
perfectly accessible to actual
small-scale tests on you know ten meter
size boulders and so on okay and we're
ready for the next one how much time two
minutes all right very quick on origin
of life
I call this the fish pond theory okay
there if you look back and try to figure
out what got live started the biggest
hurdle is a bunch of chemicals came
together by random chance and it started
replicating here's an idea inspired by
Native Hawaiian fish ponds the Hawaiians
built these rock walls out in the ocean
with rocks and they're interesting so
that there weren't any big holes in the
walls so little things could swim in and
grow and then couldn't swim out so they
were trapped inside the fish pond
eventually the fishermen would come
along and select a large fish for dinner
now puzzle on life you need a boundary
to concentrate your chemicals or else
they'll diffuse out into the ocean you
expect to see some sort of growth you
need reproduction and ideally you have
what's called heritable change which
allows revolution and then you need some
sort of energy or thermodynamic gradient
to drive the process forward make it
happen and then this line that says
evolution does the rest covers a whole
bunch of problem is beyond what I'm
trying to address here
okay the boundary is a solved problem
for people some people you assume
primordial soup you know an ocean full
of chemicals and you assume the oily
chemicals float to the top of that ocean
and those become cell walls you get a
wave the wave breaks the oil is becomes
oil and vinegar basically it's the
bubbles I'm apologizing a small magic
molecule my magic molecule is smaller
than most magic molecules but it's
probably bigger than amino acid but not
too much bigger I call it m um one of
the things atoms like to do and
molecules like to do is polymerize on
sulfur in particular the room
temperature stuff you see the yellow
mass is made up of molecules of eight
sulfur atoms arranged in an octagon and
sort of I don't know the name of the
configuration it's not a flat plane but
it is an octagon I think they call it
crown so I'm going to assume my magic
molecule forms rings that's good that
means it's Nick's polymers it has at
least two active ends like amino acids
do or a lot of the stuff that becomes
poly plastic the one kind in another
that the joining of the two ends is
energetically favored now for amino
acids that's actually not exactly true
it's roughly neutral and whether the
amino acids joint or not depends on
detailed conditions and when we actually
joined together amino acids to make
proteins their enzymes and energy
driving and so on to make sure it goes
forward and em likes to polymerize but
doesn't usually because there isn't a
whole lot of it around the M monomer
can't cross an oily boundary and i'll
note that amino acids actually meet most
of these criteria more or less
em will polymerize if you get it enough
of it together and the Rings hide part
of the functionality on the M molecule
what's left on the outside likes to
dissolve in oil but there's a hole in
the middle of its octagon or whatever
and in that middle that becomes a hole
in the wall which in fact cells use a
lot they they put proteins in the walls
with holes and we're going to assume the
hole is big enough to let single em
through but not mm or triple them
because they're bigger molecules they
don't fit through the hole so inside our
cell if you get two M's coming in
they're trapped um after you build a
real ring oh ok I need to brush through
this ok the ring travels to the wall and
becomes a new hole you get growth simply
by rings adding to the wall and more m
wanders in because the the cell in
effect is a sink for EM because it's
removing him from the solution to be
produced you need a wave that breaks up
the cell the leftover pieces of wall
form a new cell heritable change is iffy
but I'm assuming you have varieties of
them the energy gradient is just the
polymerization this theory is lab tested
bowl and contrast to most origin of life
theories we can actually try to make
molecules and see what happens and this
is another different idea and that's the
end so thank you very much
you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>