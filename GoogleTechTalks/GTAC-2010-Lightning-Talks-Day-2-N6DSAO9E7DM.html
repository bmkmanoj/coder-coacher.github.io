<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2010: Lightning Talks - Day 2 | Coder Coacher - Coaching Coders</title><meta content="GTAC 2010: Lightning Talks - Day 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2010: Lightning Talks - Day 2</b></h2><h5 class="post__date">2010-12-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/N6DSAO9E7DM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so right now we have Ramesh Romani from
tavant speaking the next speakers will
be Ramona and nilesh from mindtree so
good afternoon folks I'm Ramesh money
from Taiwan technologies I'm here to
share our experience with model-based
testing on the open source world quickly
as all of you have been also been using
combination testing tools in testing web
pages reducing the few thousand tests in
200 tests and being benefited out of it
we just felt why can't we use it in the
interesting models so our first
experience was trying to build like I
just took a quick example of licensing
of one of our application in terms of
language product and things like that
every model needs condition to be put
that's a place where we have took a
first cut then what we have done is we
went ahead looked into various tools we
identified a tool called Jenny it's a
very good tool the only challenge being
it communicates it gives the input and
output in the orthogonal fashion which
is not very easy to understand so
actually I built a tool called Jay wrap
and also published in sourceforge.net
well now you can see where you can give
these yellows like Japanese trainees and
full-text search would not go hand in
hand so meaning a condition can be put
in and you would be able to use it so
problem one solved and the next thing
what we also realized is towards how we
would able to efficiently use this tool
I'm sure all of us would have read this
software testing a craftsman's approach
where we talked about a week normal
equivalence class partitioning which
predominantly helps us to reduce the
number of tests but still try to keep
like know at least one test covered at a
time so we use the same approach use
this model where you could see there are
two tests we could able to use from the
same model one which could be used for
functional testing where it's an
exhaustive number of tests the another
set which is a very very small concise
number which can be used for smoke
like no doing some kind of a patch
release and things like that when we saw
this benefit one of our team member came
and said like I think that there was a
question today morning also i am not
able to associate results and every time
when i execute this we have a challenge
in terms of filling all the results
again so what we have done is we have
put our results also with the model not
like an elaborate result but a simple
pass/fail where we were now we are
saying japanese chinese full text and it
will not go with pass so it has to fail
so we achieved two benefits one probable
results is also given to user point
number one point number two we also
covered lot of negative test which we
have not covered as a part of your
previous test and the nice thing about
it is as someone said in the morning
also where there are lot of conditions
which we would have not thought about
which comes out of this where you find
all these issues in the requirement
phase rather than finding it in the
testing case of like Oh with this what
is the result so that helped us in terms
of improving our productivity and the
best thing is it allowed us to sell this
whole idea to our test engineers as well
as our managers once we have done this
extensive work we just realized that we
need to add lot of conditions and to
make the model really work and we felt a
JJ rap was not scaling up completely so
we used picked from Microsoft it's
another tool which allows us to do a
model-based is where we have given quite
a lot of conditions they're probably you
can see it and the nice thing is when we
have started scaling up our business
analysts have also become more shrewd
and they said look we need these kind of
conditions to be added in artists so we
came up with the idea of adding seeds to
it where the seeds are like no the
combinations which are like mandatory
conditions which you want to add so we
are these seats and we have we were able
to generate these models by this way
what we have achieved is like one we
have able to completely cover the model
we are able to get the results we were
able to increase the productivity as
well as we were able to kind of find the
like no challenges or not having proper
expected results up print so to
summarize
our experience in like you know the
model based test shows that it is going
to be a challenge in terms of trying to
bring the whole model into the tool but
the best piece out of it is it improves
your productivity it improves your
quality and using OpenSocial like all
pairs J rap and picked also saves lot of
cost and it helps you in terms of like
no time and again proving your manager
is that like know there is a better
return of investment on this tool thank
you so much for sure thanks for this
time so next we'll have ramanathan
nilesh from mindtree after them Red's
one from me mas will be speaking
hello good afternoon I know you guys had
a good lunch so we have been told that
quickly finish our talk without
disturbing your sleep so we will try to
maintain that so the talk we are going
to power is on achieving testability in
performance testing I will probably take
30 seconds and give it over to Neal H
because i told him that i will give them
the full time to talk because i already
recorded and put it on youtube so you
can look for this title and you should
be able to see a video recording of our
session which has much more details and
things like that so what I would like
your gist of things what we are going to
talk about then let an elation and take
over so what we have seen over the last
couple of days is a lot of different
aspects right one is we saw tools we
talked about certain methodologies we
talked about certain best practices we
talked about various things right so
this talk is primarily to bring it all
together right so we know that each of
them right are powerful in their own
when you take tools tools are powerful
you take about methodologies they are
powerful you take about the expertise
that people bring in office via smart we
are powerful right so but when you bring
it all together the amount of power you
get in this whole thing is amazing so
we're trying to cover that aspect in our
talk right so I leash and maybe come
later if we have any points to add good
afternoon everyone so as ramnath right
rightly pointed out there are you know
many aspects that you know brings
testability too many to or the testing
activities and tools methodologies
people expertise they kind of contribute
to that and so when it comes to tools
you know there are you know as I we have
seen a lot of focus has been shifted
towards using open source tools these
days but you know using open source
tools has its own challenges no and
because if they have there
own limitations and in order to bring in
order to anika overcome those
limitations you know we have to turn or
take some measures to or do you know we
have to do something extra to be able to
effectively use those tools because open
source tools they kind of they're good
at what they do now they're there do
good with doing one activity you know
let us take example of and I jmeter
which is an open source load generation
tool it is good when it comes to know
generating load but it lacks certain
capabilities like distributed execution
reporting etc so we need something extra
to bring the stability or bring down the
effort of a no performance testing you
know while using open source tools like
in addition to that you know we would
require certain helpers also to to know
kind of deliver under the pressure and
you know bring down the time aspect of
it then you know because in performance
testing is very critical to get the
things enough worse right at the first
time because performance testing in most
of the cases is an afterthought that
when no product is about to release you
know we are given the product that you
know we are releasing in two weeks
please do in a performance testing so
that you know we can make sure that we
can grease the product so often there is
no there is a pressure to get the things
right and at the first time so that I
know adds up to the pressure on the
performance testers so you know and
there are no customers or I know as
users we are kind of now you know are
less patient as compared to our earlier
days now we want something in to be
appeared on our screen you know when
within microseconds so we are kind of we
have to manage that end user expectation
also while carrying out performance
testing so you know as I am NOT pounded
out you know we have to kind of do a mix
and match of four and a major components
to and a kind of bring testability to
performance testing that is to bring
down the total effort required
required in for doing performance
testing and first of it is you know
methodology kind of step so methodology
when I say methodology there are two
aspects to methodology in my mind one is
a step-by-step kind of guide or a
roadmap as to how we I'll go about doing
performance testing because if you miss
a thing in performance testing and the
kind of impact that it will have on
overall performance texting effort will
be huge as compared to the functional
distinct right so having a roadmap as to
a step-by-step guide as to how you you
will carry out performance testing is
important one second is the knowledge
base and as to how you will do perform
each of the step a the second is
framework since I know as I mentioned
open source tools have their own
limitations we have to kind of do you
know build frameworks around those open
source tools to achieve an out to carry
out those end-to-end activities right
the third is accelerators you know you
need accelerators in order to kind of
save some time for example in a jmeter
jmeter doesn't have a very good
debugging capability so it while
debugging a stream you may end up with
no spending a lot of time so having some
kind of accelerator to easily debug
jmeter scripts will be will certainly
help a performance tester and lastly
expertise so expertise is now in using
all these things you need to have people
who are kind of good because performance
testing demands a lot you need to know
databases units unit to know how wave
applica we have server works how to
monitor them how to analyze the results
and stuff like that so having that
expertise is also very critical so and
when this comes together you know
certainly the time and effort will go
down and the value it will bring to in a
performance testing will certainly go up
thank you very much thank
Thanks it's a challenging schedule so
red Sun from mimosa speaking now and
after him Tenley from Akron X Factor is
a bit weird but that's actually the
first positive that i always get
whenever i execute the usability testing
at the end of the usability testing
cycle as the you know participants doing
the debriefing and I always say
everything is fine there's no problem so
this is something wrong in the way that
we or myself conduct a usability testing
for example one or techniques that I use
is the think aloud well initially when
they are executing the usability testing
using the web application they'll say
things out loud whatever that they think
but after half an hour they'll be
thinking of going back so it's not going
to be loud anymore then they we use the
Likert scale and people tend to put
everything at the middle because it's
easier for them and we had some success
using a I tracking video recording and
audio recording to try to analyze the
behavior but all that cost a lot of time
and and the psychological part of it is
users going to get tired they get
uncomfortable and everything we call
them to the lab to conduct the usability
testing so the key point here is if you
can minimize direct human interaction
you can actually have a better or
maximize the usability effectiveness
during your usability testing so I'm
looking at right now a crowdsourcing for
usability why don't we do that we
minimize the interaction maybe get a lot
of users to do the usability testing for
us for example you know minus all the
Toshi I have in the market today I have
something in mind maybe we can use the
you know despite tools the tools are
used to maybe to track your spouse or
your kids internet connectivity
you can use that to do the usability
testing of course there the privacy part
will be will have to be dealt with later
this tool can actually do a keyboard
logging the coordinates the mouse
movement and mouse clicking and
everything and with this kind of
information and you have thousands and
thousands of users assessing your web
application it can actually consolidate
all this information we have a passer at
the end order of the of the server to
consider all this information and we can
actually build an effective heat map for
every single page of your web
application so it's a good way in my
opinion to measure the effectiveness
efficiency and user satisfaction that
key areas in the usability measurement
so that's it thank you very much
speaking and after him will be merciless
whistle blows from Sookie okay hi guys
hello just go in today good okay so
today I have an opportunity to talk
about behavior driven development using
J behavior webdriver and sharing the
story that the team is doing in a
connects with your guys traditionally
what the way we develop in software's
that we moving our requirement process
actually moving from outside in and
contagion actually moving from the
inside out so we often end up with a
product having gaps and behaviors only
validated for the end of the development
lifecycle and we end up with the product
is not meeting the requirements at the
start so it's interesting to see that
there there are no more coding the code
is going you know requirements thrown in
our the door in code it just pick it up
coding in a cave in and just throw out
the product every end it really
collaborate late if now in a more agile
environment so talking about BJ it's a
term coined by a guy called Dan north
from talk works and the principle is
very simple saw bow behavior so we
encourage all the templayer actually
using the same language the same
linguistic to defy the behalf of the
system throughout the software
development lifecycle and geo their
principles enough is enough so upfront
planning is often having to mission
return so we need to develop those
requirements that we go on and fighting
areas or mistakes to improve rather than
having a bunch of you know requirements
are from never leave and die throughout
the development lifecycle deliver
stakeholders value so the fact that we
have these pieces value and bad in a
test case so story reaching in plain
English and we use JB have exactly
hooked it up to the actual
implementation on on the back end so do
given when then so annotation and
provided by job you have to do all that
behind the scene will be a bunch of pay
objects or we call and also the UI
control widgets allow us to do certain
things without custom I widgets and
webdriver used to drive the torso as
well so typical story will be looking
like this exactly what like you know the
the english-speaking on we do well to be
a also the Chester actually get into the
room and decide whether that is do the
feature that we're moving forward to
dysentery actually acted a septum
criteria and it living throughout the
development process so we'll pick it up
and we develop test as you can see here
that we have a bunch of annotation given
we map them to tax with the actual test
need to be run and make note here that
we develop a stain machine here that
asks colleague on the new mail page so
we set them stay and then we expect what
is behavior during their free
the test has been readable by lawsuit
the QA and developer and at the same
time as well it's given reports been
reading English as well to see those
paws here highland green or red if it
failed paths as well so just to wrap it
up so why it's really matter because
actually provides when only one source
of truth so we we end up with just dis
documentation living throughout the
development lifecycle less code is
better so we r I these before writing
the implementations or when I would
better cleaner start at the very end in
praise quoting myself across the whole
team so the fact that we have ownership
of these documentation at the start to
the end and everybody actually agree on
that is helping to improve quality
myself okay so that would be an for my
talk so things great i love it people
get to the point to what's important
we've got vasilis Rizzo Poulos from suka
and after him will be himanshu I grew up
hi guys Amos Lee's I work for 2k it's a
Swiss company he some of the guys
working for the city office might know
it and this is a metaphor about my way
here you guys and me we live in
different worlds now in the beginning
that was cold it was only cold and the
code was in text files so what we did we
had a lot of code we packed it in zip
files we locked it around put it in in a
case and we moved about in crutches and
shared it now if you think if you get a
picture of people with floppy disks
running around and sharing zip files
you're wrong that happened to me a month
and a half ago
after this we put version control inning
okay it was a bit better we got to like
a bit more code around but it still
wouldn't allow us to test wouldn't allow
us to do briefings we got to figure out
who changed what and when but it took
quite a bit of work so what did we do we
added BS well the build system now that
made things a bit better we got to get
more cold we got to get bit easier we
get to move around faster but still
getting to test the whole thing was yeah
go pick the build bring it off figure
out the which tested with environmental
running on it it still was hard so in
that metaphor timeline for about 60 to
70 years we started making these things
a bit faster a bit nicer and we added
continuous integration now everybody
knows what car that is yeah that's a
DeLorean as a reason for it now
continuous integration brought us
continuous integration gave us the the
time essentially to test and start
talking about the things we're talking
in this gtalk start thinking about how
to test better how to scale how to
perform better how to do testability
discussions and start thinking about how
to improve our tools which brings us and
that's why the DeLorean is to the future
now the future is what we need to do
here improve our tools but actually guys
you need to improve the tools okay you
need to figure the best processes I live
in a different world I live back whether
they get the card was okay so please
make the tools make the processes teach
them and give them to me so I can live a
bit better thank
I think the monster I need to i need to
to refer to something the talk is
actually stolen it the yahoo there yet
the are we there yet is a talk about
edit by ricky key if you type it in and
you got in for you that is to talk about
Ricky key talking about time and how we
manage it in programming languages some
excellent ideas and I'm actually
constantly in there so I had to keep
credit you thank you very much I i think
if we go by the clapping leader that
would probably be the best talk will
hear today but we'll see so next is
himanshu agrawal HCL and after him will
be canal Banerjee also ate a good
afternoon everybody so the topic says
environmental intelligence must be we
must be wondering what is this all about
related to testing think of testing as a
ecosystem and how does environment plays
a role in the testing parlance so I take
this opportunity to leverage whatever we
have seen our in our past experiences
and touch upon briefly of some of the
ideas that we are trying to develop from
a solution perspective from here so
let's consider a scenario we are a
change request a set of change requests
are slated for release and a release is
being planned a product manager worries
about okay is the release going to be
successful am I going to meet the
customer expectation is my development
I'm going to be well under time and cost
whereas your developer when he faces
with the issues or the bugs he says that
oh it was working fine for me earlier
what has suddenly gone wrong how do I
fix it when I cannot reap ready
you see typical scenario where the
defects are not reproducible where the
tester is saying for the new release how
do I plan what has changed what has
impacted and how do I ensure that my
released I have tested it thoroughly so
that my release goes very well in the
production right and from end-user
perspective if we see that he is worried
about with the new release coming in
well there is going to be any stability
issue he is is he going to get the same
performance as he was earlier or the
change personality is going to deliver
to his expectation his or her
expectations so we thought that looking
at the scenarios when we think of a
testing is a ecosystem it is just not
about testing of the code it is about
how do you look at the ecosystem how
your customer using the product how is
wising his feedback through various
social networking channels or how is
everything other means to communicate
like service Uldyssian for enterprise
products and things like that and
whereas if you look at the other parents
so broadly speaking we see that
environment can be too broadly divided
into two portions one will be like if
you know your environment well your
environment is basically your
development environment the environment
which you are using for building the
products and the customer environment
know your customer environment is
basically dealing about how the customer
is using your product think of it is we
are we are not talking of only web
applications or less top applications we
are we talking of mobility as an area
and things like that so the ecosystem
itself is too large to deal with so
looking at a scenario the current
scenario that I describe what we are
saying is that if we can have the
ability to a look at your environment in
terms of having a bidirectional
traceable
d bye and we are have successfully kind
of conceptualized and implemented a
concept for binary analysis based on
which we are able to on the fly even the
source code is not with there we can do
that and looking at other parameters
like how do i do the impact analysis
with minimal time on it how accurate it
is from that perspective how do I find
out the code coverage or the even the
functional coverage to speak off and how
do I accurately publish the release
notes out of it so this is only one
portion of the environment know your
environment there are other thought
process we are also trying to build upon
know your customer would definitely look
at something like how do I capture the
scenarios supposingly a deferred tax
system crisis occurred how do I have the
ability to capture the snapshot of the
system when it has crashed and make it
available to the dev and the test team
to actually run a fixed simulation and
the fix on to it it greatly helps them
to actually see the scenario for
themselves and simulate it in the dev
and test environment here we are trying
to make use of our virtual test lab
where we are also having some
capabilities around p 2 v and v 2 p
virtual to physical and physical to
virtual images replication and that
gives us the ability to come up with a
capabilities to replicate the
environment and lastly the ability to
provide an integrated analytic view
across the social network your customer
environment you're Devon integrated
environment help us to give a early
feedback right from the required fish to
the development phase thank you
thank you now we have canal Banerjee and
after him will be Mike Davis hi
everybody so can I yes hi everybody I'm
canal Banerjee I'm and from ACL I'm
representing an idea of which V as it's
light are presently working on concept
engineering out of the box mostly we
will find that as developers as testers
we are in a box we keep to our task we
do what we know the best engine out of
the box the concept villain we think out
of the box we are changing the rules of
the game the first and the most
important thing it is a service company
we service our end clients who further
on have the entire set of clients for
whom they are asking us to develop a
certain product or application engineer
out of the box first initial concept is
do not think about your client think
about your end user think about his per
se what does he want think of the
standards think of the business
implications what your business end user
has so in the traditional world we
should think like this we normally what
are non-functional requirements i
discovered before that they said there
to set of requirement final requirements
which are specified in any requirement
document which i have to create which i
have to work on it has always been a
focus area all since throughout the ages
the second part is non-functional
requirement these are things which have
not been specified anywhere these we
considered them as good to have earlier
we had functionality and user interface
used to be in the functional requirement
a well-documented area we have a set
process flow everything was working fine
there there might be some silly bitches
but they were well documented and
certain actions were taken against it
the second part was good to have
performance security all these came in
this aspect what this led to is pause
development of a functional requirement
we used to then sit down and think okay
now let's see what the performance of
this application is if my client accepts
that bench market send it
but today's world is very different
today as you might see the performance
security have moved from the good to has
to the must haves now it is no longer a
good to have feature for the client for
the end-user this are the most important
factors on which is decide whether to go
for this application or the other
application now in the good to have we
have got certain new features like self
healing so we would now be focusing on
these are the normal earlier used to
have a very small Sun sdlc is the
reduced from res dlc foreign refused to
have recommend analysis we should do
designing and modeling on those
functional requirements we used to think
of how to implement it we should test it
that was over earlier with the change oh
it's not visible okay the top level is
non-functional requirements and again
the same cycle is being repeated so what
I'm intend to cover here is for each and
every are non-functional requirement we
require to analyze it we require to the
design and modulate we require to
implement it as well as just as well as
tested I give a scenario earlier when in
the earlier days we used to have clients
business a business managers plant who
is to give the request for proposals
rfps and bits today we find technical
people involved there we find consulting
firms who are involved who ensure that
such kind of NFS are documented in our
design phase what I suggest is we
analyze we think for the end output of
say 55 seconds to display a page what
should my internal each component B what
is time required for that break that up
into module wise requirement then in the
implementation phase let the developer
know what is the constraint what is the
top level mark so that he can implement
in the same way testing phase very
important start the testing early this
is what disability is all about
according to me thank you
next we'll have Mike Davis and after him
will be Phillips em bro okay hi my name
is mike davis i'm an SCT in the london
office and i'm here today to give you a
quick introduction to call Jax what is
called jacks so call Jax is an
open-source research tool developed by
the University of Delft I have to make
quite clear it's not a Google tool but
over the past year also a few of us at
Google have worked very closely with the
team in Delft to take this research and
apply it to some real-world web apps and
today I want to share my experiences of
using the tool and give you a quick demo
of what it can do so what is called
Jack's call Jax is an automated tool for
helping with end-to-end web app testing
so traditionally when we do end-to-end
testing we think about scenario based
testing we we define scenarios work
flows through the application and we use
tools like webdriver and selenium to
automate them then we assert things on
the page and we go about it I this call
Jax takes a slightly different approach
it's an automation they are built on top
of webdriver so rather than doing
scenario based testing it automatically
analyzes the pages identifies what is
clickable and explores the app itself
doing depth-first traversal to find all
the possible states so I think the best
way to show it is a quick demo which may
or may not work given that warning we
just add so this is the test it's
written in pure Java so it integrates
with all your standard Java tools i J
unit and this you can't really read that
but that's pretty much the whole test we
define we give it a web app to test here
it's google image search we give it a
little bit guidance as to what to click
so we say click all anchor tags and
click all buttons and we give it a
little bit of restriction we restrict it
to just google com otherwise it will
follow the image links through and try
to map the whole internet which is
probably not a good idea and we've put a
couple of limitations in because this is
a demo and we don't want to go on
forever so see if this plays
look how how do I play it ah looks like
it's not going to play no oh ah if it
played you would see it fires up
webdriver is built just on top of
webdriver and it would do a depth-first
traversal of the google page it would
click all the links goes through finds
the images clicks on the images and then
at the end it will produce you a nice
state graph showing all the possible
states your application that's call Jax
I said it's not a Google tool it's
developed by the research team in Delft
but obviously that's just a crawler it's
giving you a nice pretty state graph of
your app but the thing that we're really
interested in is how you can use this to
add testability right how can you add
value to your tests we using the saw
tool and this is where the collaboration
with google has been working so the
first thing we did is we start
experimenting with very simple like page
invariants things you might have on
every page that you wouldn't necessarily
check with your webdriver test perhaps
you've got headers and footers you want
to make sure they're on every page so
you can write very simple plug-in every
time it finds a new page check the
headers and footers perhaps you got help
links pipes you want to make sure that
you never see the error page that says
an engineer's being called to test like
this very simple and because you don't
have to define your scenarios it should
hopefully require less maintenance than
traditional webdriver scenario based
testing other stuff we've experimented
doing is things like cross browser
testing certainly the developers or use
firefox so in firefox the app is pretty
good so we can crawl it with firefox
then we can take this explored and
derive state graph and we can replay it
through all the other browsers and test
whether or not we see the same things
whether we see errors when we load it in
IE that's proved quite effective we've
also looked at doing things like load
testing performance testing the fighting
out bugs that michael tan presented at
gtech last year you can you can write a
plug-in to do that in two lines and run
fighting the out bugs are for every page
of you I that's quite nice I think so
yeah this is call Jax say it's not our
tools written
University of Delft if anybody thinks
they can use it to add value i highly
recommend to give it a go and yes this
is an open research problem so if you do
give it a go I just ask that you let
them know give them your feedback give
them your experiences they're doing a
great job to sort of try and solve our
testing problems I think we should try
and support these people as the same
with the University earlier like if
we're building the sort of DeLorean in
Back to the Future they're setting out
trying to build the flying train from
the third one so we should try and help
them with that thank you next will be
Philip sembra and after him is Marianne
ramon marion you still want to give your
top yeah okay he'll be after hello I'm
Philip same road I man s IT software
engineer and test in the Stockholm
office and I want to talk about tester
specification and I'm focusing on
automated tests here of course in
automatic tests as specification is
nothing new that standard test driven
development lore but if you've ever like
I usually do started reviewing code by
reading the tests that you probably have
found that some tests work very well as
specification they help you understand
the code it's very nice and other tests
do that less well or not at all and i
like to call these code these tests well
specifying tests and pulley specifying
tests the latter in my experience are
typically typically tests which are
heavy unlocks heavy on Makka
expectations and they are often pretty
much like a plaster cast of the
implementation so for every call in the
method that you test you will find an
expectation among expectation in the
test and what this test in effect does
it locks in the current implementation
says this method is supposed to be
implemented like it is right now and if
it is not that's a bug these tests are
not very useful in my opinion and not
really
a proper specification well why should
you care you could are quite likely to
run into some problems with these tests
for example just the plain simple what
the heck is this test actually testing
mm or this test is failing is that
serious mmm this code is actually tested
but frankly we still don't really know
how it works how it behaves very
unpleasant and last not least hmm I
reflected this module now I have to
rewrite all the tests that's a real pain
yeah and by the way where's your safety
net for the refactoring are there any
tests that are still valid or are you
free flying and hope that it works
afterwards after you locked the new
implementation in in place um on the
other hand if your tests are well
specifying there's a couple of benefits
you can get there and the two I find
most interesting ones are well
specifying tests tend to be more robust
if your test clearly specifies what it
is testing and everybody agrees yes the
code we have the module needs to pass
this condition this is a must it's a
specification it's a requirement then
it's quite likely that after you change
the code this test will still be valid
nope test change will be necessary or
even exact dual and the other point is
well specifying tests have more
authority so this situation I just
sketched test fails and you don't really
know what it does and you're considering
ignoring the failure then you're sort of
starting you may start to ignore the
test that has losses authority you might
ignore it and you might even be right
what the test is doing might be totally
irrelevant to what you're actually
achieving
and so the better specifying a test is
the more authority it has so where you
want to be is that is what does this mod
you do look at the tests it's written
quite plainly this test is failing is it
serious or absolutely if this one
doesn't pass if we don't have this
property no way are we going to ship
this you need to fix this corner case
and very pleasant for a programmer hey I
reflected this module looks much nicer
now cool are you sure you then broke and
break anything yeah tests all pass
coverage is good i'm quite confident
didn't have to change a single test
that's why you want to be and based on
this I had this idea of an authority
rank for tests on a scale from zero
point zero you can safely ignore this
test when it fails in other words that
I've rode away to 1.0 this taste there's
no way around this test if it fails no
way are you going to ship this code and
what one could do with this then is wait
a coverage metric with this code covered
by high authority tests a code covered
by higher authority tests could then be
considered well covered as well and code
covered by poorly specifying tests not
well covered at all this is of course in
line with what Sebastian told us
yesterday thank you very much
next we have Marion ramen and after him
will be Rahul Verma hello everyone my
name is not uncommon i'm the author of
sahi another web application testing
tool what I'm going to speak about today
is a better object identification for
web applications one of the things ok
one of the things that has been kind of
prevalent right now is that
identification of objects on the web
should always happen through X paths or
IDs or some other names so it has been
actually over the last 23 years experts
have been considered to be kind of the
right thing to do so before that let me
just take a quick check how many of you
do web application testing ok and how
many of you use X paths on further
testing and if you do not have IDs and
if you do not have experts what do you
actually recommend to do a add IDs today
to those objects and if you do not have
control over that what do you do any
answers so you mean that like an
application is not testable if it
doesn't have IDs and if the XPath is
complex right so the thing is if if we
were to actually use expert to let's say
get up to this board right now you would
actually start from the top like go to
this come here third fourth box and then
here but really what you could actually
do is to say that like get to the tix
get to this particular board near neuron
drama right if you actually had a PS
which did that but say that ok get to
the text box near that user so that
would be a much better way of actually
defining your test and the thing is when
you say that like a text box is near
that user name in a list of users then
what happens is that like even if you
actually put in a column in between or
like you add something else in between
there is nothing it changes in the test
really all you're doing is saying that
ok one thing relative to the other and
the other is actually something fixed as
far as the business logic is concerned
so likewise if you were to say that ok
um
there are there is a check box which is
actually and near this user which says
there are two check boxes near a user
one says delete one says edit let's say
so if you had to actually define this
you should be able to say okay look at
look for the check box near the user
under delete or under edit if you have a
PS like that you don't have to actually
resort to IDs or two experts and what
I'm talking about is not something that
is like kind of theoretical this is how
sahi implements all accesses and it also
has a recorder which actually lets you
do all this other thing the thing is and
the amount of time people actually waste
in X paths and going back to the
developer to add IDs to that if they
just actually use API is like these they
would have a much better time so that's
it thank you much next we'll have Rahul
Verma good afternoon so here i am again
after yesterday's lightning talk so you
guys had rejected my talk if you haven't
realized so far so what I've done is
I've split my talk in 25 minutes chunks
name them subtly so that I can pass them
on to you in the form of lightning talks
anyways so this topic is on the design
of automation framework in such a way
that it could be used for performance
testing so when we talk of early
performance testing early performance
engineering one challenge which we face
is identification of performance
critical scenarios we depend on usually
the dev team or the testers who have
knowledge about internals of the code to
give us such scenarios and most of the
time it has remained in books the only
book which has been written on the
subject as I guess performed performance
solutions by Connie Lloyd there was no
one who did write on performance
engineering on non web stuff out non
client-server stuff that is the
challenge which we face in the name of
death of resources and time performance
engineering in desktop or SDK
applications is is usually not done so
what we can do is you can use your
functional tests as performance
indicators the automated functional
tests
okay even if you have performance
testing practice engineering in place
still your automated functional tests
can be very very good performance
indicators so what you have to do is if
you are using multiple frameworks you
have to build a matter framework around
them provide the provision for passing
on a boolean switch which says okay now
you have to log performance statistics
these are the metrics which you have to
collect and these are the number of
iterations number of iterations is a key
element especially in desktop
applications because the response time
or the operations are in decimal places
you could have time unit in microseconds
milliseconds so you have to have
statistically equivalent data for that
you would need multiple iterations for
your functional tests now data is there
how what would you do with that do you
treat it as absolute performance data or
do you treat it as comparative or
heuristic performance data that would
depend on your context to hints which I
can give to you is if it is a
client-server application there is a
concept of probing client okay some
people want to do is while the
performance testing is in progress your
virtual users you have a big lab what
they usually do is they put a manual
tester who exercises the web application
while the main performance testing is
going on now this experience of virtual
users would be averaged or at the most
they will be percentile taken
statistical analysis would be done but
this probing client the manual tester or
a set of manual testers would be
providing to you the absolute experience
of a user when your application is on
high load okay so you could use your
complete functional testing including
unit testing white box tests your system
tests as the probing client to give you
absolute performance experience second
essential thing is that in the design of
performance tests you are usually caught
with work load distribution pattern
assigning weights type types of users
and although Scott barber Alberto these
guys have been suggesting that you
should include error scenarios and your
performance tests we hardly do that but
in your functional tests you have those
parts covered so at least in your
probing client experience you would have
the error scenario
covered and resource utilization peaks
are usually observed in such scenarios
so functional tests can be very very
useful performance indicators it's just
a matter of time that we realize that
whatever what I'm saying is beyond j
unit instead of j unit you use j unit
perv i'm not saying that because there's
a limited use to that you have to
develop a meta framework either you have
to do it from scratch or you can build a
framework around your existing stuff
which is the suggested option thanks for
patience we actually could take one more
lightning talk if someone wants to do
something spontaneously any takers rah
who wants to do a third shall we say yes
okay here goes the third part
so a similar challenge which we face in
the field of test automation is there
was a related topic as well test
prioritization in the theoretical field
we deal it with risk-based approach and
rated stuff so what we can do for an
existing framework ok the solutions
which I am suggesting they can be
employed on whatever framework you are
doing ok so what you can do is for a
regression framework to become
autoregulation framework a framework
which at runtime realizes what all tests
it has to run based on the areas
impacted ok simple solution you split
you start with a high level activity
then you can model it down ok so what
you do is you split your complete
application functionality into a set of
logical labels ok for example feature
and just go one underscore whatever ok
now you have logical labels it is a list
of strings what you have to do is any or
each test you subscribe to these labels
ok each test could subscribe to one or
more labels so that it knows that
whenever I am past the configuration I
have to check that ok these are the
labels which have been passed to me
maybe a bug was fixed or maybe a code
change was based and so I should run ok
now what what you have to do simply is
you have the labels in place you have
the tests and the registration in place
when you configure it as cycle you just
pass on the logical labels that these
are the labels and whatever tests
subscribe to these labels should run now
this is a very easy solution to
implement in any existing framework ok
you can start with a high level maybe
come with 20 labels slowly you can keep
making sub levels of them and you would
see your regression testing framework
becoming an auto regression testing
framework thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>