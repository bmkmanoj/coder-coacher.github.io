<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>OSS Speaker Series: The State of the Linux Kernel | Coder Coacher - Coaching Coders</title><meta content="OSS Speaker Series: The State of the Linux Kernel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>OSS Speaker Series: The State of the Linux Kernel</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JiIl123dz50" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">well thanks for coming everybody how
many Australians are here excellent
and how many over not Google is how many
not Google it's you that's a lot - it's
good to see we have there's still
somebody we haven't hired people from
the real world
myself a bit of background on myself I
started a next development in 1999 which
makes me a newbie because people join
the kernel project never seem to leave I
started out doing some maintenance work
on network drivers and then in the year
2000 I spent pretty much the whole time
just fixing bugs in the 2.3 series I
look on the mailing list try and
reproduce other people's bugs work with
reporters attempting to fix bugs and so
whenever young fella comes up to me and
says how do I get into kernel
development I tell them just fix bugs
because it's a great way to learn the
code I found that you could stare at
code for days and days stared into your
teeth fell out you'd never learn it as
well as when you needed to get in there
and make a change so I always tell
people that none of them ever do it Brad
about 2001 I got a job doing Linux stuff
I was putting the Red Hat's 2.2 based
ext3 into the 2.4 kernel and file
systems and memory management are
terribly closely linked a little mixed
so but inevitably I learned a lot about
memory management that way so when the 2
5 series opened up I did a lot of work
on memory management managed to fix a
lot of the problems I had wrestled with
when doing the ext3 port then Linda's
came along and take me on the shoulder
and asked me to look after the 2.6
series after he had branched off 2.7 of
course we then changed the plan so we
have no plans now ever to open up to
seven series so basically Loomis and I
maintain Co maintaining if you like the
production kernel which is also the
development cone all the to six series
and that situation has been relatively
stable for the past three or four years
now
my talk today is what thought Leslie
politely called a reprise of a talk that
I gave earlier on this year so if any of
you were here were in Belgium who heard
me speak of February you can go go hey
now but it's surprising that when I was
doing my reprise of the reprise how much
stuff had changed us in that two-month
window I've quite a lot of things I
think not gonna do that
a lot of new things came in so kernel
development is pretty a rapid rate of
change of code is very fast a lot of new
things come out very commonly and very
rapidly so the sort of things I was
going to look at today and I've got
about 40 minutes of Stand and Deliver
here I think and probably 20 minutes of
Q&amp;amp;A at the end it's important to
understand my job in the world is to
serve people such as yourselves so it'd
probably be more beneficial if you are
all standing up here and are sitting
down there and you're talking to me
because it's important to me to
understand what people are using Linux
for what their pain points are etc so
please let's use that 20 minutes which
I'm happy to arbitrarily stretch so to
help me understand how we're going in
the kernel and whether we're going the
right direction etc in mind prepare
batter I have some stuff on which
features have recently been merged in
the kernel which we're which features
we're presently contemplating what might
turn up in the kernel over the next
twelve months or so I'll spend some time
looking at who is actually developing
those features and what their
motivations are for doing kernel
development work I'll look at what the
role of professional developers is
people who are paid to work on the
kernel possesses those who do it out of
love loss GP duty and we'll also look at
the private developers and how I'll also
touch on how individuals who are not
paid to work on the kernel but who wish
to contribute to the kernel how they
could most effectively do so
first up what sort of machines use Linux
that's pretty sophisticated or against
here this is probably not really news to
you I like to break it down to four main
classes of machine the servers and the
other large machines which obviously do
database web file and all the other sort
of servicing which goes on a lot of
attention for scientific computing
machines are the really big number
crunchers which are very predominantly
ia-64 based nowadays and most of the
funding for kernel development is still
in is comes from companies who are
interested in markets which use Linux as
a server so it's from the server market
and that includes the hardware companies
Intel I think is most prominently autos
the software companies his customers use
Linux that includes not only the distro
so obviously RedHat and SUSE are a great
kernel developers but it right also in
that categorize companies such as Oracle
IBM you have motivation to have Linux
working as well as possible on their
customers machines and we on the kernel
team always get blamed of being
excessively focused on the server side
of things that's not true we're only
excessively funded by the server side of
things moving down the stack the desktop
machines
I believe it's less commercially
important for major players in kernel
space but to us who actually work on the
kernel I mean we all run Linux on the
desktop and most of the people who very
freely email us are also desktop users
so desktop gets a very high level of
attention even though it's not as
commercially significant as a service
base consumer or what you might like to
call large embedded I think you can see
in my machines they often tend to be x86
so they're basically a glorified PC with
various bits taken off such as
instrument control systems the digital
video recorders
and the PlayStation 3 etc so big
embedded systems if you like the amount
of funding which the kernel development
gets from companies who are in this
space is I think disproportionately
small that's because I think people in
the consumer space are afflicted by what
I will call the embedded problem which
is about three charts are hidden the
fourth category I look at is embedded a
lot of smaller devices listed some here
cell phones PDAs your little wireless
routers televisions I discovered the
other day that I think every digital
television that comes out of Asia now is
Linux based all from Panasonic Sony
Samsung all of those so I discovered my
new flat-screen television as a Linux
box and I didn't know I can press my
kids it works
camcorders lot little camcorders
nowadays are running Linux a very old
version of Linux but they're running
Linux and the handhelds these tend to be
not actually from the manufacturers it's
people who've grabbed a handheld and
then ripped out whatever was on it and
put Linux in it the very smallest
devices which run software are things
like things like television or remote
controls and the garage door openers run
software I don't know that those things
are not addressed by Linux there tend to
be much more specialized and I think
Linux is always going to be to
heavyweight to get into the very
smallest embedded devices most of these
embedded systems they're usually non x86
they often use a very cheap
microprocessor a microprocessor which
doesn't even have a memory management
unit in it
and they generally won't have a rotating
disk of course a lot of them will have a
flash disk and matter funding which we
on the kernel team get from companies
are doing embedded development is
disproportionately small and maybe it
was four shots ahead but we'll get onto
and looking at what company's
motivations are at a fun development of
the Linux kernel I think there are three
main categories here there are the
hardware companies the people who
actually sell adapters motherboards all
that sort of thing
which their customers wish to run Linux
on and obviously they want Linux to run
as well as possible on their hardware
well the software vendors the IBM zero
calls the Red Hat's and all the rest who
sell software and services to those
customers who want to eliminate the door
that has Linux in it but the customers
generally won't even see it
I'd be a critical difference between
these groups here is the hardware and
software vendors their customers have an
expectation that they will be upgrading
the kernel version across the lifetime
and we all know we've gone from Fedora
core 5 to Fedora core 6 or l4 or l5 etc
the customers expect to have to do that
and their providers expect them to have
to do that I think this is a critical
difference that reflects back on the
funding situation these companies have
worked out if they want to get new
features into their customers kernels
from your hardware support new
optimization features etc turns out
finally after many years everybody's
worked out the best way to get new
features in to end customers hands is
via the kernel or dog kernel used to be
the case back in the 2.4 days for a
number of reasons a lot of companies
would just get their drivers straight in
the Red Hat kernel straight into the
suzer kernel and they have no real route
up into mainline that all changed things
nowadays people are much better many
companies are much better against
working against mainline and this has
been aided by some policy changes at the
major vendors particularly Red Hat
nowadays I just have a strong tendency
of hardware vendor comes up and says
look at our driver they'll say no send
it Andrew send it to lineThe send up to
James
and everybody's being very good about
that I think the overhaul both quality
and consistency of the kernel has been
added for benefited from that process
and the fact that people have worked out
the best way to deliver features to
their customers via kernel elorg
that has helped us get funding for the
kernel development mainly in the form of
salaries now some of the device
manufacturers not all of them they also
have upgrade plans for example ps3 that
I expect they will plan on revving their
kernel sometime and future company I
previously worked for djao who make
personal video recorders also they
upload their kernel version during
development to pick up the new features
which are coming out of kernel at all
whereas for embedded companies I think
the critical difference with an embedded
company is once they ship the product
they have absolutely no plan whatsoever
to approve the kernel so if you're
making a camco
camcorder you'll golf and grab a two
4:18 kernel or something perfectly
ancient like that customize it ship it
and you'll never upgrade that current so
because you have no plan to upgrade the
kernel on your device you really have
very little motivation to get your
features your changes fed back through
the kernel or dog kernel and one of the
main reasons people do that is the cost
optimization so they don't have to
permanently maintain the patches and
retesting every time you dump it on
Linux and Co and they look after it for
you
but that argument doesn't apply if you
never intend to take that kernel back
now from kernel at all other reasons
were obviously relatively low funding
from the embedded side of the world is
it's a hard scrabble life
the timelines time to mark is extremely
short and there's not a lot of money in
it the major in what we do so obviously
see some involvement from embedded
companies and I think a lot of that
comes not from the people who actually
shipped the products as much as the
people who ship components
to them say for example ah they don't
make embedded products but they have
commercially made of a commercial
motivation have Linux run as well as
possible on arm based machines so they
can pick up as many device manufacturers
using Linux as possible so arm do as an
example do fund a Linux development for
that region so despite the fact that
embedded is under represented in the
kernel development community will think
it's cool that so many devices out there
all the cell phones and television sets
running Linux and so even though a lot
of people who work on the kernel they're
not really funded to work on to make
embedded better we we do care about the
quality of embedded support and we
always review those big service patches
with an eye on what is the impact of
this on embedded will it hurt or are the
users
switching topics now this is basically a
very partial overview but some of the
things which are happening in the kernel
development at present what I think is
going to happen soon who's doing it why
they're doing it and other stuff it's
always hard for me to predict what's
gonna be in the kernel and six or twelve
months time I have no stuff I can't I
don't have a quarterly planning meeting
where we sit down and work out what the
what features are going to develop over
the next 12 months and assign heads to
them so all I can say is what I see
other people working on there people who
do have engineers working for them I
find it on the grapevine what they're
working on and so my prediction is just
based on what other people tell me they
plan to work on on the server side and
if any band is huge a lot there have
been a lot of changes going in and large
amount of changes continue to flow
through in a surprising amount of work
happening on core networking new
protocols which I never knew existed are
appearing in the stack and a lot of
refactoring and restructuring of the
network code base goes on new
implementations of TCP flow control say
entire new protocols sitting at the IP
on top of IP etc storage I think most of
the activity at present is in serial ata
scuzzy in some ways is a bit stalled
because of the sheer complexity of the
scuzzy stack having to support so many
old crufty old hardware and crafty old
drivers that sit on top of them and when
we look at things like serial Attached
storage people are seriously considering
bypassing the scuzzy stack to a large
extent to avoid all of that legacy
tremendous amount of work happening in
Umarov the past two or three years it's
very much been driven by SGI who
recently I believe booted Linux and
4096 CPU machine but a nice thing about
the work which SGI is doing to improve
Numa is that it's also beneficial for
the Opteron machines locked ROM machines
which are also NEMA and it tends to be
the case that an uma and Vance Minh if
it's a good one will also help pass
scalability and performance on a boring
old multi-core or symmetrical multi
processing machine virtualization
obviously as the great war between Zen
and VMware which has been going with
about three years and the war between
Zen and the kernel team and the wall
between everybody and everybody else and
that becomes KVM and they got in first
KVM came out of nowhere but israel
actually but metaphorically no way and
was an easy merge VMware support has it
appeared in two 6:21 which was released
a week ago I expect support for Zen
domain you will be in - 622 although
it's being a bit of a difficult birth at
present and of course rusty Russell
decided none of that was any good and
went off and write his own
implementation of both the hypervisor
from the it's Linux on Linux so he has a
very simple client host side and guest
side and no versioning between nor
anything so if you try and run at to 620
guest on a to 621 host it won't work but
it's basically L guest is supposed to be
a minimal skeleton how to do it code
easy to hack on and I'd expect our guest
will appear into 6:22 tremendous work
going on in containerization this is a
very difficult topic because it means so
many things to so needed from people you
have the V server the virtual server
type people who want to take a single
machine and partition that up against a
couple of hundred different customers
who are all run their own version of
Apache and stop by everybody else's
version of the pageant
on the other hand you have the
enterprise guys who want to have
resource management so you can have your
your backup suddenly fires fires often
you don't want it to cause excessive
latency from your database query engine
so you want to be able to partition
machine and avoid interaction between
different jobs running on the same
machine
so that's resource management other
groups of people apparently there's some
time between containerization and high
availability which I've never understood
I think partially it could be do with
migrating migrating jobs from one
machine to the other so whole budget
people with different requirements all
of which fall under the category of
containerization and the requirements
are a little bit different their
implementations a bit different and a
lot of them have gone a long way down
the track of having implementations I
mean the openvz guys they've been
shipping the product to many customers
and they've got hundreds of thousands of
machines are running openvz
so their ability to accept the changes
which other stakeholders are going to
force them on is it's pretty limited
because they obviously when most Beco
gets in the kernel adorab they want it
to be regionally compatible with what
they're already shipping so we've been
dancing around the containerization
issue for a couple of years we are
converging I think most of the
stakeholders are playing together quite
nicely but it's a complex problem some
of the bits and pieces have gone into
the tree the many in terms of
virtualization of particular global
resources within the kernel and right
now everybody seems pretty happy with
poor Minaj's patches Paul's at Google
he's done some work on this and unless
somebody makes serious objections for
that approach I expect we'll be going
down that track using pool stuff and
then let everybody else build on top of
that
resource management I touched on before
this is the ability to not have one job
running the machine trash another one
get some degree of quality of service
between different unrelated jobs IBM for
many years was pushing su-kam the kernel
class-based kernel resource manager and
that went through many generations each
one about half the size of the previous
one in response to what we politely call
feedback to reach the stage where it was
actually quite a sane looking patch set
but now most of their developers they're
slotting in there or slotting in behind
the containerization effort which will
pretty much meet their requirements if
and when we ever get them k exact and
kdump kdump is important enterprise
feature it's the ability to generate a
kernel crash dump it kernel goes up
Siddal then go and spatter its guts on
the hard disk so that we can then pick
up the result after the reboot and
analyze why the kernel crashed there
been numerous implementations have done
this done out of tree all of them
involved the crashed kernel writing a
copy of itself to the network or to disk
that was generally never acceptable to
us Luna's always thought it was stupid
you had it you have a kernel which is
already toast to attempt to get that to
write to disk as a very dangerous thing
so we took a new approach and it was
completely vaporware but we decided to
do this two years ago kernel summit in
ottawa to use k exec instead k exec is
ability for linux to load a new copy of
the kernel into itself and jump to it so
you can basically do a reboot in
fraction of a second where we modified
care exec was that once you jumped into
this new kernel we would leave the old
kernel alone not touch that memory and
then in the new kernel we have a little
slash dev mode which you can access all
the old kernels memory so the kernel
will crash will then jump into the
preloaded new kernel and then the new
kernel which comes up fresh clean hasn't
trashed its data structures that kernel
will then write the crashed kernel to
disk or across an
and that's been merged a lot of people
are working on it and the various
vendors enterprise people are slowly
slotting behind it my secret plan with
kdump
is I would very much like we developers
on the kernel team to be able to get a
crash image from people whose goal has
gone tits up because at present all you
get is loot streisand it's always were
draped and and you don't have the symbol
table it's very hard to work out exactly
what line you're crashing on etc so it
would be lovely
one day when someone's Colonel crash
they can say oh it crashed and by the
way here is my crash dump so you can
then fired up in gdb and have a look at
the data structures so I've UK done even
though it's an enterprise feature it
could be quite useful for the general
kernel development effort and now I'm
not interested in people's page cache I
don't want to see your password files
and whatever else you have in memory so
we expect kdump will not dump that part
of memory which is the great bulk of
memory we're not interested in user user
data we're only interested in kernel
data K probes that stability effectively
of a kernel module to set a trap point
somewhere in the kernel and main reason
for that is for advanced instrumentation
it's supposedly our answer to the
Solaris D trace feature system tap is
the user space component of that and
it's supported by Red Hat and various
other vendors the way it works is you
you write a little script in a funny C
like programming language can you feed
that into system tap tools which then
will turn it into a kernel module low
that module into your kernel and then it
will hook itself into the core kernel by
inserting trap points using the K probes
facility and then we have high bandwidth
interfaces coming out of that module to
user space so if you want to get in and
say I want to trace context switches or
I want to trace disk i/o or trace dip
this particular line you can do so all
in this programming language which
systemtap provides
I think it has pretty graphical user
interfaces and things as well
difficult project but the vendors seem
committed to it seems to be going fairly
well ext4
I think file systems generally is slowly
turning into a weak spot for Linux ext3
is but slow good I believe has limits on
device sizes and it's just generally not
particularly 21st second century
technology the xt4 is well XFS I think
is generally a better file system
it's creepy how well XFS can do file
layout for the high-end machines it is
extremely good there are and there have
been various times when we found
problems with ext3 or where somebody
tosses are really truly were clear that
it does really bad stuff I think aha but
XFS can't do this and damn it does every
time so a lot of work has gone in Exodus
it's fiendishly complex and nobody
understands it
unfortunately the vendors for which we
mean principally Red Hat and Sousa seem
very reluctant to support except s I
think the reasons for this are they
don't have any engineers who can
understand it and the attractive thing
about ext3 is that it is understood and
supported by engineers from a lot of
different companies so as far as I can
tell all the vendors have decided to
hook up behind ext4 rather than
investing in XFS ext4 has all the new
features extent base allocation it will
have delayed allocation it large device
support etc I don't there's any reason
for thinking it would be a lot faster
than ext3 in a lot of cases but it
basically for certain easy workloads and
for large devices it will fill the gap
that I suspect will still have
significant performance problems with
significant workloads on the XD for
basically I think we need a new file
system
I just don't know where it's gonna come
from very simple multi-core people yes
Daniel ZFS I could talk about son at
length if you like um well ZFS is the
licen licensing incompatible so one
would have to start again
things were doing for desktop machines
hot-plug ability or actually it's like
then crash ability hop like a being
hopping of CPUs and modes and memory is
not a desktop feature that should have
been on the previous chart which I
apologize hot-plug ability obviously has
many things like a car bus devices
firewire devices and USB devices all the
work going on power management it's
still pretty stupid about power
management we said really support I know
two states that's often on I suspect one
day more pressure will come upon the
operating system community due to have
smarter states than that like if my
network card hasn't sent any packets for
the past ten milliseconds well why is it
still fully powered up but I really
haven't seen any threat that we're gonna
have to do that yet but I expect it'll
happen one day
just bring devices into a lower power
state which is not off we don't have
much infrastructure support for that
we're having trouble getting off and on
working
it's always the biases faults never
alphabet' framebuffer drivers it's one
of those subsystems I know nothing about
it just enormous amount of activity
coming out of the new drivers a lot of
maintenance work or fix up happening
there
we have a wonderful maintainer Tony de
players who is a physician living in the
Philippines there's no interest in
working for Linda company just simply
spend all this time ignore his patients
and working on frame buffer drivers he's
great
direct rendering drivers this is the 3d
stuff obsolete all sorts of problems in
this area to do with lack of
specifications and certain close source
drivers from certain companies again a
great maintainer there David le is of
course in Australia doing tremendous
amount of work been the input system a
whole plethora of input devices popular
source of crashes and hangs and things
like that but again a lot of development
there strong maintainer sound is taken
care of by a couple of Sousa engineers
with the ELSA stack USBs got about a
thousand different developers each one
about a thousand devices to take care of
1394 the old fire worse tech this has
been a problem child for a long time he
used to be a long time at running fire
wire on SMP was a good way to reboot
your machine but Stefan's done a lot of
sterling work there and a new fire wire
stack and I think a complete new fire
stack was central in us for moving today
but I haven't checked whether actually
most it so the plan there is to take the
new fire wire stack build it up to the
same level of function old as the old
one and then throw the old one away and
even though the kernel API is a bit
different they assure me that everybody
uses user space library and will be API
compatible at that level so if you're
programming directly to the system
called API sorry you should have used
the library anyway
a lot of our work with the desktop
concerns latency this is what I call the
squeaky wheel problem where people who'd
never say oh that was 100 millisecond
glitch I need to email Ingo and Andrew
and everybody else at that my hundredth
of a second glitch so we have a lot of
squeaky squeaky gates and on the mailing
list and so a lot of work happens this
is people who complain a lot
squeaky gate gets the oil so a lot of
work is happening with interactivity now
I must admit I had a report the other
day that guys machine went to lunch for
20 minutes so he had a right to squeak
but not all of our interactivity
problems are that bad but we continue to
work on the interactivity and this is in
three main areas the i/o scheduling
generally the prioritization of reads
versus writes on the disk our dirty
memory write out policy which right now
I politely say is optimized for
performance rather than latency and the
CPU scheduler which everybody always
seems to have an opinion about even if
they don't have their own version of a
CPU scheduling dirty memory right out is
I think probably our biggest problem
there are certain situations in which
the kernel will perform very badly it
doesn't just affect just desktop
machines that can also be a quality of
our service issue for server class
machines several people are working on
that from totally different directions
and none of them are quite got it right
yet it's a tough problem the other thing
when people say oh you don't care about
the desktop I'll tell them we put in
identifier I haven't actually done any
work on I'll notify or F notify for the
past year or so but it's a fancier way
in which the kernel can deliver
notification to use a space that's a
file has changed or been added or
deleted or read from so that you can
update it in your little GUI window few
technologies going in that are more
targeted at the smaller machines
consumer and embedded the ones we
emerged into to 620 of course of the
dynamic ticks and hores timers
I used to work AIX guy his jaw hit the
floor when he found out the leaks are
still doing interrupt
retain memory second says why you do
that if there's nothing to do what's
hard but it was hard but now we do have
dynamic tics which works on some
machines but it's very good at forming
back to the old scheme if it doesn't
work out and it will basically the whole
machine will go to sleep if there's
nothing to do for another 1.1 seconds
the whole machine will just go to sleep
and won't wake up for 1.1 seconds rather
than waking up every 10 milliseconds and
leverage on the back of that because we
are now have instead of program your
timer to go be 10 milliseconds we
program it to go off exactly when we
need it this gives us much higher
resolution timers than we previously had
so we've gone from the 10 millisecond
resolution down to something pretty
arbitrary depending on what you are a
clock our Doyle support the people who
are really crying out for this were the
One Laptop Per child who do not want to
wake their machine up every 10
milliseconds and it's a significant
power saving for the OLPC but a lot of
embedded systems are really aggressive
power requirements do like that feature
2 6 coma I think it has got better I
think this smallest build you can do on
a tiny little unit process machine is
still a bit larger than 2 for Colonel we
are concerned about it we do continually
try to counteract it but they just these
things happen it's been a very slow
growth one thing we put in recently
finally was the ability to just make the
whole block layer go away the entire
support for block devices and buffer
heads and disk i/o and all that sort of
stuff you can just disappear that
completely from your kernel build if you
do not have disks in the system
no MMU support support mm ulis machines
is being maintained mainly by Dave house
at Red Hat and as far as I know that's
working well funny little CPU
architectures keep on turning up frv AVR
32 from I forget who that's from
Blackfin comes from hat mill that will
be in - 622 a number of these no MMU and
some of them are either no me or MMU
various bus technologies and i/o
technologies that happen spi being
actively maintained by people who are
also working in the embedded area very
important to embed it is Ingo Molnar
real-time tree which is a separate patch
set from the kernel which contains all
sorts of features in a panel it does
real-time hard real-time very well but
I've been a lot of technologies that
available out of tree and add-on monster
patches or little operating systems
which run underneath Linux news Linux as
one of their applications but I think a
lot of those are sort of falling by the
wayside now as the serious real-time
vendors of are actually shipping in goes
tree and as we're gradually moving
features a Domingos tree into a mainline
kernel a lot of things that come across
the mingoes tree it's sort of a testing
ground and I'd imagine at the end of the
day if we can merge things faster he can
write them will actually get most of the
real-time tree into the mainstream
kernel but one feature which you may
have a little bit of trouble putting in
is one feature Ingo has is all the
interrupt handlers for all the devices
actually run within tasks contexts so
we'll take an interrupt on they all just
basically cloak a task and them a task
will run the interrupt handler rather
than running it synchronously within the
interrupt that's the sort of thing where
Linna says no no no no no we'll never do
that when we see the patch we'll
probably end up doing
what we said about this is that about a
simpie forever sport assembly so I ain't
guys putting up these things I'd imagine
when he finally gets down and presents
the patch to Italy yeah that's not so
bad
instrumentation I think this is a weak
spot in the kernel particularly for the
sophisticated enterprise side of things
people who really want to know what's
going on inside that kernel we do I
don't think we expose enough stuff to
the sophisticated program is to help
them understand what the kernel is doing
to them and why it's doing it features
are going in at a steady pace if not a
high pace we recently put in perta
statistics called task stats that's a
fairly major change what ty stats does
it'll basically when a task exits it
will grab a little packet of information
about 30 40 fields about how much run
time it did and all sorts of things like
that and deliver that across the net
link socket connection up to a daemon
which is monitoring tasks stats is
designed to be very scalable for the
high-end machines the important thing
about start test stats it is now it is
now our future way of delivering per
task instrumentation out to applications
and already one fine programmer namely
myself added per task accounting for i/o
into tasks that's so I was able to just
stick a few more fields on the end so
when a task exit you can find out how
many how many bytes of i/o it caused to
be read and written and that was very
easy to do also touch debts you don't
have to wake the TAS to exit you can
actually query a presently running tasks
and get us cameras out of it so for
ongoing monitoring another thing we're
working on is per process memory
footprint monitoring that's a fine term
isn't it it's very difficult people want
to say well how much memory is my is my
process using it's been running 24 hours
I can see the resident sets
is one point five gigabytes well how are
just really using search me we don't
have any way of knowing so we had a
little brain wave here what we do is we
go into the kernel and for every page
which that process owns we'll just go
and clear all the reference bits and
within the page table entries so now as
soon as you've done that you can then go
into the process and count up how many
reference bits that's it so immediately
after include them or you expect none to
be set but as your process goes off and
touches pages touches pages you'd expect
to see the number of reference bits go
up across time so you can so the
programmer the system administrator that
can they can get some idea of how much
memory his process is really using
rather than how much it actually has
allocated so that was good but in fact
were brought to you iGoogle but now Matt
McCall has gone to totally turn that
upside down and has developed new
interfaces for the kernel which let you
get access to every single page frame
within your process to find out whether
your page is reference for the rich the
dirty and what sort of page it is etc
very low-level interface might change at
any time in the future so we changed
kernel internals but I think anybody
who's sophisticated enough to use this
interface will be able to cope with that
but it's something we've always lacked
it'll do quite a lot of user space
development to be able to use these
interfaces you need quite a lot of
knowledge they should give great
transparency into both the static and
dynamic memory behavior of applications
perfmon there was once upon a time a
thing called perfect counter which gave
us access to your processor CPU counters
the ones which Intel AMD and IBM etc
givers perf can have died and now
perfmon is the way ahead it basically
does the same thing it's already
implemented in the mainstream kernel for
ia-64 tremendously large patch which
then gets a gives us access to all of
the or hopefully most of the
advanced performance scanners on sort of
the AMD Intel power I think several
other architectures various states of
support the perfmon is taking a hell of
a long time to get into the mainstream
kernel we had a decent round of review
about six months ago and things went
quiet but we will get there eventually
but it'll be pretty important interface
for people measuring getting detailed
information about the behavior of their
applications things happening in the
kernel core Kay event this comes from a
gentleman in Russia somewhere who came
up with a scheme for anything which can
generate an event in the kernel and when
you go through the list there's an awful
lot there's TTY IO and file completion
and socket completion and timers going
off all sorts of things had a unified
scheme where the kernel would place a
description of the event directly into a
user space ring before and send the wake
up to the application which is waiting
for it so that's basically for your
threaded service we have a whole bunch
of tasks or wedding on the one ring but
they pick up an event runaway handle it
come back wait for next one so Kevin I
think it reached version number
forty-seven when he started to get a bit
dispirited we never quite got over the
hump I was never to find quite enough
people who actually sit down and spend
the time to review it I couldn't get and
it's a major interface very important
thing and I couldn't quite get enough
mindshare behind it so then along comes
a crown from Oracle and proposes
something completely different
rather than having new event reporting
interfaces how about we just make all
system calls asynchronous so if if
instead take a read from disk what you'd
like to do is they start the read now
and tell me when it's finished its
acquires new infrastructure to be put
around the read system call but with a
synchronous system cause what you can do
is say run some arbitrary system call it
happens to be read and tell me when
that's finished
every theoretically every system call on
the kernel becomes asynchronous and this
basically solves the whole problem
because you can take all these old
synchronous system calls and not have to
wait on them so it's a nice idea so that
came out with this and that got Ingo
coding for about 15 when it sort of came
out with a massive patch that which did
it in completely different way I woulda
called his version of that sis 'let's
don't quite at present because he's
disappeared into the CPU schedule a
black hole for a few weeks but I'd
imagine that when he comes out of that
black hole we'll start looking at sis
let's again and it was looking pretty
positive but wouldn't surprise me if
maybe towards the end of the year we do
have some asynchronous system called
implementation in the kernel foo Texas
that's the kernels basic synchronization
primitive which allows you to implement
user space locking in which you've don't
enter the kernel at all in a non
contended common case lots of things
happening here we recently merged an
implementation to basically a simpler
version of food X's which didn't have to
support sharing between different
heavyweight processes so that's an
optimization and I'd imagine that while
I'm planning on merging that under T 622
people work on 64-bit food X's priority
inheritance on Felix's as well what our
work happening there and it's all well
supported by the G Lipsy guys who to a
large extent driving the changes in
footings adding a new Moto M advisors
not exactly a world shattering thing but
it's a really example of the the little
incremental changes we make in the
kernel to attempt to improve the
situation user space there are some
performance issues with melt in G let's
see which is function it gets used quite
a lot so we've been working that with
with the G let's see developers and now
there's an implementation in Maya tree
of a new mode - in advice which Mallory
News to optimize this internal functions
plan to get that into to 622 as well
David lesney came out of nowhere and
buried me in patches which is an
alternative decay event in which we've
got these various objects in the kernel
of which generate asynchronous events to
an instance here are signals and timer
expiry but there's no way you can select
on them so if you've got an application
which wants to either wait on a select
on a socket or on this timer going off
on the signal coming off you enter home
to do a signal based implementation
which tends to be messy and slow so what
David's cut with is a new sort of file
descriptor which will when a timer goes
off the timer will be delivered to you
across the file descriptor so you can
just add that particular special file
descriptor to your select set and it
will come up and say hey here's a timer
for you and that's looking like to 6:22
material as well gee Munsell debug
ability it's important to us we don't
all work in one building and talk to
each other from 9 to 5 kernel developers
kernel testers that are all spread all
around the world it's very important to
us that the kernel have a lot of self
checking self consistency checking and
also a lot of infrastructure in there to
help the developers who are 12 time
zones and 5,000 miles away from the
reporters find out what the heck went
wrong Ingo did the locking dependency
checker recently that's pretty
sophisticated thing that will monitor
the order in which various types of lot
taken and develop a dependency graph
between them and later on if it sees
some locks being taken a different order
with incorrect dependency will report on
it so you have a potential deadlock here
originally modes a framework for
deliberate injection of thoughts so you
can if you're designing a device driver
you can wire it up to this library and
deliberately poke faults and your device
to simulate memory allocation errors or
checksum errors or anything like that
nobody's using that yet
Colonel debuggers everybody thinks we'll
never have a debugger in the kernel
because Linda's said no I think I can
talk him around my preferred option
there is K gdb the only other options on
the table really a KDB which i think is
too low level it doesn't understand the
source code and the Novell debugger
which the patch is pretty scary-looking
k gdb I would have measured years ago if
it really had somebody is prepared to
stand up behind it and support it long
term but mobis really been on offer yet
however there have been some changes
recently which are optimistic looking I
could get cagey to be back in my tree
within a month or two I have it might be
on the way to mainline cleanups they
drive everybody wild people go in and
they make factions static and they fix
up your white space and they take out
your includes and they add new includes
everybody hates it but and it does
sometimes it breaks things sometimes I
get nasty grams from the developers
saying hey you broke my code but we grit
our teeth and bear it because we do
expect the Linux kernel code base I mean
when are we finally going to delete it
probably will after my career's over
it's gonna be there for a long long long
long time we understand we're in it for
the long term the clarity and
maintainability of the kernel is an
important asset so even though there are
short-term cost we do believe all this
cleanups
of long-term benefit and certainly when
you go back and look at the 2.4 tree say
yeah did we do that things have got a
lot better so yeah we merge them we had
it immersion because we feel we need to
do so things I don't know about yet
people just pop out of the woodwork with
features which I never expected Kay
event was one case there KVM of course
is the classic from the recent last year
people have a brain wave them cut for
something and sometimes it's somebody
you've never heard of
the curious thing about KVM was that it
came from a bunch of people would never
heard of but it was very clean and very
Edom idiomatic kernel code it looked
like the guys have been working in
Colonel amperes but it was as far as I
know their first submission that was
such an easy merge so it's a pleasant
surprise
colonel contributors the greater joy to
Colonel work now is done by people who
have paid for it
most of them deserve to be paid for it
the middle but the private contributors
are still important they're not as
important as they were ten years ago I
don't think but I'm they're particularly
important in desktop related development
because they're doing thing because they
mainly desktop users and they're doing
things which matter to them and
oftentimes you get somebody as a
contributor and you don't know who they
work for they may hide behind some email
address and you find out oh I've been
working for Intel for five years Oh have
you and I'd say a lot of these people
for any good they don't stay individual
contributors for a long people tend to
snap them up the area where non
professional contributors best
contribute is of course in testing there
are lots of crazy people who are
download the latest snapshot Colonel is
the latest release kernels or even the
latest mm kernels for one I inflict on
the public and just test it
find out what any problems are and
report on them
these people are indispensable of kernel
effort if these people didn't download
and test development kernels the whole
project grind to a halt I don't
exaggerate that reason being I mean
you've got a core of one or two hundred
kernel developers which means they've
got a core of five or six hundred
machines to test kernels on those of
them who do actually test stuff
but that's only such a tiny subset of
the machines we actually need to run on
so people will get their code and test
it beautifully I mean I used to
allegedly still maintain the freak on
network driver I only had a stack of
NICs this high the device is supposed to
support 23 of them and then you get
interactions with various PCI issues
interactions that are with ACPI
wake-on-lan the number of combinations
is awful so we're very much dependent on
the external testers because they have
different hardware from what the
developers have and because they'll toss
different workloads at it seems that a
lot of our useful tests as the guys who
are like working at an ISP and he's
supposed to be looking after his
customers instead he's loading the
latest scalable Carolina's production
machines I'm not complaining you punk
lab don't work for me
a lot of them quite sophisticated users
and they just great and can't thank them
too much but if you're - fine people
want to help the tribute for Colonel
effing testing is an easy and extremely
valuable way of doing so so this is my
astronaut what the colonel can do for
you but what you can do for the colonel
slide how to test the Linux kernel if
you're brave enough to compile your own
kernel you'll grab the latest snapshot
from the snapshots directory i'm colonel
a dog and i think it's linked off the
front page
and just use it people say oh should i
run benchmarks should I run Bonnie
should I do this I don't think so I
think it's valuable of people just use
the kernel in their day-to-day use it
works ok fine if everybody does that
worked ok for them we're done nothing
special needs to be done testing
probably I think once a week or once a
month the suitable interval to update
your kernel and keep an eye out for
things which are going wrong Fedora open
SUSE very nicely they put out a bleeding
edge kernel I'm not sure about the
openSUSE one but the Fedora kernel is
generally no more than one to two weeks
behind the kernel a dog kernel very much
in sync with the kernel
colonel and we do readily accept bug
reports against the latest fedora
colonel they're almost always also bugs
against mainline and the nice thing
about that is you can just grab the RPM
which they put up there for you and
install it without having to build the
comb if it doesn't work great if you do
have a problem reporting it is the
greatest value often developers will
Gavin come back say well can you please
try this patch or that sort of thing a
lot of people can't do that because they
just downloaded the RPM they're not
interested in building their own kernel
that's when we get in a little dialogue
with Dave Jones to get him to add the
patch so it comes back down via that
route but actually reporting a problem
is the main thing when reporting the
problems the best way to do that
particularly if you well if you're
testing a leading edge a snapshot kernel
some development kernel reported via
email be careful about who you send it
to make sure it gets Linux kernel and
also to the developers and the relevant
mailing list and if it's a long-term bug
like give youth right now we just
released two 6:21 if you find a bug in
two 6:19 or something like that it's
probably best to go straight to bugzilla
kernel a dog to raise the report there
so what we do what I prefer that we do
is the short term hot bug fixes for code
which is still in people's mind let's do
that by email generally we can get it
resolved within within a day or so if it
looks too hard if it's been there for a
while I'll push bugs into Bugzilla for
longer-term
tracking those people who have built
their own kernels if we can talk them
into it they will use gits but the
source code the revision control systems
bisection feature so you can actually
say yep - 6:20 unworked
- 6:20 worked - 621 didn't work and get
you can then just say yes that works no
that doesn't bisect through all the
change sets in the kernel can you come
down to a particular patch which is the
one which broke your machine
it's wonderful when it works sometimes
it doesn't work because get it doesn't
have a linear sequence of patches it has
some complex n-dimensional graph which
I've never understood so git bisect will
sometimes get stuck close to but not
exactly on the buggy patch but that's
still useful news chances are it's
pointing an ACP eye patch it normally is
so then we can tell Lin look one of
these hundred patches yours is broken
you're fine put it in Bugzilla in a
couple years time it won't be fixed
but if you do get stuck on git bisect
people come talk to you through how to
get over the hump and actually get down
on a particular change set so git bisect
has been very useful to us and a lot of
people people you've never heard of
before Canton say I bisected it down
this particular patch and it broke and
that's so good bye-bye patch or send a
nasty grin with originator that's it
from me my forty minutes went for 59
minutes questions and answers please
and it's important you tell me things I
need to do I need to know rather than
having me tell you things you want to
know yes sir did not talk about that the
funding situation with embedded systems
well that was all my waffle about why
they're not motivated because they don't
have plan to upgrade to new colonel
means they don't work against kernel.org
you see a lot of people go to various
conferences and stand up in front of the
embedded people and tell them how to
interact with the colonel community etc
but the message doesn't seem to be
getting through very well they just they
don't have commercial motivation to do
so then ZFS excellent yes
yes only anecdotal data the problem with
XFS is well as a long-standing problem
with XFS in that you're using XFS your
righteous and files your machine goes
you bring it back up and that file now
has zeros in the middle where you'd
expected to see data what the way ext3
gets around that is it writes all you
every time it runs a journal commit
every time it writes out your files
allocation information it'll write the
data first
so writes the data out then it writes
the metadata which refers to the data so
if you get a crash bus recovery you
don't have metadata referring to data
which hasn't been written yet
Exeter's doesn't do that it's a metadata
only journaling so XFS it'll if when you
do write to a file it'll dirty the page
cache then it will write the metadata to
the journal first and then if you crash
you have metadata in the journal which
refers to data which hasn't been written
yet Steve laws many years ago that
should be no no no no that doesn't
happen because of waffleh waffleh
waffleh but it does happen and people
regularly complain about it yes files
will come back with zeros in them or
make surface I think we can fix that but
to do that I know exactly how to do it
you need to take over the MM tree for me
so I'll get time to do it I have to
describe how we should do this several
times but nobody's picked up the ball
and run with it yet but we can solve
that in the VFS simply by doing a
sophisticated F data sync before we run
the metadata commitment it's basically
it's ordered mode for XFS but nobody's
done
was it very little
I don't read anything useful to say
about CFS I see people seem to regard it
well it's very unknown exceeding that it
obviously Linux separates the concept of
volume management and filesystem growth
from the file system itself we like to
keep these things separate rows I
understand ZFS does a lot of these
management roles internally within the
file system that make me that might make
sense I just don't have the experience
or knowledge to say if it's if it really
is if it does come out under a
compatible license yeah wouldn't
surprise me somebody got in there and
did it
common infrastructure for TCP offload I
don't think I could say anything
intelligent about that I know David
Miller traditionally has been very anti
TCP offload mainly because it does
things such as bypassing things which X
people expect women to have such as net
filter and various other packet ingress
egress filtering options but that's as
much as I know I know David doesn't like
it a lot of people have tried they
haven't managed to get past the David
humping whether that hump is being
smoothed out nowadays I do not know
Raisa three is obviously it's kind of
moldering nowadays it doesn't perform
very well not a lot of maintenance is
going into it
most of the maintenance that goes into
it manages to break it rather than
improve it I'm afraid but there are a
few people who work on rise up three but
it no it doesn't really seem to have a
future
Rosa four has been in my tree now for
about two years obviously your hands had
a few personal problems which has
impacted Rises rise of force development
but I'm still getting paid just for it
and a couple of the name sis engineers
from Russia are still working on it I
think in an unfunded basis and so I
wouldn't rule out the possibility of
Reiser for getting merged it needs a bit
more work done into it needs to get a
little bit more mindshare in momentum
they had a bad reputation from several
years ago where absolutely had the
kitchen sink
everything was in erisa for always going
to be in Raisa for all those plans are
being wound back a lot a lot of code is
taken out it's much more regular file
system than it used to be so I haven't
stuck my nose in there for every year I
measure what we have there is closely
being merged well than it used to be but
the barrier there's a pretty high
barrier for merging file systems in the
Linux there's significant maintenance
cost for everybody involved we need to
handle bug reports is the interaction of
the VM which is often complicated and
affects the memory management developers
so it's not the sort of thing you can
just slide in and think I will let them
take care of it because it has impacts
on the rest of the kernel and other
people so we testing is very nicely put
out late again she could not Rebecca
Salem Oregon with Jim Beam no more than
one to two weeks behind the camera vodka
very much a secret
and we do readily accept bug reports
against the latest always and the last
thing that is you can affect the up
again up there for you and reporting it
is the greatest company in the morning
mr. bodeaux around Telmo that's when we
get in a little bar with a chance to
indirect effect any bar that yeah but
Hector reporting the problem is than
anything when they're going the problems
this way to do that particular if you're
testing a leading here's a snapshot
kernels of them reported by email became
that incentive to make short resolute
external and also to the developments in
the row of loneliness and it's a woman
both like right now we just won a bucket
into six nineteen or something like that
probably just to go straight to my
village
the bicycle sometimes gets stuck closed
movement on exactly on the buggy that's
still useful you get stuck on git bisect
people control you through how to get
over the hump
next we get them so they get by second
thing very useful to us
the funding situation with embedded
systems one left a little more hopeful
about whether motivated because then if
anyone can be gentleman I won't think
about the various compositions end up
kind of the until happened
see
in the
we can solve that innovators simply by
going to stay there basically
I started my first kiss
possible that if
Owen is welcome to be awkward I don't
think I was like
so while we're on the subject of file
systems the other costs that had to be
paid a couple years ago was resurrect us
what's the starting with that is it
still being developed our runs a fleet
is it's coming over in there they look
for very well-known automates going into
it most improvement
what does it for this being my training
after that two years hopefully your
hands up if he person allotment is
infected by us develop muscle memory and
our nicest engineers from
temporary protection for 70 years ago I
actually have the kitchen sink was
generosity less depends on the
environment whether the water is taken
out a regular file system used to be
there's possibly but the barrier this is
pretty high very of emerging processes
with Linux on this maintenance cost for
everybody involved
we've handled bike reports with
interaction with the ending the memory
management abilities so it's not sort of
thing
my favorite arbitrary positions
and most of our users can't really
explain to them what next card is all
about and training to arts and then
their program will pay off Isaac with
the director happy people of 10,000
files and we responsible but is there
any chance we can simply get widows
or at least heaven be simple sides or
like the end
recycling processes the command line
length limit you know whatever we reach
about 2.6 stop X velocity six I want
important because my pageant directory
now become a monument just about Cuba
it's not situation now the program pool
as well where that says the latest
economic standing wave or something but
we're let the season relationship
kernels dated October it is a problem
yes there was a pretty group of impacts
occurring for somebody at Google whose
name get dynamically allocate all thing
so that allocated that's not quite the
bus terminus it's a difficult match
Watson seven pages into the new
processes Damien
Tania
can answer this question that's fine so
the word on the street is that google
has their own kernel they track outside
of the mainline kernel and there's what
I understand a lot of changes there I'm
curious Google is
other included will come and pull the
patches the neighbors are of interest
rate never ever it's basic
much of our villages too much money but
ever since directly for rednecks and
Susan estimated tens of thousands of us
out they have a big liberation invest
it's not like that
so large projects completed see it seems
a terrible battle but me
this is an awful language except maybe
for a project - experiments than the
right choice is there any chance that
the most Awkward faculty who's another
programming like
I've seen friend of its abash company in
the hole would give you a very emphatic
answer to that aspect
why did nothing that's needed but I
think even like excellent system
software in the communities that they
said no I see no
I don't have any education committees if
somebody sees somebody kernel module to
be able to accommodate and this may be a
cost for us for doing that
it is pretty limited so there is a flame
right now which has been proposed for
mr. de ruyter so there are days if you
have a particularly bison to read some
particular specialist you see numerical
control company or scientific
instruments then you have a complicated
device what we need is the little
skillet into the kernel jostle the
package a result descend by seconds
later we have now about 150 lives the
other is in the great bulk of your
sophisticated information within a from
user space to spoken to a minimal
sputters I don't think I had some
concerns a bigger than this user for a
license price opinion maybe something to
stop getting decent kind of support the
people convinced me otherwise
really and especially us people we
definitely run a quite a message driver
which might include plating fortune or
some things so I think that's a part of
it
basically these specialized devices
became the usual is multiplying like for
right
I see that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>