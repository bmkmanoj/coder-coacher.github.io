<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AQC 2016 - Quantum Monte  Carlo vs Tunneling vs. Adiabatic Optimization | Coder Coacher - Coaching Coders</title><meta content="AQC 2016 - Quantum Monte  Carlo vs Tunneling vs. Adiabatic Optimization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AQC 2016 - Quantum Monte  Carlo vs Tunneling vs. Adiabatic Optimization</b></h2><h5 class="post__date">2016-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/t8BPaY06XCo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so our next talk is by arm Harrow and
the technologists promised us that he's
going to appear there yes hi Aaron hello
hi so Aaron you are being seen by
everyone in the room and you could great
I come a bit okay so how am I going to
be able to signal you that you're going
overtime can you see you can't see me
can you
no but I can hear you okay I'll sit I'll
have to say I'll be verbal go for it
okay so I have half an hour right yes
yes so normally I I I love to be
interrupted by questions I might not be
able to hear questions unless you use a
microphone so we'll see how that works
do you see my slides great okay so I'm
going to talk about the same work that
Elizabeth talked about but I'm going to
give a different perspective on it I'm
going to talk about kind of more broadly
what our goals are for this project what
we think are the relevant structures to
look at and and talk a little bit about
where we think we might be able to go
from from here and I guess the sort of
broader question that we are we're
interested in is this question of
quantum supremacy we'd like to
demonstrate to do something with a
quantum computing quantum computing
device that is out of reach of classical
computers so there are a number of
things we want to do here as as
theorists we want to come up with
algorithms that are feasible for quantum
computers and at the same time hard for
classical computers to simulate and
ideally they would also be easy to
verify that our quantum device actually
did the thing that our theoretical
calculations have shown is is hard to
simulate and if we really want to be
ambitious and maybe they could even
solve a useful problem while we're at it
so that's kind of the broader the
broader goal of a lot of
Logan's work and a few candidates are
factoring performing low depth circuits
may be random circuits which the google
group is looking at beause I'm sampling
something called instantaneous quantum
computing by shellner and Shepherd and
Bremner something called the quantum
approximate optimization algorithm or
the adiabatic algorithm and let me kind
of talk generally about about how these
how these stack up so the first example
which I kind of for a long time I think
was what people had in mind when they
thought about a quantum computer doing
something demonstrably beyond the
capabilities of classical computers was
the shortest factoring algorithm and
it's worth thinking about this because
it is all the desiderata of a good
quantum supremacy experiment except that
it's a challenging experiment for a
quantum computer and but so that in the
first column I'm talking about
difficulty for quantum computing and
this is a hard challenge for a quantum
computer because to factor a number
that's beyond what we know how to do
classically you need quite a large
quantity Q and even to get one of a
non-trivial size you need to do a it's a
pretty difficult experiment on the other
hand the hardness assumption that we
need to rule out classical simulation is
one that is pretty mild it's not that P
is not equal to NP but it has to we have
to assume that RSA is secure we have to
assume that there's no good classical
factoring algorithm and this is
something that people cared about before
quantum computers came along people have
worked hard on this problem arguably for
thousands of years and you never know
maybe a breakthrough will come tomorrow
maybe the NSA already has one but it's
one of the better study problems one
that we can be pretty confident that
there is no good classical algorithm for
it has the further advantage that you
can check that it got the right answer
you can pay two random primes multiply
them together put them into your
factoring algorithm and then you can
verify that it spits out what exposed to
and of course it's also solving a useful
problem so this is sort of the
prototypical quantum supremacy candidate
and because it's such a
difficult experiments two people have
been looking at whether you can do an
easier weather than a simpler
experimental platform that can lead to
quantum supremacy and there are a number
of works that are based on the
assumption they're kind of two ways of
saying this one of them is that the
polynomial hierarchy is infinite another
one is that exact counting is not the
same as approximate counting so let me
explain what that means the polynomial
hierarchy being infinite is the
conjecture that's similar to P not equal
to NP yet it's like I'm not like
specifics precisely explain the
difference but it's it's similar to that
approximate counting being different
than exact counting means that two tasks
both beyond the reach of poly-time
algorithms should have should themselves
be different in complexity approximate
counting means if you have a 3sat
instance approximating to within a
factor of two the number of satisfying
assignments so you know are there more
than a thousand or fewer than 500
satisfying assignments whereas exact
counting means exactly determining the
number of satisfying sense and again
it's a plausible assumption from
complexity theory and crucially one that
does not involve the word quantum
anywhere in it that these two tasks are
very different in power and if you
believe these are different in power
than all of these simple quantum
algorithms become hard to simulate so
boson sampling becomes hard to simulate
low depth quantum circuits that means
that you apply a series of gates and
each qubit only participates in say a
constant number of gates
there's the iqc by Shepherd and Bremner
this instantaneous quantum computing and
the quantum approximate optimization
algorithm by Farhi Goldstone and Gutman
all of these become hard to simulate
under this very plausible complexity
theoretic assumption on the other hand
there a few drawbacks so these we don't
know how to efficiently verify that if
we have a device doing this that it's
doing the right thing in some cases we
can verify some aspects of it so maybe
for the quantum approximate activation
algorithm we can we can look at how many
at what value of the objective function
is achieved or four random circuits we
can check that some of the moments in
the distribution that come out are the
are the right thing but it's not as
strong a verification as we get for
Shor's algorithm where if you see a
10,000 bit number being factored then
you're really are convinced and finally
many of these are not actually useful
problems so those on sampling samples
from a distribution proportional to the
permanence of some matrix that is hard
to do classically but it was not
something that we were clamoring to
solve before quanta computers came along
the main utility would be just this
demonstration and of all of these the
quantum approximate optimization
algorithm has a has a chance of being
useful and that it actually does give a
solution to a comment or optimization
problem which may be beyond the reach of
classical computers the last row of this
of this table is of course the theme of
the conference is adiabatic optimization
and I say that this like both on
sampling are easy in that they require
capabilities that may not be Universal
for quantum computing whereas the
moderate column refers to things that
are universal for quantum computing but
you just need a short amount of
coherence time so this can really use an
architecture which is does not have
Universal quantum computing capabilities
but everything else we're not quite sure
about so whether this classical
simulation is really an open question
whether you can verify the solution
really depends if you find the exact um
you know if you if you find the solution
to a satisfy to a 3sat instance then you
can verify there satisfiable but but
otherwise if you achieve something less
than that you may not be able to verify
it's doing the right thing and that's
where it's useful you know again that
that depends on on whether it can solve
hard combinatorial optimization problems
better than classical computers so this
is kind of the the the overview of our
quest forever for quantum supremacy so
let me talk specifically about the
adiabatic algorithm I think this slide
is one I I don't really need to explain
it in this conference but I just want to
say briefly that I'm going to focus on
the one that's originally proposed I
know adiabatic means something much more
general it can mean non stochastic it
can involve noise I'm gonna focus just
on the on the simplest case is
originally described with a Hamiltonian
triple Eight's between all
exes and between a diagonal Hamiltonian
and I'm not going to consider noise or
non stochastic terms so when I say the
adiabatic algorithm this is what I mean
and just realize in the back of your
head that of course there are more
general versions out there that are
being discussed um I want to briefly
mention something I've worked on with
Eddie a little bit the quantum
approximate optimization algorithm so
also because this is almost like a gate
version of adiabatic in some ways so you
start with a uniform superposition the
adiabatic the algorithm would say that
you interpolate from one Hamiltonian to
another one you start with H of X and
you interpolate to H of s instead if you
apply them in alternating pulses you get
the Q AOA and you do this P times and
then you measure in the end and see what
you get and what what you can show is
that this if you take P to infinity this
includes the adiabatic algorithm we know
if you run that for long enough you can
get the exact answer so yes you can
exactly optimize with this but what's
interesting about it is a case when P is
small where we don't think that in
general it may look at the optimal
answer but in many cases it may get a
good approximation and any of these
co-authors have proven that this does
give good approximations in some cases
when P is small and also it has some
good noise resilience properties um and
in some cases this gives a you can even
bound the approximation ratio and there
have been periods when this has been
better than any known approximate at any
known classical algorithm so I think
initially the approximation ratio was
the best known for some problems then
classical people realized that the
quantum algorithm was beating the
classical algorithms worked harder and
improves the classical performance then
the quad amalgam was improved currently
they're close to a tie and it's it's
open question whether a better
approximation ratio can be can be
achieved by this and I think remains a
compelling juristic for for
combinatorial optimization so what and
so this like some of the other things in
that column are hard to simulate unless
the polynomial hierarchy collapses and
unless approximate counting is equal to
to exact telling but what I don't talk
about are is the last column which I
think is to me is the most interesting
because of all the questioners because
we're so unsure about the power of
stochastic ground state adiabatic
optimization I think it's worth
investigating so I would say that the
the possibilities for this range from
very pessimistic to very optimistic the
most pessimistic possible is that
there's a classical simulator that
always runs in time at most a polynomial
of the time required by the adiabatic
algorithm in other words only polynomial
speed ups are possible now we know that
you can get at least a quadratic speed
up with adiabatic optimization via
growver type speed-up so we know you
know linear time simulation is ruled out
the best you know sort of the most
pessimistic thing would be that there's
a quadratic simulator and there's some
evidence in favor of the pessimistic
scenario which is that there is this
quantum Monte Carlo algorithm does not
work for simulating in general quantum
circuits and even though we don't know
how well it performs for adiabatic at
least there's an algorithm at least
there's a candidate algorithm to
simulate adiabatic evolution the
optimistic side would be maybe that
stochastic
adiabatic evolution is universal for
quantum computing and this is probably
too optimistic it turns out if this were
true it would lead to these unlikely
scenarios a polynomial hierarchy would
collapse approximate observation would
be just as powerfully exact optimization
things that are considered to be
unlikely in terms of outcomes for
complexity theory but that doesn't mean
we could have something just short of
that for example I don't know of any
evidence against a an adiabatic
algorithm for for factoring this this
could well exist and I would say this is
I'm the optimistic end of the power of
quantum of adiabatic quantum computing
and whenever you hear a pessimistic and
an optimistic scenario it's tempting to
believe that the truth lies somewhere in
between and perhaps it's true that
adiabatic evolution gives you
exponential speed-up
meaning that there are things that
cannot be simulated classically without
exponential slowdown but still cannot do
everything that Jen
purpose quanta computers can do there's
some evidence for this in terms of an a
paper by Denis gieselmann here for OVA
which if adiabatic but sort of it leaves
the ground state for a part of the time
so it may or may not qualify and gives
you an exponential speed-up a bit with
an Oracle some further evidence is that
quantumatic are low sometimes seems to
take exponential time so that seems to
if our only good classical cinema video
takes exponential time then you know
maybe all classical algorithms do if so
um I want to talk more about the
possibility of simulating adiabatic
evolution with with quantum Monte Carlo
let me talk specifically about the the
map from from quantum to classical you
kind of saw this in Liz's talk so I
won't dwell on it basically the quantum
partition function can be mapped to a
classical Hamiltonian with the same
partition function and the way you
obtain this classical Hamiltonian is you
take one little Trotter slice and you
break up the Hamiltonian into diagonal
and off diagonal parts and these
correspond to different terms in the
classical Hamiltonian so it a classical
example is this is the one the
transverse Ising model that's a quantum
Hamiltonian which turns gif mapped into
a 2d classical ferromagnetic Ising model
so if you have over here these for
quantum spin this becomes a four by L
grid of spins with two types of bonds we
have vertical bonds are kind of the new
thing introduced by this and they're
ferromagnetic with pretty high energy
the energy is on the order of L over
gamma gamma some measure of the of the X
field and what that means is that each
bond has probability of disagreeing that
scales like gamma over L so if you think
of gamma the constants in L being large
that means that most of the bonds agree
the total number of disagreements with
some constant gamma in the entire column
so mostly these columns are all the same
but there's a constant number of flips
then we also have the horizontal bonds
which correspond to the to the diagonal
Hamiltonian so the diagonal part of the
Hamiltonian kind of gets applied to each
each row attenuated by this factor of 1
over L but there L rows so once you add
it all up you get back the the original
energies so this is how you turn a and
generally a quantum Hamiltonian into
into a classical one and as Elizabeth
talked about the kind of standard
component of quantum Monte Carlo is that
we use local moves of course it could be
world line update something more
complicated but some kind of of updates
to generate samples from the Joint
Distribution and this is a part we don't
know how well it runs then once you can
sample it's easy to reduce this to
counting to estimate the partition
function estimate values observables
that part is is relatively standard the
hard part is to show that the the Markov
chain corresponding to to your local
updates converges rapidly and what this
Markov chain looks like is you have all
the configurations of your classical
systems so a configuration looks by like
a rectangle of n by L bit and a move so
I'm not gonna consider world line
updates but you can you can modify this
to do that move by consists of flipping
one bit so you know flip go from all
zeros to a single one and this gives you
a giant graph over all the possible
states of your classical system and it's
weighted according to the prescription
from quantum Monte Carlo so the weight
is going to be given by the average
energy of these rows so you get an
exponential factor from that and also
you get a factor from every every jump
so every jump in the vertical direction
from zero to one cost you some factor of
beta gamma over L and so you don't
there's sort of this this cost to
putting in too many jumps on the other
hand and tropically it's favored to have
some jumps and so they'll be typically
some balance between and the question is
whether this is is rapidly mixing and so
this relates to the question of whether
quantum Monte Carlo can simulate a
tea-bagged evolution and I should
mention that this be possible there's a
few things that we we kind of know will
be necessary so oh sorry I wrote the gap
is is greater then let me lesson let me
take greater than um
so I said so this should only work if
the if the gap the quantum algorithm is
at least one of a polynomial and this is
because quantum Monte Carlo has this
inverse temperature parameter beta and
beta needs to be at least one over the
gap for the thermal State to be close to
the ground state and beta tells you the
number of imaginary times that's this
this length L is going to depend on beta
so if the gap is too small then we won't
even be able to get a good approximation
to the ground state
even if these things mix graphically
also this will only work if we follow
the adiabatic path or rather we should
expect that our algorithm
you know maybe in some cases doesn't
need to follow the adiabatic lapse but
generically it should because otherwise
if we could just jump to the end we
could solve np-complete problems since
we know at the end of the path the gap
is large if we could just jump there and
do something it owned it and on the gap
that'd be too good to be true is there a
question
no Arum it's a question for me Eddie you
have turned off your slides we like
looking at you but we want all your
slides think Thanks let me do that hold
on
good do you see the slides are up now
right yeah you're back and while we're
at it you have 12 minutes 12 12 minute
great okay and so we should follow the
adiabatic path otherwise we would give
it something too good to be true and if
you look at my papers Elizabeth the
place where we use this is as a sort of
warm starts to mean that you start when
you start sampling for a given value
you've got a parameter you have
something which is not to unphysical the
configurations are not too unlikely it
sort of looks reasonable in many ways
and bravi inter-college is something
similar in a paper of their some about
ten years ago and of course even then
there's some arguments that there'll be
maybe topological obstructions so
Hastings and Friedman argued that if the
quantum state space looks like a circle
then the classical state space looks
like strings on the edge of a cylinder
and these can have winding numbers and
it may be hard to transition from one
winding number to another this is
something which I think it's been under
explored and we would be worth looking
into into more so
okay so what I want to talk about is how
quantum Monte Carlo to understand how
quantum Monte Carlo performs I want to
talk about the measure over Palace that
we get when we run quantum Monte Carlo
and there'll be a talk tomorrow by Zhang
Jian which will I believe it's tomorrow
we'll talk more about this so the idea
of quantum Monte Carlo is to do a random
walk on the hypercube and so you have
these classical configurations
bitstrings e1v chew through VL each one
is a n bit string typically is
conditioned to return so VL plus one is
set equal to v1 we tell if you use open
boundary conditions in which case you
wouldn't have that constraint and the
typical number of jumps will scale
roughly like n so even though L might be
quite large most of it the these are
equal to the next one and the number of
jumps where one bit changes only scales
fortunately to N and B intuition for
this let's focus on the on the bit
symmetric case the case where the
objective function only depends on the
on the Hamming weight and so then we can
consider instead of looking at n bit
strings we can just look at this as a
walk over Hamming weight which ranges
between 0 and n and let's further assume
that this function is continuous so
let's just replace 0 through endless
rescale that to be a number between 0
and 1 and and make it a real number and
in that case if we do a random walk on
the hyper tube what that looks like can
turn Hamming weight is this kind of
Brownian motion and if you want to do
Brownian motion with closed boundary
conditions meaning you return to where
you start it's something called the
Brownian bridge but most of your
intuition about Brownian motion can can
carry over to this case and if we want
to add local g fields we get something
slightly different we get it we get a
drift we get that it's Faber's you know
not Hamming weight 0 but there's some
particular Hamming weight that it
prefers I'm sorry now how many weight
and over two but there might be some
other Hamming weight that it prefers and
if you get too far away from this and
you drift back to that point and so this
this kind of looks like a harmonic
oscillator with friction something
called the Ornstein uhlenbeck process or
if you want to condition on return
we start the Ornstein uhlenbeck bridge
I'm kind of measured mentioning this for
completeness but to give intuition I'm
just going to talk about Brownian motion
so even though there are zee fields i'm
for the purpose of what i'll talk about
next but let's ignore those um ok so how
can we analyze the the Brownian motion
that we get with quantum Monte Carlo one
important thing that we'll need to deal
with is the local time which means the
amount of time that Brownian motion
spends at a particular point X for the
the problem that Lizbeth talked about we
want to know how long does quantum Monte
Carlo sit on the spike and essentially
this is a question of local time
how long does Brownian motion spend at a
particular point X and there are a
number of beautiful theorems that
characterize the distribution extremely
sharply so there's something called
LaVey theorem which says if you look at
the local time at the origin so where
the Brownian motion starts this has the
same distribution as another process
which is you take a different Brownian
motion and you look at its supreme over
time so in other words the largest value
that that Brownian motion has ever
reached in fact there's even a stronger
statement which is if you look at s
minus B through the suprema minus a
Brownian motion together the premium
this has the same distribution that's
what equals D means to the pair of the
absolute value of a Brownian motion
along with the local time and another
factor that the supremum has the same
distribution as the absolute value of
the Brownian motion
so all these seemingly complicated
objects you can really exactly write
down their distribution and there's a
nice proof in terms of in terms of
random walks
you know Brownian motions are like the
continuous version of random walks and
sometimes it's convenient to go back to
random walks to get a sense for for how
they work so let's consider a random
walk W which is just the sum of n plus
or minus 1 random variables ok so X 1 X
2 X 3 are just randomly plus or minus 1
W of n is where you end up after n steps
and let M be the maximum of this after
these n steps
so there are a few observations the
first is that if you look at M minus W
so in other words the maximum of the
random walk - your current position this
itself is a random walk because let's
say that maximum - the current random
walk is or and you take one step well
you'll either move up or down if you
move up then the maximum - the current
value will go down to three if you move
down maximum - the current random value
current value will go down go up go up
to five so wherever you are this maximum
- your current value will just follow a
random walk it'll go randomly up or down
unless you're currently at the maximum
so if you're if M equals W so that
you're currently at the maximum and
minus W is zero you obviously cannot go
below zero so then you will either take
a step zero or take a step of plus one
so it's like a random walk with a
reflecting boundary at zero so it's like
you take a random walk except when you
hit zero you have 1/2 chance of staying
there and a 1/2 chance of going to plus
1 so this argues that M minus W is
distributed roughly as the absolute
value of a random walk because that's
what a walk with reflecting boundary
looks like it's just like taking the
absolute value of a random walk and
furthermore the maximum value M is equal
to the number of times that M minus W
remain is it when does a maximum
increase well only when you're currently
at the maximum and you choose to move up
which means that M minus W is 0 and
after one step M minus W remains the
same so this argues that the maximum is
equal to the amount of time that M minus
W stays at 0 which is exactly a local
time of this walk so this argues that
the the local time has the same
distribution as the maximum of random
walk so this was all four random walks
then there was a few kind of small
imprecisions there but when you
translate to Brownian motion all that
becomes exact and and the the statement
of ladies theorem at Boston so
Eddie I think you're saying something
but I I do not here
that's um oh now I hear you you have
five minutes Eddie five minutes create
something yes I hear you
good okay so so this this argument gives
you realization of how much time
Brownian motion spends at any one point
right now just mean but all the moments
and so on
so let's look at this this problem
Hemingway's with a spike and and try to
apply it let's say this spike has with N
to the a and height n to the beat I
think Elizabeth might be use the
opposite parameters but let's use these
so how does the quantum algorithm
perform we know that if a plus B is less
than 1/2 the adiabatic gap remains
constant there's an intermediate regime
where the adiabatic gap goes down
polynomial e and if a and B are too
large the gap goes down exponentially
and this is due to far he Goldstone cut
min there's an argument by rycart and
Cong and cross in Grady Van Dam and then
Jing at all I'll have done some version
of this of this argument so let's see
how these arguments about Brownian
motion can apply here so if we have this
spike what this corresponds to is some
region that when the Brownian motion
traverses it effectively gets penalized
so when you're in this region you incur
an energy penalty and the probability
gets depressed and we know that if there
was no spike that the distribution will
be just Brownian motion and so we can
exactly characterize the what we call
the spike time which is the fraction of
time you spend on the site which goes
like a Gaussian or sorry the absolute
value of a Gaussian with this Verret
with this standard deviation of n to the
a minus 1/2 and you can prove it using
using ladies theorem as I've kind of
outlined or in my paper with Elizabeth
we proved it by mapping it back to the
to the classical to the quantum system
arguing that properties of the classical
system should correspond to properties
of the quantum system and then what this
implies is essentially that typical
paths in this a plus B less than 1/2
region don't notice the spike and the
reason is something called the phiman
 theorem but
something it's almost elementary it just
says that the probability of your path
actually sorry I left off in
normalization so proud to be a path with
the spike is proportional to the
probability path without this spike just
reweighed 'add by the penalty from the
spike and if you look at how much time
you're likely to spend on the spike and
multiplied by the penalty then in this a
plus B lesson half-breeds regime
typically you're just not going to have
very much of a penalty so that you can
phase the intuition behind the result
that you saw the actual proof of in
Elizabeth's talk let me now talk about
how we might go beyond that to a regime
where our analysis doesn't yet cover it
but I think should be able to and which
it relates to the instant on that G at
all we'll talk about tomorrow so if
you're in this regime where 2a plus B is
less than 1 but you know our other proof
doesn't apply then then what can we say
well talking about using Brownian motion
we know that to traverse a region of
with n to the a the number of steps you
need is like the square of that width
that's because they get some distance D
with Brownian motion it takes D squared
steps and so the typical number of steps
traverses by cos n is and if you follow
through how much is a probability
reduced by you get this factor here
exponential minus n to the qu a plus B
minus 1 and what that means is that 2a
plus B less equal to 1 is the threshold
to cross the spike what so if you cross
the spike once you incur a penalty which
looks like e to the minus that quantity
so if that quantity is much more than 1
you're unlikely to ever cross the the
ever cross the the spike if it's less
than 1 then you're typically able to
cross the spiked at least a constant
number of times and so that argue that
this threshold is what basically when
the state space becomes disconnected you
know they say faith comes disconnected
once to a plus B is greater than 1 and
it's roughly connected when to a plus B
is less than 1 and you can get that
using these these arguments are random
walks so I'm about out of time I think
Elizabeth sort of talked about canonical
paths and flow so don't say too much
about it
just very briefly the conductance of a
distribution is the basically the the
worst bottleneck right which which
Elizabeth mentioned and how does our
rigorous proof differ from the more
powerful results that you get using
using instinct times I would argue that
our proof is based on these canonical
path at economical flows which are which
imply that there is no bad cut whereas
if you do an analysis based on an
instant tons it implies that a a
plausible cut one that is physically
justified does not have too bad of a gap
so what I presented back in this slide
is is that is it kind of rules out a
certain plausible cut and what we'd like
to do next is extend this to argue you
know to construct a set of canonical
flows or canonical paths that implies
that there's no cuts okay so let me let
me conclude so what are the key open
questions here I think what we've
covered so far is this toy problem of a
bit symmetric case which of course is an
easy problem we'd like to go to the
multi-dimensional case which is the more
interesting one and the approach that
Elizabeth outlines and in the case of a
plus B less and a half basically
generalizes to whenever the unperturbed
problem has a good set of canonical
paths and the perturbation is small
relative to quantum chaos in that case
it means that the ground state wave
function doesn't change very much and
that the paths will not have their
probabilities shifted too much by the
perturbation but this other scenario to
a plus B less than one I think that
generalizes to the case when your ground
state does change a lot but it's still
possible to traverse the spike once
without too much penalty and I think to
be quite interesting to to kind of get a
general proof for that scenario another
open question which I think was I was
trying to start to address by looking at
the state space of these of these paths
is how does this geometry the quantum
state relate to the quantum state of
quantum Monte Carlo we know I think I
learned this from Vin Van Damme that
that grounds gates of gapped
Hamiltonians have high conductance to
you there's no good bottleneck for
ground the ground state distribution of
the gapped Hamiltonian but what can we
say about the effect the implications
this / paths in quantum Monte Carlo
how this also have good conductance that
that may or may not be true and finally
the big question is whether there's a
poly time simulation of adiabatic
quantum computing or exponential
simulation I think that that's very much
open okay so thank you thanks for your
attention I can take questions now ok
well it gonna have some questions I
guess who would like to ask a question
okay in the front row we have a question
hello
you have to talk into the mic oh yes so
you can hear me yes at one point you
said that you do not know of any
adiabatic algorithms for factoring
numbers and I just like to say that such
an algorithm does exist and some numbers
have been factored experimentally using
NMR based adiabatic quantum computation
and those numbers are larger than what's
been factored using Shor's algorithm so
far RSA 220 requires a few thousand
cubits the problem there is that the
there's multi qubit interactions for
qubit interactions so they can't fit on
d-wave yet the other thing i wanted to
say was about the boson sampling in your
table you said that the boson sampling
has no useful applications and so about
that I would like to ask what about the
paper by Alana Spooner guzik's group on
using boson sampling for determining
franck-condon factors in chemical
systems ok thanks for the comment I I
actually I I have not done my homework
and I have not read that that paper and
so I should do that and and and give an
opinion about so so it may be that that
actually yeah that I may may have to
change that part of the slide as for the
adiabatic factoring algorithm I guess I
would say that it's not proved to run in
polynomial time and it does not seem to
take advantage of the well since it does
not use the methods of Shor's algorithm
it seems to me that it does not seem to
me likely that it would do better than
it would for a gent general constraint
satisfaction problem so I guess my
conjecture is that algorithm will not
run in polynomial time
but I guess it you know that's just my
opinion is and I could well be wrong
about us your and I thank you that
proved either way okay let's look for
more questions ok well that's okay
because we're running behind so Aaron
we're gonna cut you off thank you very
much thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>