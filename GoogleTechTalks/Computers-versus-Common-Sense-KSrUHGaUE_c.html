<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Computers versus Common Sense | Coder Coacher - Coaching Coders</title><meta content="Computers versus Common Sense - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Computers versus Common Sense</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KSrUHGaUE_c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I
so it's our great pleasure to welcome
today
Doug Lennon from from psych or Doug as
many of you know is one of the leaders
in the field of AI one of the original
fellows of the AI Association I remember
reading about his automated
mathematician program in 1976 and was
one of things that really inspired me to
go into the field and doug has really
been sort of had a consistent vision and
leadership in this field of sort of
common sense knowledge representation
he's been the Moses of the field
striving to write down the knowledge in
the book since then you know things have
evolved and changed and in terms of
connecting the most people with their
queries to knowledge I guess google has
taken over the field of being the
mountain in terms of answering the most
queries but today Moses has come to the
mountain and we reference list to what
he has to say thank you that was a that
was an amazing introduction so as as you
could tell we had some audio visual
problems and so the various demos and so
on that I was going to show you I won't
be able to but after the talk if you're
interested come on up to the front and
on a very very small screen you'll be
able to see some of this stuff running
live but PowerPoint presentation is
almost as good so basically I had a
meeting with Vint Cerf recently where he
encouraged me to use the word relevance
as much as possible in this talk so
really what I'm going to talk about
today is semantically determined rather
than syntactically determined relevance
the the basic problem is that even after
50 some years software is still
incredibly brittle if you talk to
medical diagnosis systems even if there
are world-class diagnostic experts as a
joke we told the system about my old
rusted-out Pontiac and you know it asked
questions like are there spots on the
body yes more on the trunk than
elsewhere know what color reddish brown
diagnosed it as having measles with a
very high Khan
level or a car loan approval system
which granted a loan to someone who put
down that they had 19 years of
on-the-job experience at their last job
you know they were less than 19 years
old and so on I could go on and on but
you sort of have all these examples
yourself from your everyday life of this
kind of brittleness of software in terms
of Google you get queries all the time
like this one on which if you basically
type this into google you won't actually
get the answer in any one place and it's
heartbreaking because of course there
are lots of places on the web that have
one or the other of these building
heights in fact there are a lot of pages
that have both of the building heights
and because they just happen not to have
a sentence of this form they're not
going to give you the answer they for
essentially would make you get the
answer yourself by doing the arithmetic
yourself or if you have a query like
this of some movie to take the kids to
nearby here that starting soon why
should you have to go to two or three or
four different sites in order to put the
information together to get the answer
to a query like this by the way this was
in case you you you were dubious about
the fact that you couldn't answer that
query and the first hit actually seems
to answer it but it turns out they're
talking about replicas of these objects
in Las Vegas not the not the actual
originals and so another is actually a a
page you can go to and get the height of
one and the height of the other and so
if you're able to do subtraction you can
get the answer to your question so
really what I'm talking about here are a
combination of missed opportunities
where the software doesn't really
understand what the user is asking on
and can't combine information across
pieces of software that have been
written so that even if someone writes a
program which is able to answer a
certain kind of question you can't just
dump all those programs together and
have them be as smart as someone who had
all those capabilities there's a real
danger an increasing danger in this kind
of brittleness namely as programs get
more and more power
the real world you're giving power to
what are in effect idiot savants you
wouldn't really take your child to a
physician who was an idiot savant who
didn't understand that automobiles can't
get measles and so on and I'm similarly
every 20 years or so there's a surge of
sort of a media frenzy about forthcoming
home robots you may remember 20 some
years ago it was on Nolan Bushnell and
and Ron but now there's a you know
partly because of the room bot and so on
you see lots of articles now about the
impending home robots that will mind the
baby and mow the lawn and said well the
trouble of course is that they'll just
as blithely mow the baby because they
don't know they don't care they don't
have common sense programs have the
veneer of intelligence at most not true
intelligence and sometimes when they
have the veneer of intelligence they're
even more dangerous than when they don't
so to give you an example of what I mean
by the veneer of intelligence we could
go back 40 years to the Eliza or doctor
program that Joe wisin bomb did at MIT
back when Rogerian psychology was very
popular this is sort of reflection so
you say things like I smoke and it's a
it says things like tell me more about
the fact that you smoke so one of my
favorite examples was where we said my
dog's mother died recently and the
program said tell me more about your
mother now the less you know about
computer science the more deep the
psychiatric insight really appears to be
mostly what's going on here is that the
program simply doesn't know the word dog
so it's sort of hear is blah blah blah
mother and then it says tell me more
about your mother this is a lot like the
Gary Larson far side cartoon that you
may have seen where it's like this guy
is talking to his dog and it's like what
he says and what the dog actually hears
and for those of you who are dog people
i will show you the rarely seen cat
version of this of what you say to the
cat and what the cat here's so basically
fast-forward 40 years and you say well
surely in 40 years we can do a lot
better job than that well it turns out
if you look at the touring test
competitions that go on there still won
by these annoying little chat BOTS like
Alice I'm where you say like what is the
color of a blue car and it gives you
back some garbled Eliza like version of
that or you say I'm going to ask you
some simple questions and it says like
do you think your plan will succeed or
where is Sue's knows when Susan or house
and it says where it belongs now this is
actually not such a bad answer but it
then ruins it by going on to say try
searching the World Wide Web anyway
obviously if you go to end karda and ask
that you get some garbled but actually
in this case you get two hits one on the
history of automobiles and then one I
guess because it doesn't understand
capitalization and punctuation on the
Central African Republic if you go to
ask jeeves you pretty much get the same
results on that you'd get from google
namely pages that happen to mention
those words but not actually
understanding the question so the basic
idea is can we get the computer to
understand semantically not just
syntactically not just store information
for portrayal and depiction and
presentation to human beings but
actually understand the questions that
are coming in actually understand the
material that it's displaying and
searching through and indexing to reason
to decide what's relevant and even
better to reason to decide how to
arithmetic alee or logically combine
information from two or three or five
different sources to answer a query that
isn't answerable
on any one single page anywhere so okay
let's go about telling the computer all
the sorts of things that you know about
cars and colors and the Eiffel Tower and
heights of buildings and movies and and
so on and there's actually a lot of
stuff that people know but still we
could write that stuff down and tell it
to computer so here's a couple sentences
about kitchen appliances now after you
say this does the system understand that
microwaves and dishwashers are kitchen
appliances well not really I mean it has
those sentences and if you ask it in
just the right way it'll tell you yes it
understands that but I'm really for all
intents and purposes we could have typed
this in because it doesn't really know
what the terms mean and so you could say
well we need to tell it more about each
of these kinds of things while this
first thing requires electricity and the
second one requires electricity and
water well but remember it doesn't
really know English so it doesn't know
the meaning of those terms so you have
to tell it more about those things like
buzz qua is on shipped to people's
houses in liquid form through pipes and
so on you keep on doing this again and
again and again keep explaining the
meaning of these terms and not just the
terms but also the relations like
requires and slowly this converges
slowly it converges after writing
millions and millions of these
assertions into a set of axioms that
have only one model namely the real
world and finally when you've written
enough you can believe that the
conclusions that would deductively come
from all these assertions would be the
same conclusions that you would believe
about things in the real world like
pipes and water and liquids and heights
of buildings on and so on so on to bring
this home to you guys how do I think the
results that you present could be more
relevant if the search engine had some
sort of understanding and I've actually
included here for old times sake some
examples that were motivated by people
in the audience in some cases actually
implemented by people in the audience 5
10 and in this case 15 years ago this is
something that RV goo ha worked on when
he was working on our project
so I'm here someone is asking for
pictures of someone smiling on and the
system psych system was able to come up
with a match on this particular
captioned image a man helping his
daughter take her first step we're
obviously none of these words are
synonyms so syntactic matching is not
going to find this particular match for
you but on the other hand as a human
being you understand things about the
real world like when you become happy
you smile and when somebody you love
accomplishes something it makes you I'm
happy and taking the first step as an
accomplishment and parents love their
children and so if you believe these
things then it's a fairly short
deductive proof to decide that this
image is likely to be relevant to this
particular caption ie this image is
relevant to this particular query rather
that this image probably depicts someone
who is smiling and so psyche has these
pieces of knowledge that represented in
some machine manipulable formal language
basically predicate calculus form and so
we're talking about a three or four step
proof to decide that this query and this
caption I'm actually unified so if you
have these pieces of knowledge finding
this match is trivial if you don't have
these pieces of knowledge finding this
match is impossible it's not like you
could add another fifteen thousand
servers or let your algorithm run
another five seconds and it would find
this match it'll never find this match
without these pieces of knowledge here's
another example from the RV goo ha days
where the query was for pictures of
strong and adventurous people and the
entire document here is a caption of
just half a dozen words a man climbing a
rock face and you have to know things
like when you're doing rock climbing you
have to repeatedly lift your own body
weight so you have to be at least
moderately strong and if you put
yourself at risk of dying like this then
you have to be at least moderately
adventurous and again we're not talking
about beating Kasparov at chess doing
the 37 deep reasoning this is a trivial
kind of search if you have those pieces
of knowledge and if the computer is able
to use those to mechanically manipulate
those to do deductions and there's
nothing special about an image retrieval
one recent example from a project we're
working on for the government was an
analyst query for government buildings
damaged in terrorist events in Beirut
during the 1990s and the actual document
talked about a 1993 pipe bombing of
France's embassy so you have to know
things like embassies are government
buildings in 1993 is during the 1990s
and if there was a pipe bombing then
probably it was a terrorist event and so
on so again knowing a few things about
the real world you can answer this query
sometimes you need domain dependent
knowledge as well like to answer this
one you have to know things like sa 7s
are capable of shooting down low flying
on aircraft and so on but you still you
get the basic idea we're talking about
relatively short relatively simple
searches if you have the pieces of
knowledge so this is little thank you to
goo ha for pushing us in this direction
not just finding information but also
consistency checking and in some cases
guessing at missing pieces of
information can be done this way so here
you can think of this as an Excel
spreadsheet or a relational database of
employee information and in the second
row we see things like well this person
looks like they were hired before they
were born and they listed themself as
their own emergency contact and the
person that listed them is their
significant other is different from the
person they listed is their significant
other and so on and so this doesn't
violate the data type of this particular
data structure doesn't violate the
constraints let's say of the spreadsheet
but it violates common sense it violates
your knowledge about the everyday world
and human attention should be called to
this and you could say well why isn't it
the responsibility of whoever put this
together why when they were putting this
schema together why didn't they pre
conceived all the different constraints
well in reality there aren't eight
columns there eighty thousand columns
and they're not spread over one single
table they're spread over hundreds or
even thousands of tables and the people
who put those databases together had no
idea of the existence of each other and
it's your ability to read the column or
relation headings and understand what
they mean in human terms in common sense
terms that enables you to decide that
of these things are contradictory with
each other so how can our programs be
intelligent rather than just having the
veneer of intelligence and the answer is
by having and by being able to apply not
just store and display this large corpus
of knowledge spanning pretty much
everything from domain dependent
knowledge to what you would call common
sense that ugh the caveman had like if
you've got some open container of liquid
and you turn it upside down the stuffs
going to fall out so basically I could
go through lots of different examples
from lots of different subfields but
partly because of Peter and some of the
other folks in the audience here I chose
some examples on poignant examples from
natural language understanding to to
drive that point home of why you really
need to have this kind of knowledge if
you want to semantically understand not
just store and display on this kind of
information so I'm here's on a lot of
these examples are actually 30 years old
from class I took from Terry Winograd at
Stanford backyard on the early 70s but
basically here's one where you know that
the first kind of pen is probably a
writing implement and the second one
isn't but what tells you that is it the
definition of these words is it
linguistic theory no it's your knowledge
of how big they are and where they
usually are and stuff like that or here
the police watch the demonstrators
because they feared violence or the
police watch the demonstrators because
they advocated violence one of the days
is going to be the police one of the
vaise is going to be the demonstrators
but how do you know which is which the
referent of that pronoun is basically
determined in your mind by your model of
police and demonstrators and what they
do in the context and so on Marion sewer
sisters if I say this to you you
probably assume I mean that there are
each other's sisters not that they each
just have a sibling and they're not
related to each other it would be cruel
and misleading if that's what I meant on
the other hand if I Sumerians who are
mothers it would never crossed your mind
for a second that they're each other's
mothers you know and why is that well
it's because of your knowledge of
biological reproduction it's not the
English language or linguistic theory
that that tells you this or every
American has a mother obviously not the
same mother but an almost identical
sentence it is more or less the same
president
John saws brother skiing on TV the fool
didn't have a coat on who's the fool
presumably the person skiing but it's
your knowledge of skiing and climate and
weather and how televisions work that
enable you to determine that if I had
said the fool didn't recognize and now
the fool would be John the person
watching television again your knowledge
of the real world helps you to
disambiguate these possible reference I
could go on and give you lots of more
examples but just one final example
almost every Burns and Allen routine is
built around this kind of
misunderstanding so here's one where
George is saying by ants in the hospital
I went to see her today and I took her
flowers and Gracie says that's terrible
you should have brought her flowers and
that's because there are a lot of words
like took and sanction and table that
actually reverse their meaning depending
on the context in which they're used and
we rely on our knowledge of the world in
order to tell us what is actually being
intended by the speaker or the author so
when I talk about a large corpus of
knowledge what is this knowledge we're
talking about facts and rules of thumb
and so on but we have to represent this
in some fashion on that the machine can
manipulate and so by using logic by
using predicate calculus as our
representation computers can do
deductive reasoning and incidentally
inductive and deductive reasoning as
well themselves on that represented
knowledge and because the words are
composed of sentences I'm sorry the
sentences are composed of words the full
list of words or terms that we use in
our language is something we refer to as
the ontology and because the grammar and
syntax is formally regulated we can
refer to this as essentially a formal
ontology so when people talk about a
formal ontology this is pretty much all
there they're really talking about
restricted set of terms and a restricted
set of grammar rules for how you can
compose on sentences out of this and
hopefully restricted enough that the
machine can logically create valid
deductions out of all this um it's
useful to organize terms in your
ontology in a kind of hierarchy or
taxonomy on that gives you the power of
generalization the power of inheritance
so you can save
things about vehicles or trucks or
whatever and some particular truck down
here will inherit all that information
things like this truck is probably
driven by a trained adult human being
and probably can't control to altitude
and that kind of taxonomy can also help
you to correctly place information so if
you say water vehicle slowdown in bad
weather you look around at the
neighboring parts of the ontology and
you say well that really applies more to
surface water vehicles and it really
applies to surface vehicles in general
so even though you didn't have trucks in
mind when you wrote that rule it now
applies to trucks and in particular to
this truck over here that the system
will understand that that truck will
probably have to slow down in bad
weather so you so to get the idea of
using the ontology to help the system
figure out and to help the human
building the system figure out where
knowledge should be attached when I say
that we want to represent knowledge in
logic obviously you know what i mean by
representing knowledge in on english
these are ways of representing on in a
simple predicate calculus notation that
Socrates is man or that men are mortal
these are just two alternate ways at
different levels of verbosity of saying
that men are mortal and you can go on
and write more and more complicated
expressions to represent things like on
everybody has a mother who's a a female
of their species and and so on often
what we do in a case like this if we see
the same kind of form occurring again
and again and again is we introduce a
new predicate in this case relation all
exists so that what used to be a
complicated looking rule is now a ground
atomic formula in this case a simple
ternary assertion in our language so
slowly the number of relations the
number of predicates has increased to
about 16,000 in psych and that number is
slowly increasing especially as we add
new domains but we increase that number
kicking and screaming not because we
want to be able to say that we have a
large number of different relations and
what do I mean by the system can produce
deductions I mean that I'm just like you
would expect a human being in this case
to conclude that Socrates is mortal
given
socrates is a man and men are mortal if
we ask our system is Socrates mortal it
should and will come back and say yes
and if you ask for the justification
it'll give you exactly the two-step
justification that you would expect here
if we had our live demo running I would
show you some cute examples we have
about 50,000 common-sense tests that we
try to run every night just to try to
make sure that the system keeps on
consistency one of them is something
like kind of can can can and if you ask
that it'll say no and if you ask why
it'll say because on cans or inanimate
objects and doing the can-can generally
requires at least a a partially mental
doer as the the motive force behind the
action and so on and similarly oh good
we can actually show the one of the the
ways that this would actually be asked
and one of the forms in which the
argument would come out here you see the
justification in predicate calculus you
can press a button and the system can
generate mediocre English understandable
but by no means on English were proud of
to translate on these predicate calculus
assertions into English assertions like
inanimate objects can't be the doers of
partially mental events and cans are
inanimate objects and ken ken dancing is
a least a partially mental event and so
on so you get the idea and in terms of
more complicated examples we have
something that we call the analysts
knowledge base which on intelligence
analysts used to answer questions like
where there any attacks on targets of
symbolic value to Muslims since 1987 on
Christian holy days or things like that
and I think I'll skip through some of
that but you can get the idea here's an
example where the analyst is asking who
had a motive for the assassination of
rafik hariri and they type short phrases
in that get parsed well enough that get
recognized well enough that novices who
aren't familiar with psych and its
ontology and AI and predicate calculus
can still get their quest
informed in a way that both they and the
system believe it understands and then
when you ask the question you get on
various answers some of which are
surprising like in this case on the US
and Israel being behind her ears
assassination and if you ask like for
the sources there it turns out well this
is actually on set some editorial that
appeared on al-jazeera and obviously if
you want you can click over to the
original source for that one if you look
at a more traditional Western answer
like Syria was behind her ear is
assassination you can ask for the
justification there and basically you
get something which says well Syria
opposed Lebanese economic reform and we
think hariri advocated Lebanese economic
reform it's in blue because the system
isn't sure about this this is a kind of
abductive reasoning and if you ask
whether or not this is true the system
will generate a kind of augmented query
handed to Google and you'll find a set
of articles in this case 19 hits all 19
of which are actually perfectly adequate
for answering question was rafik hariri
an advocate of lebanese economic reform
to take an even simpler example if all
you want our articles about his
assassination if you go and essentially
type in that to to google putting in
different forms of the word assassinate
and assassination you get some large
number of hits but there are a fair
number of false positives and negatives
in the results that come back to see
some examples of false negatives we
basically had psych used knowledge that
it had about his assassination like the
fact that it occurred as a car bombing
while he was traveling in a motorcade so
you put in some of those terms and you
actually get more hits thousands more
hits than you got before and so there
are really large numbers of false
negatives that were simply missed by the
previous by the previous court because
they happen not to use the word
assassinate or assassination similarly
to see some of the false positives psych
knows when the assassination occurred
and in particular it knows enough about
causality to know that articles that
came out years before the assassination
are probable
Lee not about the assassination in this
case it's a statement hariri is making
about assassination many years before he
himself was assassinated this was a hit
that was among those returned earlier
anyway I could go on but in this
particular audience I'm love to talk too
much about removing positive and
negative errors because probably
everyone in this audience knows a little
bit more or a lot more than I do about
that subject by the way I want to thank
Joel truer for pushing us in this
direction several years ago that's
partly also how we met Michael wit Brock
who's with us now is our VP of research
I'm Joel came to us when he was at hot
pot and actually came to us with this
really cool idea of taking ambiguous
queries like this one and I'm sure you
can return the the hits right away in
this case about 26,000 hits got returned
but there's a mixture of hits about
veterans and veterinarians and other
things involving motorcycle race
veterans and so on and I've just asked a
Quarian if the user happens to click on
one of these like the the user happens
to click on military veteran then go
ahead and augment the query and ask it
in this case to Inc Thome with oars and
not terms to basically hopefully
eliminate the unwanted veterinarian hits
and indeed in this case on you get
hundreds of thousands not tens of
thousands of hits and they're all about
veterans and similarly if you had
clicked on this one then you get the
symmetric augmented query and again
you'd go from tens of thousands of hits
to hundreds of thousands of hits and
they'd all be about veterinarians and
the other idea that I'm Joel had which
was a good idea was used the
understanding of the query to suggest
plausible follow up queries so you
wouldn't ask for a thing you wouldn't
suggest follow up queries like how do I
train to become a veteran and so on so
you basically get the idea there now
some of the queries that i showed you
like this one basically require not just
common sense knowledge but up-to-date
database type now the kind of knowledge
you might get by visiting
a web site in this case a theater
listing website or google maps website
or the IMDb database website and so on
so how do we get that knowledge accessed
via the psyche system as well so this is
really another kind of application of
psyche to access structured semantic
knowledge in databases and websites out
on out there online here's an example in
which someone was asking how different
in age kousei and Uday Hussein were and
for the sake of argument let's suppose
that one structured source I'm contains
information about one brother and one
structured source contains information
about the other brother and obviously
using arithmetic and common sense you as
a human being could put these pieces of
information together and psyche because
it knows things like objects age one
year per year can also answer this
question and basically in the case of
this question come up with two years as
the answer but more than that it can
come up with 1966 over here add it to
this database and put as the source this
number 30 over here and it can put the
number 32 here and put as its
justification this number nineteen
sixty-four over here then you can do
something cool which is to throw away
psyche entirely and now you have these
augmented structured sources that
contain information they didn't contain
before so they're a little bit more
complete than they were before this
process happened here's an example that
occurred more recently than the one I
just showed you in which analysts were
asking on psych what cities were
particularly vulnerable to anthrax
attacks and you have to know things like
the number of suitable zoonotic hosts
residing near each large city in the US
and if you're not careful you add things
like the number of chickens on the
number of pullets and you get a wrong
number because if you don't know that
pullets are a kind of chicken then you
accidentally add them together that sort
of thing by the way in case you wonder
the answer is the lucky winner today is
Phoenix and it's basically because
Phoenix is
warm enough and it has enough people it
has an astonishing astonishingly large
number of animals living near Phoenix
and some horribly small number of
hospital beds per resident in Phoenix
and so on so that makes it particularly
good target for anthrax attacks and if
you ask why Philadelphia it's unsuitable
it's because Philadelphia was too cold
on the day we ran this and so on it's
worth mentioning that there is no one
correct monolithic ontology a lot of
times people mistake the psyche effort
as trying to claim that there's a single
correct monolithic organization of
knowledge set of knowledge to tell the
system about that's really not the case
Sykes axioms are divided into a vast
number of locally consistent contexts or
what goo ha called micro theories on and
you can think of different attributes
like time things true at one time and
false in another things true at one
level of granularity and false at
another so you end up with apparently
superficially contradictory statements
or things believed by one group and not
believed by another like who killed
rafik hariri and so on if you didn't
allow for this kind of local consistency
but global inconsistency you'd quickly
never be able to accommodate something
as inherently inconsistent as the human
mind let alone humanity's world wide web
there is a single correct monolithic
reasoning mechanism namely theorem
proving but in fact it's so deadly slow
that really if we ever fall back on our
theorem prover we're doing something
wrong by now we have over a thousand
specialized reasoning modules and almost
all the time when psych is doing
reasoning it's running one or another of
these particular specialized modules for
instance on TV a which is transitive via
argh that was used in the canna can can
can is used for rapidly answering
questions that involve transitive
relations and graph searching on
transitive graphs of relations and so on
it's also worth mentioning that almost
everything in the system is true by
default not absolutely true you can
later learn things that will cause you
to disbelieve something that you used to
believe after all so we reasoned by
argumentation we gather up pro and con
reasons why we believe or don't believe
something and let different meta-level
heuristics if necessary decide whether
the system should believe something or
not there are also cases where an
analyst or a typical user will want the
pro and con reasons in this case who was
behind a certain event or whether Bill
Clinton was a good president or
something there is no single right
answer there are pro and con arguments
in each case a lot of times people ask
me things like how many predicate sand
concepts and assertions are there all
together in the knowledge base and so I
have a slide like this to forestall
those questions but really this is a red
herring and you shouldn't really care
about these numbers to give you an
example of why you shouldn't a small
number of what we call sibling disjoint
assertions in the knowledge base take
the place of billions of class level
disjoint pneus assertions and really
hundreds of trillions of instance level
non set membership assertion so like if
we have a question like is any seagull
also a moose now psyche should and can
answer this question by the way the
answer is no and if psych news let's say
10,000 kinds of animals that means there
are about 100 million questions like
this it ought to be able to answer so
option one is we could add a hundred
million assertions to the system then we
could change this number 2 103 million
it would look really more impressive but
we're not here to look impressive we're
here to do as much as we can with the
smallest number of axioms like piano did
having you know five axioms for
arithmetic is really impressive so
option two is we could basically add 50
million disjoint with assertions and one
single assertion that says disjoint
nathji with is symmetric a better option
is to add 10,000 linnaean biological
taxonomy assertions and one single
sibling
destroyed Nyssa sir shin which basically
says if you've got any to tax ons and
you don't know that one is a
specialization of the other assume
they're disjoint so if you don't already
know that seagulls and moose is one of
these as a specialization of the other
from those 10,000 assertions just assume
that they're disjoint tax ons so that's
a really good rule and with these 10001
rules you can answer those same hundred
million queries or depending how you
look at it like was Bullwinkle a seagull
you can answer hundreds of trillions of
queries okay so you get the basic idea I
don't have time to go into detail of
what's in the knowledge base but just to
give you the rough flavor of a few
things that are in there we have dozens
of ways of talking about the way that
something that exists in time relates to
something else that exists in time like
starts after the start of and using
those kinds of relations on you can tell
the system things and get the kind of
deductive answers you'd expect like if
Sharon was in Jerusalem pretty much all
of 2005 and condi rice was there for 10
days during februari of 2005 then yes
they must have been in the same city for
at least a few days during that month of
that year and then other pieces of
knowledge would tell you that people
with their respective positions would
surely meet even if there was no news
story to that effect lots of senses of
physical containment so you want to be
able to answer questions like is the
Sonora Desert part of the sum of
California Arizona and Mexico actually
the answer there is yes and so on dozens
of senses of physical containment and if
you don't distinguish these dozens of
meanings of in if you just use the word
in because in English we just use the
word in then you will get some questions
wrong that you otherwise would get right
even things like whether something is
nailed into the wall or screwed into the
wall you get the answer wrong of what
will happen if I pull this off the wall
so slowly we've had to add metaphysical
distinctions that are not captured
linguistically of course you can express
them in phrases and sentences in English
but they happen not to be captured in a
single English word or a single Japanese
Chinese word but still they've turned
out to be useful and so that's why I'm
the number of predicates even in our
system is fairly large over 10,000 types
of events ranging from things like I'm
giving somebody something to pumping
fluid to thinking and so on four hundred
ways of relating a participant in an
event to that event like something
that's created during an event or
somebody who did the event or something
like that lots of ways of talking about
emotions and contradictory emotions and
what led to various emotions and what
the impact of having an emotion is and
so on lots of propositional attitudes
like knowing dreading believing desiring
perceiving and so on all these are modal
they go beyond first-order logic and so
again kicking and screaming we had to
extend our representation language to
second order and then eventually end
order predicate calculus because
otherwise they're just lots of things
that you can't express that you need to
express because human beings deal with
this like Israel once Egypt to believe
that the United States would never dot
dot you have to be able to communicate
and represent those and if you can't
then your language is I'm only going to
represent a fraction of what human
beings know and communicate with each
other thousands of kinds of devices of
various kind and device predicates and
so on so basically the question is how
we're going to build this we started on
in 1984 originally my work in the 70s
dealt with things like machine learning
the trouble with machine learning is
while one of the good properties seem to
be that learning occurred at the fringe
of what you already knew so you learn
some new thing is similar to what you
know already and here are the
differences so you could learn things
that were one step away from what you
already knew so the more you know the
more rapidly you can learn but
unfortunately if you're way over here on
the x-axis your way over here on the
y-axis and a lot of our learning
programs were there 40 years ago a lot
of our learning programs are still there
today they don't know much they can't
learn much to the extent that they
appear to learn they're largely either
doing statistical parameter fitting
which of course is extremely useful
limited in terms of what you can learn
or they're discharging potential energy
that was stored in them by their
creators and since I wrote a lot of
those learning programs i'll say
unconsciously stored in them by their
creators potential energy in the form of
a judicious representation to use a
perfect set of training data to give the
system a perfect choice of what
variables to pay attention to and so if
Kepler it had this little table of nine
our guests in his day five pairs of
numbers he would have come up with
Kepler's law in an afternoon rather than
in a lifetime so you get the appearance
of learning without really deeply
learning on if you if you try this
approach and over and over again people
who've tried to learn from scratch to
get programs to evolve and so on have
run into this problem you're able to get
parametrized learning of what you
already know but it's very hard to get
the system to take off unless it already
knows an enormous amount about the world
so we have to prime the pump so then we
thought well we could get the system to
understand English to understand and
process language then we could just read
all the online material and even in the
early 80s we believed that something
like the web would be coming and there
would be massive amounts of online
material to read but if you remember all
those examples I gave you about why
natural language understanding was so
hard basically you have to already have
a lot of common sense in order to
benefit from reading natural language
except in isolated ways which we'll see
in a little bit so the sad realization
we came to in the early 80s was to get
the knowledge prompt prime to actually
build enough of this end to prime the
pump we'd have to manually add pieces of
information one after another to the
system till we got enough in there that
we could get natural language
understanding until we could get
automatic learning to take place so the
calculation we did on the back of an
envelope actually Minsky I'm insisted on
an actual envelope so he could do the
calculation on the back of it was that
on the order of a person millennium of
effort is what it would take and just
about this time I'm Admiral Bobby Inman
came to see me I was a professor at
Stanford and he he basically said like
you've got like half a dozen graduate
students here
you do the math if you're really serious
about this you could work for 200 years
and maybe get this done or you could
move to the wilds of Austin Texas on
have 50 people or a hundred people work
on this and live to see the end of it so
it was a close decision but I ended up
deciding to move to Texas and to make a
long story short that's basically what
we did so we spent ten years at MCC
getting this pump primed we spent the
last 12 years as a separate on spin-out
company I'm called psych work continuing
to do that and to make a long story
short after a couple decades of working
on it we got close enough to this
crossover point where nowadays most of
the activity that we do in our company
is not this manual monks in cloisters on
scribing on illuminated manuscripts to
add the 3 million and seventh piece of
information but rather learning by
automatically extracting information
from the web and extracting it in many
cases from natural language on the web
to give you an example of how we do that
and this is stuff that was motivated by
Peter Norvig and on some other folks and
again you probably know the history of
all this better than I do but basically
every time you have an organization for
instance Abu CF there are a hundred
things you want to know about it who are
its leaders where was its headquarters
on when was it founded and so on for
each of those we have various ways of
generating some English sentence
fragments that would basically be a way
of saying in this case when the
organization was founded so you simply
hand this to google and you get your
answer in this case you get something
that says in the early 1990s and we have
a way of representing the early 1990s
some other source might actually have
the date various sources might have
conflicting dates and so on so not all
the information you get this way is
reliable in fact only about fifty
percent of it is reliable here's another
example for the height of the Eiffel
Tower where basically you have various
ways of fishing for this and in case you
wonder why there's only fifty percent
reliability well you know why did is why
does it say the height of the Eiffel
Tower
is 36 feet it's basically because if you
go there the very first hit that Google
gives you says you know the height of
the Eiffel Tower is 36 feet now it
continues on after that but still if you
just read the first part of the sentence
you'd get the wrong the wrong answer
there so the cross out line basically
means sike using knowledge of monuments
and towers to know that 36 feet is
probably the wrong answer and hundreds
of feet is probably the right answer
here's another case where there's not a
single marital status but there's a
small number like half a dozen different
marital status a--'s so for each one of
those marital status a--'s you do what
we just said and in this case on in the
case to see if he's married I'm you
generate on various things like this and
you find out yes something talks about
his wife and so he's probably married
and so on so we did some experiments
about five years ago for could we
actually populate sykes knowledge base
by doing this kind of fishing on the web
and we basically found that the answer
was by and large yes for various kinds
of predicates you could get fairly high
rates of success so remember what we're
talking about is translating from sykes
formal predicate calculus language to
various English forms handing those
English forms to search engines
sometimes we use altavista because it
allows us to put in even longer queries
character wise than goop than google
does and then based on the results from
that translate those back into predicate
calculus and we were able to get
hundreds of ground atomic formulas ones
that don't involve variables per hour
that way which is pretty exciting in
case you wonder why it's not again a
hundred percent accurate in this like
the hats worn on head it turns out if
you look through the top whatever it is
10 or 20 hits about half of these aren't
hat on head their hat on something else
like hat on nose or hat on legs or
something and that actually goes back to
one of Peters examples actually about
water flowing I'm downhill it turns out
because most people in the real world
know that water flows down
he'll if you look on the web an awful
lot of the expressions on the web are
water flowing uphill used for
metaphorical effect and so the web is
written for people who already know that
water flows downhill and it's like
confusing or stupid or bizarre to
actually say that in writing and so if
you're not careful you end up getting
the sort of fifty percent hit rate fifty
percent error rate so what are we going
to do about that what we decided we
would do is take the cycle that got
produced generate alternate paraphrases
in English generate different ways of
saying the same things in English negate
half of those hand that to novices tell
the novices on these web volunteers that
they're playing a game a matching game
very similar to the ESP game that CMU
has come out with for I'm captioning on
images and if you go to our website you
can actually play the game and
afterwards I can show you a live demo of
it I did bring a few PowerPoint slides
in case something went wrong so I'll
show you a few PowerPoint slides but
basically the people who play the game
are told things like the act of
clenching one's fist expresses
frustration and they can agree with that
or not agree with that or whatever and
if enough people agree with it then the
system believes that and half the people
we're told that it expressed something
else just to make sure that we're not
putting in stuff that on people just say
yes to all the time and sometimes their
order of magnitude questions like this
like what's the rough order of magnitude
of size of most liquid products you know
atom-sized or whale sized for
shoebox-sized or something like that and
once we know a whole bunch of things
which are shoebox-sized then pairwise we
can ask volunteers which of them is
bigger than which other and so on so to
get the basic idea because psyche has no
actual taboos on it occasionally on asks
you questions that are like embarrassing
but you know you win some you lose some
this is actually a reasonable question
even if it's a little bit embarrassing
so to get the basic idea so there's a
kind of apparent conflict paradox
between what needs to be shared if
you're really going to have the semantic
understanding
and the fact that there is no correct
ontology so this is actually the
beginning of the summaries I'll try to
wrap up in the next five minutes or so
so what needs to be shared over the
course of the last five decades people
have slowly move down this list a lot of
the Semantic Web people still believe
that something like sharing on XML bags
of keywords or XML terms is going to be
enough the trouble is that 12 different
sites will differ on what the meaning of
an employee is or what the meaning of a
company vehicle is or what the meaning
of a holiday is and so if you're not
careful you have the appearance of
understanding without real understanding
if all you're doing is trying to find
relevant pages that's not so much of an
impediment but if you're trying to
answer arithmetic or logical questions
by combining information then small
errors magnify as you combine the
information to actually get the answer
for the user so you really need to share
content and you need to share not just
the meaning of the terms but the context
in which various things were said who
believed this when was it true I'm at
what level of granularity was it true
and so on so if you're not careful if
you just look at something like RDF you
have a handful of relations even
something like damn LOL al you have tens
of relations what we've found is that
you need tens of thousands of different
relations to really capture the nuances
that will keep you from making the sort
of brittleness errors on you could think
of this as the analog of why do we have
more than 5 or 50 words in English you
know basically because if you try to
limit yourself to that smaller
vocabulary I'm there's going to be an
awful lot of misunderstanding among
human beings when I say there's no
correct ontology I mean things like like
our poinsettias red flowers well it
turns out they're not really flowers at
all but if your spouse asks you to pick
up those red flowers that he or she
likes and you come home and you don't
have them and you say I didn't pick them
up because what you like our poinsettias
and poinsettias aren't flowers that's
not a good thing
to do it's not a good strategy so there
is an ontology of like survival in
everyday marriage for instance in which
you damn right poinsettias are red
flowers and there's an ontology in which
apes are monkeys and an ontology which
monkeys or Apes and so on so basically
this is where contexts come in where in
one context one generalization
relationship holds in another context
the converse or no relationship holds so
you really need to divide your knowledge
base up into locally consistent contexts
much the same way that the earth is
locally flat even though you know that
it's globally round and spherical you
act as though it were flat and that's
okay because it is locally flat in much
the same way our inference engine acts
as though our knowledge base were
consistent and that's okay because it's
locally consistent I'm going to skip
this issue but basically there's no
correct knowledge base facts that are
believed at one time or one by one
person even things like if it's raining
you should carry an umbrella which you
might think it's pretty uncontroversial
well that's really only true if we're
talking about human beings after the
invention of the umbrella and not if
you're about to like go swimming and you
know not if you're someone who is
basically dying of thirst and you know
things like that so each assertion has
to be put in the proper context and by
now we've identified about a dozen
different facets or attributes or
dimensions of context space or micro
theory space and I won't go into them
here but I have a long article about
this if any of you are interested in
that and their various calculi for the
system automatically deciding things
like when you can consider if you've got
a piece of Pennsylvania and a piece of
1985 is this statement still true well
yes in this case Thornburg is still
governor and Reagan is still president
but if we had said things like there are
nine hundred thousand doctors in the US
it's not true that the nine hundred
thousand doctors in lehigh county in
February of 1985 so you have to be able
to know when you can and can't do these
sorts of conclusions like
because I'm talking from 1 to 2 doesn't
mean that i'm talking at any particular
second well it may seem that way but not
at every single second during this hour
so there's sort of a complicated
question of if p is true in one context
and P implies Q is true in another
context in what context can you validly
infer Q and that turns out to be a very
complicated question and we're slowly
making progress on the system
automatically being able to answer that
so how do people harness our system they
extend the ontology they add new
vocabulary terms they add new assertions
in many cases using those new terms in
very rare cases they have to add new
reasoning mechanisms to the set of a
thousand heuristic level mechanisms that
we've got and at another level what
people are doing is making use of our
ontology which we've made available for
free even for commercial use for anyone
who wants to use it our they're also
using the entire knowledge base of the
several million assertions involving
those terms which we've made available
for free for R&amp;amp;D purposes for anyone who
is interested so if any of you are
interested we encourage you to make use
of research like in your R&amp;amp;D projects
and if you have the time and want to
play that factory game as one of our
volunteers you're more than welcome to
do that so open site contains about a
million assertions even though it mostly
contains the hundreds of thousands of
concepts just the simple taxonomic
assertions it contains are on the order
of about a million research site pretty
much contains the other couple million
assertions we have a moderate number
even though we haven't been advertising
this in a big way we already have a
hundred thousand people using open sike
in various ways and almost a hundred
different groups around the world who
are using on research like for various
purposes so summary was I showed you
some examples of questions that are just
sort of heartbreaking in the sense that
Google can almost but not quite answer
these questions the final arithmetic or
logical step still has to be done by
human being that we could somatically
break that bottleneck
if we could get the system to even
partially understand the queries and the
content and that you can do that by
priming the pump getting enough
knowledge in there that the automatic
mechanisms that you guys are all
interested in doing could use that as
grist could use that as a starting base
to rule out statistically implausible
and semantically implausible conclusions
that were gotten by the learning process
so we pretty much have prime that pump
over the last 22 years and we're now at
the point where we're focusing on on
that kind of learning and knowledge
acquisition we look forward to working
with any of you who are interested to
help accelerate this process so that we
can achieve Sergei's goal of a general
AI by 2020 thank you so I'll take a few
questions I'll folks have and those of
you who want to see some of this stuff
live on a very small screen come on up
and actually we can try again to get it
to project because using the washer
repairman heuristic on this time it'll
work yes yeah so our original plan in
1984 involved an awful lot of human
subjects work with young children and so
on looking at children's books looking
at the Y well I'm trying to member what
it's called not why we learn to that's
why it's true or something series of
books for kids and so on and basically
what we found on to our chagrin was that
I'm reading children's stories and
talking to children was in many ways
linguistically just as complicated as
reading adult stories and they're all
sorts of additional complications like
for no reason that we could tell in
children's stories it's okay for animals
to talk with no explanation
but it's not okay for animals to fly
with no explanation you know it's like
you know what the hell so it basically
became more complicated and if you look
there just a very very metaphor laid and
effective anything children's books and
children's science books and so on are
even more laden and riddled with
metaphors and analogies to try to reach
kids than college textbooks on the same
subjects and so on so somewhat grumbling
Lee we were forced to sort of cut back
on that kind of work however one of the
things we do is to constantly ask our
people to come up with these common
sense test remember I said we had this
large library of common sense test that
we're constantly asking the system as a
way of measuring progress and a lot of
those common sense tests are what's
something that you noticed your kid
saying the other day that caused you to
realize your kid knew something and see
if psych knows that thing so we
definitely are interested in what kids
know it's just that many of the
structured programming structured
content like on Sesame Street and so on
is something that it's going to take
psych plus additional knowledge in order
to really make effective use of yes the
quay you can infer the question from
that answer but I will I will repeat the
question next time other questions yes
does the stories cover wife
work
what about say that question of like the
virus
yeah so that's that that's a good that's
a good question the and one level I
basically want to tell you that in order
to do a good job of that we would have
to do a vastly better job of integrating
probabilistic or uncertain reasoning
with the kind of logical inference that
we do so having said that by the way we
keep waiting for someone to do that so
five years ago we were waiting for
Daphne Koller to do that we're still
waiting and we're still following folks
who are doing that Michael you're just
waiting to tell us yeah yeah so I was
going to okay so that was the next thing
I was going to mention which is having
said that we can't do that yes under the
covers slightly we're starting to work
on little projects to try and do some of
that and in some cases were able to come
up with fairly provocative scenarios
abductive Lee of essentially terrorist
threats that the government should be
watching out for not so much working out
the third or fifth decimal digit
probability or even the first decimal
digit probability but still coming up
with things that are likely enough that
it's worth a human worrying about this
or that particular scenario so we're
just at the stage of grappling with this
issue and I look forward to the day when
all of the issues that we're grappling
with our sort of at this level rather
than the kind of slowly pulling the
system from idiot savant to enough of a
kind of a artificial but still ignorant
human being that it makes sense to try
to get that next level of education done
Michael do you want to come and use the
microphone this is Michael wit Brock is
our DP of research so there are some
things that you can do a purely the
Dutch a deductive reasoning for
prediction so for example psych contains
a large number of int so things like
what goes on in a kidnapping and one
thing that we've got in fact several
projects are both in the past and
ongoing at the moment with the
government is trying to do that sort of
avene recognition so if you've got some
idea you've got a
some indication that you've got it some
sort of have been going on you can then
take the roles which are instantiated in
the event which has happened so far and
use those to protect what's likely to
happen in the future and that is
something that you can do usefully we're
purely deductive reasoning you can do
even better at it we think if you're
able to do probabilistic reasoning
especially with respect to recognizing
what have been type some are probably
going on well one other example of that
is if you have a comprehensive knowledge
base you can do is to reliable
statistics based on that so one of the
largest contracts we actually have
gotten was from the department of
defense to build up a large terrorism
database large terrorism knowledge base
in psych and so you can basically once
it's complete you can already do this
but not as accurately you can ask
questions like in cases in the last 15
years when Hamas has abducted someone
and ended up killing them what was the
number of hours or days between the
event and the the killing and if you
have a complete database it's not rocket
science to answer a question like that
so based on that you can begin to make
quantitative predictions about the
future and so on sort of evil purposes
so can google but it seems like that
yours is a little bit more directed
right cuz I mean if I wanted to go to
google and say you know tell me a city
that you know has lots of birds and you
know few hospital beds it would be a lot
of work seems like it would be a lot
easier and i'm not sure if there's a
good answer to that question the second
question which you can also dress is I
noticed that you had a prod like some
sort of product that you're pitching for
sort of security called like secure site
or open secure psychic or something like
that and I wonder if you could tell us
about that okay so on I don't have a
great answer although I have an answer
for the can this be used for evil it's a
kind of radar gun radar detector
situation where of course the technology
can be used for ill as well as for good
if you look back to electricity or
almost any power source the same thing
can be said for them in fact the first
practical the first commercial
application of electricity the contract
that was fought over bitterly by both
Westing
and edison was for the electric chair
and when westinghouse one that contract
on edison for many years tried to get
the verb to Westinghouse to mean to kill
by electrocution but yes of course any
power source can be misused but by and
large on the US government is much
better funded and much better informed
than the terrorists and I'd much rather
see these tools in the hands of people
working to safeguard this because
basically on yes it may take the
terrorists 15 minutes to answer the
question of on cities that are warm
enough and have enough animals and so on
using only google but the you know
they're going to spend the 15 minutes
and so i'm given that they're going to
be getting these answers anyway i don't
think we should apply the kind of
ostrich head in the sand approach of
let's not develop the technology because
it could be used for ill I think overall
if you think about what artificial
intelligence could bring to the world
it's a kind of amplification of the
human mind in much the same way that on
physics and engineering has amplified
our physical cells to enable us to do a
lot more than our muscles can in terms
of how far and how fast we can travel
inhale far we can shout to another human
being and so on in much the same way
that biology and medicine amplify our
physiological selves we live longer less
disease ridden lies so that kind of
mental amplification would allow people
to misunderstand each other less by
doing a better job machine translation
for example in real-time translation
would enable people to be more creative
to search deeper to search faster to do
more things in parallel and if we as
individuals are smarter than I believe
it's going to follow that we as a
species are going to become smarter and
if you look back historically at when
the last time was that our species got
qualitatively smarter that way you
probably have to go all the way back to
the creation of language and say well
just like we look at the pre-linguistic
cavemen and say they weren't quite human
were they I think in the distant future
people will look back at us at this very
moment in time and say they weren't
quite human were they
on then in terms of your second question
as far as psych secure one of the
commercial applications that we're
trying to push not not actually getting
commercialized but we'd like to see it
commercialized is using psych to come up
with attack plans and defense plans that
would work against and defend for a
particular Network so here's a plan
that's a 30 or 40 or 50 step plan that
would only idiosyncratically work on
your network and it only works because
this person takes their lunch hour at a
certain time and these three machines
are near each other physically and so on
and maybe it involves real-world steps
like calling in a false fire alarm and
who knows what so basically used Sykes
knowledge base and use just plain old AI
planning to come up with attack plans
and defense plans using something like
bug track do dessert and so on as the
zeroth level plans for what are the
zeroth level ways of causing problems or
having vulnerabilities in known
commercial pieces of software out there
and having an ontology which we have of
different kinds of attacks and different
kinds of mischief and harm that people
can cause to a website or to accompany
tony is microphone the reason that
hasn't been visualized is due to a lot
of very silly stuff other people's
staffs failing sorts of reasons and we
were very much
to for example have a good knit with his
bid to try to push that for today so I
do contact you about yeah me about them
we can give you all sorts of information
about see or talk more about them yes I
didn't want to do any finger-pointing
but basically that's what happened which
was an under capitalized company that
tried to commercialize it unveiled and
now we're back to starting to
commercialize it once again one way you
might gain capital for that give them
the thing about the whole plot of when
it ends up by someone are taking a
ticker lunch hour etc you thought about
selling that to same election is
impossible script but three more serious
question we have actually had one x
files based on our side okay three
questions possible some which were
related whether whether this was the
speed performance sorry you're breaking
up yeah that was a joke in the case of
the stuff we did for I'm hot pot we had
to perform in something like a 40th of a
second and that involved caching tables
of information from the system so that
we could do a good enough job in a small
enough piece of time and similarly we
have some other applications that we're
working on right now that require that
sort of sub second response time for
some of the complicated queries that I
showed you typically two or three second
response time is considered adequate but
we haven't ever really pushed too hard
on that the good news from your point of
view is that we just got a contract from
the US government specifically to speed
up inference in large knowledge-based
systems and so over the next year we'll
be having some workshops with
researchers around the world like mon dr
renkov and so on Jeff Sutcliffe and so
on to try to bring some of these
techniques together and to try to
harness some of their theorem provers to
try to speed up on by at least one or
two orders of magnitude on the way
inference is getting done a second thing
to remember is that you really have to
continue believing in Moore's law at
least for the next several years and so
something that's a few times
too slow right now won't be a few times
too slow in the future and all this is
without parallel ism so if we had
seventeen thousand machines working at
once i bet we could do a lot better than
if we just had one machine especially
one little you know one pound laptop
working for two seconds but no I design
answer to this if you look at problems
like those ones are answering up what
terrorist events happened in this
location carried out by this
organization against that sort sort of
target those generally answer in
somewhere between 10 and 100
milliseconds there are some which take
very much longer than that or so much
take this time than men I think across
the TV content test which is this large
corpus of discs where's the average time
to first answer for them is around the
second at the moment and its own so it's
it's going down so it's so than we would
like it to be especially since we'd like
to us be able to solve complicated you
know questions which require deep
influence but it's not unusable for many
applications right and I was about to
say there are a lot of applications
where a delay of a second or two is
perfectly acceptable especially if
you're getting a qualitatively better
answer than you otherwise would the
other two were I guess sort of related
them I guess they sort of trying to
reflection or meta information on how
knowledgeable is psych about knowing
when it doesn't know the answer or can't
come up with it I guess is retiring to
how it's learning from reading the web
and alike but not in a general sense but
also um you mentioned the context of say
Pennsylvania in 1995 how knowledgeable
are aware of it is when it would it be
for dealing with a fairly dynamic
situation where things are constantly
changing like the position of the
attacker is here now one second later
the position of the attacker is here etc
a lot of our applications actually are
of exactly that sort of nature of course
of action analysis and battlefield
awareness and things like that where the
situation is rapidly changing and so we
do have to represent on dynamic
situation snapshots and
four dimensional time-space worms of
situations changing and so on in terms
of Sykes knowledge of its own knowledge
base I would say it has an excellent
ability to represent all of that and
mediocre coverage in terms of what it
actually does currently represent but
there's no reason why the system itself
can't automatically learn a lot of that
material on its own by trying these
questions systematically and recording
what kinds of questions it does and
doesn't seem able to answer some faith
in terms of driving usability we're
talking about the answer the answer time
that sometimes it takes a long time to
answer questions even when the system
doesn't know the answer so one way that
we're trying to improve usability with
respect to that is you can usually do
some queries of the type of cycle answer
very quickly which allow it to work out
whether it's likely to have an answer or
not so in our interfaces we try to
reflect the system's estimate of the
likelihood that already our answer a
question of the sort that you're
formulating before you get to the end
announced answered so it's so we realize
that on this notion of knowing what you
know and knowing whether you can answer
a question is very important for the
types of question answering that people
do this is a very important facility
that human beings have and we're trying
to work out how to do that inside a
logical system and we've got you know
some approaches to it but we don't have
a complete solution yet right and some
of the common sense tests are things
like at this very moment that you're
running the test is George W Bush
inhaling or exhaling and of course the
right answer is I don't know and any
other answers in some sense the wrong
answer so there are tests like that
which basically depend on the right
answer being the system should know that
it doesn't know enough to answer this
question it should know that really
really quickly take maybe one more
question and and then call it quits for
this large assemblage but as i said i
welcome you to come up and take a look
at the system actually running
yes please
um no we don't have a the question was
was is there a an interface where people
can actually type in questions to the
system so we don't have something like
that yet but we're slowly inching in
that direction and I'd like to I'd like
to believe that in less than a year
we'll have some facility like that at
least in the form of structured I'm
question sort of like I showed you the
the the psych analysts knowledge base
where you won't be able to have a
blinking carrot and type in anything you
want but you'll be able to have
fragments of queries and fill in the
blank fragments and so on and by pulling
those together and filling in the blanks
there's a truly astronomical number of
queries you will be able to ask and then
have the system go off and work on those
queries well let me stop at this point
and thank you all again it's been great
on being here and I hope to talk to some
of you in the in the coming our thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>