<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit 2008 Day 1: Power and Green Computing | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit 2008 Day 1: Power and Green Computing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit 2008 Day 1: Power and Green Computing</b></h2><h5 class="post__date">2008-09-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9PlaqUq--1k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a delight to see you all here and
to see if we some familiar faces though
I guess the fact that I don't see more
as an indication of how long I've not
been part of the academic computer
science community I'm what you might
call lap stir reformed computer
scientists after about 20 depending on
when you start counting 20 25 years as a
computer scientist about four years ago
I started to shift to become someone who
works on energy and as alfred was saying
before I'm not a computer scientist who
works on energy I'm now an energy person
who happens to dabble in computer
science and I joined here about two and
a half years ago with the job of making
Google greener more sustainable and in
the process trying to help make the the
rest of the world more sustainable and
what I want to talk about is some of the
challenges and some of the opportunities
in making an organization like Google
greener a lot of those challenges and
opportunities apply to much of the rest
of the world certainly other
organizations with large IT
infrastructures or even small ones and
for that matter and when you start
looking at the the supply side of energy
then then the entire world so let me
start by saying that computing
technology has had an amazing track
record of positive impact on society and
huge transformations that we all benefit
from and that's one of the reasons I got
into it i think when i got into computer
science back in the mid-70s I certainly
didn't have a vision for what that
transformation would be like I know
there were visionaries at that point
talking about it I wasn't one of them by
any means but the I think the
transformation has been incredible I
look at my kids and what they just take
for granted and and compared to what I
grew up with and it's it's a huge huge
change we could do more and make even
more change hopefully most of it
positive with more computing
capabilities but more computing
typically has met and probably for a
long time will mean more energy and the
challenge there from my point of view
and the the the sort of field I've moved
into is how do we use less energy to get
the the same amount of work done and how
do we use greener energy ideally
completely green but you know we'll get
there eventually in the meantime how do
we make it progressively greener
and that's really what what I've been
focused on so I'm going to start by
talking about how to use less energy and
I just like to thank Luis Barroso and
hopes by for much of the content they
published a paper last year I think an i
triple e computer that I've liberally
borrowed stolen copied plagiarized from
so let's start and I'm going to focus
here mostly on servers since as you know
Alan put up the picture of our a picture
of our server farm or data center in the
dowels enormous building huge cooling
towers lots of power going in packed
full of servers and in fact those kinds
of facilities have gotten a lot of press
and there's been a lot of what I have a
few times publicly referred to as hype
and hysteria around the coming sort of
collapse of the industrial or modern
economy because all the power that's
being consumed by x server farms around
the world and how that's going to put
enormous strain on the electrical grid I
think it's mostly hype and hysteria
because in the process all of that
energy that we're consuming actually is
in many cases enabling less energy
consumption and other parts of the
economy by in order of magnitude but
it's still an issue we can't just
willy-nilly use whatever energy we we we
feel like we want to so today best
estimates are that worldwide electricity
usage of servers is around one percent
of global electricity consumption it
doubled servers from 2000-2005 could
increase by another 40 to 75 percent by
2010 from there depending a lot on how
many servers how much volume grows as
well as what the the growth curve looks
like for energy consumption you know per
unit that's where all the hype and
hysteria has been I think the
interesting thing is people aren't
really talking about this which is the
amount of energy used by PCs laptops
desktops workstations which is likely
much much higher the installed base for
servers in 05 was about 27 million it's
probably I don't know 40 or 50 now for
pcs in 2005 870 million it's over a
billion today okay
so one and a half orders of magnitude
more pcs use a little less power than
servers typically and their duty cycle
is different so when you factor that all
in you know pcs probably use something
like five times the total amount of
energy today you know this year then
servers do but people don't talk about
that because it's much more diffuse and
sort of scattered everywhere and they
can't point to others that big building
and there's you know water vapor coming
out of the cooling towers and we should
worry about that but I think we need to
worry about both so if you want to make
if you want to use less energy you have
to be more efficient the first question
is how do you measure energy efficiency
for computers for the last 30 years and
the pc industry people talked about
price i talked about performance they
talked about features i talk about price
performance right and we've improved
price performance you know Moore's Law
other innovations have allowed us to
improve price performance unbelievably
far more than any other technology I
know of over the last 30 plus years but
people haven't really talked about
energy efficiency and and I think the
right metric there is to think about it
as the amount of work you get done
divided by the amount of energy use in
other words how much does it cost in
terms of energy to do a given amount of
work the complication there is how do
you measure work because what you do
with a laptop might be very different
from what what you know Ed's doing with
his laptop might be very different from
what you know the receptionist's done
and the lobby is doing and very
different from what my kids are doing
it's very different from what our
servers are doing which are probably
different from what Wells Fargo servers
are doing so what's the right measure
for work in that process and you can
sort of think of this as a little bit
like computing speed / power Nords if
the things running at 2.7 gigahertz and
it's consuming 120 watts you can kind of
if you had those two numbers for a
system you could could you know compare
them but that's not a great metric
because computing speed is not exactly
correlated to work done as we've all
learned even though gigahertz certainly
for a long time was what systems were
sold so if you try to break it down
let's take work done / energy use to
break it down well it's really work done
/ the energy used in the chips and
that's really where the useful work gets
done in the CPU and the memory and you
know on the disk and so on then you want
to look at well the the chips are using
energy but not all the energy that goes
into a server or for that matter into a
PC actually makes it to the chips so
you've got to divide that by the energy
provided to the computer and then when
you talk about a facility like a data
center or for that matter of building
like this it's full of workstations and
so on look at the energy provided the
computer is divided by the energy
entering the building because there's
there's building overhead so in the
building and in the computer there's
overhead waste their power supplies here
that wastes significant amounts of the
energy that comes into them there's
cooling overhead there's overhead to
provide backup power and so on so all of
those things reduce your overall
efficiency and if you just focus on the
chips you could say well you know wow
I've got one of the most efficient CPUs
in the world that's great but again put
it in a system that throws away half of
the energy coming out of the wall and
put that in a facility that has a
hundred percent overhead so it's fifty
percent efficient the overall system
it's pretty bad so so this is computing
efficiency you know really what computer
scientists tend to focus on this is the
computer and this is the data center and
in in the data center world since people
like to be ordinary and and confuse
things they talk about pua which i think
stands for power usage effectiveness
which is one over the efficiency just to
complicate matters so it but it gives
you a direct measure of facility
overhead if the pua is 1.5 that says for
every one watt going to the computers in
the facility kapha wat goes to facility
overhead okay which would translate to a
efficiency of two-thirds okay so where
are the opportunities in energy
efficiency well one is in data centers
and this is an area where you look at
our facility in the dowels and we're not
going to give you a lot of details about
it the overtime I think over the next
few months in a couple of years we will
be more and more open about it but but
there's enormous opportunity to make
those facilities more efficient
Lawrence Berkeley Lab's did a survey
last year showed an average pua of 1.83
so if every watt going to the computers
across the data centers they surveyed
for every watt going to the computers
point 8 3 watts eighty-three percent of
additional energy went to cooling backup
power losses in power distribution
around the the facility etc etc lighting
the lighting is usually these days and
dense energy dense facilities pretty
small part of it that's I mean that's
crazy that ignores the additional
overhead inside the computers you know
weird but this is the way we've been
building facilities for the last 20 30
years because energy was cheap and we
didn't have to worry about it okay but
that's beginning to change our
facilities I won't give you an exact
number but they're much much more
efficient than this and one of the ways
we get that is rather than using
mechanical chillers the kinds of
packaged units you know cooling units
that you'd find on the roof of a
building like this typically or
something and where you're running
compressors to move the heat out of the
building instead we rely very heavily on
evaporative cooling which from an energy
point of view for for evacuating heat is
much much more efficient but to do that
and do that well and do it most of the
year there are a lot of things you have
to design pretty carefully and this is
stuff that I never learned anything
about in my 25 years as a computer
scientist this is about mechanical
engineering electro mechanical
electrical engineering and so on at a
scale that I think in fact when I think
about you know when I was in school back
in the 70s you know there were in in
electrical engineering departments there
were still people who did you know power
engineering but those parts of the
departments were beginning to shrink
okay I think this is an area where as we
start to build very large energy
intensive facilities and as we start to
think about from the point of view of
greening the energy supplied
transforming our energy infrastructure
that's an area that's going to need to
expand again and we're going to need
people who are trained in it and can do
research in it and so on
so I think we're seeing some cycles here
the other issue that is HUGE is data
centers that are underused so if you've
got a data center that's been built out
to be able to provide say 10 megawatts
of power to equipment in it but you've
only populated with two megawatts worth
of equipment you've probably got backup
power facilities oversized equipment of
various sorts and Power Distribution
oversized cooling that is now running at
very light and load and as a result all
of that is running typically
inefficiently and so you're wasting much
more than you would if you were running
say it at full load in addition and I
think Louise had a paper where he talked
about if you look at the provisioning of
capacity at various levels of a facility
from the rack level to the row level to
a cluster level to an entire building
typically what you find is that there's
a lot of stranded capacity that when
people build facilities they look at
what's the the nameplate rating of all
the stuff at a given level and then they
add it up and they keep aggregating and
they build out each level to be able to
handle the maximum peak nameplate of
everything that it feeds and you never
get even close to that and the result is
your building the cooling and the power
distribution in the backup power to
support much more than you actually can
put in there that leads to serious and
efficiencies so understanding what the
actual loads are in terms of power not
computing modes but power under real use
is important if you actually want to
build a facility and have it be be
efficient so this is an area where we've
been doing a lot I think there are
opportunities here for research there's
certainly opportunities for students who
are trained in the right kinds of things
to come in and help us and help others
and there's a huge opportunity for the
industry to reduce the power consumed by
data centers by thirty forty fifty
percent over the next five years by
better design of new facilities and and
simple changes relatively simple changes
to existing ones now the second
important area is in the computers
themselves
and one of the big opportunities there
is in the power conversion devices the
AC to DC power supply and the DC to DC
voltage regulators on the motherboards
in the server for that matter in a in a
desktop laptops do better certainly on
this stuff then the most then desktops
were many servers simply because of
battery life and because of the the you
know small form factor if they don't
make those things efficient they're
going to get too hot and you're not
going to be happy with them on your lap
and the battery won't laugh last very
long but in a typical server you most
power supplies lose about twenty five
percent of the energy coming into them
to heat so seventy-five percent of what
comes from the wall or from the you know
power distribution into the rack makes
it through the power supply to the
motherboard and we know how to do much
much better the technology's there in
fact we are power supplies are about 92
to ninety-four percent efficient in our
servers and we're not doing that you
know certainly we've got altruistic
motives in part but we're saving money
in the process and I think there's an
opportunity especially with the move
toward digital power supplies and
digital power conversion there's an
opportunity in fact to make those kinds
of power conversion devices much more
efficient without having to spend extra
money on them today they cost a little
extra to make them more efficient but
that you know certainly for servers that
cost you you get that that extra payment
up front back and reduced operating
costs very very quickly 4pcs it takes a
little bit longer maybe two or three
years for servers it's going to be
months but I think there's an
opportunity to reduce that cost premium
enormously the the voltage regulators
dc-to-dc converters lose another
twenty-five percent or more in a typical
desktop so if you look at a desktop what
you'll find is you got power coming from
the wall and typically half of that
energy coming from the wall is thrown
away as heat before it even gets to the
chips I mean a chips turn it all into
heat to they actually do some useful
computing in the process from an energy
point of view I want a computer
scientist
look at a you know desktop or a computer
and said well that's a space heater
right something else going on in there
it's basically just a heater is taking
energy you know from from the electric
lines it's turning into heat that's what
it does but the chips at least do some
useful computation maybe they could do
it more efficiently but the power supply
the dc-to-dc converters there's no
useful computation going on there it's
just voltage and current transformations
and you'd like those to be a lot more
efficient obviously they're cost
trade-offs but you can make them much
more efficient so one of the things that
we did last year was we started an
initiative called the climate savers
computing initiative which the focus is
basically to drive much higher
efficiency through IT equipment and this
is not mostly not a research effort
today it's an effort to set some
standards on efficiency targets and also
then to get purchasers to sign up into
pledge to buy high efficiency equipment
most purchasers today look at all this
one's cheaper all by that and I think
that's true for institutions as well as
as individuals one of the things we're
trying to do here is drive demand so
that is the demand grows for high
efficiency equipment the price premium
that's there today will go down because
it's mostly a volume manufacturing issue
not a technology issue and I know that a
few universities have have pledged to
basically to purchase high efficiency
equipment when they're when they're
buying pcs etc if yours hasn't here's
the shameless plug please join encourage
your institution to join I think there's
an opportunity to really transform the
market for IT equipment and and
particularly for power supplies and and
dc-to-dc converters and drive out in
efficient equipment from that market but
to do that we need to drive demand up up
quickly okay then the third thing is the
actual computers and today computers
especially servers have poorer energy
efficiency in their most common usage
range so
may be designed to be relatively
energy-efficient when they're completely
idle okay or when there are a hundred
percent utilized but most systems don't
spend very much time in either of those
regimes especially servers laptops and
desktops spent a lot of time just idle
but servers don't and this is a real
problems and talk a little bit more
about this and in fact this is a
distribution of CPU activity in a number
of our servers over a six-month period
this is one hundred percent utilize this
is completely idle and what you see is
that they aren't running full blaze are
do we ever running full-blast that they
spend most of their time from 20 to 45
or so percent utilize and a moderate
amount though not a ton down at the very
low end yeah question I believe this is
a snapshot of data from a bunch of
systems not just one so it's a range of
workloads but I think if you look for
most of our workloads and I suspect for
most server workloads if you look just
at a single computer you'll see a very
similar picture okay so they aren't
running full-blast and they mostly
aren't idle but they are running
something all the time most of the time
so from an energy efficiency point of
view you know you could ask well what's
what's if you know if i run a workload
to run them you know sort of flat out
what's my efficiency what's my work done
/ energy use so if i run some spec
benchmark and just crank it as hard as I
can and look at how many spec marks I
get in you know an hour and how much
energy i use that's a measure of
efficiency but for real systems that's
not very interesting because that's not
how they operate so you need a workload
that somehow captures this and you need
systems that are energy efficient in
this regime not just up here and down
here yeah your computer
deficient in so the question was doesn't
mean we just need fewer computers and
that our servers aren't efficient and I
think the answer that is unfortunately
no okay there are times when because of
when you have large-scale cluster based
services firstly first the overall you
need enough capacity to be able to
handle your maximum load with reasonable
latency for the users if lot depends on
your work would if you're running a
non-interactive service if you're you
know we have a scientific computing data
center well in fact you can probably
arrange so that you've got in you
probably in fact have very quickly after
you install a new supercomputer that
you're up in this range because you've
got plenty of demand and you're running
what are more or less batch jobs in some
sense and people are just cranking it as
hard as they can but when you're running
interactive real time services you need
enough capacity to handle your peak load
and if you try to run and this is where
my queueing theory is old and rusty but
if you try to run you know up in this
regime you're going to find Layton sees
going through the roof okay so you need
to be no more than you know sort of up
here in terms of utilization before you
start to see major increases in latency
and certainly for google we have made
latency and low latency a key design
goal for our systems right and when you
then look at well okay if this is our
design goal sort of at peak to avoid
large latency this is where you're going
to be most of the time because you're
mostly not for the whole system running
at peak okay mendel
okay so the question was this looks like
you just got a crappy load balancer
which I don't think is true so let me
let me go a couple more slides and they
will come back to that but one of the
messages here I think is that a data
center is not the same thing as a laptop
the workloads are very different the way
you manage it is very different and
obviously the energy demands they're a
little different than certainly from one
of these okay so but this really gets to
Mendel's question which is if you think
about a well-designed large-scale
internet you know huge cluster service
you want high performance you want low
latency you want high availability that
requires load balancing it also requires
why data distribution these aren't just
computations these are computations
involving data and if the data isn't
where the computation is running you got
to move it that's going to add latency
so you need services that that have data
distributed around and can run the
computations in appropriate places and
what that means is because of that data
distribution but because of managing
that what is typically then replicated
data you actually don't have much in the
way of useful idle intervals certainly a
system might be idle for a brief period
but it's not going to be idle for five
minutes or 15 minutes where you know
like with a laptop or desktop you might
say let's put it to sleep okay and you
have lots of low activity intervals and
I think today this is fundamental to the
way we're building these kinds of
services and for that matter I think to
the way many people most people are
building these kinds of large-scale
Internet services it's not fundamental
the way every data center based you know
sort of back-end business application or
services running but for these kinds of
services with replicated data high
availability low latency high
performance requirements I think that
this really is fundamental and I think
there's an interesting question of how
could you design those services i was
talking to Fred about this a little bit
last night how could you design those
services those kinds of replicated
services so that in fact you know when
load on the overall cluster is low you
actually could avoid those low activity
intervals on most of the machines today
they're required you know if you have
something where you so take gfs replicas
are on multiple machines you've got
reads load balanced very nicely and you
could choose to say well you know the
clusters that ten percent utilization
will concentrate all those reads on
twenty percent of the cluster and those
machines will be fifty percent utilized
and the others won't see any reads at
all you can say well now we could shut
them down or put them some very low
power state the problem is if there any
right you need to reach them all and if
anything breaks the whole cluster is
involved in rebuilding replicas and the
result of that is there's low activity
on every machine so could we design
those services in fact to be able to put
so that the machines that we choose to
direct load away from could actually go
into a very very low power state that's
one possible solution to these problems
okay I don't know how to do that very
well today and I think if somebody else
that would be great yeah yeah I just
want to ask a quick question about the
big thrust behind the server
consolidation and virtualization it
seemed like the graph you showed on the
previous slide where most of the
machines are running at twenty percent
or whatnot it's not say the average is
probably you know I don't know thirty
thirty-five percent right on those yep
the key is this exact motivation where
you can run two or three virtual
machines on a single physical machine
and then shut down some of the other
ones right so we do run several services
on any given machine we don't use us a
VMware other virtualization software
like that but we're effectively getting
that kind of effect the issue really
comes to if you shut those machines down
there now now not participating in the
replication service changes happen to
the data when you need to bring them
back up the question is how do you bring
them a
to date how long does it take what's the
latency to actually reintegrate them
into that replication service so they're
not simply machines you can say I'm just
going to shut them down and nothing's
going to happen that affects them okay
number one number two there is business
value and having machines that are idle
and ready to take on load very very
quickly so the latency to bring up a
machine and reintegrate it into the the
cluster of services is a key issue okay
but it's definitely something that that
you know increasing you know if we could
get our average utilization I mean I
don't think we'd want to go much about
fifty percent because then we'd start to
see latency go out because of queueing
but increasing average utilization to
forty-five fifty percent would be a
great thing but it's not a simple thing
yeah nothing to do with making computers
more efficient give you an example you
can scavenge vibration at certain
frequencies up to about sixty percent of
energy value so there's this trade-off
in your green program between you know
innovation in energy scavenging versus
potentially higher costs of
configuration and configuration and
design do pay attention to that or is an
outside of your realm
so the question was about energy
scavenging and whether your scavenging
vibration or waste heat or whatever
turning that back into useful energy you
can scavenge some of that wasted energy
whether it's mechanical energy or
thermal there are limits to what you can
get there and all of the solutions I
know they are don't get you very much
back and cost a lot so if you've got
finite budget and people to figure out
ways to do it better today that's not
where I would put my money it is a
trade-off and you know there's still
opportunities lots of opportunities in
our systems and in other people's
systems to do better that's one Avenue
at the moment I I don't see I think
that's one that needs a lot of really
basic research before it it shows real
promise to be deployed on any
significant scale right so question of
value of data versus physical
infrastructure where the data is located
in trying to manage that yes I think one
of the one of the things you could
imagine doing and saying you know what
some data is lower value or less
frequently accessed so we'll make the
will accept a higher latency to get at
it sometimes you know will spin down
disks and do other things that that mean
that sometimes we're going to take await
and see hit that might be okay for some
data but you have to be very careful
with the user experience this is one
things I learned at Akamai that if you
look at the latency curve that people
experience the tail of that curve really
matters and even if people experience a
very long wait and see quite rarely it
colors their perception of the overall
service an inconsistent access times or
response times Rio really really matter
in terms of user experience so it's
definitely something we think about but
something you got to be very careful to
okay okay so let me move ahead a little
bit
but one of the things that says is that
today given the way our systems and a
lot of other people's systems around
strategies where you put systems to
sleep or power them down for servers
aren't necessarily going to work very
well it's not easy to make those work
well and if you focus on energy
efficiency at peak performance which I
think's pack is beginning to where
they're looking at at spec power for
example that's not where systems run in
fact they're never really going to run
flat out if you care about latency so
that's the wrong the wrong thing to
really be focused on now an interesting
thing is if you look at power the
question is power efficiency versus
activity level okay so typical server
this is somewhat fudge data this isn't
exactly the real data but it's it's
pretty much what we've seen looking at
our systems and other people's systems
when a systems running at zero percent
load just idle it might be using about
fifty percent of the power that it uses
when it's flat out at a hundred percent
okay now down here notice that the
efficiency if we graph efficiency not
power efficiency is zero because you're
not getting work done and over here if
we normalize it efficiency is is one ok
but in between it drops in essentially a
quadratic curve ok so when you look at
say one-third of peak utilization which
is a likely activity point for a lot of
systems a lot of the time you actually
drop your efficiency by half so if you
measure efficiency here and that's what
you care about and you optimize for that
you're not actually running there a lot
of the time your efficiency is much
worse in terms of work done / energy
used at the points where you typically
run mendel
isn't this red wine set by the so this
line is the power used at different
activity levels now you're with power
manage say if we if we're thirty percent
utilization this is how much power the
system uses okay it is a function but
I'm talking about it is a function power
management rata Jesus but if you look at
the power management capabilities in the
hardware and the software on machines
today and ones that i know of coming out
this is the kind of curve you're going
to see okay and if you disagree i think
we should talk about it later and
certain size okay intel has some very
interesting road maps and i'll get to
that because that Intel is only a small
piece of the story okay so if you will
get this from spec power you see exactly
this if you run it a hundred percent you
know you get the this is and look at the
average power this is you're sorry this
is the power that's used for these
various target loads okay and this is
the power efficiency work done / the
energy use and when you look down here
at say thirty percent target load you're
at about half of the the efficiency 730
7/16 10 or less than half of the
efficiency when you're running a peak
load okay so that I think I mean this is
data from real systems running real
applications and I think if you
replicate this on other servers you're
going to find most likely very similar
data but there may be ways that you can
change it i think that one of the points
here is we need to change this okay so
the idea that we'd what we'd like to see
in our systems and in other people's
systems is systems where the energy you
use is proportional to the amount of
computing you get done so if you're not
doing any work you don't consume any
power that would be ideal
or very very little if you're doing some
work you consume some and if you consume
doing a lot of work you can symbol out
of power okay and then we wouldn't need
I mean if you had systems that did this
you wouldn't need power management
software you wouldn't need to have the
system go to sleep and sometimes fail to
wake up or sometimes fail to go to sleep
because drivers are hanging onto
resources and the system can't put it to
sleep you know the system would it would
just use less power when it's doing less
work so if your systems idle you know
fairly quickly it goes down to using
very little energy so the question is
what's keeping us from achieving that so
this really gets to your point about
Intel having all these wonderful
roadmaps intel and AMD actually have
done a lot to make cpus much more energy
proportional over the last number of
years both energy-efficient going to
multi-core architectures but also energy
proportional multiple power domains on
the chip where you shut things down when
they're not in use for example so if you
look at the different components of a
system and the power they consume at
different activity levels this is the
amount of power and nas's as a
percentage of peak amount of power that
the CPU consumes when you're running
flat out it's almost half of the power
consumed by the system this is D Ram
this is dis that's other stuff okay as
you drop the activity level the CPU
drops a lot the other components don't
drop as much so even if you got the CPU
20 even if you made this a straight line
okay you'd still have pretty significant
amounts of power being consumed at low
activity levels by the other components
and if you look at this now as a
percentage of the total you can see that
much more dramatically the CPU drops
from fifty percent to around thirty
percent of the total the others become a
much larger fraction so the CPU
especially at low activity levels
doesn't dominate the whole system it's
much more balanced among the different
components and really what's going on
there is the CPUs are fairly energy
somewhat energy proportional not perfect
yet but the rest of the system is not
the amount of energy consumed by dr AM
by desk by the other stuff doesn't
change that much
at low levels so why does CPUs manage to
do this well they've got a very wide
dynamic range where so nidal cpu
consumes less than thirty percent of
peak power other components it's fifty
seventy five eighty five percent of peak
power when their Idol so when their Idol
they don't throttle back on the energy
consumption very much and furthermore
for the very low power mode CPUs have
what you might think of as active low
power mode by scaling voltage and
frequency with CPUs you can still
execute instructions just more slowly
but that's okay whereas other components
the low power modes are mostly inactive
so you trigger those only one there's
zero activity you put the system to
sleep you have a very small amount of
power you spin down the disk you turn
off the network interface you have a
small amount of power going to maintain
the component of the contents of memory
but you can actually do any work in that
state so what we need is active low
power modes for other components or if
you're going to have in active low power
modes you need very very low latency to
wake them up okay which we don't have
today yeah flash storage has very
different characteristics than
questioners do is that we see this
changing as we transition to flash or
solid-state disk flash has very
different characteristics here and so
that and I think better in a lot of ways
from an energy point of view the if you
do put them to sleep well first of all
they're non-volatile so you can reduce
power consumption and the latency to get
them going again is very very low
whereas a disk if you spin it down
there's significant weight and so you to
spin it back up so yes I think there is
a potential for big improvement there
now when we will move to having no disks
in all solid-state I hesitate to go
there and you know I don't try to
predict that yeah
looked at the amount of energy required
to execute a user transaction how has
that Barry over the last few years and
this gives rise to are there algorithmic
issues and programming language issues
that arise in terms of how you implement
the activities that you're doing so the
question was if we look at the energy
used to execute a typical user
transaction how has that changed over
the years and you know how much is that
affected by software the programming
languages the tools the algorithms etc
in volume of data right so the data is
going up enormously as Alan was talking
about especially you start looking at
things like video at the same time the
density of disks has gone up enormously
so I think that the energy used to
execute a typical user transaction has
probably improved in the last few years
I think there was a period when it
wasn't improving much partly because the
CPUs were really pretty much flat in
terms of performance per watt or
efficiency but in the last few years
they actually have gotten significantly
better i think that there's still
enormous room for improvement by paying
attention to these kinds of issues in
the hardware software makes a huge
difference okay so if you write more
efficient software so that you can
actually get more done with the same
hardware and the same energy consumption
that's probably in some ways the easiest
thing to do or I'm going to potentially
the easiest software engineers would
probably say you're out of your mind
it's not an easy thing actually getting
higher utilization and tuning the
software isn't necessarily easy but
there is an opportunity there it's
something that we'd pay a lot of
attention to you know it's it's ongoing
you can't think you've fixed it and then
then you're done because people are
writing new software and you know
modifying existing software all the time
but that is clearly a huge piece of it
you know efficiency of the software in
using those resources translates very
directly into efficiency in energy
consumption so teaching people for
example you guys been out there edge
cating the folks were going to hire
teaching them about efficiency and how
to measure the efficiency of their
programs and beginning to get them to
think about not just computational
efficiency but energy efficiency and
teaching them about algorithms and how
to design algorithms that are more
efficient really really does matter
especially when you start talking at
scale like this if you're writing an
application for PC maybe the PCs more
than fast enough to just do what you
need to do and you know to think very
hard about it but if you're writing
something that's going to run on
thousands of machines if you can run it
on half as many machines you can either
save money on the infrastructure or get
twice as much done either though some
combination of two semantically can see
in this equation because I want an
answer that's good enough right right so
the question was about user latency
versus what you might think of a
semantic latency which is there a notion
of good enough for an answer and could
you say stop after some amount of time
or some amount of energy and say oh no
this is good enough or I've spent my
time or energy budget I'm going to give
you the answer I've got and that's
absolutely something that for a lot of
services really can can matter for you
know email when you want to click on an
email and see it well I can only give
you half the words but you know I ran
out of energy I'm sorry that doesn't
work okay but for an internet search you
know there is no single right answer you
just want a really good answer and so we
need to make sure it's good enough
resolution speed is not so easy right
right so different services think you're
absolutely right that the there may be
useful notions of resolution or good
enough for some and maybe not for others
okay so I just want to draw a quick
analogy and then I want to move for the
last few minutes to talk about the
energy supply side not just the demand
side okay you look at a person and a
typical desktop machine and they're kind
of similar in terms of average power
around 120 watts okay you look at the
you know performance or energy you know
power consumption versus activity level
for a pc and that's kind of what the
curve looks like 2x difference from idle
to peak you look at a person and this is
lance armstrong's Tour stage okay 1200
watts here and resting 61 okay so factor
or 20 not to order a magnitude
difference in energy proportionality
okay and actually the louise has a
really fun graph that shows a you know
whole range of activities that people
engage in that that really span this
range and show you a much more you know
linear curve here okay so there are lots
of examples of devices natural and
otherwise in the world that have this
kind of dynamic range we're not building
computers that way and i think the
simple answer is we never needed to it
wasn't that important i think it's
becoming important so what if we could
build machines that had an activity
range you know very wide dynamic range
here and energy yeah that that's
something that i think we really need to
work on so if you had a better server
and that's what the power curve looked
like you'd see an efficiency curve that
looked more like that and in the you
know this range a third of peak power
efficiency is above eighty percent of
what the power efficiency is at peak
that's pretty good okay so that that's I
think what when you destroyed for as
much as possible okay so let's talk
about the supply side which in fact is
where I spend most of my time you know I
kibbutz and
you know talk to luis and others who are
working on facility design and system
design about the demand side if you will
but I spend most of my time here in fact
on how to use greener energy and just to
give you a sense of what the problem is
that we're facing in the u.s. in 2004
and the data since then is pretty
similar Cole was responsible for about
half of the electricity generation and
coal from a greenhouse gas in fact most
other pollutants perspective is the
worst that we've got natural gas was a
little under 20 oil was very small back
in the 70s oil was pretty big for
electricity we pretty much almost
completely stopped using it nuclear is
about 20 hydro six and a half renewables
2.3 and then there's a little bit of
other stuff okay so well it depends on
who you talk to most people would say
it's renewable as long as you have good
rainfall patterns it has does have big
ecosystem impacts okay though the truth
is I think any large-scale energy
generation whether it's so or win or
something up there will be some impacts
okay but I think the real issue with
hydro is if we want to think about how
we replace all of these polluting
sources would account for almost three
quarters of our electricity generation
today with things that don't pollute or
don't put it anywhere near as much we
don't really have good opportunities in
the US or for that matter around the
world to expand hydro in fact the hydro
we've got may well decrease in its
output if we continued to see changes in
rainfall patterns that and particularly
snow patterns that people expect okay so
we could debate whether it's renewable
and invite some environmental so would
say don't call it renewable because it
has such huge impacts on on ecosystems
but it really doesn't matter because
that's not where there's room for growth
so but it gets worse and this is part of
why I you know reformed a few years ago
and became an energy person which is I
spend a lot of time thinking about what
I want to do for the next
my career and where was there an
opportunity in a need for enormous
impact and I thought about the problems
were facing in energy and in climate
this is where I started to get really
scared and decided to see if I could try
to do something about it instead of just
being scared so as coal is responsible
for about half of the electricity but
about three quarters of the greenhouse
gases so we can do all sorts of things
around renewables but the message from
this is that until they can compete with
coal we're not going to solve the
problem okay and in each of the last
four years China added more coal fired
power plants in the entire electric
capacity of Spain and as far as we can
tell for the foreseeable future that's
what they're going to do so until we can
come up with solutions that make it so
that China doesn't feel the need to do
this and that they can still continue to
grow their economy but not do it on the
backs of call I think that we're in
trouble and you know the Western world
the current developed world we build our
economies on call and other non
renewable non-sustainable very polluting
sources but we need to find a way to
transition our energy infrastructure and
find a way to help the developing world
grow and grow their economies but on in
a different way than we did and the US
and Europe sad to say are also adding
coal okay and there are reasons one its
cheap too you can get reliable what
people call base load power right that's
there all the time or most of the time
you obviously have maintenance outages
and so on where a solar and wind are
intermittent sun shines during the day
many days not all days the wind blows
when it blows but certainly not all the
time okay so you can't get constant
reliable firm power out of those sources
the other issue today and this is really
i think the the a key issue and the
problem is that from a cost point of
view renewables can't compete with coal
at all in China you know cheap
pulverized coal is somewhere between two
and six cents a kilowatt hour in the
u.s. it's a little more expensive maybe
three to seven
if you do gasification with combined
cycle it's somewhat more expensive but
if you most people aren't doing this
they're very few of these plants because
they're expensive and they're somewhat
cleaner but not a lot natural gas is you
know six to ten depends on the very
volatile with the price of natural gas
call if you do gasification and do
carbon capture and sequestration which
basically isn't being done at scale and
commercially today that's going to bump
the price up even more you know nuclear
and wind or here still more expensive
than coal wind you know sort of competes
economically with nuclear but it's
intermittent nuclear is a base flood
source so the value of nuclear is much
higher than if went to a utility and
then when you start to look at
geothermal solar thermal PV that that's
actually a very misleading bar for PV
because the ceiling doesn't go high
enough it's probably more like 25 to 35
cents a kilowatt hour okay just
completely out of range photovoltaic I'm
sorry okay solar photovoltaics so the
panel solar panels that when people
think Solar that's what they think of so
or thermal this is what people sometimes
call concentrating solar power it'sit's
Archimedes plus James Watt you you and a
little bit of high-tech materials here
and there you know you concentrate the
light you know I know you may have heard
the story of Archimedes with you know
the guys with the bronze shields
reflecting the light onto a attacking
warship and it burst into flames and
there actually been some interesting
experiments try to replicate that this
is a little less aggressive shall we say
but the idea is to concentrate sunlight
onto some kind of receiver and then the
most common thing that people do there
is that they heat something up it's
either water or something else that then
you used with through heat transfer to
heat water and make steam and then drive
a steam turbine so you got Archimedes
you got James Watt you know piece of
cake but it's expensive okay it's closer
than solar photovoltaic there's a pretty
clear cost decline curve that solar PV
and wind or on question is when are they
really going to be cost-competitive with
coal and so what are some of the
challenges and opportunities here what
one is to drive down the car
and we started a major initiative last
fall called re lesson see it breaks
every HTML page if you just type it in
there unfortunately you might think is
an Internet company that we would have
thought of that before we came up with
that acronym but it's answer renewable
electricity cheaper than coal so the
goal of the initiative is to drive
innovation to drive down the cost of
renewables and do that quickly and the
reason we thought that was something
that we wanted to do and that we
couldn't just leave to the the
marketplace and we don't expect we're
going to do it ourselves but the capital
markets today and for that matter you
know the government funding of research
is the focus is on getting to what
people call grid parity which really
means it's some level beating the price
of natural gas and it is I showed in
that first slide on this that'll solve
maybe a quarter of our greenhouse gas
problem from electricity but at least
three-quarters of the problem completely
unaddressed so we need to set a target
that actually will solve the problem and
our hope is that lots of others will
will focus on that as well Solar Thermal
csb and what people called engineered or
enhanced geothermal systems are probably
the least mature of the technologies
that could be done at utility scale that
could really power our economy and the
nice thing about that is that those are
as a result probably the areas where
those the most opportunity to drive
costs down quickly because they there's
still at the very steep part of the cost
decline curve that we could get on
through innovation wind is much more
mature there's still opportunities there
but they've been you know I think that
some level they've hit diminishing
returns in certainly current
technologies the other challenge and
this is quite an opportunity but there's
a huge challenge here which is how to
scale you know renewables are two
percent in the US or a little more than
two percent you know that order
magnitude worldwide how do we scale that
250 or eighty percent over the next 30
years if you start looking at the amount
of investment required and just the
amount of steel and you know etc the
sort of level of industrial stuff that
has to happen
its enormous and how do we do that you
know will the capital markets and the
sort of natural free markets do that on
their own and my guess is not fast
enough certainly to deal with the
climate problem and if not then what can
we do from a government policy market
incentive point of view research
investment etc to try to accelerate that
because I don't think we've ever there's
anything else where we've scaled as fast
as we need to certainly not sustained
for that long the transformation of our
industrial economy in World War two
where we basically just shifted to
building tanks and planes and so on
maybe as the closest analogy we didn't
do that for 30 years storage is another
key issue since the major renewables
solar and wind or intermittent
geothermal has a nice property that
actually it's just there so that's one
of the makes it very attractive but if
you're going to have intermittent
renewables you need to provide base load
power you know people need power when
they need it you better have some way of
dealing with that and then another issue
and this is where I think actually
computer science can start to play an
interesting role is that the grid itself
first of all from it just a power
engineering point of view it's ancient
okay we're building the grid with
technology that's you know eighty a
hundred years old so there's an
opportunity there to be much smarter in
terms of the the sensors and the control
of the grid but then I think there's a
very disruptive idea which is to start
to think about the way the grid is
operated today people dispatch the
sources dispatching means basically at
any point in time the the loads and the
sources need to match if you produce
more power than is actually being
consumed then you get frequency and
voltage fluctuations other issues if you
produce less than is being consumed you
get you know brownouts and other
problems so they need to be matched very
closely and that's what the grid
operators do they do that today by
having the power plants ramped up and
down their output to keep it matched to
the load but what if we were
to start thinking about dispatching the
loads not just the sources now obviously
there's some loads you can't do that
with you know if I'm sitting here
working and I need a light or this
projector needs to be on you know I
can't have PG&amp;amp;E saying you know what dim
the projector turn it off for a couple
minutes you know make for very weird
life but there are a lot of things that
actually you can choose when to consume
the power and still get the work done
that you need to get done so take
something like a plug-in hybrid car or
an electric car plug-in hybrids have
them are probably better for this but
you could choose when to charge you
don't have to have them just charge when
you plug them in they could charge say
when the wind is blowing and you're
actually producing wind power or cooling
air conditioning well if you've got a
cooling unit it's making cold air and
blowing it through the building you need
to do that when you need it you don't
want the temperature in the building
fluctuating up and down wildly but
suppose you put a buffer in between and
have the coin unit make ice or in some
other way make cold that you then use
when you need it to actually make cold
air you can choose then when to make the
cold and start dispatching those loads
and lots of major appliance of the same
thing right imagine if you know in the
evening I'd be happy to put the dishes
in the dishwasher close it hit a button
and it'll decide at some point during
the night when to run I don't care okay
but today I hit the button it runs if I
want to run at 3am I gotta set an alarm
and get up and I'm not doing that my
kids are too old I don't need to do that
anymore okay so this is an idea that
then becomes a massive information
gathering and then control problem but
it also there's the opportunity with
many of these devices to control it on
much finer time scales than people can
with the grid today which actually I
think weeds a not for an opportunity to
make the grid much more stable okay okay
so what are we doing let me just flip
through this I'm not going to talk about
it I'd be happy to talk one-on-one or in
small groups we're doing rd we're doing
some investments we expect to do some
academic research awards and invest in
renewable energy projects we're becoming
active on energy policy and we'll have I
expect a lot more to announce
the next number of months so that's it
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>