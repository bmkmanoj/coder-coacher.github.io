<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jürgen Schmidhuber at AGI-2011: Fast Deep/Recurrent Nets for AGI Vision | Coder Coacher - Coaching Coders</title><meta content="Jürgen Schmidhuber at AGI-2011: Fast Deep/Recurrent Nets for AGI Vision - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Jürgen Schmidhuber at AGI-2011: Fast Deep/Recurrent Nets for AGI Vision</b></h2><h5 class="post__date">2011-10-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rkCNbi26Hds" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm going to talk about now about the
second neural network Renaissance which
is currently ongoing and I try to show
you how you can win all kinds of pattern
recognition competitions using our
special breed of deep or we can't neural
networks AGI is driven by two types of
progress at least on the one hand we
have these new millennium results on
optimal universal problem solvers that
are theoretically unbeatable and
mathematically optimal but then we also
have another type of progress driven by
hardware advances computers are still
getting faster by a factor of 100 or
1000 per decade per cent and this is
what we are going to use in this talk a
long time ago 20 years ago my first
student support writer he showed that
you cannot really train deep networks
with many nonlinear layers or a deep or
recurrent networks which you can
translate into deep v4 networks which
have as many layers as there are time
steps in the sequence that you are
processing because there's this
vanishing gradient error problem as you
are as you are increasing the number of
layers nonlinear layers to which you are
propagating in these networks every time
there's a new layer or a new time step
you decrease the error signal by at most
a particular constant factor which means
that after it vanishes exponentially as
you are adding layers and time steps
which means that you cannot really
propagate far down in traditional
networks like this this prompted one of
the pioneers of neural networks to say
that nobody in his right mind would take
a deep multi-layer perceptron and and
train it by backrub I won't mention this
pioneer by name except to say that he is
Geoff Hinton
so nobody in his right mind that seems
like an accurate description of our
neural computer vision team here we see
Dan and Wally and Jonathan and Alex and
so we took deep multi-layer perceptron
with many layers and trained it by
background although my own lab showed
that you shouldn't really do that
however something has changed because
now computers are a million times faster
than they used to be 20 years ago and
suddenly we can propagate arrows down a
little bit further then be used to and
now we can have as many layers in a deep
network as our connecting our retinas
with visual cortex 7 8 9 nobody knows
exactly something like that and we
applied that to the most famous
benchmark of machine learning which was
developed in the lab of another pioneer
of neural network of young Lincoln in
New York and there's a long history of
Rockland benchmark records in on this
problem and many people use all kinds of
super support vector machines and
whatever however our approach achieves a
new world record just last year and then
we greatly profit from graphics cards
which makes everything 50 times faster
than on traditional CPUs now
you can further improve this result if
you take not only one deep network like
that but you can take seven or ten and
then each of them is slightly different
lis initialized and maybe has slightly
different P process in and you get
different experts automatically as a
by-product is a random byproduct of that
and then you do a democratic committee
which just takes the average of all
these of all these predictions of the
different networks and the result is
better than any individual network and
this led to a new world record on the
same data set which is now 0.31% and
what it's really what you really should
do is take not plain background but
something which is combining all kinds
of ideas that range back to fukushima
the neocon Neutron and max pooling which
is a way of down sampling
one layer to the next and convolution
and weight sharing where you have not as
many three parameters as you would have
in a plane deep network and then the
current world record on that Emma's
problem is 0.07% you can also do other
images with that for example this is the
cypher object recognition problem of
Jeff Hinton's group in Toronto and then
we also just a while ago broke the
record on that one
and the current one which is not even
published yet is now 13% on this one
yeah there you have to distinguish frogs
from cara's and-and-and-and-and and
horses and boats I have a lot of
problems with see with the frogs and
just a while ago
Willy and Dan they they were
instrumental in winning the Chinese
handwriting recognition competition
which where we used exactly the same
approach now that's an interesting
problem because unlike with eminence for
example you have not only ten different
patterns but 44,000
and they're weak at the first on the
second rounds that was just a two months
ago and if you look sand at the details
of these these feature detectors that
are being learned automatically as a
byproduct of these deep networks you see
the stuff that you know from vision of
decades ago you get automatic
automatically you get Gabor filters and
on center of surround detectors and
orientation sensitive by detectors in
the lower layers and as as you are
looking at feature detectors and higher
layers they get more and more or Park
and in transparent ins listen to this
clear what's going on there just like in
human brains now we apply the same thing
to the no object recognition benchmark
and also set a new record
so I'm sorry my slides are going to
remain boring like that for a while but
then they will become boring in a
different way
yes the traffic sign competition that
took part in January there was an online
traffic sign competition and and our
toughest competitors usually are those
from young lakhan's lab it's interesting
to see that only neural networks are in
the in are now playing a part in these
competitions and no support vector
machines no boosting and all these
things it's a competition mainly between
networks now which is kind of unusual or
unexpected because ten years ago neural
networks almost vanished from the scene
because support vector machines were so
much better in many applications and for
a long time it was not possible to
publish anything at the leading neural
network conferences that had the word
neural in the title and and there on the
last day of the competition where we
thought we have a comfortable leads and
suddenly a PS M&amp;amp;E of young lakhan's lab
he had an even better result and then
down in early and Jonathan worked late
night to and to reestablish correct
order and then the the best teams of
that time they were invited just a
couple of days ago to the IJ CNN
conference where the goal was to take
the new data set with more data and then
participate in the final in the final
competition and down there we see Dan
with the with the number one traffic
sign that you can see in his hands they
are see the differences were
unexpectedly high so PS M&amp;amp;E this time of
New York University of young glucose lab
achieved one point 69 percent correct
the second best where the humans humans
are able to get one point 16 percent
correct according to the conference
organizers and in first place for our
team with 0.6 percent error arm now this
might be of interest to everybody who is
doing a self-driving cars and of course
we all remember the this incredible
keynote of an stickman who is who is not
using GPS
for self-driving cars but is doing it in
the human-like way and in 1995 already
used these active vision systems who
drive from Munich to Denmark and back in
traffic with up to 12 vehicles
surrounding the car and tracking them
all using these you how many people saw
this talk and how the cameras built
along there the active vision camera I
think this will also be the the future
of self-driving cars in addition to GPS
and radar and leader but to do fast
driving you just have to ask and stick
months you need these these these active
vision techniques for getting
high-resolution input of stuff satisfy
head as you are driving fast you will
need to look far ahead to be able to
brake in time if there's no obstacle on
the street and so a leader or something
like that is not sufficient now once you
have identified salient points then you
still have to do the traffic sign
recognition or pedestrian recognition or
whatever you want to recognize that and
there at the moment I think I can
recommend this technique now of course
in the in the long run we don't just
want to recognize patterns that are
single patterns by feet or networks know
we have streams of patterns videos
essentially where there is no
segmentation where no nobody segmented
the stream into relevant parts and and
and to do that we we cannot use
feed-forward networks that we really
have to use recon networks which are
general computers and one of the
examples of applications is connected
handwriting connected handwriting there
somebody scribble something and you're
supposed to translate that into plain
text which means you have a rather short
label sequence however you have a long
real valued input sequence of pixels
that you are sequentially observing and
and there you need a recurrent Network
and preferably a long short term memory
networks that can really deal with these
long delays between relevant events and
Alex waves our my former PhD student and
then past the postdoc who's now going to
Jeff
actually he he used this approach in
conjunction with a technique called
connectionist temporal classification
which maximizes the probability RC label
sequences given these long real valued
input sequences without any pre
segmentation and and then applied that
to various handwriting recognition
competitions connected handwriting and
so that's how he won the the French
handwriting connected handwriting
competition and the Farsi connected
handwriting competition and the Arab
connected handwriting recognition
contest without speaking any word of
Arabic you may have guessed that my that
the Swiss AI lab is in Switzerland and
in in in Switzerland traffic signs are
really important if you don't obey a
traffic sign in Switzerland you go to
jail
however across the border there is Italy
and then Italy they also have traffic
signs in the street however only for
decoration well we are currently trying
to write a book about things like that
and I think that's the end of my talk
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>