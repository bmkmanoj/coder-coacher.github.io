<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AGI 2011: Mapping the Landscape of AGI | Coder Coacher - Coaching Coders</title><meta content="AGI 2011: Mapping the Landscape of AGI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AGI 2011: Mapping the Landscape of AGI</b></h2><h5 class="post__date">2011-09-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5OoYOjOEy6A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so what I'm going to talk about briefly
now to sort of set the tone for the for
the rest of the conference is a workshop
that was held at the University of
Tennessee in Knoxville in follow of 2009
now the workshop convened about about a
dozen AGI researchers there hosted by in
tomorrow who's here tonight from
University of Tennessee and also
partially funded by that the singular of
the Institute for AI the workshop was
focused on a GI roadmapping trying to
gather a bunch of AGI researchers
together to figure out what what could
be a viable road map to get from where
we are now to advanced artificial
general intelligence and as anyone who's
been in the AGI or AI feel for a while
might predict we did not succeed in
having a dozen people agree on anything
resembling a single road map to AGI but
we did come to some interesting
conclusions and commonalities in which
we described a little more accurately
using the phrase mapping the landscape
of AGI so well what I want to do now is
talk a bit about the workshop what
conclusions we came to what kind of
unity of vision we managed to find among
a group of diverse AGI researchers and
also what was the diversity of opinions
that was long as each each in our own
research directions so it was called the
workshop on creating a road map to human
level artificial general intelligence
and already there was a lot of argument
in coming up with that name because no
long what is human level mean are we
really all after a human level some
people are trying to emulate human to
detail some maybe just want to make
something really smart and defining what
is human level itself is kind of
contentious once you get away from
trying to identify exactly what the with
the human mind but we were able to agree
on that fairly well as a sort of
approximate term to describe what we're
after I know this slide is an a
of the participants you see we had sam
adams from from industry then coupled
triple AI fellows stuart shapiro john
john sora and then in amar Joshi josh
shaw who are here and there a couple
guys who were at least one psychologist
actually to round out the group of AI
people and rod ferland from singular the
university bring more of a futurist
perspective and one thing that we all
pretty much agreed on starting out the
workshop is that there was some palpable
difference between what Ray Kurzweil ho
called narrow AI and what we thought of
as a GI or general III and what ray
called in his early books strong AI but
that term had some baggage familiar
earlier AI theory and this is not a
consensus among all people in the field
I mean some people really feel that that
that distinction isn't worth drawing and
it's all just a I and there's there may
be some validity to that but all of us
at the workshop felt it was also
interesting to draw the narrow AI versus
AGI distinction wherein narrow AI
focuses on making systems that solve
particular problems that seem to require
intelligence when humans solve them and
then AG I by contrast focuses on systems
that can solve many many different kinds
of problems without requiring
specialized reprogramming for for each
one and I like to think of AGI as the
ability of a system to achieve a variety
of complex goals in a variety of complex
environments in reality that actually on
using limited computational resources
one of the many things we couldn't all
agree on that the workshop was what the
heck AGI really means that everyone sort
of has their own definition and i think
that's that's true among the researchers
here as well there are various
formalization of general intelligence
and their various practical
understandings and they have a lot of
overlap but there are also some
differences i mean we we found that a
quote by nils
one of the old founders of AI who built
shaky the robot and then did a bunch of
other stuff and the way he looked at it
was kind of practical like I i claim
achieving real human level AI would
necessarily imply most of the tasks
humans performed for pay could be
automated rather than work toward this
goal of automation by building
special-purpose systems I argue for the
development of general-purpose educable
systems that can learn to be taught to
perform any of the thousands of jobs
that humans can perform joining others
who've made similar proposals advocate
beginning with a system with minimal
although extensive built-in capabilities
an interesting hedge these would have to
include the ability to improve through
learning along with many other abilities
and I think that's that's from a
magazine article in 2005 many decades
after he start his research career but i
think it's a it's a fair practical
summary of what we're talking about with
human level AGI I mean we may ultimately
be able to go far beyond that level but
that that would certainly be an
interesting start that doesn't anybody
but how do you get there now that this
slide is maybe not that easy to read but
at a GI 10 John Laird is one of the key
authors of the sword architecture which
again comes from a long long legacy of
American AI work they laid out some
systematic requirements for cognitive
architectures environments and tasks for
AGI which I also think made a lot of
sense I mean an AGI system should be
able to deal with new tasks without
requiring reprogramming it should be
able to somehow realize a symbol system
which could be through emerging it
internally or by having it built into
its its architecture and needs to be
able to represent and use
modality-specific knowledge large bodies
of diverse knowledge knowledge at
various levels of generality beliefs
independent of what's perceiving at the
moment rich hierarchical control
knowledge metacognitive knowledge
deliberation both bounded and unbounded
learning of diverse varieties learning
that's incremental and online it should
be able to operate
environments that are complex with
diverse interacting objects dynamic
environments with tasks at multiple time
scales where other agents impact its
performance the tasks must be complex
diverse a novel that's able to deal with
its computational resources are limited
and it's a lifelong system it can keep
on existing in the world continually
from one task to another learning as it
goes and of course listing these
requirements is a lot easier than
fulfilling them but it's still
interesting to have some some clarity on
what you're after and Sam Adams from IBM
the author the Joshua blue AGI
architecture like to view this in
developmental psychology terms which is
somewhat amenable to my way of thinking
as well looking in terms of Piaget's
hierarchy of individual capabilities
going from infantile through concrete up
through a formal stages of thinking and
vygotsky's hierarchy of social cultural
engagement where you're able to get more
and more adapted to working with other
agents and looking at AGI as we develop
as moving moving forward on on both of
these skills now where things got more
controversial was trying to settle on
exactly what practically do you do to
achieve all these kind of highfalutin
sounding aspects of general intelligence
and what we had hoped when starting out
the workshop was that we could agree on
one sort of testing scenario one
environment where we could all put our
GI systems in the same environment and
let them play in that environment and
have a common set of tasks at which you
would compare everybody's system and
this was a very nice idea but not
surprisingly what came out was more that
everyone sort of favored the environment
that was similar the ones they were
working with that there a GI system was
or proto edge EOS system was good at
dealing with and this was not terribly
surprising nor incredibly disappointing
but it was interesting and these are
some of the scenarios that were proposed
and flushed out
one with general video game learning
basically taken a GI system throw any
video game at it with or without
instructions let figure out how to play
and do well I mean anyone video game you
could address with the narrow AI system
but to be able to deal with any of the
many video games out there without
specific preparation this is an
interesting task the one that is dearest
to my heart is an early childhood
education basically a robot preschool or
virtual preschool where you can
structure the tasks so much you're a
human preschool curriculum then the
joshi talked a lot about story and and
seen comprehension and it's arguable but
if you can understand say a scene from a
Hollywood movie and explain what
happened and answer general questions
about what happened that may be what you
call an AGI hard problem and may also be
a decent path to development of AGI
systems and that that seems to suit it
so fairly well to competitions and
shared tasks the reading comprehension
curriculum is something that Stewart's
Shapiro was interested in just take
reading children's picture books first
through sixth grade and answering
questions on it like kids have to do and
some of us argue that may be easier to
sort of game with narrow AI system so
that it's not clear to me personally
school learning going beyond the reading
curriculum to more and more subjects
steve wozniak the co-founder of Apple
had proposed what we like to call the
coffee test he said it'll be a really
really long time to let him and can make
a robot that can go into a random house
in the US and figure out how to make a
cup of coffee and that josh hall was a
strong advocate of that as an AGI
environment and you can see that
involves integrating a lot of things you
got to go in through the door you got to
find where the coffee grounds are kept
you gotta figure out with all the
buttons on the coffee maker do i mean
there's there's a lot of stuff you have
to do there now of course you can see in
this list of scenarios that if what
you're working on is robotics you may
like the coffee test better if what
you're working on this natural language
processing you may like reading
comprehension better so everyone kind of
agreed on what the end goal is in terms
of nils Nelson's Rhonda
and Laird and raised rundown of a list
of things you have to do but what you
want to do first second third and fourth
and fifth in what order is harder for
different researches with different
paradigms to to agree on even though
that the end goal is agreed more
commonly we had a little more agreement
on a sort of laundry list of what
competencies are required for for human
level AGI and you can drag this down in
a lot of ways by looking at cognitive
science textbooks by looking at AI
papers there's there's fairly good
agreement now on what kinds of things a
human level mind needs to do and that
this list will bore everyone because
it's all obvious or there's perception
actuation memory learning reasoning
planning attention motivation the motion
modeling self another social interaction
communication quantitative understanding
building and in creation and for each of
these you can run down along a long list
of specific instantiations of that save
for dealing with emotion you must be
able to express emotion to understand
emotion to perceive emotion to control
emotions and all these things are
important we could all agree all these
things are important but again what
order you want to proceed in with these
and which ones are the core the crux of
intelligence and which ones they're kind
of things you can tack on afterwards it
is a much harder thing for all the
researchers to agree on what it did seem
is that for a particular scenario say
the virtual preschooler or the coffee
test for each scenario you could look at
each competency area say learning in the
virtual preschool modeling self another
in the virtual preschool or say
communication in the context of the
coffee test once you have a scenario and
a certain competency that interests you
then you could figure out how to put
those together and generate some tasks
based on that which then becomes a huge
matrix and eat each scenario and each
competency what is the task and
it all starts to become quite diverse
and quite complicated now you can
contrast all that with say the
definition of general intelligence given
by Marcus Souter and Shane leg is it in
some of their work when they just define
general intelligence as in essence the
ability to solve our software
reinforcement arbitrarily complex reward
functions where you wait you wait each
environment in which your reward
function exists by the the salami
lochleven prior and this is a this is a
very elegant mathematical definition of
general intelligence which seems to
contrast with this horrible laundry list
of scenarios and functionalities on the
other hand humans are not fully general
intelligences and we are may be fully
general in principle given an infinite
Turing tape to write on but in terms of
our practical lifespan and resources
were heavily adapted to particular
environments that we that we evolved for
so we didn't come to any grand
conclusion I'm sorry if you were waiting
for one um we wrote a paper on this
which should appear shortly kind of
running through the various
possibilities and trying to organize
them in a sensible way and part of the
conclusion is that human level
intelligence is not that simple and
well-organized of a thing I mean humans
are evolved systems we evolved for
certain environments within certain
physiological constraints we're not a I
excise or arbitrarily intelligent
mathematical super intelligences and
because of this messiness of human
intelligence and the diversity of
functions that we've evolved to fulfill
there is a certain diversity to the the
field of AGI and so far as it's aimed at
emulating something vaguely like human
human level III and to an extent I think
that this diversity is a feature rather
than a bug it's okay it's led to the AGI
fields having a lot of different
approaches beyond the ones we considered
here I mean
going to hear an excellent talk shortly
about kind of proto a GI work oriented
toward driverless cars and that's a
scenario we didn't consider in this
workshop but you could also look at that
as a path to a GI but there's a lot
there's a lot of a lot of possible
pathways and the the main point is
really the one we started out with in
terms of not focusing on just a single
narrow task area of say driving a car
through the streets of San Francisco or
playing chess or playing a go or
analyzing genetic data but rather trying
to build systems that can achieve a
variety of complex goals in a variety of
complex environments including the
ability to do kind of unpredictable
things that you didn't program the
system to do I think this can be
approached in a lot of of different ways
through different scenarios and that the
various sub components of human
intelligence could be approached in a
lot of of different orders and none of
none of us knows yet which is going to
be the path to lead to the best success
so it's great we can have a conference
like this with so many different
approaches represented and I guess
Jurgen wake up so the great juergen
schmidhuber will now introduce our our
first keynote speaker so Jurgen Jurgen
with the chair of last year's AGR
conference and it is without a doubt one
of the world's leading AGI researchers
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>