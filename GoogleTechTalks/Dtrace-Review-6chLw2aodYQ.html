<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dtrace Review | Coder Coacher - Coaching Coders</title><meta content="Dtrace Review - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dtrace Review</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6chLw2aodYQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Hey ladies and gentlemen I'd like to
welcome Brian Cantrell from Sun
Microsystems to talk about DTrace all
right a very succinct introduction Paul
thank you so I'm I'm Brian Cantrell Sun
Microsystems and I'm going to talk to
you today about technology called eat
rice uh but actually the to kind of
start off maybe a slightly philosophical
um if you just seen this book on
dreaming in code by scott rosenberg you
seen this it sucks
don't read it I'm reading it right now I
reading it because actually the story
behind reading it as actually along with
some Google engineers I contributed a
chapter to a book called beautiful code
on which I wanted to read one actually
came out because I only wrote a chapter
so I read beautiful code I think I'm
probably the second or third person to
actually read the entire book because if
you read the entire book from cover to
cover you come away with some very
different opinions that I think other
people come away with home anyway that's
um it's a very kind of its initially the
beautiful codes very intricate it's very
discombobulated it's that there's that
you've got wildly disparate ideas of
what constitutes beautiful code and my
my assertion on my blog was that you
can't possibly read every chapter and
believe that every chapter is beautiful
because there are diametrically opposed
mutually exclusive definitions of beauty
contained within that book but I seem to
be the only one who either either has
read the book or thinks that or has any
taste I don't know one of those three is
true perhaps perhaps more than one but
so I always like to read books in twos
so I figure well it's been a long time
so I write a book on software even
though that's right do for a living you
know pick up this the streaming in code
which I knew is a bad idea you know you
know when you're on Amazon thinking
yourself I know this is a bad idea why
am i doing this and yet that whole cycle
of reading the book I don't know about
you for me I'm a finisher once I start
reading a book I've got to read it all
the way through and I'm just cursing
myself all the way through why am I
doing this and it's a bad book because
I'm not necessarily because it's the
writing is bad although that that also
is true um it's a bad book because it's
it's talking about a very tough subject
in software software and I assume most
of us in the room have some interaction
with software you either build it or you
maintain it or you deploy it into
production and software is really
different
it is unique it is it is different from
everything else we have made and when we
try to draw analogies between software
and other things that we build those
analogies always come apart that they're
always loaded with fallacies so what is
it that makes software so special and if
you're curious about the book the I that
the book is is about a thing called
Chandler which is his open-source Python
personal information manager and he kind
of follows Chandler for a while and then
kind of like Apocalypse Now kind of goes
up the river and starts wandering around
the the domains of software kind of
getting hoodwinked by every long known
crank and software and people like Alan
Kay and and so on I put him under his
spell um and those guys I have to say no
offense to those kind of folks but I
think that software was so new when they
started to work on it that they didn't
understand just how different it was and
people kept trying to draw analogies
between other domains of engineering so
what do I mean by software being being
unique or special um software is here's
the paradox is software information or a
software machine exactly the answers is
both like nothing else in software the
blueprints are the machine there's no
day laborer in software right you know
for those you live in San Cisco you
don't go down to like Cesar Chavez and
pick up you know eight guys throw them
in the pickup and have them go in
platonic lists so the way it works right
because in software once you designed
the thing you built it the design is the
machine that's why the waterfall model
is so fundamentally flawed this idea
that you could design the design before
you design it which is what the
waterfall model is essentially saying is
flawed software's both it's both
information and machine and this is the
point that was hit home to me when I
first came to son 11 years ago and I
first came just under work with an
engineer called Jeff bond WA I'm Jeff
developed the ZFS filesystem which you
may have heard of um and so I was in
Jeff's office and I'd been at sons like
three weeks and um fresh out of school
and we are we're debugging some problem
and we've got the source code up in one
window and the debugger up in another
window and we're kind of making progress
on the problem and often Bonnell kind of
steps away from from Piske
says does it bother you that none of
this actually exists I like come again
help me out whatever I where we going
with this it's a one you know we're
looking at we're looking at the source
code over here we're looking the
debugger over here and and we think that
we're looking at a thing isn't a thing
doesn't exist this is it we're seeing
we're not seeing an actual manifestation
we're seeing representation of an
abstraction this does not exist any more
than your name exists your name doesn't
exist we made it up doesn't this bother
you like well it bothers me that I've
only been here for three weeks and
you're going completely mental on me
that definitely bothers me um and I
guess Jeff was just having one of those
moments but it's um when you think about
it it really is troubling um it really
is very different and it really it does
set software apart in particular as far
as I'm concerned the one of the most
immediate manifestations of this is we
can't see software what does running
software look like it doesn't look like
anything doesn't emit heat doesn't track
mass it's not physical it is
mathematical machine and that is the
problem by the way with all the the
thinking around software engineering has
come from the gentlemanly pursuits of
civil engineering you know kind of men
in top hats who would employ billions to
make you know to build bridges and dams
and so on it's very romantic but it has
no analogy in software that's not the
way software is built software is much
more like a bunch of people sitting
around trying to prove theorems many of
which are irrelevant theorems
interaction no one actually cares about
but nonetheless that's a much better
analogy so in terms of seeing software
if you can't if it doesn't if it doesn't
emit heat doesn't if it doesn't attract
mass how do we actually see it well we
see it generally by actually modifying
your software right by saying printf we
got here you know if debugging printf we
got to this function whatever here's the
problem with doing that you're modifying
your software such that it is emitting a
data right and the problem with doing
that is that it costs
now you can say well I put this in an if
statement you know if debugging enabled
then / Nathan cost very much not sure
doesn't cost very much but it's still a
load and comparing a branch right
towards the microprocessor take it run
that they said well okay so fine yeah
you're right that cost too much so it
doesn't cost too much I do it once but
if I do it in tens of thousands of
places if I do all of my code
I've got code that's too slow to ship so
what do you do you conditionally compile
right if def debug if def tracing if def
I want to see my software then if
logging printf or whatever now you've
bifurcated your software you've got two
versions of your software
you've got the version that you can see
that you develop on and you got the
version that you can't see that you put
into production and when you put that
software in production order that the
ISD ships deal right when you're buying
software from someone else they've
stripped out all the all the things that
would allow them to understand their
software have largely been stripped out
because they made the software slower so
in order to be able to see software we
make it slower that's a that's a really
tough burden to bear and it explains
part of why we have had such difficulty
in software because you get these
abstractions layering on top of one
another right that's another thing that
is very unique about software is this
notion of the layer of abstractions
because when you're at a higher layer of
abstraction you can you can do more and
more and more as you go up to those
layers but you have less and less
understanding of what's going on beneath
you and when the whole thing misbehaves
you can't see any of it so what we do
well the the load and comparative branch
is obviously out on and when many years
ago now the I and a couple of other
engineers son Mike Sparrow and at 11th
all began to think about this problem
what we need to be able to do what we
want to be able to do is walk up to a
system running in production and we want
to be able to dynamically on the fly
change the text that is being executed
change the program text of either the
operating system kernel or running
applications and we want to change that
text in such a way that we can we can it
will emit data we're gonna take that
data and process it understand the
problem and when we're done we want to
we want to change the text back to what
it looked like
fully optimized debuggers have done have
done text modification for a long time
but this is not human is not in the loop
here and so this is what we did what we
did with the trace he traces a facility
that originally we we shipped in 2004
and has been shipping now for for many
years um that allows you to dynamically
instrument the running operating system
kernel running applications on top of it
and to stitch it together
we are me this is I the screensaver is
some random presentation no that's my
dad boring alright um hey wake up the
guy behind you he's kind of drifting off
cuz I know I'm boring oh not that boring
maybe if you read the book
you'd be ranting like this as well um so
that in short is what is what we did um
and so what I'm gonna do this morning is
just um is give you a quick introduction
to DEET rice and and show it running on
on this live system here my little
Solaris laptop uh and then we'll I'll
take you into where we've gone with each
race since we've actually shipped it and
talked about some of the problems that
that that you might have and how it can
be relevant to them so this is my little
source laptop here and my ones
introduction to DTrace is just to run
DTrace see a very kind of UNIX e style
help message here and what I want to do
first is just list the probes in the
system
ste trace - L so what this is going to
do is list every point in the system
that we know how to instrument so we can
see lots and lots of probes flying by
now um and in fact we can may actually
want to pipe that to WC so we can see on
my laptop I've got fifty thousand four
hundred and eighty nine points that we
know how to instrument probes now what
does that mean these these are points
that the system has determined can be
safely instrumented this brings up a
very important constraint on dtrace
dtrace is designed for production
systems as a result dtrace use must be
absolutely safe so we are analyzing the
text and we are determining places that
are in contexts that are known to be
safe that we can
instrument we can see we got a whole
bunch of probes here and I'm actually
well I'm going to list the probes again
and actually let's we'll just pipe this
with a head here and see what this looks
like so in terms of this output
we've got a couple columns here that the
provider column denotes the fact that in
DTrace one of our observations was that
we were always coming up with new ways
of instrumenting system new kind of
instrumentation techniques and we wanted
to separate out the way you instrumented
the system from the larger framework
that consumed that data so that's what
we did with these providers and each of
these providers knows how to instrument
a different portion of the system this
is called provider for example knows how
to instrument the system called table so
you can see system calls this FBT
provider up here is the function
boundary tracing provider it knows how
to instrument every function entry and
return in the kernel we got a lot of
providers and we'll get into those in a
second on the this module column denotes
the kernel module for a kernel level
probe or the user level shared object
for a user level probe the function
denotes the name of the function and the
name to notes the name of the probe so
we can see here we got it we got here we
can see here we have me I'm over there
that is me I am pointing myself there so
if we can actually get my laptop back
maybe not be so actually I can see
myself you can pass out anywhere alright
thanks then have to house actually
interesting I felt like that scene in
Spaceballs I so now I'm gonna list the
probes again and this time I'm going to
fully specify we call the probe tuple
these four elements the provider module
function a name form what we call a
probe tuple and I'm going to list them
again and we separate this with Cohen's
is the kind of a canonical computer
science thing to do and this this is
going to list every probe from that
syscall provider so this is a shorter
list I'm probably a couple hundred here
however many system calls we have these
days 230 um so so far we've just been
seeing how the system can be
instrumented let's go Instamatic enough
of this kind of horsing around here to
do that all I'm going to do is strike
that minus L so when I delete the minus
L instead of listing probes I'm going to
Internet the system and this is just
going to instrument every system call
entry with the default action which just
indicates hey you came through here
okay so we're saying every system call
as it happens on the box
now on the one hand this is actually
pretty interesting we actually believe
it or not before DTrace didn't really
have a good way of doing this on a
production system he said wait a minute
hold on oh that's not true
you have TRUS you have s Tracy all sorts
of things that stereo system calls it's
true those things do show you system
calls on a per process basis what those
things do there are trois and s trays on
Linux they're automated debuggers what
they do is attach to a process they
instrument its its system call table
that is say the system call points in
that process using either p trace on
Linux or proc on slash Brocken solaris
and they stop the process every time it
makes a system call and then your s
trace or to trust principally out it
runs the process again it stops and hits
another system call so the two problems
with that first of all the probe effect
is ginormous to use a technical term so
if you've ever had a performance problem
and you've gone to use s trace or truss
on that problem you will often
discovered you have a new performance
problem called you're running trust race
on your process right it'd be enormous
enormous chrome effect any other problem
of course is it's only on a per process
basis now I've got to ask have any of
you been so desperate to solve a problem
that you've tried the truss or s trace
every process on the system you can do
it if you want to right and Solaris you
know trust - be back take P grep - the
comic quote quote back tick and I'll do
it that will trust every process in the
system now of course you probably
forgotten that you're running on direct
server whatever l your whole system is
gonna basically grind to a halt as
everyone is going in now to the debugger
you're going to be you know walking into
the next queue being I taking them just
ssh into my machine and kill off my
processes oh you didn't trust your x
server again didn't listen all right
let's um so and you if you've discovered
this it's great and if you're trying to
find a problem using that you probably
don't find your problem you nervous or
another problem which is very painful so
what this is join us this is not showing
us on a per process basis this is
showing us system-wide system calls
they're being executed and we're not
stopping anybody they're zipping right
through the system call table we're just
making a note off to the side so this
has got much less probe effect and we're
seeing a a system-wide view now that
said it's not actually that interesting
right it's like you got rights and I
goals and polls I mean unless you you
know had some bet with the summer intern
that LDV sig mask isn't called or
something I don't know what you would I
don't know how this could possibly be
useful because all you're showing really
is is the system cause that somebody is
making so we actually want to record
some interesting information with this
we don't want to just know the fact that
someone somewhere is making system call
we want to pull some some data out of
the context when that system calls being
made and this brings us to an important
design decision indeed choice because we
realized that no matter what data we
would predefined to be available you
would want some other data and as these
things usually work you would want that
data on the worst day of your life
because that's usually the way these
things work it's like that day when
you've got that the the production
problem where you you know when you got
that there's one of those days where you
have a problem and then you go to
diagnose that problem and you have a
second problem in diagnosing the first
problem and then you go to diagnose that
problem you run into a third problem
this is when you're normally you don't
scream your computer or haven't since
you were in college or high school you
start screaming at your computer and
your spouse begins to you know get a
restraining order
maybe that only happens to me I'm but
those are the kinds of days that you
would want the data that we didn't
provide right when you're debugging that
third problem so we realize that we
couldn't provide predefined data what we
needed to do is allow you to gather
arbitrary data and of course that
arbitrariness implied a programming
language so what we did is invented a
very simple see like awk like language
called D not the D from digital Mars by
the way you're familiar with that date
different D I'm actually finally story
with that D we invented our DS roughly
in parallel not one of us know about the
other if you know about the digital Mars
day and at one point they mailed us
implying that we actually need to back
off the name D in that legal action
might be just around the corner said to
be reminded that you can't actually
copyright or trademark a letter of the
alphabet
just they otherwise microsoft would own
us all if not google um anyway so we've
come up with a with a c like language
called d that allows you to record
arbitrary information here's what i'm
going to do is attach a clause in d to
trace the exact name trace the name of
the executable
now we're going to see is actually that
was a listing let's not do that let's
try to actually
instrument
system now we're going to see is more
useful power now D and X org and mixer
applet to whatever the hell that is
and send sent I don't know send mails
here when I plugged into a network but
send mails doing something all right
this is more useful this is much more
useful so what I see here D try scan on
terminal D triskin eternal what are we
seeing here we're seeing us right we're
seeing all the system calls that it
takes to write all this out to the
screen not really all that interesting
indeed I would actually call this the
the top effect these top when you're on
top what's the top process cop tops like
hey man good news I found the problem
I'm the problem
uh who would've thought that don't run
me say our top listen it's true you have
become the problem but you were not the
problem when I endeavored to find out
what the problem is actually it's funny
I was I was talking to one customer
about this customer in the financial
services sector we think they might know
better and I was in the know that's not
the top problem the top problem is we
log into one of our boxes run top and
the top eight processes are eight
different tops from eight different
admins logged into the box trying to
figure out what's going on so so one or
more topside adjust to that's the top
problem um indeed that is a problem and
the reason that's a problem is because
the methodology the top uses top goes
around every process and an ass asks it
a question does not scale with the
number of processes you have 5,000
processes top is going to be the top
process by the way we've got a much
better implementation of top and source
called PR stat you have if you have them
use that in Pierce that's got less of a
probe effect but still has a significant
probe effect so we wanted to get away
from that and eat rice and we wanted to
get away from this idea of when you're
using a tool to understand the system
the tool itself becomes the problem and
so when you look at this data this is
not actually answering the question that
one might have had right I'd actually
don't need add atom every time we do
this what I actually want to know is
what processes are making system calls
on my box and so what we did is we we
developed aggregation as a first-class
notion in DTrace if we didn't denote an
aggregation with this @ sign and we can
aggregate on an arbitrary tuple in this
case I'm going to aggregate on the exact
name
and I'm going to take the action to
count now when I run this I don't
actually see any output just that we've
matched the probes and what we are doing
in the system we've instrumented the
system and every time a system call
happens we're indexing into a table
based on exact name and just bumping
account much much much much much much
much less probe effect when I control
see it I get the answer to my question
now is that this laptop happens to be
idle so Dee trice is it popping up more
than otherwise would she will make the
laptop do a little bit of work here
so if I click around and there we go and
we can see that there's a bit of a party
going on my laptop actually a bunch of
thing IX screensaver that's here
ok don't know why we're running the
screensaver Matassa t trash applet oh
good yes crash out boy please you need
to do a lot of work please have at it
what is the trash applet doing actually
I'm actually you may discover that may
already discover in DTrace as in good
cocktail conversation the answer to one
question provokes the next question
really trash applet 58 system calls over
a couple of second period what the hell
are you doing that's interesting so we
want to investigate one particular
aspect of this and in dtrace that that's
a first-class notion called product out
predicate so we're going to do is we'll
add a predicate to this probe say if our
exact name is trash output great name I
don't want to aggregate on the exact
name that's going to be trash out but
one would assume I want to aggregate on
the probe func it's going to be the name
the de proton is a D variable it's the
odd the name of the probe function will
be the name of the system call in this
case for I let that run for a second
presumably in control C I can see that
over that period of time we did one pole
one read and to octal x' from trash
applet okay this is this is getting
interesting this is telling me what
trash output is doing now if I I just
had one trash app I might be able to go
off and use my traditional tools but if
I had thousands of trash outputs running
on this machine I'll be very difficult
still to figure out what's going on now
if I wanted to I could aggregate by pid'
we do pro Punk and pit actually see if
or how many trash outlets are talking
about presumably only one so here's our
here's our pit and there's our count but
I want to actually know let's take these
reads for example what the hell is trash
haplit reading really is actually kind
of odd um so what I want to do now is
actually hone in on this enabling a
little bit instead of every system call
let's just do the reads and instead of
aggregating on probe funk what I
actually want to aggregate on is the
user stack back-trace with this you
stack action so now we're going to do is
when this thing comes in to read we're
gonna take a user stack back-trace and
tell me where are we in this application
oh we're of course from panel applet
Factory main closure calling Bonomo
general I swear the genome guys like
either want to give everyone else RSI or
love RSI it's like how anyone types in
that functioning I don't know um but
here we can see we are coming through
GDK event in check and index pending and
into a read this is interesting uh and
maybe I actually want to go off and I
saw that we had any word pid' one zero
zero nine seven to here up to this point
we've instrumenting the colonel right
actually let's let's hop up into the app
and see what this thing is doing let's
go instrument X pending in that in trash
applet so the Detroits minus n I'm going
to use the pit provider now the pit
provider is able to instrument every
single instruction in every single
running process which is a lot of
instrumentation and what I'm going to do
is instrument will do X pending entry
now what we're going to see is whenever
this guy call is X pending we will see
output amazed it's not gonna call
expending don't be obnoxious trash
applet bad demo this is the problem with
actually a doubling things you never
seen before
alright let's say okay now oh I've got a
feeling so I think that is it related to
that no
all right it's definitely related to my
input though all right you call X
pending when I hmm all right interesting
so query when I it with actually let me
try so we do this printf called X
pending at
sent why we'll do a wall timestamp with
a minus Q option all right now we're
going to see it whenever this thing
calls X pending we're going to see a
wall timestamp now if I stay away from
my laptop I don't think it's going to do
it let's see if I if I kind of horse
around here do a little clicky clicky
uh-huh mm-hmm
interesting okay so clearly when I'm
interacting with my laptop we're calling
X pending somehow I'm you could actually
if you were developing a budding
paranoia that someone was coming into
your office at night and screwing with
your mouse this is a a little little
script that you could write and confirm
it hi to in the morning
the 2:37 someone was in here did you
were in here 237 all right
Magilla that's how it usually goes with
me with the jock use I usually end up
being the culprit myself um so okay this
is interesting I'm actually interested
to know on query it's calling X pending
when there is there are auxilary events
elsewhere in the system from this GDK
event check business um I may be
interested in Oh what does X pending do
exactly I don't really know that much
about X pending presumably it's got to
do with something pending with X and for
that actually I want to I'm going to
write a little more involved script here
I'm going to write we call it D script
I'm and we'll call this X D which lets
get that process ID first so what I'm
going to do is write a little script
these RS been T trace minus s and we're
going to instrument X pending entering
what I want to know is what does X
pending do it kind of runs through the
software stack was it deal so what I'm
going to do is when we come in here
instead of just printing out a timestamp
or whatever I'm going to I'm going to
set a thread local variable which we did
note with that self points to send X to
1 that's what self points to follow is
going to set a thread local variable to
1 then what we'll do is instrument every
entry and every return in the process
with the predicate itself it follow a
set
so we're going to light up the entire
process but we're only going to see
output when self Apollo is set self
Apollo is only going to be set if we
came through X pending then when we're
done if self Apollo set well set self
Apollo to be zero and actually I wanna
get one of these so I'm going to exit
when we're done all right
make that kind of skew table now when I
run this is going to be a pause and in
this pause we are instrumenting every
function entering return in that process
so it's a big process apparently my god
it's a huge process um that's a very
large process this is going to be a very
large number okay so we've we've
instrumented this this thing and a
hundred nine thousand different places
and now I'll try to get this guy to do
some do its tricks okay there we go and
now we're actually d instrumenting that
entire process in all one hundred nine
thousand places so now we can see
exactly what we did from ex pending ex
pending called underbar ex event skewed
which called underbar ex flush called ex
flush in that returned ex flush then
returned we called X eleven trans bytes
readable and so on it's a little hard on
the eyes actually so what I'm going to
do is go back into the script
and I'm going to set the flow indent
option and what this does is when we see
a when we see an entry we're going to
dent to the right two spaces when we see
a return getting in to the left two
spaces so now if I run that again
we're now going to go again rhe
instrument the system in 109,000
different places and occurs to me that
actually I think this the power saving
mode is actually biting us here a little
bit because the guys having to figure
out that we're doing a lot of CPU work
on we're going to instrument them and
see if we can
and there we can see exactly what
happened from X panic and there it's
coming into that read remember this is
how we found that starred Francisco and
worked up right and indeed if we wanted
to we could actually instrument not just
all userland week actually in spent the
entire kernel in fact actually let's go
back and let's go back and do that and
instead of just every entry in return
let's do every FPT probe as well and
actually we'll just do this you don't
need to see the light up those pit
brought the pit probes again make a
little bit faster um and now we're going
to do is now going to match a bunch of
points and cementation
forty eight thousand in the kernel and I
got to make it do something keep waiting
for it to do so fee on its own and this
is everything in the kernel that that
actually induced so we can see there's
our sis call entry this is coming to a
read so this is all in the kernel now
and this is coming in for a tie octal um
so that all the stuff we saw before is
pre syscall work on then we we do the
get F that actually you teach a seminar
on operating system design in
implementation in history with the
output of things like us that set active
ft is kind of interesting story on so
what set active FTE is denoting is that
I am doing work on this file descriptor
I being a thread um we had a bug in
Solaris that was in source for a a ston
assuring Li long period of time if you
had an application bug where you were
closing your file descriptors as you had
another thread that was I Achtung them
reading them and so on
you could die on kernel heat corruption
this is Alberto Solaris to sex we
substitute for word so on but for an
operating system it was supposedly
multi-threaded it was a bug that existed
for a long period of time in order to be
able to solve that problem you have to
do something when you come into the
system called layer you've got to make a
note that like I'm operating on this
file descriptor whatever that note is
going to look like you've got to record
the information that I'm operating on a
file descriptor you can't actually close
this file descriptor until I'm done with
it or until I'm out of the carnal anyway
so we can see it running running all the
way through its I octo which um is if
you're me if you're a kernel of manner
this is really interesting and
incredibly valuable stuff
for us as technologists it's probably
interesting but in terms of your day to
day work it may be less interesting on
how does the operating system kernel
relate to what you're doing
well the operating system kernel is in
charge of scheduling all the resources
on the machine
and if you want to understand how your
resources are being used if you want to
understand how CPU is being used want to
understand what IO you're doing you want
to understand how process is being
created destroyed and so on you've got
to be able to instant the kernel in
order to do that
now you can instrument the kernel in
terms of its implementation but this is
a bit hairy I mean if you wanted to know
for example where am I being D scheduled
well you could know that we actually D
scheduled you in one of three e order
you can you can catch the your being be
scheduled in one of several places or
little ticket being cued to run even
when you're in queued to run you will
call set back to Q or set K PDQ if
you're above K preamp rye or set front
to Q now you can go instrument those
three places that's a bit of a pain what
we actually done is developed we call
stable providers so in particular
there's something we call the scheduler
that provides points of instrumentation
around things like rubber it is an q NQ
on CPU off CPU you don't have to know
that we take you off CPU and either
resume resume from zombie or resume from
inter if you just want to know where am
I being taken off CPU you can say skid
off CPU and actually if we wanted to
just aggregate on exact name we could
figure out the number of times that any
process is being taken off CPU index by
application now you can do all sorts of
interesting things from this for example
if we wanted to know why is mixer applet
2 coming off the CPU this actually may
be a very relevant thing let's say
you're developing mixer output 2 which I
believe does audio mixing and you
believe that when you're playing audio
you should be completely compute bound
never come off the CPU I want to know
where if I'm being taken off the CPU
where am i we can say exec name equals
mixer applet - I want to aggregate not
on the exact name say but actually the
user stack back-trace
this will tell me where I am in that
application has been taken off CPU now
this is and we can see that pussying is
being taken off CPU because it's
deliberately giving up the CPU it's
calling pol so if you thought you
shouldn't be taking off CPU actually
this is an interesting point because it
was down here right here is where we're
being taken off the CPU because we're
calling pol presumably either I'm I want
to wait for something to happen so fine
you're taking off CPU here you were
taken off CPU because you had the the
audacity to call GST Sun audio mixer get
volume you would necessarily think that
that would rip you off the CPU now be
interesting no what exactly happened
there so instead of aggregating on just
a you stack what's actually aggregated
on both the user stack trace and the in
kernel stack trace so this is tell us
where we were in the kernel and
hopefully we can get that guy to come
off CPU in the same place so this is
giving us two stack traces here ah
interesting
here are two stack trisection on the
other way so you could have seen a
little bit better like they will do the
other way give you a better view of
what's going on
and we can see that here we are calling
first of all why is this thing getting
the volume a million times
it's you know it's another day another
bug with you tries I swear you can I
know what's that is it really fixing in
a newer genome it's pretty funny
yeah I um I've got a whole bunch of
notebooks with the tribe's needless to
say actually I'm oh I'll talk about
interesting story in a little bit um but
one of these it's interesting about
genome and more to learn about desktop
applications is they've been very
spoiled by an embarrassment of riches in
terms of CPU horsepower and we have got
actually pretty interesting product that
wouldn't be a relevance to you but is
irrelevance to things like education
organizations governments and so on
project called sunray which allows you
to have a completely brain-dead clients
and all your server state is on the
server and it's very cool because even
like put your smart card in session pops
up you ain't got your smart card walk
down the hall pop in your smart card
session pops up again you know playing
your videos doing whatever it is you're
doing really cool stuff great for many
different customers and different
environments one of the problems when we
did that that we didn't really realize
at the time is that we were taking these
applications that had had this
embarrassment of riches and we're taking
them into an environment the server room
in which there's not an embarrassment of
rigidus by any means and what we found
is that a lot of these desktop
applications for me a lot what this guy
is doing which is waking up periodically
and doing work and on the server room
like you do work when you have work to
do the end and we found a whole bunch of
interesting problems so this would be
actually kind of interesting story in
that is the we actually had a summary
server one of the the first actual uses
of dtrace in production was a summary
server in Colorado that was in a whole
hill of hurt and these guys actually
came into my office because they wanted
me to help the budget this is um I they
start describing the problem you know
we're seeing this many involuntary
context which is per second and so on
and would you help us take a look at
this and so I asked them well what
versus the operating system you're right
like while running Solaris 9 and so this
was back in what 2002 and the thing is
by that point I D Joyce had not
integrated into Solaris but I'd already
been using teachers myself for a year in
debugging problems and what you'll
quickly discover when you debug a
problem with eat rice is it's kind of
like watching TV with TiVo in that
there's no going back like you can like
TiVo you can hate TiVo but you're not
going back to pretty TiVo
right I mean I don't view Teemo is not
even I don't even you TiVo as as I think
anymore TiVo is like a just it's just a
part of modern living it's like a roof I
don't think about the roof I'm not like
yeah my roof rules I love my roof it's
more like I don't like sleeping outside
right TiVo is the same way I mean that
ninyo pick pick your you know your DVR
or whatever but the whole notion of
putting you in charge of the information
that you're gathering which is what TiVo
does right I'm now in charge you're not
in charge schedule corporate scheduler
same way with the choice so I told these
guys listen you know I didn't give the
whole Tebow spiel on but if you want me
to investigate this problem you're going
to have to run sorors 10 on that box
this is about 20 proxy and the problem
that of course is the D tries only
existed in a in a prototype form there's
no way they're going to run a prototype
in production so those kind at the end
of that so come back in my office like
three days later like okay it's running
you want take a look down like what I
mean what's running we talking about so
he told us that we should run the D
choice prototype in production in
Colorado so that's what we did
it's like dice don't use the imperative
did I say run D um did it boot so yeah
yeah yeah why you're not a Buddha no no
that's cool that's cool that's good I'm
just like it but it like we're all happy
I'm happy mood you're happy booted all
right so now I'm like all right not
really up to take a look at this thing
so much for procrastinating so I hop
onto this box and the first thing I did
and you know I I don't know how many of
you have any large experience but the
first thing I did is the first thing
that basically any slower side one would
do when they're looking at a box will
just run this little command MPs data
and there are analogs in in every system
right just give me kind of a 1-1 line of
output per CPU what is this thing doing
just give me a basic idea with this
things doing and this pretty cool box
ten CPUs 32 gigs of memory 172 some odd
users some like that um so big box at
the time certainly this is a couple
years ago now almost five years ago now
I and I look at this this out
some piece output and it failed my most
basic test for the happiness of a box
and that is quite simply in this output
God intended the columns to line up and
ignore many say if you have never seen
this you know this might not mean
anything to you but many a Solaris box
you're running run and piece that and
it's like output is all over the place
you've got like some nine digit number
kind of floating out here you've got no
idea I can't even line it up anymore you
got no any what it is and so I'm
literally this is my algorithm like I'm
going to call them zero I am going to
proceed to call them n the first
statistic that overflows its column
we're going to figure out what the hell
you're doing and then we're going to
make your column line up and then I'm
going to the right and then we're going
to all the columns sly up then we'll
figure out what's wrong with the box all
right so start with CPUs we have got
three digits here we have plenty of
space that's fine
notnot going ten CPUs okay this mint
column use a minor faults right so a
minor fault is where you've got a
mapping in your address space but you
actually took a page fault on it didn't
have to do any i/o we had to take a page
fault and we got four digits here and
we're seeing the you know couple files
in a second line major fault a major
fault is where you take a page fault we
actually have to go to disk to actually
resolve the page fault we're only see
him like 30 of these a second we only
have three digits here but we're seeing
very few of those that's not an issue X
call this is the cross a cross call
column this is one CPU getting the
attention of another CPU by sending it
and either an inner processor interrupts
in in x86 bake mondo and spark but in
any case interrupting another CPU we
have four digits here that gives us a
maximum of 9999 cross calls and here we
had our problem this box routinely
seeing 12 to 15,000 cross calls per
second per CPU and I asked myself the
question that we have asked ourselves
for time immemorial in Solaris kernel
development namely what the hell is
causing all the cross calls now we know
what causes cross calls and if you're
interested I can give you the seven part
seminar series on what causes cross
calls cross calls are typically caused
by the way but due to TLB shoot down due
to addy map right so you get when addy
map comes in we've got to go actually in
dala date that entry another tlbs
and that's a cross called a stab that's
a typical reason that's the that's what
you hope is causing the cross calls but
we kernel developers always get fidgety
when this number gets
I and the reason we get fidgety is that
there are some there are some back
corners of the operating system where we
have to do cross calls to work around
some very nasty problems if you're
interested in in one of them actually um
this is a somewhat of an interesting
technical issue so um spark
microprocessors have what's called a
virtual address cache so it's a
virtually indexed physically tagged
cache right so normally on an external
cache is physically indexed physically
tagged and you're on but the SPARC
processors have a why would you have a
virtual index and a physical tag because
you can begin doing the cache probe
while you're still translating right so
the to you you go you go in parallel to
the the TLB unit on the chip and your l1
or l2 cache you're starting to probe
that thing then when you know you've got
that you've got a line you wait for the
TLB dammit and then you can match the
physical tag say it's you cycles is
usually on l1 cache we're just cycle
counts very very important where you did
the cycles of the the number the base
couldn't speed what you can execute in
the problem of the virtual index
physical tag cache is that if the if the
cache size is larger than the page size
you can end up with a really nasty
problem called a back alias that is
where you can take the same page same
physical page and map it at two
different virtual addresses that do not
map to the same line in the cache
they're what we call a different color
if the colors do not match then you
could have the same data present in both
halves of the cache if you have two
colors or multiple places you have more
colors this is bad this is very bad
because this is data corruption right
and that's these are hard problems to
debug take my word for it if if you have
to debug them yourself and you know how
bad these are um so we don't want to
back out is to arise so when you do an
EM map what's on SPARC at least aren't
on on microprocessors that have
virtually next is we tag cache when you
do an EM map you're letting us pick the
virtual address and so we're going to
always pick a virtual address for you
that lines you up with other ways that
this physical page is mapped so you
don't have worry about it but mmm and
this is a good example of how very
subtle additions to an API can lead to
really nasty problems when they
developed a map somebody somewhere
thought it was a good idea to have a map
option a map fixed flag to MF that says
no no no I want to map this here you
don't get the pic of virtual address for
me I am a smartypants and this is where
I want to map it well the problem mr.
smartypants is that you can actually map
your physical page in such a way by
having two different processes or
mapping fixed in the same process same
VA arranged with two different colors
you can have you can create your own
back alias so we don't actually there's
not an air know with like there's not
like an e bad idea that you can return
from M map or you don't know what you're
doing trust me
you have it's like not you like I'm
talking about of it let you figure that
right all right jackass you're going to
get your mapping but you're not going to
like it uh and what we do in particular
is for that context Novak for you know
vert why does cache for you l1 off sorry
um and so whenever we see a hurricane
across calls you know like we get a
little bit fidgety we think ourselves
you're not doing minute fix anywhere are
you it's like no no I wasn't that
important so no no that's cool let's go
just because we're always a little bit
nervous that you know all of a sudden
it's a good try like oh yeah Oracle was
doing that and now the performance is
like you know one one-thousandth what it
used to be which is roughly the kind of
performance decoration you'd say and
there are other ads arcane uses across
calls so this is what's going through
our head every time we're seeing this
cross call column and the reason I go
through that in some length is because
we have not this is going through our
head because we have historically not
had a way of investigating us on a
running system what is causing the cross
calls with these race fortunately it's
very easy to investigate this because
each one of these statistics has a probe
that corresponds to it in the kernel
that one of those stable providers that
I mentioned so in particular actually
sorry I'll list the probe first there is
an ex calls probe from the SIS
infoprovider this is info provider makes
available these probes that you see with
MP stat so I want to know who's causing
the cross calls it's that that's it and
I would hope that we're on a unit
processor so I don't think we're going
to be causing any cross calls so relief
you never know on so running any cross
calls on unit process or Galax and you
never know I wouldn't be surprised at
all the states like oh it's my code
making cross calls why isn't mean
but when I ran this on this big this big
box this big 10-way box I discovered
that the X servers are making cross
calls bunch of X embers and this wasn't
actually that surprising because
although the Sun Ray model is that
you're running all of your brought all
your desktop processes are running on
that server so everyone's got an X
server process you've got 170 X server
processes it would make sense they're
doing most of the work right but why
were they inducing the cross calls for
that instead of agreeing on exact name
just aggregator on a stack backed rice
and you add a predicate in there that
I'm only in the X server ran that for a
second look at the output of that and to
our relief it's not because of that
complex than map X and so on
it's because of the common case we're
doing a D map we're in the mud map code
path doing a D map that's causing TLB
shoot-down why are we calling it mud map
that seems odd and for that normally
that would be a very tough question to
answer on but the action let's see if we
can we looking at this process I should
say and when they were doing mud maps
over and over and over again so go with
um maps over over again you'd eat rice d
tracing the MF system call shirt off
you're seeing a bunch of M map activity
what exactly are we M mapping and for
that I looked at the art the argument
and I think it's f DS at 4 this is going
to be this is this is a bit dangerous to
do this well looking at the main page um
I'm sorry that it's not on
rather actually let me oh I'll write it
like I'll read this to where the way I
wrote it read join this take it back and
I can write it that way
all right I'm go to the main page
stimulant I think it's Arg 0 1 2 3 40
miles right I just forgot the argh Oh
such a tragedy sort of ER expecially
before that should be hard for all right
there we are so what I'm doing now is I
am instrumenting M map entry and I'm
looking up the file descriptor are at
four into R into f DS which is an array
that we provide in D trace and getting
the FI path name this is a
well-documented structure this is all in
the documentation and now when I control
C this I should see that we're mmm
mapping nothing that's not very
interesting what's kind of this is what
we were in mapping over that period of
time and what does none mean by the way
it means that in all likelihood we're
passing a negative one for the final
scripture right which means map and
autumns memory and indeed that's what we
saw we're mapping here was an autonomous
memory with an anonymous memories of
memory that doesn't have a file backing
and it is thought to be a cheap way of
allocating memory is to M map anonymous
memory the reason I say cheap and put it
in giant quotes is because it's actually
a lot more expensive than just calling
malloc this is an example of where
knowing too much can be harmful to you
you and there are good reasons that the
objects has to do a lot of work to
actually set up a new memory now but
there are reasons to M map def 0 the
reasons to edit it to M map and on this
memory but the the performance is not
one of its because you're in a context
that is too delicate to be able to calm
out see looking at this we saw that we
were m mapping def 0 we were M mapping
in autumns memory ok this is interesting
aggregate on you stack on the user stack
back-trace what we see we REM mapping
dev 0 from the pics map creation code in
the X server ok now we understand what's
happening we're creating pix maps in the
X Server when the X Server is creating
pics Maps it's calling M F 0 because of
the things that that's faster even
though it is it it's M mapping def 0
when those pics maps are destroyed it's
mind mapping it when it
naps it that's causing the TLB shoot
down cross call and that's causing the
common overflow and God becomes angry
okay now we have the full path from
pixmap to angry god here's the problem
that's not the full path right because
the funny one could say the bug is that
pixmap creation destruction code should
be calling malloc and free not m map and
moon map fine that's not actually the
bug who is creating all these pics Maps
that's actually the more interesting
question and to answer that question
well I actually wrote a slightly more
sophisticated script will call this who
a map D and what I did is I said let's
come in and map entry and if we are the
X server I'm going to say I'm interested
in you this is an x over that has done
nm map actually this is when it was
called X on it's now called X order so
let's change that the X or change our x
over while back and then what I use is
one of these skid probes in particular
sked wakeup schedu a cup fires when one
process wakes up another so what I'm
doing is I'm saying when the X server
doesn't M map who caused me to do that
mmm that process is blocked on me in the
kernel rikes it did an X call so what
I'm going to do is well I'm gonna do my
own map fine when I go to wake him up I
got him and I want to know who that is
so if self it interested is set I'm
going to aggregate this makes available
two arguments one is the r0 is an
argument that is the LVP we're raking up
arms one is a process that we're waking
up so it's going to one not in all caps
and what's that self-interested action
we'll do that after we sense up it just
be zero one get the first thing when we
wake up that's it and indeed if I make
out executable and spell correctly
that's PR FA not P uh PS and final let's
try like that now are you happy and now
let's see if we can get the X server to
do M maps on my Thank You X server for
doing very little first of all let's
make sure we're after doing this is call
m map entry what's that yeah without the
dots we're gonna find out of course we
can't get the X or do anything it's
likely very interesting but watch
Firefox another hey oh the exit of
course not of course if they've you
actually I'm recalling of course that
they have changed the extroverts no
longer do that so the exit was probably
not going to the x over no longer to mf4
pixmap creation instruction so it's I
would actually have to be lucky to catch
the X out of doing them all right that's
not going to work on the live demo but
we can just because the expert doesn't
do this anymore so let's just get who's
doing ex calls forgets this call em app
it will just use schedule a cup if the
exact name equals x org we're just a
great on who are waking up this will
actually give us a rough count of who's
doing what on the box and that should
that should do something there we go so
this is actually a rough indicator of
who is making X requests on the box and
the instigating is when I ran this I
didn't see Firefox been over here at the
top um I saw the so looking at this
output on this was the so we were seeing
now the number of M maps induced by
different X applications the second
largest number over this 10 second
period that I ran it was it was actually
Matassa T and it was coming in or
Matassa T as I call it coming in at like
700,000 some like that and the number
one with 6600 final call correctly
induced M maps G tik to applet two so I
don't know if anyone knows what the hell
do you take travel to is I was asking
myself the same question what the hell
is G take to output 2 and why is it
trying to murder this box gt2 a platoons
it turns out is a stock ticker
application and it didn't take too many
further aggregations and so on and
looking at stack traces to figure out
that gt2 appala to was waking up I
wanted to actually wake up once every
millisecond but do the scheduling
granularity in the system can only wake
up once every 10 milliseconds every 10
milliseconds what would it do create a
graphics context draw a pixel and
destroy the graphics context now for
software developers this is something of
a capital crime there's actually there
been several this is like a this is you
know special circumstances the works
we've got a there's several things here
that constitute capital crimes one
you're waking up every every millisecond
on when you should know the schedule
grinding on roads every 10 milliseconds
and what do you need to do a be 10
milliseconds anyway I mean aren't we
talking to like a stock quote that's
being updated like every 20 minutes
I mean we really need be waking up
several hundred thousand times a second
if you had it your way
one two so we're drawing a pixel to the
screen as if this were like a military
flight simulator we for whatever reason
instead of just a someone seeing how
underwater their options are in my case
and above water in your case perhaps um
but in the definitive courses that we're
creating a graphics context drawing a
pixel in destroying the graphics context
you've got any X programming when the
graphics context is a server-side
resource you use the draw and when it's
first introduced in your X manual
there's like you know one of those big
caution signs like slow down knucklehead
graphics contexts are server-side
resources they're precious you create
them at the beginning of your
application do all your drawing destroy
them at the end of your application
don't create destroy these things the
reckless abandon
but the orangutan that wrote gt2 applet
to apparently skip that chapter and um
proceeded to create graphic contexts
that would try to create graphic subtext
a thousand times a second only succeeded
in 100 times a second there were six of
these running on the box and it was
murdering the box and to see just the
degree to which was burning box there's
a three thousand processes by the way in
this box and six of them were doing all
this damage IP stopped the six gtq
output is and that MP set output I
showed you it was like a hurricane blew
over not just that column but every
column lined up the the system time if I
recall correctly dropped by 30%
idle time skyrocketed cross calls
plummeted cross calls went from 12,000
per second per CPU to a thousand per
second per CPU we were able to put 20%
more users on that box at much lower
latency encrypt big increase in
throughput great drop in latency and
it's you know you might say it's like
okay well the problem is that we had an
orangutan right G tick to Apple 2 and
that is a problem for sure
but don't actually blame your Ranga tank
necessarily because this is this is a
problem that's endemic to software when
you're building this with those layers
of abstraction I talked about it you're
up with those very high layers of
abstraction and it's like literally this
is it there are two lines that need to
be hoisted out of a for loop those two
lines caused son
quite a bit of monetary damage so in
terms of and I this is in 2002 I should
say
when I think things were just changing
in terms of the the languages that
people are deploying to production
right so 2002 people deployed a lot of
Java but things like Python Ruby so on
we're still serving an auxilary role
we're not actually running in production
in anger that's changing and I've been
actually interested to know how many of
you have to debug say Python problems in
production
oh you're going to be very happy really
okay that's interesting giggle was the
first company I'd ever heard of in what
99 when a friend of mine worked here was
mentioning that it was like yeah you
know they do a bunch stuff in Python and
so I pick it up so Python it's like wow
that's really powerful language so it
this sucks the first company I heard
people developing Python in production
more than or than just kind of in a
supporting role so it's no surprise that
several of you are dealing with Python
production how didn't you see to see a
ruby in production JavaScript I'm a Perl
Wow Java Java presumably know so we've
Python kind of the really well that's
very interesting okay um so if you've
ever debugged a Python problem so even
with the choice you go to run Python and
what's actually do got some Python here
this is a very very very simple program
so we're just going to loop around and
we'll call that guy so you have this
Python running in production and you're
curious what the hell is this thing
doing and actually let's should actually
Mike you make it think a lot more
interesting let's second make that a lot
more interesting loop dot d speed loop
wi y 1 dot p y so let's make this guy to
spin out of control how about that
that seems a lot more interesting fungi
will just take out the slates here
goodbye sleeps this may be a more
accurate representation of what you see
in production alright and actually we'll
run that over it well let me run that
over the background here so let's say
you've got DTrace very happy you're very
excited you've got DTrace and you've got
the production box and it's getting
killed doing something or another so now
we're going to see if questionary block
a lot of the terminal it's like ah Jesus
what's going on columns line up
fortunately but God is still angry um
and you know you run your usual you know
because you got D trace and you're so
savvy say oh this is a great opportunity
trace I can you know angry on exact name
where we doing I'm gonna figure out
who's murdering my box death tada
of course hmm Python ah yeah ah I've got
you now I got you now Python I am so
close to understanding what this problem
is just gonna do a little use tag action
I machine stack back trays I'm gonna
call Python developer I'm going home no
you're not you're gonna see a lot of
this I've got a problem I just need to
find the guy who wrote call function
call function mmm call function look
it's a recursive this moron what is he
doing don't call yourself recursively
call function stupid call function and
hope
you don't actually raise the selenium
your coworkers hopefully you realize
wait a minute coughing OH
don't because you're not seeing this is
not like there's not like Hall functions
that's you know this is not like you
know calculating you know PI out to some
number of digits call function is just
executing Python somewhere and even with
D trace you what you have to do is go
instrument the actual Python the
implementation of Python to figure out
what the hell is going on so this was
the state of DTrace when we shipped it
2004 and we realize that there are all
these environments out there Ruby Python
Java and so on and how are we going to
go instrument those so what we did is we
developed a couple of interesting
technologies that allow us to put zero
probe effect zero disabled probe effect
probes into these various environments
so what we and the way the technology
works is actually pretty interesting is
the in we actually declare a probe site
that gets turned in that gets turned
into a call that the linker then knocks
out but records the probe site that gets
all i--all down to the kernel we know
where that is in the application we can
turn that knob and turn that knob on now
what we discovered is with environments
like Python and especially Ruby even
that wasn't enough because they had to
do so much work to figure out where the
hell they were in a function entry for
example Ruby getting the class name is
like I mean it's like trying to get your
tax return from eight years ago I mean
they the amount of work they have to do
to get the class name in Ruby um so for
that we actually did we met in something
called is enabled probes that allow you
to say if this probe is enabled here's
this block of code that I want to
execute then that becomes an OP site and
when that probe turns on we make that go
live and now we're gathering this
information and and and you can hit the
probe site with some really interesting
information
what kinda mentioning information let's
take a look at this my laptop doesn't
melt here and it's trying to what we'll
see here
our Python probes and actually I'm going
to know I'm like I was good put myself
in real time together in class pixel
into that on so what I actually want to
go do is in instrument
Python star function entry that will
fire whenever we execute a Python
function now that's not necessarily that
interesting so I want to know what we're
actually executing now this probe has
got arguments and the arguments consist
of first of all are X 0 is the file so
if your first question was what file are
we in then this would be this would be
the the Python file so if you you've got
a I running Python that is you know this
this huge collection of modules and you
want to know very simple question that I
see this guy is compute bound where
which module is it I just knew which
module was I would know which phone to
pick up so I can do that by just doing
this aggregating on copy in store of r0
take the aggregating action to counter
and now in this case it's all wild one
not necessary is that initially I want
to know what function were in what
function we're calling that's arg1 ah
funky funky funky
next let me show you a script that a
co-worker of mine road where we can
actually do float racing through Python
so I'm going to use just those probes
and written by getting burning Gregg who
works for Sun now but wrote something
called the DTrace toolkit and I'm just
gonna run this sucker and what you're
gonna see is the actual flow through the
Python rather useful actually alright so
I'm gonna stop my little wild one goober
over there um and let me actually run
the different I'll run the loop here so
I want to show you something that's
that's even cooler actually so it's
great even now instant Python throw away
one problem that we have we still have
in many environments we had initially in
Java is this that okay fine I can
instrument I can insert our Python and
understand exactly what I'm doing what
happens when the point of
instrumentation is in the kernel what
happens when I'm doing i/o for example
I'm doing i/o I'm in the kernel I want
to know where is my wearing my Python my
alright that user stack back trace just
gives you call function call function
call function or RB eval RB eval RB eval
which actions kind of fun you can tell
people who have to deal with these these
languages in production because they see
these that those names so many times you
can just kind of utter the name and
watch the you know this watch the rage
erupted RB eval is a good one if someone
has to do Ruby talks in terms of
performance and you see a lot of RB eval
um so I want to know actually where in
my my Python this is really hard to do
and we have this problem of Java and so
that the problem is this just to restate
it we're in the kernel
we're coming off CPU we're doing i/o I
want to take this stack back trace and
turn into something that's meaningful
for Java the problem is all that
information that you record in that sack
back trace by the time you post process
it later is irrelevant to the JVM JVM is
you know jaded things and recompiled or
whatever so okay all right fine so what
just go up to the JVM and we'll ask it
hey you're a bunch of addresses like can
you tell me what the stack trace looks
like that's all well and good but hey
we're coming off CPU
all right we're in the kernel coming off
CPU you can't even grab locks dude like
you're coming we are in a very delicate
context you can't go around running
other processes can't stop anybody some
can't grab blocks you're done that we've
made the decision to take you off CPU so
what we did is something that is
mind-bendingly complicated and took us a
long time to satisfy ourselves at it
with the simple solution to the problem
because I generally hate complicated
solutions but this is a very hard
problem what we actually did is the JVM
has something that we call a you stack
helper and it is a special D script that
fires in the context of the actual
enabled probe getting a you stack and
what it does is it allows the JVM and
then this this D script is compiled in
what we called off which the D object
form it sits in the JVM when the JVM
runs it I aquas this down to the kernel
and when you grab a user stack trace it
executes these these instructions this
virtual machine to actually calculate
the stack trace into something
meaningful these are very very hard to
write and took a long time to get all
this to work but once it works it's very
powerful because now you can correlate
your your Java to what's happening in
the system and so I actually wrote one
of these for PHP to kind of prove to
myself that it can be done for other
languages and I but I knew that so
basically I had written I had
effectively written the Java you stack
helper
I wrote the PHP use deck helper like
there's no way anyone else on earth is
ever gonna be able to write one of these
because this it's so delicate in terms
of the context that you're in but I was
wrong and I'm blessed with very talented
colleagues a guy named John Levin at Sun
wrote a python you stack helper that
even better than writing it he actually
integrated it it's actually in in Nevada
now if you're downloaded that is is the
the most recent version of Solaris if
you were to download the data after
build 65 you will get John Levin's
Python provider plus you stack helper
and this is unbelievably powerful
because now I can do things like this
scared off CPU well first of all let's
just agree on exactly
we should be able to find that Python
guy should be over here and he should be
in here somewhere this Python 2 4 so
it's a exact name equals Python check
out for I now want to aggregate on you
stack I'm going to give you stacks and
special options here normally you stack
just keeps a default number of frames to
store and I'm gonna tell you stack
actually I want you to keep a larger
buffer for string data that's coming out
of a you stack helper and I'll just give
it a 81 92 is kind of a nice round
number
and now when I control C so there's your
PI eval eval code looped up High Line 20
looped up PI line 17 func a looped up PI
line 11 func be unbelievably powerful
and this is um this is what you're
seeing is effectively the deepest
technology in dtrace and fortunately
it's it is technology that is very
applicable to the kinds of problems that
you are solving um so I actually I think
your this is the the first time this has
been publicly demo John did this work
very recently on blog dialects had
integrated it and I not I first learned
about it from the blog entry I couldn't
believe you go to a blog intro you'll
see my first comment thing like I can't
believe you managed to write this thing
because it is such a delicate context
but you don't have to worry about
technical details of writing it as far
as you're concerned the upside is
awesome because you're able to actually
understand what your Python is doing so
for you it's going to make quite a bit
of sense I would assert for some of your
problems to actually have a box that can
run dtrace with the Python uses a
caliper and actually go it because the
you know Python kids should I mean we
Python sloshes between operating systems
awfully well and it will make sense for
you for some of your problems because
this is such an unprecedented level of
production Python visibility observe
ability to reproduce some of your
problems on a box it has this kind of
stuff and actually be able to understand
what your Python is actually doing so
that I is the that's kind of I think
we've got until 11:30 right or my over
I'm not oh grandma
I'm over there's a 10 to 11:30 I'm 10 11
okay I'm 40 minutes over sorry about
that
well thanks for staying I didn't realize
that uh I guess I'd more people I
thought would have defected if I aren't
sorry about that well you're late for
your next meeting but who cares
interested meeting um so with that I'll
open up to questions um within with my
apologies Norway I thought I had 90
minutes here yes especially here okay
yes great question um what is the status
of DTrace on linux so um let me be blunt
with you on the linux is unusual in that
it is upside down in terms of where its
expertise lies normally with the system
like Solaris your best so Eris expertise
works for son
perception and I'm out
there's juice mix honor then there is at
Red Hat and about then you're pretty
disagree but that's my experience the DS
range can absolutely be poured to Linux
it is it's open source it's it's ready
when you are it's been ported to it
support Mac OS important FreeBSD net BSD
port underway if you can I should say
because I'm being videoed if you keep a
secret I would tell you another
operating system ported to but there's
lots and lots of interests out there
because people that are doing their
homework are recognizing that if you
actually start to take apart the
technology required to get this to work
you ain't gonna replicate it it took us
a long time to do this we were very
focused on it we've been thinking about
this problem for a long time before even
started and there the Linux effort is
hampered by several things first there
is some fear uncertainty and doubt about
the licensing issues those issues are
not issues for you you do not distribute
Linux the you do not need to the GPL
does not apply to you until you actually
attempt to distribute it so you can port
dtrace to linux and be scot-free so can
vmware so can pixar soaking these other
companies um they're in I think it's
actually licensing Fudd because the GPL
is never actually been tested in court
and but they're going to be does it'll
be disagree Mila I don't want to die
virginal licensing discussion I believe
that one can make a very strong case
that you can port dtrace to Linux
distribute the whole thing and actually
be in in fine shape but others
absolutely will disagree with that you
can certainly port dtrace to Linux and
use it internally I the second
phenomenon that is hampering the Linux
effort is a just for personal pride
reasons Red Hat is interested in
competing with Sun Google is interested
in solving problems and that you have so
Red Hat is on into the importing dtrace
to Linux because that would actually
that would be this huge deference to Sun
so Red Hat has a rival effort did you
try it's called system tap which
unfortunately I mean it's great that
they've been you know that I guess
imitation is the sincerest form of
flattery but is bad imitation net
sincere form of flattery under no um and
and atrocious imitation I don't think
actually is flattery or I'm not I'm not
flattered let's just put it that way
um they don't understand the problem we
solved the problem they're trying to
solve is son is kicking the out of
us on Wall Street with dtrace that's the
problem they're trying to solve not I've
got Python that's running in production
that I can't observe that's problem
you're trying to solve very different
agendas you guys don't bust my knowledge
you probably probably got some Red Hat
kicking around but paying Red Hat for
all your hundred thousand boxes right or
if you are I found a good way for you to
save some money um right
you're not a red head customer lot Scott
and there are lots of people like you
that aren't if and I believe when Dee
tries to be ported to Linux it has to
come we believe from technologists a
company like companies like Google what
will it take well first of all will help
you we understand the code very well we
understand having worked for the FreeBSD
folks having worked with the Apple folks
we know what it takes support it to
another system uh it's not easy we it's
deep technology and this is not
something that we need more than just
like I'm interested in using detrital
next yes yes we know a lot of people are
just using each is on Linux but if you
can do the heavy lifting that's involved
in actually getting it to work will work
with you so what we're trying to do
actually right now is put together a
coalition of folks across companies that
are actually using Linux that have the
expertise to do it and if you're
interested I we would what we'll signing
up and I think we'll what would be
looking forward is you would probably
need to be local in the Bay Area or be
able to come out here for some period of
time and what we're thinking is like we
get everyone together for a week and get
in a conference room and see how far we
can get so we've got guys that some that
are women take a week of vacation to do
it and I'm sure the Google would be
asinine if they wouldn't give you the
week to do it so if it's something you
think you can do and it's something
you've got the technical ability to do
we're here to help you out because we
think that the the issues about not
taking dtrace to Linux are like
I'm going to work
but I did anticipate that question at
all I was I was totally caught
flat-footed by that question yeah that's
right I have a related question can
DTrace be ported to Windows yeah
actually the absolutely actually I mean
the device itself is um in part actually
because of the problem we are trying to
solve
we have to operate in very constrained
contexts so means we can't go calling
kind of kernel services at large right
we don't we can't go call print K which
are the equivalent in in Solaris we
can't really use the Solaris primitives
that much
we don't use mean meet axis for example
synchronization primitives we only use
synchronization primitives in the
infrastructure required to get DTrace up
and running when you are actually in
probe context you can't grab locks and
probe context we run with interrupts off
right so and we've separated out that
layer pretty well so it's um it can
absolutely be part of the Windows if
Microsoft's interested words that we are
anyone that wants support DTrace to any
platform we are interested working with
to make it happen because we think it's
a win for everybody so win for humanity
so the the technology is can definitely
do it it's not easy I'm I don't want to
say that it's not easy and you can
discover issues or it's like oh
this is going to be really hard because
we built the trace on the foundation
that we had built in Solaris for years
so we built the trace on some
technologies that we'd spent a lot of
time investing in at sun and the freebsd
guys decided to take a bunch of that
technology in freebsd
which is great that might not be the
easiest route for other systems but it
absolutely can be done other questions
okay great thank you very much I'm at
all sorry I sort cut off my own applause
on the if you want to get a hold of me I
am BMC at Eng Eng comm and you can find
my blog online but if you want it if
you're interested contact me either come
and see me afterwards and we'll change
contact information and let's try to get
a Linux port off the ground so thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>