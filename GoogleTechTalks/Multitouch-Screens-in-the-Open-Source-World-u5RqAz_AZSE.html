<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Multi-touch Screens in the Open Source World | Coder Coacher - Coaching Coders</title><meta content="Multi-touch Screens in the Open Source World - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Multi-touch Screens in the Open Source World</b></h2><h5 class="post__date">2008-06-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/u5RqAz_AZSE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon ladies and gentlemen and
welcome to today's Tech Talk multi-touch
screens in the open source world our
speaker today is mr. pibbles so yeah
from the Wroclaw University of
Technology
two-time google Summer of Code student
and now a mentor for the natural user
interface group well tick right Thank
you Thank You Leslie so thank you for
having me here it's my second tactic
here I was here one year ago talking
about my google Summer of Code project
actually one of these projects will be
gonna be a part of this detector today
so I'd like to talk today about two
things basically one is open-source
software and the other thing is
multi-touch screens and how those two
can be used together and what can we do
with them so as you know Google is
supporting open-source in many ways
Google Summer of Code Google highly open
participation countries and many
open-source project so that's a good
place to talk about open source project
so I can talk about history behind user
interface in general and multi-touch
screens then a little bit about
available multi-touch devices that we
can buy right now or see some prototypes
and how those devices work and more
details from the learn about the
implementation that is required from the
hardware point of view and from the
software point of view what is required
to make that multi-touch screen work
then of course what kind of open source
projects exist to enable you to operate
multi-touch screen and how to create
multi-touch screen using open source
software and then a little bit about
events that can gather sent from
multi-touch device to your application
and what can you do with them and about
200 protocol which is tangible user
interface objects protocol used by many
open source projects for handling
multi-touch events then about
and the most fun part I think will be
the demonstration of some of the
applications and and multi-touch screen
so let's jump right in into history so
in early 70s at Xerox Palo Alto Research
Center they've been working on something
called win window icon menu pointing
device which you are probably familiar
with they worked on WIMP on his on their
first computer
Zarek's Alto with the graphic user
interface which looked like this and
right now after more than 30 years we
have Windows Vista we have Mac OSX leo
board or Linux with cool 3d effects for
using xgl and really now not much has
changed since since early 70s we still
have Windows we still have icons menus
and the pointing device keyboard and the
mouse that is used as a pointing device
in the meantime in the late 70s at MIT
speech interface group they worked on a
more natural way of interacting with
computer I think the most interesting
project or those two the pushed out
there in 1979 and a spatial data
management project in 1980 using the the
pushed out there you could basically
move the objects by showing them by your
finger without even touching the screen
and also use the voice comments to to do
something like take this object move it
here and things like that and the
spatial data management project is more
about Zoe
interfaces which is zoom able user
interface which is now
used also in multi-touch screens world
where you can zoom in zoom out and have
a big work space on which you can work
and also I won't like I would like to
mention that computer mouse has been
around it took Mouse around more than 30
years also to be widely used because it
was invented in 663 and it was widely
used with Windows 95 so it was more than
more than 30 years to be widely used so
even though multi-touch screens it's not
really something new because even in an
85 the bill paxton from Microsoft
Research he's working right now at
Microsoft Research but an 85 he was
working at the University of Toronto he
started project called the multi-touch
three-dimensional touch sensitive tablet
and 85 so multi-touch isn't really
something new it was it's known for more
there more than 30 years 20 years right
now so we have so sometime to get it to
state where it is widely used then later
on a 95 key also work on project called
interactive desk it was a project with
Microsoft Research and University of
Toronto so what the multi-touch screen
really is and how does it work you're
probably familiar with the regular
touchscreen which only enable you to
sense one point of contact so like
machines like ATMs or palm tops or
tablets they usually just have the
touchscreen which can which can only
sense one one point multi-touch screen
allows you to sense many points
simultaneously so at the same at the
same time you can use many fingers you
can
also multi the screen is also a
multi-user device however because it
allows many users to work on the same
screen at the same time there are
different techniques for doing
multi-touch screens the one that I want
to talk about is the frustrated total
internal reflection
it's called FTIR and diffused
illumination di and those two are based
on image processing mostly I'm going to
talk about them a little bit more in the
next slides there are also many other
ways to handle multi-touch there is some
electronic field sensing technique which
was used by Mitsubishi electronic
research lab there are also techniques
that are patented for example the
technique that is used and iPhones iPod
Touch or MacBook Air and pro multi multi
touch pads those are from the company
that upwork wired a couple years ago
called finger works so I'm not going to
talk about those but more I gonna poke
focus more on image processing ways of
doing multi-touch screens and basically
multi-touch is a new way of
human-computer interaction that's how
it's most many ways in many places
described so about the available
solutions what kind of multi-touch
devices we have right now on the market
or the prototypes that that have been
developed one of them is the reactive
vision table or react table it was it
was made at the one of the University
and one of the universities at in Spain
it's a sound synthesizer which allows
you to sense multiple fingers and also
sends markers that are placed on the
screen those markers are named fiducials
and as you can see there are different
different markers on the screen and this
multi-touch screen allows you to sense
the position of them also rotation and
that way and I will enable you to create
really really innovative applications
like this one is that this is a sound
something some synthesizer that was also
used at one of the concerts of the orc
I'm not sure if you if you heard about
that and the other device is called
diamond touch
it's from Mitsubishi electronic research
lab it allows you to also sense multiple
fingers at the same time and allows you
to identify which finger belongs to
which person there are special chairs
out there it uses the technique called
electronic field sensing so thanks to
electronic field and our body it allows
you to sense which finger belongs to to
who and you can up to four
I think there's up to four persons can
use the table at the same time and also
there are other devices that are
available that you probably are familiar
with it's Jeff Hannes FTIR screens that
I'm gonna talk about a little more and
about the FTIR itself later Microsoft
Surface
it's space on this diffuse illumination
technique and also iPhone and iPod Touch
this is based on the on the technology
from the company finger works of course
there also there's also MacBook Air and
my pro which has the same technology
used in iPhone and iPod Touch just
without the screen and there's one more
just I don't I want I would like to
mention is called chess moutains L'Amour
it's a multi-touch screen small one
which is used for visualizations and
also for sound synthesizer at the sound
sound to sizer and has a really great
configurable and programmable and
graphic user interface this is the one
on the left so the list of those devices
can go on and go on and we could talk
about an hour about Yahoo that are
available but the one that I would like
to mention after today's project by john
lee a researcher from Carnegie Mellon
University which worked on some remote
hacks that allows you to send multiple
points using just v controller and it's
embedded infrared infrared camera I will
try to present that during during this
detector how does it work and what can
we do that there are also Microsoft and
Dell is working on some solutions for
multi-touch laptops and recently they
announced a technological touch wall or
Lasser touch which uses three lathers to
sense multi-touch this is the video in
the middle and also they announced that
Windows 7 will be full multi-touch
system the video on the right with Dell
Latitude XT laptop with some duo Sense
technology that thou has developed but
let's switch maybe to those technologies
behind I've used image image processing
those are the demos by Jeff Hahn from
the company that he started called
perceptive pixel in 2005 he showed first
prototype of his device using uses the
frustrated total internal reflection
for sensing multi-touch tenon and 2006 a
little bit bigger prototype with some
really impressive demo applications and
in 2007 he showed case pretty big wall a
multi-touch wall with many great great
multi-touch applications this is for
example Google Google Earth using using
multi-touch so what really makes
multi-touch screens work actually we can
talk about image processing so for image
processing techniques it's it's light
it's light it's all sorts of light maybe
not that big bulb but actually more we
use LEDs different kind of lights
usually it's it's infrared LEDs the
actually the top top left image shows my
lights that I use for building my first
multi-touch prototype and those LEDs are
used for the technique that are going to
describe right now it's called
frustrated total internal reflection fgr
and how does the work so you can imagine
that we have a acrylic piece of acrylic
and we have infrared LEDs that shine on
the both edges and the light from
infrared LED bounces inside inside the
acrylic and we have also an infrared
camera that can sense those this
infrared light and once we once we touch
the screen the light frustrates
frustrates from the from the acrylic and
it's picked up by the infrared camera
and what we see it on the video input is
something like this image something like
this one with those white blobs in the
place where you where you touch so then
later on using
using image processing and algorithm
like blob detection or blob tracking you
can really easily sense multi-touch
using this FTR technique and this is
that that technique that Jeff Han
invented three two years ago there's one
problem when you're trying to if you
don't have a silicon rubber that is
sometimes needed there's a problem when
you're trying to draw drug-drug things
around on the screen so we use silicon
rubber as an another layer on top of the
acrylic and then a project projection
surface projection screen and the
silicon rubber really helps and when you
do things like drug drag-and-drop
the good thing about FTIR technique is
that the blobs that we get as you can
see on this image on the right or have
have really strong contrast and it's
really easy to find them using using
image processing techniques the final
final setup of FTIR screen looks
something like that
we have a projector we have a mirror and
we have a computer acrylic lats and
infrared camera which can see those
white white blobs when you touch when it
has the surface so that's the basic idea
behind the FDLR screen
another technique that is for example
used by a Microsoft Surface
it's called di diffused illumination
it's almost the same as the FTA are but
instead of having I infrared LEDs on the
edges of the screen we actually have the
infrared illuminators just next to
infrared camera which shine a light in
the direction of our hands into the
direction of the surface and what we get
is the image like this one on the on the
on the top the rarer it's this this one
this technique is also called rare
rare diffuse illumination because we use
the light from infrared illuminators
however there is also a technique called
from the front diffuse illumination
which where you don't really have to use
infrared illuminators or you can just
use the ambient light that is around and
in the room that you actually have the
multi-touch screen so those two video
input frames showed on the right this
one and the rare D I showed you how do
you see the fingers when they touch the
surface and the other one the front di
using the ambient light shows you how do
you see the shadow that is created when
you touch when you touch the front di
multi-touch screen the final di setup
looks something like this so it's pretty
pretty much the same as as the FTIR one
but instead you have those infrared
illuminators if you use front di or you
don't really have nothing at all you
have nothing at all if you if you use if
you use where di you you have those
infrared illuminators if you use from di
you use ambient light so you don't
really need them so how does how does
the look from the camera point of view
what I see on on on the video capture
when I capture the the frame from the
camera is something like that and what I
have to do is use special image
processing filters the one that we use
is high pass filter to filter out
everything other than the touch and
actually it works pretty well this is
this is the example that I've put in
in quartz composer on Mac OSX using just
the filters that are available in Mac
Mac OSX and this is the output of the
filter chain and how we can sense
multiple fingers and how we can filter
out everything at it and then the touch
on the on the diffused illumination
setup so actually you can see that
here's the the input video and the
output shows pretty well when when and
where you touch the screen so actually
you have to do those image processing
things so you start with video input you
capture the frames then you do image
filtering using high-pass filters
background subtraction and other other
filters that are used for that when you
get the really clear image of the
fingers which usually is the Binnorie
image you use the blob detection
algorithm and the size of the blobs and
then later on you do blow up tracking to
assign finger and ID and track its
position based on the data from the blob
tracking algorithm you can easily send
events to to your to your user
application and based on the events that
you going to send you can do get your
recognition before we go to the before I
going to talk about the open source
project that are used to handle
multi-touch and operate multi-touch
screens I would like to talk a little
bit about anyway group it's our natural
user interface group it's an open source
community behind modern user interfaces
and in particular multi-touch screens we
started that two years ago in September
start the forum
in January 2007 and most of the project
that we work on or released as open
source software we have a forum block
Vikki IRC Channel and right now we have
over 2,000 members that are working on
different tutorials hardware and
software tutorials also share a lot of
photos videos how to create your own
multi-touch screen and we really have a
lot of students PhD students researchers
from around the world
programmers graphic designers interface
designers so it's really it's really
really nice community for example from
May 2008 this is a new a group comm we
we got almost 60,000 visits from five
over 5,000 different cities all over the
world so we are getting a lot of
attention and we are really happy about
that and our good thing about that is
that actually in 2008 we got into google
Summer of Code it's our first time in
google Summer of Code
I'm a former ji-suk student and for this
organization I'm also a mentor and we
group is an umbrella organization
because we have a set of projects that
we are working on so we got seven slots
which is really amazing number we we
received over 40 over 40 amazing
proposals and it was really hard job to
pick those only those seven those are
the projects that we are we are working
on with the students some of them are
really really really interesting and for
example South Sandler this is a really
great student he's been in our community
for from almost a peck at the beginning
and he's actually working on a new I
touch framework and and flash to handle
multi-touch applications and there is a
lot more like Mac OSX open touch
conversion this is I've been working on
the open touch project during the google
Summer of Code 2007 and right now the
student is we convert convert this code
that I wrote in C++ to make it more OSX
specific and when he will write it and
and and imported to Objective C so I've
talked a little bit about techniques
that can be used for sensing multi touch
and multi-touch in general and so it's
maybe now switch to to those multi-touch
open-source projects that are available
and we can use to operate multi-touch
screen so this is this is a list of some
of the projects that noe group is
working on and also our that our other
developers are working on the two three
that I'm going to talk about today is
called the first one is called touch
sleep the other one is Tabata and the
open print touch this is my project from
google Summer of Code 2007 there's a why
there's a lot of different other other
projects that are available likely they
leap FA GS and it's Britain and in part
on MPX it's an extension to X Windows
Server to handle multi-touch on X
servers open table it's written in Java
dotnet multi-touch framework is wrapper
to to touch sleep in c-sharp
touch api is a project and flash that
allows you to receive multi-touch events
and flash BB touch is a new project that
is right now on the open touch
repository it's for objective-c
project for handling FTIR screens and
there's a lot a lot more actually I
typed in multi-touch and at Google Code
project hosting and
I got 24 different projects some of them
are here some are not here but there's
really a lot going on in open-source and
multi-touch so I'm gonna talk a little
bit about touch sleep this is actually
the first open source project to operate
multi-touch screens started by David
walling from Pennsylvania it supports
both FTIR and di techniques right now we
will start only with FTIR support and
right now there's like seven developers
that work on this project and even
though the first version was released
only by David it uses OpenCV it's the
library released a couple years ago by
PI Intel open computer vision library
for it uses it for image filtering and
it supports the 2eo protocol for sending
events to to your final application I'm
gonna talk about two-year protocol in a
little bit and it uses a wide range of
external libraries to handle cameras and
you can use TS video lip video wrappers
CMU firewire driver and video for linux
so you can use many different cameras
with roughly how does it work
this is a showcase of some of the
applications that are that are made
using touch lip touch lip is used for
for blob detection blob tracking and
those image filters that are needed for
a tird or di setups and for sending
events to to your final applications so
here you have some smoke demo in OpenGL
here is some water effect in flash some
image viewer also in flash some
application and processing on the left
those although all those videos are from
our and we group members and that kind
of videos are available also at our web
page if you'd like to check it out
my project and I was working on Google
doing Google Summer of Code 2007 it's
called open touch this is actually how
the how the input from FTIR screen looks
like you can see those white white blobs
when I touch the screen and how the blob
detection algorithm works and the texts
where is the what's the position of the
finger so this was blob blob detection
algorithm stration this is a blob
detection and blob tracking algorithm
instruction so we can see that each
finger after it is detected it has ID
and using blob tracking algorithm we can
track track the fingers and send those
events to some external application as
you can see on the top right this is
actually the external application that
receives the events from from open touch
using the two-year protocol this is
another example simple example open
touch is sending even to processing
application which is a Java environment
for doing visualizations and this is
just a simple demo of some drawing with
multi-touch so actually I can draw using
many fingers at the same time and then a
year ago I started a project to extend
quartz composer on Mac OS X it's not
finished yet
it allows you to receive events in
quartz composer on Mac OS X and actually
do some kind of visualizations using the
data that you receive from open touch
this was the explosion a simple
explosion example this is simple
particle systems
which trucks your finger finger position
and that's pretty much how open touch
works and what can we do with it of
course to to ride your multi-touch
applications you need to receive those
multi-touch events and we have three we
use three events for that first one is
finger down it happens when you when the
new finger appears on the screen
then we have finger up when the
previously detected finger disappears
from the screen and the third one
happens when it's finger update it
happens when previously detected finger
changes its position and based on those
three events we do also get your
recognition for sending events as I
talked before we use tui or protocol
it's based on open sound control it's
similar to MIDI format it uses UDP to
send packets to Europe to to your
application it was created by the the
same team that created the react table
and reactivation software that I showed
you before the good thing about about
two year is that it was released with
many implementations with
implementations in C++ and Java and
c-sharp and in flash and also another
visualization there are some available
some patches and plugins for other
visualization software like pure data or
max/msp it uses two types of comments
one is the cursor which is used when you
touch with your finger and the other one
is marker fiducial which is used when
you place a fiducial on the screen
fiducials looks something like the image
on the right there is I think about 50
50 50 fiducials available
and it supports right now all the
multi-touch screens are an entity
because we have a flat flat surface but
you never know what's gonna happen in a
couple years so - we are supports 2d and
3d events so if something's gonna happen
and tweedy later on a couple years to
year also supports that and as I'm as I
mentioned before touch sleep T beta and
open touch projects those that we all
support
- yo for sending events to your
applications so once once we have those
events in our applications we can do
gesture recognition what kind of guest
sure we can do we can do one finger
gesture just like Mouse gestures or we
can do multiple finger gestures some if
you if you're a I phone owner you
probably know the zoom pinch rotate or
if you're a Mac owner you also know how
to scroll with two fingers there's a lot
more if your Mac bougar owner you can
use pinch expand taps the second
secondary click we're using using two
fingers click track and swipe using many
fingers you can use those regular
gastrous that are pretty pretty much the
multi that's standard right now you can
use three three fingers for tilting or
scrolling you can use two fingers for
rotating two fingers for zooming on
scaling but you can also have different
gestures dependent which you are
dependent on the under your gesture
recognition algorithm and your gesture
recognition software those some some
proof of concepts of something like
confirm except cancel delay exit or a
new ad there's also a lot more gestures
available actually the company that
Apple acquired the company finger works
has a great PDF file under under webpage
it's a multi multi-touch gestures
dictionary which has many many
for examples of gestures that can be
used on multiple surfaces if you are a
software engineer if you're a developer
programmer you probably want to know
what kind of languages you can use to
develop multi-touch applications
absolutely actually it's I would say in
many languages starting from C C++ going
through c-sharp Java Objective C right
now we have two EO framework for
receiving 2 EO events in an objective-c
then a new group also works on
ActionScript libraries that can handle 2
EO so you can develop applications in
flash and in Python there's a project
called pi 2 EO also to receive to your
events and you can implement your own
implement your own 2 EO protocol library
in any other language that supports UDP
however if you're doing if you're making
creating your own multi-touch
application what you have to remember
about is that design really matters that
Mouse is not the same thing as a finger
and when you when you design your your
user interface if you're an interaction
designer or your interface designer and
you need to remember about the precision
with your finger because you can you
cannot be it's gonna be so precise as a
mouse so the balance should be bigger
and and things like that you really have
to remember about that but also if you
have the final application how do you
how do you test it what happens if you
really don't have a hardware device that
allows you to sense multi multi touch
and how do you test your multi-touch
applications they're actually two ways
you can use the hardware that you might
not have this is this is also a little
bit of a hassle because you really need
this multi-touch device next to you when
you develop your application
and sometimes the easiest way is the
software software testing of multi-touch
you can use there's a project to code to
your simulator that you can use to
simulate multi-touch cash and
multi-touch events and send them to your
final applications without having a
hardware you can use just Mouse I'm
gonna show you how to how to use just
Mouse - to emulate multi-touch and you
can develop your own protocol if you
want - to send those events to your
final application and use some kind of a
simulator actually what we are working
on right now is a application called ite
Oh for iPhone which uses multi-touch
screen on the iPhone and allows you to
send to your events of over wireless
network to your multi-touch applications
so you really don't need multi-touch
screen but just an iPhone - to send
those even then and then later on you
can test that on on a bigger bigger
surface and should work the same way so
what I'm gonna try to demonstrate right
now let me start with two-year simulator
how it works and how we can send events
to multi-touch applications and I will
try to show you how it works in action
by running my application called touch
earth which is multi-touch Google Earth
it's it uses Google Earth comm API - to
extend it and handle multi-touch events
in Google Earth so I will use through
your simulator to operate touch surf
after that I will showcase
anyway framework this is a framework
that we developed at the company that I
work for for creating multi-touch
applications and for many easy
prototyping of Multi Touch apps
and after that we will try to use
Wiimote and the technique that generally
showed on YouTube to do interactive
whiteboards I actually just have one
infrared pen so we really want to have
multi that's interactive whiteboard put
just just and one one point interactive
whiteboard and after that what we gonna
do is I can try build simple multi touch
sensor using cardboard box picture frame
tracing paper and I have infrared camera
here so you're gonna see if that if that
works this is actually a project biceps
and ler the student that I mentioned
before so this is a really low cost a
nice way to put a multi-touch sensor and
early five minutes and using this mmm
project called empty mini you can try to
test some of the multi-touch flash
applications some simple draw
application fire application and physics
example and that's about it so let's
jump in to some demonstrations
I try start with
okay here's the reactive vision - video
simulator I can use mouse to just
simulate one finger and if I press shift
the finger will stay and I can do
another finger and another and later on
I can move this one or disable this one
I can put a fiducial here rotate it so
actually I don't really need a
multi-touch table just to simulate a
little bit or just play with with
multi-touch applications actually that
the torture publication that I developed
was done without multi-touch screen at
all just using this dis simulator so now
what I have to do because the touch
refworks on Google Earth application for
Windows so I need to run Windows and for
others in order to show show you how it
works
this will take a little bit
there is a way to to control Google
Earth on Mac OSX to using AppleScript
and there is there is actually some team
developed Python multi-touch framework
and they send Hubble script events to to
Google Earth on OS X but I never really
had a chance to develop that so just a
minute a way to windows starts
so yes I can put many many fiducials on
the screen rotate them each fiducial has
a different ID so that way I know which
fiducial is is where and what it's it's
oriented orientation and also two years
supports those two comments different
for for cursors and different for for
fiducials so that way I know whether
it's a cursor or or fiducial
this is going to take a little while
just a second
to check what's the what's the IP
address of the per hour session
that's slow cuz it's in in four hours
okay
so what we have here is full screen
touch earth application which uses
Google Earth on top and I can easily
navigate using finger using to video
simulator I can zoom in or rotate using
two fingers I place this one here and
then using second finger I can do things
like that
zoom in zoom out and using three fingers
actually I can tilt so I place two
fingers in one in the same position and
then using the third finger I can tilt
the screen too so that's basically
what's what is possible with the comb
API of Google Earth what is possible
using to your simulator and and
multi-touch screen the same thing should
work just fine just same as with to your
simulator it should work on any
multi-touch screen that can handle to
eat to be a bit even okay that's about
okay the second demo I'm gonna try to
find is - anyway framework
you can bring bring up the menu we have
some sort of applications if some games
won't bone we have viewer draw
application box select viewer for
example here and right now I'm not using
to your simulator at all
I'm emulating multi-touch to finger
touch with right click to the first
finger and then with this second click
with using left click to for this for
the second finger and I can move the
application around zoom in zoom out I
can inside the application I can also
zoom in zoom out move around things I
can bring up another application like
example warm which is pretty pretty cool
game I cannot showcase it and then full
power right now because I'll need two
players you just touch the surface to
create this line and
that's basically how it works then we
have draw plication to draw on the
screen using using multi-touch - and all
those applications are or also they can
receive multi-touch events and then use
two cashiers to zoom in or zoom out or
change change its size what else we can
bring up here we have a nice game old
box
multi-user game you pick up your bug and
you try to catch them together if you
catch them give catch two or three of
them the bug becomes bigger and the
winner is the one who gets the biggest
bug and that way using multi-touch many
users can play the same game at the same
time
yeah so let's try this okay yeah
quick here and it's quick
okay so that was
I was there anyway framework and not was
the Microsoft Windows sparked now let's
try to play with with the remote and the
infrared infrared pen
see if that works
okay
so generally released his software for
Windows I think and probably for Linux -
as an open source project and then later
on somebody created a project called
Wiimote whiteboard which is part of that
- - OSX it's actually written in Java
okay here we have we moved whiteboard
then I try to calibrate the device
okay I got some exception try again
okay
so it detected remote it says it's
calibrated but it's really not so we
need to recalibrate it and what I will
try to do is select this screen we can
see the air camera monitor and this is
the infrared pen I like that I are
working and basically I have infrared
LED here and just a simple button and
and we mode has the embedded infrared
camera which can sense up to four white
blobs from the from the infrared lad so
if I do something like that you can see
that a here's here is some
some block that it can detect and truck
so up to four points it's that way you
can get a multi-touch also like using
two two pens for example I actually I
just have one here but we're gonna try
to do is we're gonna try to calibrate
this screen okay it's a little bit up
maybe just a part here and see if that
works and try to
Hey
and now let's fire some paint
application
and now when and uh wiimote it actually
shouldn't be there should be like some
somewhere here or at the top of the
screen you know it works much better but
when it sends the infrared pen and it
actually allows you to to draw easily
it's not at the best surface I guess
because it's not calibrated on the whole
screen it's just a burden and in this
part
okay seems to work so that way if you
have second finger you can do
multi-touch also but actually this is
the wrong position for the for the
Wiimote but that's that's the way it
works
so very easily very very fast way to
change any surface to interactive
whiteboard or a multi-touch while boy
okay
okay and what I'm gonna try to do now is
I have a chair here I have a cardboard
box I brought here from Poland and I'm
gonna try to build empty mini really
quickly just to show you how he better
works with with empty me this is going
to be okay what I have here also is
picture frame with tracing paper without
the back back is actually here and I put
it here as my multi-touch sensor
other than that I have a FireWire
infrared camera I have a set of filters
actually we gonna use the ambient light
without any infrared illuminators
without any infrared LEDs that is used
for FTIR setups so I don't really need
this this is the visible light filter we
use when we have a FTIR setup so that
way we only see those white blobs
without any external light so I don't
really need that for for now because I
gonna use an ambient light okay
but the camera inside
okay
here is the T better software this is
what we see on the on the screen and
actually you can see how I can sense one
finger two fingers three fingers without
any without actually anything it's just
just a cardboard box and just a frame
right and thanks to this application and
also that it supports to you I will try
to demonstrate some multi-touch flash
applications this applications was
actually developed mostly by self
Sandler as I mentioned before and then
Christian more so I'd like to thank them
right now for all that work so now I'm
gonna try demo those flash apps
problem with flash is that it doesn't
support UDP so when I send UDP to flash
I actually have to use another
application called FL OSC which received
OSC and converts them to XML data that
flash can receive so I have to run the
FL OSC application first
okay I got it got it running here still
works
okay
and maybe let's try with fire
application
your simple fire application so this is
a flash application which receives
even's from FL OSC first I sent from
from Tibet ice and two events to a
fellow at C then F LLC converts them to
to XML and here we have simple
multi-touch application so this is a
fire fimo we have some paint up also
since sometimes what happens sometimes
if I use the ambient light is that I
sometimes get a random blobs if the
light conditions changes a little bit so
that's why it is going correct crazy
sometimes let's change the color yeah so
this is simple paint
simple physics using one of the flash
open source physics library you can move
things around
yeah so those are the three applications
and I go for you today so you can have a
look how it works with that I'm being
light and I can put more fingers also
and this is the final result from the
image processing you see nothing else
but just white wops and those white flop
some are sent to blob blob detection
algorithm and then to plop-plop tracking
a girl also those random oh yeah right
now we can see that there is this random
blob which shouldn't a cure but because
we are using this ambient light and this
is not well configured and not all the
values are way they should be
we might get sometimes some random block
okay so this was T beta application and
now it's going back to the slides
so we are almost there what's the future
of multi-touch screens I believe that in
couple years maybe even at Google you
guys gonna have multi-touch screens in
your conference rooms maybe there gonna
be some solution for multi-site
collaboration where you can work on the
same surface around the different
offices around the world we're gonna see
multi-touch screens and hotels claps and
restaurants and many public places
actually ms surfaces right now and atnt
stores it's gone it's gonna be also in
hotels and in casinos the video that you
can see here is from CNN they actually
bought a a prototype or just a product
from Jeff Hahn so they have a big
multi-touch wall so it's also used by
television stations and in when when it
become even cheaper we might see it at
our homes - and actually Microsoft with
his touch wall technological and
touchable technology is trying to make
it as cheap as possible so a couple of
years you never know maybe your kitchen
a kitchen table gonna be a multi-touch
and I would if you'd like to get some
more information about multi-touch
screens and from the hardware point of
view and software point of view please
visit our web page at WWE Groupon anyway
group comm and also forums which is
really active anywhere group.com slash
forums I think this is the right time
for huge fangs to all of our
contributors like to mention Christian
more Seth Sandler Tim Roth Harry van der
Veen David Rowland and Lawrence Murrell
many many more of our community members
that have been working on those
applications and are still contributing
in many ways so thank you very much
to them and I'm not sure if we have time
but I would like to open up for Q&amp;amp;A if
there are any questions okay any
questions
sure
projection and yeah so we mentioned the
question
yes yes so the question what barriers
exist enables us to do to have a flat
multi-touch screens something like on a
LCD or or plasma this place actually the
one that Apple is using the one for the
company and they acquired that this
finger works company is something that
enables you to do that on on any flat
surface there are some more but I think
they are patented and they're not so
widely used yet but I believe this is
going this is going to change and then a
couple years to because I know that
Panasonic and LG are also working on
some ll LCD LCD multi-touch screens and
also this technology that I mentioned
this last hour touch technology is just
as just a sensor next to the next to the
surface attached so it actually can be
placed on whatever surface you want
whether it's a LCD or Plasma or any
other surface so yeah probably in a
couple of years so how does my work if
it's not an image processing probably
some electromagnetic sensing or some
something like that I'm not I'm not
really in those technologies yet but
probably something that is
are there any accessibility implications
for any of this stuff because it seems
like you know this is very cool visually
but I wonder if it affects how you know
how other people can use the system you
know people who can who aren't that
dexterous or you know are people that
are blind or whatever the good thing
about those technologies is that they
are really intuitive and for example for
children or for elderly elderly people
it's really simple if it's like first
it's their first contact with the
computer and they can just touch
something I like just zoom in or drag
and drop something and things like that
just like on their desk it's really
intuitive but other than that I don't
think there is anything about that
accessibility accessibility yeah yet
because it's pretty new there I mean
it's not new it's known for over 20
years but it's got a lot of attention
over like the last two years or the last
two years how many of you have heard
about multi-touch screen two years ago
probably okay so one person on so yeah
and it's known for over 20 years so
thanks to iPhone and Microsoft Surface
and things like that it's it's more
popular and there's not really like any
standard for also for gassers and I'm
not really sure about the accessibility
accessibility issues
um so multi pointer X was recently
merged into mainline X so the next
version of the main distribution line
its distribution should have multi point
in the Xserve how do you think that's
going to affect like adoption of multi
point stuff and is this compatible with
the stuff you've been doing well the
thing with Empire MPX is that it's also
used for multiple Mouse's right you can
use it when you'd have like three
Mouse's or things like that but what you
also need for like this techniques for
FTIR RDI you need another additional
software that will do this image
processing and they will send those
evens to your to your X server or
whatever other application I believe
like tab sleep is also working on Linux
right now so I believe guys are that new
right group gonna also create some sort
of maybe live CD or something with MP
and px and top sleep on on on the CD you
can just run touch sleep and then MPX
and Guetta and get a multi-touch X
window but what needs also it will
happen is because it's it's a different
way of interaction it's also we can we
can really use those menus and small
icons and small buttons and things like
that so if you create a multi-touch
applications you have to think about
that so working with just regular
applications and just using multi-touch
table I'm not sure it's it's a it's a
good good way of doing things so I think
there should be new applications
developed on the x window that will
allow multi-touch but they will be
developed by thinking of a multi-touch
and by designing for multi-touch and not
using the previous house I'm not sure if
that answers your questions
any other questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>