<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>CORE - Cooperative Reasoning for Automatic Software Verification | Coder Coacher - Coaching Coders</title><meta content="CORE - Cooperative Reasoning for Automatic Software Verification - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>CORE - Cooperative Reasoning for Automatic Software Verification</b></h2><h5 class="post__date">2008-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VogqGbRs1j8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to welcome Andrew Ireland it's
apparently midnight his time now so he
should be real sharp as usual he's going
to tell us about software verification
fine it's John so today I'm going to be
talking about a proposal that's very new
or a project that's very news really in
the proposal form we're just taking
forward now it's about four months old
it's the focus as John said is on
software verification and particular
automatic software verification so what
I intend to do in this is this
presentation is really to give you some
motivations explain the foundations for
the project and also outline headline
the approach we're taking so it's going
to be out quite a high level but i'm
going to use examples to motivate what
we're doing okay so first off the
cornerstone of this project is a new
logic this is not of our own design this
is a logic but we're building upon
called separation logic and separation
logic is only maybe about seven eight
years old it's an extension to the
standard whore logic for programming so
i'll go into a bit of the background of
that and i'm going to then focus in on
the automatic software verification
challenges so my background is very much
in automated reasoning so I'm interested
in applying automated reasoning
techniques to new logics and in
particular logic that can be used for
developing correct programs and in
particular I'm going to focus on this
notion of cooperation that's in the
title and is this where the core of the
core project comes from and I'll come
back to that at the end after I've gone
through my examples to show what i mean
by cooperation here more than just
simple integration as a few more project
details so my postdoc you McClain and my
PhD shin and behind kind are already
working on this project back in
Edinburgh
it's supported by the British government
fruit through EPSRC and those are a
website so you can find more information
background papers and presentations so
to start off separation logic as I said
it's a very new logic it was designed as
a joint effort between John Reynolds
from CMU and petrol harun from Kwang
Queen Mary University in London as I
said extends kors as axiomatic approach
to programming essentially introduces
new assertions that allowed to allow you
to talk about the heap and it was
created to allow one to reason about
point2 based programs these are very
widely used but notoriously hard to
prove correct and maintain those proofs
and separation logic has a real
advantage when when doing those kinds of
proves and we want to build on that
advantage for example it's able to deal
with 30 features like memory disposal
and address arithmetic in a very elegant
way the central selling point of
separation logic though is a notion
which is called local reasoning that is
in order to to reason about a program
the idea is that you should only have to
worry about the parts of the heap which
it touches okay so to show biz
graphically I've got our program on the
left here and this is the big yellow
heap on the on the right so if we're
interested in reasoning about the
correctness of this central piece let's
say it's a subroutine then ideally we
only want to talk about or think about
or worried about the sub part of the
heat the heap lit for which that program
unit can actually touch ok and this is
what separation logic provides you with
at the logical level that's done by
introducing what's called the separating
conjunction ok so the separating
conjunction operator is this star here
so if we assert p star q
what we're saying is but we can divide
the heap we can separate it into two
disjoint chunks one of which this red
one here for which the P is true one of
which here is green for which Q is true
okay so it's a spatial operator logical
operator so I'm going to run through a
little example execute a little program
to give you a flavor of how the program
relates to the logic or vice versa so
the top here is a store below the line
is is the heap the first instruction is
our allocation represented here by a
cons so we're allocating two adjacent
cells of the heap and we're initializing
them to one and two so that's
represented here in the picture so X
points to the first element and it has
this adjoining cell next to it this is
represented in separation logic by the
maps to operator X maps to the pair of
adjacent heap cells containing one and
two two quick there the second command
here is allocating another two cells
three and four pointer to buy why okay
in separation logic because we can
separate these two he plates at this
point our heap is containing just for
sales so we can separate into two pairs
and that's represented using the
separation connective I introduced on
the previous slide okay now we can
mutate the heap elements so here square
brackets is dereferencing so what we're
doing is we're taking the contents
speedin scuze me of what X plus 1 points
to and reassigning that to what why
points to so we're introducing a pointer
from the second sale on the left to the
first cell on the right of the pair
and then the last step we're taking
before we're reassigning that cell so
that it points to the first element okay
so you can see the separation logic
assertion has now changed we have Y here
where we had to before and we have X
here where we had for before okay so a
cornerstone of the logic not
surprisingly is the frame rule this is a
rule which linked with the separating
conjunction operator allows us to get
this local reasoning it allows us to
decompose larger specifications and
programs into smaller specifications and
programs okay so if we think about using
this rule in backwards direction as
we're moving back we have a frame
invariant a frame axiom corresponding to
our and we're able to isolate just those
parts of the specification below which
are relevant to verifying the code see
in the middle here using these these
whore triples okay so a keysight
condition is that are this invariant
here are none of the variables occurring
in that are modified by see if we
preserve that then this is a sound rule
of inference so moving forwards it's
like building up verifications of small
program fragments and then this rule
allows you to join them together okay so
separation logic just to recap is this
new logic extends whore classic core
programming logic and it's great virtue
is that it allows this local style of
reasoning and that local style of
reasoning gives the promise of scalable
reasoning when it comes to reasoning
about pointer programs so my interest is
in as I said before the automated
reasoning the automated reasoning the
Thea
proving in particular that you would
need in order to make this framework
this logic mechanical or automatable so
I'm going to tell you know about some of
the challenges that our project is going
to focus on and in the next three years
and we've made some some progress
already i'll refer to back to at the end
i'm going to do that by a few examples
and i'm going to base those examples
around an acyclic linked list data
structure okay so we have a head pointer
here I and the tail is the limited here
x IJ the top elements represent content
or data a 1 through 2 a n so this
pictorial representation is represented
below by this predicate list this list
predicate has three arguments the first
argument is an abstraction of the linked
list structure it's simply abstracting
out the data values so this represents
the picture above so the data values are
a1 a2 through to a n that's represented
here using a prologue list notation so
think about a sequence of data elements
the second two arguments relate this
abstract view of a data structure to the
actual pointer level data structure so
that's modeled here by a pointer to the
first element in the data structure I
and a pointer to the last element in a
data structure so you can think of this
data structure is representing a segment
of our a linked list structure so
typically the ones we will look at this
guy here will be nil they'll be
terminating segments above here is the
inductive definition for the list
predicate I've described informally
below so the top case is the base case
when we're dealing with the empty list
the list containing no data then that
means that we're looking at the empty
heap
okay and that means that the the point
is y and z must be equivalent to that
point this is the recursive case the set
case if you like we're looking at the
constructed element here again using a
prologue notation w use the head acts as
a tale of the data component if we are
to unfold that we introduce the
separating logic conjunction again so on
the left here we have the top element so
why the outer pointer is pointing to a
pair w is the head of the list and p is
a pointer represented here by the
existential quantifier p which links the
head of the list to the tail of the list
okay so you can think of these
existential zaz providing ways of
talking about internal pointers okay so
we're going to use this definition a few
times now so the first challenge if you
want to automate verification efforts in
this logic reasoning about pointer
programs is you've got to invent these
frame axioms so this simple example here
is our a copy list example so the
precondition at the top here is that I
points to a list with contents a
terminating an ill the post condition
we're going to verify against is at the
end of the computation that I still
points to a list with contents a but
there's a separate lists now pointed to
by joy which also has the contents its
value is the same so we now have two
copies of the same list and this is the
algorithm I won't go into too much
detail it's recursive is the main point
to take away and when we make the
recursive call here on the tail of I in
the tail of GA then we get to assume
our specification at the coal point okay
it's analogous to the induction
hypothesis if you think in terms of
recursion and induction the Eureka step
we're looking for though is this are
here so this is a meta variable in this
presentation is a gap we've got to fill
that in if we don't if we can't fill
that in then we can't complete the proof
and in this particular example I filled
in what about red meta variable should
be instantiated to its this structure
here so i won't go into the details but
this separation logic conjunct is
essentially talking about the rest of
the heap at the level above the
recursive call of the procedure okay and
if you if you think about this an even
more detail you can actually isolate
parts of this missing information some
of its talking about the shape of the
heap in this this missing are and some
of its talking about the content okay
and I'll keep coming back to this idea
that these specifications but also this
missing information can be decomposed
into content and shape and we're going
to use that in the way in which we
tackle the automated reasoning problem
okay so the second example is an
iterative examples or going from
recursion to iteration we're reversing a
list here so the specification at the
top we have a list again I list with
head pointer I content a we give the
content a and name a in it the initial
value of a and at the very end of the
computation at the end of a loop then
we've got our another list pointer to x
j with content be
so it should be is equal to the reverse
of a in it okay so with we've started
with a list pointer to buy I we've got a
list pointer to buy J at the end and the
contents of that j list is the reverse
of the a-list so we've accomplished the
list reversal task now the Eureka step
here not surprisingly is coming up with
the loop invariant okay coming up with
are essentially the work that remains to
be done and the work that has been
achieved so far the partial result if
you like and again there's two parts to
this there's a shape part which
basically tells us that there's a list
still pointed to by I and a list pointer
to by j so we're building up this result
list be while we're going through the
list a there's also a content part so so
the functional part is telling us that
at an arbitrary step in the loop then if
we append the reverse of a to be that's
the contents of the list pointer to buy
I and the contents of the list pointed
to by J we reverse the a and glue it
append it onto the front of the B then
that will be the reverse of the initial
list a in it okay so eventually this a
will dissolve away it will become nil
and we'll be left with be here when we
get to the post condition okay so we've
got to invent this structure in order
again for the proof to go through so the
last application I'm going to look at
all the last challenge is that quite
often when we're doing verifications at
this level it's not enough just to have
the definitions we need to have
additional the matter additional
properties that allow the proof to go
through
and in particular we very often need
inductive properties so this last
example is about lammer discovery the
program is simply taking two lists one
containing a one containing be it the
list containing a is pointed to by X the
list containing B is pointed to by why
and what we want to do is to get a list
pointer to by X with content see so such
C is equal to a appended to be okay so
this is just a functional presentation
of this iterative structure here and the
key thing you need to do here is you
need to invent a lemma an inductive
lemma which allows you to reason about
this gluing together of two lists data
structures essentially and that's the
inductive lemma they're taking the list
pointer to buy the terminating and W and
then gluing that on to the list w are
terminating an ill is equivalent to just
the list starting with the ending and
they'll with contents X appended to Y so
this again is our a Eureka step in
verifying that program so we were
interested in automating all of these
types of Eureka step and again there's a
shape component and again there's a
content component to coming up with
these structures okay so I'm now going
to move towards the end of the top so
I'm going to talk about the approach
we're taking so what we're going to do
is we're going to we're picking up
separation logic but we're also picking
up some off-the-shelf tools in
particular a tool called small food
which comes out of pedro herons group in
london small food is essentially our
shape analysis tool which is based upon
symbolic execution of a program where
the heap is specified using separation
logic so small fruit was developed so it
would operate on loop 3 code
that is you would have to provide lupine
variants for the verifications to go
through are an extension of small foot
RG but rely guarantee developed by
Matthew Parkinson a Cambridge has been
developed for working with with Java
applications one of its features is that
it deals with shape invariants by using
a process of abstraction to generate the
shape and variants I just talked about
two slides ago okay but we are
interested in both shape and content so
we want to use these tools and one of
the things we want to do is to make
these tools extensible okay currently
the tools are hard-wired for certain
data types acyclic lists binary trees
etc if you need to introduce a new data
type then you would have to prove a lot
of theorems in create additional
inductive Lammers so we want to support
that activity that's where our expertise
comes in the other part of the mix in
terms of this project is the area where
we come from an ad is automatic
automatic theorem proving and in
particular a technique called proof
planning so proof planning was was
invented by Alan Bundy Edinburgh
University in the the late 80s and it's
been developed ever since and applied on
a number of projects now so the basic
idea behind proof planning or the best
way I think to describe it is is think
of our proof plans as kind of design
patterns or they are the analogous to
what design patterns would be when
you're capturing common patterns of
reasoning at a high level and the idea
is that if you have common patterns of
reasoning represented in this kind of
planning framework through what are
called methods and critics you can note
use those common patterns to constrain
the
search that is automate the search for
proofs so proof planning is a
hierarchical activity your various
levels or proof plans so you start with
your conjecture and your theory and
there is feedback here because you may
modify your conjecture generalize it you
may modify your theory discover lemmas
and as you work down you generate what's
called a tactic so tactic is simply a
program it's a very low level part of
the proof process it guides a proof
checker in making sure that the proof
that's come from the proof planner is
indeed sound so proof planning itself is
not sound its focus is on search and
automating search we rely upon a proof
checker to make sure that the proof
planners instantiated is indeed a pro
gives us a proof so this kind of pulling
these activities apart proof planning
and proof checking gives us the ability
to reuse high level strategies proof
plans gives us robust this because we
can do analysis which allows us to do
things like generalization and lemma
discovery and it also has been shown to
facilitate integration because we can
communicate between various systems at
the planning level much easier than at
the proof checking level so one of the
key features of proof planning we're
going to make you solve is method level
as I metal out reasoning where we use
meta variables to delay the choice so
there was three examples I showed you
the areas of choice we're focusing on
our the the axiom the frame axiom I
showed you the the loop and variance and
also just working out missing lemmas
requires middle out reasoning I didn't
quite sure you about detail so this
might kind of middle out reasoning is
facilitated by what are called proof
critics so critics if you think I'll
proof plans and methods as design
patterns prove critics
alike anti-patterns they capture common
patterns of failure and along with those
common patterns of failure the associate
patches ways in which you can get around
the failure in the proof in much the
same way as we in attempting to do a
proof will realize we need a missing
Lama of a conjecture we need to prove
needs to be generalized so we have quite
a lot of experience of using this
mechanism and generalizing conjectures
coming up with llamas and also lupin
variants from previous projects in terms
of corporate of reasoning previous
projects where cambridge hall was linked
to to the clam proof planner at that
time and that was used to bring
mathematical induction or automatic
search for the mathematical induction
proofs into the whole system most
recently i work with a company called
praxis where we developed the tool
called spade ease which applied proof
planning and lightweight program
analysis to the spark language this is
the ada subset but column was talking
about this morning and there we were
develop automatically generating lupin
variance for exception freed improves so
lastly i want to come back to this
cooperative reasoning i put it in title
for good reason because it is a central
theme of the project so one way you can
think about a corporation is that it's
just the sum of the two parts you have
this part here and this part here you
glue them together and what you have is
just the sum of the parts we believe
that we can achieve some synergies and
get more than just the sum of the two
parts and the difference is instead of
just gluing things together adding them
together we're looking for interaction
between the two parts and in particular
we're looking for interaction where the
complementary techniques compensate for
each other's weaknesses so both of the
techniques I talked about proof planning
and symbolic execution through the small
food family of tools have their
trends but they also have the weaknesses
and we want to compensate for those
weaknesses by drawing upon the other
tool and we believe by doing that the
outcome will be larger than the
individual components on their own so
what do I mean by that well in terms of
symbolic execution and small food shapen
variants is something which is not well
suited or ship and variant discovery is
not well suited to the proof planning
approach the proof planning approach
relies quite heavily on syntax there's
less syntax involved in these shape
properties for our proof plans to be
able to constrain the search for propria
and variants on the proof planning side
we can deal with content small food
doesn't deal with content at all it's
it's this shape where is that the
content is it definitely a fee improving
activity so the proof planning as our a
powerful contribution to make there
there's also soundness so i should add
but the small food tools are sound okay
but if you were to extend the tools or
if we moved outside the small fruit
family of tools to other tools which we
treated just purely as Oracle's we could
use the information that they pass
across and not care about the sounders
because ultimately the proof planner
coupled with a proof checker will give
us a sign this guarantees so it kind of
liber8 seeeeee the kind of an
integrations we can go for we can talk
to things like shape analysis but we
could also talk too much more liberal
tools where there is no sign is proof
lying behind them and also extensibility
I mentioned this earlier if we want to
extend the small food family of tools
based around symbolic execution then we
have to come up with new inductive
lemmas precisely what the proof planning
framework has a proven track record in
so the executive summary are so the key
observation is that these
specifications can be broken down into
shape and content and we're exploiting
that we're using our shape analysis
tools for the shape we're using theorem
proving techniques for reasoning about
the content but we also believe that
there's interplay between these two our
reasoning activities so we're currently
adapting and our existing and extending
our existing proof plans for our use
within separation logic this is within
the is a plan our proof planner which is
developed to Edinburgh University and
which fits onto the Isabelle proof
development environment that's our proof
checker here we're building as I've said
upon the office shelf shape analysis
tools from pito herons group and also
the Cambridge group and our hypothesis
of the overall project is that the
proposed cooperation will increase proof
automation and thus promote more
comprehensive level of specification so
up until now people have been focusing
on shape properties we believe that we
can bring content into those and extend
those shape properties to have more
comprehensive specifications and
therefore more comprehensive guarantees
okay thank you questions
so I just wonder whether you have
experiences how easy it is for freshmen
to get acquainted to this approach so
how long do I need to train some guy
until he is able to do prove vs okay so
what we're aiming for is automatic proof
ok so the inputs are the program the
precondition and the post condition so
that's one question that we're not
addressing we're assuming that we've got
a contract a specification to work with
we're not assuming what our research
strategy is to go for full automation ok
so obviously in general that's
undecidable but we'll see how far we go
but it's a good point you're raising so
one of the outcomes from this you could
imagine is a tool which will give you
suggestions as to what a loop invariant
should be and invite the user to
instantiate parts of the loop invariant
of a frame axiom for example so we
wouldn't expect people to do low-level
proof we would typically be in well in
some of our previous work with this
proof critic mechanism we we developed
an interactive version so basically you
didn't know anything about the proof
until things went wrong and then you the
proof system started to have a dialogue
with the user it presented lemma schemas
and also presented a candidate
instantiation so the user could select
that lemma or generalization or they
could choose to instantiate dilemma
which was partially instantiated to
fully instantiate it themselves so what
we would believe is that we would raise
the level at which we could interface or
rather people could interface with our
proof development environment
do you have any sense of how what
percentage of the theorems that you want
to prove are provable automatically
right now what I remember hearing
numbers from way back when I Brielle was
working on the B method of something
like ninety percent or whatever and it
seemed like Colin this morning was
talking about numbers like that as well
as the do you have any sense of that and
is the remainder these things like
inductive proofs and discovering
invariants and things like that okay so
that's a good question so we don't have
a real feel for it yet in our previous
work with spark so the spark tools that
didn't address the problem of loop
invariant discovery so typically
safety-critical software doesn't have
many loops and they usually fairly
simple loops so but we were able to
increase basically we got eighty percent
of the loops that we encountered in the
in the case study data we were given to
buy praxis access to but we don't really
know how far we're going to go with this
so obviously one set of data is going to
be to look at just the literature a run
separation logic where people are doing
proofs by hand and interactively ensure
that these techniques can be used to
automate in that area but we're also
talking to industry so in terms of the
grand challenge for verified software
one part of that is is to develop links
with industry and there's people in the
UK we're talking to where we can get
access to two real case studies so there
we're not going to be too ambitious but
we will be focusing on maybe key areas
of say runtime operating systems things
like that is the kind of area we're
thinking about where you have a
scheduler involving queues and we could
maybe verify certain functional safety
properties that the ordering of
priorities in the queue are maintained
over time we feel we could get those
kinds of examples
so thank you again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>