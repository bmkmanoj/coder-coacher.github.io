<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GCC: Current Topics and Future Directions | Coder Coacher - Coaching Coders</title><meta content="GCC: Current Topics and Future Directions - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>GCC: Current Topics and Future Directions</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AfwNbUxbKr0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and I work here at Google as part of our
compiler team and this talk is just some
discussion of what's going on in the GCC
compiler these days with some notes in
particular on the work that we're doing
in Google all but I'm also going to be
covering work that's being done outside
of Google please feel free to interrupt
me anytime with questions or comments or
screams of horror and here we go I think
that everybody here knows what GCC is
but just in case it's the canoe compiler
compiles that list of languages that you
see listed up there the project was
started in 1987 by Richard Stallman the
founder of the Free Software Foundation
and the starter of the entire new
collection of code I've made a little
list of GCC releases over time you can
see that Richard released one point 0
back in 1987 and most recent release was
just a week and a half ago 4.1 point2 as
you can see from this little chart we
managed to do 42 releases in the first
five years and 9 releases in the next
seven years and five releases in the
next three years and since 2005 we've
basically managed two releases not
counting minor releases so as you can
see things are slowing down quite a bit
we like to think that's because we're
doing more testing and it's becoming
more stable over time there's still a
lot of changes going in but we've
changed the release process to be quite
a bit more arduous to get through than
it used to be I personally started
working on GCC in 1990 by the way with
GCC 1.34 and I haven't worked on it
exclusively in the years since but I
have spent most of my time working on
GCC and on the related tools
here's a list of changes since 1998 the
number of changes per year you can see
that it's a quite an active project
there's a lot of active contributors to
it you'll see that the number of changes
has dropped down in the last couple of
years that's mainly because we've
shifted to a model of doing major
development on branches on so from the
point of view of this count we'll do a
lot of development on a branch that will
come into the main line of GCC as a
single change and only get counted once
here but as you can see though an active
project a lot of work going on on it
people from a number of different
companies contributed contribute to GCC
not just Google but also major
contributors include Red Hat Susa which
is part of Novell IBM code sorcery
specifics and there's a lot of
individual contributors that
universities and the like I haven't
tried to break it down and of course we
have a number of volunteer contributors
and we were a google Summer of Code
project last year it will be again this
year so the first topic I wanted to talk
about there's been a recent major
rewrite of the internal data flow
framework within the compiler it's it's
actually still on going on and hasn't
been committed in two main line data
flow is the word that compiler people
use to track the association between
when a variable is defined and when a
variable is referenced the existing
implementation that we have in GCC was
written in 1987 by richard stallman on
academic compiler research has proceeded
quite a long time since that date and
we're revamping the infrastructure to be
much more accurate and also to run
faster on the result should be better
optimization in the long run as we are
able to update some of our old code
that's been around since the 80s and
replace it with
more modern code I have a little example
here to show what data flow is here's a
simple program you can see it assigns to
a couple variables uses a couple of
variables data flow tells us the
definitions and the references what
we're adding is the ability to as you'll
see on the numbers they are refer to the
line numbers so as you'll see on line 7
we know that that J refers to the
assignment made on line 2 and cannot
possibly refer to the assignment made
online for this is a very simple example
of the kind of knowledge that we're
going to have in much more complex
programs for the benefit of optimization
here's this will be in GCC 4.3 as you
saw 4.1 point2 was just released last
week 4.2 we expect to release on let's
see see end of februari oh I would hope
it would come out in April or May 4.2
we've already done a release branch for
4.2 and then this work is going into 4.3
here's some more work going into 4.3 um
we are improving the warnings about
invalid aliasing and I'll explain that
in a minute Sylvius who's sitting right
there has done this work now you have to
wave so everyone can see who you are
he's uh he works here at Google on the
compiler team and I wanted to mention
that Danny Berlin who is now at Google
is one of the major authors of the
aliasing code in GCC he started he's
worked on that since before he came to
Google last year now for our example
what alias aliasing means in the
compiler is when two different pointers
can refer to the same memory location
which of course is a very natural thing
to have happen it's how one typical user
pointers but
the interesting thing about aliasing is
that the language standards for C and
C++ specify that if you have a pointer
of a given type the standard says if you
try to use that pointer to refer to an
object of a different type then that
access is what compiler people call
undefined behavior undefined behavior in
the compiler means that the generated
code can do absolutely anything compiler
writers like to use hyperbole like it
could launch nuclear missiles it could
sell your house and practice what it
means is that the generated code may
jump to a random memory location and you
have absolutely no idea what's going to
happen next so what we have here in this
program is you'll see that there's a
pointer tint and a pointer to float and
we're going to cast the pointed end so
that it's a pointer to float and then
we're going to dereference that pointer
to float now that's an example of
undefined behavior because we are using
a float pointer to access an int
variable so would anybody in this room
who is not a compiler developer care to
predict what this function will return
that's correct
if you compile this with GCC today it
will return an uninitialized value it
will simply return whatever value
happens to be in the return register so
don't write your code like this a lot of
people do write their code like this
we've discovered because well because
before the language standard this code
might have been defined it might have
said something like return whatever the
bit Matt the bits 43 happen to look like
if you interpret them as a float that
might have been a valid interpretation
of this program most compilers
historically not recently but
historically would have done exactly
that they would have taken you know 00
11 and whatever that happens to be as a
float some very small denormalized
number and just return that but modern
compilers do not do that now there's a
reason they don't do that and the reason
is if the compiler knows that a pointer
to float cannot alias a pointer to end
that is if a pointer to float cannot
point to the same memory location as a
pointer damned that means that the
compiler can rearrange loads and stores
of float pointers without regard to int
pointers and that permits the compiler
to generate more efficient code it
permits the compiler to reschedule the
code so that the instructions run you
know in some order that's particularly
efficient for the machine at hand all of
these things are increasingly important
with modern processors the ability that
is the ability to reschedule
instructions is very important with
modern processors so compiler writers
take advantage of the leeway that the
language standard has given us to say oh
this is undefined behavior you can't
possibly mean give me you know the
bitmask of three interpreted as a float
I don't know what you mean but I'm just
going to pretend give me nothing so
since real code does actually work this
way especially old code we found that
it's desirable to warn
people when they're doing this GCC has
not in the past implemented a warning
but Silvius is implemented a warning
here's an example of what it would say
for this particular code I'll just read
that bike Lee type punning may break
strict aliasing rules object star F of
main type float is referenced at or
around blind five and maybe alias to
object I of main type and which is
referenced a tour around line one so
hopefully programmers will be able to
interpret this to say well something's
wrong here and they will fix their code
by the way the correct way to write this
code it would be to use a union the
language standard doesn't actually
support using a union but on GCC and all
other compilers do in fact support that
so that there is a way to do this kind
of reinterpret reinterpretation of the
bitmask value or the other correct way
to write this code of course would be to
rewrite it since it doesn't really make
any sense but any questions about
aliasing very good so it seems like a
pretty simple change to add this morning
but Olivia's worked on it for a few
months now it's actually pretty
complicated you'd be surprised the next
one is a somewhat similar case which
I've been working on this is another
example of compiler undefined behavior
is that if you get an overflow of a
signed integer value the language
standard says that that is undefined
behavior it doesn't say it's going to
wrap around the way you might think
because you remember how to's complement
numbers behave it says absolutely
anything could happen and the compiler
takes advantage of that for example this
might be a simple loop which attempts to
test how many bits there are in an int
as you can see it simply adds it doubles
the int and it keeps looping as long as
it is positive because as we all know
when you double eventually if you keep
doubling a positive number you're going
to wind up with the most negative number
that's what's going to happen
actus so here we see an example of
signed overflow because you know that
that overflow that I mean that is
overflow when it overflows past a
positive number to become negative
that's signed overflow and that's
undefined behavior again so if you
compile this with the current compiler
does anyone care to predict what's going
to happen with this loop somebody must
have a guess you're on the compiler team
GCC will happily turn this into an
infinite loop yes yes turning this into
an infinite loop is a brand new and
exciting feature in GCC once again you
might sort of start to think to yourself
I don't really want this to happen but
there is a reason for this again and the
reason is when GCC knows when it knows
that your loop indexes cannot overflow
it can do a much better job of unrolling
your loop and of determining the number
of iterations that your loop will
actually execute which also helped with
unrolling helps with inlining adding
this feature you know on various
standard benchmarks gives us
significantly improved behavior very few
people write this sort of loop but of
course some people do so when we roll
this out in the GCC 4.2 release
snapshots some people tried running it
and they said you know wow my program
really takes a long time
this GCC release is not very good so I
have implemented warnings which will
become part of GCC 4.2 two new options
one option is a dash f strict overflow
that's a new option which tells GCC yes
you may assume that signed overflow is
undefined behavior and as you can see
turn on at o2 and the other more
interesting option is now there's a
warning w strict overflow you confessed
I've had to make a range of levels
because there's a number of very
innocuous optimizations with GCC makes
which assume that sign overflow is
undefined I didn't I forgot to put in an
example of it but an example of that
would be something like optimizing I
times 10 / 5 into I times to that
optimization can only be done if you
assume that signed overflow is undefined
because I times ten itself might
overflow and my turning to a negative
number we've done that optimization for
a long time we've only done this loop
optimization as of GCC 4.2 so with this
new option you will get a warning which
will basically say GCC assumes signed
overflow is undefined when optimizing I
greater than 0 to 1
moving on we've been working on a faster
preprocessor a while back in GCC
three-point oh we integrated the
preprocessor and the compiler proper
that is we used to have two separate
programs one which was called cccp which
was the c preprocessor and did not refer
to any former country and the other was
the compiler itself which took the
preprocessed code and generated assembly
code the new preprocessor was faster
when you were doing an ordinary compile
because instead of being a text to text
transformation it actually tokenized the
and you know I tokenized the input into
a series of tokens which the compiler
could then processed directly however
the new preprocessor was slower when
pre-processing and mostly everybody was
fine with that because not very many
people ran the preprocessor by itself
but more recently programs like c cash
and CC separate the two steps what C
cash does is it runs the preprocessor
and then cake builds essentially a hash
table from the preprocessed input to to
generate an object file and it just if
you if it's already compiled that we
process the input and it returns the
object file directly without running the
compiler with us it's a compiler speed
up mechanism for projects which have a
lot of header files in which modifying
one header file doesn't necessarily
change the generated code this is pretty
characteristic of large projects written
in C on disk CC is a similar project by
the way these are not associated with
GCC per se although they're written to
be used with GCC disk CC is a program
which distributes compilation across a
bunch of machines it again does the
pre-processing on the local machine and
then it picks up the preprocessed codes
and sends it to one of a set of servers
where the actual compilation is done so
if you are lucky enough to have you know
or 20 or two thousand machines to run
your compilation then DCC will let you
run parallel makes much much faster as
the code is shipped out but the
preprocessor is slower we've sped it up
in part by not tokenizing by going back
to the way used to work when when you
give it a special option and that was
implemented by oli wild here at Google
and I also do is mostly done by only
while they also did some work on it
myself and the next thing I wanted to
talk about was a bunch of changes we're
making for the next update to the c++
standard I'm sure that many of you are
still just getting used to all the
features the last c++ standard but
there's another one coming out the
clawing at c plus plus 0x in the hope
that it's done by 2009 but it's just
talking to laurens here who's actually
on the committee and looks like it's
going to be more like c++ 0a or 0 b it's
just uh there's a apparently quite a
long lead time in getting these things
actually approved I don't know how many
of you remember the the ISO the ANSI and
I so C standardization process but I
remember that took something like three
years after it was finally finished to
finally get approved and turned into an
official standard despite that we
already support options we have we don't
support most of the features but we do
have some features already implemented
you can select C++ ZeroAccess standard
you can there's a warning option which
says whether or not your code is
compatible with C++ 0 X is defined so
far several new keywords are being added
so the main effect of the warning is to
say you know your variable name is going
to be a keyword when c plus plus 0x
comes out we've implemented static
assert which is pretty much what it
sounds like it's a function which checks
at
all time that some condition is true
we've implemented at a very exciting
feature in the past here you had to have
a space so that space is going to be
optional and C++ C all right so this
turns out to to change the meaning of
some valid programs which involve the
right shift operator so that's also
warned about if you give the warning if
you happen to be so peculiar as to where
I one of the programs which would be
changed we also have an implementation
of very attic templates in which you can
write a template with a being a variable
number of parameters I'm not quite sure
why that's useful actually but I'm sure
there are some good uses for it I'll
part of doing more good compilation a
compile-time I guess I mean more of your
computation at compile time this work
hasn't been done in Google it's mostly
been done by Doug Gregor at the
University of Indiana and a number of
other people have contributed and we
have three members of the
standardization committee here at Google
whose names right there and Lawrence is
sitting up front
any questions about what's coming down
the pike here you know parts of it some
that's pretty scary you thought that C++
was a complicated language before it's
just another new layer of complexity is
being put into it now something that's a
little more in the future this is not
going to be in 4.3 but it's going to be
rolling out I hope in 4.4 we're going to
see this is whole program optimization
this is the feature that several
compilers several non-free compilers
have had for a few years now like IBM's
xlc and intel's IC c compiler and though
i think also path scale has this feature
basically i'm going to describe what
we're going to be doing as part of GCC
at least when you compile code it's
going to compile not just into object
code but also into an intermediate
representation which will be stored in
the object file itself if you use the
appropriate options and so forth then at
link time instead of simply invoking the
linker with the object files the
compiler will run you will grab the
intermediary or intermediate
representation add the object files and
it will proceed to attempt to optimize
the whole program at once and I've put
some examples up here of things that we
can do when we do that the most obvious
one is that you can write your function
in one file and then have it in lined
into a function right into another foot
written in another file the only way you
can do that today is to put it in a
header file which of course is not
always desirable it breaks your
modularity but with this with this
feature will be able to do that in
lining across photo files which is also
convenient for if you're using programs
written in three different places like
some library that's distributed will be
able to with with whole program
optimization will be able to in many
more cases know every single caller for
a function
which generally is not the case today
we'll be able to take advantage of
visibility attributes to say we now know
everybody who could call this function
and that gives us a number of advantages
we can actually change the calling
convention for that function to pass me
or more arguments and registers or fewer
arguments and registers that caught that
we can say this function no longer has
disabled its registers that can be a big
help for a small function it can make a
huge difference for some types of code
we can similarly we can actually clone
the function we can so you can say
looking across the whole program you
know for some reason this program this
function is called a hundred times with
the first parameter of 10 so let's just
make a copy of it let's say now we no
longer have to pass that first parameter
let's make that first parameter can
let's do constant folding through the
function will get a more efficient
version of the function will be called
more efficiently we can also do much
improved alias analysis when we can see
the implementation of the function we
can say oh you know originally I
dysfunction might have changed these
global variables now that I can actually
see the value I know that it does not
change these global variables I know
that it does not be referenced these
pointers I no longer have to save
everything into memory before I call the
function so alias analysis which I
talked about earlier might seem like a
somewhat abstruse topic but it's
actually very key for a wide range of
optimizations within the compiler this
project within GCC is called the lto
project I forgot to write that up there
which stands for the length time
optimizer I've written the names of a
number of the people who are working on
it as you can see we've got a couple of
people at Google working on it as well
this is a big project it's not part of
it of course is the simple matter of
writing out that intermediate
representation but we also have to the
traditional problem with whole program
optimization is that you run your
compiler it runs around to all the
object files it sucks in all the
intermediate representation for your
program
the compiler then uses up 4 gigabytes of
memory and crashes because it can't have
a look any more space so in order to
make this work it's very important to
optimize the memory usage of the
compiler and to compact the intermediate
representation and that's what that's
what people like us and rinaldi are
working on in order to UM just making
GCC more memory efficient this is going
to be if we can make this work and this
is still obviously experimental if we
can make this work I think it will be a
very huge step forward in optimization
for real programs and as I say we hope
the first implementation would be in 4.4
although we'll have to see if we
continue our current release schedule
4.4 won't be out for another year at
least so let's give us a pretty good
chance any questions about this
yeah well ddb will know where it is
because the debugging information will
point you right back to the to the same
source code minds that had before but
will it be a mangled a yes it will have
to will certainly be a mangled name gdp
will have to be taught let that mangled
name actually means we don't currently
have any mangling scheme which can
represent this it will be making
something up for it this is actually my
last slide these are on additional
projects which people are working on on
using GCC as a just-in-time compiler for
virtual machines this is as I'm sure
many of you know virtual machines like
for example the java virtual machine
which executes java bytecode the most
efficient virtual machines these days
actually say to themselves you know I'll
look I'm about to execute this function
for the 100th time instead of
interpreting this bytecode I'm going to
compile it instead and simply execute
the machine code every subsequent time
that I run this function Diego is
working on the steps required to make
GCC be a compiler which can be used for
virtual machines built out of fully free
software and similarly the CIL is a see
intermediate language which I believe
was defined a Microsoft roberto acosta
is working on having GCC generate that
intermediate language these as I say are
longer range projects
and those are the topics I had to talk
about today I think hope this has given
you an overview of what's going on in
the compiler community it's a very
active community and we always welcome
people who are interested in compilers
or just interested in anything really to
help out the website which I probably
should have put up here as GCC GNU org I
should also add as I say we have a
compiler team here at Google of some
nine people I guess we don't have our
own private version of DCC we do have
some local patches which we're
continuing to try to contribute back to
the main branch of GCC but mostly we're
just a active member of the wider GCC
community and I'll take questions on any
topic yes a question about profile
guided optimization good question GCC
has had profile guided optimization for
quite a long time although I'm not sure
how many people are aware of it you
compile your code with the dash f
profile generate option and you know
your optimization options or whatever
then you run the code several times
using some representative data set and
it will write out a I think it's a G
cavo out file then you compile your
right on actually a set of those files
then you compile your program again with
the dash f profile use option and it
will this time it will look at the
profile information and it will use it
to optimize the code the kinds of
profiling information which it does is
on branch prediction it will decide it
will record which way branches go which
will let it rearranged the code to get
better cash locality it will also do
value prediction which you will use for
some very specific cases for example for
calls to mem copy
it will predict it will record the
values that are passed as the size of
the buffer to be copied and if that if
it turns out to be helpful you know if
some more than fifty percent of the
calls at some particular call sign are
always with the same constant third
value then it will say it will add in a
condition you know if length is this
then it will do the copy in line using
all the knowledge it has about the
alignment instead of calling out to the
library function and you're right I
didn't put it on the slide that there
are improvements they are being done by
aldi Hernandez and and yon who become
and they are Inc they are working to
increase the number of cases which we
take advantage of profile generation
also swing Bay Park here at Google has
been working to make the profile
feedback more flexible
the question is whether you have to use
exactly the same binaries when you when
you compile it again and unfortunately
the answer is yes you do and yes that
does make it more difficult to use so
it's very much something that you might
do at the very last stage of a release
when you've got your code finally drill
down that's the time when you might
start using the profiling feedback of
course then you've changed your code so
then you have to test it again these are
parts of the reasons why it's perhaps
not as popular as it could be good it
can be quite effective I would like to
make it more flexible so that that kind
of approach would work more effectively
but we don't there's nobody working on
that in that area right at the moment
I'd in front
how does which compiler how do
precompiled headers improve performance
precompiled headers improve compilation
time so precompiled headers is a feature
that GCC has had since i think around
the 3.4 release it was implemented by
Jeff Keating an apple with precompiled
headers you can basically use you can
compile your dot H files essentially and
then you're permitted to you can only
use one pre-compiled header /
compilation but it can be a very
effective way of cutting your
compilation time down by quite a lot it
was developed at Apple because Apple has
this vast set of header files many of
which are included by every single
application so if you compile you know
all the local header files or something
into one precompiled header it can make
your compile time you know go down forty
percent or something like that so it's
it's a very significant benefit on if
you know if you fit the profile of you
know you only need one pre compound
header most of your projects include the
same header files yeah there are no
current changes planned for that Dean in
the back are there any plans for auto
vectorization why yes there are the
Haifa lab of IBM has been working on
auto vectorization for several years now
it's actually implemented if you use the
dash F tree vectorize option your code
will auto vectorize if you're very very
lucky the I've always been a little bit
skeptical about auto vectorization
because it works mainly for scientific
code scientific code and I don't
personally happen to be a scientist
budem if you do write code which is very
loop heavy especially fortran code let's
say and if your alias analysis is very
good this is a case where alias analysis
is absolutely key if your alias analysis
can prove that your assignment to some
element of an array is different from
your uses of some element of some other
array which is something that's pretty
easy to prove in fortran but it's pretty
hard to prove in c
where you do not know where pointers
point2 if you can prove those cases than
the auto vectorization does work is
useful for things like s señor sse2 on
intel chips or altivec on powerpc chips
it will actually take your loops and
just without any special effort on your
part it will turn them into loops that
use the sim d instructions which have
been added to modern processors so as I
say it works for fairly very special
cases which mostly happen to be Fortran
programs you can write C programs which
auto vectorization works for but most
people do not write those C programs the
question is are there other things going
on to try to speed up GCC's compilation
time yes I mentioned the lto project the
whole program optimization project in
order to make that work we need to speed
up GCC's compilation time we need to
speed it up in general so that it will
speed up for the particular case of
whole program optimization and the
approaches that we're using to it using
to speed up optimization time are
primarily are in the area of changing
the internal data structures it turns
out that once you get beyond trivial
programs you can predict GCC's
compilation time by measuring how much
memory it uses during the compilation so
the way to speed it up is to make it
used less memory and also to make that
memory be more cash friendly that is not
to point all over the place so efforts
are being made in both of those
directions I don't know how many non
compiler developers know this but GCC
actually has a garbage collector inside
it which is part of what it does when
you're compiling a very large program
you'll never see this unless you use the
options which say you know tell me about
this well you're compiling a large
program DC will actually run in garbage
collector on its own internal memory
structures this is this is a convenient
way to make it easy to write Optimus new
optimization passes but it
truly terrible effects on compilation
time of large programs so a lot of not a
lot but a significant amount of the
efforts of speed up GCC are also to take
chunks of memory out of the garbage
collector and into you know memory pools
or various other memory objects that we
have within the compiler I mean for
those of you who are not compiler
developers you may you probably went to
your compiler classes in school or or
not but if you did then they talk to you
about parsing and code generation it
turns out that actual compiler work on a
real compiler has nothing to do with
those things a lot of compiler work has
to do with managing your data structures
it's kind of like any other large
program in managing your data structures
and learning how to traverse them
rapidly and spending as little time as
possible implementing your optimizations
it turns out that generating highly
optimal code is much simpler than people
think it is it's just that when you
actually generate perfectly optimal code
your compiler takes hours to run and
users find that unacceptable and they
never turn on your options and it's very
disappointing so you have to have to
learn how to implement your option your
optimizations so that they will run in
an amount of time which people are
willing to tolerate
Wow
so well at the comment is that el tio is
going to take a long time and is
particularly is going to be very cereal
and not take advantage of multicores and
the question is is there any plans to
cash the object for how information in
some way the answer is we haven't gotten
that far my hope which is not being
realized right now but there's still
time to change them I hope is a it'll be
possible to simply a map the object file
into memory and not do anything else it
will just be ready for use that's not
the approach we're taking right now but
they maybe do purchase well if I have my
way that'll be the approach we move
toward in the future I should also add
that Ken's a tech who's spearheading the
lto project is does have plans on paper
for Kura lysing it more than you might
think to you can you can actually do
things like say you know oh gosh
dysfunctions in lined in these 20
different locations and then just
paralyze the effort of doing the actual
inlining and then come together at once
so yeah that is as you say multi-core
architectures are the wave of the future
and the compiler does need to learn how
to take advantage of them he's actually
thinking of paralyzing it by shipping it
out to different machines this is not
going to be in 4.4 does JCC collaborate
with LOV my are you from Apple ah that's
the I mean well the short answer is no
we don't the longer answer is we do talk
to chris chris lattner quite a lot chris
lattner is the lead developer of lvm at
Apple and as you know there are several
other developers of lv emma as well of
course we did discuss the possibility of
actually incorporating llvm into GCC at
one point but technically it seemed
doable but the legal issues turned out
to be a problem llvm is owned by the
university of illinois under a
reasonably generous license
GCC of course is under the new public
license the licenses were not compatible
we tried to persuade Chris to get Apple
and the University to agree on some kind
of license which we could use to
incorporate the code but that wind up
not happening in part I'm sure there
were legal difficulties I have no
understanding of and in part I think
that Chris felt that the GCC community
was not quite as welcoming of llvm is he
hoped it would be i mean i like i like
chris lattner and and he's made
excellent suggestions for GCC over the
years but at the moment we don't have
any any plans to incorporate it directly
we may we may there's been talk about
having GCC generate the llvm by code
representation to feed into the LLVM
compiler which is one feature of lvm I
don't know if these things are going to
happen but it's a good question and I'd
like to see more cooperation I just
can't say whether it's going to happen
on Apple has been pulling away from GCC
to some extent they've historically been
a strong GCC contributor they're moving
much more strongly toward lvm these days
we'll whole program optimization support
libraries and the answer is yes it
absolutely will the question is if
there's a security hole in lipsy you
essentially have to realign call your
binaries and the answer is yes if you've
chosen to take advantage of whole
program magnetization and then you find
some some such bud then yes you will in
fact have to recompile your binary so
that's one reason you might not want to
do it for lipsy depends on how
performance sensitive you are the
question is with the improved aliasing
support are we going to bringing more
static analysis into the GCC compiler
that is something I would very much like
to see it's not something that's being
actively worked on by anybody as far as
I know let me take that back there's a
group called global GCC in Europe which
is being funded by a coalition of some
European governments who are working on
improving GCC static analysis
unfortunately they're taking an approach
which I'm not sure is ever going to get
back into the main line of GCC although
it may become useful as a tool by itself
they're taking an approach which is push
it's a compilation time up enormously to
the point where most people are not
going to be willing to use it for those
who don't know static analysis tools are
essentially tools to to warn about you
know questionable cases in your program
that's the primary use of them to say
you know oh well you're doing something
here which looks like it might be bad
programming style maybe you know what
you're doing but maybe not so the
compiler obviously has a great deal of
knowledge that can be brought to bear on
on issues like that then but there's
nothing going on other than global GCC
that I know of
the ending
better start singing every board
the question is where the CIL has the
information needed to do better static
analysis and my answer is I have no idea
anybody know nobody knows
any other question
I think that's it well thank you very
much very good trust</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>