<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AQC 2016 - Parity Adiabatic Quantum Computing | Coder Coacher - Coaching Coders</title><meta content="AQC 2016 - Parity Adiabatic Quantum Computing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AQC 2016 - Parity Adiabatic Quantum Computing</b></h2><h5 class="post__date">2016-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HTbRkvzFaY4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">start with a talk by Wolfgang luckner
followed by Tammy mal Bosch followed by
iDEN Roy and let's get this started
Wolfgang on the floor is yours okay
first of all let me thank the organizers
for this great opportunity at the talk
here a perfect place I always love to
come here what I would like to present
is the parity adiabatic quantum
computing scheme which we actually
actually introduced last year in theory
this was work done together with Philip
and Peter Sola and today I would
actually like to present what happened
in the last year we have like a list of
new exciting developments and then his
talk I will basically start by giving a
very short introduction on this parity
scheme what it means and what the
opportunities are then I would like to
discuss some encoding aspects so one way
to look at the scheme is to look at it
from from encoding perspective so what
what new opportunities do we have for
encoding and then there's also aspect
about efficiency in this in this talk
which will be then also covered by Tamim
in the talk after that another point of
view for the encoding is the
implementation aspect so I hope I
convinced can convince you that this
encoding not just gives us new
opportunities on what we can embed but
also on the implementation level and I
think these two aspects of the encoding
and implementation should not be treated
completely independently but they should
really go hand-in-hand
and as the last part I would also like
to talk about application aspects
means things that we can now do in this
parity scheme for for applications and
that the example will be machine
learning so let me quickly introduce the
parity scheme the the Hamiltonian that
we have seen now like several times at
this conference that we usually look at
is a spin class Hamiltonian so we have a
t transverse field and we have our spin
class a problem and the the paradigm
here is that the problem is encoded in
interactions so here I've taken the
example for two body but this can be
free body for body and so on but sort of
say what we have to program is our
interaction matrix now in the parity
scheme we are looking at a different
Hamiltonian and I would sort of say as a
teaser just a compare the two the first
thing that we observe about this
Hamiltonian is that it's larger so what
we the price that we pay is that we have
to introduce more qubits on the other
hand we gain and I think we gain a lot
one thing is that this is not a spinning
class Hamiltonian but this is a lattice
gauge Hamiltonian so this means we have
constraints the parity constraints and
these are the interactions and these
interactions are are constant what we
have to program is a local field so the
strategy of the scheme is to separate
interactions and programming elements
and put everything into the local fields
so this is intended as a teaser and then
in the next few slides I will show you
about this exactly means but as a
summary the optimization problem is
fully defined by local fields the
interactions are all nearest neighbors
so they are really local they are
problem independent and they don't need
to be fine-tuned so they can have they
can have errors this can be realized in
various cubed platforms and in the
implementation part I will outline this
a bit more I think this is a great
opportunity to also bring other
communities from quantum simulation into
this field another important fact here
is that the K local K locality in the
logical problem is abstracted so this
means these the qubits that we introduce
they can also represent free body or for
body interactions I will outline this
also in detail and then there is some
error tolerance for spin flips which can
then be corrected by a classical
algorithm so the main idea is this and I
would like to illustrate this for two
body terms but keep in mind this can
also be free body or four body terms but
let me just give you the outline so the
idea is to take our fully connected a
spring model and now represent it by the
dual variables so instead of looking at
the individual spins we would like to
represent the whole system by spins that
actually represents a pairs of spins or
pair correlations so if two spins are up
then the physical spin is up if they are
looking in different directions its down
and if both are up its up and now what I
want to do is I want to represent the
whole system by these new variables and
for example if I have free spins which
is down down up then the new spins will
be up down down and now if I if I look
at this so here in this is basically
just a product of the two which means if
I have a Hamiltonian that looks like
this
no I have an interaction matrix times
the product then in the new variables
this simply becomes a sum over N squared
elements and what was previously the
interaction matrix is now suddenly a
local field so it's a different physical
thing
but now if we count the number of
degrees of freedom we have to many many
degrees of freedom so here we have K
elements and here we have K elements so
k is N squared but here we have only n
degrees of freedom because we have n
spins while here we really have n
squared degrees of freedom which means
we have to get rid of them and we have
to get rid of K minus n of the
additional degrees of freedom so that's
basically all that we have to do and now
we could ask us as well what what are
these constraints where do the new
degrees of freedom come from these new
degrees of degrees of freedom come from
configurations which have no
correspondence in the original model so
if we take the example of my free spins
again I can make a translation table now
so in my original spins will be 1 2 3
and my new spins they would always
represent pairs now I can make a list
and maybe at some point I want to have a
1 2 is 1 so 1 2 is up 1 3 is up so it's
also up but to free is down and there
there is not possible to arrange the
original spins like this so this is an
unphysical solution of the new spins and
this I have to get rid of and the way I
can get rid of this is by simply
translating this into a Hamiltonian term
again so here's my logical problem and
then actions translates this into my
physical qubits so my my pairs and now I
give them a free body term know so I say
1 3 1 2 2 3 gets a free body term this
means I rule out all configurations that
have an even number of spin down now
this rule is true for any closed loop in
in any spin model so if I have a loop of
4 I would have a 4 applicator for and
this will give me a 4 body turn so this
is sort of say the general concept and
now I can look at
what can I actually encode with this so
as I said this example was now built on
the two body now let's look at the two
body so imagine we have now a fully
connected system so all-to-all then i
can ask yourself which of the
constraints do I have to select no so I
have to make a selection so I have
enormous number of closed tubes but I
only need K minus n of them and it turns
out that there is only one particular
solution that actually allows one to
make all interactions than local so we
can get rid of all local interactions
and the basic building block always
looks like this so I go like one to the
right to left free to the right to left
back and this is sort of say the pattern
which which then goes through the whole
system and the closed loop that I've
drawn here would then represent this
block head for example and if this I can
make represent a fully connected spin
glass in in 2d by going to dual
variables plus constraints and what
comes out is then a triangle and the
Hamiltonian that I had in my original
model also had now the Sigma X term I
want to do quantum annealing now you
might say well what you did now was a
classical transformation so what did you
do with the Sigma X well we just sneaked
it in again into the new variables so we
just added a Sigma X term in our
physical new variables so this
Hamiltonian corresponds to this triangle
here because the only requirement is
that the heirs of orthogonal and we
don't really need to transform the
original Sigma X we could transform it
but we don't need to transform it and if
we do it like this then we have only
local terms so we have no multi-party
Sigma X or anything we program our
problem with local fields and we have
constraints which are all local and now
I would like to show you that this
particular set up actually allows you
just to encode like to body terms or to
all but actually an enormous number of
different models so for example if I
have auto all free body and then my my
new cubits represents the product of
three original spins because I have now
three body terms and there have more
possibilities but it turns out that if I
want to implement a full free body then
I need to go to three dimensions so this
is not not very very convenient but
later I will show you that we can
actually also do this in 2d if we have
less than than also all connectivity so
until now this is more or less what I
presented last time in theory now I
would like to show some some additional
aspects which I think make this very
interesting let's look at other special
cases for example the bipartite graph if
you have a bipartite graph which means
we have two layers we have some some
some local field which I represent now
as a as a bias with as an interaction
then this translates in the in the
parity scheme into a rectangle so I have
exactly the same the same Hamiltonian as
in the two body free body the only thing
that I changed is the geometry of my of
my block heads and the bipartite graph
for example becomes a rectangle but it's
also interesting here is that the the
local field terms so in the original
model have like local fields and
interactions in the new model they all
become local fields so they are now on
the same footing and this will be
interesting then for the application
point of view now if I want I have now a
bipartite but maybe I want to make a
deeper net no so maybe I want to have
more layers then this actually becomes
still a rectangle but in a staircase
geometry so what we see here is this
this is the first layer and then the
second layer would be interaction
between B
and see so I put this down here and then
here I have some connecting in
connecting plug heads which actually
represent closed loops that go through
to two layers so I can just put them
below and then the next layer will be
between Z and D so this would be here
and so on so this becomes like a like a
staircase and interestingly we can of
course also feel the the square again
and if we do this we get additional
interactions between additional layers
we can also make a think of what happens
if we start now with a cargo mellitus
for example this becomes a tripartite
graph in the in the logical problem and
so on so there is like many graphs that
we can think of which have some some
interesting representation but I really
want to emphasize is this work here this
is from the Oxford group around Simon
Benjamin they looked at our parity
architecture in a very general way and
they formalized it also in a very
general way and they have a list of
interesting encoding opportunities there
the first one is I can take the alt or
to body and just add K locals to it very
easily so all I have to do is add some
connections inside the graphs so I can
for example here this is one original
Burkett if I add interaction between
these two guys then I have four body
terms in there additional four body
terms one can also make six body terms
of rebodied terms and so on another very
interesting part about this paper is how
to make arbitrary K locus out of three
bodies so I can take our our
architecture and add on the sides this
cascades of rebodied terms and this
allows me to introduce higher and higher
K locals so I can make I can select any
number like 1 2 3 4 5 and
I can generate the the interaction one
two three four five by making a cascade
of Freebody terms this also gives me
then the the four body and the Freebody
on top of this and it's the last point
from this paper that I also want to
mention and this is also something that
I like very much is the rerouting so if
I have less than all-to-all connectivity
and I want to select particular
interactions then what they found out is
that one can actually reroute the
interactions so what does this mean what
we've seen about what we see here is the
the triangle that we have before and the
lines that we see so that the colored
lines they are something like the
original qubits so this would be in the
in the squid or in this flux qubit
picture this will be the lines that we
have to draw but now here they are sort
of say an abstract object and because
they are an abstract object we can
actually reroute them so for example by
changing the interaction on this block
eight from four bodies from four for
body two to three body plus one six body
we can actually reroute these lines this
means we can select where they actually
hit each other by just changing local
fields so just by the software we don't
have to really unhard we're level a
change where these lines go and the
example that they give here is this so
this would be a graph is more or less
random but so they said well let's say
we want some connections that are fully
connected with 100% connectivity some
nodes that have 50 twenty five and
twelve and so on so this would be this
graph and this translates then to this
rerouting scheme so this is all in 2d
and has has less than all-to-all but it
gives us a very nice flexibility in
which qubits interact with which other
qubits and it also allows us to we are
very flexible in which free body in for
body terms we can add here because
of the rerouting so this I think is a
very very interesting paper now as a
last encoding aspect I would like to
talk a bit about efficiency so there is
the error correcting code by preska and
past offski this is a classical error
correction which which corrects for for
spin flip uncorrelated spin flips error
that are due at the readout or it at the
very end of my of my annealing what this
means is or what they what they use here
is that for the construction of our of
our lattice we actually used some of the
closed loops but they are still all the
other closed loops know for example one
two two four one four one two is still
there and this allows me to do a very
clever readout so if I want to know the
value of one two I can either just read
out one two or I can read out every
closed loop that contains one two except
for one - so if I know for example what
2 4 and 1/4 is I know what one two must
be because of the parity constraint and
from this I have an exponential number
of possibilities to read out one two and
they do is even more cleverly so not
just a majority vote on this but
actually a belief propagation on this
and if they do this for uncorrelated
spin errors then this gives an
exponential suppression impression of
these errors now Tommen who will talk
after me they looked at this from a
Monte Carlo a point of view and the the
result so they used this error
correction they did the Monte Carlo and
the result is quite bad so if you sort
of say look at the graph in this looks
actually very bad and
so what they looked at in particular was
this protocol so you have the two terms
one is one term which contains the
constraints and the local field and one
term that contains the Sigma X and to
compare this to the same problems with a
minor embedding and at a relatively
large temperature and the conclusion was
that that minor embedding always
outperforms the LX so that the parity
problem so at this point so if you see
this graph you probably would go back a
bit
but fortunately so Matias troilus group
of Maori currencies is also here we were
also looking at this and one can
actually solve this problem and the the
way to do this is or what we did now was
to to add this to change the schedules a
little bit so we have three terms here
one for the local field and one for the
constraints and the constraints actually
can contain two parts okay two means and
by doing this for small systems we get
up to a hundred percent for 100 cubits
logical qubits so five thousand five
thousand physical qubits up to 92
percent for max occurs problem compared
to the unencoded problem an embedded
problem which i think is really
fantastic there's no real optimizations
done yet so mario brought some genetic
algorithm to actually improve schedules
and so on so this is just guessing some
of some constraints and we get a
fantastic result so I think this is very
encouraging now let me come to
implementation aspect so I think this
encoding aspects are already very
encouraging but in combination with
implementation it's even more
encouraging let's let's think first
about the flux qubit so why buy a flux
it's so fantastic for annealing the
reason is at least that's what I believe
that you can elongate the qubits which
means in the condensed matter sense they
are not really nearest neighbors the
neighbor interactions more but they are
really so say long-range interactions in
some sense or next neighbor interactions
so you have like these long qubits and
then you have the couplers and then with
the minor embedding you can go on and on
now in the parity scheme you don't need
any long-range interactions so you
really only need to interact with your
local neighbors and all interactions can
be the same and this opens the field for
all quantum simulation qubit platforms
and this is something that I really like
because we can actually get a whole
different communities into the annealing
business and these are some examples of
people that we are collaborating with so
these are all setups which have so to
say this square lattice structure and
which can make the four body terms just
as an example maybe due to the time I
will make this a bit shorter with
repaired atoms so there's a whole
community on Richburg atoms marks othman
in in medicine wisconsin with whom we
are collaborating here has a very nice
experiment which combines riparian
cesium atoms and in our group reconned
and alex they worked out the scheme how
to do the parity scheme in this in this
setup and this is a very natural setup
they have this basically already running
so I think this could be very
interesting to do some tests but real
experiments already in these in these
systems other implementations include
transplants so here we have a paper how
we would do this with transplants this
is probably not optimal from the number
of of until a qubits that we need so but
it has some advantages and lifetimes and
then there's also flux qubits by Poul
that we heard yesterday and how to do
the four body terms with flux qubits
with Jeff and Phillip who is also here
this I think is a very nice or a very
natural setup what they looked at this
fixed frequency rotating frame qubits
there was the talk also yesterday in the
lebowski and what they have is like in
this scheme here - couple qubits and the
Hamiltonian that they can get out is
contains xx YY CC X and C so all we need
and this this is here worked out for two
qubits but what I can also do is they
can add additional qubits and make n
wake up loss so these are not anybody
calculus but anyway Cal Plus which means
you have n pair interaction so we have
like five cubits and you can get an all
pair interactions simultaneously and you
get simultaneously X and C direction and
this means with a five-way coupler you
can immediately make the the four body
block yet so you declare one person on
Cilla and the rest is two logical qubits
and from this with the five way coppers
you can immediately build the parity
scheme and what I would like to
emphasize here is that we also have 2 xx
terms and they have the same physics no
so they they have the same constraints
which means we have N squared non
stochastic terms which we can also a
program so I want to make an exclamation
mark here now as last point applications
so can you also think of applications
very directly profit from the parity
scheme
let's think about the restricted
Boltzmann machine
we heard two talks yesterday by Ames and
dyf on the restricted Boltzmann machine
so I can make this very quick in the
restricted Boltzmann machine we have the
bipartite layer we have already seen
this has a very natural implementation
and in the unsupervised learning what
learning means is that we maximize this
marginal probability for the visible
layer and now the suggestion by by many
groups oh I hope I cited everybody so
but there were two talks yesterday which
basically said well in the in the Hinton
update rule we look at the gradient of
our log likelihood and this then gives
us two terms one which is simple and one
that is hard hard in the sense that we
have to sample it and this would be so
to say these two paradigms of tf1 where
we have the optimization one we have the
sampling and in this case we would then
do the same thing on the annealing and
update our weights now what I would like
to do is go back one step to the maximum
likelihood this is an optimization
problem but the problem is it is an
optimization problem where I have to
update the weights which are
interactions enter biases and this is
very unnatural in physical systems that
we optimize for interactions actually if
we have sort of say the spin glass
picture what we would have to do we
would have to make the interaction
somehow dynamical now in the parity
scheme the interactions and the biases
are local fields so this means can we
just make the local fields dynamical
variables so I replace the local field
by an additional qubit which is now a
variable which interacts with with Sigma
C and then I have to give the neurons
also some dynamics and if I do this
so here I have an illustration of this
so this is my my restrictive Boltzmann
machine the the visible layer the input
of my visible layer would be the final
state in the C direction so this would
anneal into the final state and all the
rest can completely relax known and what
we see here these are the neurons so
they have the four body terms and then
the yellow and the red part this is sort
of a the memory which is now a
dynamically variable so this is this
additional this local field variable
that I have introduced here and this is
a back action from from every pattern
that I learned so every time I learn a
pattern this vector on the Bloch sphere
says it changes and this isn't the
learning mechanism so I can do the the
likelihood maximization as an
optimization by introducing here this
local fields and I think that's an
interesting application for the for for
the parity scheme another interesting
scheme is to hopefully network I think
I'm running out of time but let me just
show you one idea what I would really
like to do so this is a bit semi-classic
and also here in the Boltzmann machine I
have sort of a still individual patterns
that I have to learn it what I would
really like to do is I would like to
give him all patterns at the same time
as a superposition but how do I create a
superposition of arbitrary
configurations I could use a hopfield
network the problem with the hopfield
network is or the idea would be let's
make a hopfield network where learn the
patterns and then a needle into the
final state if this is a degenerate
ground state and have a superposition of
my states now the problem is they are
not to generate they are actually local
minimis but they are not really
degenerate but if I and I can measure
this by looking at a standard deviation
now by adding the free body and four
body terms that I have available in my
parity scheme from the schemes that we
saw before I can actually make them
more and more degenerate so what we see
here is a measure for degeneracy so one
is bad and zero would be perfect
degeneracy is a logarithmic scale and if
I add now so this would be hopfield
network with only two poly terms if I
add now a Freebody and four body terms
this disk goes down dramatically and
this could be sort of say the first step
to to introduce something like a
superposition of configurations that I
can then give the the Boltzmann machine
which has the dynamically local fields
so if this I would like to thank you
great yes please okay so using cleek
substitution we can turn an end body
term into a quadratic term into a
two-body term with n minus one over two
auxiliary variables so for N equals four
aquatic term can become a quadratic term
with only one auxiliary variable so
really what I'm interested in is turning
quartic terms into two body terms with
zero auxiliary variables or quadrat
izing higher-order like five body six
body seven body interactions into two
body interactions with less than n minus
one over two auxilary available so what
I wonder is for an N body term how many
auxiliary variables do you need to turn
that into a two body term so the what
you're suggesting is to reduce
everything to a logical two body term a
logical two body problem is this one yes
to test you so you want to take a
logical problem with n body terms and
reduce it to two body terms the
impression I got from your talk was that
you need auxiliary variables - you need
exhilarates
to perform your scheme yes
how many auxilary qubits do you need so
1 / 4 body turn one for a four body turn
yes which is the same as cleek
substitution
and for five body terms I don't need
five body so physically I have only four
body terms maximally okay got it thank
you
just a comment really to advertise my
own talk but in the we already showed
well in fact in 2014 that you can
actually do everything you did with just
two dimensional icing interactions
nearest neighbor without any four body
terms or anything without anything
beyond two body and entirely nearest
neighbor so so I'll talk about that in
an hour's time yes but I think I somehow
I think we post our paper and well we
were theorists we didn't probably make
it very accessible to people right
trying to do really practical things
there is a different I'm not trying to
say this obsolete everything because our
construction is very polynomial at the
head but very very inefficient I think
there's an interesting dialogue to be be
had between what we show is possible
theoretically in principle and what can
be done practically without ridiculous
overhead yes I just want to mention that
so here it's about the fact that you
program in the local fields not in the
interactions
so okay fantastic talk thanks for a
super interesting subject the I was
really intrigued by the belief
propagation error correction scheme and
then Mario Casas some techniques for
like you were saying using genetic
algorithms to sort of program schedules
do you feel that there is a future for
being able to find techniques like that
that would be efficient to run to sort
of correct errors so that you can you
can boost those success probabilities
coming out of the system with the error
correction schemes but having them be
like small numbers of steps as
post-processing maybe I don't know so
it's a classical error correction and I
think we already identified yesterday
that error correction will be important
at some point okay any last quick
question I'm really intrigued by your
idea of approaching the restricted
Boltzmann machine training as an
optimization problem and treating the
connection weights and biases as a
dynamical variables but in that case the
solutions the opposition problem you
would get would be binary not real
valued right so have you tried that does
that affect accuracy does it work or
curious so I'm not not that far so
that's very preliminary what I showed
you it might work some people in the
room have you know look binary
classifier weights and I will be very
interested in this thing
thank you okay then so you didn't
mention it but the gap and the spectral
properties of their system after
embedding significantly changes so do
you know what under what conditions you
you do not end up with the exponentially
small gap after ability so how much the
gap closes how much more it closes yeah
so I don't know but so say the gap is
always a property of the whole quantum
Puffs no not just sort of say that the
embedding it at the end
and I think the the N squared Sigma X
terms will help us a lot there I think
that question about the gap is probably
going to be addressed in the next yeah
thank Wolfgang again thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>