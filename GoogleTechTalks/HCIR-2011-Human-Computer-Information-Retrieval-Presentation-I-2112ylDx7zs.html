<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HCIR 2011: Human Computer Information Retrieval - Presentation I | Coder Coacher - Coaching Coders</title><meta content="HCIR 2011: Human Computer Information Retrieval - Presentation I - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HCIR 2011: Human Computer Information Retrieval - Presentation I</b></h2><h5 class="post__date">2011-12-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2112ylDx7zs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome back for our first session of
paper presentations we have two kinds of
papers that are going to be presented
the first are 15 minute presentations
and we'll have five minutes for
questions afterwards of course you can
always talk to people during the breaks
and poster session and then after those
three presentations we're going to have
a series of five-minute presentations
that were shorter and there won't really
be that much time for questions
immediately after each of those so hold
your questions on those and if we have a
little time after that before lunch we
can feel the few questions on those so
first up I'd like to introduce Sofia and
I'm not going to try to pronounce your
last name she's going to talk about
search as you think and think as you
search I'll sell my name is Sofia
xenakis and actually the one that I'm
presenting today is my dissertation
project too precise my second visitation
project and it was completed to end so
actually today my dissertation advisor
dr. Charlene is also attending so I'm
going to present and you can ask a
difficult ask us questions to him so we
are dividing the labor so but anyway
before I begin I have to tell you that I
had the worst flight of my life last
night because I was sitting next to a
baby that was crying monster for six
hours and the flight arrived at took up
two hours late of course it arrived too
late so I hardly slept and then I came
today and I was hoping to eat something
when dr. coolest suggested that the work
show was starting in a few minutes so I
had to give up my precious free
breakfast so as you can see I'm sick and
tired and hungry but I will try to to my
so but before I begin I really thank the
anonymous reviewers who reviews my our
papers our aunt gave helpful comments
and the my regret is guy could I
actually incorporate the comments into
the final version of the paper because
let's face it i have only four pages and
if i add something i have to take him
something so but hopefully in the
journal version of the paper i can
elaborate so today my outline is
introduction research problem and
conceptual framework and semantic
knowledge base but of course the focus
will be a semantic search interface and
information with drivel evaluation and
conclusion acknowledgments and
publication the introduction just in
case you are not familiar with this
project so my objective in this project
was to demonstrate our utility and
feasibility and effectiveness over
entity and facts retrieval and I'm going
to explain that later an approach me I
extracted semaine technology using
Wikipedia and based on that I
constructed a semantic search interface
an application domain I used a film
domain as a sample domain / application
answer the products of these are
projects are cementing knowledge base
and semantic search interface but I
won't get into the details of the first
parts but only focus on the interface
today and finally the results are
through the evaluation the effectiveness
of entity facts extraction and which
people have been come from sir oh oh
let's do research problem actually it's
all set our backgrounds motivation and
research problems so my basic point is
that you must think about things and
make sense of things largely by virtue
of classified things into different
classes so when we understand something
we already know what kinds of things
there are and our knowledge or
understanding of the kinds of things
already improves of us of the kinds of
things that we ask or sick about things
so in that sense the ontological
structure of the world in the human
thinking constitutes the base
of the semantic structure of sales
making and a significant kind of
information sticking activity is
concerned with are asking about things
we want to find some things that have
certain attributes and when we are six a
search was those kinds of things we
already know what kinds of things we are
looking for and because we already know
what kinds of things we're looking for
we only ask relevant questions so in
that sense the ontological structure and
semantic structure constitute the basis
of information seeking but the keywords
based interface are actually separates
these are two process over information
seeking and sounds making in the sense
that the query string is decomposed into
individual keywords and dance as a
result you get the documents not the
entities or things themselves as a
result so they'll query and you get the
results as the list of documents so what
I wanted to do was to go to the direct
entity retrieval and not just any entity
retrieval but what I call type and
conditions specify the entity retrieval
so the user can specify type of the
entities and also the conditions to be
satisfied by those entities and as a
result you get the list of our entities
directly as a result your query not just
a list of documents so the problem is
how to enable this kind of entity facts
with with tribal effect please that goes
away from the words based
document-centric and indirect
information retrieval through the
meaning based entered eccentric and
thorough and conceptual framework so I
will also explain very briefly about
this pot so by entity I mean thing very
kindly that it has certain attributes
attributes is a property of an entity
and what do I mean by type are Tigers a
generic class in the ontology over our
entities and the which one entity is
classified and by anti deceptive I mean
the most discussed as
civic class and a Widgeon and it is
classified and in my project I
represented fact as an entity a truth
value and new pupils so this is there is
an additional notes field that to the
standard the subject predicate object
model so we're nerds I used to save and
also retrieve relevant to contextual
information about this entity attribute
value triple and by semantic condition I
mean a trivet and value pair so all the
things in my prose in this project have
been are classified according to the
ontology so that a top-level there is a
thing and then the level one we have
person work organization blah blah blah
and of course each of these level one
classes are also plus by the more like a
concept it becomes out to acrylate in
concept and something else and it is
also further classified for the
classified and so on so by type I need
the level one class and by subtype I
need them perfectly parts indian point
so um the first pots actually this
project is doing the project so one main
part is the information extraction part
knowledge extraction part and another
part is information retrieval and
evaluation parts about this effective
minutes of interface so I will not go
into the details of the extraction
process inhales just briefly show the
results of extractions so I used it are
the film pages in Wikipedia and other
are you uh no words related yeah and
touching result and also one point about
this extraction in my project is that I
did not use just to directly extract
information that is in Wikipedia but
also a major part was indirectly derived
knowledge based on the knowledge already
extracted so this figure these figures
actually contain pools those two
have been directly extracted and those
that have been either derived or device
so there are for example 209,000
entities and there are about two million
entity centric facts and of course you
can also see the numbers of each
different types of entities and so
today's focus is to understand it if
search interface so this is the
interface that created and as you can
see there is there are tabs for
different kinds of search functions and
there's also page that has the user
instructions so I implemented are
different kinds of semantic search
functions for entity facts retrieval and
general end it with low query this is
the main function that I aimed at
demonstrating and by using this the user
can retrieve a entities that
specifically match the entity types of
pipe and conditions mental conditions
there is attribute-value pairs that the
user entered but you are the user can
also use the specific entities entered
query to retrieve or facts about a
specific entity and there is an ended
commonality final area where the user
can find commonalities between two
specified entities of the same on
subtype enter is a direct relation final
query the user can use this function to
find relations between two entities
regardless of their type and subtype and
also there is an indirect relation find
of queries so the user can all find in
direct relations between to specify the
entities that are mediated by a third
entity and finally there is a broad and
function category based entity browsing
so the user can browse on Ilum entities
according to the hierarchical categories
so I will focus on the general entity
retro query so how the process works in
the main menu the user selects search
type
and choose a general entity we throw
prairie and then the first thing that
the user thought is to select entity
type once the user selects entity type
the next step is to select a subtype
under the given time once the user does
that then the next thing to do is to
specify an attribute and won't see you
specified an attribute then you need x
value and of course this our process of
specifying attributes and value
specifying this condition can be
repeated so once the user is finish with
that this process then the user can
submit perry and then the user will get
the query results and the criminal
results are that's not a just consist of
the list of entity names but it also has
a relevant complextro information
furthermore the user can also click on
any entity name highlight it does not
just those in the direct for answers but
also in the contextual information to
get there are information about the
selected entity and of course this can
also be repeating that this is actual or
actually input face so let's say with
general editorial query you can retrieve
all entities that directly match your
career so user clicks the button and
this is what the user sees the user does
not see the whole form like but only
sees the first relevant options so the
user needs to select an entity type so
if either use Eclipse it and then the
user / entity 5s end user chooses one
that will happens is that now the user
is aha given the menu further into the
subtype selection and the entity subtype
selection menu only contains those
relevant options according to the user
selection of the proof in the previous
step so you will not see like some sub
types that are relevant to present type
and you see when you chew when you have
chosen the concept type entity in case
of person actually are the users are the
interface simplifies the selection so
that the user can just say any once the
user does that then you get the menu for
the attribute selection and again the
menu only contains deals you a
attributes that are relevant to the
given or chosen entity type and subtype
the wants to user chooses that and the
in this case directed fila me is the
attribute because there are so many
films in the databases so actually the
input box first appears to show that the
user can type something to get stuff
just but in case that there are only a
few values only like a few hundred
values then the menu are directly appear
so we are in this case as the user is
seeking to find the films that have won
awards and the user wants to specify
what awards it was so the user selects
Academy Awards for Best Picture and then
as soon as the user or specifies a list
one condition then the user can submit
query or at this stuff a user can have
another condition to be satisfied the
entities or the user can remove the last
condition and specified two minutes left
ah so this is who yes sir see it anyway
so evaluation actually I wanted to go
into the evaluations so the evaluation
melt that i use the comparison between
our internet movie database and my
interface for comparison and why did I
use the internet movie database because
of the domain orientation of the product
so all subjects had to use both
interfaces and we compare the results so
the design is that although the user
were the user group was divided into six
groups so they could start with the my
interface or IMDb first or also the
questions were are presented in a
different forces
some of the questions the questions
asked like entities and so who played
all of these roles but that's not the
whole question the whole question is
once you find that gave me the name of
the actor and the titles of the films
and so on so on so the user help to find
not only the entities but also related
entities or some related information and
in this in this case a with ya in this
case also like this so that's why I used
when I are calculated precision Iroquois
it was said to be based on the awaited
correcting his score because the user
had to find of course to entity names
but also some contextual information so
the effectiveness was measured by
precision and recall based on the weight
its correctness score and the hypothesis
was that the perceptor average precision
and recall will generally be higher but
I was not sure whether it will be always
higher but per group precision and
recall I thought that it was rehired and
it has been confirmed I have no time to
be I will just share the main reason so
this is the main result the user was
given ten questions and they did our
work done five questions on IMDb and
unfired questions in panama open and the
result is the average precision recall
was substantially higher than the panel
open interface and per subject average
precision greater than ninety percent or
there were several are in the group and
for all of people all the subjects the
our perception of her subject have our
average precision recall that's higher
for the cannot open interface versus
IMDb interfaces and this is the coast
task force no responses so the only one
person said that the IMDb was
effectively try
almost all subjects agree that the
opponent open was effective also they
said that they could easily understand
and use panel's open and up furthermore
they were also interested in using
similar interfaces well it in terms of
relative effectiveness they all agreed
that the pan-african was and why they
thought that the punishment was affected
the user like the fat other subjects
like the fact that they don't need to
guess the right keywords to use and they
also like the step-by-step search
process and they felt that actually they
could easily understand the entity types
of pets and attributes and they like the
fact that they can actually search for
specific things precisely by specifying
multiple conditions so on so yes this is
a conclusion so actually the evaluation
results are actually show that the the
interface was effective at least for the
subjects and because I have to skip the
parts but actually the subjects were
general subjects they were mostly
undergraduate students but they did not
ask actually measure in information
science room so on but there were
various groups like a biological
engineering biology mechanical entering
and soul and future work oh I'd like the
fighters refers to other domains in nine
yeah this our research has been
partially supported by the 2011 ujin
Garfield the doctor so sorry
yeah I mean there was I did not are
focused and actually a device are that
the focus of actually they came from I
device of questions but my focus was to
see the other friends of curious if they
can in principle be answered because I
MTV has all the information about all
the films so the questions are in
principle answers by IM DVD but it is a
helpful actually practicable when you
really do that so i wanted to show that
so i tried to be non wires to put that
still I had to show the difference
otherwise there is no point of creating
a new kind of interface if way it is set
just as hey thank you very much next up
of 15 blue from Rutgers University and
she's our favorite colors pouring the
effect of past difficulty and domain
knowledge on well time and hyperbole
belkin
good morning I'm Chanyeol from Rutgers
University so I'm presenting this work
on behalf of our poodle project is our
part of our a primary study on this
issue so the topic of our study is
exploring the effect of task difficulty
and domain knowledge and protons I know
how these variable names are very
familiar to our audience and so we are
talking about Joe of the domain
knowledge and we are talking about task
difficulty and we are also talking about
12 times many researchers have done this
but oh I hope we hope our research will
add something new to what we already
know and maybe provide some unexpected
results so let's go first the peripheral
go through what we already know with
respect to the task difficulty in fact
with some reason study have found that
users tend to issue more diverse queries
has been longer time on search result
pages and use advanced operators more
and spend larger proportion of task time
on search result pages when they are
working in difficult task and here
another study that we have done we
examine task type and task difficulty
together so in that study refund when
user were searching for single fact
funding task in difficult task they are
they tend to have longer total to
outcome and longer first 12 time are
unique content pages but there's no
significant difference the dwell time on
search result pages well on the other
type of task especially when users are
searching for multiple facts or general
information gathering we have we found
the other pattern the users tend to have
longer dwell time our search result
pages but there was no significant
difference between flow time our search
our content pages in tip code and easy
task so in our current study will ask a
participant to search multiple
information
with our general information gathering
we will compare this result later with
respect to domain knowledge effect we
there are a lot of research and
something related to what we are doing
here is that users with low domain
knowledge they have less efficient query
terms and less efficient query tactics
oh and Kelly and cool also found that
when searchers topic familiarity
increased their reading time decrease
that means there dwelt among content
pages decrease and their search efficacy
has increased defined as the ratio of
number of documents saved to the number
of documents a building the task and a
reason studied by a group of Microsoft
the researchers they found that it
depends in different domains so in
medical and law law domain the phone
expert had longer average page display
time than non-experts I think the
display time here is very related to the
dwell time come on content pages and in
finance and computer science domain they
found the other package that expert head
shop your average healthy sleep then
non-experts in our study we will have a
petition from medco domain so we can
also compare our results with their
results you mad co domain ok also in
order to address this question we have
weakened like a user study in which we
recruit 40 students from Matco to me and
when they first come to our experiment
we give them a background questionnaire
in which we collect their background
information computer experience search
experience more important we evaluate
their domain knowledge through the their
greeting on their knowledge of selected
mesh terms I will talk about that
briefly later and then we give the demo
of training task how to use our system
after that we kept them for search task
and during each task they are given up
to 15 minutes to search and they can
save useful documents that were related
to this task after that they have acted
questionnaire and all their interactions
with computers were logged by our login
system so this is the way that we
measure their domain knowledge we give
them three mesh three match trees that
in total to four hundred and my terms
associated with the topic categories we
will ask them to search in our task so
these topics are like genetic strength
structures genetic processes genetic
phenomena these are so for each term
we've asked them to evaluate how how
much you know about this term from one
to five that is from no knowledge to
five that I can explain to others and
then we add all their greetings together
that is the top so we add all their
regions and whether some of them were
not read it so if they have read that
term we add them together and then / by
this member that is to normalize their
greetings by an X hyper hyper ties the
expertise who will read all the terms as
five so that five plus the number of
terms they read it in that in that
questionnaire and then participants were
divided into two groups by the median
about 0.4 into hi to my knowledge group
and low domain knowledge group and also
we control their task difficulty the way
that we control their task difficulty is
a different the so hard task was defined
as the number of let me put it this way
so hard task means they there are very
few relevant documents are returned when
we have their topic as a query issue
into the system as per senior night 10
so
so in our task design we control the
task type and then in this figure shows
that users freaking about task
difficulty and that to confirm our
desire of Pascal difficulty so you can
see that among the five task we have a
topic 7 and topic for have a lower
rating than the others so we so we have
two group of pasco with easy task and
difficult task now we look at the
results first we look at the these
factors on the Proudhon of content pages
and since users are searching for
content page to accomplish this task and
they will save some documents that were
related to that were useful to their
task so we also consider document useful
in two in this model and document
usefulness what defined as whether this
page has been saved by the user and this
is the of the result from general linear
model and we can see that only
usefulness has a main effect on their
drought ham on content pages and we also
find there is an interaction effect of
task difficulty and domain knowledge so
let's look at them one by one first the
providing way users spend much longer
time on viewed pages than unsaved pages
that is quite different with what we
already know some study have found that
most of study I have say that if there's
the relationship users tend to spend
longer time on useful pages than long
useful pages oh they are multi
significant if a relationship but here
we found that different item so users
spend longer time are not useful pages
than useful pages and then let's look at
the interaction effects I think this is
more surprising so the right line stands
for the low domain knowledge the blue
line hi domain knowledge so we can see
that you need a task our tree users ways
hi to my knowledge spend much much
longer time on content page then users
with low domain knowledge and there is
not significant difference when they are
working for difficult task and in
particular particularly if we compare
real-time and content page in typical
password need it has only focusing on
our users with high domain knowledge the
themselves spend longer time in
difficult task and you needed to ask
that any difficult task so after that we
continue to examine the the effect of
these two factors on their flower mound
search result pages and all here we only
found that task difficulty and domain
knowledge level have main effect here
and there is no interaction effect so if
you look at this figure these two lines
are parallel also 40 users when they are
working for hot difficult task they're
dwell time on search result pages is
longer than easy task and for users with
high domain knowledge they spend or
shorter drought time on search result
pages than users with low domain
knowledge and we put these together so
that we can compare their dwell time on
search result pages and a beard welcome
all content pages so um I think if when
we look at this figure the dots lines we
represent the 12-time answers and the
solid line stands for their klonopin on
content pages so if we look at only
users with low domain knowledge two
lines with in red we can see that in
difficult task users with low to my
knowledge they spend longer dwell time
on content both content page and search
result pages and then if we look at
users ways hi to my knowledge the blue
line here we see the different item that
again easy task users with high to my
knowledge spend much longer
time on content pages then our search
result pages but the in difficult task
they spent longer time our search result
pages then our content pages so that is
our funding and now let's discuss so one
of the unexpected result is why users
with high domain knowledge spend much
longer time our content pages in easy
task than in difficult task um we don't
know the exact answer and one of the
explanation could be the way we define
task difficulty so hard task were
defined as task where search system
returned few relevant documents using
the task description at the query so in
the search result pages in difficult
task they have very few relevant
documents show there so it is possible
that users with high to my knowledge
they already made the document useful
niche judgment on the search result
pages and then when they get go through
in that particular content page they
just go and save the page that is one of
only one explanation but for users with
wrote open knowledge they the this do
need some time to read the documents and
then make the final decision so then we
can compare our study with previous
study for some task difficulty so in
previous study that we did we found out
there's no significant difference and
real-time of all content pages so maybe
our study could help explain that maybe
the health I don't know the domain
knowledge he has an interaction in fact
with tasker difficulty so they did not
firm significant difference between easy
and the difficult task but there might
be some difference between people with
high and low domain knowledge and with
respect to the girl time on search
result pages both this car is found
users spend longer time on search result
pages in difficult task than easy task
and we also confirm that so users tend
to stay too
stay longer time I'll search result
pages when they are searching for
difficult task so compared waste our
time on content pages maybe dwell time
on search result page it could be a
better indicator of task difficulty and
also tell domain knowledge and if we
compare that with the results in domain
knowledge in fact actually our results
were different and we are not quite sure
maybe the task difficulty has some
interaction a factor here so here comes
to our conclusion that is users spend
longer time out search result pages in
difficult task hanging easy task and
users with low domain knowledge spend
longer time I'll search result pages
than users with high domain knowledge
and dwell time and content page has
chosen a interaction effect by the task
difficulty and domain knowledge and also
i have to mention that it is possible
that users spend a longer time in long
useful pages than useful pages so we
found that our study the result from our
study may not be generalized it may
depends on our desire of task and the
gender of our system but this is what we
found and we would like to discuss this
with the audience care we got very good
reviews here and we would like to
continue to do this and especially
examine the relationship between the
12-time and content page with the
drought time on search result page to
fully understand how user search in very
difficult task thank you very much
perfect
so you mean the total time they work on
the task may affect their such behaviors
yeah you have up to 15 minutes to search
and actually these tasco very difficult
and in our data collection we found most
of users use all the times so 15 minutes
and maybe ID and they were later by a
little bit hurry and they want to save
more maybe that could be an effect here
thank you domain knowledge Oh a search
skill we also collected information
about that but and I don't think we have
analyzed to do you have any Michael
there we have the data but we haven't
organized thank you for the suggestion I
think we will try to see if that hasn't
risen
so one thing to consider this is not
necessarily before now that could be yep
thank you it's just a suggestion that
you might actually look at daring the
qualities of the snippet as a way of
forcing the effectiveness of the result
pages mm-hmm I mean the their search
results on the search result page dry
yeah yeah ve reevaluate their search
performance but their search performance
is all may focus around whether they
save that page but I think your question
about their overall quality of the
search result page right yeah so this is
the content page they look at the
abstract and this is the search result
page and we have that their title or
author and the name of journal so the
only information that they can get more
from contemplated the abstract
they just saved relevant document
yeah that's an interesting question but
in fact our house where our task word
boring okay so if you you are interested
i have task examples and this is easy
touch and this is a typical task these
are from track 2004 and i have no idea
what they are so they are really domain
photo being limited and very we only
recruit students from medco to me so
they can understand this and they are
not searching for fun they are searching
for they teacher so I with some great
discussion here I hate to cut it off but
would you need to move on so I encourage
you all to talk to right well thank next
up is hinging blue state university and
Pegasus partners and she's going to talk
to us about knowledge examination in
bulk confession tasks
okay hi everyone yes as we did to her
hurt knowledge did have some effect now
here we have another paper about it this
was a museum icon education research
data but it are the very different
analysis from what I did before there is
there some mismatch theorem I know in
this study actually we look at a user's
the self assess the knowledge in a
multi-station task and both before and
after they work with the task and post
before and after the work with each sub
topic of this motivation task and we
just look at you know the relationship
between the knowledge these kinds of
knowledge that i just mentioned and see
what is the pattern of them and the
funny is that uses knowledge of the
general task and their knowledge of the
sub task top a okay they did have
different values and also they have
different patterns of change and some
attributes of the past knowledge but not
all of them varied across text has just
an overview the Y knowledge we know that
knowledge is obviously an avoidable
about aspects when they look at it when
we talk about information search and
previous study have fun that including
the one that we did okay the users
knowledge they did affect you to search
behavior and their search performance
also from evas from the starting point
they choose to use the search terms
query terms how long a query is and to
reading the result page and even the
procedure and recall and there you know
correct native answer the question of
tasks so it quite quite obvious that
knowledge affect users
performance and in terms of the
knowledge elicitation or assessment
there have been several and different
kinds of a methods use the included
studies for example according to
different stage of taking a course or
taking or in a program you know the
earliest age probably corresponds to a
lower knowledge and a later is a curse
felt with the higher knowledge or you
know a person inside or outside of a
domain corresponds to the novice and
experts and even their answers to some
kinds of questions in the test some
other method views that are like reading
the terms in a thesaurus or just the
same plate to ask users to self judge
how familiar are you with the topic and
previous studies found that the fourth
and the fifth or curly here with each
other and this study that I'm talking
about we use the fifth method hey so um
we know the knowledge is important in
affecting use a behavior so but we don't
know there are how knowledge change
actually in the search process and this
is why we had this research also because
multi-session tasks are often seeing
different life and also it is a very
pretty and EV and convenient way to
assess users knowledge pain throughout
the process I we're doing research and
the specific questions we try to answer
include that what is the pattern of
users general knowledge a gen knowledge
of the general talk and what is the
pattern of users knowledge of the
subtopic of the task and are there any
difference between these two and how are
you how different a task type would
affect users knowledge and also how does
users knowledge change across and within
different sessions
okay so as I mentioned this was about
this date I said was coming from my
decision research so those who know
about it Hannah who I basis it last week
please feed pigeon and molarity ok so
this study we had a 24 participants from
other words journalism and media studies
and they were paid and respond us to
encourage them to have a serious manner
in 30 and working on the pack okay half
of them worked with the defendant has
and the other half work is the parallel
path just to explain further what are
these two they say that the task was
that each participant participant was
asked to write a three section article
in three sessions and each session with
one topic in a parallel task they were
asking to focus on the three topics of
the honda civic toyota camry and vanessa
edema but John other hand in a dependent
ask the three sub topics were collecting
information bihari cars and the selected
three models that many focus on in
article and just compare and the pros
and cons of each of the model so you see
the difference structure here why is
parallel and the other is given
I have click somewhere but i cannot see
when out back to the study design as I
said that this was a motivation and
study each user actually came free time
those recession each session work with
one topic of the three and up before and
after each session they were asked to
complete a questionnaire and each
questionnaire they were elicited they
were acted to self reach their
familiarity with the topic of the
general task and they're familiar with
the topic of the sub task based on the
seven-point likert of you what is what
at all and seven is extremely so here's
how our dinner was elicited from ok
another of fact your unit study was
actually a system version so there were
two systems versions are involved one is
called a firm suggestion how it looks
like this either on the left side there
were some terms which suggests which
suggests to the users another version
which is a long-term suggestion it was
just a blank ie window just the right
size in a full side the in the study of
service actually um and based on the
interview afterwards with the petition
fairly used to those terms so we think
that this system effect does not affect
what are or are a current research it's
like anyone are going to talk more about
okay now let's talk and here is the
results showing in the graph about users
knowledge of the jammu attack before and
after each session for all three
sessions now we see that like to
increase inside of each session that we
know that from the study from the
results actually in session 3 the
difference will not seek significant so
it seems like in the previous two
sessions users gained knowledge on the
general health topic but in the third
session that the kind of reached a
plateau and the didn't support didn't
increase significantly and women look at
the free translation comparison we see
that for the pre task and the post ask
this seems like you both increase across
sessions and a post-hoc analyses found
that the difference was between section
1 and section 3 session to actually
didn't significantly higher than second
one that session 3 was here is his
friends now we looked at the knowledge
of the general task again for in two
different tasks what is in parallel and
the other is in the dependent now we see
that actually for the open with the
evening session of in the dependent talk
actually users knowledge cleanser in all
three sessions but in a parallel has
meetings below they're in session 1 and
7 3 users knowledge the Rinnegan but in
session to begin so one possibility is
that actually we loaded the results for
the parallel task in session one users
had a pretty high
slide please line knowledge so that's
why they didn't seem to gain more
knowledge in our today's session and
session three of the parallel task the
pattern was the same as as well we said
kills me as what we saw just now for the
in this slide ok when we look at the
bitterness anything ok for the dependent
ask actually the pre task and for the
breed has padding for both the dependent
has and the parallel task was the same
pattern as what we saw just now in this
slide but we will look at the post
session general task knowledge with you
something different so for the dividend
ask actually users knowledge after the
sessions the increased across each
session but in the parallel has because
they didn't seem too thin across any
session there were no difference there
ok so we did further analysis use in
general in your model and just to have
an overview of the task and the session
effect now we see from this results the
search effect was in accordance with
what we just saw in a previous full size
and about the task effect that was not
seen in the previous slide actually we
saw that the for the pre task knowledge
a dependent task users had lower
knowledge than the parallel task
although that after the the tasks the
poster session tasks they to reach the
same it seems to correspond with what we
just saw but out explainable more later
yes so now let's look at the subtask
knowledge so now we see that it's quite
a different from the done without my
knowledge and because the sub house at
happy because they are different than
different at each time so the previous
the pre task pre-session knowledge
actually they didn't seem to change at
all and because they are different but
post knowledge when we see that the
session one a session three there were a
significant difference possibly because
the users when you get them went
together the third session they already
got some knowledge about general task so
they were higher in the topic of the
subcommittee as well it is the same
analysis into tasks we see that the with
in session the English all the time and
better in session no difference at all
and again this is a general linear model
analysis and we see that such an effect
in or sing or was the same as what we
saw just now and just ask it back to no
not at all so free and opposed to both
tasks are the same now here's a summary
of the findings first about general and
the subtask we see that the akadi
different patterns the general has
knowledge users seem to increase within
sessions except for some exception when
they seem to reach the plateau but and
they seem to increase the train stations
also but for the subtask knowledge they
seem to increase within sessions but not
increase between sessions and another
thing that when we look at the parallel
dependent as we see that we saw that for
the general has knowledge dependent ask
users have more knowledge than the
parallel properly because parallel task
easier third in a process okay users
didn't seem to gain knowledge in the
parallel task that they really gained a
knowledge in a dependent ask until the
end of the task they reach the same
level ok so now so what do these all
tests they think that first we know that
they are two different
of knowledge in such a complex study or
complex talk we want to be sure what we
are married and also we see sometimes
users could get a petal or like a silly
effect when they have a pretty high
knowledge already they what with another
session we're not supposed to vacantly
increase their knowledge and then study
design I think we want to try to avoid
this also we see the difference in the
parallel and dependent at the parallel
task is kind of like easy when you're
ready task that you didn't gain
knowledge in the process difficult as
the dependent has goals on a different I
may seem very difficult in the beginning
I uses actually gain knowledge so in the
end the conv which the same oh so this
has seemed to indicate what systems want
to do to help users if they have high
enough knowledge already what kind of
system do to help them gain more
knowledge even and also how to help them
to serve the pack so this is our final
and thought and we also are open to all
the other comments and the additional
for our additional thank you
okay as I mentioned actually there are
different ways to different ways to
measure endless knowledge and the one
that we are using was used to previously
in other studies this is one thing that
we also in a used to the same method and
also second thing is that this method
was found to be correlated with uses
video of their familiarity with some
settlers terms we think that it's kind
of not a purely objective but it's more
objective than they just to self reach
my knowledge we think this is a somehow
reliable way to test users knowledge
because the scissors term we know that
not every domain has a service for some
domain again
yeah I I hope we were able to find that
these orders for the high vehicles at
the time but obviously years I'd like
your suggestion and the in future
studies we could also look at the use
this kind of knowledge change using
other kinds of method to assess their
knowledge oh there was another study
actually also out of the ruggers group
and using the study you just heard by
channel we actually in the study we
asked the users the medical participant
they come to reach their familiar with
the scissors terms for things like five
medical ogia genomic genomics I've just
taken from mesh the medical subject
headings they're actually with the
structure the tree structure and we ask
the users to self-assess their family
with those terms for each of the terms
and we also in on the other hand we ask
them to self reach their priority with
the task topic it just that as you see
from the previous paper so we got both
methods and we look at the correlation
between the two radios and we found a
high very high correlation probably
eight or ninety percent
okay so next up we're going to move into
our lightning round of five-minute
presentation we have time for questions
after each of these might have time for
a couple of questions and right before
lunch the first up is mark tucker from
University Waterloo to talk about an
analysis of strategies for processes
right this document doesn't know I guess
I'm trying to put everything into the
title which is apropos for a five-minute
talk yeah so I'm mark smoker from the
University of Waterloo and when we have
users and they come in and they do a
search with a query then they're
presented with their results and now
they faced with the task of examining
and processing those results and this is
where I'm focusing on here today I'm
interested in questions about where do
they spend their time similar to the
rutgers work okay so where do they spend
their time on the summaries where do
they spend their time on the documents
and also with what sort of accuracies do
they operate on clicking on those
summaries and also the judging of those
documents now to do this actually had
previously a 48 participant user study
and in this user study we asked the
users to search for relevant documents
and save them if they're relevant okay
they were given prefixed lists of
relevant documents okay so these were
already manufactured for them and they
were to search for them they had ten
minutes for each search topic they
worked on we had a very basic user
interface instructions at the top search
topic on the right there you go 10 blue
links or so and query by summaries you
can click on them get to view the full
document and the documents would have
query terms highlighted in them for the
users the user could then go ahead and
if they wanted to say oh yes save it as
a relevant document this is not a
required judgment but it is that's how
they would do it then when they're done
with the page simple back button to go
back to the results continue searching
for relevant documents and when they if
they wanted to they could certainly go
ten more results in 10 more rizal
it could keep going for as long as they
wanted to now to look at this behavior
we used k-means clustering alisis and we
again are focusing on both time and
accuracy but here instead of notions of
just accuracy we're actually taking
signal detection theory measures very
commonly known as true positive rate in
the false positive rate so we're looking
at this at the for the summaries the
accuracy there and also the time spent
and again the accuracy and time on the
documents and that's those are the
variables on which we are going to do
our clustering all together so now these
are overall results for the 48
participants this is not the cluster
analysis this is to give you a taste for
what you see oh let's just take the
whole population and compare it to the
cluster group and basically on the
summaries we're going to see oh they
seem to be what we would call fast and
liberal they only take about nine
seconds to before they click on a
summary and by liberal what we mean is
if in doubt they're going to click on
the summaries they're operating in a
manner which is very similar to I don't
want to miss a relevant document so I'm
willing to click on non relevant
documents to avoid missing the relevant
documents now they are distinguishing
between relevant and non relevant
documents here so the false positive
rate at sixty-two percent so when they
it's a non relevant summary sixty-two
percent of the time they're going to
click on that thing for the relevant
ones eighty-two percent of the time to
click on them so the art distinguishing
but they're very liberal in their bias
towards whether they're going to click
on for the documents they also seem to
be quite fast I mean they're only
spending on average 26 seconds before
they leave that page or have made a
decision to save it but now their
decisions are quite neutral the true
positive rate in the false positive rate
are balanced now we're going to cluster
them into three groups the paper has
other as a clustering by two groups and
the paper has lots more details than
this I encourage you to take a look at
it or come talk to me now the best
performing group that quite out does the
other groups combines a strategy of
being very fast and liberal on the
summaries with actually take being quite
fast but neutral again on the documents
so six seconds on the summaries
20 seconds on the documents and they
really churn through and find the
relevant documents the fastest there are
two slower performing groups and they
basically adopt opposite strategies so
the better of the two slower performing
groups actually goes ahead and has a
slow evaluation of the summaries they're
taking 15 seconds in comparison to these
six seconds but now we also besides just
seeing them as being slower they're
actually neutral in their decisions okay
they're actually balancing the their
true positive rate in the false positive
rate and that's very interesting but
when they get to the documents they're
able to go very quickly the other group
is they're very fast on the summaries
but then when they get to the documents
they take 40 seconds ok approximately so
we really between these two slower
performing groups see them basically
allocating almost sort of the same
amount of time about 45 seconds for a
summary and document total evaluation
but how they spend their time is quite
different ok one group says oh I'm going
to go really fast on the summaries but
then I have to spend quite a bit of time
on the documents and the other group
says nope I'm going to spend quite a bit
of time before I make my decision on
which summary to click on but when i get
to the document i'm able to make this
decision very quickly and with that i
look forward to your questions later
because we're taking them at the end of
all of these talks all right so next up
is Jim Jim with updated prof david smith
talking about the guy's wedding and a
foot browsing model by simulation
Oh
hello everyone um I'm drinking from
UMass Amherst um my my group is not
typically associated with HTC our
research but there I am so these are
talked about how we can improve our
access to on documents our own personal
documents are start by this simple
question what do you remember about your
documents so we read you your muse
originally don't have very good memory
or documents and in that case or memory
is typically covered this way and if you
can if you're lucky you can come up with
copper key words by which you can use
keyword search interface to find the
document right but unless you're is
lucky you not you not be able to find it
but you may still remember some other
information which is association with
this document and other documents and in
that case and if the system supports
some sort of browsing between document
to other document are believe that you
can use this um can start interaction by
keyword search and then a move to the
target document by browsing so this is
the interaction model of proposing and
we use done something like find similar
kind of interface to evaluate this our
interface interaction method but and we
did some user study or in other work
which are present next week on cikm
conference but today's top should is
focusing on so they given that
interaction model how we can evaluate
that by simulation and I think that
simulation is are important because it
allows you to test your method with lots
of variations in a system configuration
and a user user parameter and for
simulation we first proposed some sort
of problem probabilistic user model
which is composed of your generation
the state transition between search and
browsing and Link selection for are
browsing so just to see also our mother
starts by on search and then user can
click on the list of the resort if they
want to browse and then they can finish
interaction by finding the target
document so our give you some more ether
interaction monitor so we start by
taking this target documents and our
poverty newer model takes the term on in
this case this James registration and
use it for user to initiate the search
procedure and the search is now 11 that
or it will leave formulate the curie but
if the search looks reasonable relevant
which you can pair because we have the
we can use the rank position of the tart
original target documents then it
initiates a browsing by clicking one of
the results and in any case if you can
rank the target the ultimate top 10 it
finishes the interaction this is the
interaction model of probably seen use
your mother and the point and the
hypothesis we evaluate using this
simulation technique is a two-bit
parameters of future the first days on
you just browsing behavior which we are
divided into van out and the Bradford's
versus depth first search approach so if
the user is browsing the pie pan out I
mean Twitter user click one versus on
more than one item for our research and
this up reference and depth first search
is different by the order in which they
are Proust so this is the behavior part
of the user model and exporting
knowledge part we have three different
levels of neurology witches random
informed and the Oracle and really since
we have the rank position of the target
document we can uh
you can weaken mother the users
knowledge of the arm this no one item
finding scenario so I don't have time
for evaluation a presentation of deep
deter bottom over with your show that
compared to the other user study that we
perform we found that browsing is used
and is a successful or most at the same
rate as the users to the church that we
did and the other thing that we found is
when he looked at the success ratio of
the browsing on we found some
interaction between users behavior and
the New Jersey level of knowledge or I
can tell you more about this when you
come to my posture later but their
summary is that we are proposed this
associate browsing motor and down
evaluation by simulation and I just want
to make a brief comment about this
ongoing work so you can see that my
previous work solo break very simplified
version but we want to incorporate our
humans of memory model to actually are
more realistically simulate users
interaction with the system thank you
alright the next up is a talk about some
of the United Earth stages during the
third session the change here if we can
do this
brain
alright so mike robb said this is work
that we did on trying to understand the
stages of a search that people go
through during an exploratory short
session without lines with standard talk
format um this was specifically done and
when we were looking at we were studying
faceted library catalogs and we've done
a couple of studies on this and the
typical thing is we give you know the
sort of standard lab study where we give
a we give a exploratory search task we
have going to go run through about 60
those we leave in using eye-tracking and
using that to to collect data in this
particular case what we were interested
in understanding is are there particular
patterns what's the overall distribution
of time they spent in the various search
stages of their search and are there
observable patterns and i'll come back
to what the stages are that we were
looking at in just a minute um just a
little bit of background the study was a
18 subjects undergrads they were we're
having them do these exploratory
searches where they were sort of
grounded in writing an academic paper
early stage research going to the
libraries in the library catalog to find
to find information had them do six of
those tasks and then what we did is
we're recording the gays data and then
at the end of the session we actually
replayed the last two of their stages of
their searches um and we had that we did
a little retrospective interview where
we we replayed the gate the the search
the video those searches at half speed
and we overlaid the gays data so we
could act they could actually see what
they were looking at slow slow motion
and then what we asked them to do is
report at each every 10 seconds or so
report what stage of the search they
were in and we captured that data the
full detail of the study are in our
jasus paper is the example of the
exploratory task the sick though we used
five stages and the reason we did this
is
a number of different models of stages
of surf surf sessions Martini's model is
the one that grew on a lot um we had
this collapsed at down to something that
was more usable for the end users for
the for the searchers because um first
of all they didn't know it was a lot of
stages with those complex and then the
other is that they don't the labels and
the names the stages and the models are
not necessarily readily understandable
to the end users and so what we ended up
doing is trying to collapse them and
come up with more meaningful or
meaningful stages news were the five
stages coming up with query terms
getting an overview extracting deciding
what to do next in their search and then
deciding on the topic which was the
nominal search task so when we hear that
and then we basically summed up the
amount of time that they spent in each
stage of that task over the course of
the search you can see that in the
extracting stage they spent
significantly more time not turns out to
be about forty percent of their time was
spent extracting and then the other time
was spent roughly divvied up among the
other stages and then what we did see if
I can get this to work in one minute his
look at arm we try to do is visualize
each stage each search and the sequence
of stages that met through and present
that in some visually way that gives you
some way to look at an overview and
drill down into the details so for
example if we look at a zoom out a
little bit little um you can start to
see an overview of all the there's about
30 pink about thirty six sessions total
hose off a couple min and you can see
how the Pat how some of the search
searches were no longer or shorter we
saw some interesting patterns of you
know most of them started with the query
term not surprisingly and then but some
of the some of the searches went you
know through this query terms overview
query currents overview deciding on a
top
three turns over views you can see these
different patterns of how their search
progress some of them were very lower
and we're deliberate perhaps others
spend more time on the extracting phase
so those are sort of some of the
interesting patterns that we saw and
I'll stop there but there's some
interesting future work that we want to
do sort of building on that though come
talk to us at our poster last but not
least is like a bowl to talk about your
domain knowledge not during church okay
that's kind of down okay so what I'm
going to focus on is a work that we've
been doing that's developing a new
methodology to take I movement data
directly from Toby I tracking log and
really focus on analyzing the eye
movement patterns and what we're
interested in in particular is focusing
on modeling the process of information
acquisition as the persons experiencing
it during search and the way in which we
operationalize that is to focus on
cognitive effort that's associated with
that the connection with knowledge
without getting into an awful lot of
things the general idea is that words
are indicative of concepts and concepts
are more or less the same as knowledge
we decide questions of relationships
between rules and so on and so forth ah
but very importantly the process of
reading involves using knowledge in
order to understand other words that
you're dealing with and also to process
the concepts that are involved and both
the acquisition of information and
concepts that you're getting from text
that you're reading that you can see
that it's a very central element in all
aspects of search so it's very important
is to understand that the user knowledge
actually controls interaction during
search it controls it both in the sense
of selecting the words that a person
chooses to read and it also importantly
imposes some cognitive demands in order
to understand what's going on so here
are a couple of really key facts about
eye movement the first is is that eye
movements are cognitively control hey
you do not passively move your eyes
around and process the information that
comes in rather you look where you want
to look and there are a number of
studies that show generally that where
you look depends upon what your current
needs are and we can make the assumption
at that form for information service
well now a really critical point and
somewhat surprising point is that when i
fixate on a particular location of with
respect to reading they remain fixed
until you've acquired the meaning of the
words at that but studies have been
conducted where you take the words way
and people will continue to look at the
word until they've acquired it so words
that are less familiar take longer so
this really tells us why we think I'm
pattern analysis is extremely powerful
first is too obvious to mention you're
not looking at it you can't possibly
acquire the information but the second
is I think really the Keystone here and
that is that you consider one and two
you realize that there's a direct causal
connection between the observations that
you're making of people's eye movement
patterns and cognitive processing states
and by extension mental states so that's
really nice because we can think now
about how we can connect that with
observable user behavior so this is an
example of looking at a page I've
highlighted in green one says where
person is actually reading so the yellow
dots are the fixation have the isolated
fixation point so that there are three
sequences where they're engaged in some
what extent
but what our methodology does is to take
I tracking logs on the front end that
record the fixation information and then
produce this representation of the
reading experience that is say grouping
things together in these long eluded
sequences and the shorter ones here are
the four cognitive processing measures
if you come by later I'll be able to
tell you a lot more detail about them
readings the nuptials and how long
you're looking at it and how many times
you awkward there's a lot of empirical
support for connections between each of
these here's the study you've always
seen this several times before so the
results that we have are that there are
strong individual correlations between
the level of domain knowledge and at
least three of our cognitive effort
measure first is perceptual scan which
is roughly the spacing the fixations and
very interestingly there's a lot of
evidence showing that thats related to a
conceptual processing bottleneck of
human beings second is how long on
average you're looking outward and then
finally and what we built is some
regression and classification models
we've had some success and being able to
show that at least some predictive work
uh so main points methodology lots of
grounding and empirical research roughly
20 or 30 years and cognitive science
directly connected to the information
acquisition process very nicely it's
completely domain-independent know where
have we talked about processing the
content that's there and also as a
follow-on it's also culturally and
individually independent because it's
driven by the users experience how
they're actually interacting with the
information thank you very much or
pudding project
okay well thanks or tighten up on time
so any time for questions to the last
five minute folks that i really
encourage you austin during lunch and
give them all the questions that you can
thinking about holding back we have one
public service and out at four in at one
alright so i prevailed upon my
organizers to let me do one public one
little PSA HHS is proposing to change
the rules for human subjects research
and they've had a proposal out there
this is going to affect anybody and sort
of on the academic side is doing human
subjects research they've had a proposal
out there for a while they're looking
for comments there's a number of
promising things about the the proposal
but obviously the devil is in the
details in this rulemaking process one
of the things Marty first back in August
I think sort of said well let's get make
sure that the HCI researchers voice is
heard so we've looked at that there's a
bunch of us that have developed drafted
a letter it's gone through a few several
revisions and it's now available if you
want to look at it and hopefully sign it
up here at this google address um and
it's a it's a summary we shouldn't
address all the issues so we encourage
you to look at the letter read it if you
agree with it please sign it we've got
seven got about 100 HCI researchers
we're hoping that this makes an impact
when they read their comments um if you
want to see the full proposal it's
available there there's also a link to
it on this page remember that whole
thing and we encourage you to read that
and look at that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>