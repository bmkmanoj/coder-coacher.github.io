<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2013: Automated Video Quality Measurements | Coder Coacher - Coaching Coders</title><meta content="GTAC 2013: Automated Video Quality Measurements - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2013: Automated Video Quality Measurements</b></h2><h5 class="post__date">2013-04-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IbLNm3LsMaw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so next up here we have Patrick hoogland
who is add the drummer which was
probably comes in quite handy when he's
banging his head against this automated
video quality measurement system so with
that Patrick thank you thank you all
right so I got to talk about automated
video quality tests that is a problem we
ran into with the web or to see a
project so first how many I've heard
about we're about to see before as a
couple okay well for the rest of you of
none web or to see is a web standard
that is being developed right now for
video and moisture built into the
browser so we are implementing this
right now in in chrome and and also
Firefox and opera are are implementing
this Web stuff in here so Weber to C
gives you the possibility to in a web
page with JavaScript acquire users
webcam and microphone with their consent
of course and I'll send it over the net
directly between the participants so it
uses a peer-to-peer technology and all
that stuff is built into the standard so
it's really easy to write a video chat
application that works regardless of NIT
and firewalls and other things that can
be anyway okay so the chrome
implementation of this is done in in
Stockholm and Mountain View and in
Kirkland and I work in a Stockholm
office with with this project so we
wanted to to test this but to explain
what we need to test I'm gonna explain
briefly how we were to see it all works
all right so this diagram here as you
can see is a very simplified description
so what happens here is that we can
imagine we have two browsers on two
differential means somewhere and then it
is up to to the web page to implement
that application part they are agency
and implement a signaling solution and
at the point of the signaling solution
is to first figure out like who would
you like to call with web RTC for
instance and and I can maybe implement
like a
contact lists or random or or whatever
and also the the singular solution
exchanges the information that that is
needed to set up the call for instance
what codecs their support as on we're
gonna glow so over that part completely
I'm instead focusing number two you can
see you down there which is media when
media starts flowing okay so given that
we set up a call how do we test it so
one of the goals we set out to do here
was to to set up a call and measure the
video degradation because obviously when
we send video over the internet we're
going to have to compress it right and
also in we're able to see there's a ton
of built-in algorithms for bandwidth
estimation like adapting the the
encoding parameters to how much
bandwidth you have or or loss your
connection is or as I like to see it as
a test engineer a lot of things that can
go wrong a lot of things that can break
so we wanted to measure the video
quality the consult on the other end of
the call and we wanted those
measurements to correspond to user
perception as much as possible and what
do I mean by that well basically if a
user would think it looks bad it should
get low score and if it's arc effects
that the user doesn't really notice that
much it shouldn't affect the score too
much we want this thing to run
continuously we wanted to be a reusable
tool chain with small tools that have
well-defined tasks as much as possible
so it's to make a view usable and we
want we want the implementation work to
be some cell self-contained unit so we
can hand it off to an intern and that is
precisely what we did when it tough to
our intern very spot so far from from
Bulgaria and she implemented it and it
worked right so that's why I'm here to
share with you an overview of what goes
into making a tool like this so we're
gonna obviously gloss over a lot of
details but hopefully to give you an
idea what they need to do okay so when
we started this thing we already had the
test which could launch a browser open
two tabs
launch a small c++ binary which is a
signaling solution
and have the two tabs set up a weber to
see core so the output video gets fed
into a regular video tag html5 video tag
we we had some fake webcam drivers on
all major platforms so that we can
basically feed a known input video into
the webcam and have it looked like the
webcam to our about to see and we also
had implementations of the peak
signal-to-noise ratio and structural
similarity algorithms and i'm not gonna
go into detail what those are but
supposedly together they give a pretty
good picture of the video quality all
right so now the first problem to solve
was how do we record what goes into the
what's coming out in the video tag on
the other side first we can see the
screen is creating solutions where you
scrape the pixels on the screen and that
kind of thing but fortunately we were
able to avoid that because you wouldn't
have to make a platform specific
implementation of that one yeah it
started turns out you can take a canvas
tag and tell the canvas tag hey canvas
tag capture the pixels that are
displaying in that video tag right now
right and then we hook that up to a
JavaScript timer that tries to capture
at 30 FPS or as fast as it can really
and now we run into some other problems
like we can't write the frames to disk
from the JavaScript environment so our
intern wrote a Python server that we
talked to using WebSockets and then the
Python server writes on the disk it's a
bit the mold I know so after running
this you that stuff yeah not basically
with a couple of hundred of image files
on disk and now we run a small tool to
consolidate those into one video that is
raw video right but there are still some
problems like we are no idea where the
video starts like when we run the test
we don't know where we are starting in
the input field because the driver is
just going to loop it over and over
right and since the algorithms I talked
about earlier compare frame to frame and
give you a score you need to compare the
right frame in the output video with the
right form in the input video
otherwise I'm gonna get the wrong score
and also even if we sold that
synchronization problem with the camera
driver what if we dropped it first two
frames then we will compare frame and in
the output video with frame and - - and
input video and our score would be very
much punished for something a user would
not notice oh that's not good and also
if the JavaScript app is not capture all
the frames because I sure don't know how
to predict how fast Yama script will run
so the trick is to encode bar codes into
the input video all right so you can see
it at bark of sleep at the top there it
is going to move along with the video
and you see free examples of the video
here because this is what our test looks
like like what's going in what's coming
out from the other side on the canvas
that is keeping up capturing the stuff
there so how will that help us well it
will make it able for us to encode the
unique ID in each frame in the input
video and and then later find out which
frame we actually captured on the other
side so the encoder user uses I'm gonna
go quickly through this theater so the
encoder uses a library called zebra
crossing if you can hear and I
regenerate barcodes from us for us so
generate a bunch of barcodes in rising
numbers like 1 2 whatever now we use
this use ffmpeg to convert those to V
and I'm a combined divide lease to a
barcode movie so that's just gonna be a
very narrow movie with a moving bar code
in it and then we can stitch that
together with any input file of our
choosing and creates a video such as the
one we saw over here so our setup ends
up being feed that video into the fake
webcam have WebRTC acquired that webcam
then we also test that you know our
device acquisition code and all that
stuff works for all operating systems
we capture what we get on the receiving
side with the video cameras finger I
thought about decode the barcodes and
then we unanalyzed it so the analysis
step is the next slide and I'm going to
talk about first work out the code
so what does the barcode decoder do so
it it takes the yov movie reproduced in
the capturing step splits that into a
bunch of PNG files because that is
receiver crossing understands again
using ffmpeg run it through zebra
crossing and then we get a bunch of
numbers so our tools is going to produce
a file we call stats not txt analysis
and mapping for each frame in the output
video what is the corresponding frame in
the input video and that is used in a
final an hour and I wasn't stopped here
so then we have this thing that takes
the original video the capture video and
that that mapping and then it is going
to run psnr and SSE M on each frame
using the mapping from stats dot txt and
what we end up with is something like
this okay so it's a bit hard to see here
in the graph but what you can see in the
graph is that first those lines that you
see either that is the distribution of
scores so each frame is scored
individually and then a big fake line
and middle that is the average for that
particular run so what you can also see
or maybe not
is that we are around 36 decibel peak
signal-to-noise ratio which I would say
is reasonable for internet Princeton
transmitted video the big dip on the
right there by the way is our regression
looks like and when it goes back up
again that is where the the regression
was rolled back and for the structural
similarity similarly we get consistently
I think about 0.92 696 out of one in
each quarter right so when we put the
whole thing together we end up with that
so as you can see it's a fair amount of
stuff in there this the the parts I
mentioned earlier like you have your
input video that you just need to
prepare an encode once and then you when
you run your test continuously you feed
a same video into the webcam and
you you run the tests as in our case and
on you you do the necessary conversion
so that you get Yee file and you decode
the barcodes and you end up with
something we can analyze and produce a
score from that right so that concludes
my talk thank you for my time Thank You
Patrick
so if you have a live question I can go
to the mics
I see somebody up there and then we can
also pull from the dory so why don't we
go live first please hi so a question
about the output frames does it ever
happen did you lose output frames
because you couldn't decode the barcode
in other words that the quality is so
low that you can't decode it yeah so it
hasn't happened very much for us when it
has happen it was being because whoever
to see has been completely broke and in
the CSS rendering black or garbage or
whatever so if if the image gets so
distorted that not even the barcode
library can decode the barcodes down the
image is probably completely broken so
that is the conclusion you can draw from
that really Thanks all right let's pull
one from the moderator here do you test
a vsync issues if yes how do you do it
no we don't but so I guess the balance
that's question no but I mean that is
obviously maybe something can extend the
test tube and Bide whether that is a tip
for all of you are that's all this code
that we have written for this is open
source and check into the chrome
repository so if you want to use it you
know so if you want to write something
like that you can probably do it very
cool all right let's take another one
here are you able to measure the video
quality while streaming at various
network conditions no but we would love
to be able to do that I mean presumably
when when you have a lot of packet loss
or bursty packet loss or a lot of delay
or whatever you would expect the
bandwidth facination algorithms dosed
accordingly and then you should see
probably that
okay 2% packet loss who'd ever get maybe
34 in PSN or whatever and you know then
you can keep your stuff working for all
customers and I think this is something
people don't do enough of you know
verifying that okay it looks great and
Google's office network but it will not
work in an ADSL line in India for
instance so we have plans for that
interesting and we have time for one
more live question I think you got up
here first is that or did you it's
awesome
okay left please what's your name where
do you where do you work in your
question why bar codes you might as well
have written numbers in there yeah
absolutely well we had a library for it
like like I said Sierra Christina I
think barkos are relatively resistant to
normal artifacts when you encode and
decode a video so I mean we don't want
that to be flaky and it has turned out
to work very well if they had use
numbers and they would have had a cookie
monster instead of zebra okay all right
thank you Ken thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>