<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Split Snapshots: A New Approach to Old State Storage | Coder Coacher - Coaching Coders</title><meta content="Split Snapshots: A New Approach to Old State Storage - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Split Snapshots: A New Approach to Old State Storage</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6dLSAATRWCc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">oh um welcome let's go ahead and get
started um so I'd like to introduce Luba
sharira lubisz a professor at Brandeis
University and she's she was a postdoc
at MIT when I first met her as a grad
student at MIT and she's worked for many
years with Barbara Liskov at MIT as well
and has worked on storage systems and
distributed systems kinds of issues for
many years so not on whoops I just
wasn't holding it close enough sorry
should I repeat all that are we okay now
I think we're fine okay anyway I'm gonna
let Lou but tell you what she's going to
be talking about today thank you tell
people this is actually going to be
videotaped and put on google video so
not that anybody is likely to ask any
proprietary type questions but don't all
right hi so I'm Lou bashira from Brandis
and this talk is motivated by disk which
is so cheap and so such plenty that it's
time to rethink what we want to do with
it and the other motivation is actually
my personal fascination was time and
memory so unsurprisingly i think that
what we should do be doing with disk is
keeping snapshots so i will tell you a
little bit about some of the technical
issues that came up when we were
building this snapshot system so this is
not the first time that it happens with
a disk so a little trip down the memory
lane so by 1984 when they just become
really big it became important to
actually take an account the sequential
layout of the disk because the reeds
really are going fast if you do it
sequentially but if you seek that's
expensive so berkeley file system came
along with the extents and redesigned
the system so you could really are put
out think sequentially then in 91 around
91 the memories became so large that the
berkeley people again said or what is
happened
if every if the memory is so big the
performance of the reeds is determined
by access to the cash so these are less
important so what remains if you are dis
bound well the rights remain so how do
you make rides fast you write them in a
log sequentially again that architecture
didn't go too far because as it turns
out because of various scalability
issues are reads still remain important
no matter how much cash you put in your
server then there are those other front
ends and once you start going out of the
cash into the disk and reeds are
inefficient essentially your arm
performance doesn't do very good and
because it de clusters basically your
data and so requested in the back is
expensive because now you have to read
and put together so that does not really
work very well for large databases then
in 1989 um elephant came along motivated
really by the plenty of disk and this
was really the first the idea was not
new the idea came along earlier but that
was a real first system that actually
allowed you to in a file system to say I
want to run my code as of that time and
you got the complete file system state
and you could run it as of and so around
2005 the disk was became really so cheap
that we thought well maybe you can even
keep it for a long time and I had this
idea that maybe we can finally come to
the state where I can screw in the bulb
of the snapshot sort of in any storage
system that you come and then you can
have those snapshots and that's what
sort of the motivation for this project
so chicken in every pot and the question
is how does your post looks but I will
show you in a particular system how we
did it and try to talk about what it
means for others so disc is chip a store
system can take those naturals of past
eight can retain for a long time
forbes says pass states are becoming
increasingly important for example if
you go to Las Vegas you play the casino
really overnight we'll send you Cupid
coupons and upgrade your hotel room if
you lose enough they also want to know
if you win too much so they keep track
of what was happening before what they
do they basically take the past day they
ship it to Ohio where they have this net
as a storage system which process square
is blindingly fast so by the morning
they can give you coupons so this is not
a very long term past preservation I
think health care increasingly trying to
capture keep your state so you can come
to you know I hope you don't but if you
come to emergency room there is some
kind of information about how your prior
reaction to drugs anything interesting
there so this is information that
probably should be kept per lifetime of
a person and then just couple months ago
Judge Posner for the first time about
the ruling citing the hippie do so after
that's very interesting because
Wikipedia what the lawyers do they
basically ask the questions later what
was Judge Posner thinking well guess
what it's hard to answer this question
because Wikipedia actually is mutable so
you don't it's a bit tricky so no
problem says lawrence lessig you just
need to have Wikipedia as off and in
fact already this exists so now you want
to capture not only the past the state
of the rulings and surrounding but you
want to capture the context so the real
question is how can you capture past
eight in allow interesting analysis over
long time so our premise is that what
you need is back in time execution
capability which allows you to run
read-only code hole with a read-only you
can also do right but just for now
read-only code overpass states so that
you can ask all questions like for
example what was Judge Posner thinking
but also you can ask new questions for
example what was he not thinking so what
can you do with bite with back in time
execution well clearly you can predict
the future because that's what we
analyze fast really there was some
recently some kind of study that showed
that the people amnesiacs who lose the
memory the first thing they lose is
ability to predict what's going to
happen next so you really need the pass
state basically it's only interesting to
predict the future but will allow other
things for example we allow you to
organize may petition to organize your
past for example let's say when the
digital camera came along suddenly you
can take lots of snapshot lots of
pictures and retain the ones you like
but you can imagine you can take other
snapshots of other things and run code
automatically selecting for some
features and returning only useful ones
um maybe you can check audit your past
dates for example databases they can
improve enforce consistency but some
transactions are bad not because the
database made mistake because the user
typed in bad information you may want to
trace the influence of the bad
information and undo the past states so
you could actually audit your memory so
what do you need to run code over passed
its first you need the snapshot to be
consistent now consistency is a notion
which is a relative to the storage
system so let's talk here about
transactional consistency because it's
kind of clear what it means but we have
a way of thinking about it in other
storage systems so you need to be
consistent why because um so the same
invariants home so that your code can
run of the over the snapshot um you want
we want back in time execution of
general code not just can't queries like
temporal databases so you can actually
ask new questions so the phrase ad hoc
nua algorithm sir analysis you want to
let application to choose the snapshot
this is as opposed to snapshot isolation
for example feature which allows you to
you have some snapshot in the past maybe
you want all of them but if you don't
want all of them then one the
application choose and finally we want a
high resolution
our mechanism so you can take as many as
you like and then later we can decide
what we're going to do with that over
time let's look about what happens to
snap shots over time so here is one
question that actually has two parts
where is your past so one part of this
question is where do you capture your
past dates at what level is it logical
like temporal databases or is it disc
level what is it we're in a system are
you capturing the past it's the other
question is where do the past dates live
so most of the systems today that
captured by States put the past it and
the current state together it's all
happy family and therefore the size of
the database grows with the size of the
past so that's not very good if you
think about high frequency past are
snapshots that last hit many years
because now suddenly even if you had
those wonderful indexing mechanisms
which are logarithmic well if your past
is growing at that rate that will affect
your current state the other question is
not all snapshots are of equal
importance some maybe are not important
for a long term today you you cannot
discriminate there is no technique that
allowed to discriminate the past states
we would like to do that another is
inherent tension there is the latency of
access with versus compactness of
representation you may want to trade off
today you mostly can either compress or
not but you may want to keep different
resolutions in other words you may want
to manage your past representation okay
so what we want is we want just right
distance we think that the right
distance is to be non-disruptive so the
past should not disrupt your current
state so we can put it in every storage
system we want it to be online we want
to be able to run code in real time we
want the task to be discriminated want
to represent different path States in a
different way allow some pass states
outlive the others and you want to be
adaptive maybe recent states are more
important so you want to access the more
frequently for example because you want
to run that analysis
go the chooses which snapshots to retain
long-term ok so now if that's what where
is the beef right what is it about so I
try to motivate you that retaining path
States is interesting I hope I convinced
you so under this premise I will show
you how to be creative with your past at
the cost of doing some surgery to your
storage system and I will try to
convince you that it will not hurt but
it really is on the premise that you are
interested in your past States because
if you're not then I would not go to
surgery if I don't need it so since
nobody lives here I assume that you are
interested in pasties and so the
question is how do you retain the test
now everyone retains past incremental
you clearly are not going to save all
your state you want to retain just the
past the parts of the state that changes
so everybody does that it's called
copy-on-write and so let's assume that
you have solar system state and now an
application declares a snapshot so
basically the system thus natural system
has to guarantee that this is the state
when you later ask for Stafford the
system will present you with now next
step the application modifies the stake
so you have to somehow preserve the past
it so how do you do copy-on-write so
this is how everybody does they make the
following reason him they say okay so I
need to keep the past I already have
that passed my current state currently
is the past eight so let me leave it as
it is and let me put the new state
somewhere else so I do one right copy on
write my past is here right so it was a
very simple database right I just showed
you just has three pages and um actually
just to say and here is its page table
right so it's a very simple model of a
storage system
juice and page table at that point so
here is application declare the snapshot
and now it modifies PHP I need to save
the page P so this is the common copy
all right I take the new state and I
copy it over there and I create a new
page table so the boo page table points
to the new state to the current state of
the database it has the same it points
to the same q and w but p is a new state
where is the snapshot the snapshot is
the forward page table right the former
page table and the former state of the
database is the past eight so I'm set
I'm done now what happens over time so
first of all the database and the
storage system are together right there
together because if I modify now W then
it will migrate somewhere else and it's
all together that means the database
gets de clustered over time so i will
have to reclass stir it so I call this
approach rent it's very cheap in the
first place but long-term you have to
pay something everybody does that
postgres immortal that's a sequel server
database annette appliance waffle see
BFS extra cup everybody does is no
overhead cow except the guys who have to
show tpc results so Oracle and sequel
server they don't do that because that
costs yes he usually not the way the
story is already
yes the way later basis or organized so
this now the page is my grave right so
if you put together remember the fast
very fast file system said it's
important to put things together so
databases do a lot in clustering data
they put things that I read together on
this together so you can read you read
sequentially so do you lose that feature
if your pages get de clustered all over
our the database so our approach is
different approach called the split
copy-on-write so here again here's my
database here's my cable and now
application declares the snapshot and
after that modifies and I'm trying to
make sure I can come back to the past
eight so I copy out before I modify p in
the database in the same place where he
was before I did take P in place I copy
out the pre state of P to a different
place so I did to rights I copied out
the prior state and I updated my current
state and I updated the page table see
there is a page table here that now here
is my snapshot page table if application
asks for snap to run on snapshot v1 I
will just use that snapshot page table
and get the state so let's say let's say
there's another snapshot declared again
v2 and then again there's couple
modifications I modify again p and q so
here are the things i copied out again
before i updated p and q i have to copy
them out because snapshot v2 requires to
see the state before the modifications
of P and Q and here is my new page table
that points to the snapshot v2 if later
notice I update for example w I will
have to go back and update those page
tables right because the state that they
are pointing right now
are pointing to the current state but I
will have to copy out that state that
I'm obliged to keep all right so you
should be asking yourself how could it
possibly what's good about that because
I take this extra right yes the vertical
boxes represent both the page table and
the storage for the pages in the world
this is scarce for the pages in the law
the snapshot store those are the pre
states of the pages that were copied out
and the page tables are also stored
long-term or should be at least
conceptually stored so that you can run
the code first copy yeah you mean in
this scheme right yes yes so a pop is
storage copy yes in the database on the
left side the blue is the current state
so it doesn't change it looks exactly
the same shape as it was the green is
the new is the past eight they're split
I keep the past separately from the
current state okay so first of all as
you can see the blue state is in the
same shape as it was so this does not
the cluster the database but I paid
extra right not only that I will have to
find those pages when my snapshot code
wants to run on the snapshot so you must
thinking well wait a second what's good
about that so one degree of freedom that
i acquire this way because i'm copying
the past eight i have the degree of
freedom to change the representation of
the past in two ways i can compressing
encrypt i can do all kinds of things i
can store round pages it doesn't have to
look like the database pages and i can
put it in a different place I control
where I right so for example if I want
to keep my
past old pass states in the corner of my
data center where can I power down the
disk I can do that if I want to
replicate and put it across I can do
that because I'm already moving it I can
change on the fly it doesn't cost me any
more so I will show you how I can take
advantage of that for example to do no
copy garbage collection generation one
snapshot so I can pull out and other
things which come from that but first
let me summarize so by splitting the
past I get one opportunity which is I'm
not non-disruptive in short term and I
can do in flight search organization
without paying and I bought myself to
problems that extra right that I did I
have to show you how I can be
non-disruptive and my code needs to find
those pages so those are the two
problems I have to solve now before i'm
showing how to solve it i want to show
you how the snapshots are used so the
snappers have a very simple into the
application basically application says
give me a snapshot this natural in this
system let's say it's a transactional
system is serialize like a transaction
the application gets back a snapshot ID
could be number Combinator's you
couldn't call it Bobby whatever but
something you present it back you will
get that snapshot how you present it
back to access a snap you just tell
topic a replica to the snapshot system
here is give me a snapshot and it gives
you the snapshot states you run your
code on the snapshot so what do you get
back so because it's natural just like a
transaction it's well-defined would you
get back if the snapshot is serialized
here after those two transaction it has
to contain all the changes made by those
two transactions and none of the changes
made later if you declare a snapshot
here it has to show when you ask for v2
you will see everything committed before
and nothing after so the meaning is well
defined because we are going to allow
you to discriminate you can actually get
specify discrimination policy for your
snap you can say this is an important
snapshot keep it for longer or other
attributes and the system will do
something for you for simplicity think
about some ranking you know long-lived
short-lived
and then if you cannot decide put make
up your mind right away when you are
declaring the snapshot we allow you to
do it lazily in other words you can
lazily said later give the snapshot ID
and say keep it for longer or something
else ok so this natural system
architecture has includes two components
there is this database storage and there
is snapshot store where we put our past
eight the snapshots system is integrated
at the buffer manager-level it basically
virtualizes the buffer managers view of
a disc so a special copy-on-write
captures the pre state of page p4
snapshot v the first time p is modified
after snapshot v declaration and corpus
rights that pleased that it captured
into snapshot store before it updates p
on disk so the buffer manager basically
plays the following game it captures the
pre-staged and when it's time to write
to the disk it quickly create snapshot
pages and writes them in parallel to the
different disk and this invariant that I
told you allows me to be recoverable
from databases I don't need any extra
recovery mechanism the same mechanism
recovers the database will recover also
the snapshot the snapshot store
interface really does virtualize the
page table and the snapshot page tip the
database storage so the snack fruit is
really just a snapshot page table and
snapshot pages so you can run the back
in time execution code completely
transparently by just mounting a
snapshot page table it looks exactly
like the database and how it runs so
here is your database disk with pages on
this if you don't have the green stuff
you're just a database buffer manager
here is your cash here is a page table
and page table points to pages and if
you're called normally running code
asks for page to access page P then the
buffer manual grabs the page P looks the
page table and brings the disk from the
disks the page but if you are in a
snapshot system like for example I'm
here there is an extra component the
snapshot a store that has a disk and if
application asked to run back in time
execution on snapshot v there is a page
table here mounted for the snapshot page
table for that snapshot and where let's
say application access is the for the
first time page q so that's a Miss so a
request for page q comes in and paige q
has been already modified after snapshot
declaration and therefore it's in the
snapshot store so the page table entry
modified grabs the page and sends it to
the client the client dereferences a
pointer from page q that points to page
p this is the first time the page p has
been accessed so it's a miss so i miss
to page p comes in it go through the
page to a snapshot page table but now
PHP has not been modified since the
snapshot has been declared therefore the
correct state is in the database so the
page table points actually to the page
table of the database and the client
gets the page from the database if some
time later PHP gets modified before the
page p gets updated here the pre state
will be copied out to the snapshot store
in this page table when your next time
mount it will be updated so it actually
points to the pre state of p the one
that corresponds to this state now I
made a picture of the page square but it
doesn't have to look like that in the
snapshot stores can be represented the
way you want all it needs to do is that
when it returns the page it has to look
like a page so that gives me the way
some d.video freedom to play with okay
so here's my first problem how do I deal
with that extra
okay so let's talk briefly what does it
mean to be non-disruptive I say to build
a disruptive means in my system that the
snapshots have to keep up with the
database rights it's an remember my
approach is a by approach I pay
everything up up front so if I just can
keep up that's good enough I will be
non-disruptive right because I just need
to be able to create this past days grab
them underneath the storage system of
course I want to do it without stopping
the application because it's easier to
keep up with application if you stop it
so I have to be non-blocking now let's
look for the moment what does it mean
for a database to perform well what is
latency and there is throughput how do
you get the database to provide you good
latency Yule Log something small to be
recoverable so we don't my technique
does not affect at all this business of
logging so I don't affect latency I will
explain the moment just a bit more this
other part how does the database get
good throughput the database gets the
throughput by writing lazily right the
laser it rides the more times it can
amortize up pages and so on so the
throughput depends on writing lazily so
my skin not disrupt him I have to grab
the pre States and ride them to the disk
without actually interfering with
database ability to update it to do to
get it through put if I slow down the
database that might affect the latency
right sagra taking snapshots in the
system is an asynchronous activity so I
have to make sure the database can
propagate updates at this rate that it
needs to propagate so I characterize the
non disruptiveness with this metric
called imagine you know database you
poor transactions in and the database
buffer manager writes them so there is
poor and drain so
the propagation rate is determined by
right of drain / rate of poor as long as
you are can drain faster than you pull
your non-disruptive so my skin has to
preserve that so let's look at the game
um the cage I will not go precisely the
technically the paper that describes but
basically the key issue here is repeated
modifications why is that when you have
repeated modifications to the same page
the database is doing is very happy
about it because it doesn't have to
write it the database just waits it
absorbs in the buffer the better the
database is of the worst i am of the
snapshot system because i have to write
a frequency natural system has to write
it all so why do I have any hope because
I write sequentially those are snapshot
pages while the database basically does
random i/o so there is some hope here
the other problem is that the repeated
modifications may overwrite in the
buffer cache the pages the snapshot
states that I need to preserve so many
systems what they do they block after
the snack fruit is declared they block
the system and say wait wait wait wait a
second I'm going to write out my
snapshots I don't want to do that so the
way I deal with that again I will just
wait be waving hands I basically keep in
memory enough pre states of the pages
that I all for the snapshot so that when
the buffer manager is about to write a
page I create the required snapshot
pages and write them concurrently to a
different disk what do I pay I need
extra memory to hold the pre States in a
system which has like database which
modifies small parts I don't need a lot
of memory in a system that overrides
completely pages I will need to keep
more memory so that will create so we
analyzed and we show that actually you
highest frequency snap
shots with some extra memory allow it to
be non-disruptive so you can do that if
you are interested in the details then
there's a SED paper and you can look it
up and what i show you here actually is
how the buffer manager look cause the
buffer looks the buffer no has the blue
is this normal buffering manager state
and the green are those immutable states
pre states that i grabbed that i'm using
to create the snapshot pages before
writing database updates just did state
on disk ok so now my other question is
was a department I created was how do i
find the snapshot pages so notice this
problem does not exist in the no
override system it doesn't exist because
no overnight system has it froze the
page table and it froze the database
that so it doesn't have to do anything
it has already the indexing but I need
to figure out how I'm going to give back
those page tables and notice especially
was a change over time right anytime for
example the blue means it's still the
database the page for that's natural but
if it will be updated every kind of come
back and modify it vegetables can be
huge going back in maintaining large
page tables would be very expensive
clearly you don't want to do that now
let's just think for a moment how can
you get the snapshot back so here is one
approach you could do let me just go for
a sec backward um I could for example
rollback I just want to do it but I
could roll back the state here and apply
to the database those pages up to the
place where my snapshot starts I could
get back the correct state but that's
disruptive for a long history right and
we'll also have to apply over very long
roll back that's essentially like
recovery I could also go from the place
where my snapshot start and go forward
so for example I need page p for
snapshot V sometime later
I can start from plip place where the
snapshot started and look for the first
occurrence of P that's API want right
and then if my code asks for Paige q I
can go forward and look for the first
occurrence of page Q because that's the
first time you got modified and copied
and that corresponds to the queue that
corresponds to that snapshot that make
sense but even that is not very good
because I have to scandal where though I
really doing recovery over big chunky
pages I don't want to scan them so
instead what they do I keep pointers to
the snapshot pages so now my pages are
CP was the priest the page the red page
is that was copied after snapshot V was
declared the next p was the one that was
copied after snapshot week to was
declared and so on and I keep pointers
there to those pages so i have this log
of mappings think about Lulu page table
with just mappings for individual
entries which say PHP address in the
snapshot so-and-so page P and I scan
that mapping glob instead of the pages
so mappings are smaller and therefore my
scans go faster if my so this is my
indexing method it right it's predicated
for copy-on-write snapshots there is
this notion first encountered mapping
that's the first mapping that I was
found that's what I'm looking for so i
would i need to do to run that I just
need to remember where were the first
time I copied and notice i have to write
the mappings in the correct order the
order invariant is that the mappings
retained for snapshot v have to come
before snapshots nothing's for snapshot
v plus 1 so this way when I scan I will
find the right napping but notice I
don't have to control the order in which
the pages are written I just have to
make sure that the mappings are in the
correct order that's actually very
important for third part implementations
because I can track the buffer manager
as opposed to manipulating how it rides
and the mappings are smaller can reorder
them in memory so the lookup is then
scan the map map log what is what my log
is cold and collect those first
encountered mappings now this is great
better than scanning pages so let's
think about performance of this scheme
so if the database is updated uniformly
in other words you have n pages and the
infant probability of updating any page
then after approximately and login
updates this is a standard coupon
collection problem you have overwritten
all the pages of the database so after n
log n our gates you will have the entire
database copied out into the snapshot
log and therefore the mappings right so
here is your the database will be up
there in the page long the mappings will
be here and so when you start scanning
looking for pages of snapshot v1 after n
log n mappings you will find all the
nothings for your snapshot so when Logan
the problem is database updates are
actually not uniform database updates
are skewed some pages are very cold it's
actually well known log structured trial
system cleaner algorithms have seen that
some pages are very rarely modified once
in a blue moon and yet that doesn't mean
they're not accessed frequently so you
have the problem I have the problem that
even though writing those mappings is
very cheap but scanning to find a
mapping for a cold page may have to pass
over many hot mappings which will occur
all the time because the more cause
really have some things that are very
hot and some are cold and I have to my
scans are very long long so we have this
super simple approach like a charm very
simple the idea is the problem scanning
here is wrong is because you have many
duplicates so instead we create another
layer
her which drops the duplicates so what I
do looks like a fast lane I start
scanning here and then I go over to that
fast lane and I have a variant which
says if I do that scanning here the
first encountered mappings that I will
find when I start scanning for V here
are exactly the same first encountered
mappings I will found when I scan in the
fast lane right so how do I do that so
for example here I had this is the
mappings that were copied after he was
declared so there is p4 p5 again before
because we to was declared then p 5 so
in the upper area I copy p for the first
time p 5 I don't copy that because when
I copy from here I don't need that so I
don't need here and then when I finished
if I stop here I scan here up to here I
have no choice but from there on I go up
and scan the fast lane and there there
would be exactly the same see the pic
there will be no p want you want to go
only once if you want this one will not
go to will be there this p1 will not so
I could essentially collapse the
duplicates over a chunk right I
eliminate duplicates across the chunk
what is this junk corresponds to it
could as opposed to basically the i/o
unit that you want to read from the disk
and keep in memory and while in memory
I'm collecting those mappings I am also
collecting those mappings at the same
time and the more skewed is the workload
the better this scheme works because it
just doesn't keep the repeated
modification so we analyzed it and we
implement it and it really works really
well we just need a couple couple layers
and you are done so this is the first
index for copy-on-write snapshots that
actually is both right optimized because
writing those extra sequential logs is
very you know they're not they're cheap
and it's also read optimized you can
scan and what it does it essentially
brings down the cost of scanning
a snapshot a long-lived snaps rotten
exeggcute work alone to the cost of
scanning a short-lived snapshot uniform
so that's the best I can do so it's
disco your optimal for both rides and
look up it allows to run cold in real
time over multi-year snapshots and it
actually its performance matches the
fastest temporal indexes like tsb and
snapshot in terms of look up but we're
cheaper in terms of writing because we
write sequentially and they indexes you
know you have to update them so they're
actually a random so we're going to help
you with that now I have about 10
minutes love that okay so i will tell
you one more story so i told you about
how to overcome that problem of extra
ride I told you how to find the snap
just now I want to tell you how do I
take advantage of this new freedom that
I got which is reorganizing so I
discriminated snapshot storage so all
right let me remind disc is cheap you
can keep it over time however it's not
even though the desk HT but babysitting
the disc in a data center actually costs
you energy bills so if you need the
state you want to keep it but if you
don't need it really it's a you may want
to get rid of it or maybe you want to
put it in a place where you can power
down the disc today you cannot
discriminate in those past days because
basically you have this copy-on-write
status altogether you also may want to
keep some some snapshots with better
access than with other today you cannot
adapt so we're proposing this new
feature called discrimination it has two
parts there is a policy and a mechanism
the application specifies the
discrimination policy so it can say this
snapshot is more important which means
it will stay for longer and it can do it
either eagerly right away when it
creates a snapshot or lazy later
the system provides the discrimination
mechanism that in retains the important
snapshots for longer or stores them with
faster access so let's just review how
the snapshots are created okay so there
is no you're useful notion is this the
span of the snapshot which is really the
transactions between that snapshot and
the next snapshot and pages retained for
a snapshot are the pre States of the
pages that get updated in this spam so
let me give you an example that would be
simple so let's say I have a snapshot
before I declared it and now here are
transactions that commit modifications
to page is p s and P again and here is
the new snapshot v5 so I say the span of
snapshot before is this transaction
sickness sequence and the page is
retained for snapshot before our P the
pre state of P and the pre state of s
but not the pre state of this speed I
don't need it right because I already
retained the prison that corresponds to
snapshot before and so on right so this
is the two notions I need to explain
okay so if you look at the snapshot
store right if the snapshot starts here
the pre the page is retained for viv for
the snapshot for our the red ones this
is the mappings and the yellow ones are
the pages retained for snapshot v5 now
what happens if I want to do garbage
collection so if i do the policy is
aging meaning i want to chop off the
kale so all snapshot go away first then
in this system there is no problem
because I want to basically discard cage
is retained for v4 before pages detained
for v5 I just chopped off the red one
and I forget about it that's really easy
but what if the application actually
told me that it was to retain v4 before
the
portant one every five is not then I
retain I have to retain the P up there
the red one p I have to retain s I don't
need the yellow p up there because that
belongs to the v5 and I already have my
p what about Q I need the Q because Q
right was the is that the first
occurrence of Q that i will need when I
scan so if i discard the P I get the
whole so I get the fragmentation right
now normal snapshots the no override
snapshots you get fragmentation if you
try to pull out the snacks in the middle
either way so you cannot do anything
about that yes discrimination policy
says like really press an exchange for
vote for slower access time I might want
to press the later peels Delta from
earlier visits desktop in which case
this picture that's what I'm showing you
just garbage collection in other words
there would be different policy and I
have to apply different mechanism this
is just a mechanism for doing garbage
collection right ignoring the speed of
representation is exactly example got
good point ah fragmentation is not good
fermentation is not good because you get
overtime non-sequential page rides and
then you get in order to the class that
is back you need to read and write and
that's expensive and it's hard to bring
on the slug non-disruptive if you need
to do essentially cleaning copy out so
we don't want to do that so here is an
approach to do garbage collection no
fragmentation and without copying right
so the rank the application gives you
the rank of a snapshot when it declares
the ram determines the snapshot lifetime
what I do is I put when I copy out I put
the long-lived
and the short-lived snapshots in
different places now as you have seen
some snapshots some pages belong to two
snapshots both long and short so I put
that joint pages with the long-lived
guys and I also create an index for
every separate snapshot rank and I make
sure because the snapshots the shared
pages go with a longer lived that the
pointers the index pointers only point
from short-lived areas into long-lived
areas and never point from long-lived
into shortly and then when I collect in
each area I do a gym so I just take it
out and throw it out eventually no
fragmentation whatsoever and I haven't
copied I didn't touch the disc so that
allows you to do essentially
generational garbage collection for your
snapshots without touching disc just by
doing the right kind of copying so this
looks like this using so here is
snapshots right before the guy we talked
before about is the important guy so it
was declared to be the long-lived but v5
and v6 and other guys there shortly here
is my short-lived area where there is
long-lived area and here are the indexes
for longley for short lived and for
longer and indexes point to the pages
there so when page p gets modified after
v5 for the first time the page p is both
a page that belongs to V 5 snapshot and
before but because this is the first
time it's modified after before it's
shared page I have to put it in the
long-lived area so here is it's up there
but notice it's being pointed from both
short-lived and long live Q here is
modified for the first time after v6
so it belongs to v6 and actually all the
other previous guys again it's a shared
one it goes out there and it's pointed
from both this P though is modified
after v6 but it's not it only belongs
two v6s well below doesn't belong to
either be fat to be five so it stays
here and it's only pointed from the
shortly so when I get sick of the
short-lived snapshots I just yank the
short-lived area with its index and I
stay with them yes
could easily with the limited exactly so
this is another approach called lazy
discrimination which is what you say
maybe I use cold so what I do when I do
it lazily I necessarily have to copy
because i didn't know in advance where
to put it so the game i play i change
the representation so my copying is
cheap alright so the game i play i
basically represent my snapshots now in
a way that we were sort of eluding i
make them look like a database log a
little bit checkpoints and diffs so by
just make keeping snapshots as divs they
become very compact if if modifications
are small which often are so then when I
need to copy them it's cheap for me to
copy just the diffs as opposed to copy
the entire pages but of course the
constructing accessing snapshots based
on dips takes a long time so I insert
like a database checkpoints the
checkpoints are just page based
snapshots the regular guys so look
what's interesting so the back in time
execution is very simple right you
basically put up your checkpoint and
then you roll forward with it with the
divs that's how you get to run but here
is how it looks the lazy discrimination
what it does it copies the divs so okay
so I just click declare the snapshots
and then later you come to me and you
say that's natural I declared there
actually is important I want to keep it
for longer so I have to get rid of the
other guys so what i do i will copy out
the diffs but the checkpoints the system
controls them so the system can decide
whether they are determined their rank
and because it can determine their rank
I can garbage collect them without
copying in the old way by just writing
them in the right place so let me show
you how it looks so here is the
representation here is a checkpoint and
here are the diffs
corresponding to that checkpoint then
there is another checkpoint it was just
snapshots right but those are page based
naps like keep them in different places
and here are the diffs corresponding to
this nap checkpoint so if you want to
run a back in time execution here you
just need to mount this snapshot and
then apply the diffs ok so if
application later tells me how to
discriminate the snapshots I have to
copy out the diffs that I need up but
the checkpoints I decide when I create
them I calculate whether they are
long-lived or shortly so what happens I
put the short the long-lived pages here
as I create the checkpoints exact
because a checkpoint is just a
long-lived page based naps that I showed
you how to garbage collected without
touching so when time comes to get rid
you know if I need to squeeze out those
two checkpoints because basically I just
need that one and those gives this role
that goes away the same way and I am
staying with this one because i could
write because the system creates the
checkpoint so it can copy out so there
is more I have to stop now because it's
getting close I can also this is slow so
I can make it faster I can in other
words let me just go forward to the
conclusion because back in time
execution alright so so we have the
system running with a snap the
non-disruptive system runs on for some
people here are familiar with store snap
Sanjay had some work in that there is
treasure our garbage collector runs we
have a paper in use nukes describes all
those garbage collection schemes hours
newest index the old system used a kind
of slow index but the new one index I
just showed you we have it implemented
in snap and now in BD beats in review
and the performance looks really good
you know the questions are very simple
about foot performance how fast is your
back in time execution how much does it
cost you to garbage collect and how long
disruptive are you in other words can
you really go forward without paying so
let me just summarize I don't really
have time to show you because the matrix
our eyes they explained they talk about
rank about non disruptiveness as being
the ratio of pouring and raining and the
way I measure the draining is how long
it takes for me to clean one page in the
database so I measure it in the system
that has no snapshots in the system that
has snapshots and I see how long does it
take me so that's my slow down for the
drain of poor and control some
parameters which is really the
overwriting and density as I explained
and they check it for busy database and
database that is works really long load
because the interesting question is what
happens if you have a lot of time this
easy to be non-disruptive but what
happens when you are busy so here is the
only thing I want you to tell you about
the busy part what's interesting about
this skin when the database becomes
really busy and I want just to show you
them picture what happens how does video
becomes busy there is more clients more
transactions submitted what happens in
the database when the load grows you get
mrs. in the cache the database starts
reading from disk when the database
starts reading from this it actually
slows down because it pays it now in
order to produce an update it has to go
to the disk to read this is a really
great news for the snapshot system
because now the database pays more to
produce that update so me this natural
system I don't pay more I have more time
to shovel them to the disk so this is
what you see here when they run it with
one client and for client this metric I
had known disruptiveness drops but when
i get to eight clients in my system runs
at full capacity suddenly i do better
so that's actually good news in other
words I have I do better when the other
guy that's worse that's all so I showed
you basically the higher order bit is
split copy-on-write snapshots of baskets
at run code in real time retained a disk
block level with garbage collection are
cheaper than you might have been
thinking and the take home is really use
natural techniques keep your past
current statement disruptive
discriminate past I showed you in a
storage system techniques which in a
transactional we have some ideas how to
do it in a file system I want to talk to
those people that I talk today from UCLA
yes how do you do it in a file system it
seems like there is a good chance with
your mechanisms to do it and the
questions what happens in your storage
system right we can do it in a bit EV
but what about your if your it is in
past that's it any questions yes how
does this relate
I absolutely because you know what is a
virtual memory it's a cable and pages so
all you need to do is to keep your let's
skip index that I have right that allows
you to basic that model captures exactly
so you can do that all right
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>