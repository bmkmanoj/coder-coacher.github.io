<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Regret-based Methods for Preference Elicitation and... | Coder Coacher - Coaching Coders</title><meta content="Regret-based Methods for Preference Elicitation and... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Regret-based Methods for Preference Elicitation and...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6qFdXIFawhs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">our pleasure to have a second to talk of
the day in this very room with experts
in probabilistic in statistical
reasoning cricos beyond that to also be
an expert and
Markov processes partially fully
observable and elevates right thanks a
lot Peter it's a pleasure to be here
it's not often one gets to meet with the
brain trust behind responsible for a
piece of software they use more than
anything else in your life so that's
fantastic and I'm really looking forward
to having the chance to chat with some
of you folks to you know talk about the
challenges I think the research
challenges that you're facing are
probably some of the most intriguing and
provocative on the planet these states
so I'm really looking forward to the
rest of my day and half here so before I
get into my talk which is on as you can
see regret based preference elicitation
and mechanism design let me just say a
couple of words about myself as Peter
mentioned I've done a lot of work in
markov decision processes both fully and
partially observable generally speaking
on I'm interested in any problem that
has to do with decision making or
optimization under uncertainty and its
many in various guises and that includes
game theoretic and excuse me game
theoretic and economic models more
recently and something that I will say a
few words about in the talk today
depending on how time goes in particular
over the last say three or four years a
lot of my work is focused on the problem
of preference elicitation and that
actually does relate to mechanism design
in ways that I hope will become clear in
a couple of minutes real key question is
why mechanism design what is so
important sorry why Mac and why
preference elicitation what's so
important about this problem well we in
AI when we think about decision making
or decision making under uncertainty we
usually have in mind that we're making
decision on behalf of some individual or
some organization we're doing something
for somebody one way to think about it
is that we want to match individuals to
two products that they desire
information services other individuals
or even when you're thinking about
planning we want to match them to the
appropriate courses of action or
specific behaviors that they would find
desirable
but of course decision making for me
means optimization optimization means
having some objective function the key
question is you know what is that
objective function and obviously if
we're acting on behalf of somebody that
objective function needs to represent
the user's preferences yeah and this is
what i like to call the preference
bottleneck in AI in order to make
decisions on somebody's behalf we have
to know something about their
preferences okay so a lot of the work
that I've been doing over the last
couple of years some of it's been
focused on preference elicitation a lot
of it and this is what I'll be talking
about today deals with the problem of
preference elicit preference assessment
actually more more broadly speaking
either direct assessment in direct
assessment to the sequential or the
one-shot assessment of individual or
organizational preferences in particular
in problems that I I view as hard
optimization problems combinatorial
optimization stochastic sequential
optimization problems things of that
nature and thing that a key question
that guides most of what I do is the
following what preference information is
most relevant to the task at hand and is
the cost of assessing or eliciting that
information does that is does that
outweigh the value of the information
itself when it comes to making object
level decisions okay you know I hate
these kind of box and arrow diagrams but
I just want to flash this briefly to
give you a sense I'm going to be talking
today about direct preference
elicitation where we ask users
specifically questions about their
preferences in various forms but when I
think about preferences assessment I
have a much broader view in particular
if we have some age and that's making
decisions on behalf of a user possibly a
stream of decisions over time there are
a number of things at any point that
that that we can do in order to assess
the user's preferences we can explicitly
ask them queries we can sit back and
passively observe how they act and
exploiting the notion of revealed
preference going back two decades old
work in economics we can be passive but
but let me call it semi passive we can
manipulate somebody's environment to
find out how they react and get
information about their preferences that
way without explicitly asking them
questions okay and of course we can take
various decisions on their behalf and
see how they react see if they're
appropriate or not okay we can rely on
the information the preferences of other
users as one might in a collaborative
filtering setting and so on and so forth
so there are a lot of different modes of
preference assessment and in terms of my
my overriding interests it's to develop
agents that can do all of this and
integrate all of these various sources
of information just to give you a sense
here's a here's a project let me just
click on this there we go the project
that I'm involved in with some
collaborators and occupational therapy
and some of the hospitals in Toronto
it's called coach this is a prompting
system for for patients with Alzheimer's
with moderate to severe dementia who
have a very difficult time getting
through even the simplest activities of
daily living such as washing their hands
I've got the audio off here but the
system is actually prompting this
gentleman to do various things when it
appears that he's confused so the
question here is when should we prompt
somebody how should we prompt them when
should we intervene and call the
caregiver to come take over and make
sure that the user can get through can
get through the task okay so why do we
view this as where does preference the
assessment come in here well in fact
there's a very difficult preference
assessment problem we solve this we have
this great big palm DP that we solve in
order to in order to do the prompting
but the difficulty is assessing the
reward function dynamics are easy to
learn there they're probably a thousand
people in this organization this company
that could tell you exactly how to learn
the dynamics of such a process but when
it comes to assessing when it comes to
assessing the reward function in an MDP
or upon DP we've got real difficulty
here because caregivers cannot
articulate what it is that we should be
doing and why over this temporal stream
of events okay so here we're looking at
problems in a problem where we have to
rely on indirect assessment by looking
at caregiver behavior by looking at by
having them critique the policies that
we produce and so on and so forth let me
skip this just in the interest of time
another problem that will talk about
which involves direct reference
assessment I'll get into a little bit of
detail here because I'll be talking
about elicitation methods for this
problem specifically this is a problem
of winter determination and
combinatorial auctions so I don't know
how many people here are familiar with
what goes on in the sourcing or
procurement world these days but
expressive bidding in auctions has
become has become very very common in
things in areas like sourcing logistics
procurement and things of that nature so
rather than having a supplier say I will
provide you with a particular good at a
particular unit price bidders can now
packaged up what they offer to to a
purchaser and say look I can offer you a
if I can offer you a at a certain price
per unit but if you give me so much
volume i'll actually discount the price
per unit by twenty-five percent or i can
give you a at this price but if you also
let me provide you with be i can
discount what I give what I give a to
you for and so on and so forth the basic
idea is that if we've got expressive
expressive languages that allow these
package bids various side constraints
discount schedules and so on we allow
bidders to directly express their
utilities or the cost function thereby
leading to greater economic efficiency
of course this degree of expressiveness
means that it's solving what's called
the winter determination problem given a
set of these bids how should one
allocate one's business it now has
become rather rather than a simple
problem becomes very difficult
combinatorial optimization problem but
companies such as combine that a company
that I do a little bit of advising for
have have been developing techniques
that allow one to determine the least
cost allocation of business to bidders
in very robust ways for very very large
procurement problems
so that's great where does preference
elicitation come in well obviously
having bidders provide expresar cost
function can be viewed as a form of
preference elicitation but even the bid
taker or the purchaser exhibits complex
preferences over the allocation so we
might imagine a Joe here that Joe here
offers to provide to a and B for twelve
thousand dollars C and D for five
thousand dollars Hank comes in and
offers another complex bid you get a
whole bunch more of these bids you run
your winter determination algorithm
basically a weighted set packing problem
but a very large one and it comes back
and says well you know you should get a
and C from Fred and B D and G from Frank
and so on it's going to cost you fifty
seven thousand dollars and then the bid
taker says but that's no good it gives
too much business to Joe ok what's
happening here is that the purchasers in
this case have prices have preferences
for non price attributes of the
allocation they don't care about
minimizing costs alone which is the
focus of these combinatorial
optimization algorithms but they have
preferences for non price attributes
they might not want a particular
supplier to get too much volume for
example because of the risks associated
with it or they might want what might
not want to supplier to get too little
volume because they've got a long-term
relationship with a particular incumbent
they mayor care about the average
quality of the product that's being
produced they may not want too many
winners too many suppliers or too few
suppliers for various reasons and so on
it's very clear that purchasers have a
particular utility function in mind the
problem is they're very uncomfortable
articulating precise trade-off weights
if you ask them what would you pay to
reduce a percentage volume of your
business in this procurement auction or
sourcing event that went to Joe by 1%
they'll say well you know maybe five
hundred thousand dollars but you know no
more than then you know 1.2 million or
something like that ok they have a hard
time articulating with any sort of
precision exactly
what their preferences are and how they
should be traded off against cost all
right so those are a few examples what I
want to talk about today and I will get
back to this procurement / sourcing
example in a few minutes I want to talk
today about the using the notion of mini
max regret as a way of of doing robust
optimization under utility function
uncertainty what we'd like to do is
illicit enough information about the say
the bid takers preferences to be able to
make a good or perhaps optimal decision
on their behalf but without completely
nailing down their utility function okay
so i will talk about the general model
that we've developed in a number of
domains so i'll give you this the
specifics of the formulation for the for
the sourcing example then move on to
talk about how minim acts regret can be
used to drive preference solicitation to
determine what are good queries what is
the relevant information that will help
us make better decisions on behalf of
the particular the particular user and
then depending on how much time we have
I'll talk a bit about mechanism design
with partial revelation as those of you
familiar with mechanism design are aware
you know mechanisms are basically
eliciting utility functions from people
there by facing what facing this
preference bottleneck so we've been
working recently on the design of
mechanisms using partial revelation of
utility function or types using some of
these minimax regret techniques to
decide how best to design mechanisms all
right so let's jump into the into the
details here basic decision problem just
to set the terminology we're going to
assume that we've got some multi
attribute out outcome set I'll call it X
plus here over a set of attributes x1
through xn I'll assume that's got a
finite set of attributes each with
finite domains it's not strictly
necessary but it'll ease the
presentation so to speak we'll also have
a set of constraints on the set of on
this this multi attribute outcome set
defining the feasible outcomes these
might be logical constraints it might be
constraint satisfaction problem for
example the
the feasible outcomes might be simply
the elements in a particular product
database they might be the outfit might
be the outcomes of some complex
optimization process as we'll see in
winter determination feasibility can
actually be very difficult to determine
in some cases will assume that we've got
a user utility function mapping the the
outcome set into the reals telling you
how good or bad a particular outcome is
soo particular user generally this
utility function will be parametrized
fairly compactly say with some weight
vector W in a lot of the work we use
linear models or additive models I'll
show you an example of that generalized
additive models things of that nature
our goal then is to find an x star that
maximizes the users utility among all
feasible among all feasible outcomes
okay and generally speaking this will
require some optimization louth solve an
LP do some dynamic programming a mixed
integer program something of that nature
okay of course that's great classic
classic decision problem but of course
as we know user preferences are often
unknown be and they very much more
widely than dynamics okay it's very hard
to predict what a particular user will
want us to do okay and that this is
basically the preference bottleneck that
I've already alluded to okay our goal
one of my personal goals is to automate
the role of the decision analyst I would
love to have a decision analyst sitting
on my desktop okay of course decision
analyst face very difficult questions we
know that people have a very hard time
articulating their preferences with any
degree of precision certainly numerical
preferences and we're going to have to
account for that but we also have some
other questions that we need to address
in particular we want to ask well when
is what preference information is
relevant to the particular task at hand
I don't need to know everything about
your utility function to be able to
decide that this is a good decision if
the feasible outcome set is fairly
restricted second question is when is
the elicitation effort we engage in when
we get some information from somebody
about their preferences worth the
improvement that it offers in terms of
quality okay generally speaking I could
I could take a long time and oppose a
lot of say cognitive burden on a
particular user to find out exactly what
their preferences are but it may not be
worth the improvement that it offers me
in terms of underlying decision quality
I may be able to make a good decision
without knowing all of that okay if we
admit that then we know that we're going
to have to make decisions with partial
utility function information okay if
that's the case and the question
naturally arises what decision criterion
should one use because you can't
maximize expected utility for example if
we don't have the users utility function
in hand okay so I want to start with
that last question what decision
criterion should one use when making
decisions with decisions with incomplete
objective function information or
incompletely standing completely
specified utility function so I'm going
to talk today about strict utility
function uncertainty I'm going to assume
that the users utility parameters W or
unknown but that they are known to lie
in some feasible set w okay where W for
example is defined by a set of linear
constraints on on the on this weight
vector okay where these linear
constraints will come from well
generally it'll be the outcome of some
elicitation process and we'll get into
that in just a few minutes okay so what
we've got here is what will call and
unquantified or strict approach to
uncertainty I assume your utility
function is in this set but no more okay
this is in contrast to say a bayesian
approach we might have a density over
the space of of utility functions don't
have any problems with bayesian
approaches its it's something that that
I've worked with in the past and
continue to work with but there are some
advantages to to looking at this this
this strict uncertainty model so now a
key question is if this is all I know
about your utility function how should I
make a decision okay what I'm going to
propose is the notion of mini max regret
or I shouldn't say proposed and going to
advocate the notion of min and Max
regret which I'll define in three stages
and then say a few words so try to
motivate or justify will say that the
regret of a particular outcome x given
that the users utility function
you is simply the loss incurred by
taking decision X rather than acting
optimally given the users given the
users utility function is in fact w okay
so how much you lose by not acting opt
only by doing X instead the max regret
of a decision since I don't know the
users utility function only knows it
lies in this big set w the maximum
regret is this what is the worst is the
worst case loss given that an adversary
could select any utility function within
w okay so if I were to do X and
adversary could make me regret X by this
much ok then we'll say that the minimax
optimal decision or the decision that
minimizes maximum regret is that
decision that that gives the adversary
the least power in that respect ok so we
basically want to choose the x star that
minimizes max regret in the presence of
such an adversary alright so I hope
that's fairly clear I'm going to go over
this very quickly why would we want to
use mini max regret as opposed to other
criteria that people have considered in
in robust optimization like Max and min
well obviously the we've got a certain
robustness in the face of uncertainty
here okay in in particular if if we're
concerned again about this worst-case
loss okay then this is the right thing
to do okay now one can say well this is
very cautious but there are a number of
reasons which I can get into maybe maybe
later why I still think this is a much
better approach than say max and min of
course if one has priors then of course
one could be bayesian about this and and
not be quite so cautious but it turns
out that even when we've got priors
available that using minimum X regret as
we'll see can be a very effective driver
of preference elicitation okay obviously
it's useful when priors are not readily
available and in our experience it's
much more tractable actually to
do the reasoning with the strict
uncertainty sense okay so how does one
go about computing minimax regret very
briefly let's write out this is sort of
the obvious formulation in a very
generic form we have to go on a min min
over our choice of outcome and then let
the adversary max over the choices of
utility function and in this adversarial
outcome the difference between the
utility of the adversaries outcome under
that chosen utility function and our
outcome okay so in terms of making sure
that we can compute these things
effectively and quickly well we've got a
couple of problems first of all we've
got a mini max program so we don't have
a straight forward straight forward
minimization for example we've got a
quadratic objective which we which is
not a problem in general but for integer
programs it's going to cause us some
some difficulties so the general
approach that we've been taking in many
of these domains is to use benders
decomposition I'll explain this in a few
minutes for those of you not in the math
programming world vendors decomposition
and constraint generation to break the
minimax program to convert it into a
minimization and then we use various
encoding tricks to the linear ICS
quadratic components okay and of course
the details are going to depend on the
specific problem or formulation all
right we've been looking at this in the
context of a number of different
applications product configuration
resource allocation and autonomic
computing recently been doing some work
on robust the robust solution of markov
decision processes where we don't know
the reward function precisely what i'm
going to talk about just to give you a
flavor of how these formulation work
formulations work is win or
determination in combinatorial auctions
in these sourcing problems okay so first
let me just again set the groundwork and
then i'll describe how we go about
computing computing minimax regret going
to be talking about a reverse
combinatorial auction settings really
quite simple we've got a buyer who
desires collection of items g-got
sellers who can offer bids on bundles of
these items
abid is basically a collection of these
items and a particular price with which
you're willing to offer that collection
we can have a lot of sweets various side
constraints and we can make this more
expressive if we'd like but this is this
is sufficient for our purposes here
feasible allocation is basically any
subset of the bids that covers the
buyers needs G ok we're going to let you
zex to denote the set of feasible
allocations and the winner determination
problem is basically to find the least
cost allocation that covers G ok the
least cost feasible allocation ok but as
we saw earlier generally purchasers have
preferences for non-price features so
they care about things like the number
of the number of winners geographical
diversity of their suppliers things of
that nature so we're going to sue me
I've got a finite set of features f1
through FK that they care about that
we've got a quasi-linear utility
function so basically have linear
utility / outcomes less the cost of the
allocation ok we have ways of
generalizing this if we've got non
linear nonlinear features and or
nonlinear tility for features but this
will illustrate what we need to do here
so we're going to assume the user has
nonlinear utility quasi-linear utility
function but we don't know the weights
we don't know the parameters all we know
is that it lies in some polytope w ok so
you write this out and we basically have
the same in MX or bread equation with
where we look at the difference between
the weights x the adversaries features
less our features and the difference
between our costs ok and we want to do
this optimization ok again minna Max and
quadratic right so how do we get around
that well first we can take that mini
max program and convert it into a into
an integer program simply by minim by
minimizing over our choices the
minimizing over X are the outcome that
we'd like to choose delta which
corresponds to X is max regret subject
to the constraint that delta is greater
than the actual regret for any choice
the adversary could make of utility
allocation and
utility function okay unfortunately this
is going to have infinitely many
constraints two simple observations so
let us let us break that first of all
the active constraints here can only
occur at a vertex of the polytope that
should be fairly evident second given a
particular utility function say W at one
of the corners of this polytope the only
thing the adversary should do to make us
maximize regret is to do the optimal
thing at that the optimal thing for that
utility function if he does anything
less he's losing advantage relative to
to our choice okay so all we need to do
then is rewrite this thing by minimizing
delta subject to the constraint that
it's better than the regret we would
face at any corner of the polytope given
that the adversary does the optimal
thing at that utility function okay so
that's great as far as it goes but again
we don't like to enumerate vertices of
polytopes and anything but you know
something where we've got maybe two or
three features so we apply constraint
generation procedure again pretty
straightforward we're going to assume
what we're going to do is basically
going back here is solve various relaxed
versions of this of this of this integer
program will start by throwing into a
set gem a set of an arbitrary feasible
allocation and an arbitrary utility
function we're going to then iteratively
solve that same LP but only with the
same IP but only with the constraints
the only with constraints corresponding
to those in this set gem two pairs in
this subject at any point we're going to
get a solution to this relaxed IP look
all that thing x star and it's going to
have objective value Delta star
basically this is giving us the
allocation X star that has minimum
regret minimum sorry minimax regret if
we were to tie the adversaries hands and
say you're only allowed to pick utility
functions and allocations in this
generated set okay and Delta star will
be the solution Delta star will be the
max regret against that restricted
adversary okay
but of course we don't know if this is
the minimax optimal solution because
we've tied the adversaries hands so then
we just untie the adversaries hands and
say alright I'm proposing this is a
solution how much can you actually make
me regret it if i untie your hands ok so
we solve the the an integer program will
tell you about this in just a second on
the next slide we compute the max regret
of X star against up with respect to W
this will give us a solution sorry this
will give us a solution let's call it X
double primed and w w mm that which is
basically the adversaries choice the
witness the adversary will will you will
will compute to prove that the max
regret of X star is in fact some value
are ok so this is the max regret of X
star now if R is greater than Delta star
we know by untying the adversaries hands
he's been able to make us regret it more
so obviously we didn't have these
constraints weren't tight enough so
we're going to throw this thing into the
set gem all right and iterate however if
our was equal to Delta star can't be
less than Delta star if it's equal to
Delta star every act of constraint every
active constraint or that all we need
has is is actually present in the
solution here ok we've given the
adversary no more power we know we have
the minimax optimal solution ok notice
that basically what we're doing at this
stage is computing the maximally
violated constraint and throwing it into
the throwing it into this IP ok now in
the interest of time I'm not going to
say anything about this computation this
is where some of the quadratic stuff
comes in and we've got to get a little
clever with respect to particular
formulations all right this is this is
the computing the max regret program we
end up with quadratic with quadratic
terms here because the adversary has to
choose an allocation and utility
function but there are various tricks
that one can use to to linearize this
thing so i'll skip over that ok yeah
yeah
restricted set is the idea that you
believe that most of the action is
actually going on in the polytope
well i won't i won't say that it's a
little corner of the polytope but what
we'll be doing is basically slicing off
good chunks of the polytope to say well
okay if this is all I let the adversary
do if he's only allowed to pick
something in this corner okay then then
you know I would do something here right
then we untie him and he's going to you
know choose a different corner all right
we're going to then compute the minimax
regret when the adversary can do either
of those things right and so basically
we're starting to start slicing off
various bits of the top polytope until
we're basically you know forced into a
particular region right so we're not
necessarily focusing here's what well
empirically we do okay it it's an
imperial it's a purely empirical
question okay and it turns out that it
actually does in in in a number of cases
this is a very small very small problem
from combined net right that's these are
these are tiny procurement auctions or
sourcing events okay here's a very
simple problem has six features I think
it's got on the order of maybe 150
vertices they actually did the
enumeration constraint this is the
number of rounds of constraints
constraint generation until convergence
over a hundred instances right it maxes
at eleven okay on average it's around
for four and a half okay so it actually
does work very very well okay these are
some other these are some other examples
very different domains it's not sourcing
but its product configuration very large
problem utility functions with 160 160
parameters so that the polytopes are
huge okay and here we look at as a
function of don't worry too much about
the details here we're seeing we're
showing how tight the initial polytope
is what we're showing is the number of
constraints that are generated okay a
scatter plot over again 100 instances
okay and we see it's on the order of 10
to 100 okay so we actually do enumerate
very few of these things
practice okay but it is a purely
empirical question now the one thing I
should note you should be concerned
about solution x like 19 seconds and
here solution x ranging from 10 up to a
thousand seconds for some of these
problems okay it turns out that this
algorithm a because we've got IPS so we
can stop we can terminate early once the
gap is sufficiently small and B because
it's an earlier in an iterative process
it turns out we can cut this thing short
with approximately minimax optimal
solutions and it will do a very good job
with respect to preference elicitation
and i'll show you that now because we're
going to jump into preference
elicitation okay so let me just oops
jump ahead okay that's just to give you
a flavor but of how many machs
optimization works now how do we use
this for preference elicitation
basically the question is this we get a
mini max optimal solution given what we
know about the users utility function
may not be satisfied with the quality of
the solution right though the loss may
be too great the regret may be too great
so obviously one way to improve quality
well the only way to improve quality is
to get more information about the users
utility function okay so which will
produce which will give us tighter
bounds on the utility parameters okay
the question is which queries should we
ask we'd like to reduce regret as
quickly as possible obviously we'd like
to would like to do it sequential you'd
like to have an entire elicitation plan
not just do this not just do the stuff
myopically to date unfortunately we all
we have are you ristic approaches to the
elicitation problem but they do seem to
work reasonably well so let me let me go
over these now the first thing I need to
say is you know what are the types of
queries that one can consider I've
already talked at the beginning about
the many in various modes of interaction
one could imagine with a particular user
I'm going to talk just about a couple of
very simple query types there are a lot
more that we've played around with but
again in the interests of pine I'll keep
this brief one very natural type of
query is what are called comparison
queries
we ask a user do you like this outcome X
better than this outcome X Prime okay
which a positive or negative answer will
obviously impose various linear
constraints on the on the weight space
okay these are nice queries in one sense
the interpretation is straightforward
not asking the user to assess anything
numerical it's purely qualitative
question unfortunately these types of
queries are excuse me non-local so
you're asking them to compare one
outcome possibly over a whole whack of
features to another one okay we actually
do have versions force a generalized
additive utility models where we where
we know how to ask local queries of this
type as well but it's something that's
that's worth keeping in mind I'm just
here focusing on on global comparison
queries another type of query are we
might ask our bound queries right I
start asking asking about bounds on
specific utility parameters okay so we
could ask about the specific be specific
weights for example is this weight value
is this way greater than V yes or no
okay well that's a difficult question
for somebody to answer because it
assumes that they can calibrate these
various weights across each other well
in decision analysis though we know how
to take that calibration to effect by
phrasing them in terms of standard
gamble queries so that it's basically
just a probabilistic assessment not a
not a utility assessment directly per se
so becomes just a preference query
anyway don't want to get into the
details here but suffice it to say that
there are ways to get people comfortable
answering those types of questions now
they're very solicitation strategies one
could imagine okay an obvious one I
don't want to dwell on the details an
obvious thing to do is simply look at
the gaps in these utility parameters for
example and start slicing them in half
right obviously if there are no
constraints that's the best thing that
you can do theoretically okay in fact
people have been proposing this in
conjoined analysis in the marketing
research
in the marketing research community
there is this notion of polyhedral based
conjoint analysis for product design for
example this type of strategy is very
much like very much like that where we
would pick the utility parameter that
has the biggest spam okay and ask the
user to refine their their their
estimate of that yeah something that
we've done a lot of work with and and as
we'll see actually works incredibly well
when we're doing regret based regret
based elicitation is something will call
the current solution strategy basic idea
is this if we're trying to reduce regret
what we need to do is either increase
the lower bound on the utility of the
address of our solution right the one
that has the one that has minimum X
regret or decrease the upper bound on
the utility of the adversary solution
the witness that he's using to show us
how much we regret our solution okay so
the current solution strategy in many
different domains it comes in various
instantiation basically says only ask
queries that involve parameters that
determine the utility of one of these
two configurations because if you don't
you're not going to reduce minimax
regret because the adversary will still
have the same upper bound on on his
solution and the same well we're bound
on our solution okay so basically that
would eliminate some of the parameters
from consideration and and you focus
only on those that are in the active
solution so to speak okay a number of
other query strategies I again in the
interest of time I won't go through them
that can be applied in a number of
different domains the thing to note is
that some of these are actually
computationally easier to implement you
actually don't have to do minimax
optimization you can do straightforward
optimization to determine which which
parameters to ask a user about okay so
let me just show you this is just these
are just some illustrative graphs not an
exhaustive sweet just to give you a
sense of how these things work here's a
simple sourcing problem the same type of
thing 50 sorry 10 bitters
500 items forgotten the details now
sorry I think was ten bitters 50 items
500 bits and what we see I'm blanking on
exactly what the true optimal allocation
value was I think this is about this max
this max regret level here is around 15
to 30 percent of the true value so it's
not that hot we knew coming in a lot
about the utility function what we see
as a function of the number of
interactions that max regret drops very
quickly using the current solution
strategy furthermore true regret since
we actually know the utility function
that we're querying here drops even more
dramatically ok see our goal is not to
get an optimal solution we just want to
we just want to go until until max
regret reaches a reasonable level but we
took a hundred instances from this
domain hundred random instances and
actually plug have a histogram here of
the number of interactions a number of
comparison queries that need to be asked
until you actually make mac to ret zeros
until you know the optimal solution
again for procurement asking somebody 30
or 40 questions is not very many okay
typically you know they go off in a room
for six weeks and figure out what they
want so here's a simple product
configuration dhum product configuration
example slightly different domain the
thing i want to point out is a that the
current solution strategy along here
works really quite well it outperforms a
lot of the other all of the other
strategies that we looked at including
this theoretically motivated hlg or have
largest gap this is a very fairly large
problem a large constraint satisfaction
problem utility models that have 150
parameters so that may look like a lot
of queries but given that you have 150
utility parameters is actually not that
many so current solution works very well
the other thing I want to note is that
this current solution 5 here is the
current solution strategy where we cut
off minimax or direct computation after
five seconds to make sure that we can
ask user every
five seconds well what about this what
about this what about this and even
though it's a pretty severe
approximation it actually has very
little unnoticeable impact on the
reduction in max regret so even with
very severe approximation we can
determine the right queries so to speak
okay all right so we have maybe ten
minutes or so let me just wrap up want
to take just a few minutes and talk a
little bit about mechanism design as
well but again just to summarize where
we are with preference elicitation here
the current solution strategy across a
variety of domains works in the
autonomic computing work that we've done
product configuration whether it's with
it whether it's with constraint
satisfaction problems or product
databases in these procurement
resourcing problems it's it it is by far
the best solicitation strategy what we
see is that minimax regret actually is a
very effective driver of preference
elicitation by focusing on that worst
case loss you're actually pinning down
the user in just the right ways okay
approximation has very little impact on
query quality which is very encouraging
right because we can't do preference
elicitation unless we have real-time
response good a number of other issues
that I don't want to get into about I'm
happy to talk about them there are a lot
of issues if you surrounding the
decision theoretically sound elicitation
of information about utility functions
so that you ensure proper calibration
indifference or indecision on part of
the use of this am not sure if I like
that one better or worse inconsistency
in responses in fact our elicitation
strategies will never allow an
inconsistent response because there's no
value of information in asking somebody
do you like a better than B where one of
the right answers can actually be
inconsistent okay however and there are
other interaction modes that we've
looked at we're in consistency can arise
so how does one deal with that interface
design all kinds of cool problems that
that I and my collaborators and students
are looking at so let me take maybe 5-10
minutes and just say what all of this
has to do with mechanism design ok so
imagine the pageant a problem of
bargaining for a car you got this poor
guy here's got various preferences over
the possible car configurations that you
might want but also sellers on the other
side that have various costs of
production okay so they have their
utility for particular transactions at
specific prices as well okay why is this
a preference elicitation problem well
it's pretty clear that if we want to
match the buyer with the right seller
and choose the right car we have to know
something about all of their preferences
okay this of course so we we might for
example want to want to choose the
seller and car pair for this user that
maximize a surplus right maximize the
social welfare the difference between
his value and his cost okay and then we
might want our system actually to help
them bargain on a negotiated price as
well alright this of course is just that
the province of mechanism design where
we want to design protocols for
interacting agents that are assumed to
be self-interested in such a way that
some social choice function is is is
maximized or some social choice function
is implemented for instance efficiency
or social welfare might be our goal find
the best match between this buyer and
particular seller okay those of you
familiar with mechanism design I'm sure
you know people here are very concerned
about ad auction so you should all know
about mechanism design there's an
incredible focus on the revelation
principle which basically says that we
can restrict our attention to the design
of direct incentive compatible
mechanisms where the agents
participating in the maneka and the
mechanism reveal their entire utility
function to the mechanism their payment
schemes that are involved that ensure
that they that they reveal truthfully
etc etc okay of course this simply means
that we're facing the preference
bottleneck if we're asking participants
and some mechanism to the root to reveal
their utility function
we've got to face the preference
elicitation problem okay so we've been
working on this is with a student of
mine at high offal over the last last
two years or so is the development of
what we call partial revelation
mechanisms basically doing mechanism
design where we get users to reveal just
the relevant parts of their utility
function okay again i'm going to go over
this quickly so i won't go into details
there's a long history of this bait
dating back to the classic work of
mountain writer in the early 70s and
there's been a lot of action in the cs
and economics community on this topic
our focus is as has been a has been
related but a little bit different so
let me let me jump i knew the stars mean
i knew i wouldn't have time to go over
this so let me jump right into the right
to the heart of the matter so you again
given the basics of mechanism design the
goal is simply to have users reveal
something about their utility function
it's usually called type revelation your
type encodes the relevant private
information that you have about about
your environment here again that's just
your utility function partial type we're
going to generalize the notion by by
saying by rather than having somebody
reveal their utility function or their
type they're going to reveal a partial
type which is just a subset of their
types basically says I'm not going to
tell you what my utility function is I'm
going to tell you is that it lies
somewhere within a particular in within
the subset okay we'll call a one-shot
direct partial revelation mechanism
basically a mechanism reach agent
reports a partial type okay a truthful
strategy we have the same the same
notion of a truthful strategy simply
means that when you say when you reveal
a partial type that your true type
actually lies within that subset and the
goal is to Devon is to devise a
reasonable set of partial types that
minimize the amount of revelry
or the amount of computation required on
the part of the agents or the amount of
computed communication while still
getting good outcomes while still
maintaining appropriate incentive
properties okay well this is going to be
difficult in particular we're generally
interested in dominant strategy
implementation where it's a dominant
strategy for the agents to reveal their
utility function truthfully no matter
what the other agents do there are some
classic results in the economics
literature by Roberts more recent
extensions by la vie at all they
basically say you know what you can't do
it okay basically says the only social
choice functions that can be implemented
in dominant strategies in dominant
strategies the social welfare
maximization or some variants thereof of
course we can we can expect to maximize
social welfare if we're only doing
partial type revelation because we're
not going to know enough about
everybody's utility function to say
definitively this is the social welfare
maximizing application allocation so
there are various ways that we can go
what we do is actually relax a solution
concept of dominant strategy
implementation and hope that we get
intuitive results okay and here's how we
do it well go through the details here
what we're going to do is basically say
suppose that that a set of agents
revealed their partial types to lie
within a particular subset okay so I've
got a partial type vector the utility
functions for each agent let's call it
theta okay given that we don't know what
the users true utility function is we
can use max regret to determine sorry
minimax regret to determine a good
allocation the one that minimizes the
the minimizes a loss with respect to
Social Welfare if an adversary were to
come along and pick everybody's type
from this from this set that they reveal
in other words pick their utility
function consistent in a way that's
consistent with what they've told me
okay if we do that if we do if we have a
partial revelation mechanism where each
agent reveals just a partial type
okay and the outcome is such that we
always allocate or choose an outcome
that minimizes max regret with respect
to those partially revealed types then
we'll call this a regret based partial
revelation mechanism okay now what does
that mean obviously as we said you know
you can't get efficiency we can't
maximize social welfare if we don't know
everybody's type but obviously if
obviously if the max regret for every
partial type okay every partial type
vector is less than Epsilon okay then
we're going to be epsilon efficient
we're going to be within epsilon of
maximizing social welfare no matter what
the agents reveal as long as they reveal
truthfully okay that should be fairly
obvious of course and this allows us to
trade off efficiency or social welfare
for elicitation effort which is a nice
thing however how do we ensure
truthfulness okay very briefly we can
generalize the gross payments for those
of you familiar with gross schemes or
vicar or Clark groves payment schemes
basically you know these are the payment
schemes that are used in vc g well we
can't use groves payments gross payment
payments basically say you pay something
that's independent of your type ok or
what you report less the social welfare
we realized by the other agents
participating in in this mechanism with
respect to the the outcome that I chose
unfortunately we don't know what the
social welfare is for the other agents
because we don't know their type but if
we have a selection function that picks
an arbitrary type consistent with what
they've revealed ok then we this partial
revelation as partial revelation
mechanism with groves payments will not
only be epsilon efficient but
truth-telling will be an epsilon
dominant strategy in other words no
matter what anybody else does I will I
can gain at most epsilon by reporting
something other than my
partial time okay quickly just to wrap
up we can also generalize Clark payments
as well so that we get so that we get
approximate approximate individual
rationality approximate individual
rationality and what we've got is an
approach to the approach to the design
of partial revelation mechanisms that
that allows us to trade off the amount
of elicitation effort for efficiency
we're going to have to live with
approximate incentive compatibility the
that that's an unusual notion people
don't typically proposed approximate
incentives but the key to motivating
this is that if this epsilon is not on
here if epsilon is small enough okay we
know that computing a good lie at least
intuitively is very very difficult okay
with route from a computational
perspective if the most that you can
gain by lying by deviating from the
truth is bounded by a small enough
Epsilon even though formally we only
have a proximate incentive compatibility
from a practical perspective agents will
be incentive to behave truthfully okay
same thing with approximate incentive
ration approximate rationality and so on
ok so these regret based prm's offer
good scope for trading off these various
considerations elicitation effort with
with efficiency and incentive
compatibility as long as we can find a
good set of partial types okay that's
the key this assumes you've got a given
set of partial types so I'm going to
wrap up simply by saying that we can
take some of the techniques that we've
described for max fit for for mini max
regret elicitation and use these to
design the set of partial types okay I
won't get into the details but basically
there are techniques like the current
solution strategy that say this is
exactly how it should carve up the space
of the space of utility functions among
the agents participating in the
mechanism ok we skip all of this some
very preliminary empirical results here
this is a 16 good
bargaining problem with eight utility
parameters here we're simply comparing
how our design approach is a function of
the number of bits of information about
one types about one's type that we ask
the agents to elicit how this how
epsilon which is are bound on efficiency
and and incentive compatibility how it
reduces ok so our regret based approach
does a little bit better than is sort of
an arbitrary uniform based approach
we've also done some work with loops
sorry we've also done some work with
oops and went backwards here we've also
done some work with sequential partial
revelation we actually get a lot more
power because you can ask somebody a
question given the response that
somebody else has given you okay and we
actually get for much larger problems we
get much better elicitation performance
we have to live with weaker theoretical
guarantees we can only get ex post ex
posts incentive compatibility guarantees
rather than dominant strategy which is
usual in sequential mechanisms okay let
me let me stop there and just summarize
with with sort of a
a couple of key points with respect to
partial revelation mechanisms this is
just in its infancy from our perspective
there's a lot more that needs to be done
for for the design of these partial
types are techniques algorithmically are
fairly crude but I think there's a
there's there's a there's a lot of
encouraging progress that's been made
there we actually have an extended
design framework where we can do much
more than optimized for social welfare
we can optimize for arbitrary social
choice functions in various ways okay so
just to wrap up here where are we right
preference assessment from my
perspective is a key bottleneck for a
lot of AI applications okay the regret
paste techniques that we've been
developing are very encouraging the
regret seems as I mentioned to be very
effective driver of elicitation
computationally it's much more
manageable and much more tractable than
a number of the Bayesian approaches that
we've experimented with in particular
the kind of computational approximations
one needs to make with with Bayesian
techniques are going to be problematic
from the mechanism design perspective if
we want to maintain suitable incentive
properties there's a lot missing okay
obviously we're again you know I have a
grand vision of decision analyst sitting
on my desktop and in order to do that in
order to do that we've got to start
looking more more critically at
sequential elicitation looking at
long-term elicitation plans not just
myopic ones both from a theoretical
perspective and a practical perspective
we've got to look at the right
techniques for user interaction we have
been doing a little bit of that but
again that's very much in its infancy
we've have been doing some work where we
exploit distributional information
within these regret based techniques
where we make allocations using minim
acts regret but we use densities or
distributional information over utility
functions to guide which questions we
ask since that doesn't really have an
impact
on robustness or the incentive
properties in mechanism design and
obviously we want to integrate these
passive observations through revealed
through revealed preference revealed
choice and things of that nature what is
commonly now called an AI inverse
reinforcement learning into this whole
this whole framework that I think will
address the grand challenge of
preference assessment so I'll leave it
at that and see if there any questions
yep
so you won't always get a preference
right this well you want the question is
how do you do this when you're talking
about groups when you're talking about
groups of people I got to answer that
question one is I don't actually haven't
bought a whole lot about this problem
this is the subject of marketing
research and conjoint analysis for
example when you're doing product design
you do this kind of elicitation not for
specific individuals but you actually
aggregate you aggregate all of that data
okay in in various ways we actually in
sourcing in fact we are implicitly doing
group preference assessment right
because the the people in charge of
sourcing events for example it's not an
individual it's an entire team and
they're all reporting to different to
different people when you look at the
utility for specific attributes like
number of winners okay you've got people
in charge of lunges logistics who want
as few winners as possible okay whereas
you know your your your CFO wants you to
spend as little money as possible right
the marketing guys want you to give as
much business to people in the Eastern
corridor right and so on and so forth
okay what what regret lets you do the
social minimum X regret lets you do is
not make people commit okay where they
don't have to write so in fact what's
happened is when we've played around
with this with people doing sourcing is
that it seems to relieve some of those
conflicts because you don't actually
have to have a consensus utility
function right if you're all comfortable
with it in the with the bounds right you
say well I don't know where my utility
is it somewhere in here and somebody
else says lying on my where mine is but
it's somewhere in here and we can say
you know what you don't have to refine
it any further as long as it's in here
this is a good decision then we're in
good shape okay but this doesn't
directly address you know aggregate
aggregate preferences but you know it's
a very difficult question
I guess I have a kind of philosophical
question so it seems like the whole
reason you do preference solicitation is
because people act irrationally if they
could just make the right decision one
shot you wouldn't need to get their
preferences so the question is what
happens if people's preferences are
irrational you know so say you have an
agent a decider who says you know my
most important preference is I never won
admit I made a mistake yes and then you
go on from there when you get into a
more and more trouble right is there a
way to recover from that or I mean there
there are there are various techniques
that one can use so you know in some
other work that I've done we've actually
used noise models for responses to say
look when you say you like a better than
B there's some probability that you
didn't really mean it right so we can
recover in that sense I it is true that
people are it's well-known that people
can be very inconsistent when it comes
to stating their preferences you know
there's a whole literature and decision
analysis and and experimental economics
that addresses that and we haven't
brought that to bear on these types of
techniques not yet some of it's starting
to filter in so I don't have definitive
answers but it is a problem that people
have talked about okay I would take
issue with the question that you know
the only reason we're doing this is
because people are irrational right
people can be perfectly rational and
still not be able to solve these
procurement problems or planning
problems or things like that they want
us they want our intelligent agents to
be able to do this for them right but we
don't know enough about what their
objectives are what their goals and
trade-offs are to be able to actually do
that optimization right so it's not so
much that they were irrational but
they're computationally limited okay so
an important part of this is to be able
to frame the questions in such a way
that they can in such a way that they
can you know get their heads around what
it is that they actually are after what
it is they prefer or
don't prefer okay so we can't getting
back to the coach problem where we're
actually looking at trajectories of
behavior it's very hard for somebody to
take one giant trajectory behavior and
say I like this one better than this one
you could show them the same thing you
know two days later and they may give
you the opposite response right so
that's a that it's really a question of
framing that's right so we're looking at
techniques for mdps for example as that
will allow us to break these things up
into the relevant chunks of behavior
that people can actually wrap their
heads around so it doesn't quite answer
your question but yeah kind of goes that
so so in a lot of situations there's a
fixed set of sort of baseline strategies
like for example if I'm talking about
classification I might not know what the
optimal classifier is but I might have
some experts or if I'm talking about
portfolios I might not know what the
optimal investment strategy is but it
might have some fixed baskets and then
it's interesting to show that any
particular algorithm has some bounded
regret with respect to retrospectively
picking the best of the competitors
shore baselines truck so let's say I
gave you some baseline allocations right
there guys inside the company who say I
don't know about all this fancy
preference elicitation blah blah blah
but I propose the competitor X sub zero
that's a baseline so is there something
you can say about oh if you follow this
particular minimax elicitation strategy
you'll do no worse than clairvoyantly
having picked the best from this list of
baseline allocations yeah I can mean
that it's a bit it's yeah I'm trying to
get my head around this notion of a
baseline allocation say in this setting
right so well clearly there are various
rules of thumb that people use okay I
will so let me tell you how the how
standard practice is once you've got
sophisticated optimization techniques
right the way people actually do this so
we haven't deployed we haven't deployed
this preference elicitation technique
technique with clients yet they've seen
a kind of in demo
all right I'm pushing us on this but the
way people actually do allocation in
these sourcing events is to basically
say look get me the least cost give me
the least cost allocation right I don't
like this let's redo it with a
constraint so don't give this much
business to Joe price shoots up they say
well I didn't mean that is a constraint
let me do when we put in a different
constraint and they go on and on they'll
generate what are called thousand you
know what are called scenarios and often
hundreds or thousands of these things
they'll eyeball them all and say I like
that one okay that does immeasurably
better than any baseline heuristics that
people have used nobody who's done
sourcing this way has said you know what
my rules of thumb to gutter right I mean
that that's about the only response
about the only response that I could get
okay what we're trying to do is
basically automate this technique right
so
okay thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>