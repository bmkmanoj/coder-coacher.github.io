<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Music and Machine Learning Workshop: Multi-Timescale Principal Mel Spectral Components.. | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Music and Machine Learning Workshop: Multi-Timescale Principal Mel Spectral Components.. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Music and Machine Learning Workshop: Multi-Timescale Principal Mel Spectral Components..</b></h2><h5 class="post__date">2012-02-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7fFmh-iLvSY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is worked with my hope my advisors
that has egg and national geo so I'm
going to talk about the new features
multi time scale features for particular
for the task of automatic annotations
so this talk I will try to describe but
first of all the base model model that
we presented in a 2001 and we will build
on that to you build multi5 scale
features so first of all what which is
the thematic innovation well Gert gave
talk this morning that was pretty good
describing the other clinical annotation
but let me present you a little demo of
what does in real life it's a wonder
so this is a system done to you working
in real time over a real deal so
actually look at treats the cancer 40
can make a decision and can look we
averaged over w songs while in the
nation are pretty good but busy subtly
makes a mistake so sometimes it thinks
that that is most of the time does
something pretty good let's stop
listening to music and will be serious
for okay so first of all why do we need
the multi timescale representation well
has you know no level aspects of music
can be easily represented by a frying
level pictures that's not hard to do and
we use a backup feature representation
but higher levels such as melody
phrasing and rhythm well you need a
longer time scale to entities those
aspects so what we propose is to combine
the different titles in one feature that
we will learn upon so the idea of this
time scale is not new here are a few
well
or they're all well no but some pretty
old features using so like they are some
that are vital GT inspired like the
essay is and the cortical representation
convolution with work and wave it which
are more mathematically inspired or you
can just take a set of handcrafted
features like a future that represent
rhythm and then some definite wasn't
temper and just put that in a whole big
vector and you will have some kind of
Miss cat thanks get representation but
recently I've noticed that there's a lot
of new research on you to stay with his
camera these are a few papers from is
made 2011 and as you heard today a lot
of thoughts were about these kinds of
representation of proteome so let me
introduce to you the model that the the
model that actually we submitted to
Myricks tues at 2000 1 &amp;amp; 2 my life and
12 and actually to my surprise got the
best result with us very simple mouse so
all the type described I did what it is
first of all of our kind of features
that we use I we call them a principle
bells tekram components or PMC's so we
put very difficult prior knowledge in
the features all we do is pry not
is a male compression and we have a step
of this a to be able to be a tentative
to a given set the volume so compared to
ms feces here are few differences I'm
not going to die a tale about that but
is just emergencies are the most human
features right now mrrr automatic
feature automatic tagging and they might
that be good for actually as good as we
can yeah so how do we compute the nscs
simple twist at the spectrum spectrum LP
to you now compress and we do some DC
whitening to be precise the PCA
whitening is not a data dimensionality
reduction we use the whole pc a space we
just use pc to rotate our features in a
space that's more convenient so what
does this look like well this is a
spectrogram it's pretty tall it's all
blue because all the energy is in the
lower frequencies so it's not log scale
so we apply male filters over this so I
maybe you like that see here's a red
line so the lower frequency here are the
frequency bands and ml frequency bands
so the lower frequencies are linear so
they are not transform but as we go
higher in frequency the higher
frequencies are more compressed this is
just a look at rhythmic compression so
this is what we are saying if we do have
a compression so now where's my program
is a bit more easy on the eye we can see
the beats and we can see a few of the
notes and by the way this is the song
I play the per year it's a little like
the Rose aircraft buy a bag so next step
to compute certain PCA over this so we
take a few thousand training example and
we compute pcl over this and we obtain
this kind of matrix so this is are the
eigenvectors of the vca or don't I I can
values so here the projector doesn't do
it's nothing really the real picture
that I had but what we know this is the
first few eigenvectors are basically
temper shapes really almost playing and
but as you go though in their lower
ragged values you notice that we have
this kind of harmonic structure that's
captured by the pc components and if we
apply this matrix to the amount i
program we obtain a pc mm which is well
it looks like noise but there is a lot
of information into this so what do we
do with this we need to so this each
column here is what we call a PMS see
some principle valves
now we want to do some automatic and a
patient with that we need to well we
want to do some temporal pooling or time
aggravation this is a well-known fact
that using statistics over over time
gives better results for classification
for many reasons the main reasons i
would say is a community of the feature
and variance to time shift our focus
shifts also so we tried different
pooling scale and we found out that
going to two or three seconds is kind of
a good plateau for performance so we're
going to go with that and now what do we
do when we aggregate well typically
people take to the mean and variance or
the max of the features we decided to
test a few functions we tested the main
max minimum variance and we also tried
to third and fourth statistical models
actually we were surprised to see that
the third and port moments i really
don't well so the best preference we got
with my mixing main variants maximum and
minimum in love me um by the way i'm
very the the performance measure that I
used here is the area under the ROC
curve which is basically if you're not
familiar with that it's a ranking
measure basically gives me the
percentage if I take two random examples
in my data set it's the percentage of
chance that there are ordered well in my
predictions so now if we take our busy a
gram and we aggregate the features we
those of let's say two or three seconds
we obtain something like that after the
pictures are cool so this is a window
colony here is a vector that gives us a
good statistical point of view of the
features that are into pooling window so
these are the features that we want to
send or classify so to use a scheme of
the learning model basically we have our
nscs and we do the pulling like a letter
sent explained and then the classifier
is just a simple plain vanilla neural
network with one Ilah are also called a
multi-layer perceptron so the output of
the classifier is basically the tanks
that we want to predict so a few
advantage of the MLP is that it scales
well to make data sets it's also good
for the multi-label classification
that's it gave enough because you obtain
let's say hundred and sixty a different
output that can give you a measure
between zero and one of like how good is
this diagram from this song and you can
also learn some kind of dependence
between the tags thanks to the hidden
layer so we know that tax arson can have
some relation like rock and pop can come
together so
okay so I already talked about that so
basically if i compare the pmac to other
kind of feature like the basic ms.d CC
using the htc's but with larger larger
number of bins I think pca tone FCC's
just the amount spectrum without pca we
all see that okay the pms sees seem to
they do a better job and they train more
rapidly so now let let's extend this
model to know to time scale well we did
the thing that we talked with the
simplest so basically we just take
different window right with different
frame time scales and we do the
processing in paola so the only
differences for different time scale the
the free transform will be done with a
different number of samples so the lower
a time scale we have thats a thousand
twenty four samples and then for the
next time scale we have 2048 and we go
with a brass tube and we have met the
the time scale but we keep the same
number of Melvin's so basically the the
longer time scales get compressed a lot
more but what gets compressed into the
high frequencies which are already
modeled by the lower time state so we
aggregate after the pc and the pooling
we aggregate all these features
concatenate in the baked peak in the
feature vector that we send to our
classified so this is a distillation
these will
at different time scale so this is 14
seconds hundred and 60 milliseconds c640
and we would go to the extreme three
seconds well that's what you get ok so
what kind of experience we did well the
test is a diuretic an indication so we
use a tag item data set which is the
largest that I said that we on the
automatic added annotation a linking
that comes with tags and do you there's
22 out of 22 thousand songs of 30
seconds and 160 tags and about we use
its this model i just described so here
are two numbers the fabric tears of the
models so here's a graph of the
performance of each time scale is
initially so if i take only the features
at the 40 minutes ago Estelle well we
obtained this performance and when we go
up well we see that longer time scales
seem to perform worse than the smaller
ones but if we aggregate the features
together so this is using only the 40
minutes seconds nine scale this is using
the 80 and the 40 millisecond time scale
and so on and so on so we see that using
five or six times five or six time
scales give us a significant
the improvement over unperfect so we get
something over this having this
different representation of all do
together but if you look here this is
the negraph I just showed you like the
performance of high every time scales
are really bad and virtually there's a
reason that's easily explainable is that
we since we aggregate over a fixed
window well hire timescales have less
frames so the statistics that we
aggregate over have like less stable so
we want to correct that we get a simple
the second set of this thing that we
thought about is just them we take this
kind of a window or different time scale
and we just move the overlap instead of
just having consecutive frames so
basically we get in the same number of
frames for your time scales so now this
is the performance of single time scales
using this overlap you see that the best
individually individual time scale is
the 90 seconds and make milliseconds in
this case and we still sleep as the
longer time scales are or worse than the
short ones but if you compare like the
here the worst one is at Point 835 and
here is that point seven eight so we're
orders of magnitude over to the 16
inches deep or over other performance
for these time scale so it's important
to have a lot of frames to do aggregate
the statistics so if we aggregate the
different times you off together we see
that me still get the same kind of
result using a lot of time scales
improve the performance a lot and the
performance is iron with this then using
a single time scales using overlap so
you're the best performance where the
mean of the best performance is about
that point eight seven and before
without overlap it said so we get a
google so if we compared to other
state-of-the-art mouse go so this is the
multi time scale model that i just
presented you care c is for full feature
classifier so here is a simple single
time scale a boom fiyah feature pacifier
this is the multi time scale learning
model that was presented in the bigger
event is named in the same missing paper
as the PFC this is kind of a convolution
model that had it added a layer of
learning before the blue link so it's
better than that just forgetting the
features
but it's a hunger to train so i could
not submit this harder into are executed
to the timings and finally they each
other well here is muscles it's a
basically it uses SI eyes which are we
kind of complex features and some kind
of an embedding model that tries to
embed in the same space that put your
pictures in the tags so it's quite
surprising that with really basic simple
features well relative still relatively
simple pictures at all big mathematical
transformation it's all linear and
simple gasifier NLP we get the sake of
the art in automatic annotation make
what we have to take from that is that
there is a lot of making a lot of work
to do in the picture extraction before
going into a complex learning for these
tests we have improvements so in
conclusion
yeah this is our new features that seem
to be i would say that should be worked
on more but i have some potential so
future this is like great really recent
work and there's still ton of things
that i want to try what at the first
thing that I want to rise to use
different cooling scales for different
high scale so instead of having
different overlaps for different axial
just having different fabrication time
that could it be the wavelet style I
would say so good help other classifiers
could be useful for example in Casa
parties that could handle missing
features that katemel mean
classification over excerpts of
different 2 seconds or five seconds 20
seconds accumulating the data but the in
oracle yellow-headed there's a other our
tax task that will be used with features
and yeah there's also i realize that
there's a lot of mathematics behind
these these things that could and
probably commence the computation and
lastly I don't like the acronym you have
it with
no I should call these features where
the thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>