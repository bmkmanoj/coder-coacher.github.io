<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Semantic Desktop: The Intimate Supplement to Memory | Coder Coacher - Coaching Coders</title><meta content="The Semantic Desktop: The Intimate Supplement to Memory - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Semantic Desktop: The Intimate Supplement to Memory</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HfDdzoeQCnE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi welcome everybody I'd like to welcome
andrew has dangle to Google I've known
address for quite a while now he's quite
known in the world of document analysis
and recognition he is currently a the
management board on the management board
of the DF ki which is a German center
for ulterior intelligence he's also a
professor of computer science at the
University of kaiserslautern in Germany
and even though I know his work mostly
and document analysis to date was
something totally different line of
research has been involved into the past
couple years I'll talk about the
semantic desktop as an intimate
supplement to memory welcome address
that's it so thanks a lot Luke so I'm
happy to be here today and I'm also
happy to introduce you to one of our
made guiding teams in dfk I but first of
all I would like to ask who knows the
FKI who don't know okay so just the
question just maybe some send in the 70
slides with media is actually the
largest AI Institute in the world we
have about 490 employees which work on
various topics on AI and we are a
nonprofit private research companies so
to say I'm a professor of informatics or
computer science all the directors have
the same position and the dfk I works
with no basic money everything is
acquired so we are steadily growing and
we our mission is to provide transfer on
one hand side but also to have
leading-edge technology on the other and
due to this we already found it about 49
spin-off companies with about 1,200 jobs
outside of the FKI we brought out about
50 staff members to Professor positions
etc that's it if you like to know more
please visit our webpage so when I start
today i would first talk a little bit
about what is the Symantec desktop from
our point of view and how to build it
because as you know Semantic Web is now
one of the
the guiding phrases everywhere but the
problem is how can we get or how can we
enhance the web to a more semantic level
and the question also because of my
background is what could we do to also
integrate information from paper
documents of any kind in such a scenario
and furthermore what can we make how can
we profit from user observation so first
of all I like to talk a bit about what
is a semantic desktop manages took a
definition we put in one of our papers
and it just would like to read it in
advance and later on I am going to
explain this so a semantic desktop is a
device in which an individual stores all
her digital information like documents
multimedia or messages these are
integrated as semantic web resources
each is identified by uniform resource
identifier URI and all data is
accessible in variable as RDF crafts
resources from the web can be stored in
authored content can be shared with
others ontology zylle ow's the user to
express personal mental models and form
the semantic clue in the connecting
information and systems more than that
applications respect this and store read
and communicate via ontologies and
semantic web protocols so the semantic
desktop isn't a large supplement of uses
memory this is our interpretation of
this and our starting point to think
about this is how the developments in
the web are going on and this is just a
visualization of the hundred most
important blocks in Germany and it's
just one way to show how much
information is in it how much is it
accessed and how the different
connections are in between if you
consider this this is some outcome of
the recent trends everywhere what's the
primary means of the information society
that we put all the information together
mainly on the web so everything we have
can be find on the web today so
scientists
published a paper send the salesperson
put their catalogues of new products in
the web and the journalists have the
news available so most important in this
is however that documents are mainly
understood by natural language so people
are aware of what's going on we have
lots of mining technology but in many
cases we cannot ask why we can ask when
we can ask how many we can ask who
sometimes but why is the main question
so eighty percent of information today
with respect to many studies is captured
in unstructured technology in it's very
hard to make this available by
technology to to provide decision
platforms and to further direct our
processes so today researchers attempt
to transform the web of links into the
web of meaning in which documents are
described by a vocabulary by a shared
vocabulary of people providing them the
way how machine can understand and can
derive meaning from this vocabulary but
if you could see the Semantic Web which
is going on today then it's still a
initiative to what standardization which
means that people try to provide higher
order languages like all so the web
ontology language in order to have a
framework to describe vocabularies but
the main problem is that people are not
ready to manually create all this kind
of vocabulary and furthermore to
maintain the vocabulary so we need
something that allows us to provide such
a vocabulary but semi-automatic means so
the question is how could we provide
such a vocabulary to build ontology
which is a kind of shared vocabulary for
the society if we try to find the right
vocabulary at the starting point there
are already some very important
questions
solve what are the right terms to be
used if I show you these for fluids over
here and I want to ask you what are the
categories to put them in what would you
answer speed which 100 strange however
any other proposal the mower at once the
more green ones one which the colorful
ones the one we say stick the one
without the one with a more rough skin
the clap or more fine screen the one I
like the one I don't like so there are
many ways to categorize and this is just
a simple example to show you and we
daily have to work on documents and it
strongly depends on our understanding of
the contents of the document of the on
the situation we are of the of the
awareness of terminology we are using in
order how we do in the parade contents
of documents and documents are mostly
resources and they strongly depend
however who we are what is our interest
what is our role what is our recent time
to work with the documents so it's very
hard to really provide categories in
this sense so coming back to the to some
of my statements to develop a kind of
semantic web will be very hard because
subject subjectivity is inherent in our
thinking about contents and therefore we
have to resolve the problem so
respective usability of a vocabulary
strongly depends on the users how the
users categorize information and there's
only a few support today in companies to
categorize information by objective
means so if you just look at a study
which comes out from Delphic group in
june twenty two thousand four you can
see that with respect to 400 companies
where they asked people how they
categorize information you can see that
most of the people
still do it by themselves they are of
course some companies which provide tax
on amis how people can categorize or
allow to or they can search for
documents however with respect to our
experience people to not really except
such taxonomy because they do not
reflect their terminology in order no
their specific interests so we have to
find other ways because the user tends
to prefer its own way to categorize
information and I'll give you an example
or first of all I like to make some of
theses that is that the bondage of
former organization of information
inhibits creativity and limits the
options of self-organization on the
other hand the document is like and no
today we should not consider a piece of
paper still only as a document today
it's a note in a dynamic environment
this is constantly changing over time so
a document is something which is fluid
yeah and strongly depends on changes in
standards in law in references or
whatever so we have to just resolve the
traditional way how to archive documents
because it strongly depends how
documents are used in specific
informations by specific roles of people
etc coming to categories categories
mostly are at rest by specific terms
these terms are selected in order to
describe the main or common features of
entities within such a category or class
and I would like to follow a statement
by Immanuel Kant maybe you know him we
who said that imaginations was our terms
outlined in terms without imaginations
or empty so which would say if I have
something in mind I could tell you you
are not able to see and on the other
hand if I would use a term you don't
know you have no image in mind
people today they think about in
pictures imaginations associations in
their mind and unfortunately we have to
do abstractions via the language so of
course if I would use a concept you are
familiar with I'm sure talking about my
daughter you know what the daughter is
but you don't know whether it's a small
kid or a young lady know how she looks
like so this is strongly driven by
shared context and by the mental models
in our brain which are related to the
beliefs the values we have to the
experience on and so on so communication
always takes place in a shared context
coming from subjects and this is very
important also to web how people could
be creative but we can also have a
transfer of this idea towards our own
laptop or PC whatever we work with that
at our PC we are storing information of
documents or single documents according
to our own preferences so our subjective
you to the contents so we define folders
and they give the folder names providing
a kind of taxonomy which is a
conceptualization of the world how we
look to the world but however these
concepts have no unique meaning which
means that I just take a simple example
like this folder and give him the name
vocation we could have something in mind
collecting information about our
preferences what kind of occasions we do
but if I just use the term and tell it
to somebody else there could be a
completely different meaning of
occasions and this is the reason why if
employees quit leave a company there is
a kind of lost of information is
cemetery of data which is back nobody
has time nor the experience to really
explore so if my colleague is on
vacation I would look at his or her
laptop and look for infamy
it's very hard to find by its just using
desktop search yeah you have to
understand more behind that and there's
another problem with respect to these
taxonomy is this is given that these
technologies allow perspective
considerations today so for example if I
would if I would take some of my talks
today the one of today or any others and
you might be interested and may be
interested also to store it on your
laptop you always have the same problem
where to store this talk register all
the slides because on an abstract layer
information has different dimensions
this is who what where when why
dimension and it's always hard to put
this information in one folder only
because the situation later on that
requires to have another perspective to
the information so the question is where
to store the information moreover there
is a third problem that today we have no
integrative view to information we have
the file system on one hand side
wherever these folders we have our email
folders on the other and we have
bookmarks we have our archive system
another one and whatever so in here
there are collections of information
which have of course in my mind a lot of
to do with each other for example that
there are talks inside here which I
discussed with people over there may be
taking place in a hotel somewhere in the
world but these are unfortunately
completely separated and it's very hard
to provide associations among this
information so in a first step we took
advantage of machine learning techniques
allowing to learn how people store
information on the desktop and
furthermore also provide
multi-perspective access to information
while we use an integrative view to all
of these sources
and this looks like that that we allow a
usual interface to information but we
have virtual views to information at the
same time one of these views can be
integrated via the Explorer or via any
system while the other ones are just
virtually and they provide aware when
who why do to information so that one
document can be virtually stored in
different folders belonging for example
to the document type unfortunately this
is in German the document type for
example bro check proposal addressing
partners like Accenture or DM BF having
the organization of quality insurance
the department inside topics of AI etc
so a document may be stored to different
folders and this works like that that
because we learn the contents of each
folder the document could provide a kind
of electronic mental model this is the
kind of network of term correlated
concepts you are providing a profile for
all of the folders at the same time so
if we I'll show you some examples later
if you receive for example emails the
Swiss system can make proposals to what
topics or what document types the system
may may may be classified so you can see
this at the question markers here it's
just association the system gives you
back and the best thing is because it's
the same mental layer I do have i well
understand the behavior of the system so
it's a very personal assistant right now
in order to handle information and then
I can accept these proposals for example
just making hook at each folder
otherwise it's not relating to the
profile of the folder but as soon as I
do that so the the electronic mandal
model so to save a folder is adapted to
the new document at the same time yeah
there are various retrieval technologies
also include
it I don't want to go into detail we
have kind of feedback surge and concept
search and fuzzy search etc I've other
slides of this technology but just to
sum up this is at the first step it's
nothing than a machine learning approach
towards multi-perspective integrated
handling or associative handling of
information however to summarize there
are a couple of advantages in this
approach that is that the contents the
text of information objects whether it's
a taxonomy a folder or a single document
they could all be related in the same
way the communication between a user and
this kind of personal information or
personal memory is trimmed by these
concept relations allowing to associate
and to imagine in his or her own mental
world and furthermore the combination
with the perspective directions user can
have very nice possibilities to retrieve
information however this is just a way
to qualitatively or just to relate
information to each other it's not yet
semantics and the question would be how
can we profit from this in order to
provide something of a higher level
considering these resources on a
semantic layer without lots of manual
impact and I'll give you an example to
that if you transfer this idea just
presented to you to a real application
environments a insurance company where
are lots of clerks work on specific
topics and incoming documents then can
be filed in different views at the same
time for example document types contacts
views events and so on the system may
give proposals in which folders such
information may be classified and the
user may accept and as soon as the user
do this adjust if enlarged some of these
folders and the user can activate some
of the generic relation
which are stored behind the folders yeah
and they express some semantics between
the folders for example that if the
document is put in this folder it is a
notification of a claim or if it's in
the folder of mr. Smith's it generated
by mr. Smith's furthermore it scribes an
accident it furthermore addresses the
car damage and so on and I could also
have generic relations between folders
of individual views for example if a
document is stored in two folders of
different views at the same time we
could further generate a link that this
person here declares the event or that
this event implies a specific case so
step-by-step chest by classifying
information we on the fly generate
semantic links in between so we have
further documents coming in this is a
certificate which generate by another
person addresses the same case and
comments on an accident so if we have
this step by step we can collect
information on a certain semantic layer
and so we consider each information as a
kind of semantic web resource whether
it's a document of any kind and also the
constituents of it like a message to
sender the recipient and address or even
a calendar event and all the resources
are identified by your eyes where they
are in the file system or an Outlook or
wherever and as a result we can generate
something like a personal information
model we call it Pema and to give you
example we have this announcement for
example where I have to give a talk very
soon of the null of the chasm 2007 and
we have this uri and if we have a audio
vast class you can say that this is a
event but for the more this also has a
certain location which also has
another URI and this location here is an
organization and this conference is
hosted by another organization and this
also is chaired by somebody who has own
web page and there is a speaker namely
me who has another webpage and both of
these are persons and furthermore we can
say that this person works for the
University in Melbourne while I do work
for DF ki and dfk I again is another
organization I further could combine
native applications namely outlook for
example why where the address is stored
of such a person and I also could use
calendar events and all of those could
be easily combined so we could wide
using document exciting documents
handling documents of any kind we can
step by step establish a higher level
representation of what we do so we have
networks of tribbles which assists us to
file organize and share information of
any kind and this is called chemo as I
told you it captures all relevant
information items at the same time
whether we have instances as RDF or we
have concepts in terms of ontologies
like rdfs and the user then may excess
share categories which are defined here
for example like the most general one is
the thing and we could have persons and
events and groups organizations whatever
and we could generate instances on the
fly when we handle documents at the same
time we should take care there is a
concept called smashing not to duplicate
resources at the same time and this is
kind of just mining towards having the
same resources and avoiding to do that
you can I give you a link on that you
can read where to find it i also maybe
you notice there are always papers you
have a look you can have a look more
deep or more detailed information about
this so
we take the data here from native
resources of various applications we
have a partner as f net to provide an
adapter to our dff and we have a kind of
rebirth engine which then matches this
to the existing ontology which where we
do the update of the pmo model and have
a certain user interface i will talk
about the user interface a bit later so
this is the current way how to do it and
so this R is also the basis for the so
called semantic desktop which is a kind
of adaptive personal assistant towards
the handling of information and allows a
lot of different functionalities I'll
talk about this later but most important
it combines the PMO also with a
important fact with user in observation
so why do we need user observation
because the user acts on specific tasks
in specific contexts and this is also a
very valuable thing how to assist the
semantic desktop in how to help use in
the best way so what how can we profit
from that first one is very obvious that
if we have appt emo and this is a kind
of hierarchical organized ontology we
could just look at contents of simple
emails and the system could just make
some proposals to what topics the emails
belong now and we also see that ontology
is a topic and that Reb use is I can see
sorry the reviews are belonging to a
conference called WM o something and
this is a conference and we have
knowledge management this is the
department EDF ki so we can see this but
more than that we could also if you
write a document we can do a save as and
if you do a save as the draw box opens
up and makes proposals where you store
the document best and how to relate the
contents of the document to the existing
p mo but a step further is for example
that we are observing uses when they
browse in information so there is an
example of a web page with specific
contents and now we allow for
information push for the user what is
doing whether it's a browser or whether
it's an email application don't care so
we have developed a kind of site bar
it's assistants part to the user which
is adaptive in the sense that if the
mouse is here or the cursor is in this
application the mini choir adapts itself
and shows for example first of all it
allows full text search but it also
shows all existing tasks all data source
sources all concepts which are available
it also shows all current task which
exists it comes up with all content
related informations with the categories
which the persons and also the projects
which are always related to the contents
of the actual application as soon as we
is we change the application going out
of the browser to the email system where
we just open maybe a call for a
conference the mini choir adapts itself
to the new contents always showing the
recent and the related topics of it and
furthermore we also see or we are able
to then just confirm semantic links
which are proposed also by the system to
be added to this consideration so we
combine traditional I our technologies
with some rules which are integrated
into this scenario like such as with
extract the contents of an invitation
email and infer the location and
attendees of the meeting very simple
this could be part of the PMO we also
this is a very recent one it's not yet
fully developed this is a kind of
semantic tagging if user consider
contents of documents we use
webservices tagging services from the
web in order to combine them with our
PMO and then make proposals to the user
how the user can tag information another
example is semantic search so which
means because we have the Pima model
with all the semantic the concepts and
the instances we can input some strings
in our semantic search entity and the
system then shows us relevant aspects to
that namely persons projects concepts
and events which are related to this
string so for example the string vit o
belongs it could be the first name of a
known person which is stored under this
uri there is another person found how
does it come from because well we also
find a broad check this is this project
called business register
interoperability throughout Europe and
the guy who is the project leader is
Burt inclined and Vito Gwen Ella he is a
project member on that so all related
aspects are found by such a semantic
search which looks in more detail like
that that we have search fields over
here we have first of all the overview
of the most important instances and
basic classes what we have we have
another more detailed interview where we
could provide rule based retrieval of
related instances namely concepts and
documents they are other ones like
customer requirements so it's not
limited to this consideration depending
on all the classes using in the PMO but
for example we have Sparkle rules behind
that if you found the project also show
the members you can relieve them with
respect to the query itself so our
architecture for this semantic desktop
has two fold the one which is below
combines the native sources from outlook
file system or email server with torture
crawlers and then we have
Colonel of season me to repository with
the Pima store resource store and couple
else and then a couple of services
including clustering tagging crawler and
so on and we have some interfaces which
are provided through the web itself
namely we have editor we have the
personal wiki a semantic wiki
application plugins and desktop
applications just to give you examples
we have already realized a interface
towards Firefox thunderbird or outlook
even to inquire to where we have such
plugins and it's very easy to to browse
and to search via these plugins in the
PMO for related aspects you need however
if we consider resources themselves they
are of course valuable for individual
users but it's also important to note
that most of the information is captured
is at all the beginning within documents
and the question would be if we already
know about persons events topics etc
which are described within documents how
could we further deepen the analysis
into the documents themselves and we
just started to use lots of our
experiences in document analysis to do
that and the first one is for knowledge
workers which are not working on mass
applications of document analysis
problems for example at their personal
desktop when I talk about future of
office work we also have to think about
interfaces which allow us to bridge the
gap to Gutenberg's world and so we work
with the kind of table camera i just
presented this at the ector conference
in core giba last week I have it with me
in the car unfortunately but I can give
a demo however so we have a camera and
we staff the camera with OCR and the PMO
itself and the camera allows then or it
protects first of all a kind of laser
frame on the test
we could put in a paper over here you
may click and you get the paper in your
laptop with OCR information of it and
then the pmo itself proposes a kind of
category for the document and
furthermore identifies in the text known
concepts known instances known persons
known events and this is then published
within a semantic wiki which is shared
by a group for example where all the
known items like DFG I this is a known
institution bis is a known project
kaiserslautern the city I came from is
known by the system etc my person so
it's very easy also to use the PMO to do
a kind of intrinsic tagging of document
not only the extrinsic view just to tell
that this is a kind of invoice or
whatever but also to look into the
contents and to build relationships on
the semantic layer and this is a very
important aspect because when working
with document yeah with respect to your
specific problems your individual
project it's also important to look more
into the text another way to do it like
we see it is to use pen and paper we
just started a new project we are using
the annatto pan which is stuffed by you
know all of this not only ink but the
pressure sensors so we can really do
online recognition of handwriting and
Chester's and so on but we also tend
towards a kind of semantic gesture
making on the document as soon as we
find a new person which is unknown up to
this moment we could just do track 'it's
in a certain way to show the system that
this is a new person yeah so we are
building different interfaces to
integrate printed information
paper-based information into our
considerations
another very important topic is I talked
about user observation and I up to now I
showed you only the example of this
browser but we have mouse position and
cursor maybe to use sex information but
there is much more we can do and last
year we started a very promising
approach about I tracking which is I
Triton is potentially used in
advertisement to just check how people
look on specific information to do
optimal position of the advertisement
information you want to give to it but
today the technology in in eye tracking
allows us without any special device
just to look at information and be very
accurate and this is an example from
in-house from google ow people look at
information provided by google just 10
results and our intention is to also
observe the user while she or he reads
information on the screen so for example
if we have a document on the screen we
are now able to just track the success
these decades over the text the duration
of fixation and therefore could also
determine reading modes whether the text
is carefully read or a user is skimming
over the text or is neglecting specific
passages of the text this is very
important assume just you would put in a
document in a folder but you only read
the second paragraph why should you
index the whole document you would not
remember the whole document you should
index of course but you should
individualize the way of indexing
because the user will remind this was
the important thing for him yeah so this
is one of the most most important
outcomes of our research that we just
published a paper at thi that we now are
able to really measure the relevance in
the way
user reads information and this is
another way of visual feedback to
information which is valuable for the
future we also integrate this into our
semantic wiki considerations to keep
track of attention and information in
the personal workspace etc and so to sum
up I have some more ideas about it but
let me first sum up up to now so we also
think that I mentioned at the beginning
that the web is changing several
considerations towards the web of people
and focus today is set on Fox on amis on
community building collective
intelligence and most important this
also affects the way how people work in
the office and so the sharing and
collaboration mode is changing
step-by-step opening itself you are
giving information is more important now
to know how instead of collecting
information hunters and collectors are
out sharing information is in so the
semantic desktop we see is one of the
driving paradigms in order to provide a
new way of desktop computing where we
use on one inside aw D of s RDF may be
old sometimes but integrating also
native applications which we have on our
in our workspace so the web is part of
our thinking and part of our work space
on the other hand the documents would
generate are becoming part of the web
and we have trusted networks of friends
which allow people to work on other
people's information and this is also
part of our strategy that semantic
desktops are very nice on one end side
but you have to consider the recent
trends what's going on in a whole web so
we are going to socialize the semantic
desktop which means that if we consider
the web 1.0 and we see the semantic
foundation this is still very low and
also the community
relationships but we today have web 2.0
and we also build on a semantic web and
our intention is that we can both
combined both via the semantic desktop
having trusted communities which built P
Mo's and then we have a kind of ontology
mapping and merging in between with
establish knowledge goods no tradable
knowledge which is handled by machines
which describe limited domains of
expertise and which could be shared
among different Pierce so we applied in
2005 in the EU for a project called
semantic social semantic desktop the
project name is nipple MOOC this is the
largest integrated projects right now
from the last call in the EU with a
couple of a lot of partners and the best
thing is up to now we have not only
least 15 fixed project partners but we
were able to acquire 50 other partners
including big companies like itachi
which share our ideas and this is
open-source the platform we provide up
to 2000 a date is open source so
everybody can share and develop new
technologies for the social semantic
desktop so this is the kind of plan we
have because our intention is also to
provide a couple of spin-off next year's
on the social semantic desktop so we
start with internal exploitation and we
also what would like to come to external
exploit external exploitation in the
year two thousand and nine and ten etc
while we already today have some
companies we convinced to use it
internally so furthermore we also think
about how to provide a physical
environment for the semantic desktop and
I just convinced a couple of sponsors
and companies to provide as money and
this is the first scheme drawing of it
it will be available very soon made of
October already so we are going to
integrate all this technology
having three large screens around us and
having various interface technologies
like tablet PCs touchscreens pins table
cameras I told you about and in January
first we also start with e paper we have
some very valuable partner on that and
see what happens so thanks to my team so
it's a big team as you can see and thank
you for the attention and if there are
questions I'm of course ready to answer
thanks please please I can't unsend
my question is in your experience
working how feasible or easiest to get
the user to develop
okay I have to repeat the question the
question was up to my experience how the
user is willing to participate in
developing such a scenario at his own
desktop and use native applications and
put them together and build ontology
well to tell the truth we made
ambivalent experiences it strongly
depends on the kind of virga user is
doing we already try to convince for
example insurance companies in a kind of
scenario just mentioned but the truth is
that today their technology and the way
to think in their technology is far away
from ours already so they have very
basic infrastructures some companies
share for different archives so this is
a heterogeneous platform which is very
hard for them to handle the complexity
is very high but if you go in
environments how like we are working in
and we have tools which are not only
manual driven but rather learn from the
user step-by-step adapting the behavior
towards the user people are very willing
to do that all of my group members
without any pressure use these tools and
we have shared ontologies already
finished and so it's a lot of fun to
work on such platforms and this is
something I think this is inherent to
the web 2.0 those people who participate
in YouTube and Flickr and chair the
information yeah they are also willing
if they are tools available yeah which
support them in building up first of all
trusted communities so small web so
bring the web from the desktop too small
semantic webs and then evolutionary
establish the web of meaning this is
strategy will be long please
why
yes well the question was that mailboxes
are sometimes organized in a linear
order so they're most very flat and
people do it in different way temporally
organized topically organized contact
organized so it's really very individual
how people do that so what we did and I
showed you this multi-perspective way to
organize information it allows you in a
first step to just import some of your
taxonomy is for example from the file
system and then start to work which
means if you have folders and you put
some whatever you have say contacts who
puts everything to contact it learns
about how you consider information if it
belongs to contact but we also recognize
that over time people tend towards
opening up a different view because they
recognize that it's inconsistent just to
have one single view so they put out for
example I give you I had an example
where the documents are organized by the
roots named documents nothing else and
then were documents for example of an
employee of a company called German post
so German postal services but German
postal service is not a document but in
the folder again there were other
documents like an offer so people
recognize that the the the this user
recognized it and opened up another view
liked organizations and put this folder
it's very easy to track and drop for the
folder here and also make a link to
other folders and over time it's also
possible that the system could be
reconfigured in the way that you ask the
system to reclassify the information in
order to the new profile which is
generated over time so the answer is
people learn how to use the system
and step-by-step provide alternative
views to it please
the question was that the suspect is
with respect to my statement that most
of my club members are sophisticated
users and whether we have experience of
unsophisticated users using for example
usability cases or tests with them okay
so in a very early stage with some of
our technology including this personal
memory technology we did some use
abilities with a mixed kind of success
to tell you the truth because you need
some kind of knowledge how to use such
systems in order to profit yeah this is
very important to say with respect to
the semantic desktop we change a little
bit in strategy in that way that we
would like to have the technology with X
in the background you don't see it
really yeah but you are able to
complement the technology by the plugins
just browse or link or search which I
showed you in native applications so the
intention is to not change anything but
rather do have additional functionality
working in the background but however
the plan is that in the third phase of
these nipple moog projects we are
concentrating specifically on usability
and we have usability groups in April
MOOC which today already design use
cases for it to get some feedback from
users
please given the relevance of the
information stand out so that you can
see the contacts the timing the person
is all so why even bother why not just
what you're doing search filter design
yes the question was because of the very
heterogeneous way how people organize
the information why using taxonomy and
not just search correct well search from
my point of view or only addresses
intrinsic characteristics of information
which means that you need to have the
string inside of a document but
sometimes documents have a certain
meaning like being an invoice without
having the term invoice in it so you
need also extrinsic features to describe
the information and furthermore you have
to develop a kind of object of objective
taxonomy which is common for all persons
at the same time many companies do that
and you can see this also in the
development of Google who will also
return to folders the question is why
people tend to organize information
within folders to have a complementary
way how to use it it's very important
search is important i completely agree
but sometimes document should be
searched by information which is not
captured in documents but in human way
of thinking
please yeah the question is that with
respect to audio fo DFS and the the
performance the scalability of the
system up to our experience how many
data will generate when we work with
such environments well today in our
group the people have about have been p
MOS which are about up to 500 notes i
would say 500 these different concepts
to be used and this is still somehow
Hannibal you should not I'm not sure how
this would develop it's what we can
identify is that many colleagues use
existing concept of others when they
already exist because the system
proposes concepts which are pre given by
others so they didn't do not reintroduce
something similar so over the time I
think there is a kind of logarithmic way
how to two step by step find a kind of
threshold which would help but I can
tell you real results up to now
yes we have a you have up to 7,200
triples at one workspace yeah but but
maybe you've heard about this new
initiative in Germany about the tea
sighs project give guys the main
research partner in that and this ice is
a very huge project right now you can
see that in all the new stickers in
Germany it's a project for five years
and it's an annual budget of close to 50
million euro and our intention is to to
really give a push to Sigma X semantic
search but there are also two tendencies
there is one who is more top-down which
is more tore down and mine is more the
evolutionary bottom-up approach ok
that's it so thanks a lot for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>