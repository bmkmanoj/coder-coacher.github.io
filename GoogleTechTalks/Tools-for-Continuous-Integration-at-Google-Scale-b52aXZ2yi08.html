<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tools for Continuous Integration at Google Scale | Coder Coacher - Coaching Coders</title><meta content="Tools for Continuous Integration at Google Scale - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tools for Continuous Integration at Google Scale</b></h2><h5 class="post__date">2011-01-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/b52aXZ2yi08" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let me introduce Nathan New York he's a
beginning my speed with Google about six
years and been an integral part of thank
you sure our engineering tools that
systems have been growing at the scale
of Google's growth both in terms of
users we have and also the hardware at
first the applications and the offerings
we have so a native is call themselves a
tools guy and I let him share why he
thinks that and also talk about the
tools for continuous integration ok
thank you so yeah I'm here to talk about
tools for continuous integration at
global scale and this is really this
talk will really be about the build
system and how we're using the real
system to enable this type of
integration system so a quick question
how many people here interact with the
build system of some sort quite a few a
lot of managers in the audience ok
that's ok
so how many people actually really truly
love their build system totally happy
with it yeah ok that's kind of the
response I was expecting so a bit about
kind of what we're doing it at Google
and this talk will not be just about
what we're doing but how we're doing it
we have a dedicated tools team within
the productivity area and we've been
working on the scaling issue at Google
and particular the challenges that are
specific to the way we work at Google
and we've been working on this for about
six years was a fairly decent-sized
engineering team and so this talk is
really distilling kind of the key
insights from six years of development
into this one talk to share with you
guys and the reason I really want to
share this with you guys I'm excited
about this is the first time we've ever
really talked in depth about what we're
doing and we want to share this because
we feel like build systems are really
not talked about much and they're often
overlooked and in many ways
underappreciated and this leads to what
I refer to as a software engineering gap
where we spend a lot of time and
resources on kind of the very low-level
platforms and pilers we have very
specialized people in this area
and then of course we hire specialized
teams of people to build applications
and features but there's this gap in
between where the tools that everyone
are interacting with are in many ways
just overlooked and under provisioned
often developed in-house many times it's
just some poor guy who gets stuck with
it usually the new guy on the team or an
intern or something like this and in
most cases the the bar is pretty loads
you get to the point where the tools are
good enough to use and then you move on
and hopefully you'll see in this talk
that really believe that there's so much
more potential there so what this often
leads to and this is probably why a lot
of people are frustrated with their
build systems are things like incorrect
and flaky builds slow builds that's a
very common one spending a lot of time
waiting for the build system having a
cumbersome and/or fragmented build
system so many companies I believe once
the code gets to a certain size we we
see that pieces of it pieces of it start
fragmenting off into different kind of
code silos and then of course there
needs to be a process for you know
integrating this stuff all back together
and it can become very heavyweight
process and of course usually this is
under maintained overall and so one of
the insights we had here very early on
was that make clean is actually the sign
of a deep flaw in the system if you
think about it if you if you don't trust
your ability to do a incremental rebuild
we're really saying is you don't believe
the system has correct information it's
not gonna be able to understand what
you're doing in a correct sense and this
is one of the things we set out to
address and so there's also a question
of why why build systems matter right
and of course in an agile test-driven
development type of model you know
however long the the tests and the bill
takes that's how long people are waiting
at each iteration iteration that's
important but also this affects the
ability transitively for things like
automated build systems and also
building and releasing products
basically the the the build system forms
the core of productivity
and in the end this is all about getting
feedback to the user right and the build
system is kind of sitting at the the
core of this feedback loop
you know I'll point out here also that
one of the things we discovered very
early on was that in the race to get to
speed oftentimes correctness has
overlooked and we found that this
usually is counterproductive so it's
easy to spend much more time diagnosing
incorrect build results flaky build
results than the actual gains produced
by the build system so the challenge
we're facing at Google 6000 engineers
spread out across worldwide offices one
codebase everyone's working on the same
codebase people don't generally work
from branches everything is built from
source we don't build really from
libraries except things like system
libraries this has advantages we don't
have things like big integrates so
called merge hell it also makes the code
very open and transparent people are
free to experiment it's very easy to go
in and change some core piece of the
system this doesn't mean that they can
just check in what they're experimenting
with but nevertheless it's it's very
easy to try ideas out and there's a set
process for how to get these changes
back into the main code line and of
course one of the keys to making this
all work so that we're not all just
sitting around fighting broken builds
all the time is very very extensive
automated testing and there's a link
here on the slides to a talk that
Patrick Copeland the director of
engineering productivity gave earlier
this year in Paris he kind of goes over
some of this stuff in a higher level
detail so some of this is a repeat of
what he talked about earlier but I'm
going to go into more detail this is an
eye chart
it describes really a rough outline of
our developer workflow
and this is kind of a very rough cut but
this is our understanding of how
engineers at Google work and for those
that are probably even in the front row
who can't read this
processes really start with a clean
client Chuck Allison code obviously that
you have to do a clean build the first
time to get the initial build results
make some modification run some tests
iterate and the code review process
includes this iteration and at the point
where we actually submit which is down
on the bottom left box there once that
submit goes in everyone in the company
sees it and if you broke something
everyone's gonna see that breakage so
just you know this is one of the reasons
that having good tools for this type of
working environment is critically
important so we realized that our older
make based system was really
insufficient for what we needed we
needed a better build system and one of
the things that we one of the insights
we had was that build metadata things
like describing the dependencies the
inputs and outputs in the source code is
really a type of source code in and of
itself and as such it should be treated
as any other kind of compiled language
it should be deterministic well
specified it should enforce things like
dependencies and inputs and outputs so
we built a better build system it's it's
really an optimized and tuned
implementation of a build language it
does dependency analysis and scheduling
it's not just a build language but a
complete build system and it leverages
Google infrastructure to provide
scalability and kind of the bottom line
and all this is we took this as an
opportunity to really reinvent the
again getting back to this speed versus
correctness kind of trade-off we really
believe that this is a false choice
people talk about choosing one or the
other and we decided let's choose both
correctness and speed so moving on to
another insight that was a core piece
conceptually of how the build system
works was that
this notion of content addressable
storage that we can refer to files not
by file names and timestamps but rather
by the the digest of the content itself
and that we could use
we're in places where we do need to use
some type of path to set up an
environment for executing a some type of
compiler or tool we should be really be
using relative paths instead of absolute
paths this is all really about trying to
eliminate global State in the system and
to have Universal handles to the
resources in the build so that we can
build a functional build model so the
idea is that you know in this functional
build model we have files our values and
expressions or actions as we call them
are transformations of files so we have
this very simple functional equation and
of course outputs from an action can be
inputs to another action so this is how
we set up the dependency graph within
the build system it's all well and good
but of course one of the issues with
content a digest of the content is that
you need to actually be able to read the
content to get the digest and if we're
talking about again building everything
from source code eventually we got to
the point where we are reading a very
very large amount of source code people
were checking out very large amount of
source code was taking a very long time
to get the build system was taking a lot
of time just doing i/o to read the
contents to get the digest so we
actually built a special-purpose file
system for providing source to the build
system for those of you familiar with
fuse file system and user space this is
a fuse based system it provides only
read-only access it actually gives an
entire view of the entire code
repository over all points in time so we
can see snapshots of the repository at
any arbitrary point in time it does this
efficiently by only pulling content on
demand so as as users or tools like you
know GCC or Java C or whatever are
requesting and opening files at that
point we go and pull the content down
but we only paved
the content transfer once we do very
aggressive caching and reuse and the
immutable part of the file system is
really key to this right we know that
the files in the file system don't
change into a way to change the snapshot
we're looking at this also means of
course that we can keep all of the
source code in the cloud until such
point it's needed on the workstation and
also this means that we can provide the
digests for the content as part of the
metadata in the file system so in fuse
we're using the extended attributes in
Linux this means that the build system
can then get these digests without
actually reading the content and one
interesting observation from this when
we rolled this system out was that only
about 10% of the files that were being
synced by developers were actually being
read during a build and this was after
you know doing a very good job of trying
to limit the scope of what we were
pulling down we were still trying to
pull just the dependencies that were
being declared we found that in many
cases that was even much too broad so
the next challenge once we get the
source code was to make the build fast
and what we find is that this notion of
a functional build system where we don't
have global state and the source code is
already in the cloud allows us to
execute build actions in arbitrary
locations so build action can be again
like a compile a link a Java C a jar or
whatever and so this allows us to do
large large-scale distributed execution
of arbitrary actions and this is
language and agnostic we could even be
running shell scripts or whatever the
case may be as long as those conform to
the the functional notion of the build
model the scheduling and the parallelism
is really only limited by the shape of
the dependency graph and so there you
have it we can do we can basically
distribute the load across Google
production infrastructure so we can do
things very quickly but of course the
faster we make
engineers the more that you builds and
the more they do builds the more load it
creates sorry next issue is really how
do we scale this up so that we're not
spending a huge amount of resources on
doing a bunch of builds in many cases
the builds are sharing overlap or not
having overlapping information and so we
found is we can actually want the
insights is that we could do with this
functional build model we can do caching
at the build action layer so if we see
the same inputs and again the inputs are
defined by their digest so if you see
the same digest as input and the same
action that we've seen previously we can
just return the cache cache result for
that and we avoid actually reacts acute
in it this means that in most cases when
engineers are doing builds are actually
getting the build results from people
who had done build previously it's
really the equivalent to like an
automatic binary release every time
someone checks in code and does a build
but it all happens seamlessly and no one
actually sees it as a release and the
the overall amortized cost is very low
we'll get into some numbers on the
results of this in a bit and then
finally the last scaling problem we hit
was one with how to deal with the build
outputs we were so effective in
distributing this across a large number
of machines that we were basically
saturating the network links and
overloading the workstations so we had
to build a another file system for
storing the outputs from the distributed
build on the back end the idea here is
that again we can present to the
engineer the illusion that you know the
build outputs are available locally but
in fact they're all being stored on this
back-end system and they only downloaded
at the point where one of these files is
being read for example to be executed or
you know to run a debugger on it for
example and this is also a fuse based
system so this is a
SystemVue of how this works we have the
workstation on the top we have a build
in the better build system that kind of
sits as the user interface between
several or two different file systems
and another client that talks to
distributed builds on the backend the
the backend is storing and retrieving
objects directly to the bat the object
back-end for engineers builds look like
they're happening locally they see all
of the warnings and things going by on
the screen it looks just like locally
that's going extremely fast and in fact
all of the activities happening in a
data center and the interesting thing is
that you know the data center can even
be on another continent and it's fine
like we can locate the backends in
multiple locations it doesn't
necessarily need to be all that close to
the engineer so what does this have to
do with testing I've been going on and
on about build systems this is really a
backbone for automated testing systems
this is a platform to build upon and one
of the insights we had was that
executing a test is just another form of
a build action a test you have the the
action being executed is the test itself
the test binary the inputs are the the
data files if there are any of those
being passed in as input and the output
are the test results the the test log
essentially so and we can break up very
large test we can shard them into
smaller tests but this allows us to run
a very large number of automated tests
in parallel as it's fully integrated
with the build system so engineers can
say you know I want to make my project
and then run all the tests and this all
happens in the cloud so to speak
this means that at this point we can do
automated testing of all changes going
into the repository currently about 50%
of the activity we see is from automated
systems and the automated systems share
the same action cache with the rest of
the engineers as well so
yeah the interesting thing here is this
means that if someone checks in a
breakage for example the automated
systems pick it up very quickly and you
know emails go out and the alarms go off
and people get nagged mail to a rollback
your change like you know you're
breaking everyone so we get very quick
feedback to engineers on the state of
their change so this is all well and
good theoretically but what kind of
results are we getting so our code base
actually changes about 20 times per
minute
about 50% of the code changes per month
but we're able to keep up with this
change rate running that the 10th the
builds we do about 65,000 builds per day
20 million per year we run seven point
seven and a half million test Suites per
day
this requires on the backend system
about 10,000 CPUs with about 50
terabytes of memory and it produces
about 1 petabyte of output per seven-day
window this is unique output going back
to the scaling and the importance of the
caching in the distributed build system
we have about a 94% cache hit rate so in
most cases you know 94% of the time what
people are seeing as build results or
things that are coming back from the
cache um only about 10% of the builds
are clean these tend to be things where
people are creating new clients or
automated systems that you know are
doing this out of paranoia but we
believe that most most of the engineers
now grown accustomed to the idea that
it's safe to do incremental builds and
even though we're building all from
source and we're generating you know a
very large amount of output build times
are typically five minutes or less some
variation and then depending on the size
of the build but also going to the the
title this talk why I put global on
there we actually get the very similar
build and test times in offices around
the world so it's very interesting if
you think about that we we have the same
tools same come
online in all the offices around the
world and they all have very similar
response and it's all very fast it's all
you know within the five-minute area so
this is a this is an example of what
we're seeing globally this is average
time of builds over a period of days in
September from different offices this is
in milliseconds so we see that there you
know there's some variation there but we
have Munich Sydney New York and Belo
Horizonte and Brazil and they're all
fairly close together in terms of their
performance so it's just a show that you
know we are in fact seeing the
performance we expect going back to the
clean versus incremental builds the
far-left bar here over the zero those
are the clean builds and the bar over
the right those are the incremental
builds those are the smallest
incremental builds we're like a single
file has changed and so we see that you
know indeed most of the build activity
is now just doing these small
incremental builds which is what we want
we want people in this kind of tight
build debug edit cycle and then also we
did some analysis based on how we how we
believe users are interacting with the
system basically their frequency of
different actions in the workflow and
estimated that this is a very
conservative estimate but estimated that
the the tools we built are saving about
600 person years so again this is a
fairly large engineering organization
but it has probably even more beneficial
than this because there we know people
change their behavior when build times
improve right people get up less to go
get coffee and you know talk and chat
and stuff so we know that they're
probably the benefits are greater than
what we're seeing so my conclusion is
all this the build system has really
should be viewed as a core component of
software engineering it's unfortunate
that in
cases it's not and many of the kind of
esoteric principles of build systems
things like Hermeticism and correctness
reproducibility are often kind of pushed
to the side in the name of expediency
and we're actually finding is that
correctness is just as important to
speed and scalability as you know
distributing load across you know many
machines and so kind of the question I
want to leave with before I ask
questions of you guys is how much does
good enough cost what's your experience
with your build systems and hoping you
guys will come up and talk to me during
the the mingling time because I'm
interested to you know get more data
points on and what people's experiences
are with this and again get people kind
of thinking about this so with that any
questions and we have 100 so sorry yes
very clear we have very extensive
automated test systems so as again as
changes go into the repository automated
systems see that and start running the
test straightaway and so those automated
systems are using the same caching
mechanisms that the interactive users or
the developers are using so what happens
is as those tests are executing it's
actually pre warming the cache so that
when engineers come along and are doing
the next build they're hitting the the
warm cache make sense usually any build
cycles we do is mainly been on a base
dinner or time cycle that time stamp
here you are talking about metadata
which is actually having all the
information for the bill to happen so
will it say which compiler what what
information this metadata contains
and when I check in the code should I be
mentioning or what is the compiler it
should run on and all those things
formation because every time I check in
I have to update the metadata is it what
is the expectation no I mean obviously
at Google our our current build system
is a little bit we're not dealing with
as many platforms maybe as some places
so the goal is to not have people
changing the build metadata frequently
although they can and it's it's written
in a fairly high-level language but in
general we don't expect that people are
changing the the build metadata every
time they're checking in that make sense
so what because the bid cycle
is it a tickin and taking timestamp yeah
so several things can trigger a build
cycle so one of course is the engineer
just requesting a build but the in the
case of automated build systems we have
things listening to changes as they go
into the repository and as soon as you
know a change goes into the repository
various automated systems are triggered
okay thanks
so the question is how much of the
five-minute bill time is from the cash
versus distributing the load and it
really depends right I mean we have peak
load times where there's not a lot of
spare capacity and you know you know
totally clean build may take longer than
it would otherwise that the cash is not
warm but the the primary feature of the
cash I would say is just the ability to
scale if we look at the the cash hit
rate that we see and the amount of
resources that's currently taken the
build you can kind of interpolate how
many CPUs we would need to have without
that caching to do the same level of
activity it would be significantly more
expensive it's more of a resource usage
issue and in the back if I understand it
correctly the complete build is
controlled using the build config files
and other config files so how much
effort is spent on constructing or
building that config files
I mean how easy or difficult yeah so the
the build language itself we've gone
through a fair amount of effort to keep
it clean and simple it's fairly
declarative but of course there are some
ways to extend it and add more features
to it as teams need need to add those
features the goal though is to make it
as simple as possible for people to to
deal with it's it's no more it's hard to
make a comparison on how difficult it is
but it's it's not overly complicated I
think the main feature is again we try
to focus on declaring the the
dependencies and the the inputs and the
outputs along with any other metadata
required things like you know options or
whatever we try to focus on what the
user actually needs rather than forcing
them to think about how do we how am I
going to distribute this or how am I
going to scale this there's no notion
for example really a well there's some
notion of threading but not really so or
more questions
yeah so the question is how to take care
of multiple platforms in a build and so
within Google we do have several
different platforms we use and there is
a notion of like host versus target
platform and there are ways to do that
if I could really distill it down to the
the content of the talk it's really the
the definition of the action includes
the binary that's being run so for
example if it's a cross compiler and it
includes the options if there's some
type of option to target a different
host platform that's all part of the
action description some part of the code
can be common between platforms do you
like I mean do you have a separate
compilation for the common part of the
code or so we do we have ways handling
that I can't really go into it here but
okay so yeah we do have ways of doing
that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>