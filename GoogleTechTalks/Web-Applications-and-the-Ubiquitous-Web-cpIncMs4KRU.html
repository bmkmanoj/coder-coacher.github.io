<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Web Applications and the Ubiquitous Web | Coder Coacher - Coaching Coders</title><meta content="Web Applications and the Ubiquitous Web - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Web Applications and the Ubiquitous Web</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cpIncMs4KRU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to introduce dave raggett Dave
and I go back a long time I think we
actually started working together in the
93-94 timeframe on what was at the time
called HTML max he then did math ml
together and we did forms together and
the last few years Dave's been the w3c
lead for voice and multimodal and the
thing I like about Dave is that whenever
he does new things with the w3c he
usually first built build sites so he
builds a few things and then you know
both around throwing little lighted
match sticks around to see what fires
cash and the thing he's been focusing on
the last few months are actually the
mobile web which actually he's been
focusing on for quite a while in the
context of multimodal but he is now
driving the mobile web activity along
with the ubiquitous web does it'll be 3c
and his talk he's going to show you some
interesting things he's been building in
the context of web applications he's got
speech and his demos he scored Alec
window TTS and ASR engine and he just
told me that his ASR license is having
problems so you'll have to take his ASR
bits on faith but hopefully the T TS
bits will work in this demo so mom take
it from that end we are going to be
recording the stocks or hold questions
for after the video cameras stop rolling
since you and we will be putting this up
on google video thank you good it needs
to be here so how many of you have
actually coded HTML tables by hand okay
all right if you want to shoot the
person who's responsible that's me
okay so I'm going to do presentations
and one of the applications i'll be
talking about just called HTML sliding
so sort of a powerpoint my clone and so
basically i'm going to cover the
following areas there's some new area
which I've instead of promoting and
called ubiquitous where which we'll
start with then i'll be doing a
described work I've been doing the last
few months with Luke window on speech
enabling web pages using Ajax and
unfortunately I just discovered although
I gave this demet successfully yesterday
the AVR speech like west conference in
San Francisco I think my license must
have expired overnight because it was we
license the software i think from
january through january and now it's
februari but so sorry about that have to
give you a canned version that's right
everybody well okay and then i'll talk a
bit about this sliding the idea of web
presentations and how that can be in
expanded on to web meetings some ideas
for doing that together with audio
control through ajax and some sort of
opportunities potential opportunities
for exploiting this business point of
view ok so the oxford english dictionary
says that gives us definition for the
ubiquitous is something effective just
often encountered and seemly present
everywhere and the term really goes back
to knock riser in the early early 90s
and heat while he was working at xerox
parc no you started this work up on the
bicker dis computing and so the idea of
being you be able to have all different
kinds of devices which are networked and
that's kind of come true to some extent
now now we have the a lot of devices the
networked but we've yet to really take
advantage of that that's the point of
view of the web the web has been very
ubiquitous released on the desktop and
to a gradually improving degree in the
handset and letting the phone but
there's many more opportunities for
exploiting the kind of perfectly
the devices give them to work together
and in combination with services network
services so the ubiquitous web sequence
6 doves were pretty broaden the
capabilities of browsers to enable that
to enable new kinds of web applications
particularly those involving this
coordination whether devices and network
services there's some examples you hang
on skip of this ok the main idea behind
this is that you really want to be
identified resources and manage them in
the context of an application session
and it could be that these resources are
like hardware devices or it could be
that there are services and so the idea
is to provide a framework for exposing
device coordination capabilities to the
web browser so that you can take
advantage of the power of the web the
ease of which people can develop web
applications using markup scripting
style sheets and images and other
resources
so to support this to get this off the
ground I'm organizing a workshop for
double 3c hosted by double three C's
offices in ko ko university in tokyo in
early March and it's got these three may
instead of areas we're trying to do is
to really explore the vision of the web
as a distributed applications platform
and to help people to develop
applications this way to increase the
range of such applications the main
things you can do today is just hard
work so we want to be able to extend the
range of applications district
applications and just the cost of
developing and applying those
applications and another goal of the
workshop is to explain the work that's
already being done at doubletree see in
this area in this context so there's
work on essentially standardizing things
just been out there for some while and
the web application api's work such as
exit XML HTTP there's also some work
which I started off and the multimodal
group a few years back and on the
adaptation and that goes under the name
of delivery context interfaces and then
there's the idea of device descriptions
multimodal architecture these are all
through pieces of activities going on
different working groups wtz today which
have a impact on the ubiquitous way so
the workshops are usually there to try
and see if it's right if it's really the
community the timing is right for
further standardization work so in this
case a is to identify prioritize that
such areas and in particular I think the
areas which seemed to me at least and
obviously went to ground this through
the workshop is the integration of
sessions and device coordination into
web applications and okay
so a little bit more detail about the
current work with been going on so the
the web api is working group is part of
the the rich client activity and that's
of standardizing existing to the web
scripting interfaces such the window
object and xml httprequest then in the
device independence working group
there's this piece of work I should have
brought their on delivery context
interfaces this work has changed its
name over its life is it's moved from
one place to another so it was
originally called a system environment
then the dynamic properties interfaces
and then finally delivery context
interfaces and so the idea is you want
to be able to model user preferences
device capabilities and environmental
conditions as news is the Dom tree is it
of the Dom nodes so then you can swim
manipulate them in the same way to
manipulate markup and so the idea is
then to allow applications to navigate
down to those conditions example and if
you have a multimodal application and
you mute mute the microphone to make the
output maybe the application needs to
change its behavior accordingly you'll
also have other kind of conditions which
is a bit you might occur like maybe the
battery's running low so maybe you can
get a Dom event being thrown from these
Dom nodes to say your application then
you can adapt and do something
appropriate to the fact that battery is
going to run out you might lose your
work or maybe the networks are the
network isn't very good you were in a
poor connectivity area and so you can't
really expect to download a video of you
view so there's a framework there it's
something of a last call working draft
but the next and the real big challenge
is to get people to agree to what kinds
of properties what kind of descriptions
you want to do and so the best thing
there is to try and build them what
agreements there already are it's an
example would be properties describing
printers and media print media where
there are existing industry groups who
sweated blood to try and reach agreement
on how calling a 404 and things like
that so that's one piece the piece
puzzle and the next piece is how do you
couple various components together and
so in the multimodal working group has
been working on earth with an
architecture multimodal architecture
into
faces the loosely coupling components
user interface components and an
interaction manager by exchanging events
and so that leads onto some work that
I've been doing indeed the ITF with
bladder boo from Nokia research and
Finland and so what we've been looking
at there is we've set up a new working
group called with ex working group and
the idea is really is to support of
remote user interfaces where there's
user interface is described in XML and
you can have the application running
remotely in the network as part of a
general theme of moving the applications
making district and moving them into the
network and so in this case the idea is
that the application logic of the
interaction manager whatever they turn
use can send updates Tom updates over
the network to the UI and the UI can
then send events Dom events back
actually it's more symmetrical now but
that's the simplest case so that group
is just a it's been launched a few
months back and we've now got the first
requires draft and we just make the bit
smaller so this is a kind of a diagram
of a call with Aksarben with X renderer
and you can see on the Left that's the
server with a kind of a model view
controller sign and that's passing
events to the widick surrender it could
be running remotely in the network and
it can be more than one render or more
than one view for each of the instance
of the the server so that might be used
coordinate different devices as part of
the same application so the idea here is
to be able to describe updates to the
dorm as XML and so you could them
of the network so the idea here is
although it the groups called with excel
with it a widget exchange protocol is
actually independent of the mark-up
views of the user interface so it's
generic mechanism and so you'll got
updates which basically involved
modifying some part of a dom tree and
identifying which the Dom tree is in the
context of a session and then you have
events sort of generic way of passing
events of Dom events back so again in
sort of XML payload without being
specific about just what those events
are
so the there is a first requirement
draft not public and available to
comments and this will and also that
when I get back in this trip i'll be
working with Vlad on perhaps coming up
the second version of comments we hope
there's a number of different proposals
particularly for the updates and you
just have study there's a new bit more
detail and in particular as in the OMA
the quest do I made the urban Mobile
Alliance and some double 3c members
there's some work starting up in the
doubletree see a task force which is
between the compound document formats
working group and the the SVG working
group on something called a Rex and the
idea here is you want to build to stream
updates to for example SVG for an
animated sort of the user interface so
that introduces our timing constraints
as well so the both the doubletree seen
the ITF record of closely coordinating
the work on this so one could of
question really is what sort of a
missing or what's improved one server
what technologies are are needed for the
ubiquitous web and so to the one of the
key things really is sort of managing
resources in the context of sessions
today there are kind of ways of
describing sessions or sort of not very
directly in terms of cookies or
embedding session information within the
your eyes but there's no sort of way of
making that explicit so what the idea
here is to build to perhaps use a URI
itself it's in the competency of spirit
of the web architecture to name devices
sessions and things like that and
services and that then allows you once
you can name things using your eyes that
means you can then start to express
metadata provide rich descriptions it's
like to bring the power of the Semantic
Web for describing with devices and
services and so forth and that then
allows you to start doing discovery of
devices and services using full power
kind of web technology rather than kind
of the weaker approached interfacing
things low-level techniques such as upn
another component theme is extending the
device capabilities far network
resources and to the example try and
demo
is that of using through the adding
speech capabilities to modern web
browsers but there are other kind of
examples will be you may be natural
language translation services and/or
geographical location services and many
others okay so we want to support
applications involving more than one
device so you might have a handset like
a phone and a wall screen or as a very
crude example you want to use your
handset to control the wall screen in
through the network in urgent news not
necessary directly connected at all so
we have this in summary there is this
keep key thing about using your eyes and
naming things so we can apply metadata
okay so there is already quite a fuse of
techniques for doing device coordination
but not exposed to web pages if you
wanted to try and make use of them you'd
have to write maybe an activex control
or something like that and work on some
kind of proprietary approach but there's
no sir General framework we easily doing
these kinds of things from with
interface script in a web page today so
device coordination really has these two
followings to the basic ideas first of
all winner when a service is made
available you want to be able to
describe that in some manner and
register it so it becomes discoverable
you you want to have a mechanism of the
supporting that discovery and it may be
that it could be kind of a local device
and same device like some years back
when you had the cellphones the separate
cameras when you snap the camera onto
the cell phone now suddenly the devices
more capabilities or it could be it's a
remote on some servers and wells in the
network on another device like a world
screen and one of the things which
conventional device coordination
mechanisms don't do very well on is what
happens if the these resources on
completely different kinds of networks
like I've got a cell phone running on a
cellular network I've got a wall screen
perhaps running on a wide line or a
Wi-Fi network and that's on our intranet
and the cell phones on I don't know if
Verizon or something
okay so that with the power of the web
and the kind of you can sport then much
richer discovery which goes across these
different kinds of networks and having
found something you can then bind that
into a into your session and expose that
to like a web page either through a URI
or perhaps a and ID ref so you can
actually then name it in the maybe send
events to it messages to it and of
course then there's using a service so
I've talked a bit about this delivery
context interfaces through Dom knows
describing things like location
information or the battery level or not
ambient noise levels and so forth now
these objects could also have beyond the
other framework defined by the detail
itself they could have additional
interfaces which then you can make
yourself through scripting or through
marker the end of a session there has to
be some means for relinquishing the
service sessions might go on for quite a
while they might dispute the duration
single page or across a few pages or
they might be persistent in which case
you have the concept of joining the
session and maybe finding out what the
participants in that session are anyway
so there's a challenge to figure out how
to exploit existing device coordination
frameworks such as your PMP web service
for devices that are a Microsoft idea
Ginny and sanitation civil
so example about this from the DC I work
is you could think about location
information where you have you want to
get location perhaps an update every few
seconds or when you move such a distance
or maybe when you come to next region
section and whereas the the device
itself might have a front end for GPS
but that center of the network that's
converts into perhaps latitude and
longitude and then you have some third
party service which converts that back
into the information you need and based
on the parameters you provided through
the DCI that then sends you the
appropriate updates the whole point here
is to hide the details the protocols to
do that so that the within the web
application it's just a question of
perhaps setting some properties and in
the DCI and and then get receiving
events as you need so the actual detail
means for dressing location services and
the protocols used to support those are
then hidden from the application ok and
then there's a speech synthesis tough
here until more detail a moment the idea
of using a adding speech services as
well it's in the way so I've been doing
some work really on trying to figure out
how to make it easier people to explore
addition of combination of speech with
conventional web pages and so it's a one
approach to doing speeches to hand that
the mode speech modality the way you
interact with system the handles really
describe that in the network and then
obviously but a visual web page which is
running kind of locally like in your
device in your browser and a couple
those in some manner and so a number of
people have explored that combining
XHTML locally with voicexml on the
network and perhaps using some kind of
higher-level applications to flow of
example using the doubletree see call
control XML markup language another
approach is to handle the actual speech
modality with locally within the browser
visual browser itself and that still
leaves open the choice as to whether the
actual speech synthesis of speech
recognition is done locally or done in
work and there's a number of trade-offs
in between this so is it briefly explore
that I've got the next slide covers
latency but quality quality issues
obviously if you've got a small device
then the trying to provide high-quality
content of speech synthesis requires
quite a lot of resources memory sources
and again for speech recognition the
size of the the models you have dictates
largely the kind of the effectiveness
and so there's obviously memory and
there's precedent part trade-offs so
that the terms of recovery assuming but
if you want to do something the network
again you have the issue of do you want
to be pre produced some of the speed
processing the device of a so-called
distributed speech recognition or do you
want to do it all of the network and
what are the costs of doing it remotely
and particularly not just a computer
computational latency costs but real
costs in terms of dollars for the
network transport and then the
implications for the battery life so one
of the choices I looked out and doing
this work was to figure out whether it's
worth doing this through like doing a
plug-in and last februari or I think
febrile March what it is I did a demo of
an excusing a buyer extension to Firefox
for speech synthesis and that proved
fairly brutal then across different
browsers and contacts and it looked like
it'd be very hard to extend that to
support to speak to recognition where
you want to inject a result back into
the browser so that I switched from that
the approach is basically using through
the local HTTP server of speech proxy
regardless of all these choices with
your writing applications you really
want to hide the details of whether the
speech engines in the network or a local
you know maybe you want to use a
combination of local speech for simple
commands and doing all the complicated
recognition in the network so it'd be
very desirable to have some kind of
JavaScript object to drive interface
support that
okay so that the latency if you want to
have a spoken command like up down a
select and you want to see that change
the visual interface it's really very it
becomes awkward if that doesn't react
very quickly so if it's much greater
than say 100 milliseconds or some around
the human reaction time becomes
noticeably sluggish the other issue is
that when you're having a conversation
with an application or co
conversationally another human that
there's his rules of etiquette for high
hand over the dialogue from one person
to the next and so there are through the
latency is involved in that and so if
you introduce too long Layton sees again
it feels awkward waiting for the next
person to respond and the final problem
is that they know if you if you don't
actually somebody's go talking too long
and you want to interrupt you want to
seize the dialogue turn back so that's
sort of local of a barge in approach and
when you are talking of the other party
and that introduces all sorts of
subtleties of getting that to work right
anyway I maintain that the network
delays aren't as bad as they seem
certainly thought for a fixed line
networks and the mobile networks is
getting better and that for many cases
users are quite happy to wait a while
and what I was hearing the conference is
that people have brought it down to
about a second the network speech in
current technology and current networks
and for for many cases that's adequate
the thought really smooth flowing
dialogues you'll want it less than that
ok so the approach that I've taken is
really is works with goddess to work on
opera firefox and other foot of your
browsers and on instant explorer and so
this is using the the xmlhttprequest
mechanism to send a request for
initiating speech synthesis of speech
recognition and to have a local HTTP
server which then manages the audio
stream so in my case I'm using the idea
that the else are the advanced linux
sound architecture so there's an
interface which handles the capturing
the speech or the playback of speech
appropriately and using internal
interface which makes it important to
two other operating systems like windows
and don't mention here the idea of using
a speech codec my coat doesn't currently
do that but the idea is to explore the
use of the tick
the ilb zebra codec which has a number
of valuable properties and then the
remote HTTP server I've got currently
like one for speech recognition one for
speech synthesis provide speech services
so the general idea for for speech
recognition the you're just using HTTP
so it's just it's all standard start
using HTTP with payloads as a mime you
know internet media types of the
payloads for the audio PCM audio with
the ASR and the HTTP requests for speech
recognition and and then the response is
an emotional explainer surely and then
for speech synthesis you basically send
the request are those explicit texts or
reference to speak to this markup
language file and as your eye and then
you get the audio back as the payload of
response so this is a kind of
illustration the top here of the kinds
of your eyes is basically it's a local
host and some port number which the
proxy is running and then some
parameters in this case like text equals
good and afternoon or or your i equals
particularly your iris SML file the
speech synthesis markup language and
similarly for speech recognition a URI
for the grammar file the speech
recognition grammar specification format
develop a double 3c and the idea would
be to support additional parameters it
was needed example listening on multiple
grammars whether you want to have more
than one result of a period of time
sometimes you might want to have a
sequence of results depending what
people say particularly if you have
spoken commands series of clans time at
prom person and other ideas another
problem with this is that the if you
have really really large grammars it
takes a time to take the grammar fire
the XML format and to compile them into
form which could be used efficiently by
the recognizer so in some cases you
might want to do that by using a preload
command early running application okay
so I've got I've got little so applica
ply this to a lot of Pizza the pizza
grammar so the the this case the rule
format looks a bit like this is one rule
from the grammar file and this is the
top level and you can see it's pretty
compiling two parts one is to convert
effectively
context-free grammar and the other is
some annotations for computing a
semantic result based on recognition so
the somatic results computed by
executing a number of small pieces or
small statements of ECMO script in a
sense and so that's used currently with
voicexml returns the result is some of
the ECMO Script object what I do though
is actually to generate instead an xml
result in Emma which is the extensible
multimodal annotation markup language
which is being developed by the
multimodal group doubletree see and so
here's some example here's the grammar I
don't know be an F format and like I
would like for small cheese pizzas of
olives and peppers so you've got this is
a match against the grammar and the
ideas you get an interpretation back so
you've got the the N mikkel
interpretations the outer element and
within that all the mark-up in this case
is actually application markup defined
by the application right of through the
way they'd code there are gamma fans
there are a number of annotations which
you can have which is like Compton score
timestamps and as many or more ok and
then you can have more complicated
utterance as well with these kind of
interface it rather than ask me for one
piece of information as time it gets
visited by natural as much it's very
much nicer if you can ask for multiple
business informations of time give
people are more natural interface so I
think that from the light from the AVR
speech West Conference in the last few
days that's doing a lot more
acquaintance now how to do that people
are developing ways of handling that
despite the limitations of the current
technology so in this case the result
you see there's two not to Peter
elements corresponding to each of the
pieces and I had to hope to be able to
demonstrate that to you live but
unfortunately that's somewhat
embarrassed of the year the license
running out of night ok um so having
done that the idea is then you have your
speech service in the network and then
people just go code away their grammar
files and their speech synthesis files
and then the how do they describe the
behavior so one way to do that is just
to do a digital JavaScript that's kind
of tedious and
once you've figured out what particular
you want to do then obviously you can
start to figure out how to express that
and markup and maybe even code up using
some of the work which is being
standardized like the SC XML or state
child XML to being developed The Voice
browser group or maybe can roll your own
it doesn't really matter because you can
do this interpret the bark up through
JavaScript and didna works interoperable
across all modern browsers but the idea
is that sounded really follow trying
things out in the marketplace see what
things stick and really be nice to
encourage more experimentation of
multimodal before we get to thaw of
Santana's asian okay so some obviously
ways of modeling behavior for that in
terms of the kinds of books are
available to you in HTML pages so it has
obviously there's events responding to
various events there's the the callbacks
from the THX the HTTP responses layers
doing timeouts and various kinds
timeouts are very critical and
conversational interfaces the dialogue
handovers so you can sort of implement
that and top of the hooks you've got
like set timeout though all gets pretty
tedious that's why you want to do things
in terms of markup reading rapidly then
there are other kind of things like
dialogue girls and history so those sort
of things you won't want to be able to
explore so the idea is we're not going
to standardize any of those sort of
things very soon there are efforts to
think about the state transition rules
but other kind of things is going to be
more experimental for quite a while yet
I'm not suggesting that all behavior
should actually be modeled within the
web pages so because I the whole thing
of the biggest web was to move stuff
into the network and give you more
control and delivery across a range of
devices but you always the best
combination of this with the cert remote
eventing mechanism that gives you a
great deal of scope okay no all this
wouldn't work very well if you had no
means of tuning it so a key thing for
all these kind of applications is to be
able to have a rich logging mechanism
and so that you can then sort of clicked
lots of data and use that to understand
where the applications is it could do
better and so there with this particular
model obviously the speech server can
log the feeling that the actual requests
you know the your eyes we also block the
audio
wav files or PM later and but you will
need more than that you need to lock the
kind of where you are on the dialogue
itself so that has to be somehow within
the dialogue engine so that you get the
appropriate Ajax requests going out to
add that information into the logs and
this information will be no goodness you
could tie it all together so has to be
some means of perhaps using session
identifiers for that as you correlate
the different parts the log ok so
finishing up on this area the idea is
that rather than have these very simple
interfaces ask you for one thing at a
time you feel you're being dragged
around by your nose you really want to
allow users to provide more complex
utterances and lava mixed initiative
kind of applications and this requires
this is this is a desirable if it it
does take more work and time as a more
flexible approach for effective dialogue
but the techniques for doing that easily
and effectively are now being coming
well established that the exposing
speech to web pages in this way through
JavaScript gives you the flexibility for
trying out experiments exploring things
and whilst remaining interoperable
across browsers I think there's some
legitimate questions as to the details
of this approach was I'm hoping to
follow up in the future so rather than
using a speech proxy server such access
by you know by ajax may be a better
approach is to not put the audio into
the HTTP request but to have a separate
RTP stream and so the idea there would
be you might have a plug-in you first
will make a request to your server and
the backend of Apache or whatever they
have it figures out designs us port not
a P sort of server-side system and then
you call score plug-in to set up our
tippy connection appropriately and
thereafter that then allows you to do
all sort things like the meetings until
a competent stuff still come to and a
short while so I think this this is
something that I'm hoping to explore
later and I think there's an opportunity
to the sort of discussions about what if
we had a speech object exposed to
JavaScript
what should it look like and is it is
there a chance especially building any
consensus around that or maybe we could
something for the future okay so now is
it kind of a change of context I'm not
going to talk about some work have been
doing on web presentations now I'll
bring that back to the speech stuff a
little bit later the this is something
I've done which is an alternative to
powerpoint partly driven by the fact
that we know many of the hwt staff do
presentations often the presentation
that's really bad they're using some
kind of tools developed in-house and it
doesn't look very good and so it seemed
to me that just the time was ripe really
was to work on doing some thing based on
HTML and JavaScript and CSS and so I
started working that and then
independently that I discovered two
other people have been doing us to like
Eric Meyer and tante actually and so we
sort of exchange some notes and that's
help sort of the leaders of their rich
features so the basic idea here is to
use very simple markup for each slide
and in this case love a div element of
classical slide and then to have its
present each of these slides in turn
just by using a bit of JavaScript a bit
of CSS positioning and you can sports
bunch of things like automatic font size
adjusting up to the window size we've
also got controlled manually for their
keys bigger and smaller and so forth
this is all works across all pretty much
modern browsers I do have a little bit
of problem with Conqueror because it's
not quite it's a bit of lacking and some
the Dom features but on safari opera
firefox internet explorer it all works
fine although I do I have got some
challenges to look forward to which is
making sure it works well with ie7 so I
haven't had lay my hands on that just
yet I hope I seven or actually shows
solve a lot of the real difficult
problems because mostly effort getting
this to work was working around the
problems with it I a six and we weren't
of features which I'll skip through
because i'll show you later but
basically this is all done under as open
source and third of three C license
and so of course we have like
incremental display of bullet points
which is marked up with a circle
articles incremental and you can also
set these incremental class on a number
of different elements and not
incremental if you want to overwrite
this too then there's you can apply this
to images again it's like a deer the
classic incremental with some
positioning so this is a image from the
my brains gone dead the one of these CSS
tests oh yes I said it was the bottom
screen anyway there's some sort of test
asset to the asset to is a test of how
well your browser supports CSS and this
is a bit of a target for some other
browser companies so I think like opera
i think has just got there i'm not going
to sure about the others anyway so the
idea is so you can immediate incremental
slave images then there's the idea of
outline lists so here we have you add
classical's outline and so this one
you'll see this little plus thing that I
said open up or goes away the middle of
the second bullet item here is sort of
grayed out because there is no there's
no block level elements within the
content of that list so therefore it
doesn't provide the the plus or the
minus icon there so you just shows you
so it's kind of expanded so if you click
it nothing happens and then obviously
you can set you know sometimes want to
have things are pre expanded so
classical span to that and then you can
hide it in that's one feature so some
recent additions to this means a table
of contents so that's down here and you
then you can go through to each page you
want and the hardened reveal thing has
been used isn't and I'm trying to
collect a sort of gallery of things to
to encourage people to use this
basically I'm not a great graphics
designer I did try a little bit as you
can see you this style here of trying to
the digital carom I'd try and get a few
things on here to make it look
better but I don't claim to be a great
graphics designers I'm looking for some
good graphics designers to help come up
some interesting designs one of the
things i wanted to do we've been you can
use this of SVG you're best off using
this VG time because that's what we get
more chances are being implemented by
Firefox recent versions firefox 1.5 or
its Opera 8 but of course doesn't work
on ie so you can do a fall back to a
sort of the image a bit mapped but I've
been thinking about perhaps using some
mechanisms to dynamically convert SVG
tiny into vml to make it work as is with
the without the jaggies to get on it
nabbed images and scaling or perhaps
bara conversion to macromedia flash and
i've mentioned i used 7 tweaks um maybe
some richer styling remain committing
reveal content I've noticed to Eric
Myers but he's going to approach which
shows some of the bullet points before
and after and they highlight a little
dim so the question to what really
people wanted what I have here is based
on sort of asking a number of people
what they really wanted they didn't want
fancy transition between slides I just
wanted simple show and you know
incremental real based simple things all
these fancy effects aren't really used
to very much okay so one of the things
I'm hoping to develop was a WYSIWYG
editor because it turns out even with
many people aren't that comfortable with
editing in HTML and it's often very
difficult to edit mark up with some
wysiwyg editors so gonna be the screen
shot right so I can't I hope that's
visible basically the idea is to have a
very simple and easy-to-use editor for
producing slides which has something of
a look and feel of the PowerPoint but is
actually designed to be easier to use
and so it's got the idea of templates
number of slide templates and using the
content editable feature now that works
today continental has provided in IE but
not yet and the other browsers firefox
supports something called design mode
but it's not very usable example if
you're in the point of these be
seal at the title field or a description
field on the sort of cover slide but if
you press the Delete key or the
backspace key the wrong then you just
lose all your markup that's what you
really want to do to avoid people no
dammit ins destroying their markup you
would protect people and make it easy
for them to use without landing a minute
right not go back okay then I've been
thinking about the idea of being of
support remote meetings distributed
presentations where you want to drive
slightly remotely somebody noper having
a teleconference somebody's presenting a
series of slides Rodney constantly
trying to tell you move to slide n and
excitement forgetting to tell you the
next slide the idea is that you could to
start up the slidy in a way in which is
then using Ajax tivat of pole for
requests so that's straightforward the
next diet beyond that would be to
combine this with this RTP plug-in so
then you could get the audio feeds and
they're glad to be doing that live or
you could be doing it what kind of firm
later and then you might want to move
the slides at your own pace rather than
at the pace they presented originally
did it and which case that you might
want to have it so that when you move
back some forth these slides you go
through the contents to particular slide
then the audio is synchronized with that
so that's something again it should be
pretty straightforward to do again using
HTTP requests through ajax to the like
fruit of patching some back-end
patrolling the RTP stream obviously at
some point makes sense to think about
filters from PowerPoint in OpenOffice
butter I think that's going to be a
quite a long while coming at least I'm
doing it okay so we started thinking a
little bit about web meetings and I'm
gonna book meeting us things a little
bit of business stuff and then I closed
so bear with me so we've talked a bit
about presenter driven slide
presentations and the possibility of
doing that then there's the the idea of
being for web meetings you might want to
be lt's voice over IP within the
directory see we have this
teleconference bridge that was akin
bridge and people of use that alongside
IRC and server i see is used for
a bunch of things taking minutes setting
agenda items cueing people putting
yourself on the queue whole thing
stories things like that and so you want
to combine like the voice frp for the
delivering the presentation to posing
questions general conferencing and so
forth and and then the other faxes like
shared minute taking and ok so the
text-based meeting related functions
there's a lot the present spinless works
going to the sake of stuff of a ralphs
wicker to MIT so by using ajax to
control the the RTP resources that
basically means it's very scalable you
could have old farm are two pieces of
the servers handling the audio and doing
the audio mixing being controlled
through front end through HTTP with some
kind of back end model pass through a
sequel database or modeling what's what
resorted you're currently using okay so
okay so they talked a bit about the idea
of chatting in the course of a meeting
so it seems to me that despite its
current momentum with that jabber isnt
really long term solution and neither
are they are the kind of more poetry
solutions we see like AOL and msn and so
forth and we begin to see examples like
meebo or providing a kind of a Ajax or a
web based approach and so you know
that's why I think you can easily
integrate this into a kind of a web
meeting solution using XML HTTP to
support this the real tricky bits as
I've done my colleague Dan Connolly
pointed out I was not the kind of
protocol it's more to do with security
policies and mechanisms like who gets to
see when you're online and how do you
police that and what happens if people
come into a chair and how do you control
who comes into contract ruined to avoid
spamming and so forth there are other
issues are the day judge itself has some
security problems and so that the amid
Klein's describe this sort of technique
for doing referrer spoofing a lot more
and it seems to boil down to the fact
that most people writing
others use scanf as we're big took me a
while to figure this one out but scanner
you have sort of spaces between items it
allows any kind of spaces and if you put
tabs it confuses security systems so you
can then still have problems with you
can hack all sorts of things not all
browsers to do this and I think some of
these fixes to these problems are being
rolled out but nonetheless it's a little
river problem to be wearing off so I've
kind of winding up here now it seems to
me that there's an opportunity used some
of these techniques as business
opportunities so one obviously is 44
meeting services facing consumers and
ways to support these so one way
obviously is to provide free services
perhaps with some ads and maybe there's
a little bit sensitive and the privacy
issues of the spotting text I other
women they chat streams or within the
voice chat using word spotting on that
but nonetheless it's a possibility for a
foot today a lot of companies are using
something called WebEx how many people
have heard a webex okay so it's very
well known so we're nice but the
previous company I was working out
openwave this the CEO used it every week
to address us and there was all kind of
practical problems with the using or
telephone to get through and waiting for
the operator problems with the user
interface when you're trying to put a
question it was scroll a new question
came in it was scroll thing out of the
way so the CEO was frantically
scrambling to find out what the question
is supposed to be responding to it seems
to me that a lot of this stuff can now
be integrated through web browsers nor
we really need is this RTP plug-in on
the rest we can handle through just for
the existing stuff and again the
opportunities here are new to this
various ways in which you could monetize
such services it seemed it obviously
like hosted services soft by licensing
for other people to do it themselves
sporting some sort of ecosystem with
third parties to provide like
customization to a particular company's
branding or or other support they need
and maybe mashups of other kind of
services as part of these meeting
services
okay then again with the notion of these
things integration other kind of related
services so there's remote storage
archival and search we've got we have
shown you like equipment of powerpoint
or presentations but there's also
documents and spreadsheets and there we
have companies like rightly and um some
who aren't providing services for
web-based documents and spreadsheets I
won't actually short spreadsheets the
right thing to promote in the long term
I think there are many things better
than more natural and easier to use in
spreadsheets but nonetheless that's you
can do that and I'm some have
demonstrated and anyway nitin so the
list of opportunities goes on here i'm
going to read out all the details i got
to have a uri for this these slides i
can write if you want okay and i think
the one of the things have interest to
me is that education online learning
services as Ryan mentioned that we were
involved in work on sort of mathematics
and the web some years back this is one
of the things has been a little bit
disappointing that the web has a lot of
potential for educational use and the
current browser developers have have
been very I think remiss on following up
on that okay so basically oh yeah
completing rock that are the font
Eustace is actually is unusual for most
fond sisters provided under the GPL and
anybody by the camera look around goal
power out yes and I've or if you're
using ie you also get that automatically
for the web font mechanism okay so
enough of that what i want to do so
briefly switch back to the demo let's
see if the TTS license is expired too
apparently not okay so what I've got
here a the screen is divided into the
left hand side has got 3 3 consoles of
terminals the top ones running the the
ASR unfortunately says functionality not
completed due to a problem during the
execution license has expired damn IM
straited this yesterday afternoon at the
a vos conference and differ but anyway
sorry the next window the middle window
has the liquid is a speech server which
is integrated with the de cuento text to
speech services and the bottom window is
the actual speech proxy itself so no I
have it set up this Way's this I can run
it without requiring any networking says
all using local networking but they'll
kill you could put the to this teach
Texas speech in the other speech
recognition service remotely anyway so
the bits i can demonstrate example
speech hello my name is Simon and I am a
British boy from la quango now there's a
slight gap in the middle of that now
starting up because it's clearly loading
some memory virtual memory was
something's going on though I think it
works better the second time hello my
name is Simon and I am a British voice
from luck window so to get these sort of
things to work grill over average net
when conditions require quite a bit of
shooting which I haven't really got down
to at this point the next one is so kind
of much older speech synthesis voice
called Lizabeth so it's not as good
quality well this is this is the first
one is done using its presenting a piece
of explicit text to the proxy server and
this next one's done by sending a URI to
a speech since its markup language front
so ok what's happening
hello my name is a little bit another
British both from lock window okay so i
think the delay there was caused by
letting up that voice grunting soon
check hello my name is a local book a
normal British boy from lo cuento so
that's a madea voice because i think it
was it was a very much older voice and
the quaint is the new voices are
significantly better even the first one
Simon you heard I can't actually
demonstrate the speech recognition right
now curses but I can show you the I
general idea the idea is if you have to
see statements like I would like for
small cheese pizzas of the mushrooms and
olives what comes back is something back
the bottom here so you have an
interpretation which will be like Emma
Cologne interpretation actually with a
competent score which is one of the
annotations in the invitation
specification and then the actual
application markup which is generated by
this scissor or semantic interpretation
his speech recognition and so as this
emma allows you to do a bunch of things
in best lists lattices word lattices in
best list is where in some cases you
cast recognize to send back say the top
10 or the top three a recognition
hypotheses that's not always very useful
so you could be careful when you want
that then there's the sometimes you want
to see but a long at ernst and maybe one
word in the middle it wasn't sure about
the rest for fine so the overall
conference score isn't very useful in
that case so then you can idea so you
can get a word lattice back and so that
basically gives it a like a graph
showing you the words it recognized and
you can then look at the scores in each
of those I can't actually do that
because the liq Wenders speech the ASR
doesn't support that particular feature
but that's something which is when the
spirit of the is defined within emma and
will be doable with a different speech
engine so without further floor open to
questions
did you have your RSS then from last
year for sure possibly that might take a
while set up ah they have a big bone of
the night so for for the speech
jubilations so you develop the Firefox
extension to record and send back to the
server I'm like oh so for the official
get some part so you have developed the
the Firefox extension early last year I
did try using by an extension for
Firefox by two extensions prove you very
difficult to write so this destruction
this what I've got here today works on
internet explorer opera firefox and so
forth so it's basically just using xml
httprequest the audio isn't it reaches
the browser its handle entirely by the
proxy so basically the proxy service is
integrated with the in this case the
ELSA a speech library for doing a speech
capture and playback and I to carefully
design interface for that so that I own
the replace that the Oscar module with a
windows multimedia model even win it and
win mm dealer so the purchase that is
running on down the processor is running
lovely now the problem with that is that
the browser's have a security thing
which basically says you can only really
talked to you x minus GT p to the same
domain on operates worse it's got to be
the same domain and same port so it
seems to this rules very very slightly
that from brass the browser so if you
wanted to use this to access a page like
it's going here you really you'd have to
use the proxy server to also load the
web page I think that this is an
interesting model maybe there's some
ways of getting security relaxed for
specific uses like this but the other
idea is to use not EP plug-in in which
case you're just using the Ajax to talk
to the serve you download to the web
page which is in also managing the
speech but the audio can be routed to
ever you want so that's that problem
than is avoided
ok
I don't see the whole pipeline from the
microphone okay well I'll try to explain
in terms of the three winners in the lab
so the if i do the view source so so the
speech proxy when it receives a request
HTTP request from the browser okay so it
looks at the seasons at tts or Nassau
request or it's a file request and if
it's a if it's an ASR advice of speech
recognition request it then innate is it
then stops speech Cashin so why would it
get an ASR request let us browser that
the buttons i had up here okay i was
just going to show you the sauce that
illustrate how this works all right
so somewhere down here we have some
buttons yep in the middle here and this
is all very crude so on click equals
here text or here s SML or recognize so
there's just some event handlers nor did
i piss a few scripting ronix in the food
and HP purpose and then there's
functions themselves a bit higher so the
recognize me if it's the owners booster
font size because you can't see them
is that is that visible so in this case
here's the function recognize which is
fired off by clicking on that button and
in this case it's got a hard-coded 2d
the grandma father want to use within
that handler and it then if there if
it's essentially if it's a gecko browser
it tries to it calls the privilege
manager to avoid the pop-up you'd
otherwise get and then posts off the
request to the the speech recognizer man
so when that server starts up its sees
that it's got a request with an Internet
mime type of for the PCM stream and it
starts that's then audiosyn is picked
off not when likes the pcs way that's
the hand of thought the the handler for
the mother mime type which is a it's
actually integrated into brown into
speech recognizer server which is
already involved into the ground and
then that's entirely separate that's
running somewhere else in the network
this is there several comparison the
browser the proxy server which is
running locally because you want to up
your audio locally presumably the in the
network there is a speech there's to
service one is the speech recognition
and one is for speech synthesis so when
you send your HTTP request to your proxy
server it then figures out what to do
which prop which speech a service to
invoke and where affords the request and
as in the body of the request it sends
the audio stream and then the speech
server gets that request and deals with
accordingly so I really both ends are
written the server I've got this about
10,000 lines of C code which handles all
this and effectively it's basically
streaming stuff in and out of ring
buffers and doing all sorts of the choke
jinan quenching synchronization and
driven up the pole making birth mother
the linux linux pole functions of timing
and civil this very feet with proxy a
key and you just have the it's the greek
rest yes and the inject the audio stood
right so the presses directly sent to
the proxy normal way and in the proxy
server then contacts the remote server
so for our speech services this or it's
configured which server to use for
recognition and senses
functions are enterprises or anything I
don't have women running here but i'm
using linux here I haven't quite figured
out how to get out all to work under
wire so that but basically I can't
remember exactly details but I can show
you the file it's basically it's trying
to not do anything terribly difficult
we're just doing simple playback PCA or
capturing a PCN you just keep it real
simple process
running that deal that's that's the
luhley proxy server so with the like
example playback there you set up a call
back from the multimedia component but
you can't do anything in the callback
apart from sin an event so then then get
in the event in your event queue then
pick up that request and then you deal
with it from there and then use of you
have a small Q of buffers which you are
the plane through your capturing to it's
a little bit better to try to use the
things as widely available than to try
to rely on some of the fat more recent
audio interfaces I really wanted to keep
the audience base very simple so it
could be ported across platforms very
easily and similarly for the networking
functions so it's using the pole POSIX
threats and was platted
and then for the art of peace the next
question using rdp lots of people again
again just using open source are to be
hungry and for the I lbc is a codex
against an open source codec and the
mime type that's defined but in the RFC
are they an IDF the other things there's
open source acoustic echo cancellation
by a guy who works a German HIV control
organization and this is the work quite
well actually but to make those two
things work well speech recognition
there are subtleties if you start using
codecs you start using acoustic echo
cancellation things can start to go
slightly awry and again there are ways
of mitigating that so anyway so the
broader theme though is really secretive
swear which is the coordinate
coordination across devices and
resources and how it expose that to web
applications and that the speech is just
an illustration the kind of service you
might want to not be able to add in this
way ok any more questions are all real
done
we're done what say that thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>