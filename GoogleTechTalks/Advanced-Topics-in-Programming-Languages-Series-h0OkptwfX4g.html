<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Topics in Programming Languages Series:... | Coder Coacher - Coaching Coders</title><meta content="Advanced Topics in Programming Languages Series:... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Advanced Topics in Programming Languages Series:...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/h0OkptwfX4g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so today we've got a speaker
talking about parametric polymorphism
and the Gerard Reynolds isomorphism it's
a type theory talk it's Phil Gossett who
works here on mobile issues and I will
turn it over to him okay thanks
so just to give a brief outline we're
gonna talk a little about the the early
history of type theory and then move on
to a particular type system called
hindley-milner type system and various
issues related to it then we'll move on
to a discussion of the distinction
between parametric polymorphism and
what's called ad hoc polymorphism and a
particularly nice construction of the
latter called type classes which is
featured in the Haskell programming
language which will be used as an
example throughout the talk then we'll
move on to the curry Howard isomorphism
which is basically the notion of types
as theorems and programs as proofs and
then finally the bulk of the talk will
be on the Gerard Reynolds isomorphism
which is a somewhat miraculous
isomorphism between types and programs
so first the origins of type theory so
pretty much everything in computer
science began with Frigga and in
particular he was working one of the
first to work on the notion of formal
languages for pure thought and this has
all sorts of interesting implications a
lot of this carries over to the present
day this was 128 years ago so a long
long time ago and this sort of led to
the notion that well maybe you can prove
the consistency of arithmetic and in
fact the hilbert at the turn of the
century had is 10 and then 23 problems
for the next century and the second of
those was proving the consistency of
arithmetic and that sort of evolved into
Hilbert's program which was an attempt
to access all of mathematics
and prove its consistency so fairly
shortly thereafter they started running
into trouble and the one of the first
instances of this was Russell's paradox
which was presented in a letter to
Frigga which basically involves the
issue of well what about sets of all
sets that do not contain themselves as
members if you think about that for a
few seconds there's an obvious
contradiction there and you know this
that you you can't you can't satisfy
that this requirement so what to do
so Russell stood on this for for several
years and eventually came up with the
notion of type theory and this is
actually the origins of type theory and
pretty much carries over to the modern
day including a lot of the terminology
so the idea was to try and fix this
problem by having a hierarchy of types
so so the way he put it was no doubt
totality can contain members defined in
terms of itself and if you think about
this for a few minutes you'll see that
this this solves the problem of the the
paradox it eliminates the paradox so
everybody was feeling really good about
this and Russell and Whitehead went on
very shortly thereafter working on the
Principia Mathematica which was an
attempt basically to do what Hilbert was
talking about to derive all mathematical
truths from from nothing from from
fundamental principles and this involved
to see might guess a system of types of
very elaborate one and just to give you
some idea of how elaborate there were
three volumes in the in the total
Principia the first volume took about
four hundred pages to prove that one
plus one equals two okay and the the
Principia ran on two thousands of pages
there were three volumes they were
planning a fourth but they sort of gave
up on it they spent 17 years on this and
it was just too much so it turns out
it's sort of a good thing that they gave
up on it because very shortly thereafter
kurt gödel came up with his famous
incompleteness theorems the first of
which proves that any sufficiently
powerful system cannot be both
consistent and complete and this was
done by bringing up a statement this
statement cannot be proved and showing
how to map that into arithmetic now this
statement is not a paradox okay there is
absolutely nothing wrong with this
statement it is true and it's not a
paradox okay so very shortly thereafter
and in fact in the same year in a
one-page paper
gödel went on to prove that arithmetic
cannot prove its own consistency and
that was pretty much the death knell for
Hilbert's program so in a real sense
type theory was kind of a miserable
failure it was sort of an attempt to
prove the consistency of arithmetic and
that turned out to be a fool's errand
okay happily though type theory has
other uses so in particular we'll be
talking about one one type system called
hindley-milner type system and just to
give you some idea of the the syntax of
this we'll take an example from a thing
called combinatory logic and this was
invented by Moses Schon Finkel who's one
of the unsung heroes of computer science
in my opinion he invented the notion of
what became called currying which is
basically the idea that you can
represent any function of however many
arguments with functions of a single
argument and the idea is that the
function of the first argument returns a
function of the second argument which
returns a function of the third argument
and so on so using this you can you can
build up arbitrarily complicated
functions and this is represented in
this form in the hindley-milner syntax
and the you'll note that parentheses are
sort of left associated for the terms
and right associated for the types so if
you just make that a convention you can
blow off a lot of the parentheses so the
main subject of shown finkles paper was
combinatory logic which is
building block of mathematical logic it
turns out to be complete although we'll
get to that later he wasn't able to
prove that and it involves only two
combinators K and s and these are their
definitions and the corresponding types
and it turns out well we'll come back to
this several times throughout the talk
okay so one of the nice things about
hindley-milner type systems are that
their types are inferable so what that
basically means is you don't need to
actually type in the type signature
yourself the compiler can do that for
you this is a really wonderful thing you
still get type consistency checking but
you don't have to go to the bother of
typing in the types yourself the
original version of type inference the
original algorithm for this was invented
by Korean phase and in 58 and this by
the way is the same curry of currying
his name is Haskell curry
hence the programming language Haskell
this was later extended by Hindley and
independently Milner and proved to
provide what are called principle types
I'll get to that in a second and later
extended a little bit more to
polymorphism and prove complete by demas
and Miller Milner and this this is what
type inference looks like it's sort of
an eye chart I don't expect you to
actually be able to read that but the
point is it's fairly simple there isn't
that much to it the rules there are ten
rules it's fairly straightforward as
these sorts of things go so there are a
number of programming languages that use
hindley-milner ml was the first of these
which in fact was invented by Milner
metal language is what that stands for
there is an object-oriented extension to
it called Oh camel which is fairly
popular and then there's Haskell which
which we'll be talking about
okay so the next thing is in fact the
the thing that makes Haskell unique
among the handling milner languages
which is called type classes so first
off we need to discuss the distinction
between ad hoc and parametric
polymorphism so polymorphism means you
can have an arbitrary type basically in
your signature you don't have to specify
exactly what that is
there are two forms of polymorphism as
straight she pointed out one of them the
most common is called ad hoc
polymorphism and the classic example of
this is operator overloading which
you'll find in a lot of languages so so
you know a canonical example of that is
+ for integer as it means ad and for
Strings it means concatenate okay these
two things have in some sense nothing to
do with each other
so it tense ad hoc there's another form
of polymorphism however which is a
little better founded called parametric
polymorphism and the idea here is it
functions over a range of types act the
same way for each of the types and the
canonical example for this is map which
exists in a lot of languages so the idea
of map is you you give it a function
which goes from something of type a to
something of type B and then you apply
that to a list of elements of type A and
it'll return a list of elements of type
B okay so the thing that makes this
parametrically polymorphic is that you
don't need to know anything about the a
and the B this will work for anything
okay so in a very amusingly titled paper
how to make ad hoc polymorphism less ad
hoc Wadler is great about names of
papers one of one of his papers is
turning failure into a list of successes
and we'll see a few other papers he's
really good at coming up with names and
things so just to make a few
distinctions clear an object-oriented
program we have objects carrying
pointers to a dictionary of methods
and and this basically is implementing
ad hoc polymorphism so there are no
constraints on what you can do there
type classes are kind of a constrained
version of this and the idea is that
instead of the dictionaries being
tightly associated with the objects
there they're passed around
independently of the objects and rather
than having the usual type hierarchies
you instead have constraints on the
polymorphism which can form what what
are basically a network of horn clauses
if you're familiar with Prolog except
the horn clauses are at the type level
rather than at the term level so here's
an example of a type classes sort of the
canonical one so this is the the numeric
class which has add multiply and negate
and it has an instance here that we give
for integer we're assuming that add into
molten tanned Negin tour predefined
they're there they're part of the
machine that you're running this on and
we can have instances for float and
various other numeric type classes so a
little fragment of code here oops for
square can be polymorphic but you need
the constraint that the the types of the
input and the output are both numeric
for this to make sense
okay so type classes sort of give you a
way of getting the effects of ad hoc
polymorphism while being better behaved
more more like parametric polymorphism
and in fact this is being at least
proposed by Barney at all and oops low
six to become part of C++ sure
there's there some similarity with
algebraic theory and II was just
pointing out that this is somewhat like
algebraic theories yes indeed okay so to
continue on the next topic is the Curie
Howard isomorphism and the notion here
is that you can think of types as
theorems and programs as proofs of those
theorems so in what sense is the
question so first we need to discuss
discuss the concept of type inhabitation
so you can have type signatures that are
pretty arbitrary but some of them can be
inhabited by a concrete term and while
while others don't make any sense so for
example a function of two arguments of
type a and b can return the first
argument which is a type of a and that's
the constant function you can also have
obviously the identity function which
returns the same type and that works
parametrically polymorphically for any
type whatsoever
however you can't do that for what would
be called cast in most languages so you
can't in general cast something from one
arbitrary type to another arbitrary type
because those types could be anything
and you'd have to
so the question was sometimes you can do
this and indeed sometimes you can but
you need to constrain your types further
this couldn't work in general okay
certainly you would agree that there's
no generalized caste function that will
work for anything at all that that's
clearly impossible well bottom yes okay
bottom inhabits all types so let's
forget about bottom for the moment that
that's kind of a obscurity ok term is
code basically a fragment of code a
function or a variable or both terms
okay okay so this may seem like a
complete digression but it actually
turns out to be very relevant there's a
sinkhole intuitionistic logic which is a
weakened form of classical logic in
particular it throws away the law of the
excluded middle so you can't infer that
not not a implies a ok but otherwise
it's basically all of classical logic
and because of the simplification it can
be expressed very very concisely so you
have you know modus ponens which is
basically if a implies B and a then B
okay the fundamental law of all all
logics and then there's these other two
rules which don't have very good names
and a third rule which can actually be
derived from the first two rules so this
may remind you of something if you were
watching closely earlier on it turns out
that the the axioms of intuitionistic
logic are exactly 1 for 1 with the terms
of combinatory logic okay so let me go
back okay so these are implications the
arrows are implications in this case and
in this case their functions this is
sort of magical ok so if you think about
this a minute this is basically
establishing an isomorphism between
axioms and therefore theorems and
combinatory logic and terms in
there are types in combinatory logic and
theorems in intuitionistic logic okay so
we still haven't proven that that
combinatory logic is universal however
we can establish an isomorphism between
combinatory logic and the lambda
calculus which which is universal and
going in one direction it's somewhat
complicated going in the other direction
it's pretty obvious and it should be
obvious because we expressed it earlier
in a Haskell program in Haskell as the
form of lambda calculus so the Curie
Howard isomorphism basically says that
there is a term with a particular type
if and only if that type corresponds to
a theremin intuitionistic logic now now
you can take this in both directions so
in one direction you don't actually have
to run a program all you have to do is
compile it or or establish that it will
compile and doing so proves the theorem
that corresponds to those types this is
pretty pretty magical going in the other
direction if you have a theorem about
the the corresponds to the types then
your program will definitely compile and
then won't will not have a type error
basically okay so the next thing in the
bulk of the talk is the Gerard Reynolds
isomorphism which takes us a step
further so the paper that Wadler again
wrote shortly after inventing type
classes again with an amusing name
theorems for free which has a double
meaning basically provides theorem shows
a way to provide theorems from the types
of polymorphic functions now in a sense
there's nothing new about this this was
basically obvious from the work of
Reynolds it's a so-called abstraction
theorem which is equivalent to Pyramus
at Parramatta City tricity parametric
City which is basically the property
that your types are entirely
parametrically polymorphic okay so no ad
hoc polymorphism no ground type
okay so there are two aspects to this
there's there's the Girard
representation theorem and there's the
Reynolds abstraction theorem and the
former basically provides a projection
from what's called P 2 to F 2 and the
second provides a an embedding of F 2
into P 2 so what are P 2 and F 2 ok F 2
is the polymorphic lambda calculus it's
also called system F and it was invented
by Girard and independently Reynolds and
it's a second-order lambda calculus and
it has quantifiers so for all and there
exists for four types but not four terms
and there's p2 which is the second order
predicate calculus which has quantifiers
for both types and terms so obviously p2
is a superset of f2 it's larger than F 2
because you can have quantifiers for
type four terms and p2 but not an f2
okay so the amazing thing is that you
can get an isomorphism out of this
despite the fact that one side is
completely is clearly larger than the
other side so for example if you define
the naturals inductively in p2 it looks
like this okay so you have a successor
function here you have a zero and that
basically inductively generates all of
the naturals you can project this into
f2 in which case you lose all the terms
so you just get the types okay
but then you can embed this back into p2
and miraculously the the terms reappear
now they're not quite in the same form
and you'll note that there are these
Universal quantifiers for for s which
corresponds to successor and for Z which
corresponds to 0 but it's fairly obvious
that there is a there is an isomorphism
here so if this can be extended to
product sums fix points and so on
so the one direction of this is sort of
obvious if you take something small and
embedded in something large and then
project it back to that same small
something you sort of expect that to be
an identity but going from something
large projecting that into something
small and then embedding that back into
the large thing you wouldn't expect that
to be an identity but in in the
assumption of parama tricity it turns
out that it is so what is this what's
the practical use of this and it all
seems very esoteric well you can think
of p2 as code okay so it has it has
terms and it has types whereas you can
think of f2 as being just the types just
type signatures so what we basically
established here is an isomorphism
between code and type signatures so the
punchline of this is you can get code
inference just as you could get
type inference going from code to type
signatures in in the assumption of
parama tricity you can go the other way
you can start with just the type
signatures and generate the code from
that okay so this seems completely
unbelievable so let me show you some
concrete examples and turns out there's
this guy Leonard augustson who has this
piece of software you can download on a
off of darks repository the called gin
and which is indeed quite magical and
it's a program that generates Haskell
code given nothing but the types so
let's do a few examples so some simple
ones to start off so the type a to a
obviously is the identity function okay
so it takes one argument and it returns
that argument unmodified okay slightly
more complicated one this is the K
Combinator also known as Const which
takes the first argument throws away the
second argument returns the first
argument as a result
and indeed gin will automatically
generate the code for that
so the underscore basically means I
don't care so two placeholder for the
second argument which is ignored okay a
little more complicated case the S
Combinator if you'll recall that's the
type signature for it and this is the
code for it and indeed this is the code
for it for the S Combinator okay so
that's nice you know you'd sort of
expect combinatory logic to work it's
very simple it's kind of its point so
let's try something a little more
complicated so something that sort of
makes my eyes bleed I have to confess
this continuation passing style coding
so this is the Haskell way of defining a
continuation and the return c function
basically constructs the continuation
and if you give it this type it will
generate the code that in fact will
construct that continuation so this bind
C is a function that composes
continuations and this is the type
signature for that and if give it to gin
it will produce the code and this code
is not entirely obvious okay
I'd have to scratch my head a little bit
too to figure that out and then even
more complicated call with current
continuation this is the type signature
for this which is which is reasonably
straightforward the type signature you
can actually have an intuition about the
code you know I don't have any intuition
about the code it's fairly obscure okay
so how far can you take this well there
are limits of course so let's take this
function foo which has two arguments and
returns a third all of which are of the
same type so if these are completely
parametrically polymorphic if all you
know about them is that they're the same
all you can do
the only functions you can get are
functions that take one argument and
throw the other one away
but gin will produce two such functions
you take the first argument throw the
second one away or you take the second
argument throw the first away okay so
this seems like it's broken the the
isomorphism but in fact the isomorphism
only holds up to isomorphism is
sort of might expect and in fact these
two foods are isomorphic to each other
if you you know flip the order of the of
the arguments then they're the same
function so there's a clear isomorphism
between them
okay what about a function that takes an
arbitrary type and goes to another
arbitrary type a different arbitrary
type well as we pointed out earlier you
can't do that so Jen will correctly tell
you sorry do you lose okay what about a
function that takes an arbitrary type
and returns a boolean a ground type well
again can't do that in general you'd
have to code that up separately okay
okay so just to recap we've done a
little history lesson on the origins of
type theory we discussed the
hindley-milner type system which allows
you to infer types from code we
discussed the distinction between
parametric polymorphism and ad hoc
polymorphism we showed how you can get
an isomorphism between theorems and
types on the one hand and proofs of
those theorems and and the existence of
programs that implement those types on
the other hand and then finally we
showed how you can infer code from types
okay that's it any questions yeah
why can't they be realized like what
well there's no generic I suppose you
could return always true okay depending
on how you interpret that that could be
considered isomorphic to returning
always false but that's kind of a
stretch so it that turns out not to work
out and in the system and it seems
fairly reasonable that it throws up on
that sure
okay for those of us who aren't into the
math here but in a more pragmatic I
don't understand what what the
difference is in this system between a
function like factorial and the integers
in the function like identity
okay so function the question is what's
the difference between a function like
factorial and integers on the one hand
and the identity on the other well a
function like factorial basically is
only meaningful in a numeric type okay
there you know it's hard to see what
that meaning would be if it was bools
what's the you know what's true
factorial I have no idea yeah I mean you
can make something up but but it there's
no sort of obvious generic way of
generating a function from that on the
other hand the identity works for all
types okay whatever
the argument is it can return that
argument and that works no matter what
the type of that argument is so so the
former is clearly not polymorphic not
parametrically polymorphic in any case
it could be ad hoc polymorphic but it's
not parametric and the second one is
parametric homework yes
but as you show the natural numbers are
a part of the theory right so we could
probably stay something about the
natural oh sure yes yes the question was
can you state something about natural
numbers if you define them inductively
what you can do in combinatory logic you
can in fact get get numbers out of that
so but it's a little bit unnatural but
but you have to sort of think of it that
way instead of thinking it of it as a
ground type subtle distinction sure is
there any sort of natural way to extend
it to type quests so unfortunately not
type classes are ad hoc polymorphic okay
they're a particularly nice form of ad
hoc polymorphism but they're still ad
hoc polymorphism so the parameter s'ti
property doesn't apply and therefore the
Gerard Reynolds isomorphism doesn't
apply so I'm afraid you're out of luck
it'd be nice a somewhat based question
are you using gin to do anything
um a little bit so sometimes the
question do I use it myself occasionally
what I'll do actually I do this a lot I
don't use gin very much but what I do
when I code in Haskell is I type in the
type signature and then comment it out
and then start typing in the code and
there is an interactive mode of the
compiler the Glasgow Haskell compiler
which I use G HCI is the interactive
version and it has a colon T function
colon type which will return the type of
the function that you give it so I'll
type in what I think is the correct
function and do column T on that and see
if it matches the the signature that I
commented out and generally speaking if
it matches that code is probably correct
if it doesn't match then it isn't so
this actually has to has some practical
uses
any other questions
Thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>