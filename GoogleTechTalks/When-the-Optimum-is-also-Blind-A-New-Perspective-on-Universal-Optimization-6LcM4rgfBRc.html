<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>When the Optimum is also Blind: A New Perspective on Universal Optimization | Coder Coacher - Coaching Coders</title><meta content="When the Optimum is also Blind: A New Perspective on Universal Optimization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>When the Optimum is also Blind: A New Perspective on Universal Optimization</b></h2><h5 class="post__date">2017-11-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6LcM4rgfBRc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so today's talk is going to get by me up
without shake
it's a PhD student in Warsaw his advisor
is Malik Tegan and his main work is on
all I know well it's very wide it ranges
from online algorithms as for the peer
approximation algorithms so but also
things like hardness and B okay so this
is Halloween dog sorry I don't have
costume but I put some bags slides so
this is a joint work with Stefano who
visited us last week and also Fabrizio
gran Tony and maracas dumb trick and
I'll start with what this universe
optimization about introduce some new
new benchmark and then I will give some
deeper detail of some our results so
Universal algorithm is about
pre-computing reaction for for scenarios
that are not known in advance so for
example for set cover we can think about
each element as a client and the set
covering procedure is kind of service
and each client wants to be covered but
we don't know which clients are going to
be active and for each client we want to
choose one one of the sets too that
covers it and for example here I put
colors to their 2d elements so this is
example of such an assignment and
afterwards after this assignment is is
done the set of active elements is
revealed
and with the need to need to pick older
old sets that were assigned to them and
another example can be directed Steiner
tree and here each terminal needs to
have a path to the route assigned in
advance so these are three terminals
with with the paths and then these two
are revealed to be to be the active ones
and this is the the solution the English
s and us can we see this solution is far
from being optimal and this is like
because we cannot like foresee mmm
exactly we are going to line all of its
non adaptive solution for an online
algorithm like online is too big word
because there is only like a one moment
of revealing the input yes you're saying
this is just a two-step thing and but
this could be like an no I have to say
that online algorithm yes so and people
were interested in competitive ratio of
such algorithms so like how bad can be
the solution we we we offer to the
active set with comparison to the
optimal solution and it turns out that
it can be actually quite bad even for
Universal when Universal vertex cover so
in in this setting like we want to cover
each edge with one of its ends and this
is equivalent to choosing direction of
each edge
and for example for let's say we have
this assignment made and this is some
subset revealed and the optimal solution
is to cover this edges only with one
purple note but our assignment would
choose all three of them and if there is
an easy argument that and that there is
some vertex with big al degree so that
there will be one scenario in which this
ratio would be really bad
how many scenarios do you have for
general so it's a so it's like in set
covered so the number of okay number of
scenarios are set cover reversal
birthdays coming you have this question
of different scenarios can show up and
these are explicitly given scenarios so
we're gonna see there are three models
mm-hmm a scenario model where we have a
list of all scenarios and this is part
of the input and like this bound for
this what you're saying here yeah here
they are given as a list because like
that the number of scenarios is the
number of vertices yeah and in this in
this example like we said one vertex it
so now you is one vertex yes it won't
support overseas right once observer
sees in this example it's scenario is a
subset of edges and each subset can be
associated in one vertex in this special
instance so each scenario is all edges
connected to one vertex right so the
optimum solution initially is one yes
no matter like if you have and we were
and for every assignment we can find the
vertex where this assignment would
provide a best so
so that lower bound them Omega max M
comma root n is for what model so M this
is for scenario model and this also
applies to Oracle model which is which
is more difficult but I want to talk
about this models of scenarios later
okay but when you say scenario model the
number of scenarios is polynomially name
and yes I prefer yes or it's a part of
the input so we don't know want it to be
to be large okay so this is like main
message is that the competitive analyzes
for Universal algorithm is has B Clower
bounds and some idea is to make
adversary a little weaker so one might
consider model where this scenario is is
drawn with probability distribution that
the algorithm knows in advance and we
want to minimize the estimated cost of
such a solution and here if we if we
analyze the previous example more
carefully you can you can see that you
could still get this mm square root of n
lower bound also in this model expected
cost right yes and some idea is to
consider some limited family of
probability distributions for example we
can we can say that each element is
being activated independently and force
versus such a model Fabricio at all
proposed algorithm Oh F with a
competitive ratio logger
in M or M is the number of sets and the
M might be exponential with respect to n
so this is still far worse than for the
classical set cover and like this
competitive right here is is tight so
what we try to do is to replace this
compare competitive benchmark with
something more fair
so in competitive analysis we are
compare a comparing single algorithm
with with the expected value of the
optimal solution but this is not given
by by any algorithm this this is just
optimal solution given by by some some
Oracle and what we propose is to rather
compare against some best assignment but
best algorithm that plays by the same
rules as as we do and one thing is that
this competitive analysis is like
comparing apples to oranges because the
different classes of solutions being
being compared and we claim that this
this is reason why this lower bounds are
so so so huge so it goes back to it is
so like this second model only makes
sense if you have inv like a known
distribution stochastic model it does
not make sense to define this new thing
in a mother that you don't know the
distributions in advance that's right
because yeah the definition of the space
of solutions
we can also like to compute something
like worst-case ratio the unknown
distribution okay so like you have to
specify what you mean by these solutions
that the first one is handicapping
because email is instance specific
benchmark we are a single algorithm if
you want to do distributions you could
do another thing on this is you're
saying both the algorithm on the page
for distribution specific one slightly
better apples versus oranges comparison
in between is algorithm this
distribution agnostic is drawn from some
pile of distributions you don't know
whereas the benchmark is distribution
specific but it is not instant specific
because the first one specific but you
will tell us what you mean by this so we
know so one example of results in this
in this Apple to Apple benchmark is a
result by carbon min curve that showed
that Steiner tree admits constant
approximation in this approximation
benchmark in the independent activation
model so each terminal is activated
independently and we need to connect
them to the divet yes that so the
benchmark that they compare with is the
optimum dynamic programming solution for
the independent visual model where you
know the distribution in advance like we
know in advance what is the probability
that each client is activated yes the
day call it may be cast problem and they
put it in some in different words but
this is totally equivalent to
this analyzes I never thought okay so
I'm going to say like how to how to
approach to discover which will be the
simplest algorithm of our our our
toolbox so this is classical formula LP
formulation for versed cover and we
replace this variables X s with common
configurations so what changes like now
we cannot take have a one variable for
for a set because the cost of taking set
depends of how many elements would be
would be covered but would be assigned
to it so in the in the objective
function we get this probabilistic term
and so so this is the probability that
at least one of the assigned elements
would be active so are you in like the
previous language this is a scenario
based now I'm talking to like model
oblivious like we are given
probabilistic
probabilistic distribution and we can
like let's just assume we can have
evaluate okay something like that and
then I will talk more about specific
models so this is the set of sort of
what elements
that are going that'd assigned to to s
so if we have integral solution then
setting this variable to R means that
all elements from B are assigned to s
and only lemma this is like summing over
all subsets right yes yes so now we have
exponential number of variables
this is configuring a configuration l LP
so I can compare them to the to the
previous one we can see that the
objective function like changes because
this this mu term and the rest is more
or less the same so there's a
exponential number of variables so in
order to solve
sessional P we need to go to the dual
and in do LP we have now a polynomial
number of variables and exponential
number of constraints and if we are able
to to provide it with separation Oracle
then we could solve it
so for each solution vector we need to
be able to check if it's a feasible
solution and if we can check something
like that in in polynomial time then
then we could solve solve the dual and
with some known tricks we can also solve
the primal LP so the main observation
here is that this activation function is
a submodular big
like it's a combination of very simple
functions for like a sum of functions
for for each scenario and when we take
some of submodular function with
positive coefficients also some modular
and this is independent evasion so what
is what is crucial about function is
that is that we can minimize them in
polynomial time subsets is some sort of
elements confused what will do what is
confusing so the scenario the set covers
and I know I'm trying to reverse
engineer what is the problem that you're
trying to solve in writing is L so like
this what is the problem that you're
trying to solve universal stochastic set
cover is it you have different scenario
each scenario correspond to a family of
subsets or a scenario correspond to so I
don't have this one in any slide but I
believe there is nobody to be seeing
okay so what we are trying to do the to
minimize we are given our universe
universe of size n and the family of
sets of size M and probabilistic
distribution which is over
LMS or sets sets fee subsets of our
ancestors yes subsets of elements so
these are the these are the is it thank
you for this universe elements or says
it says this is a probability
distribution of all scenarios in our
sector ideas and scenarios is a subset
of elements of you great so that is a
subset of LMS at your disposal to cover
all the cells that you have to cover or
no these are the elements that you have
to cover this this says the subset of
the family of subsets that you have is
fixed in each scenario you have the same
fancy it's just the uh-huh maybe I was
also a circumference slide and capture
inputs right
the boat is captured by scenarios and
there are case scenarios there are the
probability distribution over scenarios
the probability distribution could be
over any probability distribution or
independent probability distribution
that's all body went by scenario
independent LP is yes three doesn't say
whether it is independent on missionary
is a subset of elements that you have to
cover and it says that you have to cover
them with our fixed in each scenario it
doesn't matter so so to make everything
clear let's go I wants to go through
this example so now the elements that
are not gray is is a scenario that was
revealed the this or this subset of
elements that we need to cover and this
three sets that that we can use are
fixed and now from the from the
beginning and so I we have this
assignment here and after this scenario
is revealed
then it induces family offsets that we
need to pay for so you is the allowance
and as is the family of sets so this is
what you can use to cover right as yes
yes I think I think what's confusing
means that s is not scenario yeah it is
fixed okay as it's fixed Agassi probably
okay yeah and distribution is also over
the family of of subsets and towards we
are minimizing is expected value and
this is X drawn from the distribution
and this is sum over all sets that are
in image of X and this is cause of this
of this set before even any scenario is
revealed you are supposed to say for
each element which is set you're going
to usual Power says I don't think it's
so it's here now like independent set
but then when this and is resolved you
look at each element you pick this edge
that supposed to has covered an element
and then the cost of that solution is
the one that you have to pick from you
predefined solution yes the more overlap
you have in that choice the better but
yeah okay so are we now on the same page
with yes can the optimal algorithm do
that like isn't captured by this or the
optimal is because the big the benchmark
that he had right
his instance specific optimal that means
you do it after I scenarios revealed but
do it before the scenario is revealed
that so the two kinds of benchmarks
right so what's the what's the new
benchmark okay the new password is the
best mapping this is not being
minimizing this quantity okay and then
you compare what you can do in
polynomial time to this mapping that has
the best experience cost okay yes okay
so one this is settled we can go back
now go to the hangar link oh this is a
nice term but I think for stochastic a
Steiner tree I was under the impression
in the independent activation model you
can even compete with the hardware is it
true that you can compete with this
harder things like there's a Stefano
Leone artist paper that that does that
so this is a bigger result compared to
that it's like a phone and Morrison or
am I wrong
I can say if you can get constant
competitive ratio first I need to be I
don't remember so you're saying you can
compare against instance Pacific octopus
if you relax the separate institutions
okay so so are we now do we know what
how this corresponds to the problem so
so like we encode this assignment fee
the this mapping using using variables Y
in the same manner as in the classical
set cover but we need to take into
account this probabilistic term by all
elements of B or some element of B if we
if we consider optimal integral solution
then it's all only like its exact
exactly yeah but when we do like linear
relaxation that of course like we can
allow these variables - mm - to be like
more illustrative but in in optimal
interval solution yes so coming back
when we go to we'll just in the optimal
integral solution like every element in
P choose s mm none outside so in order
to solve the duo lb we need to like
provide it with separation Oracle so for
the vector of alphas we need to check if
all this inequalities hold and the
number of inequalities is exponential
because the
the restaurant if you cater of all
subsets B of s but since the this
function G the defined as follows is
sub-module R then this function at the
bottom is also as a submodular function
is a module on there 901 cascade
execution model always always it comes
from yeah so why that supply chain so
modular is to derive it and then observe
it no it's not immediate it's quite
immediate extent for the independence I
think he's going to write the expanding
so this sum all subsets take probability
of the this substance being drawn and
here this like one if this is non empty
and zero if it's empty
okay and this function as a function of
being is the modular this is it's
basically the yes yes they are or not as
we take combination so when we add
additive term we still have submodular
function and in the in the Oracle and
the separation Oracle we just need to
minimize
such such expression for each as from
covering family so we can solve this
this LP in polynomial time and the
rounding procedure is the same as for
the classical looking set cover so we
can round it with the logarithmic waste
so this was an algorithm to be described
yes you're describing an algorithm for
this university set color but this is
like this is the the whole algorithm for
for for said color for universal
stochastic sub cover and concerning the
the model we need to be able to able to
evaluate this function G and this is
trivial
in Scenario model because we iterate
through all scenarios and we check how
many overlap with a given set B and in
the independent activation we have
formula for that mm-hm
for the Oracle model so a model where
this scenarios are taken from a black
box and the algorithm can just sample
Oracle a few times and the judging on
the results can may make the decisions
we can reduce it to scenario a model in
pseudo polynomial time
so we're for unweighted instances we get
a polynomial time but for for weighted
instances we can show also
a lower bound of square roots of em and
the idea is that the weights we can hide
a relevant part of the of the input with
really low probability and this gets us
hard
as pure Universal optimization because
we don't the algorithm cannot learn
anything about about the distribution on
the relevant part so how are we with
time twenty minutes okay so no I because
this was the the simplest algorithm from
from our paper and now I want to show
something more sophisticated and and
here I will show how to use the
assumption how to use the independent
activation model
so consider a Facility Location problem
so we need to assign clients to
facilities and we need to pay for
opening its facility and pay for it
distance between a client and its
facility and this is the definition of
the classical problem without any any
stochastic stuff and there is nice
constant factor approximation but only
when the when the function B is given by
a metric because if it's not metric one
can reduce set cover interface location
and then one needs one can get only
logarithmic factor and when we go to the
stochastic Universal stochastic setting
we are looking for the again like a best
best assignment
but we we pay for like opening facility
only when there is like only at least
one client active who wants to use this
facility and costs of like transport are
additive raha para vos ok so this is
like a very similar LP of formulation to
the to the previous one but now there is
the additional additive term on the on
the right and we can also solve it but
we we don't know how to round it to get
constant factor approximation in the in
the scenario model but in the
independent activation model we have
this nice inequality because we can
express this function G so this is the
evaluation the activation function of a
set we can compare it with almost linear
function and this is also a trick that
Karger used in the data work on the
Steiner tree so when we replace this G
of B with this almost linear term we
would lose only constant factor so let's
do that
and I only replaced G of B with with
with this term and now this is like
almost linear program and this is and
one can interpret this LP as rent or by
problem because when we take a minimum
of one
the sum of probabilities one can
interpret this that you can play one and
like open some facility for everybody or
every client can pay independently when
he wants to use and using this rental by
interpretation we can we can reformulate
this LP into equivalent one so now this
variable X stands like the purple
variable stands for clients contributing
to opening the facility for everybody
and blue variables the our clients that
contribute to they'd pay for opening if
the facility only for themselves and now
it's a purely polynomial LP and we can
we can just solve it and in order to to
round it we consider we split clients
into two groups the the ones that prefer
like renting or buying so when we when
we look at only that the big clients
also the the ones that have the purple
variables summing to at least point 775
then the middle term of the objective
function vanishes and when when this
happened when we keep only the the
purple variables this is just a
classical Facility Location but with
this
additional term GC next to the distance
so this supposed location in a distorted
metric and this can be solved by a
primal-dual scheme with factor three
approximation and when we consider the
small clients so we consider only the
blue variables right now then this LP
gets trivial because like there are no
dependencies between between clients and
for each client we can like by the
facility that is cheapest for him and
like we need to rescale this these
variables involve variance and this is
the why we chose this constants and like
so there is a four factor around in
scheme for this o P and since we use
this this trick that replace the T of B
with this almost linear term we also
lose another factor and this is in the
end we obtain something around six so
vaccination why is it for like you know
okay so for the big clients the their
constraints are only satisfied up 2.75
so we need to rescale this variables but
like you know couldn't you change the
threshold three quarters of awkward to
play with the Reena
I think I'm asking why is this division
into more than three quarters more than
one quarter optimal like big because of
the like rescaling progress proceed
like this purple variables for big
clients they form a feasible solution
for facilitation in a distorted metric
after rescaling
times four by three yeah and again and
we also lose the specter three on them
so this is four on total and we need to
rescale the smokily and clients times
four so this is that ultimate result
okay so this was the the sketch for the
facility location and this is the
overview of what we are able to obtain
so we for the set cover we can also
adapt a greedy algorithm so we can get
deterministic algorithm with just an
harmonic number ratio and it works also
for constraint set multi cover so set
cover with when each element might like
request to be covered multiple times so
for vertex cover and edge cover we also
are able to provide the same
approximation ratios are as in the
classical setting and also for their
directed directed Steiner tree we are
able to adapt like the easiest
approximation algorithm because there is
a approximation kind of approximation
scheme for their neck directed Steiner
tree and we're only able to adapt like
the first level of the scheme and in the
independent activation model we have
this constant approximation for facility
location that I just showed and in the
similar framework we can also handle
multi cut and
we have this lower bounds for for Oracle
model and the most interesting question
is like getting general algorithms so
we're out this assumption of independent
activation for the rest of problems so
first location multicart
and and spinal tree I prefer for from a
multi-cat that are the best what we can
hope is logarithmic approximation and we
will also want to have to have it in in
Scenario model so that's it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>