<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PhotoTechEDU Day 32 - Art, Science and Reality of High Dynamic Range (HDR) Im... | Coder Coacher - Coaching Coders</title><meta content="PhotoTechEDU Day 32 - Art, Science and Reality of High Dynamic Range (HDR) Im... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PhotoTechEDU Day 32 - Art, Science and Reality of High Dynamic Range (HDR) Im...</b></h2><h5 class="post__date">2008-01-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ALfiTDYLtAQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Jon Frankel of a video search
quality group and I care to introduce
John McCann I met John decades ago is my
manager for four years in my first job
out of college at Polaroids vision
research lab which John managed until
1996 has worked there focused on human
color vision and computer models in
developing rednecks Theory digital image
processing large format instant
photography and reproduction of fine art
among his professional owners is a
fellow and past president of the Society
for imaging science and technology and
this year will become a fellow of
optical Society of America it continues
to do research in color vision it has
consulting firm McCain imaging and he
has an unusually broad perspective to
bring to bear on today's topic which as
you see is art science and reality of
high dynamic range images
I went to a meeting about the same time
that John was in their lab had a
wonderful organizer of the meeting told
a wonderful story and the story was that
it's a young man went to a meeting and
presented his paper and he thought that
this was a very special paper and it was
great new work and he expected to be
really appreciated for this wonderful
work so he gave the talk and the talk
went well and people were polite but
he's kind of disappointed so he saw this
old professor sitting in the back of the
hall and he saw the professor well I
don't get it I thought that this was
good work I expected people to be
enthusiastic about it professor says oh
yes it was a very good talk it's a very
nice new idea but of course it won't
work that's why people didn't appreciate
it so he went back to the lab and spent
10 years in the lab and came back gave a
second paper this time he showed
unequivocally it worked it worked very
well putting out the same response
however the professor was still in the
back of the room he went talk to him
professor said well yes it you showed
that the idea does work but of course
it's not relevant so back to the lab
again another 10 years comes back the
third time gives a brilliant paper on
their relative relevance the answer the
same result goes and sees the professor
again this time kind of dejected and ask
the professor well what's the matter I
said oh well you've showed it's relevant
but of course it's not new
HDR is one of these topics that has
become of considerable interest these
days in not only the capture of
information but the display and so this
is a talk that first of all I wanted to
mention a number of my colleagues and
mentors or through the years most of
these are Polaroid but many of these at
at polar companies other than Polaroid
you talk measures how large is high
dynamic range imaging what's the history
and painting and also in photography
there are some things that I didn't know
well I started poking around in some of
the old books and but special inference
on spatial image processing because that
to me at least is the key to high
dynamic range imaging now it must be a
big topic in imaging it's there in
Photoshop you can take your pictures and
convert them into a HDR image it
consists of having an in photographic
parlance would be an overexposed image
an underexposed image and you synthesize
out of that an image that doesn't lose
information and either the highlights or
the shadows a lot of the current
interest is the result of a fine paper
by develop can Malak and they have in it
a famous picture of the chapel at
Stanford it uses multiple exposures
multiple times it recovers scene
radiances at all pixels from the camera
digits and what was new about this
picture it wasn't so much the idea of
multiple exposures because in fact you
can find loads of precedents for that it
was the idea that you're actually
capturing scene radiances or scene
luminances and in fact there's a recent
Journal special publication on high
dynamic range imaging in the call for
papers that says high dynamic range HDRI
is in merging technology in which the
potential to bring a new revolution in
digital imaging and HDR I the images
record the actual color and dynamic
range of the real-world seed rather than
the limited gamut and dynamic range of
the monitor or other reproduction media
so there's this wonderful brave new
world kind of feeling to the whole thing
it was almost exactly two years ago I
was giving a paper done in San Jose at
the electronic imaging conference and
heard paper by a young man who assured
me that his digital images were the
accurate record of six log units of
information from the world so after the
talk I went and had lunch with him and
said how do you know that you've really
got six log units because there's a
dirty little secret if you work for a
camera manufacturer you know that lenses
are quite terrible in terms of their
properties of stray light you get a
beautiful sharp image but it isn't
necessarily the contrast image that you
would like it to be so I said you know
don't you really want to measure the
actual range before you make the claim
of the six log units and so well I tried
for a while we exchanged emails but the
application of vapers law of the right
way to see these six log units overcome
any interest in this sort of mundane
calibration I did however persuade a
colleague from the University of Milan
Alessandra resi and we have been doing a
number of papers since then that are
just basically good old-fashioned
calibration here's what you'd like the
world to behave here are this is four
times more light and so on each so
you've got a thousand to one range of
exposures the target is nothing
more than a standard kodak test target
you can buy these or at least used to be
able to buy these from kodak they're
nice film transparencies there's also
halftone ones that I'm is good and
there's ten different stem cities and
you just put it on a lightbox and expose
the pictures and then you can with
Photoshop extract the digits from each
one of these ten sectors for each of
these exposures and now flux is the
radiometric term for luminance times
time so it's the amount of light the
brightness of the light times the
exposure tells you essentially something
that's proportional to the number of
photons so on the horizontal axis we
have log photons and on the vertical
axis we have camera digits and the world
is behaving itself you get this nice
simple function and a very nice clean
result now that's what happens when you
photograph one of these scales
however the dynamic range of the scale
is less than two log unit it's not
really a challenge again flux is
luminance times time if you want to get
seen luminance you divide flux by time
and so you if you assume that camera
digit is proportional to flux you can
get seen luminance as I say the kind of
things that camera manufacturers know is
that every air glass interface causes a
reflection it's only three to five
percent of the light depending upon
whether it's coated but camera walls
have reflected they're black and they're
matte but they still reflect light since
the surfaces reflect like particularly
worse than film are the glassy shiny
surfaces associated with CMOS and CCD so
to figure out what's really happening in
a particular camera you have to measure
it so the device that Ollie and I made
was a lodge fluorescent box mat
diffusing screen three neutral density
filters so we have zero one two and
three a hole through four holes
four of these targets and now we have a
range that has eighteen thousand six
hundred and nineteen to one and this is
measured with a spot photometer each
area is measured with black papers
around everything else in the field of
view so there's no stray light in the
spot photometer when you're making the
measurement so again we measure each one
of these one at a time and we can now
plot the luminance of the actual target
versus the digit we get in the camera
now here's one of those exposures this
is taken with a digital camera and you
can see that there's a where it's an
exposure that's appropriate for this
darkest target however you can see you
have an InFocus reversed image probably
of this you have flare all over the
place and so these other targets that
originally well they're not very big
they don't have much scattered light
they won't be much of a problem there's
stuff in that image that doesn't fit the
nice conception that we're working with
so this is the original data we have one
target we get one single curve if you
now put and do this operation for all
the exposures for all the targets you
see that well we're beginning to see
these departures from the curve and the
dark parts of the images at different
exposures we no longer have a single
monotonic function relating luminance to
digit one of the fellows I worked with
at Polaroid was a vice president of the
research naina Angela la mola and he had
a very nice set of descriptions of when
he didn't believe you his he had three
levels just like TSA has Airport alerts
there's sort of a yellow or an orange
and a red the yellow alert was when he
didn't believe you he said well let's do
a San
they check the orange alert was well
you've gone nonlinear on me now this
this data fits the the orange alert this
is nonlinear this is a problem and this
was supposed to be the control because
what we say this
well we won't use any Flair from the
background because we've got this -
stick up a screen covering all the holes
well now you take that screen away and
you put all the white background
everywhere and you've reached Angelo
lamellas red stage alert remember he was
a chemist and so when he really didn't
believe what you're saying he would say
you're completely out of the bottle and
so this data is completely out of the
bottle there's no way that you can take
this data and get back to the luminance
of the scene in the world
the flares just over the Fayette flower
availing glare just completely
overwhelming the situation now in fact
HDR imaging is complicated twice because
every camera has some measure of glare
but also when we look at it there's more
glare in the human eye than there is in
a photographic camera a different
mechanism it's Tyndall scattering from
macro molecules in the inter ocular
media but it too is a problem and I'm
gonna stay on the camera side today but
there's a lot of very interesting stuff
on the Interac EULA as well and I'll
he's giving a paper at that a TI well
just to talk about this a bit this this
is a self-portrait these are the people
sitting across from me in the Tokyo
subway I'm right in here and I'm
photographing the glass the air glass
surface that reflects 5% of the light
in in all cases this is a nice probably
darkened glass of the subway there's no
light in the tunnel so this is just a
mirror reflection a low-intensity mirror
or reflection you can see the lady in
the pink scarf sitting beside me but
that's a five percent contribution of
just reflected light it's a property of
every air glass interface in the optics
of photography a wonderful book by
Rudolf Kinsley who was the Dean of lens
designers at Kodak for decades just a
fabulous lens designer he has some nice
examples of all these rays that there
are unwanted extra stuff that bounce off
lenses and the more lenses you have the
more stuff you have that's uncontrolled
he has some fabulous examples here's a
photograph of the small light bulb you
can see the glare here and you can see
these various images off different
surfaces another example is he just
photographs the reflections of a light
bulb looking at the lens so the lens is
here and there's all these elements he
just has a light behind him and he
photographs it and I haven't counted
them but there's some big ones some
small ones some shocked ones and fuzzy
ones there's just a whole bunch of stuff
coming off the lens and as he points out
depending upon the path length of these
multiple reflections that determines
whether they happen to be in focus or
out of focus the other thing of course
is they have two lenses he calculates
the amount of light that you finally get
to the film plane and with two lenses
you can get 90% of the light but with
ten lenses you only get 60% of the light
so 40% of the incident light falling
into the lens is going someplace else
there's an image focus aperture that's
been imaged by a camera here's an
out-of-focus one but this is the
ultimate prize winner this is a
defective shutter and so each snowflake
is a point source of light
images the shutter that's partially open
and makes it into this wonderful array
of stars and so as I say there's a dirty
little secret you know if you work in a
place that makes cameras and so it's not
surprising that in our pictures some of
the images you know the higher exposure
way if you just take an exposure of this
one with much less light you'll get a
nice fine beautiful picture and
everything else will be black but as you
move down to try to capture the lower
intensities the stray light from the
higher intensities as a problem it's
other bees dictionary photography has a
wonderful term he calls parasitic images
and he explains the formula the number
of parasitic images that can be formed
depends upon the number of separate
component lenses single cemented making
up the lens the rise is very fast
it's 2n squared minus n so that if you
have five lenses you have 45 parasitic
images you can't just assume that the
flux that's following on the image plane
of a camera any camera is associated
with the scene because of these air
glass reflections it depends upon the
number of elements it depends upon the
aperture of the lens it depends upon the
axis off axis of the lens how reflective
is the camera wall sensors surface
reflection film is nice it's matte and
so you can't generalize this you have to
measure what's going on in a particular
camera to figure out there the horror
stories I don't think it happened at
Polaroid but in the optical department
they will describe how a company once
made a camera and made a lens but the
two are very separate entities they were
ready for production they put the two
together and it turned out the wall was
in the wrong place for that particular
design
and so they had to rebuild the camera to
put move the wall to get rid of the
flare because they hadn't done the
testing of the whole system all at once
Ali and I made extensive measurements on
negative films just a standard Kodak
Gold digital camera a nice nikon 900 I
think it is a good professional semi
professional it's not the real high-end
stuff but a not as regular amateur and
also a gym wear another suggestion we
did it with pinhole camera I get rid of
those surfaces associated with all those
reflections however you have a problem
because in any area disk you have all
this junk and then the big spike and
then all the junk on the other side it
turns out some of our 17% of the light
is the junk regardless of the size of
the pinhole or the and the image so you
have a different kind of unwanted light
in a in a pinhole camera
the results were I should have known
this but the sensor range in a negative
film is four point one log units the
with this target we measured three point
five with the bad men and multi maximum
glare target
we measured two point four and so with
the digital camera it doesn't have that
much range we went down a two point
eight and one point six so in fact we're
able to measure more information from a
single shot of a negative than from all
these multiple exposures with a digital
or with multiple exposures from a film
camera
so Y is negative better well a couple of
reasons first of all it will depend upon
the scene you have to be careful about
that 35 millimeter cameras are bigger
there's fewer glass elements we happen
to use a fixed focal length camera not a
zoom camera
the parasitic images for seven lenses is
ninety one hundred and fifty three for
the the particular zoom lens we had in
this camera we talked about the sensor
and as a curious thing about negatives
you get a better signal-to-noise in the
black in a CCD sensor it's the number of
photons versus the noise level in the
chip that sets your black negatives
reversed the negative turns out to be
white on the film and so when you read
it you're reading it with some light
detector and the light detector
densitometer or whatever it is you
measuring it with has a better signal to
toys ratio for we're measuring a white
signal than for a black signal and it's
just because a negative represents the
darker areas as whites and the lighter
areas as blacks that you end up with a
better signal-to-noise ratio in the bike
so anyway there's a problem Houston the
idea of capturing accurate luminance out
there in the world is is limited you're
not going to get much more than three
log units in a typical scene and so what
are some of the other ideas well where
we have people used HDR and other
technologies such as painting and
photography and previous digital imaging
well painting goes back to the fourteen
thousand years ago if you look at old
Chinese painting they're about a
thousand years old you find they're very
interesting stylistic content the
figures are painted they're painted as
if they're in uniform illumination and
they're painted on
or a plain background if you look at in
this hemisphere you'll find there will
there's rock art it's usually binary
black and white rock art it's not that
it isn't sophisticated however because
if you look at things like the Sun
dagger solstice project the people who
are making this rock out a thousand
years ago we're able to monitor the tree
we're able to track the position of the
Sun and the moon with things like the
Sun day or of light falling through one
of the Arak spirals on noon at summer
solstice it also is a calendar for
marking the tracking of the precession
of the Moon north and south over it's
somewhat seventeen year cycle or
something like that the moonlight will
fall on different rings from an edge
that's not in this picture as a track of
lunar astronomy so there's very
sophisticated things there but they were
in an HDR imaging they were interested
in a key astronomy before the
Renaissance the typical way that you
would render that at the dark painting
is you'd poke the paint the Pope with
his eyes closed therefore he was asleep
therefore it was night Brunelleschi
introduced later the idea of perspective
which then made the surrounding image
make him a lot more sense than the pre
perspective images but it took until the
high Renaissance in around 1500 when
Leonardo started painting care oscuro
painting because unlike previous
painters where if you had a group of
people that were there nine people there
might be ten different sources of light
you can identify in the picture each
person was if they were pieced together
but the light would come from different
directions they were nicely drawn in the
head and eye
characteristics but they weren't
necessarily the same light well you can
see here in da Vinci's painting the
lights coming from one direction there's
light and shadow the light is a part of
the picture the technique wasn't to
capture and reproduce high dynamic range
but to capture the high dynamic range
scene and reproduce it on a low dynamic
range media here's another example of
lien Adam 100 years later Caravaggio is
considered by many to be the premier
care oscuro painter and you can see that
the lighting is as important a part of
this picture as the characters in the
park and if you go and see the Night
Watch you walk into the room and you
think all these people in the fire wall
in the life-size painting are leaving
the room they're all in motion and
they're all just on their way to do
whatever it is they were going to do but
again light and shade is a very
important part of that my favorite
however is Van Horne Hearst the
childhood Christ in 1620 because here he
portrays the light from a single candle
and has four separate portraits spread
throughout the room and you can see that
there you can see a noticeable
difference in the appearance of each one
of these skin tones so we didn't remove
totally the effect of the illumination
in the portrayal he moderated the four
images so as to produce the what it
would look like if you were there in the
room now we can take the target we've
already described it has the sixteen
thousand to one dynamic range and we can
ask observers what they see so this is
the sixteen thousand to one the observer
and everything else in the room is black
the observers us to find the brightest
thing in the field of view the thing
that looks the best white call that one
hundred find the thing that looks the
darkest in the room call that one
now find something that has a value of
50 and so you can identify that 50 might
for example be the lightest thing in the
second in the B scale target or
something but anyway so you write that
down so then you're safe alright now
that you know 155 75 now 50 and zit 1
fine 25 okay now do the rest of them and
after listening to a lot of complaints
particularly from John's sister you get
numbers when you plot those numbers you
see that the a scale goes from 100 down
to about 10 over about a factor of 1 and
1/2 log units and intensity but the same
value down here that made the 10 in the
second target is way up not quite to a
hundred but up to 89 or something
so you find these progression of
appearances because from a very white to
an almost black to a slightly less white
to a slightly darker black and so on
down to the black being way down here in
the dark side so there's a nice parallel
here between the varnel Longhurst
painting and the magnitude estimation
done by observers all the observer data
did was assign numbers to what unhurt
von Hohn Hurst had done there in the
17th century is that he knew that in
order to portray the face of Christ it
needed to be a pure white st. Joseph had
to be a little darker and the other
people had to be slightly darker along
the way but he portrayed each of these
local areas as a separate grayscale and
there's very note there's very little
correlation between the amount of light
and the magnitude estimate the magnitude
estimate clearly is coming from the
relationship of these squares
in the area and of course if you use the
whites around and doing these magnitude
estimations you get just a completely
different answer but we won't go into
that photography has a wonderful history
is most dramatic in the 1800s over
twenty five year span it went from the
very first imaging to commercial
products as true both of the Daguerre
the daguerreotype and also of the wet
colognian plate which is sort of the
positive/negative system that people use
today this is fox Talbots first
successful
surviving silver salt image it was out a
window at Lacock Abbey near a bath in
England that's the abbe de Guerre
announced to the public and got a
pension from the French government for
describing all the details of did Guerra
type photography in 1839 we don't use it
much today mechanism for developing the
Silva is to expose it to fuming mercury
at 60 degrees C so this there's not a
popular process the images are fabulous
this is one that has a little hand
painting on it very low grain very
stable the
apparently will last forever just as
long as you put your own put your
fingerprints on him the 1880s a group
the pair by her name a herder and drift
field started to measure the science of
photography they this is from Drew
fields I heard his rather notebook where
he plotted log exposure versus density
and this is the first plot of such thing
and it's an entire field called
sensitometer II and herder and drill
have done some really fabulous work it
was a inspiration to me as the later
became director of research Kodak we'll
talk about him some more and one of the
real experts of herder and drift field
is dick here and that dick has one of
their fabulous slide rules where you can
calculate the exposure if you only know
your longitude and latitude and time of
day last dick about that slide rule it's
fabulous and time of year some well what
did photographers do to capture HD our
imaging well it turns out way back in
the 1850s just after photography you
really got going people were using
multiple exposures to make prints this
is a victorian print the idea was we
were going to sell this for somebody's
living room it was like a painting it
was a dramatic emotion building image in
fact if you look at the details there
five separate negatives these were five
actors the negatives were superimposed
and also cut in place next to each other
it was a mechanically done image
synthesis of the what you might expect
to do in Photoshop there's a wonderful
book you can get a reprint of it for
almost nothing by Robinson and Abney two
really important
progenitors of silver halide photography
in the 1880s and in it it describes what
you really want is a can't a film system
where you can photograph something like
the Transfiguration because there you
have the glowing image of the ascendant
Christ and also the deep shadows
underneath the rock and you want a
system that can capture all that
information here's another one of
Robinson's images this was six negatives
three prints the book describes all the
techniques a crucial one was to have a
good diamond so as you could score the
glass plates and cut them so that they
would buck together
mieze and his fundamentals of
photography in 1920 describes how you
could use two negatives to make a single
print and again an improved result this
wasn't so much for art or for making a
product just sort of a comment on image
quality amis in his books were often
used this image this was sort of the man
coding gelatin in his darkroom just
before the lights went out and he
sensitized it with silver but it's a
wonderful portrait of 18th century of
19th century photography where it was of
an extremely time-consuming and
materials consuming process to make your
own image that all changed in 1900 with
the expansion of George Eastman's Kodak
Company to the brownie camera this went
from the professional amateur to the
industrial imaging side you paid a
dollar for the camera it came with
loaded film you took the pictures you
mailed the camera back to Rochester they
sent back your pictures and
new roll of film in the camera 15 cents
for the film didn't say what the
processing was Me's has a wonderful book
of called photography that was the he's
an Englishman and he was an unofficial
chemist he was an undergraduate at
University College London he found the
book by first of all by captain Adney on
photography then he found the papers by
herder and drew filled his undergraduate
work was to repeat her and regret field
experiments his graduate work for which
he got a PhD in 1906 was further
advances in the mechanisms of the
photochemical process and around 1910
George Eastman went had to go to Europe
twice to hire means to come and work and
be the he's he's been had decided he
wanted to have a true industrial kind of
research lab and he wanted me to come in
order to meet his condition was an
interesting one he had gotten a job
working for a friend of the family and
was running Ratan and Wainwright
photographic materials and he said sure
I'll come to Rochester but you have to
buy Ratan and Wainwright I don't want to
I don't want to upset them and so he did
that's why and it's one of the few
things when a Kodak buys a company it
becomes Kodak immediately but there are
still Ratan filters at least for a few
more years that go back to the contract
that music got out of Eastman this is a
factory to make nitrocellulose again the
homeland security would not like people
doing this it's basically it's a clear
plastic like substance but it's highly
explosive and so many of the collections
of old negatives have to
be kept practically bomb-proof
conditions because they it naturally
degenerates and can explode the it was
up not until almost the 1950s that it
was replaced by say OSS Tate you went
from the guy a nice quiet guy in his
darkroom coding this stuff by hand to
these massive machines that were on a
high-speed and of course in the dark
Kodak needed a research lab and that's
what it looked like in Mises book it
needed an appropriate photographic
studio I love the power supplies there
and it needed a marketing department and
a marketing department was that there
was no Google 100 years ago but Eastman
had a marketing department that ran ads
first brownie camera in every newspaper
in the United States on its introduction
so without Google you can only imagine
what you had to do to run simultaneous
ads and all the newspapers in the United
States there's maize in the middle
Edison on the right Eastman on the left
I think they were watching the girls
making that movie because it's a close
tie between the Eastman and and Edison
in that 1920 book we see the change
because everybody called the
sensitometer of film H and D curves and
log luminance and density and all this
stuff but in Kodak it was a very
important thing that customer was not
the scientist that customer was the guy
who just wanted to take the pictures and
some they didn't want all this science
stuff in their manuals this is a fine
book written by Eastman but instead of H
and D curves
he describes while this is the image you
get if you had two tones and three tones
and four tones and five
tones and so Kodak in in both in
research and in publicity started
talking about tone scale curves and you
still find it in terms of the papers on
digital HD are imaging everybody's
looking for the perfect tone scale and
it was as far as I can figure out meas
in 1920 who made the transition from the
scientific term of H and D um why did
tone scale become so important well
these are the fellows whose made color
film as we know it these are Mena's and
galovski they were the guys who headed
up the development of the first coat of
color film this was the advertising
portrait there were musicians and they
are famous they didn't like clocks they
would play a tune or sing a tune for the
month of time that will they had to
process a bath this is a more
characteristic portrait of what it was
like in the labs with all that dye
spattered clothing process was
extraordinary five layers 28 steps 3.5
hours the requirements were that you had
to hold it within half a degree
Fahrenheit or else it didn't work all
these layers require that you take the
Silva reduce it in one reaction in the
next reaction oxidize it in the next
reaction reduce it and then finally get
rid of it so that I mean it was just an
incredible process but it was not
something that anybody could do in the
lab or in the home it had to be done in
a chemical facility and so that changed
photography that nice guy in the in the
darkroom at least four color film
completely disappeared it was all done
in factory there's a wonderful collector
of photography and Boston or recently
died by the name of Jack Nayla and Jack
over the years had acquired some of
Gaddafi's Kodachrome and so these are
some of the images my wife Mary got some
samples and this is one of her
micrographs of
original gaddafi suki Kodachrome of the
period you can see the die synthesized
in the process the yellow magenta and
cyan dyes just like in the in the
brochures that told you how the system
worked
porky 4 mese and the rest was that you
if you were gonna make the film in the
factory you basically had to know the
tone scale of the film and it had to be
good for low contrast pictures and a
high contrast pictures yeah it's not in
another picture of you - my son John is
here in the front so they have various
family pictures that work their way of
Hilla stalk and so you can see this this
is the curve developed by meas it's the
red one low slope so you discriminate
highlights flat slope one for skin tones
high slope for better call saturation
low slope to see detail and shadows but
basically it had to be one tone scale
fits all entirely different approach was
Ansel Adams in terms of his idea was to
use these negatives these new negatives
that had tremendous range and capture
the world but to render the print in to
again synthesize the image he wanted it
to look like so he used the spot
photometer they had grease spot
photometers well you would reflect light
off the grease spot to match an image
you saw through to the world so you
could measure the amount of light and
you would assign zone 7 is going to be a
white the zone 3 is going to be a black
and so I will do things I will control
my exposure in my development so as to
get the image I see before I take the
picture onto the final print he
described this in 1939 the print has a
range of only 30 to 1 you had to
visualize the image you wanted
measure the radiances control the
exposure in the development and Ansel
always talked about the negative being
the musical score the positive being the
performance and so you would dodge and
burn to synthesize the image that you
really want it to have is a fabulous
example this is one of answerless most
famous pictures moonrise at Hernandez
and I think we've all seen this almost
no one has seen this image if you took
the negative has developed and send it
to the local drug store and got a
straight print of the negative this is
what it would look like this is the
negative without the dodging and burning
there's all sorts of stuff in the sky
there's this all sorts of clouds you can
see the reflection off the tombstones
that Ansel was interested in but that's
the final print and so sometimes you run
across some recent papers will they say
that they have written an Ansel Adams
algorithm but that doesn't even qualify
to Angelo lamal was out of the bottle
principle that's out of the universe
this is a very highly synthesized image
to portray the image that the Ansel had
in mind there's wonderful set a book
that describes how to make photo roses
photographs and it goes through this and
it's really quite an education another
fascinating thing about all this is the
is the film response Polaroid film had a
very narrow dynamic range so there's
very little you could do to adjust it
one of the things you could do however
was that if you see this picture here
it's a high contrast scene you can't
give it the more exposure because you'll
lose the detail in the
at the top but you're not kidding the
detail at the bottom what you end up
doing is doing a pre exposure such that
you expose it to uniform amount of light
so this has gone from a low threshold to
slightly above threshold it's a
technique where you reduce the actual
dynamic range so as to increase the
apparent dynamic range it it works well
in some circumstances but it's difficult
to use Jones and Condit did a survey a
measured 128 different scenes and in the
40s I'm gonna they also we're very aware
of the flare limits versus the film
limits and it was very big part of their
analysis what they said in practical
terms they could make a system that had
three log units of dynamic range and do
well capturing a majority of scenes now
electronic photography at least in our
lab back at Polaroid in the 60s the idea
was to capture all the available
information we could we had limited
resources there compared to today but
the goal was to calculate the sensations
calculate the gradients and the edges
because you have to treat those
differently but the goal would be to
write the sensations write the
appearance on the film and do the
equivalent of what Ansel though of the
finite photographers would do in the
early 60s there was a lot of work that
went on that showed that the new are new
understanding of physiology based upon
dowling in Hubel and Wiesel and Zeki and
a bunch of other pit and Barlow and cool
floor all showed that human vision is a
spatial processing device and there
isn't time to get into that land also
was a big proponent of that and land
gave an address at the optical Society
of America for the Ives medal in which
he showed three demonstrations the first
was a column Andreea an experiment you
would have a red piece of paper on the
Left display send to your eye the same
on our flight as a green piece of paper
on the right despite showing that the
color you saw didn't depend upon the
Quantic cut by the receptors in the
retina the second display was a black
and white Mondrian which had a gradient
of illumination there was a lot of light
here on a black paper and little light
on a white paper at the top you could
show with a meter that exactly the same
amount of light came from both and that
the the I didn't care the one at the top
was light and the one at the bottom
start this also gives you a chance to
look at this edge because we just look
in this little piece we can see we have
an edge here and that edge that one
there or that one there is 160 to 200
that's a big change in appearance but if
you also measure up this way you see you
have the same change in luminance but
almost no change in appearance humans
see edges humans tend to ignore
gradients it's a very fundamental thing
so you want to make an algorithm that is
responsive to those ideas the algorithm
we developed was one where we had a
ratio to make local comparisons a
product that took the ratio from
different places and multiplied them
together to establish long distance
interactions and so the ratio of this
times the ratio he at times the ratio
here would give you a product that would
relate the top area to the bottom area
and give them a different answer even
though this amount of light here and
here were the same there are various
patents along the way that
detail that and there was the third
thing in the lecture was this display in
fact it was the first digital image
processing high dynamic range system and
it was done with analog electronics it
consisted of a target here which was
this wheel a movable light a camera that
had in it pairs of photo cells driven by
an analog electronic circuit that ran
this display in 1960s there weren't any
digital displays there were Neve any
very many analog displays this was made
by having the carpenter shop make up all
these components and put them put a
light box so the actual display was
fabricated in the image of the scene out
of wood actually that they were fancier
they did it out a lovely sintered
aluminum with light box in it and light
bulbs in it and the the electronics
drove this device in the further study
of that we learned that well it didn't
work quite the way land said it during
the lecture that there was an extra
feature electronics happened to have the
property that it reset if the value got
greater than the product at greater than
a hundred percent it reset it was an
accident associated with a design of the
circuit we played around with that to
find out that it was an interesting
property and we kept it and so then we
put in this average to just listen to
the response from a number of different
computations so the algorithm is this
rather strange it's not what you'd think
about is a spatial frequency filter or
stuff like that we physically made
ratios calculator products did a reset
and took an average and so just to go
over it again we have a pair of
receptors we determine a ratio we know
the old product we multiply by the
change we see across these we reset it
and we
average it to be the output now what we
didn't did is did a whole bunch of
different experiments measuring what
observers saw to try to tune the
algorithm to fit and time just doesn't
permit but this is one of the more
interesting ones we have essentially
like an Asscher like staircase that goes
nowhere and it gradually goes up and
steps down here's a regular staircase
here's a descending staircase and
someone had said that well if you really
only see edges these should all look the
same and by and large these this is
lightness plotted vertically versus
distance they almost look the same there
are slight differences it is interesting
however that the predictions of the
model go up and these steps go up even
though it is lighter on the left edge
than the right edge the observer tells
you it looks darker and the lower
luminance looks lighter some this funny
business about the reset which makes the
mathematics unfriendly towards things
like spatial frequency filter turns out
to to persistently reoccur as a good
thing to do and this is when John was in
the lab in 1975 we John was the driving
force that got us this wonderful image
processing device we had 512 by 512
pixels that circuit board is one bit I
think it was I don't know how many there
were 8k chips I remember all and so you
needed 24 planes of those to be able to
drive this imager making an image was a
challenge you had to synthesize the
image there's nothing that we could
capture images with John and I wrote a
patent is a very important one because
the first patent and multi-resolution
processing multi-resolution makes it
possible for you to compute large
pictures and get an answer in a time
that's reasonable
and so this is the Franklin McCann
patent is it works by making a distance
across a space to relate I to X the next
step you're late C to X however C has
already been related by a and so you
have this geometric growth of
interactions from a linear number of
steps and it does and we also did
pyramid like zoom characterization of
the image running shot at time so I'm
not going to go into the details but in
the patent is 15 pages of John's
laborious Fortran for code and a recent
paper we replaced it with this code in
MATLAB it it was an interesting pattern
because it described things what we did
a much broader version and an extremely
broad version so the things were that it
really was one of the first pieces of
intellectual property on using segmented
image areas as in pyramid processing so
this is the picture of John here he
doesn't have on his plaid pants today
these were the best I could take with
Polaroid photographs this was a sunny
day in Yosemite I found with the spot
meter that the white card in the shade
had the same amount of light as the
black card in the Sun and so this was
captured on a Kodak negative and then
the image processed to again generate
this low contrast image now I'm gonna go
through a couple of things very quickly
and show you some pictures this is a
picture taken in Belmont Massachusetts
this is the shadow from my house two
identical targets they have two image
processing you see that
different so just to recap some of the
things before showing the pictures that
Robinson's idea was to make a dramatic
portrait but he used multiple exposures
to render in the low dynamic range scene
Ansel did the same thing using dodging
and burning land demonstrated that you
wanted to calculate an image that was
independent of the illumination Franklin
mccann let the you do it in realistic
time periods we developed techniques
using single exposure film to capture
scenes and Dybbuk and Malak in their
recent work has changed the emphasis
from capturing the low dynamic range and
accepting the high dynamic range of
putting it in low dynamic range to
trying to capture and reproduce the
total range of the scene it's an
important point because if you go back
to using tone scales to reproduce the
world you're going back to the idea that
a value in the world determines a unique
value and the final output and that's
very different from what you need here
you have the same value from a white and
a black and so if you use a tone scale
approach you have to render those the
same what you want to do is to make this
darker and this lighter but if they have
the same input value you're not allowed
to do that you have to introduce the
spatial computation in order to get the
full advantage of the information you
have you can see it here that a film you
can vary the exposure and that move
things horizontally but for every
density in the negative you get a result
on the print if you human vision a value
can be a white or a gray or a black or a
red or a green you've just that fixed
input can be any output and so here's an
example
I'm concerned about the time so I'm
gonna skip through and go to some of the
examples here's a tone scale picture
done with a computer modeling the scene
is such that if you get a nice picture
out of doors and you go in and take this
inside you have a problem because the
blacks are too dark if you do image
processing you can restore the
information here is another Bob HP got
interested in using this technology and
so Bob Sobel was the chief engineer and
he did a ret NEX model in a number of
cameras this is image processed version
but all the rest of these are in fact
image processed on Bob's HP 940 it's
just a function in the camera you turn
it on you turn it off so all these
pictures are processed in exactly the
same manner this is the tone scale map
this is what you would get I guess you
can't see it so you might as well hear
me
this is the tone scale map you would get
out of the camera if you turn on the
rent next it does a spatial computation
and generates this picture as you may
recall this is taking out the same
window of Fox Talbots estate in bath
they're at a conference short while ago
and had great fun taking this picture
again these are just going to be tone
scale versus spatial processing
I recommend you come up and take a quick
look at these on this display afterwards
now here we can count the coconuts
better and if you're hungry that's a
good thing but we're entering a series
of pictures where we don't have as much
dramatic sunshade and so this process is
giving you a less powerful rendition
it's not changing the image as much this
process is a scene dependent process
because if you essentially have a
picture that is only a thirty to one
dynamic range and there's no sunshade
you don't want to do anything to the
picture you want to essentially have
little or no processing to it so the
algorithm has the property that it will
apply a different spatial frequency
filter depending upon the scene content
and so sometimes it's a dramatic change
sometimes it's no change that's all just
based upon scene content the operator
did nothing to create that difference
and of course if you're in Silicon
Valley you have to the picture on the
left is the tone scale picture of the
picture on the right is a handheld
single exposure right next processed in
Bob's Oval's camera and just a couple
more things and I'll let you eat your
lunch good friend of mine Alan Gilchrist
is a very convinced top-down
psychologist who believes that lightness
is controlled not by a simple processing
of the rent and there are lower levels
but cognitively driven so this is he
came to visit now in a recent book he
used Teddy Dolson 'he's wonderful
example of a and B looked different
despite the fact that the same digit and
he claimed that that was the poster
image for top-down image processing
well I reminded my friend Alan that well
turns out that's exactly the same
experiment as the black-and-white
Mondrian because it's gradients and
edges and it looks light and it looks
dark depending upon where you are in the
image it's so that didn't convince them
so I tortured them some more I got out
the IHP camera and I photographed its
image on the display and so I mean in
the tone scale mode I the digits that
came out of the HP camera 151 155
however when I turned on the rent next
mode the digits were 140 and 186 so I
said they were I guaranteed him there
was no cognition in the firmware and
that the results were were due to low
scale processing and there's another
example of doing this that's fun cuz
this wonderful display that psychologist
is starting to worry about everything's
the same except there's a gradient that
goes from white to black over this short
distance when you look at it most people
see that this one with the extra
gradient looks much lighter again if you
photograph it with the meze tone scale
they are the same if you photograph with
the retin X camera the one on the right
has a higher value by about 5 or 10% so
the proposal is that high dynamic range
imaging is best if you mimic what the
eye does if you do what painters have
done what photographers is done and
unfortunately it if you did capture the
entire world and reproduced it exactly
well it must be a perfect reproduction
there's two problems with that one is
it's practically hidden practice it is
impossible not not only to say difficult
you could do it if you had enough masks
and spot photography something but it's
also unnecessary because humans a can't
see a great high dynamic range in the
scene because of Interac ulis scatter
and B the experiments that means did a
Kodak says they don't prefer that as an
image they like a tone scale with more
contrast so that's the conclusion I
think I've run over a little bit but
thank you for being here and I'll be
very happy to show you these pictures in
more detail or discuss things or better
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>