<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Gesture and Tactile Interfaces: Applications in Mobile Computing and American Sign Language | Coder Coacher - Coaching Coders</title><meta content="Gesture and Tactile Interfaces: Applications in Mobile Computing and American Sign Language - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Gesture and Tactile Interfaces: Applications in Mobile Computing and American Sign Language</b></h2><h5 class="post__date">2010-10-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Z-t_MBFwCCU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a great pleasure via great pleasure
to introduce Tatiana from Georgia Tech
visiting us here and the wonderful bay
area called his father son died today
sweetie bright and nice and warm fetish
got his PhD from MIT and then moved on
the Georgia Tech in this possibly the
person that defined the user variable
computers in a productive life there's a
number of people who started running
around with better displays but his work
is much deeper much more interesting
than most of the other people he's been
working on race interfaces since input
devices variable display devices and so
on and it's a real pleasure having him
talk about his most recent research so
with that he's also a friend of soggy
Britain etiquette that's very gracious
are from we ran to each other
conferences but he's out of town today
unfortunately can't make it here well
looking forward to your presentation
thank you ok let me first apologize
because I literally got off a plane
recently this morning and drove down
here the weather in atlanta we're having
hi storms had a look like a tornado
coming in but i didn't show up i meant
that all the planes got messed up and i
spent the night in the airport so if i
seemed a little out of it that's why
we're also gonna be switching back and
forth between different devices here so
bear with me in the video folks as a
go-between between systems okay so last
time I was here I talked about how to
improve many QWERTY keyboards how to do
a lot of stuff the mobile computers love
mobile HD I stuff today I if you sell
that talk you won't be bored because day
is almost completely different let me
start out with something that shouldn't
work this is something called the mobile
music touch let me tell you what it does
with this device you can actually learn
piano melodies without paying attention
to it in other words you'll be wearing
this glove right here and be learning
how to play on a Star Spangled Banner
now how this works is that you have a
mobile phone in this case it's the open
milkha you see on the screen there and
this you upload your songs too and the
midi player in the phone plays the songs
in sorry that's actually it coming
online it plays the songs over and over
again in your bluetooth headset or your
earphones whatever you have on but for
each note it actually taps the finger
responsible for that note using this
glove now this is a bluetooth glove the
others vibrators in each finger what you
can see there and there on the knuckles
they're tuned to 160 hertz which is
about the frequency your puccini and
corpuscles are most sensitive to the
fingers the whole finger vibration so
you get an idea of which finger goes
with which note now I'm going to pass
this around as I talk about this so
people can actually play with it so
there is a toggle switch on the back
toggle it from off to on and you'll feel
startup I think it's right now doing the
sequence of dashing through the snow so
feel free to feel free to play with this
and then i'll tell you why this
particular glove is so interesting in
just a little bit no you don't want me
to sing this is not karaoke night the
inside the box that we've made it many
different versions of this this glove
but it's pretty simple it's just
bluetooth receiver you can see in the
center there attached to a glove we've
learned a lot about sewing wires into
gloves Sebastian you got working yeah
cool it sounds great well you really
have to have the music with it right but
you might say you might wonder why this
works right in particular we'll talk
about the hands moving left and right in
piano a little bit when I described to
us the simple study we did first which
is we did to nearly composed ten note
passages now we did newly composed
as the first I we did we used Amazing
Grace and the dashing through the snow
part of jingle bells and some of our
subjects were from Muslim countries and
had heard neither of them and some of
our subjects of course they were very
very familiar none of our subjects knew
how to play piano or had a musical
background but we want to have something
that we had a clean as a study as we
could get so we actually showed we
gathered 16 subjects none of them have
musical experience we showed them the
passage once on a keyboard with the keys
light up and then they had to try to
repeat it and that was the base case
then for the next 30 minutes they did a
reading comprehension exam that reading
comprehension exam was what you find on
normal sad matter of fact I think I have
it here I know if you can see that but
it's nothing where they have to read the
paragraph and answer questions welcome
back then a second after 30 minutes of
doing this they have the glove seeing
they're playing the passage in their ear
piece in their headphones as well as
tapping their fingers that's the
experimental condition the control
condition was just playing the audio in
their headphones over and over again
after 30 minutes each subject tries to
play the song again and this is a
within-subject study at ubuntu design
and this was presented a chi this year
so if people in the details you can look
at there again he was a distractor task
we actually tested people on the
distractor task their scores did not
improve or did not change in the
experiment conditioner is a control
condition and this is a total number of
errors after 30 minutes now the green
bars or kind of kind of fluorescent
green on the on this screen here show
the number of errors made by people in
the experimental condition the red shows
the number of errors they made when they
just had the audio playing as you can
see here they don't learn anything with
just the audio playing but most of them
half of them play the sequence correctly
with no mistakes the after the three
minutes of passive practice now this is
really kind of bizarre
hey how many people would have thought
that would have worked all right I
certainly didn't so this this this is
type of thing that has a cognitive
science major I go how's this working so
we've done the study again and again and
again in two different continents with
three different researchers and it seems
to hold true and it seems to work and
matter if the distraction task is a rien
comprehension test if you're reading
your email if you're watching a movie if
you're dorant doing a scavenger hunt if
you're playing a memory game or even a
chi i gave a talk and had the system
teach me Beethoven's Ode to Joy as I was
giving the talk which let me tell you
talk about performance pressure I just
said about how this thing works and I'd
to walk up to the keyboard and try it i
didn't even know where to put my hand
down at first but indeed i can now play
Beethoven's Ode to Joy he's the first
two passages the first first two phrases
pretty flawless flawless three I don't
know I didn't watch video of myself
getting the talk I will tell you that
having the audio at the things volume
was too loud so it was really
distracting but you can imagine if
you're doing things like email or
something where it's or quiet it might
not be so distracting one things we want
to do right now is a really curious to
see if the audio is necessary it may be
just the tapping the fingers is
necessary to give you the sort of muscle
memory now some of you actually play
piano might say hey how about the left
and right movements on the hands well
actually this technique is better for
things like clarinet or saxophone flute
something where you're not moving the
hands around a lot but what we found is
that when we did you know real piano
pieces and this is still just one handed
what you're moving around you have
somebody work on a song until they can
play through it once and then you turn
on the glove let them spend the next the
rest of the day feeling it on their hand
and they actually continue to learn
instead of forget so you don't sort of
passive haptic rehearsal at that point
one of our reviewers one of our papers
actually said they really liked it
because for musicians with repetitive
stress injury
they could actually practice without
practicing which is kind of cool the
other thing we're kind of interested is
in is well as work for other manual
learning tasks things like typing or
sign language or prosthetics or
complicated manual controls we don't
know yet this whole idea of passive
haptic learning as we call it is new and
we're very excited about but we don't
know how far it's going to go going to
go one thing we do have data on though
is passive haptic rehabilitation we work
with the Shepherd spinal cord Center in
Atlanta it's one of the nation's premier
centers for dealing with traumatic
spinal cord injury and in particular
working with the murder ball team you
can see picture of them here and what we
had a pilot study where we showed that
wearing this glove and actually having
this vibration season to improve these
folks ability to grasp objects and
manipulate them able to ability to feel
objects on their fingers and most
importantly ability to do things for
themselves like Bunning their own shirt
and you know we only did ran this with
two subjects so far we're gearing up for
a full-scale study but this stuff in the
literature that seems to indicate that
having this passive tapping on your
fingers actually activates the motor
region as well as the matter of sensory
region and this passive practice may
actually help neurons reconfigure and
rehook up and I can give people
references for that if they're
interested but we're trying to get this
actually hooked up this summer and fall
with a more large-scale study and show
and see if there really is an effect
here that's one of the reasons why we're
interested in whether or not the audio
is necessary is the idea was not
necessary it could be very very useful
alright any questions on that before I
move on try and make this interactive
okay I have a lot of stuff here way too
much stuff so you know we're not going
to get through it all ask away so as
some of you know I've been wearing
computers for 17 years now
I have a heads-up display on I use a
keyword called Twitter in fact right now
I'm looking at my notes for this talk in
my eyepiece and we've learned a lot
about mobile devices since then one of
the biggest things is access time is a
killer access time is amount of time it
takes you to physically get the phone
out of your pocket dead on get to the
right place in the interface ID actually
doing this right now so I'm getting to
my calendar and you can see that that
took me and I'm practiced at this that
took me about 15 seconds on average is
about 20 seconds to get to an
application on your phone it yeah and
yeah yeah Windows Windows is going to be
a serious problem in a phone what we
found out is that any time you have it
takes more than two seconds to get
access to your interface your use if it
tends to go off exponentially so if you
can make it a quick interaction people
will do it all the time if it takes more
than two seconds the the usage of it
goes down linearly or exponentially
depending on the type of interface now
the other thing that we've discovered is
that people don't really multitask they
multiplex for most things I just talked
to you about a real as far as I know a
real multitasking application but most
of time when people are driving and
texting these are driving or texting
they're switching back and forth fast or
not as the case may be by the way we
would not doing some my own studies on
driving texting while driving it's
really really bad there is one obstacle
intercourse the course is 28 feet away
from it it's a telephone pole and the
drivers still scare us to death driving
this car we're actually using the Thomas
or using a Georgia Tech's for Thomas car
for this
Lily you know is because of my subjects
not yeah but one of the things we've
discovered is that when people are
actually using in your face like say
walking down the street for walking down
the street and you know out late night
and then Palo Alto you're going to get
some ice cream or something you'll spend
on average about four seconds on your
phone interface before looking up to see
where you're going and looking back down
at your display and that kind of leads
to the four second rule if you can
actually make your interface happen in
four seconds it'll be much more useful
to people in other words if you can get
a little bit of useful work done if we
have to look back up again if you can
check point is actually much more useful
than if you can't and that's how and
that's why we're making this distinction
on micro interactions meka interactions
are fast to access a landslide fine
check pulling now if you're on something
like a bus or subway you might actually
go spend more time on your interface but
I'm talking about that the four seconds
it seems to be a nice roll from making
something is universally applicable now
when I say when I say that I'm give you
an example checking your time on your
watch if you actually wear a wristwatch
is a relatively fast interaction it
takes less than two seconds to do the
entire interaction it's very valuable
it's fast to access and gives you a
feedback now you notice that a lot of
people now are putting their time on on
their cell phone all right oops there we
go not quite so fast access but the cell
phone is a useful enough device people
willing to take that hit wristwatches
actually came into existence during or
in the popular use in World War one when
you had to time your trench warfare
right if you want to go over the trench
line all at the same time and you can't
be seeing their filling with your pocket
watch when you're about ready to go you
know run against the Germans so that was
one thing that made all the GIS back
then where wristwatches but also a VA
you can't be flying your plane and
before you around your pocket watch need
something we can look at quickly and get
back to what you're doing and back then
what we're one you actually had to fly
by your clock now so pocket watches went
the way of the dodo now they've come
back right their cell phones but I think
what we're going to see is a lot more
use of very fast access interfaces now
one of the things we're doing that for
that is something called textile
interfaces now we're trying to create
interfaces that can be woven into your
clothing I really mean woven or knitted
in this case into your clothing and
we're using embroidery because it's a
raised thread you can actually feel it
so if i was going to control my ipod
with something those on my sleeve I can
feel the controls here I can grope for
them we're called good grip ability and
actually interact with it without
looking so there's no visual distraction
now there's been a lot of work done by
this by some friends of mine Maggie or
three me post back in the mid 90s but
what we've decided to do is start taking
a look at this from a more complete
interaction as far as trying to actually
reproduce the GUI tool kit from scratch
on using these devices now way to
actually have demonstrations of
different circuits that people can use
in the fashion industry now this is a
book and I have a live version this this
machine is hooked up to do show you this
afterwards to show these different types
interfaces this is what's called a
knife-edge pleat it's got three lines in
it one on each side of the pleat and one
on the base and paying on which way the
person strokes the pleat it moves a
slider one way or the other so you can
imagine that if you have this
embroidered on your pants leg for
example uses control a web page in your
heads up display or need to slide up and
down or you can imagine controlling the
volume of your mp3 player here is a menu
widget rendered in embroidery so you can
see we have three venues three
categories like you know Phi
edit selects that you might have on a
Mac and then you have five options and
so I'm actually controlling the graphics
here on the right hand side based on
which line I touch again imagine it's
not in the book but on a piece of
clothing like on your armband on your
arms so you actually you know select
different menus on your iPhone or your
your gphone or whatever else you want to
think about this is something called the
rocker switch this is a multi-touch
system not just like the last one though
so remember the old types of rocker
switches where you can rotate you can
pivot about a point and lines goes turns
volume down one terms of volume up well
this has three different favorite point
sliders you can access and then you just
once you select one you just pivot about
it hit the two bigger circles and that
adjusts the level on each slider now for
those of you who are electrical
engineering types that in the crowd I
can give you a quick lesson of how the
circuitry is done it's this is not the
normal capacitive sensor you might not
think it is because prom with fabric is
that as it crinkles and wrinkles it gets
out calibration real quickly this is
actually recalibrating itself you know
every time it senses which is really
kind of cool here's a zipper this is a
has been done before we're doing it I
think a slightly different way it can
sense this position Jimmy nothing it's
all conductive in broiler thread so wash
is just fine the lines are conductive
thread the only thing I do is take out
the circuitry where combines in yeah
it will they will sense falsely in that
case yeah but its ways ways to do it
where you do a basically a wheatstone
bridge and you can do a little bit
better than what we're doing here this
is a proximity sensor this is that one
of the first things we did the Brothers
of broader machine we have one of those
default settings is to embroider hello
kitty so we have the Hello Kitty
proximity sensor here as you can see the
paying on how close you get it has
different sensitivity ranges it's the
brightness of the rectangle indicates
how close you are to the system
this is a really complicated one with
this by stroking the bi thing that the
top pad and one of the three but middle
buttons you select one of the three
sliders on the top by hitting the bottom
pad and when the mill 3 slider three
buttons you get the three sliders on the
bottom and then you can increase and
decrease it by doing gestures on top of
it now unfortunately this one's not
tuned very well when we did the video
but you get the idea all right so if we
can switch back to the having both
screens be the presentation I appreciate
it that way I can cheat by keeping and
looking at my notes ok so these
conductive embroidery really got us
thinking about all sorts of things we
could do with conductive embroidery let
me do this so it's not quite so
distracting we now have a way to input
we need to output as well remember what
we're trying to do is make something
here we can interact with an object you
can act get access to the interface in
two seconds or less and you do the whole
interaction in four seconds or less so
we got some output sorry some input how
about some output well these are
conductive threads they have a high
impedance relatively speaking compared
to a normal wire but at high voltage it
doesn't matter the human body senses a
voltage current tuned to the exact right
level as vibration so what we start
looking at is can we make a wristwatch
watchband that shocks you in different
patterns it feels like vibration to you
but we're trying to figure out how many
different patterns we can indicate so
you can imagine that you have an SMS or
a call coming in you'd have a different
not ring tones but shock tones
vibrations you know good sensations I
don't know uh coming in through this
wristband and I have a copy of that up
here somewhere I can show you show you
all and so we this is
done by singing leave just got her just
a fender PhD it turned out that this was
much higher resolution than the human
risk can feel believe it or not if you
take two points and put them close
together in your wrist you really cannot
determine its two points most times you
think it just one and believe or not you
have to get out to like a centimeter
before you start distinguishing their
two points on your finger tip is like
two millimeters by on your wrist it's a
centimeter sometimes more it's really
ridiculous Jimmy well if you if you
start using time delay you can do a
completely different pattern we're
looking at spatial stuff here but you
can do all sort of stuff of time and
matter fact that's what the next slide
is going to be about you're predicting
me but what's also very interesting is
that while you can actually sense what
you can actually tune the system to do
decent shock levels on the fingertip on
your wrist your wrist is often dry or
wet and so the amount of current you
need is very different from minute to
minute so my poor grad student end up
having a little tattoo no is she it was
very fine threshold between pain and the
vibration sensation we wanted so we
actually had to go away from this to a
vibration pattern however never going
back to it I said that we could sense
capacitance and resistance using these
threads so here's an idea that sent us
the water content of your skin and then
dial up or down the current depending on
how much you need to get the right
vibration feel and so we have a circuit
in our lab right now that does that it's
very crude but it's getting there and so
we're going to revisit this very soon
other people have done this sort of
thing on the forehead or on the tongue
turns all the tongues a very good place
for it because it's always wet it's
takes very little current to get good
sensation there and your tongue has got
a high density of receptors your wrist
is relatively insensitive or thinking
about wristwatches so we want to keep on
going down this wristwatch form factor
and we decide to make a display that was
just three vibrators now these vibrators
are made so that two of them hit your
wrist bones at the top just where this
way your arm bone hit your wrist is two
bones there we're generally doing this
on the bottom side of your wrist there's
one in the middle but back going up your
arm a little bit and we can actually do
24 different patterns here the patterns
differ depending on which vibrator
vibrator starts the pattern one two or
three you can see that in the red green
and blue columns it also is the we have
different intensities of the patterns
low and high we have what's called
pulsed intensities so that the
vibrations going versus disease and see
here you have frequency oh I think we
have different frequencies as well so 24
patterns total and we're trying to see
how well can people actually sense these
24 different patterns on the on the
wrist the answer is not bad except for
intensity turns out intensity is a very
very poor thing for actually gay
transferring information from
information of your wristwatch so again
I idea here is to transfer messages
alerts like who sing you an SMS which
sort of phone calls coming in to this
sort of wristwatch and we'll talk more
about wrist watch if people are
interested I can talk more about wrist
watches which watch interfaces
afterwards what's interesting here is
that intensity is a real is a really
horrible feature to use we got rid of it
direction was pretty good temporal
patterns pretty good starting point was
very good so if you're going to actually
make a wristwatch with vibrators it you
know here's a good starting point next
thing is can we actually use these
vibrators while you're doing other
things now remember what I said about
people don't actually multi-task same or
multiplex so what we did is we compared
using one these one of these wearable
tactile displays to a normal phone so
normally if somebody's smsing you you
reach in your pocket and you pull out a
device and you look at the
the see who's calling of what the SMS is
and put it back in your pocket so we
made a system where people had to pull
out their phone and hit one of these
three buttons on this keypad to complete
the trial what with a vibrator system
they had to do one of three different
patterns now we're trying to do
something that sort of mimics the high
and visual intensity the high visual
distraction of driving and for that we
have this so they have five seconds to
determine whether or not the number 51
is in this image now I know all of you
being nerds we're not going to listen to
me for the next 20 seconds as you're
trying to figure out if 51 is in there
it's not give it up but the point is you
can't help but paying attention to it
right so we're doing this on Georgia
Tech Georgia Tech students it's a very
good distractor task so it worked very
well to kind of emulate visual high
visual distraction while getting these
different alerts the buzz wire system is
actually doing these these three
different patterns they are the most
distinctive patterns we had and we're
looking at information transfer now
notice ignore the ignore the outlier on
the right-hand side for a second we have
different difficulty primary tasks one
where is where there's only ten numbers
on the screen you gotta find 51 51 is in
those 10 numbers ones that when there's
30 numbers one and when there's 50
numbers and so that's the easy moderate
and not difficult notice that the bits
we can transfer per second or per minute
in this case is actually a higher with
the tactile display that is with the
phone interestingly also the tactile
display does not interfere with your
primary task which is great but let's
look at the the left hand side here the
phone is having a much higher bit
transfer rate when you're just paying
attention to the phone then when you're
just paying attention the wearable
tactile display why is that well it's
something called the York seed dodson
law people get bored when you want to
give them give them one task at a time
and their mind wanders and because the
the tact we think because it
easy they are off doing something else
in there are mines and don't pay
attention to study anymore and so that's
why we think we have this this
discrepancy on the left hand side with a
phone it's still physically active
enough thing that people are forced to
pay attention to it but what we're most
are stood in is this this is a
multiplexing scenario like when you're
driving and you're getting an SMS at the
same time now so we've talked a little
bit about how we can actually do input
using textile interfaces how we can
actually do output using vibration and
electro stimulation but can we do
something more complex one of the things
that we specialize in is gesture
recognition and you can imagine that if
you eventually have an mp3 player that's
basically you know looks like a hearing
aid you know can fit in your ear my
problem is you don't have any buttons
you know to standard the to be walking
down the street doing this right is kind
of socially inappropriate so can we
actually make a device where you can
control an mp3 player in your ear when
it's not big enough for buttons well
again we're looking at the wrist watch
in particular we're looking at
accelerometers in the wrist watch and
we're trying to figure out can we make
gestures that are distinct in in real
life to control things now making
gestures for controlling applications is
difficult for example suppose I make a
gesture like this for a delete email
well then I'm in a little conversation
and I make the same gesture and I
accidentally doll my email that's not
going to fly a matter of fact you guys
are all familiar with this particular
problem now is not particular gesture
recognition but we have your phone in
your pocket you know how many of you
have somebody call you back and say hey
your phone called me what did you want I
couldn't hear anything right I
occasionally get voice messages from
other people where it's just the
background noise there but called me
no drunk dialing no sitting and dialing
at the same time yeah so there's other
places where you get these sorts of
problems and people go through a lot of
pain to avoid this for example in speech
recognition they always have a
push-to-talk interface even they don't
do that they do something like computer
open file something to tell the computer
to listen in on the Nintendo Wii when
you're playing bowling which is a
relatively complex gesture right it's
doing Billy fine sensing it is doing it
is requesting that you actually push a
button and hold it down to do the
gesture and release that's house that
it's detecting when the action is
happening on the iphone right there's a
push something down you put to a slide
across the interface to activate the
phone and most phones including I have a
back flip on me here AHA has the same
sort of thing as a push button and then
oops and then you have to hit another
button for it to actually work and I
need to pull this out anyways in just a
second so I might as well get it out so
what we're trying to do is make a system
where you don't need these push to
activate it be much cooler if I actually
a system where I just made the gesture
and did the action if I actually have to
have a button in my wrist wash to
activate the wristwatch and then do the
gesture it kind this is the point why
would I do that anyways I should just
have a button write it anything that
requires too much attention to push the
button is probably the wrong thing now
correspondingly you can imagine I have
accelerometer in my mp3 player here and
my gesture for training track is that
but that but then you start looking at
like night in the roxbury as you
change tracks it's a distinctive gesture
by way you can do it I just don't
necessarily recommend it but what we
want to do now is actually make a device
such a tool kit so that people can can
research these gestures easily and what
normally happens is people do some
survey like suppose we're trying to make
a gesture system for the ipod people say
so what just you need for play some i
give me a gesture for play what just did
you want you have a wristwatch on what
gesture do you want for for play this ok
what else this this ok anything else
notice i didn't get any any similar ones
yet everybody has their own gesture so
usually people go off and do a lost
service and try to figure out what's
there we go figure what sort of gesture
people want and then they try to make a
gesture recognition system for it and
then they have that system in an actual
device they find out it doesn't work at
all right because it's false triggering
all over the place so that's where magic
comes in the multiple action gesture
interface creation tool so we're using
accelerometer on the wrist again just to
start out with for those of you who do
machine learning and pattern recognition
in the crowd you can think of this is
simple dynamic time were catwalk or
warping just because it's easiest to
explain if those who aren't machine
learning or pen recognition people
basically if you have one gesture that's
sort of the one you want to recognize
and you have templates of other gestures
that are the one that indicates you the
play function you compare the red to the
green by drawing lines to the closest
thing loose closest points on each and
then the difference between the mouse
slant on those lines is the error now
for those of you who are paranoid people
were actually doing as ice axe allows us
to search very large databases in split
seconds and so we can actually I make a
user interface that just flies like I
said the design process and pass is
basically people try to
create a gesture system then they try
test in the real world they find most of
those gestures conflict with real real
world gestures that and they go back to
the drawing board what magic allows you
to do is do them both at the same time
test your gestures against each other
and against the real world now how's
that work what we do is we clicked
something called the everyday gesture
library and we put the sensor you want
to use for your ipod on your wrist let
me give it to somebody for it to wear
for a month and we try to get you know
representative actions and represented
people so we might get an academic a
librarian a construction worker you know
a pet sitter you know just try and span
the space of people might use this
device and we gather lots of data from
their everyday life we also if they'll
put up with it yet video from this cap
this fashionable cap with a fisheye lens
on now notice that fisheye lenses
extreme enough that you really have to
get within kissing distance of somebody
to actually recognize who they are in
the video image so there's actually
privacy preserving and so when we have a
whole huge library people's everyday
gestures and video of what they were
doing when that motion occurred so then
if you have a candidate gesture you want
to try say you know this or this or this
or whatever everybody was telling me you
can actually try that against
everybody's months of data and see which
one's work and which ones don't and this
is the interface for it so I am I could
probably just as a cursor here yeah here
we go so let's first look at this this
this for the pattern recognition people
is this is each of the classes so we
have four different gestures are looking
at here of each of the four gestures
we're looking at the inter intra-class
of variance versus the closeness of all
other classes and their variance as
related to that gesture so this is both
intra and inter class variance over here
hey don't do that
over here is a bomb that is our months
of data and you probably can't see it
back there but there's little yellow
pink or yellow lines for each gesture as
it happened in the month-long data and
so then you can click on one of those as
we see here and it shows you that
particular example of when that happened
in persons every day in people's
everyday lives and what they were doing
at that time using in the video it also
gives you some idea about the different
examples of class of gestures we're
doing okay nearest neighbors approach
here and some other details that if you
are a Patrick person you can tune now we
had a lot of fun with this we actually
had people try and make eight control
gestures for the new you pod touchless
by pair computer and people who had the
egl would generally have about two false
positive progesterone because people
without the egl had 50 false positives
now this it didn't matter if they claim
to know pattern recognition or not they
all sucked they are all very bad at this
bet this task so the egl really having
this database really had a big a big
impact on the system now the other thing
that was kind of cool about this is that
our subjects really did discover ways to
improve their performance by doing
particular techniques to get better
gesture recognition and I will switch to
file to show you these so this is
somebody doing iconic gesture in other
words they'll repeat each of these two
times so you can see it the first one
was iconic and stop the second one was
really interesting is impacts other
words when you hit your hand against the
other hand that looks very distinct in
the accelerometers in the accelerometers
space compared to your everyday actions
this guy is prefixing every gesture he
has with another gesture so his is the
way it is basically saying you know
listen to me
pewter and that he does this I figure
what this one this is a lot just
repeating the same gesture twice so you
get some idea of the types of gestures
you need to get uniqueness the problem
is a lot of these things are not
socially appropriate right the you know
the guy he's doing computer listen to me
okay I really mean it now this and this
that if you saw me doing that walking
down the street you probably think I'm
an idiot either that or some mage who's
doing incantations but if you saw me
doing something like you know this when
I'm just flicking my fingers and do that
my side I can do it straight up that is
something that you just you know it's a
subtle gesture you might not even notice
me doing it and it's very distinct in
the database so we're actually
discovering the gestures you can make
their very subtle for controlling your
mobile electronics now the last video
here is just for fun this is somebody's
everyday gesture library I think this
was going on a hike somewhere after a
while you forget you have a camera on so
you know I'm not going to try to show
you the embarrassing EG ales but you get
the idea and so again this is a video
you get if you found a conflict now for
those of you with android phones how
many of you got phone on you can you
accept a android phones can you accept
on if you have the backflip you can't
have unsecured apps but i'm going to
show you a nap right now what we have is
an application you can run on your
android phone use accelerometers in the
phone you can actually we have a
database of somebody walking around with
a phone in their daily life and now you
can actually make different gestures you
can happen to the database it's there
you can see how unique they are compared
to the everyday gesture library of an
android phone and so you can start
thinking about actually having different
gestures for your android phone to atty
two different activities matter of fact
you can even download the source code
for a recognizer that will recognize the
gestures you trained up so people who
have the application cannot come up
afterwards and I'll show that to you
okay one of the kind of interesting
things about all this is that the people
who are in our user study kind of fear
the egl I thought was very hard which is
understandable and they didn't really
care about the video those days care
about they had a conflict but they
actually found the system very useful in
Korean doing the task ok now I'm going
to switch to something a little bit
different here this is our probably our
prime example of doing gesture
recognition technology this is copycat
I'm gonna get some background on on
copycat ninety-five percent of deaf
children are born to hearing parents
many of those parents when their child
is born of course do not know sign
language and sits sign language America
silent which is difficult to learn as
Japanese may of them will never learn it
sufficiently to really communicate with
their children that might seem odd but
when you are working two jobs you have
three children one of them is deaf and
there's a lot of people who in the
literature who say that you know if you
teach some by two languages they won't
learn if you teach them something we
don't learn English it turns out exactly
the opposite way you should teach him
sign language first they have a much
better chance of learning English but
what we discovered in the literature in
the in the research is that these
children actually unless they learn some
language in the age between 0 &amp;amp; 3 they
will not form their short-term memory
normally let me make that clear so each
of us can actually remember about seven
things in our head if I give you a
telephone number like 2 for 4 or 5 1 5 6
you will be able to repeat that phone
number back to me the children i work
with often have a short-term memory of
two items and that happens because they
do not learn a language when you learn a
language that's when your brain is for
to form the short-term memory and so
children need access to some language
any language in order to actually form
the short-term memory so question is how
can we make a how can use this gesture
recognition technology we have to
actually encourage the formation of
short-term memory and acquisition of
language so what we've been what we've
been creating is this system here this
is called copycat so what happens is the
hero of the game iris the cat here you
can see her in the bomb left and thigh
here right where he is iris is a white
cat with blue eyes because why casa blue
eyes are often death she's the hero she
is trying to find all the gems have been
stolen and they've been stolen by snakes
and spiders and alligators and all sorts
other monsters and so the children have
to when they come upon a scene like this
they have to say that the snake is under
the chair that's the three word phrase
often times they'll be multiple chairs
and multiple snakes you guys say which
one has the gem so that case would be
the the orange snake is under in this
case the blue chair I think it correct
iris will magically poof the snake and
get the gym ago on the next level now
this is a sign language verification
task not just a sign language
recognition task and we're using gloves
for computer vision we're also using
accelerometers again that gives us while
vision might not give us up and down the
accelerometers do so think of them as
glory glory I tilt sensors this is the
scenario we have with the children in
this little kiosk at their signing to
the game now you might think this seems
like a relatively easy computer vision
tracking system but remember we have a
lot of different video going on here a
lot of different lighting conditions
here the the features were using we're
using head placement hand placement
angles relationship to each other we're
using we're doing PCA on our database so
we have the top 20 hand shapes for the
left and right hand we're doing FFTs on
the accelerometers we actually render
little eyeglasses on the children's
video so as they are interacting with
the system the eyeglasses tick on them
so they can stay within the view of the
camera now why this is heart is hard
well it turns out we're only using 19
signs in our system but they can be done
in many different ways for example this
is bed and this is bed and this is bed
and this is bed this is cat so is this
so is this most signers if you watch our
interpreter here have a hand dominance
and so most of their signs I'm actually
looking at her hand to figure out which
domine is but she's doing all two-handed
signs there we go she's right hand
dominant so so most signers have a
dominance the children we work with
actually don't have a dominance they'll
switch dominance in the middle of the
phrase which causes us all sorts of
problems they also have things like you
know flowers to go right to left or left
to right what right or left hand so
that's a problem we've loved so with 19
phrases the 19 signs we end up with
believe it or not 128 different tokens
we're looking at there's that much
variation going on the other problem is
we have lots of disfluencies in speech
recognition disfluencies you have to
actually recognize people were coughing
or or or ah you know or right you had to
recognize all those different utterances
in order to make your speech recognition
better we have the same thing we have
cough excuse me and no no no you know I
didn't mean that or mmm that's just a
sign next and we don't and we want to be
able to recognize you know the orange
snake Oh under the the green chair right
so we got it will handle these
disfluencies so actually recognizing
them as well my favorite disfluency that
we're recognizing is the pick your nose
gesture that's why our gloves are
washable
so we get about a four percent accuracy
and trying to determine if a phrase was
signed correctly or not interestingly
enough r sine linguist when we're doing
a wizard of oz study to collect data he
pretended be the computer recognizer he
only had ninety ninety percent accuracy
so we're not that far off but the human
is doing in truth were very far office
this is a very hard problem we got many
years of work left but for this
constrained situation we're okay we
actually deployed the system fully
automatic for two weeks what we had six
children use it use the system about six
hours or so and six children who are
control and we actually saw a
significant increase in their short-term
memory the ability to sign to express
themselves in sign the ability to
understand sign so we're very very
excited about that this the signed
verification program this is this
copycat program is the first example I
know of a sign recognition system
actually being used for real application
in the real world now I said now this
system already have works for children
ages six to eleven that's generally
after the critical learning period of
language which is zero to three we also
want to try to actually get a system for
children who are 0 to 0 to 3 as well so
what I'm going to do is show you
something called smart sign alert okay
so what we have is a system where the
parent throughout the day gets sign
language alerts so let's like an SMS but
each SMS is a little video that shows
them a new sign like this then gives
them a little quiz which one is it and
if they don't they don't know we'll tell
them which one was that was cat so
throughout the day we try to oftenly
space the lessons so that the parents
learn the most in the least amount of
time and it turn out turns out this is
really fun we did this with Spanish for
me and I had a lot of fun learning it
we're actually using the first 80 words
you use
when talking with an infant so what is
exciting about this we compared learning
sign language on cell phone to learning
it using a desk the same desktop
application this thing was forty percent
more efficient on cell phone than
desktop I was really quite surprised
about that now the other thing we have
is a system where i can actually i don't
know if amy i can see this but what how
did you is actually pop
is that pulled off work I said come on
video I need song
boy
oh I do stay where parents can say
things like go to bed and up comes a
video go to bed and so the children
actually learn sign in context now that
we're trying to get that out as a google
app on the App Store Android app store
before beginning the summer but it quite
we didn't quite get there we're still
working on unfortunately the student who
is working on is currently now at IBM so
primal get on there until fall okay now
I know I know I'm out of time last time
I told you guys a little bit about
trying to recognize silent night sign
language directly off the motor cortex
so let me give you an update on that for
those you had didn't see that talk if
you have somebody who's locked in
somebody's paralyzed has ALS or Lou
Gehrig's disease depending on how you
know the disease they cannot move a
muscle they have no way to communicate
can we actually have people communicate
through brain waves alone the answer is
yes we're doing forced-choice pairs
things like hot versus cold or chair
versus bed and we're actually getting
relatively good accuracies on this so
for these first choice pairs getting you
know nine percent accuracy for real sign
even works if you're just imagining
signing right if you sit there in this
fMRI tip and think about doing the sign
you can still get a decent results and
currently we're starting to work on
entire phrases instead of are you hot or
cold you know hot or cold are you in
pain are you okay do you want to go to
your chair to your bed now we're trying
to get full phrases like the beds hot
I'm in pain so that currently involves a
fMRI a big machine what I've got with me
today is
fmri sensor your sensor so this is
basically a set of fancy I our
transmitters receivers that you can put
on a little portion of your head you
tell you if that little portion of your
head is activate is active and you can
actually use this on a mobile device so
while i'm currently doing is I'm wiring
this up to my wearable computer to start
seeing if I can think to my computer in
sign language I get to do something for
me now grant this is only one bit this
is actually I called my kill bill
interface because i'm putting this right
right about here which is the wiggle my
big toe so i'm trying to make it so that
you know if I'm trying to have you know
ok or cancel i wiggle my big toe and it
triggers this we'll see how it works ok
i am running over there's lots I've a
lot of the demos up here if you want to
include a system for the for deaf folks
be able to tty into directly the 911
center a system for playing dance dance
revolution on your cell phone using
sensors on your feet that's a lot of fun
there's a system for people to learn
Braille who have low vision that's
already on the iphone that's by Brian
Keyes who I can show afterwards i also
have lots of other stuff which
apparently are i can't i can only go
forward I can't go back in this
presentation the this loss of other
crazy stuff we're working on this is a
spin us our survey so if you want to
talk to me about talking with dolphins
or trying to make better mini QWERTY
keyboards and his other type of stuff
please come up and talk to me afterwards
and the acknowledged slide just got
killed off but you solved their earlier
I have a lot of funders Neider DARPA NSF
a tree thank you to all of them and
think too of course this is mostly grad
students work not mine so thanks to all
those who are on the screen to the
second ago and I'll take any questions
thank you very much
I think we're recording so do you think
Morse code is going to make a comeback
nah that's too hard I don't even know
Morse code well enough I can do SOS so
you know that that ring tons of guys dt
DD DD T deep drives me nuts because it's
mostly SOS I don't know why they chose
that is really frustrating oh you talked
a little bit you talked a little group
out what is socially appropriate and not
socially appropriate and of course you
personally have been testing out the
stuff for a long time yep r there
changes in that or yeah from the high
level thing to camera phones holy cow
when I first started this stuff the idea
of actually having a bond body camera
people really really hated that and now
all of you have on body cameras people
used to you know the idea of actually
recording audio you know I don't record
audio I could but more importantly all
of you could record audio with your cell
phones easily 24 hours a day even worse
than that somebody could hack your phone
relatively easily and turn on your
microphone without you knowing it you
even make a phaser a microphone out of
all your cell phones so every one of you
sitting here is bugged you know the
whole cell phone with what revolution
back we were back when I started stuff
ones with this big right they're huge
they weighed pounds so now that
everybody has you know the supercomputer
in the pocket what I do is it looks tame
I'm just trying control your my brain so
you have a little display in your left
eye what is it for what you doing with
it normally
it is for as he loses it this so these
little notes that I would normally have
on my screen as I talk but today because
I'm having equipment failures I actually
had to pull my wearable and actually
used it for the videos so for example
I've got to mention that copycat is at
the CVP our workshop this friday on
human communicative behavior analysis
and if you ask real nice as a whore's
the Farella who's there we'll give you a
live demo of it so normally I have notes
on my talk as I'm as I'm giving it why
do I have it on right now is a good
question because I forgot to take it off
is the honest truth okay it's not hooked
up right now so why don't have it on I
just used to it
so I happen to notice that you're
wearing at wiggler yeah and I know that
in the past you found that that was the
best wearable input device is that still
true or have new things come up and
depends on what you're doing it's still
the best that I know of because you can
get quite fast at first of 130 I
sustained 70 where's permanent on a mini
qwerty keyboard the blackberry style
keyboard you can do believe or not 60
sustained so you do equivalent the only
problem is you need visual attention so
you can't actually sit here like what
I'm professor I teach all the time
there's no way in my class typing the
notes in their blackberry why because
they have to do this all the time they
can't look at the blackboard with the
Twitter it's all touch typing and so you
can look up just fine if you try to if
you try to touch typing on blackberry
your error rate goes up to fifteen
percent per character which is horrible
you're typing rate goes down to 45 words
per min instead of 60 so the
blackberries if you can give your full
attention to them are just as fast as a
Twitter but as soon as you try to
actually do anything where you're on the
go when you're actually moving the
blackberry rates go to hell but if
you're interested we actually have a
thing called on Mac whiteout which looks
at the facts you have fat thumbs you hit
mobile keys at the same time for those
of you who are engineers you know about
key debouncing think about key to
bouncing across multiple keys and once
you have that idea can actually reduce
the amount of errors people make on a
qwerty keyboard by about twenty-five
percent of all errors you can reduce
about fifty percent of just these off by
one errors pry a whole lot more but so
we can we can improve many party
keyboards so they're better but I'll
ever make that's wither yet there's
nothing else out there that has come
close the only thing I know that might
get there is something called
shapewriter on new Samsung phones what
you actually do gesture things for
entire words though shubin's I use at
IBM never did a real true longitudinal
study lot so we
don't know where it matches max max is
out so the Twitter hit the tech gear has
bought out Twitter so you go to tech
gear calm TK ger I sent you TV a special
special invite to talk to Scott
Gilliland who's making the new Twitter i
happen to know they got their first run
of 10 samples from the factory yesterday
and matter of fact I've been using one
for the past week except for the fact
that the Grail in less than sign are
where the Z and T r &amp;amp; g sometimes
becomes enter this one is just USB but I
haven't know Scott has made it so it can
become Bluetooth pretty easily so if you
want to get on the bandwagon and suggest
improvements it's your already have one
in your inbox as a matter of fact you
just not paying attention to my emails i
explicitly invited you didn't work on
this yeah so yeah so Scott Gillan is the
one you want to talk to he's the one
working on right now and you know
there's laws we have a lot of games and
stuff to help people get speed on the
Twitter thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>