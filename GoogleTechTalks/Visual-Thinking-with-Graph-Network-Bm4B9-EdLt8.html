<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Visual Thinking with Graph Network | Coder Coacher - Coaching Coders</title><meta content="Visual Thinking with Graph Network - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Visual Thinking with Graph Network</b></h2><h5 class="post__date">2008-03-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Bm4B9-EdLt8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">happy 5th at jumbo is visiting is a
professor at you add and I guess a lot
of people here actually knows him well
and one thing I want to mention is about
imam ali's contributors and spin ability
one thing i want to mention his last
year as if you his paper on not nice to
come one the one we can surprise for a
contribution to stay because of time
okay Thank you Thank You Thomas it's
great to be here I guess know many of
you here so and actually I should thank
Thomas also Thomas it was a wonderful
office mates for four years at Berkeley
and contribute to many of their work
that we've done together and it's great
to see him here also so today I'm going
to talk about someone work that we are
doing at Penn the title of the talk is
simplified visual recognition which
contours so i'll make that topic a
little bit clearer so usually when i
gave a talk I want to give sort of have
understanding who my audience are even
though I know quite a bit few you I want
to see what you see the images so here's
a illusion how many people actually seen
this illusion okay whew okay so what do
you see immediately for people haven't
seen what do you see immediately there's
a young girl facing that way okay how
many people actually seen a young girl
here Wow okay and there's actually old
lady here how many people can see old
lady ah i see it before okay so yeah i
see so if you just kind of covered a
little dimple here you can see that's
the nose little lady that's the mouse
that's a chain and that's her i can
people see it so usually I go go around
ask that question so see I me want to
give this talk everybody saw the lady
nobody's in hell so elsewhere as I
Christopher yeah i was in princeton
maryland everybody seen a young lady so
it's bad but see I'm you people really
just see the lady yeah so now I know who
you are I can't start so so this is
actually bit of a motivation that the
way this is an experiment that we
actually we're doing at
Philadelphia this is a project on people
detection in the dynamic street scenes
so the problem is that you have a card
that you're driving down the street so
this is Street in Philadelphia Fernando
knows well and imagine that we have some
impoverished later data so this actually
comes from stereo it's pretty bad but
they gave you quite a bit information so
those are you can see these are traffic
lights and this is individual that's
moving down the street a couple kids
coming into the field of view there play
on the street and you see the stereo is
not great so sometimes we lose the
target sometimes we get it the goal is
eventually to be able to detect people
as we move cross the scene and only that
segment and out and the reason going to
second analysis is also we want to get a
precise pose for those individuals to
understand what they're doing okay so
this is a challenging problem but we are
trying to using motion and let our data
to help us to solve this problem so just
to give you a little background on this
project this is our little band so I'm
advertising again this is our band I
purchasing the urban challenge that we
finished number 4 so it's not in use but
I just very proud that we finished
fourth and with almost no funding so we
add a little bit of camera to us we add
to steroid camera on the board we have a
ladybug which is from porno rate it does
have many laser scanner on the car but
the laser scanner is pointing to the
ground is not looking at any distance
away so mostly looking for obstacle what
we're looking for our people kind of far
away a 40 or 50 meters away so we first
took this car out and it turns out
Philadelphia is cold and the camera
freezed up and all the synchronization
circuit fails so we spend the whole
afternoon and all the data came out bad
so we had to redesign the circuit make
sure its temperature proof and we need
to plan the collection make sure the
temperature is above certain threshold
quite a bit we have so calibrate the
synchronization down to very precise
measurements ok so we took this a little
band and we drew around the center city
in Philadelphia one loop around the
University while loop around center city
the temperature as you see is about 46
degrees so that was good
we took about one hours of videos total
six miles the resolution is indicated
above so this is the video that we took
a part of the video we shot again this
is it for people know Philadelphia this
is rittenhouse square so i had two
stereo cameras and they're synchronized
exactly on top of it actually has a
ladybug so as you can see 360 degrees
but we're primarily using the steroid
images are to detect people on the
street so actually one thing we found a
very strange actually or a little bit
surprising is actually nobody we're
thinking that we have this funky car
drive in the city that people know
scaring us are or surround us I mean
Philadelphia no one cares so we're
driving around so here's a bit of
problem of a dynamic wrench the camera
which has a fixed shutter speed so we
had to manually adjust the dynamic range
as we drive so it's a busy street a lot
of people there often including each
other and there's lots of moving up just
I think so the goal is trying to detect
those people's on the street so we have
a natural advantage because we're the
urban environment so it's easy to take
the status see so no more cheers oh just
so you can see actually does a lot of
people standing on the bus stops they're
just reading the books and don't even
pay attention to us at all so it's great
so we actually feel so this is the
sequence we saw earlier okay so so when
we got this data back we immediately run
a story on that system and you can see
still is not great actually somewhat
reasonable so blue means kind of clothes
and red means far it's not great so we
decided okay we push ahead anyway
because we have a party to do we so we
actually ran enjoy Eva where's John IV
said but Debra hysterical we calibrate
the camera and he has a triangle ation
software the runner triangulation
software and looks pretty good but kind
of crazy looking yeah not his faults are
a steroid disparity fault so we decided
to push ahead anyway so and what we
decide to do is actually do some very
simple grouping of the 3d point clouds
this is actually just take the 3d point
cloud this is disparity map and we did a
very simple
sort of adapted the region growing too
abstract 3,000 blobs follows three
thousand pubs actually can delete quite
a few block because they're the wrong
size so for example facades too big so
actually we have been to clean up the
data quite a bit so this is the data
before in 3d and this is data after that
okay so this is just simply doing
connected components and threshold based
on size because you know the people are
certain size they are not in the air so
you can cut off figure our way down on
the ground so we are using as a sort of
cheap imitation of later it's also
important because we need to detect
people kind of far so this is actually
pretty close as the meters it's about 30
meters this is the 35 meters okay but
the camera can see pretty far so this is
again just an illustration of what we
got so again this is just a image
superimposed on the bounding box the
bounding box are those objects if it's
in 3d those criteria we set up so there
are good detection rate but lots of
false positives okay and we are now
using the motion so this we have
intermediate sort of occlusions and we
lose the target quite as well so this is
individual that walking across the
street let me just play the video again
okay there was this is a longer video at
the beginning of your fairy the matlab
has trouble so so after they could
correct it so this is again a shot on
the on the right hand side is the stereo
plus the cleanup version of stereo and
the cleanup what I mean is basically
attracting human like blobs in a stereo
cassette and this is superimposed on the
irregular image and this is disparity
map so you can see the individual
popping out on quite well once a while
but we lose him ah sometimes so this is
a pole I think I see if it's a pro come
in so that's individual come in okay so
so general we were doing alright I mean
in terms of using the stereo and images
together to get a very good hypothesis
of where potential human targets are but
as you can see there's a lot of false
positives are in the set and idea is
trying to using the image analysis a
vision to remove those false positives
so those are the list of
sort of true positive on top a false
positive below okay you can see there's
a lot of a post variation we didn't
quite expect it turns a lot of people
sitting on the street we didn't expect
that this you know was not our
expectation of a production but there
many of those and people that do get
included this is okay cut off because
the camera is tilted too high those are
the fast passes that falls into the
category of people looking like 3d point
clouds meaning that skinny can I
longueuil the vertical things so those
are the things that we need to get rid
of unfortunately image recognition
mostly softwares have failure modes on
exactly the same type because the
exactly skinny long cylindrical looking
objets so the rest of my talk is really
motivated by those examples we want to
use funnel vision software that can
delete those false positives so I won't
go to too much about possession just
want to show you that this is the
pipeline that we're going to work on
essentially we could have some training
examples here we only use about 20
pedestrian training example we have
examples and we have solar wet with
those examples and we want to detect
them and want to second in them so so
people ask me why only 20 pedestrians
most people when you look at the
training set up talking about thousands
so if you look at the the typical
training set for pedestrian detection is
about 2,000 3,000 training said about
1,000 test set so what is happening
actually if you look at the training set
is trying to learn I should a negative
example which tell you that's a building
that's a trash can that's not a people
where she can show that with only 20
people we can cover the most people
pretty well so in a sense the body of
compositional you could have somebody's
head somebody's lower body right might
be a perfect match but when you you take
somebody's body parts they actually can
move into any arbitrary purses so the 20
actually is more than sufficient to
cover pretty much any post variation you
have all right so so I stopped talking
about the disorder research behind how
do we do this and return to the pupa
detection later if you have questions
just feel free to stop me okay so the
first part of a talk i'm going to talk
about contour grouping so so why can't a
grouping so the contour grouping is
motivated partially
by the possession people are sort of
defined really by the shape it's not
really by deformed by the color shirt or
you know the texture of my clothes
there's no texture of my clothes is
really the shape so for example look at
a horse a horse is another animal which
are like human in the sense that they
are defined mostly by the shape and not
by the texture so on the left you see
the image on the right you see in the
edge map of the image right so you can
see the edge map actually looks pretty
bad but i want to point out actually
those in those edge maps there are good
stuff only thing you need to do is
delete the wrong stuff the image will
become much more or appealing okay so on
the right here is you simply the same
edge map on the left with junk removed
okay you can see you can see a very
clear horse with a leg the hairs and the
body parts okay so the information is in
the edge so people shouldn't forget
about edges and the information is
indeed there okay all you need to do is
somehow able to extract it out the
clutter and pop out the foreground ok
it's there so and people who are not
convinced I will call the famous
psychologist cough gases long contours
are just nice to look at it ok no one
left ok alright so a lot of my work is
inspired by a lot less of a good people
have worked on this and typically want
to give credit to the to author on top
omen and Joshua would look at the
ceiling structures and the Mohammed will
in a number we'll look at the same
attention of a contour many of it ideas
are shaking from those two papers but
those paper below also and talk about
counter groupie so what may come to our
grouping very difficult so here again
this image and our right is the edge map
right the snake is in the in the edge
map all we need to just clean it up
right it's not an easy problem because a
lot of clutter the clutter is number one
problem but that's not the biggest
problem the biggest problem is when you
have a ceiling contours even with the
ceiling contours you tend to have a gap
ok gap is due to you know in this case
the hair on the horse but could do to
your lumination or whatever condition
you have so you may have very ceiling
contours it might have a gap right so
you know making sure the connected
components make it very difficult to run
so gap plus clutter it makes things
difficult because whisk gap you have to
jump ok to connect to the other part of
the
contour but when you jump very likely
you will jump into the clutter instead
of the right contour so how do you know
you jump the right place that make the
problem very difficult since before you
want to say how that's a difficult
problem I want to show that this
actually can be done this is the output
of our systems where again you see the
black and white contours and the bright
contours are the contour we are
extracted as the salient contours so
those who would be the basis that we're
going to use for object recognition so
how we do this so the way we're going to
do this is gain formula the counter
grouping as a graph petitioning problem
with a slight twist so here we have an
edge in the image each pixel is an edge
or not edge if it's an edge you create a
note instead cream windows I'm going to
create two notes okay when each notes
actually have a direction attached to it
so imagine if your edges are sort of a
slider it's not a fixed note it's a
slider so meaning that once you get onto
that note you can slide left or slide
right okay so each you do the edge
detection you create edge pixels for
each expec so you duplicate it two to
two sliders ok so then what you want to
do is create a connection between two
sliders or two edge pixels to edge pixel
which are over linear meaning they're
roughly in the same direction and there
are sort of curve in the same way are
slowly connected and to pick so kind of
pointing edge each other two edges are
pointing each at each other they can
Sligh on top of each other even at a
right configuration they do not connect
ok this is a very important concept each
edge has a direction and only when you
go from one direction to another
consistent in a forward direction so one
of the game they talk actually enters
this from a point out this is like
Egyptian walk it walk like Egyptian so I
think about you Justin walks so you had
to two edges postpone the right
direction then you connect if two edges
kind of run directions even a right
configuration you've you do not let
things connect yeah you have and this is
edge elements at shoppers they are and
they will be known these directed nodes
in the graph right there will be then
director 82 in there at the graph edges
yes and those are other yes the graph
edges that they notify them arts college
which was this are yeah they look like a
CSO so it district make sure that they
understand right so unfortunately image
got edges and graph got edges those are
two different type of edges so we can
think of it as edge notes are just so I
called edge note because there are
pixels which are image edges with
different directions and called graph
arcs maybe that connects them so the
graph arcs is defined by the
connectivity of the edge direction okay
so two edges in the same direction so
our edge node in the same direction can
connect otherwise not okay so with this
small caveat each node in the edge map
can also return flip around directions
when as well it's a very small weights
okay so this is small yeah
so we have a very small weight basically
returning okay so it most the time I go
straight but once I will return yeah
okay come up to this point later so when
we have this graph arcs that we can
normalize it into a random walk
probability ok so you for each pixel I
we look at all the edge notes where you
can reach with take the sum normalize it
so you have a random distribution to run
a walk distribution so basically you go
from each pixel you have a probability
going from this arc sort of image edge
sliding two different pieces of the
image contours okay you can take of this
is the probability is that start with I
jump to J in one step okay where the
probability happens you want to make
sure you able to jump gaps so you're not
connect only the nearby ones but some
pixels within some radius way because
there are holes in the contours ok so
the run the normalization has an extra
degree of effect which is that when you
get to the end of the contour you have
nowhere to go so even have a very small
way to return to yourself after
normalization this return way become
normalized one so become a very large
probability to return so the end of the
contour you have nowhere to go you have
forced basically with 101 hundred
percent probability to return on the
same path so now essentially in the
image if I have open contour open comp
Romania straight line this become a
cycle in the graph and if you have a
closed contour it traditionally closed
contour you still have the closed closed
contour negraph accepting the to copy
one clockwise one counterclockwise okay
so any case we unifying all the contour
into a cycle okay to find contours open
or closed you just look four cycles in a
graph okay after normalization every
contour becomes a cycle because open
count wars they had to cycle the end
because probability one had to return
somewhere okay otherwise yeah if you
have such a high probability of
returning back in the second case we
have the clearest contour will they not
be a tendency to actually
that closed loop and this if I put a
medal yeah so that's why you had very
carefully choose the way to be self
cycle impact weights small but in the
middle of the year you have largely it's
going forward right so the rates of
return is relative small so it's
normalized there's only a 10 point we
have nowhere to go that small ways
become amplified balance so you have
this small return wait then you also
have ways to transition into clutter
good and so how does that pay no
question yeah coming up here so now the
question is how do you know how do you
find the salience graph cycle right so
now you have a cycle 24 look for in a
clutter as plendil pointed out you can
cycle too okay you can go to a contour
jump to a clod Rankine cycle can always
a cycle the question how do you find a
good cycle right so people study
computer science where they are find the
shortest paths I shorter cycle there's
the longest side code there's a shortest
average cycle you can come up many
variations the longest and shortest the
problem is we don't know the lens of the
cycle we don't know how long the contour
should be right we want a good one we
just don't want the shortest one or that
longest one or two average shortest our
average longest so we need to load the
lens of the contour that's the biggest
thing we need to find so here's the
concept going to introduce its called a
persistent seed of random walk so we
will look for is the probability of a
psycho starways I and go through some
other piece and return to himself and
some time T later okay so any there's
always a cycle that come from I go
through this graph sneak around
eventually come back to yourself after
time T okay so we want to look at this
property so this is our bro servation
the observation is that if you have a
very scoot cycle ox alien contour then
the probability to return to yourself at
the time T can be seen as this plot
wearing an x-axis is the time to return
in the y axis is the probability of that
returning happening you can see with
time very small you're not going to
return because the only way to returns
to cycle through some other guy you can
return because the graph is directed you
can only go forward totally we return
return is
going forward and eventually cycle back
so you cannot return immediately because
you cannot and then at some time T which
actually corresponds roughly the length
of the cycle this lot of random
probability returning and then you're
going to diminish at the 2t going to
return again right because the same
cycle is going to happen again at 3t so
you can see this very nice rhythm attic
posts in the probability of a random
cycle repeating to itself if you're in a
very salient cycle look at the
background clutter in the background
clutter is basically a Brownian motion
Brownian motion just going to randomly
walk around eventually we'll come back
to itself but you can see the
probability return to yourself is flat
because there's no particular cycle that
had to return to yourself with that
period because you can return to
yourself with arbitrary path so there's
you can think of the path length to
return to this office uniform okay so
that's the first signal that we're
looking for that if it's good cycle then
he saw has something called the
persistency meaning that it repeats once
you get on it okay so Fernando ask a
question about clutter so those are the
clutter so if you jump into clutter once
why you return may be too early or too
late but by and large you're going to
return that period so how to measure
this persistency or peak Gnaeus of sort
of probability so one we just simply
measure the areas under this probability
around T 2 T 3 T divided by total
probability to return okay so it's just
the probability of a random walk return
to itself k times T divided by total
time to return so visually all your new
remember is just this wise ohms divided
by total area and it is on the peak okay
so we want to speak to be if this is
picky then we want this ratio to be
large to close one if it's a Brownian
motion this is going to close to zero
okay so the question now is how to
compute it right you can write a
computer program to simulate the rather
random walks looking for the chance of
returning you can do that it's going to
take a lot of time right but that's one
way to do it so fortunately we proved
the theorem which is shows that the
pickiness orbit time to return ratio is
actually return to this a relate to this
nasty equation okay this is Nev
a good time to show a question but this
is the equation had to show was so this
equation shows essentially you can
predict this are by this ratio where the
region really dominated by the lambda
where lambda is read the eigen value of
this complex actually lenda are the
complex eigenvalues of this random walk
that we generated ok it's a director and
a walk so therefore has a complex
eigenvalues and eigenvectors and the the
time to return is only nonzero for a
none of no real or complex eigenvalues
the eigenvalues real is diminish 20 you
can show that ok so another question do
we have eigen values which are complex
so in fact so those are the eigenvalues
the random walk matrix looking for
eigenvalues and in fact this is a plot
of eigen values in the horizontals real
axis in the verticals the complex axis
so it starts appalling one eigenvalue ok
so you can see this is a complex one
because dennis has both imaginary sort
and the real components so there many of
them actually so many of us it's in the
horizontal axis which are just real
eigen vectors those are the one that
we're using before for region grouping
but it turns out there's lots of other
ones we're not looking what you have to
do with counter grouping so now we know
that the eigenvalues are useful the
question is what does eigenvectors are
so that's a natural question to ask so
so here's a contour so let me stop the
animation or maybe just play the
animation so this is a a contour that we
selected the image ok well we did is
then plot out the eigenvector associate
for each eigenvector has essentially the
real value and the imaginary value right
so each eigenvector is going to have a
value X and X has a real components and
imaginary components if you applaud the
real imaginary components it looks like
a two-dimensional plot so what we did
here is then move each points along this
contour and show what happened to to
that point in this imaginary space as we
move along the contours ok so what do we
see what do people see
so what I'm doing is moving this pixel
up and down this contours every time
moving a plotted points in the in
complex pace with which is the complex
eigen vector for that pixel okay you can
see as we move up and down the psychos
essentially the cycling run origin is
orbiting okay let's look a planet going
around so in other words that for every
position in the image XY is translated
to the complex space imaginary space
where a psycho is actually a real psycho
in the sense of a graph okay so that's
the key inside so that's our conjecture
so now the question is can we figure out
what the ideal cost is so the ideal
causeway lincoln gesture is that what
you want to do is not really you know
plot out such a nasty-looking cycles
what you want is really nice looking
cycles but this is ideal cause if I
noticed is that as we move up and down a
clean cycles each point should be put
into a complex space such that your
orbit around the origin okay so why is
that the reason is that you can think of
on the image there's action on every
pixel the actual every pixel is
translation we can only translate a
pixel allowing the contour because
render walk carry the pics or alarm okay
so in the image this action p that act
on the pixel x which is the position XY
position in the complex eigen right just
because the only thing i can do is
multiply lambda x is the position on
this complex space and the only thing i
can do is action on this complex value
and the complex multiplication by lambda
it means what rotation we can only
rotate so basically we want a couple of
these two step together right so every
time we move in the image I want to
rotate around the origin that's what I
can venture is doing no no I can't play
it again okay so as we move on the
contours I can't move orbiting around so
operating around is essentially an
action of x lambda every time I move
multiplier lambda moves okay so now you
find the equivalence relationship
between the two so I have a question how
do you distinguish other with real count
war was a good count towards a backlog
hunt war we can gesture that
how to give you a very large orbits in
an image in the bedding space and the
bag clutter has a very small orbit or a
bit close to zero the reason is we can
gesture that for the clutter on each
step you have multiple neighboring you
to go to ok you can think of it has a
very large set of things you need to get
to and you may have very largest editing
go to the radius shrinks okay so some
point actually somebody point out this
is a capital law of gravitation the
faster you move you had to shrink the
orbit so you can think of in the sealian
count where there's only one or two guys
need to go to and there for you to only
rotate a very small angle so when you
rotate very small angle you can make the
orbit very big so our conjecture is our
time Delta Theta YouTube constant okay
so meaning that you only have very when
you have a very clear idea we need to go
to the orbit become big when you get
confusing you to go to lolla orbits so
basically you want to be sure that there
are times this delta theta is constant
ok so this case you have a small area I
mean this is the same area as this area
ok so if you a lot guys need to rotate
to then the circle shrinks so now
essentially we can write on the cost
function what make a good cycle and
involved invidious theta and delta theta
we can do all the math which would
basically proved that to our self again
the way to optimize is quite cheering is
look at the left eigenvector right again
which of the solution so there's another
theorem can prove or can skip that again
so but we showed basically eigenvector
yes yet again a way to optimizing this
cost function of seeking a largest cover
or largest cycle in the complex eigen
vector space so now we we basically have
the following solution we we take the
image we build around the work matrix on
then we compute the complex eigen
vectors look at the idea metrics
self-fund the biggest cover cycle in
this graph and this is easy because we
do shortest paths essentially fund this
maximum cover path which is dynamic
programming with exactly the path lines
for 360 degrees ok in the embedding
space and that we tracked out the
control for us so let me show you some
results those are the results obtained
the
is the image with the sale encounter
suit poem post and this is the image
with the edge map we extracted and the
Seine encountering way superimposed on
this so for you people are people are
familiar this is actually from the
berkeley segmentation data set and this
is a snake you can see that we actually
can extract out quite clean in the
contours and this is a person standing
to building like things in a building or
suppress considered more like 2d like
rather than 1d like structures question
this is even the presence of gaps
guessing that be breaks in the embedding
space also so so yeah it gets miss a
little bit beginning so any gaps we
render walk is able to jump some gaps so
is able to do it so the graph has a
connection radius of something let's say
10 pixels so is able to jump ahead for
10 pixels so the run world will persist
after some kind yeah good question so
this is a more results on set of images
again the 2d type of like color tend to
be ignored and the line count worse it
turns out the human body are indeed have
a lot of two line structures you can see
she was wearing a dress but drugs to
highly textured but the background I
made the boundary between her dress to
the background has a very salient
contour okay so we're not running in
history on it right but still able to
describe the various alien contours so
this is the goal we want to do extra
race lon ceiling contours from which
then we can use for recognition or
comparing shapes yeah we pick a node
200-300 forgot a second number we didn't
really look into very carefully because
actually we're wasting all our energy in
the sense that those eigen vector come
in conjugate pairs the every item is
duplicate twice I mean you should go to
hack into the cold I you metros only
looking for one set of solutions but we
haven't get to fix that yet
we hear the same cost function so
there's a complex numbers so let's give
you the same cost function to it okay so
this is some horse images again those
are the images with back on clutters and
make sure that we able to pull out
contours we call this thing called
untangling cycles it's like pulling
spaghetti's out of the sort of very
Rendon mess so has a very clean contour
working no matter how zigzag around
which I be to pull it out okay so nice
able to detangle it I mean there's
nothing that kind of really hold it in
as a 2d pattern you want to distress
holding so if because you can always you
know you can measure that I should we
talk about this so you need to measure
the performance of the system so
performance system is we measure against
human so for example at Berkeley this is
a Berkeley segmentation data set you
have images sorry about images you have
human label data so human label edges
all the human label superimposed okay
there's some people are label more some
people may dabble less so the ground
truth is the superset meaning if
somebody labeled as edge that's an edge
okay so that's a human superhuman label
find that you can look at the hits mean
to me what you human labor what you also
detect that's basically tell you how
much recall you have you also have mrs.
which is our the blue lines that were
human label you didn't label okay and
there's a false positive that you label
the few min didn't label ok the nobody
labeled okay so you can see well some of
the fossils are reasonable but nobody
labeled so we had to pay a penalty on
this so we can look at the precision
precision essentially hit divide the
false positive plus hits recall is
basically how many real edges we need to
detect how many would do detect okay so
we look at the precision recall
performance and this is the baseline
this days is called a probability
boundary detectors pump Berkeley PB and
this is two more global methods one is
using the CRF fernando this is work done
by cell phone ran at berkeley the other
one is by pedro fun chica university
hago your hands of a method called
midland cover in blue an hour you can
see is on top
quite a bit so we do do better in the
recall reg between 5th between basically
anything above sixty percent we do worse
essentially I should we don't do
anything after sixty percent week so we
cannot do small contours the contour
have to be grouped together so belong at
that point we can group anything so we
actually don't return anything so we
cannot detect the sort of small
fragments so again you can ask where
those miss recalls miss the missus are
blue lines okay they tend to be in this
case clue to buy foreign objects so
there's a lot of high-level reasoning
goes in ah somehow we missed it ok any
questions yeah but I'm we're gonna
treasure in somewhere that controls how
small is this one
there's no parameter for small too small
but in a random walk you cannot find the
salience cycles once become too small so
because they can sneak around anywhere
so because the gap because yeah that
examples include unit there's a really
good contour they're just like partially
occluded right there i do so friend so
now we can't you have desertion
directionality right i guess you would
have something which is kind of
preferential direction so if I i can
jump if i can go in I can jump a lot
more ongoing as you wear it straight
line right right and if I take a sharp
or so if it is easily with clutter you
know the things you could connect to our
in different are pointing in different
directions and therefore you you not
allow allow yourself to jump much walk
where isn't something that's straight
that way you can jump exactly the same
direction and still hit right another
another
edge element right you say ok this is
making us of that right so this is a
vision called the modal a modal solution
this is actually what Thomas have been
working very hard for his thesis so it's
true so if we know the cooter then you
should definitely connect the background
together because they can explain away
why they're discontinues you need a way
of explaining away so you offer the
connection otherwise if you just look at
something that kind of have a big gap
you jump straight into an angle it
actually costs a lot of clutter comes
into the question so you want to make
sure that you have a good explanation
before you make this large jump but this
is actually something we acted working
on we have actually a very good method
to do this nokia questioned in relation
to your comments couldn't you use a
direction of the gradient when you add
primers to where you should link instead
of linking ya know instead of sub
audience on the edges independently from
the image ralph could you you say the
fact that you know that the gradient you
know goes from bright to dark so I
selection and is that as a prior yeah
not connect edges that should not be
connected specially when they're
disconnected right wrap the good
comments in the comment is they can use
polarity of that just start to white
white to dark transition additional oh
so we try to do that we try to many
different version actually this
precision recall is not the first one so
some of it actually is below I'm not
sure is that the top is one this
different parameter you can trick we
haven't really completely looking into
that yet yeah let's go kamen any other
questions so this is my essentially the
first part of my talk a blast through
pretty quickly the ideas essentially we
want to take an image extract those long
contours out remove textures remove sort
of small pieces now those are the sort
of a basis for my recognition or
detection so i'm going to talk about
that in the next step so there's a
couple more images we had to okay so the
second part i want to motivate the sex
helpful off where as well though so
anybody has the kids i see in this book
so where's the well though let people
see it right so you know so this is
similar to my street scene example
a little more cluttered of course you
can find it and the problem finding
words well though is the you know
probably not going to recognize me by
just purely or by color and texture so
so shape is required so again I want to
come back to this point of this illusion
and actually this illusion when I showed
again to show that the recognition is a
whole rather than son of parts so in
this case when you see this woman right
it really need to see the entire context
before you can make any decision what
this piece are for example this lie it
has no meaning it could be a necklace it
should be a line until you see the eyes
and knows the meaning of this line
depends on all the contacts that you
can't basically my argument as you
cannot see the little parts and choose
the whole so that's why things are
difficult another bit of controversial
so this is the illustration suppose you
look at this image and suppose you're
looking for swamp okay so you look at
this piece and say hey that looks like
maybe part of swarm maybe that little
corner here in the swamp right two
people agree okay it's a reasonable
guess right so that you look around okay
that's good so we look around a looking
for it really is a Swami not ready open
another window looks like yeah it looks
like good because it look like a neck of
the swamp right locally I can't tell be
but if am be together I can tell that's
sort of a configuration like this right
again bigger the contacts the better
okay okay that's so far good so let's
open up a window against like in a sort
of a guessing game you open up another
window look at this boxy and I say wow
this is really good right at three
pieces ABC it really all look like ABC
here so that's definitely a swamp right
so how many people think of the swamp
now hi everybody yeah so it turns that's
not a swamp because he could you need a
little more you find out that this image
if you can do naturally a better contour
or similarity it has some extra piece
sticking out okay so now what what do we
see it's definitely not a swamp right
there's a piece missing so the big
context so with this I want to show that
basically context is good right because
they help it to recognize but the
content is also bad because if you take
things out of context
that you can make a lot of assessment
making a lot of statements with this
object is in this case the whole
contacts are objects ABCD together if
you just look ABC you think of the swamp
but if that basically the false positive
is comes arises from the fact that
you're taking things out of context the
ABCD is a naturally a bundle of contour
that grouped together or sort of thing
had integrity what I call there's a
whole piece together you cannot take a
half of it and make something out of it
so what is this this is actually a cup
so what we saw was the I think that was
the swamp body and the neck ok so we
know this very well because I've been
working on a SWAT detection we found all
kinds of false positives who are looking
to why because as always some peace look
like a swamp so swamps are everywhere so
if you don't look at things out of
context just zoom in like just see this
is this one this one you find lots of
swamp ok you had to look outside ok just
look at the context to figure out so
this is our motivation this is or more
latest work it's not even published but
I want to talk about it at least so the
problem is that we have a very simple
example of objects this case is swamp
but this one is actually just a line
drawing ok I want to show that we can do
this we don't need any more training
example just one training example is
enough right frankly you know I have a
two kids so I just show them once what
does car they know it's a cars and the
more training examples not needed so see
here is in a problem so we have a
training set which consists only one
image for many many training test set
most positive or negative classes what
you want to do is detect this set of
contour in the image in the clutter
meaning that you ring so the clutter
consists of all kinds of back on
contours red and blue or light detectors
blues are actually for one contours okay
simple enough we also want to be able to
provide correspondence between the
contours on the model and the contours
in image ok so those are the
correspondence label the x similar
colors are the correspondence between
them so we want to achieve two things we
want to be able to take this contour
grouping results that we have regrouped
into an object we should look like him
and provide dance correspondence inside
the body ok so this is going to do it
for SWA medulla people
so this is just the starting of work so
the problem is basically to find the
right context okay so we know that right
contacts helps okay the wrong context
hurts because it made you have false
positive so what is the right contacts
so here's actually wrong contact so
you're looking for swamp ok so we detect
here is a swamp why because it's a line
lend lining it straight up that's
another line that line up there's a line
line up there's a line up so majority
line line up ok that's a swamp if you
think that's a swamp you can holla swamp
because any l-shape things is a swamp by
this measure ok so why is it wrong
because we are taking this contour out
of the context we take a partial
fragments of this long contour and
declare that's a neck right but
basically take somebody's shape and just
chop up in the middle and make made
something out of it if you allow the
system to that you basically found many
many swamps ok so here's another bizarre
swamp it's not a real swamp in a sense
when you force a model to match the swim
in the image typically what it does is
find the best match to this extra piece
of rock has this perfect shape of a
swamp body but no neck right but if you
force the system to find the match
you'll find a match somehow we don't
know that's matching or not to write so
we want to be to do that we want to do
the tail from the front of matching
whether something in the model is not
matched and we also want to be sure the
match doesn't take things out of context
we want to find the right contact to
support each other meaning that we don't
want to say that's a neck right so this
could be in that locally but this is not
a leg without the body below so the
context is needed meaning that you need
to see a lot of things around it to
figure out who you are but you don't
want to take the wrong context in ok so
that's the tricky part so our problem is
basically labeled those edges coming the
founders come to grouping 10 such that
if we reason about the ones those are
countable that collected we compute a
shape as a whole those weren't selected
we can recognize what it is ok just like
the old one many young women if you can
tell me which piece as should go
together I can reason if that's the
correct configuration but you have to
tell me that piece before hand without
that I can't even reason the shape
locally that's the major argument that
we put forth so so how do we do that
computationally the first we want to
show that low
cool a discount or selection can be done
very easily okay well not too hard at
least so imagine we're looking for a
point on the swamp on this point we want
to figure out where it is in image okay
so if we hypothesize is two pounds a
corresponding we can find out in the
image which are the count will need to
be foreground in order for me to match
this shape with the swamp okay what I'm
showing you here is a feature district
called the shape contacts so how many
people don't shave contacts okay so
shape contest essentially is a
description of the shape using a history
measure the hitch Qin is defined by this
log polar cells so we can essentially
each cell how many image edges is in SL
ok we don't care where it is in the cell
which is kind of how many edge points in
the cell just translate into a
description which is a hitch line like
so it tolerates quite a bit deformation
so now we want to do money cannot see
very well we put this the same shape
contacts on this image and we don't
match with this swamp ok and the
background color that look like this so
what I need to do is then locally select
those right count Wars such that you can
make this shape match with the shape ok
so this bright edges are the one that's
selected from the contour for at this
point to match with this point okay that
looks good so suppose we're looking for
in the second correspondence on this
this point of the swamp ok we do the
same thing we're looking for this piece
in the model we figure out where there's
an image we need to declare each contour
in the image on off such that the shake
context arrived on that look identical
ok this is again it correct now suppose
we're looking for a bud of this one or
the tail of the swamp if you look at it
actually locally you could have a false
positive like this right so this looks
like a swamp but you can see this
context is inconsistent with this to a
point ok so locally we can define the
problem encounter selection is basically
a variable X select telling which
contours on which is off and we have a
head scratch description for each of the
point in the sense that they will have a
number of histogram bins and number of
contours in image for each contour we
have a one possibility of incidents
between count when bins and what we need
to do is select the right call on
of those image such that we sum it up
meaning that select all of them that
description matches with the image to
the model description okay you can
almost think this is a a complicated
version of something called earth moving
distance so how many people I've seen on
earth moving distance okay a lot of any
good so essentially you can think of
there's a hiss cry here which is coming
from the image you had to find a partial
match with something that you know from
the target okay and in doing so that you
need to select which contour and you can
only select count 1 &amp;amp; hole in the hull
out okay and this is done by minimizing
this equation and that should be done
it's sort of a LP problemi so that's the
easy part the hard part is can show here
is the locally while you select the
contacts the contact sometimes the other
consistent sometimes not consistent okay
you need to find a consistent context
for everyone and that become a marshal
harder problem it's much harder problem
because the energy saw to problem
together one problem is called a sub
graph matching sub graph matching is
that you have a model you have an image
you have local click potential tell you
whether things are match or not itself
is a complete hard problem the second
problem is you need to figure out who is
the former whose background if you give
a foreground background you do that you
do the sub graph matching but you need
to figure out whose background who's
forgotten first before you can do the
matching so you had to do sort of two
problem together but fortunately there's
actually a lot of constraints that tied
those two graft problems together and
won't talk about the detail of how to do
it I let me skip this one so this is
basically the challenge that we face and
this is some of the results we have
again this is a very simple set this is
the model this is the contour and this
is the correspondence plus context we
selected so this is a false positive we
saw before we're able to match it but
the selection criteria was able to tell
me that the model actually isn't missing
the whole neck so using them or just
want to find the thing but it will find
the best match but also the same time
tell you actually I didn't have the neck
I just find that basically the body okay
so at that point can prune is false
positives right its wrong with that neck
is not a swamp so okay so this is a more
elaborate set of the results will rip
them at take on the top left we shown a
model that's used to detect image in
image and we show basically the contour
that we select
it as a 4-1 as a whole which match with
the object on the top left here it shows
essentially we're finding a bottle ready
bottle has a lot of color inside outside
it also is able to realize that somebody
is including the left side of the bottle
okay tell you in the left side buttons
missing okay so so the system
essentially selecting the contour in the
image as full run background also select
the model count where's the foreground
background to find the best matching
between the two okay so we are able to
do that so the test actually pretty
challenging the check the test consists
of five categories objects that looks
very simple bottle apples and giraffe
and the test set is basically the entire
set images together you need to run the
bottle image throughout the set you
don't know if it's a bottle image or
draw image and what you're looking for
is precision recall so you want to be
sure that when you do the follow
detection on the giraffe nothing fires
right you don't want to see bottles and
draft a vice versa so here's a bigger
set and this is a sort of a sort of you
can think some of sort of failure modes
this is a apple logo looking for a cup
so you find the match of the half apple
logo but it also tell you that missing a
bite okay so at that point you actually
can post Carson and prune it out saying
that's not a match here is basically a
cup looking for a actually match to a
bottle but it's also said that the
handle of the cup is missing so you can
also prove for now later on this is
actually a cup bottle looking a giraffe
they find the lower piece of the the
bottle but I sorry the top part of the
ball is missing so on this is a really
bad false positive I found the head of
the swamp and no neck and the body again
same thing this is unfortunate and she
looks like a bottle upon a distance and
this is a disorder swamp problem never
mentioned there's sa dental alignment we
see quite often an image so this is one
of them so I think actually I probably
should quit at this point we have a lot
more result to show let me show one more
result this is some latest thing that
we're doing
a selection a collection of a Chinese
emperor database where we have entire
set of facial images of the Chinese
emperor tools and those are the contours
and what we want to do is extract facial
features from those so it's extremely
difficult set because there's no color
features we can use the edges are pretty
messy so we're actually was doing pretty
well so we're able to detect the nose
label them into eyes nose mouth and
select those contours found those images
so i will probably conclude my talk here
so let me fast forward and just point
out that the work is done actually it
was a big group of students at pan and
accept this guy who's not from pan but
it's very helpful so this is a auto shop
for CMU alright so that's my talk
questions okay so more face images well
we this is all the set of a face images
again those are big collection of face
what we want to do is be able to detect
those facial features from a pretty
badly clutter scenes so this is again
we're looking at contours and remove
clutters found that contours
all right yes so I guess it's here
second to last slide are the one before
this example were you looking for swans
and hugs and things like that yeah so
your approach to detecting the clutter
is kind of independent of the task that
you're doing but that slide really
suggest that if you have the model of
the Swan at the bottom of the log in the
Apple you know the salient counters
really should be the ones that are kind
of relative from the past as are a few
any plans to benefit or yeah I don't
that way the question is the question is
if I know looking for SWA manandhar
bottles and apple logo the sealian see
if account will might be different it's
a good it's definitely good point i mean
in some sense the two are somewhere
related you can think about random walk
right so when we do the council grouping
we're doing a random walk with a state
machine of two states forward and
backward okay when we do the swarm
actually you can think of essentially
the state machine in rich's give you a
little more features like the neck of
the swarm and so on you can you actually
can design potentially a random walk in
this finite state machine space that
actually it's very similar to what we're
doing here in this guessing game in this
guessing game you can think of when you
do the random walk you can actually
think of this right now walk you start
which is state and you associate this
thing with a state which is the image
model and you which the second state
actually rien reached both state and use
retinol work and when you see a
contradiction had a backtrack so you can
think of this is actually a random walk
in some as finite state machine trying
to prove this object zist yeah but the
random walk concept is a little bit
complicated to do in a state machine
financed a machine calamba so you can
think of and sometimes I think this is a
for object recognition by proof right in
order to prove this is an object I need
to find all the consistent subset and
eat the propagators prove out and when I
see a contradiction i need a backtracked
and when I'm looking for is a salient
sort of set of usually consistent
evidence support pairs
right is that if you could have just a
single model before all right you can
clear my up yeah so you could say okay
I'm it in the in the image space and I
also have my state is consists of a pair
place and damage space and the place in
that my model all right and you just
kind of have some transition function
right that stubborn to buy what you
where you can build in your model which
is right now and butter Tran right but
that's sort of two means Greg brothers
you gotta eat you don't know where
there's one there's a rock sorry you
would have you could be deceived right
exactly all concepts yeah so yeah so we
won the state agency of the contour not
to be destructed so in order later work
we say okay do anything more but don't
destroy the native counter grouping
basically there are grouped together
there's no reason to pull them apart
there's no object that can solve the
middle of the contour so
shortcut the soft curves
short things like saying doors you can
boards windows straight angles whatever
right right but this has come back to
the same thing again so you need to sort
the contacts in order to set up the way
matrix or the retinal walk a little bit
better and the contacts depends on you
able to figure out who's belonging
together to begin with and that's sort
of create a very sort of chicken egg
thing right you need to know who your
body to see the context and then you
depends on this context to do something
for you so if you pick the wrong contact
you will do the wrong thing so that's
the thing you had to resolve how do you
know you're in the right context in jail
i think and i miss something and in the
details of how you actually go from the
shape contexts what clarifying all these
pieces and what I'm kind of left
wondering is what do you what do you get
out of doing this over the iterative
shaped context matching a deformable
template approach on orgy invalid right
so in a belonging I like what they did
is they do the local shake on text
matching using a whole window and then
do the deformation so the thing they are
trying to address is the model is
deformable on the image well they are
not dressing is the shake context has
inflammation so there in that case the
shake which context is big enough and
there's no clutter around it right so
usually the color is removed so in the
case you already kind of have a nice for
one option in front of you so you can
use the shake contest to tell you where
you are you can increase the shake
contest window to really tell you where
you are our case is that we don't have
the background removed the clutter is
there and the clutter is the one that
make heart problem hard if you already
had the forward object grouped that
become a basically what i said is a
graph matching problem so you're just in
the final correspondence between the two
graph that's what they did the problem
is I don't know which one is a
foreground which ones background
some of the earlier contour finding
first or putting that we already did as
much as we can we find all the contour
out mean those are salient contours that
just not swung that could be something
else just not the object for a good
question now yeah so in fact I was very
motivated when I was read the shake
context papers are they solved
everything but immediately when I tried
it open the shake contacts up for
articulate object like a human majority
of things on the background if ever
points on the body the most important
will be on the background ok so the
fifty percent of sixty percent your
signal is corrupted you couldn't get any
reasonable alignment to begin with not
yet not yet I mean we have results on
the sort of have a slight somewhere I
don't know so I think I Shrunk the
slides quite a bit let me see where is
it if I have one can maybe this one yeah
so this is the false positives that we
owe doesn't do it okay go to the end and
now hi this
so for human pedestrian this is a
typical of false positives okay so this
is a model of a production and this is
the false detection what happened is it
clear this is the head looks good right
and the cat this is the leg because
locally if you don't see the context of
this you find the two vertical lines we
just light up with that leg okay at that
point I found the head if on two legs
you say hey that's a body so you put a
bunny in box here in the middle say
that's a body that's a typical false
positive okay okay is it taking things
out of context because locally this to
paraline looks like a leg this to
paralyze look at another leg two legs
one head that make a pedestrian usually
but in this case you see your leg
actually go all the way out unless you
have a leg look like this that's not a
human so you again take things out of
context and here's another false
positive so you caught this is a
left-sided torso that's the leg it's
called this right side of torso that's a
leg okay left side towards the right
side torso two legs that's a human so
again you put a human in the middle of
it okay this is again take a lot of
contacts things so our strategy is for
the pedestrians not just looking to
contour so actually can use region
segmentation and our goal is trying to
piece this thing together so it should
look like a red line which is a
possession and for the false positive
for example we found lots of clutter
basically finds the vertical edge
vertical edge lost edges to the lineup
there's the people here it says well
there's a lower body but human giant
okay standing but if you look at edges
they all line up ok so again we use the
service the idea of using a region as a
basic element to select them trying to
find the combination with segments of
the region's that actually can be looked
like this person but when you did that
it turns out there's nothing can be
selected meaning that if you select them
you gain some where you're going to pay
a huge appending somewhere else in the
case of this way if you gain this piece
you're going to pay a huge penalty for
this because it does have a
correspondence that's why we for sports
correspondents and the sames together
again if you take this left side you
force the segment's is neither you put a
bow sang together and there's a human
double human it can take basely half the
thing out they can't piece this thing
together so segmentation is not perfect
but the combination of segmentation
she's close but the problem is you
turned out which combination to pick and
this is what a model-based wave piece
them together yeah so would you say you
were looking for detecting these he led
contours in is independent of resolution
so example you're shown an image where
in there were buildings one was in the
front and one was behind it did you take
the windows right smaller smaller
windows so if you zoom in because that
image but it started taking the windows
or where it's still ignorant so the
windows are pretty with a problem
because what happened is it essentially
is exactly it could be zigzagging and
this one is exacting images for the C&amp;amp;C
so if you want to get a windows then you
need to make sure the render walk goes
straight or go straight up and down if
you start zigzagging me we start losing
the CNC but but if you zoom in then it
would be similar to the windows on the
left where each yeah but remember right
mr. is actually go zigzag knees go
straight this is great versus lon so
yeah we need to get the squid out I mean
we do want to get a squared out but that
requires understanding this might be too
crisscrossing random walk together again
why they enrich the state machine this
thing is you need to recognize that
there's a state of the crossing where to
rather work hard to cross but it could
also detect just just a single
motorcycle in cycle but they get
confused because of the many costs for
psychotic or amines push that point
it's a matter of writing out right
because your junk probability maybe is
not attention to that right so it's you
for that image you should have for that
for those because you have have a much
lower jump rope you know the distance
you should analyze this is a lot more
because that's the sort of a that's yeah
background and you would is safer for
ground yeah sure but we have to
distinguish it for example a regular
grid versus let's say this kind of
chaotic grid right so there's a
difference between this regular grid and
the color because if you zoom in they
say what it has every connection then
everything will come out so you still
need to make sure that you're to me this
is more regular texture and regular
texture has additional property as
compared to sort of the clutter texture
get the nice home tours for each of the
windows right if you if you have yeah
because you were cool another problem is
that you allow yourself to jump over for
me
cause you you are too willing to stop
yeah sure I mean getting a random I mean
the eigenvector is try to find a common
explanation for many things at once
through this run don't walk matrix if
you can synchronize all the windows
together it will populate out but it's
not going to do one window at a time
because then it's wasting a lot of
energy to do one thing because I came at
a really fun the majority votes so you
cannot going to find the modes if you're
doing one in the time so you had to make
sure all of them actually are
synchronized together so it could be
because they have the same length but
that alone is not enough because the
many things are the same plan to some
geometry inside so I can mentor
essentially trying to pull out the
majority of the image I share some
common concept will run or walk and
unless it's very salient they're going
to pop out otherwise you're trying to
share them as much as possible so that
yeah yeah if you work for example
incorporates an appearance information
somehow attached
this end up kind of changing the setting
of your graph to do
right I think usually was saying that
before that we change the color using a
polarity four edges right if it start to
white transition when the next one also
thought to why is it getting you
somewhere but sometimes we're going to
hurt you because you know i'm studying
behind some background you read don't
know the contract between the background
for well yeah I mean it's definitely I
mean this is the thing I go back and
forth when you look already have the
moto that's something else articles for
face for imaginative human face right so
Palardy definitely payroll so you know
we don't see inverter face quite often I
mean there's a polarity regularity
between the facial features you know the
eyebrows tend to be you know why two
blockers or but for general objects like
human pedestrians will be really hard I
mean it could be that there may be
subcategories of body shapes or closed
was you know some program back on color
but it's hard for me to think that the
neighboring countries should have to say
yeah I think that's definitely I mean
let's open up the question of learning
so I think that's a place where I'm
pretty happy for the machine to figure
out yeah and I don't know the answer to
that school question ah forgot to
mention that so this is we don't use
candy because the Kenya trees below p p
so p p is the probability a boundary
detection this is the detective came
from berkeley there are actually pretty
good there are about ten percent above
Kenny so I think they all died is a
corner my corner is the biggest headache
that I have yes I mean all of us
struggle with corner
yeah we are trying to I think gee
jitendra has a paper just in this cvpr
looking for quarters and they were
pretty good combining segmentation with
the corner detection so the corner is a
big headache because the corner is a
junction and the junction has a meeting
occlusion usually and need to figure out
whether to jump cross or not yeah we
thought a lot about this good question
so I hope the message is you get a home
in today's that contour are very useful
it shouldn't banned them from images and
we are able to get those contour out the
second thing is that contours are
grouping together in right way provides
you a lot of information of the shape a
much bigger global shape rather than
just local contours it's all and the
message is really trying to sort of a
subtitle with the talk maybe it's get
away from patches and move into this
geometry and those big controversy but I
think I think we can make a strong
argument that you need very few training
example in that case to verify you don't
need a lot of training them
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>