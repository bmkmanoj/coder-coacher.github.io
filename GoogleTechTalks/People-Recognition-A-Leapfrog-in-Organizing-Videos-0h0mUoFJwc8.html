<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>People Recognition - A Leapfrog in Organizing Videos | Coder Coacher - Coaching Coders</title><meta content="People Recognition - A Leapfrog in Organizing Videos - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>People Recognition - A Leapfrog in Organizing Videos</b></h2><h5 class="post__date">2008-10-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0h0mUoFJwc8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my pleasure to announce the gentleman
from you do there a startup company with
two locations one here in Santa Monica
as the other one is in Kiev Ukraine was
able to catch one of the best phd's
around and that fuels some of the
algorithmic work with with us today to
present as long view he's the president
of Europe and then we have the CTO Igor
and together as I will go through this
presentation so I'm looking forward to
all right Thank You Harland so we are
very very pleased to be here and we are
very horrid also to to present in front
of our friends at Google you know when
when we when we we told some advisors we
were coming here you know they said to
us oh the bits care you know this is
this is google and and they told us it's
like you sleep in a zoo but all the
doors are open right so we still decided
that we wanted to show you the hard work
that we have done for the past two years
and we were proud of it so and we want
to share these two to google and we'd
like to have all your point of view
comments and questions at the end of the
presentation what we what I'm going to
do i will show you what it is that we've
been doing working like dogs for the
last two years between kiev and and Los
Angeles Kevin Ukraine and Los Angeles
and then I'll show you a demo that's the
best way of showing the product of so
you see what it is you see how it works
and then you go ashika will will explain
to you how it works first my co-pilots
here so i have yuri yuri is a CEO of the
company you go on siska is a CEO
co-founder and then we have alex who
actually wrote the stuff you will see
he's ahead of engineering he's a very
talented programmer about viewed 0 what
are we and what it is that we do and
we've been two years of our life in this
feudal is a set of technologies and
product so that you can find people in
videos this is really what we do this is
the core of this is the reason why we
wake up every every day we find people
in videos meaning that we are able to
identify celebrities or friends and
families within any kind of video format
whether it's professional content or
user-generated content and we show you
examples of both of things it's a little
bit further than this it's not only we
find people in video but we know people
are in video which is a kind of bad
product of this but it's really the big
asset one of the big asset of the
company fine we know people in video
means that we are building a people
database we are building a database of
extremely extremely large database with
millions of people that we can identify
in their videos this is this is really
what we are doing and we are doing it in
a way that is scalable that is accurate
and that is fast and you go we'll
explain how we achieve this and by the
way the risk the fact that is scalable
accurate and fast it's really the reason
why it works it works in production it
works with industrial-strength
environment about viewed 0 so we are
vc-backed company we have some of our
investor in this room we we were very
lucky to work with one of the renowned
scientist in in visual analysis and
structural recognition his name is
Professor Schlesinger he is actually
working for Vito since the beginning and
we also very lucky because we started
this company in Ukraine in Kiev and and
thanks to this we were able to attract a
very very talented team and two of them
are here very talented team means you
know you have to see Kiev in Ukraine
ease it's a European city there is no
many startups like we are especially
that is doing very hard technology that
we do
and and so we start to be very famous we
start to attract very very good talent
in Kiev we have 27 engineers we have six
PhDs and PhDs in mathematics in computer
science seen in visual analysis we are
very very happy and very lucky of our
fast of having this team it's a very big
asset for us we r us company also so we
have four patents in the US and we are
headquartered in here in Los Angeles
actually two blocks away from here
another thing that is a characteristic
of versus you have to see us as really a
start-up as it would be in Silicon
Valley but it's in East Europe and we
have the same mentality we have the same
culture if you if you go to our office
it looks a little bit like like here we
have a lot of young people that that a
very hard work and and that love
innovation and you see how it is i want
to show you two examples one that is
coming from the professional world it's
a work we've done with writers so it's
all about news and video search in news
and then i'll show you another example
that is a very interesting one how we
can apply this to user generated content
first about about news this is the
webpage we develop for writers and a
typical example of these as news is i
want to see someone speaking about the
subject in that case and that's what i
would show i want to see George Bush his
famous speaking about national security
and and now I have been looking at all
the about 10,000 hours of video clips we
have firm raters and this is all the
results coming from writers on this
subject let's just take one here it's a
shows push for be speaking about
Zimbabwe
you know here's this couple of
interesting things in this example of
video searches remember what I was
looking for as a consumer bush national
security what I get here is a clip of
about one minute but you can see in this
clip I started to watch the clip one
fifth ahead of the start of the clip the
reason is because that's when he is on
screen and that's what I was looking for
we think this is like this may change a
little bit the consumer experience of
video search in the sense that i am not
looking anymore at five's like you would
do in in google video you know you look
at files five minutes four minutes and
you have to watch the whole thing oh
yeah oh video is the same in our case we
can actually bring you directly to the
clip that you're looking for regardless
of the length of the clip and we think
this is changing a little bit the
consumer experience in the sense that
you jump directly to the place you are
looking for and think you think of a
video as as a cube with many dimensions
one is image the other one is soundtrack
and then you have also textual
information such as the title you know
any any kind of tagging what we are
doing really is intersection or the
fusion with all these dimensions so it's
not only that i want to see someone I
want to see someone about something the
someone comes from visual analysis that
something in this case come from
transcript or speech to text our attacks
that is around this video and and the
fact that you have a fusion between all
these dimensions is really what provide
provide the accuracy that you've seen
here I'll show you another example on
honest on a good speech to text this is
this one Congress needs to go forward
with the Columbia green and they need to
approve it as quickly as possible
proving this group is urging for
nationals
for national security reasons which is
which is what I was looking for so it's
not only that I bring you the clips that
are relevant I bring you to the place of
the clip that are relevant I also can
can make a preview of what I'm looking
for centered around these key words of
the story of national security no few
seconds before few seconds after what
this is is the following think of you do
a search on google google com and you
look for websites what US consumer what
do you do you read the title of the
website most of the time you read the
two lines of previews right and then you
find out whether these two lines of
previews is what the website you're
looking for and if it's not you go to
the next we can do the same for videos
this is a preview of the topic you were
looking for about the person you were
looking for this works very well i would
say on the shot tail let me know she's a
famous guy but it works also very on the
long tail i'll show you an example here
on google I want to see leave now no
she's um she got her five minutes of
celebrity in the Beijing Olympics this
is lee meow meow I have such a massive
information only meow meow that I'm
actually the first on search page of
Google this is really really the long
tail nobody knows about him young meow
except the one who is looking for right
and and this is me this is a page we
have on the way that we did for writers
this is lee myung yun
here she what is interesting with this
with this technology we have developed
is it works very well on the short tail
but i would say shoretel is easy because
you have tags of raj bose you have tax
of obama of angelina jolie working with
the same degree of accuracy on the long
tail is a lot more difficult and because
we have we produced such massive amount
of information on a video asset we're
able to inject this to traditional
certain and be relatively in the front
of such of such as as you so now think
of this kind of demo as of this kind of
technology for your personal use so the
example is I don't want to see jasraj
anymore but I want to see my mother
that's Christmas right I have tons of
videos on my picasa and i can't find
anything anymore that they're just too
many of them we can identify your mother
in your videos the same way as you can
do that in picasa for pictures but it
goes a little bit further than that
Imogene that I want to see he go in a
party last night but I wasn't there but
I have a friend of ego who took a video
of ego and our for our common friend put
this video in facebook so we have a
facebook app for personal media and this
is a this is a the dash part of the
Facebook of our facebook application
this is application of exact same thing
for the personal media we're very
excited by this because it's probably
one of the very first time that you can
effectively organize and share videos
based on who is there based on your
friends and family what is very cool
here and this is the example is this one
this is Sophia basic off she just joined
the company and I have one video of
Sophia but what is cool with this is I
have five other friends that have also
video of Sophia and we are friends it's
it's Facebook we all part of the same
social graph so suddenly with our kind
of technology I can start to see my
friends in my friends video
and then the next step is every time a
friend of mine post a video where I am
or where front of my is I receive a
notification of this and I start to wash
them so we think this is a probably one
of a very very good tool so that you can
organize your personal stuff and you can
share it with the people that matters in
this case the people who wear inside the
video and and we this is very very hard
to do because we say we think this is
the extreme long tail of a video search
and you go will explain to you how we we
crack this and how we did this in a very
very effective way other type of I have
to go back to my screen sorry to my
presentation here is all the type of
application for this you can imagine is
security market you know once we we have
people database and we can start to find
you in other location and we some some
people wants to have this for the
security for some security application
or content filtering we we are startup
so we are not focusing on this yet we
are focusing very much on the first two
which is business solutions bringing
this type of product to media industry
and consumer with video video friends we
are developing at the same time with
consumer a nap l'occasion that is very
targeted to advertising the answer here
is it's very hard to do advertising on
ugc because nobody knows what the UGC is
about many times we get this in this
comments from advertisers in our case
our job is pretty easily to understand
what the user sees about we know who is
inside we know what they are talking
about in some cases we know that profile
because it's all linked to our social
graph to facebook social graph so we
know there are all teenagers they all
from the same class then you can put a
nike and nike advertising on top of it
now how we achieve such kind of result
this is what ego
Anushka is going to talk to you about is
a technology that are taking that are
coming from different angles one is it's
not enough to have face recognition when
you start to work on a very very large
massive scale of people you have to use
other dimensions of the video in order
to increase the probability of positive
recognition we call this a fusion engine
the fusion is we're using speech to text
we're using optical character
recognition to kind of guide us or help
us understand what the video maybe and
then the face recognition engine is
being adapted automatically based on an
increase of ability of other dimensions
around the video and this is what you go
is going to explain to you yeah
to finish
okay we finished at that point I hope
you can hear me good afternoon so as
Laurent already mentioned fusion engine
how we call it is very important for us
and that is that very early in our
development where they stood that no
there is no technology which can handle
the problem as we formulated it in by
its own even having very good facial
recognition video technology cannot
deliver the experience you want for
video search application and having only
speech to text you have Goudy you know
this very well having only speech to
text you can't deliver the experience
with which consumers expect from a
ultimate video search application so we
been a star up and been very limited
resources we found a way to integrate
various very different pieces like
speech to text speaker separation
analyzing existing that at the end of
course our secret source face ignition
and video to integrate all this into a
single system which can produce very
accurate results in face recognition and
then give out these results in various
applications so when we say hbu soon
fusion typically we understand
multimodal recognition when you when
face recognition and for example voice
characteristics work in concert to help
you recognize a person but we are
looking at this more broadly we don't
limit ourselves to only multimodal
recognition and actually taken
recognition decision we say okay fusion
is also when you use various sources of
data to speed up training of your
database and it is very important
because this is still supervised
learning it's a little bit work ahead to
can get it to a level of completely
unsupervised learning and this is one
layer a level of fusion then you have of
course multimodal recognition and you
have something you can call fusion on
you I level the example which
ron was shown to you when speech-to-text
results are merged with facial
recognition index to produce just better
experiences on screen for video search
is exactly fusion of indexes in side
search it's not just that we better
recognize person using speech to text so
we tried many things and basically I
don't I don't want to bother you in
saying how exactly we did that but a
couple of recipes which I think we you
may use in your daily practice and
Google that of course you treat every
source of information as probabilistic I
mean if two years ago someone would ask
me what's the probability that the
caption would be the same for the anchor
i would say probably close to a hundred
percent now we know that it's for a less
than hundred percent in this situation
happens as you see on screen not because
TV channels make their mistakes but
because just captions typically lasts
longer than face on screen so this is a
pretty you have this situation pretty
often and you have to account for this
for various sources like Bloomberg and
for example BBC you have different
distributions then of course getting
this probabilistic aspect you have to
know various distributions around your
sources and there are plenty of them I I
believe you can invent dozens so just to
give a small example let's drag this
point between the eyes how its
distributed on the screen in time that
clear peak this is a bloomberg channel
this clear peak in the center of course
show that anchors in studio do not move
much they're fixed and the camera is
fixed so they spend most of their time
just sitting in the middle but what is
interesting I think you can get what are
these two small Peaks on the left on the
right side this actually corresponds to
regime when two anchors are talking to
each other and this happens on Bloomberg
specifically pretty often so all these
characteristics are useful when you
use a probabilistic sources of
information then the lower graph is
distribution of a distance intraocular
distance for the same bloomberg channel
so as you see in our environment when we
analyze TV content it's about 60 pixels
between the eyes and then knowing this
distribution can help you in second a
task which is you have to introduce
confidence loans for every recognizer or
detector you have if you have a detector
recognize which just outputs results
like for example you take Sphinx and
just output speech-to-text results you
know actually what's the confidence
level you assume that if the result is
there that is hundred percent accuracy
but it's very it's not good approach
from engineering standpoint every result
has to be has to have some confidence
alone even if it's just gradual so again
let's say face detect you have no
confidence initially but using even this
distribution you can introduce very
simple confidence level like for example
what's the probability to find eyes if
you'd side attack the face if they
detect on the very edge of the screen on
bloomberg channel say on the right down
corner i mean if you don't have
confidence from faith attack itself you
can take this distribution and think
about this as confidence and then when
you have confidence level you try to
fuse only high conference results high
confidence meaning something which is
sixty percent plus you don't try to fuse
many twenty percent confidence obviously
this will not give any good results i
mean we tried and the force recipe is
very simple I you're on a good position
here you have immense amount of data
which you can use for actually checking
the accuracy of your fusion so try to
check it on everything you have because
sometimes fusion works very well in
limited set of data once you get into
production you find some another small
piece of data where a fusion
very bad results and you don't want to
roll back your production system to the
previous version so you test on as broad
data as you can find of course in our
task of people recognition and video we
have to know what's the actual
distribution of people on screen so to
say that American television is the long
tail it's actually to say nothing like
we have almost two percent of people who
appear on screen cover 99.9 a percent of
on-screen time and this doesn't mean
that the same distribution you haven't
search queries in Google it's absolutely
doesn't mean that it just means that
American television is very much silver
British focused but once the key
channels get this content online they
found themselves in a big search engine
optimization trouble because people go
and Google's himself and if they were in
video they expect to see themselves in
video and this is a typical query I mean
I google more often my colleagues myself
my business partners more often than
Britney Spears and George Bush of course
they take bout percentage of searches
but anyway this long tail takes a lot in
percentage wise among searches in Google
and we we formulate our problem for self
as we want to be a cue to be accurate on
all these people starting from Obama and
finishing with your mama as we say in
the office so from your Obama to your
mama we want to be the same accurate
even if it's personal ugc video so to
continue this discussion of this problem
you have input media which is a real
world videos either take starting from
something taken by mobile phone very low
quality and finishing with HD quality
which you have on TV channels and this
is a real world videos it's a completely
uncontrolled environment we cannot we
cannot say to Nicole Kidman please come
to camera look straight
have even lighting on your on your head
and don't move too much no we just have
what we have and sometimes it's a even
if its digital channel it has very poor
quality like this and you still have to
at least you have to be stable on this
results and if phase detector works it's
even better sometimes you can even
recognize faces like that and of course
our objects people in the video you
cannot predict what they do the facial
expressions the variety of head poses
sizes occlusions is immense I mean the
microphone the hands of the haircut is
typical stuff which you have to deal
with and figure out what to do with a
cluster which has a cup near eyes you
have to treat it somehow so this is the
media what a requirements for our system
in terms of output of course we want to
be accurate on long tail of people so we
said that we want to have precision on
ninety-five percent on all content and
recall of sixty-five percent at least we
don't use force except rate as a
characteristic that's unusable in our
case and we want to analyze we have a
bishes goal we want to be able to
analyze all worlds television and to be
able to analyze personal videos imagine
this right because we have a lot of
personal videos in the album's so to be
able to accomplish this of course you
have to be very scalable fast and very
reliable so we achieve this level and I
would like to give a little bit more
about what we have so for the first of
all how you can achieve this fast
reliable scalable results you have to
use a lot of algorithms which work in
concert you help each other there is no
thing go magic Silver Bullet algorithm
which will handle all face recognition
or whether in all detection so you have
cascaded cascaded detectors and that's
how you can achieve first of all
fast and accurate recognition detection
and then recognition the same applies to
recognize it as in any object
recognition technology for video we have
customization piece which picks up
frames with the same person on screen
and then we recognize this cluster
versus the database of people which you
have in database is something we call
two and half dimensional models of the
head so we compare like the cloud the
frames to a model in database and of
course this involves a feature poor and
instruction and classifier and so on
yeah so there are several very
interesting pieces which we used to
speed up the system how we how we can
get sub linear performance between time
spent on recognition each person and the
size of database so what happens if you
have 100,000 people in database you
cannot run 100 times slower this is
achieved through again cascaded
recognizers and something we called
hyper matrix where we we don't have to
go through all database to compare each
face to every face and database
obviously this doesn't scale doesn't
work so we compared to a very small
limited set of faces from the database
and this applies cascaded approach and
effective fusion formulas just to give
an example we started to index a channel
we had 2000 hours and face recognition
taken alone was capable to pick up
12,000 cluster organized 12,000 posters
from blue to southern hours and this was
less than five percent this was less
than fifty percent recall which was not
that we wanted so we fused it with OCR
facing nation video and OSHA it's a very
good cobbling and in this case it was it
gave us 30 almost thirty percent boost
this system together was capable to
organize 17,000 clusters yeah cascadia
detectors this doesn't mean that every
detector has to
give out perfect results if first
detector in phase detector cascade give
out this as a face no problem because
there is a second detector which is
which is slower but more robust and he
will filter this out this is not a face
the second detector can say this is a
face again not a problem it can assume
this is Arnold Schwarzenegger but it's
not a big problem because we have a
third detector which say this is not a
face and once you detect it every single
once you collected very good sick
clusters picking up for example one
cluster of McCain's from 50-minute
speech you don't know that this is
McCain yet then you come to essential
problem of recognizing this cluster
versus a very big database so here in
scalability we separate to kind of
problem accidental like engineering
problems which you have probably in
other applications like how to get your
engine very multi-threaded and how to
speed up sometimes using low-level
instructions how to make your UI very
fast for query which runs through the
big database oops I'm sorry
and there are essential problems where
you have a huge database and how to
differentiate lag and Jaroslav who are
prime minister and president in Poland
and their twin brothers inevitably once
the database is growing you will find
situations with two people look alike
they look similar so in there it's very
hard to invent a system which triangle
inequality rule works it doesn't work in
this case so you cannot get just a
binary tree and keep it sublinear it's
not that simple so a hyper matrix
technology is exactly about this how to
make our classifier to be the almost try
and go let's say to make classifier
where triangle inequality rule almost is
true it's almost true but it's not
exactly true and that's how using this
hyper matrix technology we achieve the
thing that we can recognize currently
the each cluster is organized versus to
study 6,000 people in database and we
keep 95% precision the file the final
characteristic which we try to optimize
for ugc case is how how quickly you can
get system educated that's why I was
saying that fusion on a training level
is also very important it's how many
tags you have to do to train system to
recognize your mother how many tags how
many minutes how many seconds your
friend has to spend on screen and you
have to tag him so next time he'll be
recognized so here we have some
threshold of sixty percent recall and
right now we achieve very good results
we will have it in our application in
facebook so i think we achieve the
threshold where it's worse for user for
end users it's worse
taking tag efforts it's not 40 tags per
person to train the system to recognize
friends family so next time on screen
there or suggested automatically we also
keep in continuing our search one of the
things we are currently doing is pushing
up recall on very low quality videos
which you have from a bio phone it's not
an easy job because feature point
detection doesn't work well on low
quality image like you have 320 x 240
image just to present you one of the
ideas which were checking right now like
like you have to be very creative when
you have this kind of confined
environment so one of the ideas is
professor said okay what the contours
which you can play around in the dog
Photoshop they I was just showing them
to explain they work no
I really don't know how to take all this
okay
so this is the feature point of I and
how the contours are growing around the
eye so we say the following let's define
a feature point as something which is
surrounded by maximum numbers of
contours which are include into each
other it's pretty novel approach and
because contours are they do not depend
much on lighting and they're they're
purely defined by shape of course the
contours themselves changes but how they
include it into each other doesn't
change much so you can get a graph of
contours included into each other and so
the definition of feature for in the
feature point is something which is
surrounded by maximum number of contours
and that's how you can get an an eye in
this case nostrils mouth and so on and
this you don't need to use this on a
images of very high resolution but this
is very useful when your resolution gets
smaller and smaller when you have a face
of 50 by 50 pixels so we will include
this one this detector as one of the
detectors in the Cascade then of course
the Holy Grail getting 3d shapes from
two-dimensional images we were also
working this but under slightly
different angle we don't try to use this
an actual recognition we try to use this
to speed up training because sometimes
in the special ugc you have just a
couple of tags as you have seen that
here yeah you have to a couple of tags
and sometimes this you see person just
from let's a profile view and you cannot
get the complete model so you have to
use 3d here with even some i'd say
average 3d man to complete the model to
make make to produce faster educational
system to increase the probability of
good suggests next time this person will
appear on screen and of course budget
tracking in the detection and tracking
we started this just to as one of the
detectors which can help face
recognition but then we find a potential
client who said ok I want to apply this
to support videos
I want to track football player soccer
players and so on and the and we think
that this can be very well because we
started from premise that camera is
moving camera is not mounted still this
is this a soft problem camera is moving
even sometimes even faster than the
object so you can see the object is
almost a stable compared to for example
even cameras or taking your environment
can rotate faster than the object just
pixel wise phase detection technology
will be also built in in some future and
i think that's it if we want to add
something to to finish what i wanted to
show you is live running of the engine
as soon as it comes you will see the
actually the engine running life and and
you have a flavor of how every see that
digo told you does work so here i have a
number of videos i'm running the first
one and let's see this is the engine
rocking on this laptop so it's not
designed for this which bit slow but you
will see the engine running recognizing
someone in in the video here it is SB it
will say i hope that it's me
of the ante I am what is cool with this
demo which this video is it was taken
from a mobile phone and in this case
it's n95 Nokia and we would love to do
this on Android I think I saw 1g one
somewhere so whoever has it I'd love to
have a look at it we have developed our
a Prada on mobile phone it is this is
really experimental this is two weeks
old so we've been playing a lot with it
see how it works this is very hard to do
because that's the kind of the ultimate
New Jersey's you don't know anything you
don't know the Lightning condition you
don't know if you're inside outside you
don't know if you have direct light or
light on the side and that works pretty
well so that that's a kind of you know
to show you it really works you know how
it works in real time so what we what we
show you is you've seen a little bit of
what we've been doing and and we spent
long time believe me on this with all
our team and you go give you some some
flavor of how it works what are the
challenges and how we overcame this this
challenge if you have any question we'd
be very happy to answer you and it's
really an action so we really like to
know what you think about this and how
this applies to solve all the type of
holland that you may have thank
join us yes
the question is how large is our
database of faces too much videos we
don't mix professional videos and ugc so
yes right so professional videos is
currently 36,000 people and you just see
I honestly do not know it's couple
solvent it's not millions yet we haven't
launched replication
that's a very good question that's
exactly why i deleted the y-axis so we
feel that we suddenly push the limit up
to less than 10 tags 10 manual acts to
keep it up 65 plus percent of recall so
we are working to reach the goal of our
goal is three tags so three times I'm
ready to say this is my mom and then I
expect we then expect my mom next time
on screen order good night so I can tell
that this goal is reachable with the
face recognition in video play is still
images honestly don't know riya tried it
maybe you will tell us from picasa
experience but in videos this is
achievable
yeah yeah because that's costly right
that's that's your real course
more questions please
do you have question in mountain view
I haven't heard can you get loaded
oh I think what's the question how much
data per individual having all this how
much data for an into individual to be
recognized in in kilobytes and in one in
frames it's up to a couple of megabytes
it's not much
when they try to recognize right so yeah
as a correct me if i'm wrong i will try
to repeat the question so you're asking
what what's happening how many
recognitions we have once we collected
faces from video right so if they did I
mentioned we have clusters collected
from the USO clustering technology
pickups frames with similar with the
same person it never mix up two persons
in one cluster but it so we have let a
cluster 1 2 and 3 and this will be
person one person to in person three and
then we do recognition of cluster bomb
vs database in the process of this
recognition we have it's a pretty
complicated process but there are
several comparisons of course of with a
picture picture if you wish comparisons
but it runs fast and most importantly
that it's sublinear with a growing size
of database that's the most important
characteristic even if this individual
even individual recognition may take 200
milliseconds it's not a big problem as
long as you have to make only one
solvent comparisons or 500 comparisons
for the old database and then there is a
question how to narrow down number of
comparisons if you have 100,000 people
number of a cigar cutter so say you find
five cases in the photo we identified
the third by and then a bar sucks
recognize whether or not which will be
spira determine that
that's like it's a slow process
because we're just kind of photos have a
couple seconds
this is a ver F cluster is a shin is a
very fast process it's not it's not
scaling right its linear I mean you have
to spend X minutes to close to rice five
minutes video it can be like two minutes
right but I mean this happens fast and
then you try to recognize it Mercer's
the database so it it's also a question
of how you position this in your user
interface right I don't know what's a
delay between the moment I am posting a
photo and the moment when this photo is
already grouped with others so I can tag
it in our case clusters clusters are
growing as video goes and you can
basically switch on comparing cluster to
a database at any moment when you like
it just a matter of probability what's
the probability that this cluster will
be positive legally recognized if it's
the probabilities highest when the
cluster is the biggest right because
what you have
I labeled you so system knows that you
but then for whatever reason I that you
rotated
we don't have the ability to automatic
that's you and place it there oh by the
way it's this person's name we have to
oh this is not a case for media because
clusters are the same if you supply the
same video even if you say it's
semantics of technologies even if you
let's say downscale it reduce the
resolution there is a very high
probability that it will be this almost
the same cluster in the to be already
recognized for sure if you recognize
previous cluster so if you supply the
same video it's one point zero point
zero that it will be labeled correctly
we haven't even bit exact IDs in
clustering although just this is our
facebook application so this you can see
how you can move around a video once
it's tagged so you have in the bottom
here the people who are in the video and
you can you can you know same way you
can jump to a place on professional
content you can do the same on on ugc so
we encourage you to come and join us in
video France application on facebook so
can you can play with the application
it's it's open application right now
any more question
you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>