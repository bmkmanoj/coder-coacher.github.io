<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DSD: A Hybrid Analysis Tool for Bug Finding | Coder Coacher - Coaching Coders</title><meta content="DSD: A Hybrid Analysis Tool for Bug Finding - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DSD: A Hybrid Analysis Tool for Bug Finding</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6YHMB9ESSgA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is coast of China that's initial
question over there no- you laughs that
is an interesting question and we can go
into this after the talk good question
though so I'm going to talk about DSD
crusher DSD stands for dynamic static
dynamic and the talk is about reducing
false positives in back finding so I
know that a bunch of you have attended
the talk last week by Bill pew on fine
parks so fine bucks is a similar system
it also aims at automatically finding
bugs and our system DSD crashes similar
to that in that it's completely
automatic and also aims at finding bugs
but our system is also a little
different from find bugs in that it has
some ambitious goals on reducing the
number of false positives and to achieve
those ambitious goals we employ a
sequence of pretty wild program analysis
techniques but first for the background
so we interested in testing and testing
is very widespread many people use up to
fifty percent of the time for testing
some companies even have one test appear
developer so on what goes into testing
so first you have to figure out what
your program is supposed to do right
you'll go and read some design dog you
go and talk to your fellow developers
you have probably some emails flowing
around there are some travel blog
comments so you go and read all those
and try to understand what's going what
your software supposed to do and then
the next thing is right test cases
manually probably to check whether your
software is really doing what's supposed
to do and both of these are really hard
and tedious in both cases so for the
second problem there's there are some
approaches to deal with it for example
our checking crash tool which is
automatic test generator so it will take
away the second part the writing
your test cases manually and it will
generate those test cases for you but of
course what the test kit generator
cannot do is go and read your design doc
and go and read your email and go into
your head and find out what the software
supposed to do so that's still a very
big problem in us off in social testing
and we are trying to attack that problem
with these the treasure so I've talked
to a bunch of you before and about using
static analysis tools using automatic
back finders and one of the biggest
reason is false positives more than for
the biggest reason that they are not
used very widespread and this also
recognized in the research literature so
here I've one quote from the ESC java
developers and easy java is one of the
heavyweight deep tools that try to find
bucks in software and they'll often say
that the tool has not reached inside
level of cost effectiveness in
particular users complain about
annotation berm that is perceived to be
heavy and about excessive warnings about
non bugs particular unannotated or
partially on tail programs and that sort
of the standard usage right you have
some source code and you have not
annotated it in some with some special
constructs you just want to run it want
to run the tool out of the box and then
they say that there is excess advance
about known bugs and I also called
enforce process another study a recent
survey Rooter and others have run easy
Java and also other automatic part
finding tools on five different projects
with a total of 170,000 saw statements
and ec Java alone produced more than
9,000 warnings for potential help and
exceptions so clearly that's right too
much and the authors conclude that there
are too many warnings to be easily
useful by themselves and now i'm going
to give you the high level overview of
how we try to attack that problem
so the different kinds of inputs you
could put into some method you want to
test for example you you could have a
method that expands expects an integer
parameter right so according to the Java
semantics you could put in like the
smallest integers up to 0-1 one up to
the biggest integer it's all legal Java
but then there's also subset and this is
like the little smaller box here I have
and that box represents the inputs that
are allowed according to the
specifications you have so for example
you there might be some job or doctor
says you're only supposed to put
positive integers into this function and
clearly this box is the box so if you
want our most of our test case to be
because there should find bugs in the
behavior that's a lot of specification
now some people might also argue that it
would also be interesting to find bugs
outside this box okay robustness
problems when you feed unexpected input
to the function but for many people
that's a lower priority when they fix
problems so we try to concentrate our
efforts on that box of a lot of problems
and the way we're going be going about
it is we're going to start out with a
set of existing test cases so and these
are supposed to be passing test cases so
they draw from the input domain that's
allowed by a specification and then they
have some behavior that is also allowed
according to the specification so we got
going to try to and observe those and
I've them in this box here the existing
passing test cases and then we are going
to try to generalize that behavior we
saw to the books of the allowed behavior
so we're trying to figure out what was
the specification of the original
problem and then so there was a first
step the dynamic the first be in the
approach and the second step is we run a
static analysis tool to exhaustively
search the space we just restricted you
know to like what fine parks would do or
like what other a glint or PI check
or other tools to do and we will get
some results of those tools and those
results are here in the back finding
books and then as a final step the last
dynamic step the last D is to convert
those warnings to test cases so that we
can confirm whether those warnings
correspond to be a box hard okay and now
for example to make the process a little
bit more clear so assume that you have
method you on the test m and it expects
an integer parameter right and you have
a set of existing test cases and two
here so one cause it with one and the
other one too so we run those two test
cases with a dynamic step infer
specification that hey we've seen one
we've see two so probably what the
programmer wanted is a method that works
on all positive integers that's our gas
and we infer that specification is
bigger than 0 and then we annotate the
original original program with that
specification and feed the annotated
source code into the static analysis
system and the setting an asset system
will do its analysis and it might come
up with that there might be some problem
if you feed in input that is larger in
five that's the result of a static
analysis tool and we going to get the
we're getting those constraints and
solving the constraints and one example
is that less trial six because satisfies
that constraint so we generate a test
case that calls your method with six and
we will execute the test case and see
whether it crash or not and only if we
or exhibits that behavior that we
predicted and only if that behavior
really occurs then we're going to warn
you okay so note here that we have
excluded two kinds of false-positive
warnings the first kind is we didn't
even search in the negative integers so
we excluded those cases where we think
it's probably excluded by the
specification and also we have excluded
another kind of false positive which
arise in the static analysis where it
might want about something that kind of
occur
r &amp;amp; up any circumstances because the
sega master system did not get the java
semantics right so we also exclude those
cases and now for the concrete tools
were using to achieve that for the first
dynamics that we're using daikon that's
a tool developed at MIT by my crayons in
students so thi con runs your code first
instrumented transit and generalize
behavior and it can also annotate your
code with pre and post conditions so
using this and then we are feeding the
annotated program into easy Java ec
Chavez extended-stay aesthetic checker
you can think of like as a very heavy
weight compile that does all sorts of
static types inside it uses the simplify
automated theorem prover and the result
of that static analysis tool we compiled
two test cases and for that we use our
few constraints over the third party
constraints over and also our test case
generation techniques and then we
generate general test cases and you can
compile those or the tool even can
compile those and execute those and then
only the runtime exceptions that
occurred are presented to the user so
now would be a good time for questions
like what the high-level idea
no questions nobody's following are you
already sleeping come on somebody
and make things later but have you a
little bit adding those as
so you mean the java short statement
simply add them so oh ok so I'm going to
repeat the part where think I understood
what you what the question was so I
think the question is once we have those
pre and post conditions we could just
leave them in the code so they can get
checked at runtime every time the
program is executed yeah yeah that's a
good idea so I have not looked at this
um I mean they're few might be a few
problems in there that you know you only
have looked at a few executions and now
you say ok I've seen behavior a few
times and I will enforce that every
execution the future will behave exactly
as those few executions ever seen before
it might be able to heart because you
might have seen only a very very limited
subset that's one part of the answer
another part to the answer is that the
pre and post conditions are declarative
so out of the box you cannot execute
them you need some sort of a compiler
which compiles them to extra runtime
checks but that compile exists as their
chain mail compiler so you could do it I
don't get it they either stimulating one
english now be negative but you know it
could be its measuring low low
temperatures that your fridge for
network cells in a breeze and so lower
orders or did you make this bet well we
just make that assumption and as you
pointed out we might be wrong in many
cases but also you might be right in
many cases and our cases it proved i
have a few examples and they proved
useful so it seems to work in practice
so the question was whether the
generalizing of few behaviors to
specifications whether we're right or
whether we also might be wrong some of
the times and we might be wrong
sometimes the cases you improv their way
for the user when it gets the first case
see this tribulation and say but you
necessary you may withdraw back you see
you between i understand and that
explore that whatever duty doesn't write
them initially a few it is a gues may be
wary to go and change the gas that might
be very interesting if the developer
would be willing to look at those pre
and post conditions yeah definitely i
mean if you have such a developer that's
great okay now so this kind of the
outline of my talk here i'm going to
talk about the different components of
that we're using so first going to start
out with easy java ec java was
originally developed at compaq laps it's
a research tool and it's now maintained
at the in dublin by Professor Henry so
basically it's a compile-time checker
and the we are using the current version
the u.s. each other to and the current
version recognizes pre and post
conditions expressed as jml annotations
of your source code so j males the job
of modeling language which seems to be
with the de facto standard these days
and also it supports java up to 1.4
which was a nice and besides those
specifications that might have been
generated by some to lure
written by some user it also knows
already out of the books the pre impose
conditions of primitive Java operations
so for example it knows what the
precondition is of a division operation
or if you do an era creation but you
shift that use the Java expression it
creates an area they knows which
precondition has to hold in order that
the trap operation does not throw a
runtime exception so then basically I'm
use all this knowledge to derive
potential violations of thousand
variants we're at runtime around time
exception might occur okay and and so
basically that's an intra procedural
analysis it uses it looks at every
method isolation and I'm going to
explain a little bit how that works so
it takes a method body an inside that
method body it should place every call
to some other method or to some Java
language operation to first check in the
precondition of that entity and then
assuming the post condition so it can
use the preconditions that some tool is
generated for some other method or we'll
every time use the precondition it knows
about the lab h ave operation so in once
a test replace all those calls it will
compute the weakest precondition of the
method body of terminating in any state
so just returning legally some value or
voight or whatever and the other states
are those states where it does not
return legally but throw some runtime
exception of the way and these are
clearly the set you interested in so we
only concentrate on those runtime
exceptions like for example a
classcastexception because most people
would agree that throwing a pass cast
exceptions not good thing okay so am ii
c java like many static analysis systems
produce false warnings because they do
not completely follow or model the
language of the Java language ever
semantics of the Java language and I
have an example here so we have one
method get ten that always returns the
value 10 and then we have some other
method math that uses that method and
divides by the result of the fair
method now we just looking at that code
we know that this method always divided
by 0 divided by 10 and never by zero
right but since you see Java looks at
every method in isolation and it does
not have any pre and post condition of
the other method it just says okay
forget 10 anything can happen so it
might return 0 and there's a potential
division by zero exception and you know
it will warn the user and the user would
become annoyed because this is clearly a
false positive and i would call those
kind of false positives the easy kind of
false positives because we can attack
those by generate compiler warning to
test cases and then see whether the
curse in practice or not and we're doing
this with the last step like here where
we get a warning by the static to and
then compared to a test case and you
know if it doesn't turn out then we just
rank it very low or just do not show the
user but then there's also the other
kind of false positive that I would say
that's a harder kind of false positive
where the tool just cannot and a cannot
access the semantics other of the
specification Tori of your program so
for example here we have another method
and the method is called for + int so it
only the work for integer values are
positive and you know the method name
says it and there might also be some
javadoc specification that says it only
put in positive integers so everybody
but would know it except an automatic
tool like ours so the tool will go in
and analyze the source code with all the
analysis and we'll figure out so if i
put in a negative value here then the
coat of crash and we want the user
but besides those false positives
there's also another subtle problem so
the method above might be called
somewhere in some other method right and
in the other method caller here there
might be some serious bug down there but
since we are not aware of the
specification for poisoned all the test
case you're generating to find that bug
might crash in four percent and none of
the test cases might actually reach the
real back down there so the lack of
knowledge also prevents us from finding
real problems okay and this like the I
would say that's a more serious force
kind of false positives those are going
to attack with it first then I'm accept
okay so the first and I'm except we are
using daikon how that I can work like
that so it instruments your code
basically at every method entry in every
method exit it will add some code that
writes the values of variables to disk
so on every when the you know in the
execution every time as you the
execution enters a method it will write
or parameter values all the values of
your fields and so forth to disk and
similarly at exit and also at exit also
rewrite the return value to disk so you
end up with a long trace of values and
then the packing tool goes through the
trace and it has internally a list of
potential invariants so for example it
has invariant templates for one value is
equal then another value or one variable
is always larger than some constant or
some invariant on some contain structure
holds and so forth so it will check all
the combinations of those variables
whether they satisfy the invariance
ahmad and every time one of those data
points violates invariant it drops that
invent so then it's left for smaller set
of invariance in the end if some
invariant hell held a few times
but was never invalidated it will just
say okay I assume that this is a general
invariant and will also hold in all
future executions and then it can export
those invariants as preconditions and
it's post conditions so the state the
invariant that held at the entry of a
method will be the precondition and the
invariant that held at the exit of the
method will be the post condition and
we're using the icon in a configuration
that many people use it which is we only
use the simple invariance so most
importantly one integer variable is
equal larger smaller than some integer
constant or equal larger or smaller than
some other integer variable or that one
reference variable is always null or
Never now so just simple things we found
these are more if a higher confidence
that those are two endurance so just
ignore the more complex ones where
contain structures are involved or
floating-point variables and so on some
and one small site remark is that daikon
expresses those and variants in terms of
its some of its own methods it has but
since we using a static analysis system
that cannot execute those methods we
need to provide a few pre impose
conditions to those methods of example
we wrote pre impose conditions to add
method you okay
so now the question is how would we use
these pre and post conditions and that
also relates to your previous question
so we only going to use the pre and post
conditions as additional assumptions so
the ideas to just restrict the behavior
additionally right so for example here
we have this method and a pre and post
condition so when you analyze the body
of the method we will assume that the
input has to satisfy the precondition so
we exclude some behavior you exclude all
the input that virus at precondition and
so the drawback of this obviously is
that we might exclude behavior the least
through real bug but I think that so
it's okay because may you know note will
will find all the bugs and fast is more
important to limit the number of false
positives s supposed to find the maximum
number of bugs and similar if you call
the method and easy Java copies the post
condition so it replaces the chord with
the postcondition pre and post condition
then we also only going to use it as an
assumption so that means so we're not
going to use it as a requirement as was
suggested before so using as a
requirement would mean that we enforce
every time that a method is called that
really the caller only passes values
intel inside the method that satisfy the
precondition because that might lead to
additional false positive warnings so
you know it's very likely that we only
observed a few executions and missed
several legal executions so you do not
want to warn the user about cases where
the code executed and violates some
previously um derived precondition
first of all that would introduce
additional false positives and technical
the user has never seen those pre and
post conditions before right because our
tool inferred them and then a language
that they probably have never seen
before and their big long and ugly so
you know we're not going to deal with
the pipe if those complaints of the
users and then one interesting technical
issue that came up while using the
diagram thread in variance is behavior
subtyping so what does behavior
subtyping so you might have some Class C
are now some class super and some Class
C and C extend super and both define a
method M so that means that M overrides
the super m and if you provide pre and
post conditions for EM for example the
super has P and Q and then you also
provide Priam poor conditions to the SAP
method what does that mean that means
that in the sub method you can only
define additional behavior right because
the sub method always has to behave as
the super method when used as a super
method so for example you might have an
annual class in a dork class and then
the dork always has to behave as an
animal when you use it as anymore so it
means you can only specify this will
behave it on there that means that the
real pre and post condition of the
subtype so the real precondition is that
it's the behavior of the superclass and
the behavior or like logically or the
union of the subclass and for the post
condition is when the method behaves as
a superclass then it has also to follow
the post condition of the superclass and
if it is called as a subtype then it has
to be half a sub tab and P&amp;amp;R might
overlap in this case so but what happens
if you do then I'm dynamic invariant
detection like that conda's so our
daikon works is that it observes on
behavior and then it will associate that
behavior
the method body that was executed so in
this example here assume that somebody
called super that m and every time it
costs a bit of em or no let's say that
every time suit that M gets executed it
really turns the value of one and every
time c dot m the method body c2dm gets
executed at every time it returns 0 so
it might be you might think it's
reasonable to annotate the super method
with oso x 1 and the sub method that
always return 0 right by turns out with
the roots I just showed you and those
roots are also enforced first of all
they had forced bi CH ml and also
enforced by other design methodologies
like country and designed by contracting
those that if you put it together that
the sub method the postcondition sub
method is that has to return one and it
also has returned 0 which of course no
method can do so that is equivalent to
false and once you have this such an
inconsistency in a static analysis
system that it might throw of that
system very easily because you know from
force you can infer everything and then
you know everything goes wild so to make
that really works to make the system
really work we have to fix this and we
work on this but I'm not going to talk
about that because it's another paper
and it's like quite involved okay I'll
any questions so far otherwise I'm going
to talk about the evaluation
is that jml and ESD java yep yep daikon
doesn't know anything about this
generating there it should know that
definition but right now is I think it's
a dresser back in Diagon I mean they
have to find for the specification they
have to if they want to write legal
gmail specifications they should know
about it and when designing methods I
guess they also should do it right right
yeah
all right okay so question was and I got
that question also previously at Georgia
Tech because that's like a very
counterintuitive thing that definition
of favor subtyping especially while
coding I all violet that mice offering a
we should discuss it off cause I think
well that's an interesting point also
from yeah you allowed to give additional
behavior to work on additional cases
okay so we're going to resolve those
questions after the talk so let me talk
about or evaluation so the goal of the
tool is to find back sweat so some
people use coverage metrics to evaluate
the value of automatic askah generators
I think that's real bad idea because
assume you have one tool and generate
test cases and it achieve the coverage
of eighty percent but doesn't find any
bugs and then there's another tool where
the generate test cases achieve a
coverage of maybe two percent but it
finds 10 grade bucks so which tool would
you pick so the tool should internally
cover all the code right it should not
mean there's no point in egg and
exporting all those test cases that do
this great coverage graphing okay so and
we evaluate our tool on to third party
applications the first of the EMS
component of capers and jboss is an open
source application server use the 4.0
release kind at one version and that
part consists of five thousand on
comments or statements and the second
testy is groovy 1.0 beta one version
where we extrude some low level classes
and the resulting in class are two
thousand non-communist off statement and
the interesting part about groovy
our perspective is that first of all it
came with a big set of test cases and
those test cases were developed like for
their purposes to achieve the quality of
their code so they were there completely
unaware of our ideas with the inference
specifications or four so that's an
interesting case where you can see the
value with test cases that have been
there before so those test cases will
not develop just for our experiments and
we compare our two DS equation to two
other tools the first one is our presale
tool called checking crash and checking
crash is more or less a subset of DST
kresha so it doesn't have the first I
concept it only has the static analysis
step and then the dynamic step where we
turn our test cases so here we would
expect the DSD crusher that's better in
excluding forced process right because I
mean there was the entirety of the
project that we can access the
specification and as an example why DC
crasher does exclude force posted
warnings so in this case we have
something from jboss JMS where this
particular method throws negative error
size exception if you pass in negative
value of lengths and lengths one of the
parameters so it seems like it should be
part of the specification that you
should not put a negative value for
length inside that method here because
you will get that negative error sighs
exception so we ran three test cases
which use the method properly and from
those three test cases that I could
infer that precondition hear that and as
I'm all using general syntax anyway so
so that the length value of length has
to be equal the S the size of that array
and when we use this precondition inside
DST crasher than these de crasher
suppress that kind of false positive so
for the groovy experiments
very interesting to compare the runtime
so the runtime of TST kresha is a lot
bigger than the runtime of checking
crash which is not surprising because
now we have the entire icon statement
now but i still like reason was only
three times as big as the other on time
and in total we were able to suppress 74
positive reports and the last report
that we suppress was not a false
positive but that's just a engineering
short coming of or two because it
produced a little more complicated
constraints and right now we are not
able to parse them but you know that
should be d to fix the other two we
compared against is a clown it's by
Carlos Pacheco and Michael Ernst MIT
that's basically daikon people and it
used icon and also generate test cases a
new unit and all that but for the static
step it does not have such a heavyweight
analyzed as we have so they mainly use
random test case generation but I also
have to say that a claw has a much
bigger scope than DSD crusher so I'm
only going to compare DC crash against
that functionally they have here but
they additionally addition to that
function of the M conquer against they
have more stuff right so it's not
completely fair but I'm you know
comparing to that part they have there
and so he would expect that DST crusher
finds DB bugs because it has a deep less
diagnosis and also find small box
because it finds those DB parks so here
I have the table Sheamus component and
only the class cast accept the report
and DSD crasher found three of those
classcastexception in two minutes and I
tried several configurations of a Clow
so and it was not able to reproduce
those three although a class searches
for classcastexception and I think of an
example so in this case we have a method
get bytes that expects parameter of type
object and you can imagine if you use a
random test case generator they
you can really come up with many cases
many values for object right but this
exception only occurs for very specific
object because the object has to be
instance of this bite area with a
capital B and only that case it will go
into that branch and crash because the
programmer now casts against bite area
for lowercase B and you get that
exception so DC crusher found that and
declared not and for the groove
experiments if a similar behavior that a
client different combinations that try
it was not able to find those same bugs
that these two kresha found in similar
time and again because it found it was
not able to basically solve complex
conditions and come up with very
specific kind of inputs that cause a
particular behavior okay so I wish you
point us here and you can download the
tool for my web page and also the pre
set of tools and write for the
conclusions so I've presented a
three-step analysis technique consisting
of first a dynamic step where we execute
your coat with test cases to infer the
correct to infer the specification of
the code and then you in the second step
use static analysis to only search in
the this restricted space and finally
we'll convert those warnings produced by
cell analysis into test cases to verify
them and only produce only show you
cases where crash really occurs and with
that I come to questions
Oh this summer I'm working with John
Penix mostly and yu chen and i'm working
on automated test case generation and
i'm looking for a google project to try
the technique out so if you have any
volunteers here anybody that wants to
get out test cases generate
automatically then we can talk
afterwards was that the kind of answer
you wanted ok I'll question permit cute
oh yeah I'll ok so the question is have
a look at the cute tool from a student
in Illinois and yeah it's a related to
land it that's a interesting combination
of symbolic execution and concrete test
random testing right so basically it
uses some concrete execution to help
symbolic execution ball execution in
case it gets stuck because the
constraints are getting too complex
and it would it would be very
interesting to incorporate this into our
static analysis scheme so basically
basically it uses a very nice trick to
improve static analysis and our static
analysis tool does not do that I will be
interesting to incorporate it Joe so I
can imagine that icon gave false
positive area to be a problem this
technique I was wondering if we looked
at writing quantitatively assess just
how much the false positive the variance
report by Nikon if it hurts you if the
test sample is you used to generate it
into it early in various wasn't
sufficient so question is what happens
if daikon does not produce good
invariants and that's a problem I don't
have any quantitative results on that
but since we restrict ourselves to only
high confidence simple invariants we are
confident that especially the something
is now something's not now that seemed
to be quite helpful but as always and
icon the more test cases you have more
tests you can run the better will your
own variants be and you can you not only
restrict it to test cases by the way you
can for example monitor your tool in
production and then the user can tell
you okay this was ok behavior so from
you get a really big execution trace and
by doing that you also get better and
variance
oh definitely
question who this yes yes I hope</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>