<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: A Common GPU... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: A Common GPU... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: A Common GPU...</b></h2><h5 class="post__date">2012-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sXZ5AW_It94" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yeah except Andhra is from that per
month but why anyway so first up what do
we why do we need to come on a new
column in the early thing the first
thing is that efficient linear are you
going to the car or mini what Mike as
well so as I was saying efficient energy
lies at the core many applications
especially in machine learning but also
in dollar domains and I am and on the
cpu and Python at least you have an
umpire provides the ndre object which is
a standard the matrix tensor
multi-dimensional thing which allows
sharing code between projects that use
this as a basis for they or their data
they are already on the GPU a number of
implementations that work some kind of
tensor object resembling the NDA enough
I the channel code base has one piechota
invite shamea opencl also CUDA math
vampire trust I'll have some sort of GPU
and the airy object but all these are
indicating compatible so it's kind of
kind of renders code-sharing difficult
because you have to convert the data
representation and underlying object
whenever you want to pour the kernel or
something from one day to the other also
none of the implementation support the
full range of ndre features they
typically concentrated and sub optional
features which is essential for air work
are easy to do because a partner or
harder than others
and at that point none of them support
both cuda and opencl with the same code
base and actually the only five ppl of
it CL and all of those so what do we
want as features for a new base object
the support for varying dated last mean
not only flipping coin being a person
but also in tears blue balls and complex
possible also support for an average
number of dimensions which is because
some algorithms require more than one
dimension in two or three dimensions to
implement by a convolution if you say
evolution and then another example then
you need for dimension it will be a pain
to do with your beta objectives and
support that also support for strides
tries for those who might not be
familiar is the way to specify how much
memory to skip between each element in
the dimension so say you have a big
matrix a in think here you wanna take a
sub matrix of it without copying data
then you can say dimension of the matrix
stuffs here but the stripe for the rows
up to here so that way you can access
only the sub portion in blue while still
not copying any data and using the same
backing store for both matrix another
feature that is useful is broadcasting
this is a kind of computational trick to
east on ratios like when you wanna when
you do like a neural network
implementation you want to add the bios
vector to a matrix of matrix of examples
you have say the big red matrix of
examples and the blue by a secular if
you do a usual element voice information
like act like an addition
it won't fit the rules because there's
less than in the vector than in the
matrix so you would have to do something
else which is to make peripheral copies
of your vector so that it is kind of the
same size of a and then you can proceed
as usual but one thing here is that
these copies are not actual in-memory
copies is just virtual copies made with
a trick and tried to make it seem at
least as if the elements repeat and the
last point we want is for compatibility
with cuda in a pencil to be able to
share code hopefully between these two
platforms okay so why has this not been
done before actually the first point and
probably only the only one is that this
hard and Hankins me to get right and
also efficient the same point because
even if you support everything but it's
really really slow then now we're using
only music and the main subway of that
is that the indexing competition when
done and GPU take out a significant
portion of time compared to what they
would take on the cpu but at the same
point even if you want to support
everything and have as tries and
whatever we don't want to be this thing
to be hard to the club for so if you're
writing a colonel and you want to you
don't want to support generic scribes or
whatever brought that thing because it's
harder to go the kernel that way we
provide the convenience functions where
you can just call as contiguous or for
fun memory and then you have your input
copy in as in a fortune or whatever
order and then you can just to assume
it's catchy goes for the rest of you pro
now ok this is a comparison of the
supported features for all
implementations well not every
implementation Under the Sun that those
we found and you can see there that the
stride strides and broadcasts are pretty
much only supported by piano and since
it's much easier to add more types and
to add strides to an implementation
we started with a an approach or I think
because it's better matches the bottom
line which is what we want so what we
have right now are data types who
support all sorts of diff types like
integers closed levels whatever any
number of dimensions strides and views
broadcasting element-wise you know some
support for reduction that it's not
complete complete right now and we
support all those on cuda and opencl we
also have in Python interface and as CEO
Scott interface which is similar to the
new empire yep capi but depends on
python is will have to be cleaned up
because we want to be able to use this
not only in Python but probably in Ruby
Lua or torture something we are missing
currently estimation of a sub matrix or
elements but that's that's hard to not
too hard to add reshaping of matrix and
clean the interface as I mentioned okay
so as part of the it's hard to get right
an efficient this is an example of the
Mathemagician that we have done to make
it complete and efficient the same time
I said before that in excellent
condition on the if you are expensive
because you have to compute from a min
decks which is the thread ID or
something like that you have to compute
where you are in memory to get the
proper element and then this requires to
do a sequence of module and divisions to
get the elementary one so the cost space
per dimension it doesn't matter if the
dimensions really big or really small
number of dimension that matters so we
have an implementation that can help
alleviate this car which is a limit
applies dimension collapsing so suppose
you have a 3d things like that and the
whole cube is a 3d tensor called a
you see is really pink and then you guys
a soft answer B which is the blue part
and you want to do some element wise oak
park and that we can collapse the outer
two dimensions each one in this one so
that they press on to one single mom
dimension even it is bigger since you
have one less mention it's faster to
access memory you cannot collapse strata
dimensions so and if all of the
dimensional I could do is you can just
go to solve into one single along better
and really there are some networks you
illustrate FB are not super so man bara
there is some cyclic Rome doing a plus
one so it's just this Colonel is with
the overhead figures kernel which beam
theory with one mention or four
dimensions but before dimension want it
collapse back to one you can see the red
and green line at the bottom which are
really cool to fight with over one if
you have a party thing but it's not the
laps in a you do 40 of four dimensions
of the mixing of positions that paint
blue line this up it goes really really
up so gives you that competition take a
significant portion of line even if you
had more element if it takes Marta more
hi and if you have the 40 with one
strident dimension it becomes two
dimension that we're collapsing it's the
purple line in the middle so there's
still some over it because you have more
dimensions but it's still faster than
just not doing anything so our theater
fence for this project is to use it in
piano vicodine bike for sale these three
are kind of a given because most of the
ogres of this are also developers in ya
know and we have the other fibers
impacted are helping else but we would
like to use it in other projects or be
used
I dependent implement the good years ago
plus interface and for that we might
need help from some see people with
their feminine roof or you know some guy
find other ways to lower they ever read
like LM advice collapsing but if we can
design some new implementations that
would help you go use the implicit
looking provided by cool and opencl for
faster oops and finally wore lamination
which is being used in everything
everywhere do that for at that point we
would have library offers you come and
see us so that we can discuss using this
or supervisors to talk to your students
about this project so that they know
about it and hopefully use it I would
like to acknowledge James bextra because
he wrote some of the key honor code we
started proud and complete the nether
RTC HP and Clark and every search for
Frank funk and access to research while
doing this to photography and definitely
so any questions
yeah well we heard about similar and
every yesterday or something so yeah
that's what I'm pretty sure that if you
are not a quick what existed
the heavens
within the discipline
we work with them
later a winner base molding initial rate
or straight
promise
but if question you know right ray you
have a solution Rick yeah son is so bad
actually people I've never done
something like that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>