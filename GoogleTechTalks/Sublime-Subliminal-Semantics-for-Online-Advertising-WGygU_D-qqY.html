<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sublime &amp; Subliminal:  Semantics for Online Advertising | Coder Coacher - Coaching Coders</title><meta content="Sublime &amp; Subliminal:  Semantics for Online Advertising - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sublime &amp; Subliminal:  Semantics for Online Advertising</b></h2><h5 class="post__date">2008-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WGygU_D-qqY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone my name is Lucas
Callie rohini and I am responsible for
all the international development and
business for expert system today was
supposed to be here also Marco Verona
our CTO and founder unfortunately had a
family emergency so he's on the phone so
he's available right now is available to
answer to any any questions I have a
good technical background but i'm sure
that Marco is going to be able to answer
two more questions than I can and the
objective of today's presentation is
bein Lee to give you initially an
overview of our semantic technology and
see a direct application in the area of
classifying online content in order to
provide much more targeted advertising I
try to having a presentation that is as
practical as possible so i will use few
slides however all the presentation is
going to be available in the slide set
so we will distribute that hopefully at
the end of the of the presentation first
few world few words about expert system
expert system is a company that has been
around for a while we have been
developing linguistic technology and
shipping semantic search engines and
text analysis software since the end of
the 90s we've been active in italy
mainly for for many years and a couple
of years ago we started our
international expansion we've been
growing very fast especially in the last
few years and we've always been
profitable so we actually found that all
our development through real customers
we have been deploying as I said for
more than 10 years and our customers are
kind of in many different sectors inside
the enterprise business and also we are
supplying technology as OEM two
different companies here you see listed
twine and Microsoft
so I basically general introduction
about our technology we actually provide
a technology that taken an input any
kind of text in any kind of format at
the end of the day we perform a full
deep linguistic and semantic analysis of
the content so basically what does it
mean we will see that a little bit more
in detail during the actual demo but
basically we take we go through all the
different the four steps that we usually
go through as people when we read a
document okay so we look at the form we
look at how the different concepts are
related to each other and then based on
the actual context we perform what is
called the food is ambigua shin I'm
assuming that among you there's a good
understanding of a linguistic technology
but I want also to give this basic
information for people who have not
really heard in the past about these
kind of technologies the outcome of the
analysis which is done leveraging a very
rich knowledge base our semantic network
is a conceptual map so it's a structural
representation of the content that then
can be used for different applications
in practically today we will focus on
its application in terms of classifying
online content and being able to provide
a very rich understanding of the content
for for advertisement purposes these are
the four different steps that our
technology covers morphological analysis
parsing sentence analysis to understand
how the actual sentence structure to
then have all the information available
to perform a full semantic
disambiguation I'll jump immediately
into this is nothing else than air a
window on the technology so this is not
application is just the ng
and I'm going to run the engine on some
initially on some sample sentences to
give you the to try to represent what we
do differently which kind of depth we
can provide in the analysis and that's
is the basis of the application for them
for the semantic advertisement feel free
to ask questions if things are not clear
I'll try to be as fast and as precise as
possible so i'm using the first sentence
to describe something that i presented
before so the capability of the system
to understand the structure of the
sentence which is at the basis to really
collect the information that are useful
for the disambiguation in this case the
system highlights i run a short analysis
on them on the text and the system
highlights in red what is the main
clause inside the sentence and the in
green what is the subordinate clause
this helps in understanding that there
is an actual direct relationship between
different concepts that have been
identified in the sentence for example
the system understands that tasty in
this case it is linked to the sandwich
it is not linked to John which is
actually the nearest noun if you want
but it's linked to the sandwich as
correctly we would understand
immediately if we read the text at the
same time the system understands that
the second sentence is actually related
to giving the sandwich to me so the
system performs it a natural resolution
in this case and understand that that is
related to the sandwich and that John
gave to me is related to the sandwich so
the first element of the depth of our
analogy is really the sentence analysis
understand how the claws are
structurally inside the text and now the
different concepts are related to each
other any questions
sorry now we cover different languages
we cover Italian English Arabic and
German today we are deploying two
different two more languages and next
year the second i'm using the second
sentence which if you want it's a little
bit extreme because i'm using eat with
the meaning with just not the most
common meaning for eat i use gas with
two different meanings in the same
sentence because i want to highlight the
second element which is the capability
to perform the food disambiguation ok so
i ran the analysis and the system is
telling me that eat in this case means
to consume that gas in this case means
gasoline while in this other case means
the accelerator ok so this is based on
leveraging the information that is
available out of the box inside our
knowledge base or semantic net let me
open up the semantic connect one second
here in the center first I give you some
numbers we have for the English language
today more than 350,000 concepts and
more than 2 million links between this
concept all of this is part of the
development the years of development
that we put into creating the actual
application if you want a platform what
you see here in the center can you see
well it's a bit small here in the center
you have for example the 12 different
meanings of the word gas in English in
this instance the correct definition is
gasoline and gasoline is linked inside
this knowledge inside this graph to many
different concept by many different kind
of links so this richness helps in
performing the disambiguation for
example gasoline is a kind of
hydrocarbon which is kind of fuel which
at the end of this is an object and the
ear on the right you see all the
different kinds of gasoline but this is
only one of the
several different kind of links that we
have available in the semantic net I'll
just show you some of them for example
the verb subject this is linking
gasoline with the verbs that gasoline
can be the subject of if you change the
meaning you actually change also the
verbs that the gas can be the subject of
then you have other relationship for
example the verb object again these are
verbs that gasoline in this case can be
the object of if you change the meaning
you change the verb and then one other
interesting relationship is what we
called concept and corpus which
basically is telling us that when
gasoline it is used with that meaning
all the concept that you see linked to
that meaning of gasoline tend to be
present in document that belong to that
specific domain where gasoline is
usually used ok all of this is
information that is used in processed
through the analysis to perform the
disambiguation now let me just run a
more concrete example just taking one
article
it's just been published the idea is
that I want to show the actual a
practical example of the technology
analyzing a real article so that you can
have a feeling also of another important
element that makes this platform
something that can work in an
environment where you have a huge amount
of information right now I'm just doing
a simulation of a crawling and and
analysis or text is I clean up one
second
okay so this is the time that system
takes to process a an article we can
process up to 60 kilobyte of texts per
second on a recent dual core server your
custom the I just want to show you the
what is the actual outcome without any
training just leveraging the existing
knowledge of the extraction capability
the categorization capability and other
features that are coming out of the box
and in present basically that richness
that then can can help in increasing
significantly the precision in
activities of this sort so this is the
part related to the entity extraction so
what you see here are all the people
that have been present in this article
one thing that is very important is that
compared to other technologies that are
doing similar things we don't count on
lists so basically we don't need to
continuously manage and update the lists
we actually recognize entities based on
their semantic role inside the sentences
now we can we can we can increase an
advil knowledge base lists but we
usually work just by extracting based on
their semantic role here you see the
organization's here's the other element
like measures geographic location and
other concept of the system tend to
guess they have some relevancy but even
this is not able out of the box to
assign and understand specifically but
in any case these are the result of the
of the actual entity extraction piece we
can extract we have out of the box 14
entities which include the dresses
minidress and other entities that are
not showing up here because probably
they're not presence in this article the
other things I want to show you is which
is very relevant for the topic of the
categorization of content is that out of
the box we have a taxonomy which is used
to classify the content so this is the
taxonomy it is out of the box we can
work with this taxonomy can work with
any taxonomy because we have complete
control on the system but this is just
to give an idea of what can come out of
the box so this is in this case the
article is mainly about politics I don't
think there are any other topics that
are really relevant because the system
assigns a much much higher level 2 to
the category politics another thing that
happens is that the system does an
automatic tagging so these are the most
relevant concepts and entities present
in the article when I mean more most
relevant I mean that semantically not
it's not based on frequency it's not
based on how many times the specific
word is actually used but it's based on
their semantic relevancy we can tag
automatically and extract what are the
most romantic relevant element in them
in the content also the system performs
a I would not call it a summarization
but we just with the same logic it
extracts the three most relevant
sentences semantically most relevant
sentences inside the core the corpus of
information so at the end of this
out-of-the-box analysis you have a full
semantic analysis of the content and
this obligation of the terms you have
the categorization you have the tagging
all these elements are then available to
be to be used by any kind of other
application are there any questions yeah
how do we do that
yeah so basically like to to evaluate
the semantic relevancy we take into
account different elements for example
which kind of role a specific concept
place inside the sentence for example so
a subject is by definition more relevant
than other another section we consider
element related to for example position
inside the text and we also put this
together with the result of the
algorithm that evaluates the actual
relevancy of the sentences they answer
your present
yeah so the question is there are out
there many standardized tests to measure
the precision and recall of entity
extraction is that your question right
and the question is how how do we
compare right that we have we had
several tests in real if you want real
business scenarios where we compare and
we also use the in this comparison we
have been tested on those kind of
documents that been already
automatically tagged so we have all the
numbers and we can share the numbers one
last view of the content is why I
consider basically a clustering of all
the elements at the higher level in the
hierarchy ok so again what does it mean
means that the system understands that
in this content we have different things
for example we have many verb of
knowledge we have many verbal
interaction for example all of those are
basically a way to view the content that
creates a certain level of regions that
enable you then to do things to do
really to integrate into application
that required when you have a complete
control on the text you actually have
much more available much more tools
available to refine your your aspect
could you say anything about how your
network compares to wordnet yes it is it
based on did it start his word net and
no so the idea is that the idea started
with warnet ok now when when we actually
when Marco and Stefan our two founders
actually started to actually think about
using wordnet they realize that word net
doesn't have the level of depth and the
level of and the scope is not consistent
to really provide
the a good quality result in a typical
business environment okay so in addition
there was the requirement to work in
real business scenario there was the
requirement to have a system that was
going to be fast and performing okay so
these two drivers we're at the base of
the fact that even if the structure
seems similar in terms of nodes linked
to each other the actual development is
completely different here I have just an
idea for different things that really
make our semantic net completely a
completely different element for example
we have a much richer number of links
between the concepts compared to
compared to war net here you see some of
them we have even more than this but
this is just to give you an idea of how
much richer is actually the number the
structure of the of the things of the
semantic net another element is that
each node is associated to different
level of attributes and this is a major
and important element to drive things
like automatic categorization and the
extraction okay so these are all the
older the hierarchy is basically of the
nodes of the semantic net are actually
at the end of the day under these top
level categories of attribute and then
each concept is also linked to specific
domains okay so all these are some of
the elements that make our semantic net
a completely different thing compared to
two ordinate did I answer your question
it did I have a follow-up question when
you say that two entities are related
and I saw percentages on your earlier
display like twenty percent were those
set up by human beings or were those
based on Corpus analysis the domain
associated to the concepts um or the
Association among different concepts I'm
in general did you build up it's all
build up
I am it's or build up its only build up
manually thank you by experts linguists
okay um just going back a little bit to
the to the actual performance of the of
the the platform here you see some of
the numbers the with a recent dual core
server we basically can process up to 60
kilobyte of texts per second we have as
you see for the English semantic net
more than 320,000 concepts this is only
related to the number of scene set sorry
see a sub-dominant super domin and at
the end of the day this is the number
the total number of links that you have
all of this you see the richness doesn't
really impact performance because as you
see even with a small laptop you can
process a page in less than second at
the end of it 16 kilobyte of text is
three or four pages of that you have any
questions now let me jump to instead to
like the main topic of today
presentation which is our application to
provide much more targeted advertisement
to online content so basically we took
the capability of the system to really
understand the content and we turn it
into a platform that enable publishers
to have a much more clear and dynamic
understanding of the content inside
their platform this is valid for typical
publisher like newspapers and so forth
and it is valid also for social networks
and related at the same time we provide
a mechanism that links the result of the
analysis to a preset definition of
target that you can create based on your
requirements and provide this
information to anyone who is on the side
of the network advertisement or on the
side of the actual and customer
conceptually we take a text weekly we
clean up the text to understand the main
element inside the text to perform the
full analysis that I showed before and
that as an output it gives you a
categorization based on a taxonomy in
the current version which is the our
first beta version we have a taxonomy of
more than 440 categories we are now
building for the final release a
integrate this taxonomy with the
taxonomy that was developed with people
analyzing online content and we bring it
up to 660 categories and 34 different
levels we perform the extraction what
you will see in this example in what we
have available today is the extraction
of the main entities but we are
extending this by adding things like for
example products for example other
element that could drive the more
targeted advertisement at the end of the
day the information is passed to the ad
server in a way that is not different
from the way it is passed today today it
is past the keyword or no it's a
sequence of character at the end of the
day we are going to give that as an
input to the ad server so we can
integrate with any ad server application
that is already running on the side now
let me instead of using slides let me
just login
so what do you see here here on the
right you see the category three that I
mentioned before ok so it's 440
categories as I mentioned we are
optimizing it even more for online
content but it's already right now rich
so it's too in some cases three
different levels so all the content is
processed against categorized based on
this taxon I'll talk later about this
aspect because she reaches and which is
an additional way to actually create
profile on the left you have profiles
and 4 profiles I mean here I made very
simple cases you know like I did
demographic profile but here you can
create any kind of profiles and the idea
is that you link to this profiles based
on in this case your knowledge of the
profile you want to create some of the
categories that you have identified here
on the right ok so this gives pretty
obvious I did the 210 and I put toys and
comics and sci comics you know like
there's another tag of a category that
is linked to that this is clear
now one other element that is so this is
basically you attribute you assign a
category to a specific profile the
profile is the actual information that
goes out to the to the ad server now
another element that is important is
that in addition to the actual
categorization based on the content you
can actually create also a
categorization that is if you want i
call it emotional but it's just just
because for lack of a better definition
so the idea is that the content is
linked to the objective interest of
people okay so someone is interested in
soccer and golf and whatever whatever
sport car fault music whatever but
there's also a different level of
reaction that our customers did because
at the end of the day this is used by
advertisement company they're telling us
that there's also what we call an
emotional reaction to the content so I'm
looking at something that is for example
scary so scary can be anything from
someone that you know got lost on the on
the forest the house that is burned
terrorists at war or whatever and
reading this even if these are different
actual elements in terms of precise
contact one is related to crime and i
think is related to whether another
thing is related to other things the
actual reaction that a user can have
might be of a one kind you know when I
see something maybe a profile of a
person as saying our four is over 40 s
when C is something that is threatening
the lifestyle they look for security
okay so this is a different way to link
your content to potential relevant
advertising is this by any chance clear
whore okay um now let's just take a look
at the actual examples going to some
pages sorry
again I'm just in this case simulating
what happens in reality in the
background
so basically this is the user user
access this page the information is sent
to the symantec advertiser servers the
content is analyzed and based on the
content analyzed the system gives you
back for example these three domains ok
so this main domain the demographic
class of 18 25 year old followed by 11
17 and then 2665 and here is the
explanation so this is an article mainly
about American football ok this is not
only an article about sport is actually
an article about American football sport
of course is relevant commercial Konami
canned finance seems less relevant now
this specifically I just copied your
page so there might be some noise around
there and these are the people mentioned
so this is an additional information can
you can drive your target is asian of
the advertisement these are the
geographic locations these are the
organization's products nothing they
this is the semantically more relevant
concepts so this is basically all the
result of the analysis that we saw
separately and these are some additional
if you want debugger information on why
this thing came out let me just do
another example
sorry
is an article just published today about
a crime in Oakland and again i'm
simulating the
the result of the analysis again article
the target mayor may be based on the
count and the claw declan demographic
class of over 65 mention crime Paul
police criminal law law and Katherine
just about pizzeria but as you can see
even if pizzeria appears in the title
because semantically easy relevant it
just shows up as a kind of a lower
category it doesn't really drive them
yes so the question the question is what
happens with a page that is a hub for
four different different news right it's
basically doing something very similar
for example we can take I found this is
a good example because now sorry again i
found this good example because it's a
technorati is and in the side that
changes always the content also
belonging to many different because like
for example for a CNN website even if
the news actually change the actual
structure of the content is pretty much
similar so there's a something about
politics usually here or something about
something you know big disaster that
happened usually the topic of that
technorati from that point of view is a
better example because the content
really changes significantly
the idea is basically takes all the
content available at the game assigns
priorities if you want based on position
but like the center maybe has a little
bit of aya priority but in reality
analyzes everything that is available
and then creates an average out of what
are the topic mentioned there so if you
would try to do this I'm doing it lives
I don't know exactly what is going to
come outlet upside
politique Commerce economics internet
and software based on this taxonomy if
we go back and take a look at the
content
this is this is interesting because as
you can see here for some unknown reason
because maybe there's Paris this is a
good example probably cuz there's Paris
the technorati associate that
automatically to travel even if it's an
article about Paris Hilton that is
complaining about John McCain
advertisement I think yeah yeah so when
you see so technorati needs
classification sees this is the most
important blog about travel the result
of our analysis instead is telling us
that in reality it is mainly about
politics so the two articles of the
center and reality are about politics in
the system correctly identifies them
about politics
absolutely that's that's the result of
the crawling exercise if you want now
out of the box of this demo you have
just two takes the input and just
analyzes all of that you can actually
especially when you look at specific
sources that are relevant more relevant
because you're working with the
publisher and so on you have different
pieces of information that tells you
know for example yeah there are three
topics to extract the three topics are
separate and you put them in and
processing in the analysis together at
the end of the day however because
probably you will have to feed one
advertisement you need to find some sort
of one of the well it's not true but
it's if it's the own page you have
selected number of advertisers you can
you can decide which kind of information
you want to pass to them at server also
you need to understand how the observer
is a link to that page if it's one feed
at the end of the day you can pass a
limited number information
let's go to some different kind of
content
it's a blog now one thing to say is that
the obviously the the quantity of
content available helps in terms of the
precision of them of the categorization
okay so mainly about music maybe about
musical instrument singing show and so
on zoology we don't know but it's not
very relevant and okay we have 10
minutes so if there are any questions or
if there are even more technical
questions where we want to involve Marco
I can try to answer I no no okay they
told me is not online so I'll try to
handle then it for me can you use the
mic here so i just noticed that on one
of your slide you said something about
compounds yes maybe detecting compounds
could you speak about that at all yeah
okay I think all of this is related to
the way that we actually have built the
knowledge base okay so this is not
something that comes out of an automatic
training or you know just an extraction
of corpus reference corpus this is all
knowledge that is actually available in
our semantic net so one capability of
the semantic engine based again on the
capability to understand the
relationship between concepts is to
verify in the in the parsing phase that
may be a concept like credit card or
something like that it's not really made
of two different worlds but it's just
one word okay and so the presence of
this information inside the semantic net
can helps the validation and so you have
the credit card is actually a concept
that is very different from crediting
card same as you know cookbook if you
want there's a concept of coke the
concept of book but cookbook is actually
by itself a different a different
concept at the intense of you be the
answer to the answer enough for its it's
actually part of the knowledge that is
available inside the knowledge the
semantic net that helps the engine to
perform a disambiguation and so at that
point to validate that for example
credit card is a concept itself or step
on it is a concept itself and not a
combination of three different ways
are there any other yeah what kind of
performance tests have you done to
compare it to sort of more bag of words
construct because that even though it's
simple people say it works surprisingly
better than you'd think so like well
make it a big of words construct where
you just completely throw away any
ordering information you could get from
the words and make sure just answering
just entering keywords at the end not
related yeah well just just talking
about the counts of different word
occurrences in the article and for
catterick categorization purposes how
does disk and how much extra performance
boost you get in categorization by
adding the complete but yeah using this
technology the actual booth in terms of
precision of the categorization or India
a search test yeah just the I'm using an
example we in the moment when the
categorization exercise becomes more
complex so you don't work out of 20
categories 25 categories but you work in
the hundreds we have real cases real
customer scenario for example one case
in the in the pharmaceutical industry
where we were scoring or actually one
better cases in the for a news news news
feed for a publishing company we were
scoring a precision of 85 86 percent on
a category 30 hundreds of categories
that before they were doing it manual
they were scoring eighty-five percent
and with a statistic tool with that
number of categories we're not going
beyond fifty-three fifty-four percent
okay so that's the kind of obviously
this is not a fixed number if your
categories are ten or twenty you don't
have the kind of difference in the
performance the more you go into really
you need to understand granularly the
content the better this gap grows okay
okay
did I answer your pressing not really
yeah it's just wondering vieni charts
now you have a case study it's a
customer implementation the one I was
talking before um it's something that we
can unfortunate mark is not on the phone
rang like something that we can provide
you so my iphone can take a note of an
okay hello hi do you are you have any
plans on releasing your souped-up
wordnet or at least through a service or
you just is it through service like d
are you gonna release it to public
interest at all because public interest
there right now it's something that
we're thinking of okay okay right now it
seems like a tremendous resource yeah
and that's the reason why we're thinking
of buying doing this okay yeah we one
thing that we are evaluating is in terms
of in terms of business if you want to
be sure that we have a module attached
that we can support at the end of a but
that's one of the IDM the what we really
want to to do is to create a service
that can be an enabler for in this case
the semantic advertisement that could be
an enabler of semantic web applications
if you want you know like being able to
throw a text to and get back the tag the
tag information yeah so that's that's
the direction we are thinking about
going I'd thank you if you would cuz
weird net seems like a good idea but
when you use it it doesn't really work
very well that's annoying so anyway ok
so we count one additional vote in favor
of it hi hi I'm red I was wondering um
so you have linguistic experts
determining the semantic relevance
determining the semantics semantics
relevant since of so we have a linguist
expert the
in creating the semantic net for example
assign the right attribute to each of
the concept okay so for example the verb
to serve in a with the meaning of
serving like volleyball or it's linked
strictly linked to the domain of sport
okay because it's usually used only what
that meaning is using only using that
domain so that kind of exercise is done
by expert linguists in the moment when
the semantic net is enriched there's an
analysis of this kind and this attribute
assigned to each concept in terms of the
evaluating the relevancy inside attacks
this is actually a result of the
automatic analysis is not something that
you need to if you want customized all
the time okay it's something that once
that the knowledge is there then it is
used for the analysis name ok so the
okay so there is a like a relevant
standard that is yeah relevance I guess
I guess I'm actually more curious about
the how the semantic relevance either is
determined I always the termination or
yeah or or how it relates to the social
relevance or if that even if that is a
factor um so in in determine that the
the semantic relevancy inside inside an
article are taken into in the algal the
algorithm takes into consideration the
result of typical linguistic studies
okay so you know like in a language a
subject is more rare and making it easy
but the subject is more relevant of an
object in terms of the funny what is an
important element inside that something
that is written the beginning of
paragraph tend to be more relevant than
something written in the last line of
the paragraph this make it very simple
all this is built in the algorithm that
understand for example that john mccain
is the most important element in this
article okay so all of this is part of
so the algorithm is the result of the
typical and linguistic analysis the
result of a linguistic work but when it
is applied is applied independently from
the domain unless you do some
customization to change this relevancy
based on the domain which is not the
case of the of the demo that I did today
okay okay thank you thank you i looks
like mr. questions oh great question
question of Anita it wasn't clear
earlier whether the linguist I mean the
does how the relation between two
concept the weight between the concept a
and concept be in your oncology is
established that is you seem to be
suggesting that it's done by by hand by
linguist experts and I guess what I was
wondering about is how confident you can
be or how comfy how well can a person
say 86.5 rather than point six then
rather than point seven and you know
what kind of over had eventually this
this requires you know in terms of human
effort um when you when you're you're
saying the weight of the links are you
referring to the semantic network yes I
was referring to essentially your
ontology okay know for example that you
know a hummingbird is a kind of bird and
an ostrich is a kind of bird but you
know they're somewhat differently so you
know there is some sort of product
typical thing you know profit something
some items are political instances of a
concept and others are much more distant
do you model this in your own ecology at
all are much more distant by in your
example I I mean one my
send what the distance is in your
example if you are two different kinds
of birds there are two different kinds
of birds maybe one is most common common
the Wallaby honor another one less
common but in either in a in a link in
one of the link like for example in this
kind of link which is the kind of what
you find here on the right is the kind
of gasoline and there might be some kind
of heaven after if you want so there's a
degree of separation that is makes a
kind of even afta not directly linked to
gasoline but more to heaven after but if
you use this only this kind of
relationship I don't that there's not a
weight associated to the part of
relationship okay that all if you want a
hundred percent part of relationship did
I answer yeah okay I understand
understand correctly answer is that
actually all the relations are binary
relations you know you have them
organics okay much more clear that's
exactly okay since it's twelve o'clock
um we better end but i think our speaker
would be happy to answer questions or
have people join us for lunch or give
out business cards if you'd like further
contact and if you send me the slide so
i'll make them available to Googlers so
Thank You Luca thank you very much
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>