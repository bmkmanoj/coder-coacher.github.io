<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AQC 2016 - Adiabatic Quantum Computer vs. Diffusion Monte Carlo | Coder Coacher - Coaching Coders</title><meta content="AQC 2016 - Adiabatic Quantum Computer vs. Diffusion Monte Carlo - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AQC 2016 - Adiabatic Quantum Computer vs. Diffusion Monte Carlo</b></h2><h5 class="post__date">2016-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/D7FIHejPA68" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thanks so this is joint work with
Michael Jarrett and Brad Lackey at NIST
and the University of Maryland so the
central topic of this talk is in some
sense something we've discussed before
which is stochasticity and just as a
reminder the definition of that is a
matrix is stochastic if all of its off
diagonal elements are non positive and
most research into adiabatic quantum
computing both experimental and
theoretical focuses on stochastic
hamiltonians though not all and by the
peril and 4b Gnaeus theorem we know that
stochastic hamiltonians have a ground
state which can be expressed using all
real positive amplitudes and if you go
to someone who does say a practitioner
of quantum Monte Carlo simulations what
they might tell you is that oh well
these we should have no problem
simulating these Hamiltonians with our
algorithms because there's no sign
problem and so if you're someone who's
interested in using adiabatic quantum
computers to solve problems that you
can't solve classically then you should
take this statement very seriously so is
it true that these classical algorithms
can always simulate what you do with
these stochastic adiabatic computations
if so then that detracts from the
motivation i would say for building
adiabatic hardware at least 0 plastic
hardware although of course i'm going to
approach this from the point of view if
asymptotic complexity what's polynomial
what's exponential but of course even
there are more fine-grained questions
one could ask about finite size
instances so let's look at what these
Monte Carlo algorithms for simulating
these hamiltonians are the most widely
used as far as I understand is path
integral Monte Carlo and earlier in this
conference there have been some nice
talks such as by Elizabeth cross in an
Arum harrow about proving that under
certain circumstances path integral
Monte Carlo can be proven to converge
efficiently and in practice it's a
pretty effective method and on the other
hand there was a very interesting paper
by Matt Hastings in 2013 which showed
that even without the sign problem there
are certain instances that you can
construct where you can show that the
path integral Monte Carlo method will
fail to converge in polynomial time even
though the stochastic adiabatic dynamics
that it's trying to simulate is one that
has a polynomial size I ghen value gap
and the essence of his examples was to
construct energy landscapes where the
world lines get tangled around some kind
of topological obstacles so in pathan
equal Monte Carlo you have a Markov
chain and the objects that are sort of
hopping around according to this Markov
chain our world lines and you need them
to equilibrate and if they get tangled
around certain kinds of things you can
show that they won't equilibrate so
that's in some sense good news for
adiabatic quantum computation it shows
that at least in the worst case this
will fail to work and there are some
instances there exists some instances
although rather contrived ones where you
can prove that that you can't do this
classically by this method so more
generally you can phrase this as kind of
a fundamental complexity theory question
you can define a model of computation
based on stochastic ground state
adiabatic computation and you can say
well where does this lie between
classical and quantum computation what
is the set of problems that you could
solve in polynomial time within this
model and so here are some definitions p
polynomial time classical computing b QP
universal quantum computer includes
factoring and all that and i'll call
this stock p following scott Aaronson's
convention polynomial x 2
astic adiabatic computing and there's
actually fairly good complexity
theoretic evidence to think that or at
least some complexity theoretic evidence
to think that stochastic adiabatic
quantum computation can't do Universal
quantum computation if it could then
that would mean that b QP is in the
third level of the polynomial hierarchy
which is I think generally believed not
to be the case so the two most plausible
scenarios at this point are either
stochastic polynomial time equals P or
it lies somewhere intermediate between p
and b QP classical and quantum and so
what hastings uh paper shows is that
proving that stochastic polynomial time
is contained in in classical polynomial
time that proof cannot be achieved by
rigor izing path integral monte carlo
and putting general purpose runtime
bounds on it that's the worded that
proof path is thwarted by topological
obstructions but there's other kinds of
Monte Carlo that you can analyze and
perhaps the second most popular type of
Monte Carlo are things that are
sometimes called diffusion Monte Carlo
this actually goes by many different
names you could call it population Monte
Carlo there are in the computer science
literature there are things called the
go with the winners algorithms which are
quite similar in flavor but the
essential idea here is well let's think
about why it's hard to simulate quantum
computations classically and one of the
reasons is that the quantum state vector
of n qubits is 2 to the N dimensional so
if you have maybe a hundred qubits then
even Google can't store that much data
but on the other hand maybe that's okay
because probability distribution over n
coins is also some 2 to the N
dimensional vector and so if your wave
function is all positive then it's
proportional to a probability
distribution is just normalized
differently and so what you could try to
do is you could instead of trying to
store the wave vector on your
computer's memory you can just have your
computer inhabit this probability
distribution as a probability
distribution and so the key point to
designing a diffusion Monte Carlo
algorithm is to design some kind of
stochastic process some Markov chain
perhaps that converges rapidly to the
desired distribution which is the ground
state proportional the ground state wave
function so what we decided to do is
make the simplest most stripped-down
variant of diffusion Monte Carlo that we
could not for the purpose of necessarily
getting a really efficient practice
algorithm in practice but something that
we can analyze and we call it subsequent
Carlo I don't think it's very distinct
from other things that people have that
people typically do but what it
specifically is is we take Schrodinger's
equation and we switch to imaginary time
so now it's something that will drive
you into the ground state of the
Hamiltonian because all the excited
states will decay away exponentially and
if this Hamiltonian is stochastic then
you can interpret this as a diffusion
equation except that the total norm of
this vector which you this the sum of
the entries in this vector which you can
interpret as the sum of the
probabilities is something that's going
to shrink as a function of time unless
the ground energy happens to be 0 and so
then you can further interpret that as
some kind of continuous-time random walk
and what it means for this probability
total probability to shrink is that the
product the walkers have some
probability of dying at any given moment
and so then you have some population of
walkers that you track once you
discretize the time evolution defined by
this diffusion equation you have some
kind of a substitute markov chain you
have these little subtlety matrices just
obtained by Taylor expanding the
exponential at each little time step
and the walkers are at each time step
either hopping to another bit string
dying off or reproducing so the point is
that we can't really afford to have the
population of the walkers exponentially
decaying over the course of our time
evolution otherwise we'd have to start
with exponentially many walkers at the
beginning if we run out of walkers
there's nothing left for the algorithm
to do and it just ends so you need to
come up with some way of replenishing
the walkers we did some computer
experiments with several different
methods but they all are of the same
general flavor which is that we
replenish the population by spawning new
walkers on the sites of the survivors
after each step and if you choose the
probabilities by which the walkers
either take a step die off if they're on
a high energy potential or reproduce if
they're on a low energy potential you
can guarantee that the limiting
distribution of this walk is
proportional to the ground state wave
function of your Hamiltonian and if you
examine what happens in an algorithm
like this you'll notice that there's
something that looks very much like sort
of a classical analog of tunneling
because what can happen is that a walker
dies off at a high potential and sort of
responds or gets resurrected at the
location of some randomly chosen other
walker that's at a lower value of the of
the objective function of the potential
energy and this kind of mimics something
that's very similar to quantum tunneling
here's a numerical example we ran it's
everyone's favorite example the ramp
with the the spike and you can see so
that at the beginning the distribution
is a binomial that's centered around 0
at the Hamming weight in over two and
then you turn up the potential and this
binomial ramps down and at some point
here this is where we're hitting the
spike which is that Hamming weight I
guess five or something and there are
some walkers that are left over
underneath from earlier points and walk
on this side can die and and respawn on
the other side and you can tunnel across
this barrier that's the idea so there's
some question here about whether
tunneling is truly from a computational
point of view is truly a uniquely
quantum effect more broadly you could
even say if you think about stochastic
adiabatic computation what ingredients
of quantum pneus do you have do you have
entanglement yes you have some
entanglement there do you have
superposition over an exponentially
large state space yes do you have
interference well maybe not I mean the
ground state is at all times something
with all positive amplitudes there's no
manifest interference in this process
and there's kind of I would say a
fundamental conceptual question at stake
which is is interference and necessary
ingredient for exponential quantum
speedups so attempting hypothesis which
you might propose is that if you have
some stochastic Hamiltonian with a
polynomial gap then you can always track
the instantaneous ground state
probability distribution using a
classical efficient algorithm so we need
a probability distribution which is
proportional the ground state but just
normalized but it turns out that this
hypothesis is false we were able to
construct counter examples where you can
show that the diffusion Monte Carlo our
subsequent eye color fails to converge
this distribution and the basic idea is
that while you can tunnel if there's
some walkers on the other side and
there's some probability for a walker to
be on the other side which is defined by
the wave function and if the number of
walkers is smaller than went over that
probability then probably there's none
there and you're just not going to
tunnel so in quantum mechanics of
private distributions promotionals size
squared you can tunnel across more or
less if that probability to be on the
other side is not too small on the
barrier but you can tune the potential
so that this other normalization of your
private
distribution which comes from the l1
norm and which comes from the classical
case differs exponentially from the
quantum case in an exponentially big
vectors l1 and l2 normalization can be
very different and in that case you can
tune things so that the adiabatic
quantum algorithm will succeed but Monte
Carlo fails and the way it works is it's
just another variant of this rampant a
spike case we tune this ramp so that the
size squared down here is order 1 side
of what divided by the sum of the side
that one normalized version the
probability distribution that diffusion
Monte Carlo and related algorithms
sample from is exponentially small there
and then we lower a basin here the
quantum case will pour pour into this
basin and the classical algorithm will
never find it because the probability of
a walker ever landing there notice
noticing that this potential energy
basin is turning on is is exponentially
small and we can prove that the gap is
polynomial in the quantum case so that
hypothesis I made is false and that's
another piece of good news for adiabatic
quantum computation with stochastic
hamiltonians so on the other hand we can
also take the practical point of view
let's try running this algorithm on some
real problems on some will take some
optimization problems right down the
standard adiabatic optimization
algorithm for solving these and simulate
that adiabatic process using our sub
stochastic Monte Carlo code and so the
problems we picked were sad and Mac set
just because they're kind of standard
benchmark problems they're sort of like
the the fruit fly or the lab rat
standard lab rat of biology is max a SAT
and Mac set for combinatorial
optimization and an amusing fact is that
every year there's a competition which
is held for the fastest solvers of SAT
and Mac sets so we have a lot of data to
sort of benchmark against we know at the
state of the art is on these benchmark
processes so we ran our code
and it's not competitive with top sat
solvers SAT turns out in practice is
very different from Mac set because the
fact that you know that there is a
completely satisfying assignment allows
you to do a lot of algebraic
manipulations to your instance sort of
eliminating possibilities canceling out
variables and so on on the other hand
for Mac set our algorithm which recall
we could prove sometimes fails to
converge it can take exponential time on
the other hand on this ensemble of
instances it worked much better than we
expected and so we really had to savor
that it's it's so rare and research that
something works better than you expect
but that was the case and in fact our
simulation of this quantum process even
forgetting that we care about quantum
mechanics at all we could just pretend
that our original goal was to solve
these optimization problems it actually
is very successful on certain classes of
instances the max three set random
instances it actually was superior to
the winner of last year's contest so we
entered it in this year's contest I
think we would have had a chance except
for the fact that helmet has also
entered his code into this contest but
we'll see in a week what happens here
are some more data ours is the blue line
this is showing how long it takes to
solve these instances the only problem
is there's a couple of instances there's
a total I think maybe 200 benchmarking
instances last year there were like two
or three over here that our software
just choked on I can't I'm not exactly
sure why but for you know a large
majority of things our software not only
solved them would solve them faster than
than the previous state-of-the-art
things so to summarize we looked at
subsequent Carlo as an example of
diffusion Monte Carlo and three possible
goals you might have for this are maybe
this could be a useful numerical tool
for understanding adiabatic quantum
computation and well we haven't really
pursued that yet but that might be
something for the future could this type
of algorithm any be you
to prove that adiabatic quantum
computation with stochastic Hamiltonians
is actually contained in P that it's
incapable of exponential speed-up well
apparently not due to these l1
normalization vs el to normalization
barriers that we observed I should
mention that I think this l1 versus l2
is is sort of a known issue at the
folklore level I'm not sure that it's a
completely new idea but we actually
explicitly proved this and is it a fast
classical algorithm for combinatorial
optimization that's the third goal we
could put on there i think it was
actually Eddie far his suggestion that
we try this and that was a very good
suggestion because it turned out that
yes it was surprisingly good and before
concluding I should mention one last
thing that these barriers really apply
to anything where you're trying to track
something that's proportional to psy a
probability distribution is proportional
to psy rather than side squared so that
includes pretty much most variants of
diffusion Monte Carlo and also it
includes some forms of path integral
Monte Carlo with open boundary
conditions so we don't know where
stochastic computation lies between p
and b QP but maybe this is another piece
of evidence that it's really something
intermediate and it's not just equal to
classical computing asymptotically so
that's all and thank you for your
attention
I think we have time for one or two
quick questions so um applying this
exponential operator or be serious right
I mean um you said that some workers die
but I mean ding what do you do I me like
you clone the workers that are still
alive I mean you make copies of them and
you keep going um yeah we actually tried
three different methods for replenishing
the walkers the one that worked the best
is that the walkers on the low-energy
sites the lowest energy sites had some
probability of reproducing into two
walkers so it's kind of like you have
some bacteria and they hop around
diffusive Lee in the ones where there's
lots of food they reproduce in the ones
that there's a little bit of food they
die off it's that style of algorithm but
we tried another one which was when a
walker dies it just instantly teleports
to the location of a random uniformly
randomly selected other walker that you
can also prove converges to the right
thing but just in practice it didn't
converge quite as well for these
optimization problems it seemed like
okay so i don't believe that that is
this equivalence between the diffusion
montecarlo but it's a grossly there
should be different to the dynamics in
but integral andhra state you have a
still a finite number of replicas that
can tunnel even if there is no other
things in the other world instead in
diffusion needs something to be arrayed
in the other well know in order to yeah
so that perhaps I misspoke a little I
don't mean to suggest that open boundary
condition path undergo Monte Carlo is
equivalent to diffusion Monte Carlo they
share some shared features but I mean
basically the status right now is we
don't have as far as I'm aware any
really plausible candidate of a single
classical algorithm that could have
provable polynomial convergence for
simulating all still classic adiabatic
processes the path integral ones
be thwarted by these topological
barriers and the diffusion style ones
can be thwarted by these l1 versus l2
barriers so that's that's all I really
mean to say
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>