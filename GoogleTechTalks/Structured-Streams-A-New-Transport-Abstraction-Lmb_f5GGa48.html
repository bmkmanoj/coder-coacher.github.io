<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Structured Streams: A New Transport Abstraction | Coder Coacher - Coaching Coders</title><meta content="Structured Streams: A New Transport Abstraction - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Structured Streams: A New Transport Abstraction</b></h2><h5 class="post__date">2007-12-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Lmb_f5GGa48" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">a great opportunity to hear Brian Ford
who's a student of Franz kasha
he's going to be telling us about
structured streams and approached for
new transport directions and I turn it
over to Brian thank you it's very nice
to be here so today I wanted to talk
about transport abstractions and as I
didn't just turn okay as you're probably
all familiar with the internet protocols
currently provide basically two standard
transport abstractions for applications
to use streams and data grams and I
assume you're all familiar with their
general properties so but I want to in
this talk I want to propose that there's
sort of a problem with both abstractions
first of all the the very very
simplistic version is that streams
aren't quite the out what the
applications need whereas datagrams
really don't do much of much of anything
for the application or just don't
provide enough functionality and of
course I want to propose a solution so
to introduce the basic idea I want to
look at how applications use
conventional TCP streams first of all
and i'm going to contrast two different
approaches the first approach i call the
natural approach and this is to use a
stream as to represent an application
data unit or a logical transaction or
logical communication activity and i
want to suggest that this this approach
sort of corresponds to something that
Clark Intendant house proposed quite a
number of years ago in their well-known
paper on on application level framing
and where they introduced this concept
of application data units to give an
example of what this means take for
example HTTP 1.1 point 0 the the first
version of HTTP where a web clients used
to used one tcp stream per transaction
when when it wanted to make a request it
would open the TCP stream
request received the response on the
same stream and closed the stream if it
one wants to make multiple responses to
multiple transactions to get the images
on the page and stuff it opens
additional requests either additional
streams either sequentially or in
parallel depending on what the
application is trying to do so this this
approach has has some nice sort of
semantic advantages first of all it ends
up falling out the TCP provides the
application reliability and ordering
within a transaction while keeping
different transactions independent and
ability to operate in parallel with no
no interdependencies and and again to
bring up this idea of this being sort of
so sort of representing what onion
implementation or expression of what
Clark and hit that tenant house might
have been having in mind I haven't
actually been able to ask them in person
yet I would like to but with the idea of
application layer framing unfortunately
this approach to using TCP has a lot of
serious disadvantages they're all
practical first of all you you have a
serious set-up cost setup delays the 33
Way handshake at the beginning followed
by a slow additional round trip delays
to get the congestion control slow
started after you closed the stream you
got to keep the state around for four
minutes at least on one side and then it
has cost in the network in state in in
Mitter middleboxes now network address
translators &amp;amp; firewalls and of course
finally if you've got an application
that uses 10 concurrence dreams then
that application is being ten times as
aggressive as as the application is
competing with that's only using one one
stream yeah
I propose that these are not
disadvantages of the method but
disadvantages of TCP yes I completely
agree and so in contrast so is so
because of because of these
disadvantages people don't use that
natural approach instead people use what
I call the practical approach which is
to use a TCP stream as a session so for
example you know the quintessential
example is like ssh year the client
opens up a connection you know doesn't
does a bunch of commands and responses
and throughout an entire session but
other other you know most protocol's
these these days actually use this
approach like email you know you the the
pop client connects to the server
downloads a bunch of email over the same
TCP stream current HTTP 1.1 browsers do
the same thing that they open one or two
TCP streams and then successively use
that stream for a bunch of different
requests so this you know that nicely
solves the the practical difficulties of
the natural approach by amortize the
costs of TCP streams across many many
application data units or many
transactions unfortunately it sort of
blows away some of the nice semantic
features we we had with the natural
approach in that it's TCPS reliability
and ordering now applies across many
application data units instead of one
and there's nothing the application can
do about that so this creates
unnecessary serialization if if the
application is putting multiple things
on the same stream the things that come
later have to wait until the things that
that are before to get through the
pipeline and this creates head of line
blocking problems to where if one packet
gets lost somewhere in the TCP stream
everything behind it has to wait and
this is this is why for example delay
sensitive media streaming you know over
tcp is a bad idea and it's also why it
was it was discovered that
at least in some cases HTTP 1.1 made web
browsers appear or feel slower to users
then than they did with HTTP 1.0 even
though they make use it more efficient
use of the network and finally of course
it just makes applications more
complicated because they have to deal
with multiplexing lots of transactions
and pipelining and stuff like that and
you know for example there's witness HD
HTTP 1.1 pipelining which still isn't
widely used seven years after the spec
came out because you know some servers
just can't quite get pipelining right so
you know obviously we can always scrap
TCP and just have the application use
use datagrams but of course then you
know the application really has to do a
lot itself and this leads to you know
complexity fragility duplication of
effort in application protocols there's
a lot of this stuff that is really
common to lots of different applications
you know we'd like to share that it
across applications and so I want to
propose you know that that we don't
actually give up on TCP we just fix it
if we don't give up on the stream
abstraction is it fix the stream
abstraction and so I'm going to propose
these three basic goals for what we
would really like out of streams first
of all this stream should be cheap so
the application can use one stream per
transaction or adu efficiently it should
keep streams independent just like in
the HTTP 1.0 model so that so that the
applications can take advantage of
natural parallelism and it and since
we're proposing since I'm proposing that
the applications are going to end up
using a lot of streams we need to make
sure they're relatively easy to manage
so the application doesn't have to go
through the whole bind allocate IPO fort
numbers authenticating separately each
new stream and stuff like that it should
be simple to use and so to satisfy this
I proposed the idea of structured
streams what is a structured stream well
basically it's a TCP stream except with
a fork for
function added sort of like a like you
do with UNIX processes except now you do
that with streams too so say a web
client opens a connection to the web to
a web server this is a top-level
connection and then it decides it needs
to download some pages it sort of forks
off of the the top-level connection a
child connection a child's dream for you
know a given HTML page for example in
them you know within that HTML page as
it's downloading the HTML it finds some
images it Forks off some some grandchild
streams to download those images this is
just just an example to give you a idea
of the model and how does this
specifically appear to the application
in terms of API for example well
basically it's it's not a not a very big
modification as far as the application
is concerned all we're doing is giving
the application to listen on on
something other than a listen socket you
know you allow the application to listen
and connect on an existing connected
socket in order to create child streams
from that socket and when the
application when the initiator connects
on an existing child's on an existing
stream the responder gets the new
connection in risk reference to the same
parrot the corresponding parents dream
so that the the transport maintains the
association between parent and child
across the initiator between the two
hosts so that's the basic idea now I
want to dive into what this actually
means as far as implementing this idea
in a transport protocol how the SSD
protocol is designed to do to support
this efficiently on the I'll briefly
talk about the current prototype
implementation evaluation related work
in a little future work yeah and finally
conclude so the SST protocol provides a
number of transport services some of
these services are e
are provided independently for each
stream in other words each stream gets
it gets ordering reliable delivery and
flow control receiver directed flow
control independent of every other
stream whereas other other transport
services are shared among all the
streams such as congestion control we
relate replay and hijacking protection
and a SSD provides optional transport
layer security although I won't have
time to talk about that so what so what
does this mean in in terms of the
structure of SST well SST is is divided
sort of into two general layers the most
important components are what I call the
channel protocol which creates a sort of
intermediate level transport abstraction
which implements the parts of the
transport it implements the transport
services that are shared among all
streams and then on top of that we build
the stream protocol which implements the
transport layer services that are
provided individually for each stream to
give you an idea of how this how these
trans at these abstractions play out in
the network SST assumes that at the at
the bottom level at IP or UDP level it
has it has just an unconnected pack
adori and a delivery service of some
kind to work with and on top of that the
channel protocol implement a connection
oriented but still unreliable packet
delivery abstraction that implements
these these transport common transport
services like like security congestion
control things like that and then
finally the stream protocol takes all
the applications streams and multiplexes
them onto one or at most a few a few
channels and channels in fact channels
actually potentially have a long but
limited lifetime and so so that
the stream protocol may sometimes have
to migrate streams from one channel to
another although I probably won't have
time to talk about that much here um no
I wasn't aware okay thank you okay
thanks yeah um so just to provide an
idea of sort of the mechanics of what an
SSD packet looks like on the wire on
basically it it starts with a channel
header which contains information like
identifying the channel packet
sequencing and acknowledgment
information to provide the congestion
control support that that's implemented
in the channel protocol then followed by
a stream header that that's that the
stream protocol controls which
identifies a stream within a channel
provides flow control and bite
sequencing and stuff like that finally
the application payload and the message
authentication check provided by the
channel protocol so I'm just going to
touch on a few highlights on the channel
on the channel protocol but before
dividing into the the streaming protocol
which is I think the the most
interesting part as far as what's unique
with with SST so I'm just going to
introduce the aspects of the channel
protocol that are important to
understand how how SST works so so the
main the main important things that
provides our sequencing acknowledgement
and congestion control so if the channel
protocol assigns us a fresh sequence
number to every transmission including
acknowledgments and retransmissions of
old data so in this respect it operates
a lot like DC CP if you're if you're
familiar with that protocol
oops it also includes acknowledgement
information in every packet all
acknowledgments are selective they you
always you don't acknowledge a
cumulative point but you only
acknowledge specific specific packets or
specific ranges of packets that you've
received each packet contains fields to
acknowledge exactly one sequence range
and typically as the receiver receives
accumulates packets in sequence it you
know sort of builds their builds the
range and sends overlapping
acknowledgments which provides
redundancy against lost acts and and
stuff like that without actually
incurring the the complexity and and and
protocol header overhead of dealing with
variable length sac headers and stuff
like that so I'm just trying to provide
sort of the benefits of sac without the
without all the complexity and finally
using this acknowledgement this sequence
numbering and acknowledgement
information the channel protocol
implements congestion control so that
all of the streams that get multiplexed
on to a particular channel automatically
the share share the same congestion
control state and I'm not actually going
to talk much about congestion control
currently SST just uses more or less
standard TCP congestion control it
doesn't doesn't try to innovate in that
respect the important point is just that
the congestion control is associated
with a channel so with that I'm going to
dive into the more interesting part the
the stream protocol itself how we create
these structured streams for the
application and sort of the Mo's some of
the mo the most interesting or the most
critical parts are how we create streams
transfer data on them and then I'm going
to talk about how how we can emulate in
SST sort of
traditional data ground give
applications a Datagram abstraction as
well as a stream abstraction when the
application needs it so so our goal in
the stream creation mechanism is to make
make allow the application to create
streams rapidly and without having to
wait for a three-way handshaking delay
on startup and this is a challenge for
for two reasons first of all you know
suppose we you know that the transport
sends a create stream packet I'm then
without waiting for the three-way
handshake it immediately started sending
data on this stream well what would what
would the receiver do if the create
stream packet got lost but the data
arrived you know then you've got got a
problem a second problem is that how
does this initiator even know how much
data the the receiver is willing to
accept on this new stream given that it
hasn't had time to get its first receive
window update yet so these are SST
solves these two challenges as follows
for the first one they it's very simple
actually eat every SST packet within the
first this first round round trip time
before the initiator has gotten the
first response on the new stream carries
both the parent and child stream
information in other words it carries
all of the information necessary each
packet in the first round trip carries
all of the information necessary for the
receiver to to create this the new
stream state and figure out what's going
on no matter which which of those
packets arrive and which are dropped and
to solve the flow control issue
basically we take advantage of the the
Hyatt the hereditary relationship of
streams at parent and child's dreams by
saying that any data this the parents
ends in this initial round trip before
it's received the first window update is
actually deducted from the pair
currents flow control window rather than
the child's which doesn't exist yet so
after this initial round trip things get
a lot simpler and basically they go back
to the way they are in TCP where you
know we have byte sequence numbers with
a 32-bit wraparound just just like in
TCP you know on an effectively unlimited
lifetime and so I won't really say say
more about that for now so the other
sort of interesting thing about the the
stream protocol is how it can be because
it supports the nut the ability to use
streams in a fine-grain fashion it
allows the application to use streams in
place in places where traditionally the
application might use a Datagram
transport like UDP or DC CP directly and
well why would you want to do this I'll
get to that but SS in SST SST treats
datagrams as ephemeral streams so it
provides an operation called you know
send Datagram receive Datagram but the
same Datagram operation is semantically
equivalent to creating a child's dream
sending the Datagram content on that
child's dream and then closing the child
street and then SST provides an offer an
option to say to tell it not to you know
buffer the the data and retransmitted
you know if the if the receiver doesn't
get it the first time it's lost and the
receiver effectively gets a reset yeah
so so that's well normally if the if the
application doesn't give SST this
indication that it shouldn't buffer the
data the SST will buffer buffer that
keep the data buffered until it receives
acknowledgments that the receiver has
actually gotten those it so it provides
you know reliable TCP like semantics by
default with well this is just an option
to turn the transport buffering off on
the sender so that the the transport
just you know sends the data and you
know if it doesn't get there then sorry
the receiver is just going to get a
stream reset when it realizes that data
isn't anywhere anymore so yeah so oh oh
sorry yeah
so
yes yeah so so from from a normal
ephemeral stream packets are everything
is still acknowledged and and is is
reliable by default unless the
application tells the sender don't don't
not to buffer but if the application
tells SST not to not to buffer this
Datagram that it should be unreliable
SST actually has the option of
optimizing it a little a little further
so SST can take a look at this Datagram
that the application is trying to stand
and say is you know well is it small you
know for some suitable definition of
small which SST gets to decide if it is
SST can use use a optimization in which
it never actually bothers assigning a
child stream identifier and um and you
know do it creating the child's dream
state and destroying it and all that
instead it just uses delivers the entire
Datagram in a continuing a contiguous
sequence of packets I indexed by the
channel protocols packet sequence number
and basically sends it use in unreliable
fashion much like would be done in in in
other Datagram Datagram oriented
transports and so this makes delivery of
small datagrams just as efficient in
theory anyway as Datagram oriented
transports on the other hand this is
always up the decision to do this is up
to SST so for example if the Datagram is
too large for example you know above the
8k limit of or you know whatever limit
of what what it thinks will get to the
other end fairly reliability reliably it
can just choose to disable this
optimization and fall back on actually
you know creating a child's dream and
using it and what this means to the
application is that SST you know can
serve as a
datagram transport with no effective
Datagram size limit it can send very
small datagrams efficiently and also
very large data grounds potentially so
that's there there are other interesting
details of the the protocol of course
that you know I refer to the paper or we
can talk about offline but so yeah yeah
mm-hmm you're defaulting to reliable
what are the ordering guarantees in
particular in a stream a stream carries
both data and forks of other streams yes
is that a full order on the given stream
of both the data and the forks of the
other frames so within so within a given
stream only the data is ordered the
forks of child's dreams from from a
given stream have no ordering
relationship did different Street so if
I if I fork off several three different
sub streams to from some existing
existing stream than those connection
attempts I will still be associated
reliably associated on the receiver with
the the correct parents dream but they
may get out of out of order with with
respect to each other just like if you
if you you know initiated three
simultaneous top-level stream initiated
initiation attach those could get
disordered in the same way and so okay
and everything we're talking about is
between a single sending machine and a
single receiving machine presumably in
the normal case over a typical path over
a singer behalf of the network yeah um
so the benefit of enabling reordering
would seem to only occur when there's a
significant dropped packet so let me let
me address that later I think it'll be
addressed it and
okay so just to just to give an overview
of the current prototype implementation
it's I've implemented a prototype in
user space using C++ it's intended to be
easily you know link linked with
existing applications and portable you
know for easy deployability and testing
and it currently runs runs a top UDP
rather than directly a top I p besides
the obvious reason for this which is
applications can only get get to UDP
normally there's another nice advantage
of this namely it gets across Nats and
firewalls that would otherwise have no
idea how do what to do with an SST
package it's about 13,000 lines of code
now it's available to browser download
if you if you for anyone who's
interested and I'm not going to talk a
lot about the performance sort of there
there are some information and
evaluation in the paper on for example
against native TCP you know it sort of
does what you expect it it performs
reasonably well if you're if you're over
dsl or Wi-Fi kind of speeds but if you
want if you want to run it on you know
gigabit ethernet or something we'll
probably want a more more efficient
kernel level implementation and you know
something like that and it's TCP
friendly the which is no surprise
because it just implements more or less
TCP congestion control then all the
paper includes a couple micro micro
benchmarks and Anna in a web browsing
workload just to give sort of a flavor
of of what it what it is the the micro
benchmark basically is it just it
compares a simple request response a
protocol like like an HTTP 1.0 over
either
CP or UDP versus SST and basically the
the upshot the only take home point of
this is that at the 44 small transaction
sizes SST sort of gives you the the one
round-trip latency that UDP does but it
can still scale to large transaction
sizes like TCP does then I also did sort
of a trace based simulation of web
workloads based on the the Berkeley tres
tres set that's available online for
basically simulating the behavior of a
web browser talking to a web server
downloading web pages containing images
and other things that can be downloaded
in parallel and just comparing the
behavior of of of a naive you know web
client based on SST which just sort of
always uses one stream for transaction
and downloads everything in you know as
parallel as it can as eagerly as it can
vs vs different versions and styles of
HTTP the HTTP protocol over TCP and you
know the only the main point there is
that it basically provides this
equivalent performance as pipelined HTTP
1.1 without you know without the
application having to deal with
pipelining and stuff like that so but
the reason I'm skimming over all this
stuff quickly is because I don't think
that's the most interesting thing you
know what's interesting about SST is
well besides the the application model
it provides for for programming
transports it can make make it easy for
applications to to be made more
responsive this is because I SST
eliminates the unnecessary serialization
that the TCP imposes and and also by
allowing the application to create a
female sub streams
it provides a very convenient and simple
out-of-band communication method for
applications and so to give an example
of one thing applications can do with
this I'm going to show how how a web
client can talk with a web server to
Diana dynamically prioritizing and and
reorder requests outstanding requests
and I'm not going to show this with a
little demo so this is the SST this is a
simple web client running with SST / a
simulated network but in in real time
over a simulated modem speed 56k bit per
second network downloading a webpage
with lots of images and currently it's
emulating the behavior of HTTP 1.1 with
with two concurrent streams basically so
you know that downloads the pages as the
the images as it gets to them but if the
user you know Scrolls somewhere far the
far down in the page or clicks to a
hyperlink somewhere else in the page you
know the user sitting there waiting for
a while you know we don't like that so
with SST it's very easy to out for the
application to do something like just
fire off all of the images requests as
soon as it gets the HTML and then tell
the web server okay but these are the
images that are on the screen right now
can you send those first and if the user
then changes that you know Scrolls to
somewhere else on the screen the the
client can open up ephemeral sub streams
on the on the on the you know downloads
that it wants to reprioritize and say
hey change the priority of this image
down and chain and bump the priority of
that image up and you know give me those
first and so the application can even
you know do you know basically whatever
at once with this like you know download
the image under the cursor first and
then the images the other
on the web page and then than other
invisible images and so you know in
summary this is you know i'm not going
to propose that you know there's no
other way to do this but you know the
point is that SST makes makes this kind
of thing very easy to applicate for
applications to do and i think there are
a lot of different kinds of applications
that can benefit from this yeah that's
that's in this in this case that's just
application so so it's just the the
client application has this you know
jiff down jpg download session going on
you know several jpg download and
streams when the client application
wants to wants to tell the server to
change the priority it opens it opens a
new child stream on you know that on the
down the jpeg download stream that it
wants to change priority sends a 4-byte
you know priority change message and and
the server gets that and the server
tells its SST stack to repro you know
reprioritize the transmit queue
basically and so I well I had to add
that so yeah yeah so so this this
obviously requires that the application
know how to how to do this and how to
talk to the server to get it to happen
and stuff so it's not it's not automatic
and obviously both ends need to be
running SSD yeah yeah should we pass the
microphone around i sorry since you've
got flow control / stream could if you
could you have just used the flow
control to accomplish that by telling it
to back off on the stuff it didn't want
uh well if the server oh I see what
you're saying
yeah yes maybe in theory but I suspect
you would have a you would see much
larger delays then because because if
the window was you know is large large
like it like it typically is for normal
operation then you suddenly slam it shut
it's going to you know take a while you
know the the other side might actually
fill that window before it actually
responds and so you know that but that's
a good idea actually though it was there
another question over here should we
pass the mic so um I was looking over
the DC CP and all that type of stuff and
I was wondering what is the advantage of
using SST directly as opposed to say
implementing this kind of you know child
stream concept on top of like DCP or DC
CP that already has you know congestion
control thing actually that's a very
good point and that's a very good
question and the answer is there's so DC
DC if you look at the details of SSTs
channel protocol you'll notice that
there's a lot of similarity in terms of
what the channel protocol provides to
what DC CP provides and it actually
might be possible just to get you know
the SST stream protocol running on on
top of on top of DC CP for example and
you would get get the the same effect
and I mean there there are a few things
that might need to be fixed or enhanced
with with DC CP to make that happen and
not and also obviously DC CP doesn't
provide the transport layer security
that SSDs channel protocol does but you
know that's sort of all all details i
think you know you could probably get
SST the streams running on top of DC CP
true microphone a very similar question
in terms of alternate methods to get the
same effect you could have
if you didn't see a lot of applications
for SST other than HTTP you could simply
implement out of order streaming sub
streaming you know record ization
directly in HTTP um yes but limit let me
actually I even have a slide for this so
let me go find it is that is that
appropriate let's see right well
actually it as it is right now I don't
think it can yet what you could well be
but but if you're willing to do a little
work you know I mean think that me it
might be less work to fix HTTP than to
invent a new protocol yes oh sorry I'm
so so yes it might be possible here here
are the challenge as I think first of
all you have to in order to get good
responsiveness you have to be sure you
can stop and restart fragment you know
HTT downloads and stuff into small
fragments and you know technically HTTP
already sort of supports that and you
know with range downloads and stuff you
could do that on the other hand can you
just hear the the screams from all the
web server system administrators when
they're suddenly getting peppered with
thousands of small small HD independent
HTTP requests to download you know 1k
segments of of their large images at a
time rather than just the whole image
you know things like that and and and
also just the bugs that the in clients
and servers that this is going to reveal
so you know I mean in theory it'll work
probably but in practice I am a little
worried another thing is you know that
then the application has to track the
round-trip time and do do a bunch of
sort of transport put it sort of
replicate a bunch of stuff that the
transport protocol does in order to know
you know how full to keep the
how full to keep the pipeline if it
fills up the pipeline too much then then
you know it's going to get long delays
for reprioritization if it doesn't fill
up the pipeline enough then it doesn't
use the full bandwidth available for a
round trip and in any case you still get
head of line blocking it if if one
packet is lost then everything behind it
guess gets blocked okay but still what
we're really talking about is what's the
best way to send 100 images in parallel
without having them ago sequentially and
so if you were to fix tcp or replace it
by something you could just have a
hundred TCP connections okay so morally
that's the equivalent of having 100 SST
sub streams yeah or 100 x 25 sub streams
if you will or or or fixing go to you
know HTTP you know 1.9 yeah it which
makes it really agree and I and I
propose that that morally that's exactly
what SSD is trying to do and I think you
proved the point very well thanks would
you actually pass tonight is there
anything higher level than a simple
priority algorithm for a kind of the MUX
in between the streams and the channels
something akin to queuing disciplines
hierarchical token buckets very good
yeah very good question i mean there
there there can and should be there
isn't yet correct I mean currently I at
least a you know what one point about
that is at least in the current design
the priority scheme that you use has no
influence on the SST protocol itself
whatsoever there's no there's no part of
the SST protocol spec that needs to talk
about priorities currently anyway you
know we can debate whether whether maybe
there should be but you know if there
are priorities it's just something that
the server in this case the server-side
implementation you know the server-side
SST stack implements some priority
scheme that the application that the
server-side application knows how to
tweak to get
sort of the effect at once and then the
server-side application talks to the
client-side application to you know
negotiate what what kind of priorities
at once and you could imagine doing all
kinds of different priority schemes
right so it seems like the TC queueing
disciplines around hierarchical token
buckets could be plug out there pretty
easy absolutely that is there any
support for a fine-grained
synchronization between forked streams
currently no currently once you fork off
a stream the streams are totally
independent so so and and a child's
dream can can outlive its parent for
example so so you know again that that
could be something worth considering for
you know future work but but it's
nothing like that is there yet so
anyways today yeah microphone mic yes
question oh oh I'm sorry yeah so why
hierarchical I would have thought that
you could do sort of a two-level thing
to level stream so the top level stream
would have a different type than the
sort of the children stream and what the
top level stream would support would be
operations like fork close the screen
change priority things like that and all
the data transfer at the application
level would always happen on the second
level streams so then what you must have
had something in mind which sort of made
you go through this hierarchical model
and on yeah yeah I i well partly just
just um the the partly that the desire
for the hierarchical model just comes
from my sort of computer scientists
desire for you know as general as as
possible you know as conceptually
general as possible you know in practice
it may be fine you know to to limit it
to like a two level model or something
like that but I just didn't see any any
need to let me rephrase it did you have
you seen any concrete examples or be say
more awkward as a programming model to
live with two levels instead of more um
well it did
for example in the in the web web
browser example let me go back to a
previous slide back here it seemed oops
yeah OOP sorry I'm lost okay so you know
it seems like even in like a web browser
example it's it's a very natural model
for the you know web client to sort of
open up a top-level stream representing
a session and then you know for cough
sub streams representing representing
web pages and off of those replicas you
know edition grandchild sub streams for
for downloading specific content within
those pages you know specific images and
off of those images for cough sub
streams representing priority change you
know out of bound priority change
requests and things like that granted
i'm sure there's always a way the
application could take a strict you know
if SST provided only a strict to level
model of some kind i'm sure there's a
way the application could work around
that and get you know the effect the
application needs just by you know
associating application specific
identifiers with the streams its forking
off and stuff like that it just seemed
like you know it's so so NAT it it just
seemed to me so natural that you know
the application could you know take
advantage of a hierarchical model in it
and it sort of fit into the the API and
and the concept that I decided to go
with that because of that yeah yeah I
think in your abstract at the beginning
you mentioned a little bit about TCP
friendliness what happens when thousands
and thousands of clients are doing this
to a you know one or two destinations
right so so to paraphrase a well-known
figure in the computer science community
this doesn't solve all the world's
problems only a few of them
what is always got new problems does it
create new problem I don't think it
creates new problems um so so in in SST
SST saw source sort of solves the
problem of unfairness of of like an
application like a web web browser web
server using lots of redundant
connections between the same pair of
endpoints you know against applications
between those same two pair of endpoints
that only use one connection you know
SSD solves that problem sse does not
solve the problem of unfairness of say
for example a bit torrent client or you
know where the you know one application
has all it has 20 different connections
hammering the network to completely
different destination hosts and very you
know competing against an application
that's just trying to you know get a TCP
download over one connection and same
same on the server side if the server is
talking with thousands of clients SST
doesn't really provide any any new
answers as far as making a congestion
control more fair and I think that's
sort of a problem that fundamentally
can't be dealt with purely at the
transport protocol level just because of
the transport at least you know in this
conception of transport protocol that
transport just doesn't see enough of the
universe to doesn't have a big enough
picture to solve that problem at it at a
larger scale could you say a little bit
about some of the implementation
complexity in particular it seems as if
your channel layer is roughly isomorphic
to TCP IP layer and that but that
there's the potential for substantially
greater synchronization load and
fine-grained data structures at the
stream layer particularly when an
ephemeral child is stealing from its
parents receive buffer and you need to
make sure that the parent then doesn't
cause an overrun and I wondered if you
were running this on a 10 gig link would
you suddenly see potentially
synchronization overhead or memory
sharing issues
at the stream layer in the application
actually that's a great that's a great
question and I think the rest of my talk
will sort I mean maybe not necessarily
answer it with but will will give us a
better place to start disgusting that
question from so can I shall keep going
with that yeah so let's see where were
we okay so I think we were here so SST
actually both conceptually and in terms
of protocol design respects builds on a
lot of a lot of existing work some of
which is listed here you know obviously
one of the most important sort of
conceptual inspirations is application
level framing but builds on a lot of
ideas from a lot of protocols which I
won't go through explicitly but you can
see all the references in the paper so
but sort of to summarize what I think of
it as sort of the big big picture of
what SST is trying to do you know we we
have TCP you know the sort of you could
say the motto of TCP is you know think
serially we're trying to TCP is trying
to provide nice serial stream
connections that provide a simple
application model you know for
applications to deal with SST in
contrast is saying well ok we've tried
to think Siri serially for a for a long
time now but now you know we're sort of
living increasingly living in a parallel
world now we need you know we need
parallel streams we need a transport
abstraction that that makes it easy for
the application to get parallel ism and
to implement parallel ism at the
communication layers and so there's
there's a you know this is this research
so far it's really just the beginning
you know SST is very experimental
there's a lot a lot to do with lots of
holes to fill in that you know there's
still no even you know full fully
accurate spec you know there's sort of
the beginning beginnings of one on the
website you can find you know there are
holes in in the code obviously we need a
more implement efficient implementation
there's there's lots of
you know Additional Protocol work that
will probably be needed ultimately to to
get this a you know really broadly
applicable and I'm just going to sort of
highlighted a few specific things 14
first of all you know it I I showed an
example of SSTs normal headers before
all of those headers have you know
fields that are a certain size and
they're they're sort of sized for
efficiency under 44 you know network
efficiency under normal conditions but
the this sort of constrains how many
packets how many new streams you can
create in one round trip you know over a
given over a given path you know how
quickly you can create and destroy
streams and how many bytes you can send
on a given stream for a round trip you
know the this I I think that this is
probably okay for most normal networks
but you're no doubt going to find
networks that you know this is not okay
for and it s st won't be able to
maintain the pipeline so will eventually
need you know some kind of fat headers
or you know wide headers sort of like
like DCC DCC p does you know to to
provide you know more allow for for
larger delay bandwidth delay products
and stuff like that you know that that's
sort of an obvious need and but it's
sort of also sort of obvious how to fix
it another another one is something that
actually I've gotten already gotten
vociferous demand for from certain
people in the community is what they
what sctp calls chunk bundling basically
being able to bundle multiple small
stream segments into one channel channel
protocol packet in order to in order to
use use the network more efficiently so
a more sort of more far out long-term
thing which which is actually gets
starts to get toward answering your
question is looking into what I call you
know widening the endpoints what happens
when the end
means become become multi big multi-port
core processors with lots of nicks lots
of IP addresses what can you do with
what can the transport protocol do with
those and you know sctp has already sort
of explored this paper for providing
this notion of a multihomed transport
where the transport the logical
transport can have multiple endpoints
and multiple paths between two endpoints
which can be used for failover and
there's there's actually with some
research done in in extending this in
the context of s sctp for actual you
know simultaneous multipath transmission
and stuff like that you know obviously
that's that's useful and in you know and
an important thing to be able to do in
the future and extending even further
beyond that we can obviously envision
you know a company like Google for
example you know having you know huge
server farms of you know machines that
want to behave to client want to be seen
by clients as you know one big logical
TCP one big logical you know transport
endpoint even though they're there
really a lot of machines that need to
share load dynamically in in different
ways how how can we address that and I
i'll just say up front I don't really
have any any definite answers yet but i
just want to point out a couple aspects
of SAS SSTs design that i think would
facilitate these kinds of things namely
this this channel stream division
channel represents a path a stream
represents the applications logical
communication activity and there's a
many many many to many relationship
between them there already is actually
in the current implementation although
the current implementation doesn't
doesn't really ever use associate
streams with multiple channels that at
once the day it's already sort of it's
already designed so it so it can be in
the future and that and that's sort of
the intent that you you can associate a
channel with
stream with multiple channels channel
with multiple streams obviously and do
things like that and so so sort of the
the two key points regarding this are
that because the applications using many
streams and these streams can be
associated with on with a variety of
channels possibly you know possibly just
wondered at pine possibly a few at a
time it at least creates the latitude
for you know the transport designer it
creates the possibility of you know
designing the system in such a way as to
avoid avoid putting severe parallelisms
bottlenecks at any of these particular
in the implementations of any of these
particular objects unlike you know tcp
for example where you know if you've got
one stream and the application needs
this to be one stream then you know on
each end you're going to have locks at
the at the end of that stream than that
that's sort of in the bite counter for
each stream sort of has to has to count
in lockstep and you know you've got
central central points there so you know
actually in another sort of particular
way in which SSTs design facilitates
multi-homing and you know this kind of
parallel ism is the fact that congestion
control is automatically per channel
there there the spur path and so you
don't have to worry about confusing the
parallel the congestion control
algorithm because of the varying delays
of different network network paths and
things like that and so those are just
you know a couple considerations anyway
I'm sure there are plenty more that I've
missed but and you know there's a lot
more work and thought that needs to
needs to be done and so that's what I
have yeah oh so have you already
have you automated the muxing between a
stream and multiple channels in the face
of differential congestion on those
channels so that there's the stream
priority will automatically choose the
appropriate uncongested channel no in
the current implementation there's no
there's no load balancing per se there's
it the current implementation allows a
stream to be associated with currently
with just two channels at a time
although that's easy to change the the
immediate motivation for that is to
allow a stream to migrate from one
channel to the next you know when the
old stream goes dead you sort of want to
get it connected hooked up to a new
stream before that and and migrate but
but the sort of the the wiry the
internal wiring is sort of there to
enable streams to be associated with
more than more than one channel but it
doesn't actually really take advantage
of that yet there's usually a little bit
of a tricky control loop is definite let
me start yeah interposing that
absolutely there are a lot of issues it
it adds what happens if the application
sets up 10 million streams another very
yeah another very good question so this
is this is actually an area where the
the SSD protocol knee another thing i
didn't mention that where the the
protocol probably needs to be extended
currently the flow control only deals
with with bites essentially and I think
the protocol needs to be extended to
provide some kind of flow control not
only four bytes within a given stream
but for you know to count the number of
sub streams that that get created on on
a child's dream so that the the you know
server can for example set a cue limit
for for you know the number of sub
stream child streams that can be created
at once you know on a given parents
dream or something like that and that's
that's not done that's not there yet I
want to make sure I understand the
abstractions here
the your channel abstraction like the
existing tcp stream abstraction is
bi-directional is your screen
abstraction bi-directional yes the
stream abstraction looks exactly like a
TCP stream as semantically other than
with the addition of being able to fork
child streams and the subtraction of
TCPS TCPS vestigial out-of-band
mechanism wed that TTP's urgent flag and
duh have you thought about whether there
is any advantage in supporting
uni-directional screams um actually it
seems like that did I did think about
that at one point but I can't remember
what conclusion I came to if any so I so
I guess the answer is no I haven't
thought about that much but actually I
think I was pondering at some point
whether something like SST could ever be
used in a multicast model or something
like that and that would be an example
of where that could be used but I
haven't really explored that in any
depth so okay and have you thought about
a three machine interaction where
machine a sensed machine be a fork of
the stream that it has the machine say
yes I actually I have thought about that
so I there I mean there's there's
obviously some some extensions to the
protocol that says some work that would
be needed to be done to support that but
actually that's something I'd like to do
and in fact one of the aspects of SST
that I didn't have time to talk about is
the way it detaches and attaches streams
to different channels it uses a sort of
a besides the small stream identifier
that it uses to identify a stream within
channel SSD has sort of a larger global
stream identifier that it uses to attach
streams across channels and you could
you know with some suitable
authentication and
mechanism and stuff you could envision
that operating in such a way so that
streams could actually be handed off
among machines so okay I think we're out
of time so let's thank Brian for the
talk thank you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>