<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AGI 2011: The Future of AGI Workshop, Part II | Coder Coacher - Coaching Coders</title><meta content="AGI 2011: The Future of AGI Workshop, Part II - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AGI 2011: The Future of AGI Workshop, Part II</b></h2><h5 class="post__date">2011-09-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cpjrKmoXVfQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">which is part part two of the future of
AGI I believe John smart couldn't make
it so we have we have for talks this
time filed by a panel discussion shorter
than the last one and a yeah so first up
we have florin pipette school on the
topic of what is Dexter dee a bit of a
shift from the ethical preoccupations of
the previous session well it's not not
so much of a shift you can see what you
can see that picture is chosen for a
reason that shows the fight between the
mythical Titans and what you see is
basically one species castrating and
taking over the other and that's between
uranus and Cronus of course and so my
talk is and what is dexterity and I
hereby claim the extra minutes from Bob
strong because I have a lot of stuff to
to talk about so so here while I talk
about the definitions of this and that
let me start some cool videos and okay
so what is 630 so the as most broad
concepts the definition is a little bit
circular and vague a draught inference
meets means handy directly so but by
intuition by definition right the
concept of intelligence and handiness
and dexterity are directly linked and
which is what you just saw over there we
were paying attention you saw an
overhead kick by a South American star
soccer player and it's an example of
dexterity sand things that you know the
other two robots the the big dog and the
the Sony robot cannot do right now or at
least not asleep reprogram than to do
that and I just wanted to pay attention
to fact that there's another animal that
can do that
and that's a dolphin and that it learned
by itself to do to do this cool Petric
so in general you can see that the
exterior has something to do with
movement and how fast it is and how
flexible is but there's clearly an
intelligence factor there that
intelligence fact that robots currently
lack and moving moving on alright so the
evolution of human motor control how did
how did that happen well it was thought
since the 1920s that the evolution of
human intelligence evolved their new
brain areas that would come up and would
deal with different cognitive tasks that
we needed throughout evolution this has
been you know this is a popular view of
most people think that because if the
popular science work of Steven Pinker
however that this is out of date it
research wise it is not thought that
basically human evolution came through a
scaling up of the brain of all the parts
are basically similar in relative size
to what they were another earlier
hominids and the one thing that might be
different is the latter reality of the
print sort of right/left laterality of
the brain but otherwise you know
dolphins also evolved from similar
similar animals in the group of what's
called a clade the 12 things I have in
common right so highly confident Carter
core cortex that's much more than their
their cousins and you can see to the to
find examples there and beautiful
pictures one shows connectivity the
other one shows the cortex itself these
are the things that maybe are not so
clear but they're clear to people who
study motor control like me cerebellum
that's a very big sarahbelle that helps
in doing some of the computations and
there is a uniquely there is a very
large corticospinal tract which is a set
of neurons which goes directly from the
brain to the muscle by passing a lot of
the spinal circuitry that's used by more
simpler animal to simplify control and
you know we talked about earlier using
two or three degrees two or three
actuators in a virtual world well humans
have
actuators or an or the order of
thousands of actually an order of tens
of thousands of sensors so that's got to
have something to do with it and also
the amount of direct control that the
brain I so in essentially the body's the
muscles are extension of the brain
itself or become one in humans so
there's also a skeletal muscular
architecture that change throughout
evolution obviously and that's a related
story but a bit of side story and a
little bit about motor control now it
used to be thought that things are
simplified at the spinal cord level but
twenty ten years ago and this is known
as equilibrium point hypothesis and that
made things easier to control for very
simple 6502 typography lectures at the
time but the evidence doesn't point to
that and I'm favorite incident done some
work on that and that what instead shows
up is a hypothesis that came goes back
the years from Michael Jordan which who
claimed essentially that the brain
cortex in the servo can perform Armas
arbitrary inverse dynamic mappings and
and learn them and they'd be stable and
generalized and this is known as the
inverse dynamics hypothesis and clearly
there's some of that going on right now
as I speak as your vocal cords can
produce almost any sound and the hand
can produce control any any shape
whatsoever so there's flexibility
involved in that as well and all the
stuff you know what what is what is
still not known from an evolutionary
perspective is what there's a dark age
there's a gap of irony we evolved about
200,000 years ago but culture and you
know the Big Bang of human evolution in
the migration Out of Africa only
happened about 30 40 thousand years ago
so you know what happened in the
meantime how did it evolve what were the
pressure is that created this and yes so
evolution so what's going on and we need
to pay a little bit close attention to
how evolution Fox it's a stochastic
dynamic system right and I like that
picture a lot because it shows the
output it's basically the Hamid
lion evolution but it shows a stick at
the output of a complicated stochastic
process right and kind of what happens
if you can reduce it a little bit even
to somebody that not a geneticist like
me is that populations diminish do some
to do some pressure and in the under
distress the mutations have a higher
chance of new species creation of the
mutation has a higher chance of
propagating itself throughout the
species and this means survival and
eventually thriving to a large
population and a large area and then you
know some new event us a new competitor
comes along and this thing and there's a
crisis and the population diminishes
again and there's a final result
mutation and so on and the sub evolution
seems to work and I did there's a lot of
stochastic modeling of this in one
intelligence emerges and things that are
really complicated such as ability for
language then then you get some things
that are just implausible so the
language organ which has never been
found right it's all a pot so I start
with never been found this is the sink
will that make sense as a mutation right
so if I if I'm a baby that has the
language ability and I my parents don't
have the mutation I can't learn language
so there is no it's implausible this
isn't the dynamic mechanism which lets
us have so the actual genetic mechanisms
to civilization haven't really been
found but but they're being looked at
and you know they're complicated oh so
but but there was something about the
environment something about environment
itself that made it better overall a
better strategy for humans to develop
what's called general intelligence
rather than create bigger bodies so then
the end results tried that path and you
know it didn't work out for them and now
I since we talked about dexterity and
this is like mathematical conference or
hit I need to talk of it like in brief
about some kind of formal exposition of
victory and so I just want to talk model
motor activity as the interaction
between age and environment but the
environment is not just a bunch of rocks
that we pie a lot but like silicon Mars
rover the environment is smart is active
the Wonder is made of other members of
our species
and other species and I broken it down
removing a couple of layers that AI
people like to to put such a signal
cognition and I broken them down into
perception action and reaction and it's
the environment they react and this in
motor control parlance it's called
impedance as a dynamic that's a
differential equation but but it's much
more than just you know soft bodies and
rigid bodies and so it's it's
intelligent and I've I've written an
equation there it's kind of small but
you can see that what i did is I've no
define dexterity as the speed in time
with which an agent may modify the
structural complexity of the environment
and structural complexity is kind of
like a mug or capacity but it's it's
lower than that so that's but you think
about the structure of complexity as you
know looking from outer space and you
see all the stuff that's going on and
you see the pyramids and yea and things
appear and now thanks to super
complicated things you can see from from
space i free from the plane or from
google maps and you know it's just one
point it's boo the machine that did this
you know there's people talking about
making it emulations and massively
parallel machines that will use
terawatts of or gigawatts of power the
brain has 20 watts of power the muscles
who consume another 50 watts of power
that's what made this whole thing that
we see right and we can put balance on
that you know there's a there's a lot of
theory working on how much energy we use
and what we do with it and so on of it
okay so let's that's a so in order to
elucidate the mystery of what happened
in evolution and why we need brains and
how we get there I propose that we make
a complicated similar so I'm not just
differential equation but something much
more ambitious and complicated that's
been attempted so far so and so wait
came about because we have some size
four kids at the Institute who've been
very successful using then going to
robot all right so doing the Robocop
World Championship and you know I
noticed and i shouldnt happen now and
they spend a lot of time trying to build
a physical robot right they spent so
much time physical being a physical
robot that they didn't have time to do
to program it to be intelligent and and
and of course it helped making a better
physical robot so if you when you set up
a virtual competition like this in the
incentives need to be right so you get
intelligence out of it rather than but
but it's but it's both you see with
evolution didn't just do intelligence
this structure actuators and then also
the intelligence behind it and there's
an energy costs to making decisions and
two and having strategies and senior
moment and so what you what you also see
is a tool and development our institute
called modelica 3d which i want to which
I would like to use as a so instead of
having the these things that you guys
are used to which are simplified 3d
worlds and we talked about the balls
yesterday that he wanted to the been
wanted to model the world of
compressible it's more complicated than
that there's shear forces there's fluids
that move around but all these things
can be modeled we know how to do that
and I'm proposing that this be done on a
centralized server so we provide people
with open source tools not virtual gears
virtual muscles virtual bones they can
build their own species which can
multiply as much as much as they can and
we provide them with it with a Sandlot a
sandbox in which these things operate
and compete with each other we simulate
evolution this way all right conclusions
can I sure all right I'm a lot of
conclusion endeavor and therefore to
conclude all right evolution is the only
known path to general intelligence
that's proven now worked if you simulate
it it can also be safe because despite
what we talked about programming
morality and things like you know may
not may not work you know it's it's
virtual since sandbox we do control it
and you know I also study a little bit
the man trying to find out machine
learning techniques to fund to diagnose
schizophrenia Swanna murders and so what
can happen though instead of developing
you know emergence of
beings that are evil what's more likely
to happen is wondering what I actually
happen in evolution is that you get by
scanning our brains you get bugs in the
system and these bugs are like psychosis
um so that's what we all have to boy
okay thank you next we have Alessandro
ultramar a on visual intelligence beyond
representation so moving from a action
to perception of course each of the big
a broad topic branching out into
everything else yeah so thank you very
much I think that the focus of my talk
would be much more narrow the other one
that we see so far so I would try to say
something about the general problem of
what doesn't mean to enable visual
intelligence in artificial systems and
in particular I would try to make the
point for the for adding something more
than representation in the overall
framework so I start with this general
reference by France brentano so work and
be represented in so far as phenomena
are preview presented so namely
structured and perceived as experiences
by human beings what does it mean so in
terms of general distinction between
computer vision and visual intelligence
you can think about computer vision or
machine vision in general as dealing
with the information extraction from
seen from scenarios and the
state-of-the-art make as the performance
is very good concerning object in
features recognition visual intelligence
is not really just information
extraction of course from seen but is
trying to be some kind of knowledge
structures from information and in
particular 11.1 important point is that
basically you you get knowledge by
adding some kind of semantic structure
to to eat to the disease pieces of
information that you thought Francine's
for example you can say that event
are not just the sum of the objects and
the features that you detect from from
an Essene front from from from an
external an external detect the scene
the elements in the scene play specific
roles so they act in a specific way in
specific scene in specific context and
humans learn to recognize the general
pattern of events via multiple
presentations or instances of these
general event types so how to enable
kind of artificial visual intelligence
that add these knowledge structure to
information extracted from scenes so I
just try to scream at eyes a bit the
mainstream model the main string theory
behind how this machine vision and
computer vision words that kind of
standard theory of perceptive semantics
where perceptive semantics means how do
you build semantic structure meaningful
structures from perception so basically
you have some kind of sensory dimension
of stimuli and some electrochemical
transactions that was late those sensory
input into symbolic dimension so in some
time representation of course this is an
oversimplification but I'm just trying
to scam mata is everything the kind of
the right model of artificial vision is
that you take some kind of sensory input
light position the orientational
brightness the motion shape and other
specific optical features from seeing
and bias and kind of information
processing you build up see the symbolic
output which is the counterpart of
representation from a viewer of human
representation in terms of computer
vision but if we go back to the premise
or to this quote by brentano and other
and in particular in the field of
experimental phenomenology you see that
the problem of abstracting from specific
perceptions true representation
is not solved at all I mean the the
so-called linkage problem is the way in
which you try to explain how symbols are
created the built up on these stimuli
from from the external world and they
the concept of of presentation which
comes from the so that this distinction
between presentational representations
come from the distinction in the in the
content theory of knowledge between the
stands and were standing so the fact
that you distinguish between the
abstraction from the act of stimuli the
role of presentation is to make the
filter let's say from the stimuli to
representation in the human visual
intelligence so basically us and kind of
dynamic dimension in the middle okay
which builds up and using an
intermediate level between the level of
representation and the level of stimuli
so you can visual intelligence is is
able to add the kind of so to build up
this knowledge structure from
information filtering the stimuli using
some kind of schematic structures there
is a huge amount of data from
experimental psychology on how this
receptor phenomenal work so how you
really focus on some of the elements of
the scene how you combine those elements
how you put certain structures on those
elements and there are also robust
explanation on the single of the
specific receptor phenomenon cognitive
semantics for example as we put into
formal semantics try to understand how
those that say pieces of knowledge that
you filter from the scene can add up
into meaningful structures for natural
language and these obscure forms of
presentation is obscured schematic
structures so called concepto schemas
makes the difference actually when
dealing with the complex cognitive task
has action recognition on disambiguation
because helps human to to focus and to
extract specific knowledge from the
scene just to carve to unfold the
preceptors piece space conceptos k a
scheming in general can be seen as some
like cognitive relations which hold
between the elements in seeing like the
mutual position the dependence between
the elements the science of elements and
in particular if you want to like make a
list of these concepto structures which
are in a sense anthropocentric with
respect to as opposing to an objective
and let's say optical based elaboration
as in the act or current computer vision
you can find these among these primitive
forms of presentation like the path
source the app down front back center
periphery the container and some of the
so called guests schemas like the
profile base which is the difference
between the figure on the ground which
is quite easy to understand but for
example viewpoint and distribution of
attention which can be translated in
some kind of you know naive concept of
vocalizing in specific elements from a
complex scene in order to carve the
scene and to understand which are the
minimal feces pieces that you can focus
on force dynamics and scanning and
container and so on so forth so trying
to understand if these kind of features
that permeate the human visual
intelligence can be translated can be
implemented from the viewpoint of
artificial visual systems this is a kind
of proposal of augmenting the actual
architectures the actual integrated
systems using those kind of
features like for example in the level
of low-level processing so visual
classifiers which actually exploit
optical features could be augmented in
terms of let's say kind of counterpart
of forms of presentation so trying to
implement structures which can identify
these difference between for example
center periphery but source
figure-ground Sun support at the high
level of the processing so for example
in cognitive architectures like soror
akhtar you besides this mechanism of
general human cognition like learning
memory and perception try to mix a kind
of computational rendering of this guest
alt effects that in a sense is a
specialization of the perception layer
of the overall cognitive architecture
from the viewpoint and this is from the
viewpoint of mechanisms from the
viewpoint of content so for a few points
on how you build this knowledge
structure this is a semantic meaning
meaningful knowledge structures you can
think for example to say enhance set of
the art semantic resources like
ontologies like open psychic dolce sumo
and computational xicans like water and
frame net and by the way frame it in
some sense already exploit some kind of
general notion of schema or frame to
build the knowledge structure with this
notion of concept of schema web for
example from the viewpoint of the other
knowledge content means to vocalize on
the object action coupling sub verbs and
nouns are they are combined in
meaningful semantic structures or for
example metaphor which for which which
can which in a sense improve and other
more more relations in the space of
lexical semantics and these are some of
the references for this work paper we
are going to maybe a
presenting the topology I fall symposium
on advances in cognitive systems and a
couple of reference for cognitive
semantics and visual intelligence one is
the most recent so the third one is a
new book curb by Bert a savant alderney
visual perception beyond inference which
focus really on these which is inspired
me for this talk and focus on you know
going beyond representation in order to
improve the artificial visual
intelligence system thank you thanks a
lot my talk is simple simple idea it's
short so we're all here we're interested
in creating artificial Minds so all of
us in this room we have natural minds
and one of the great things about
natural minds is that they're all about
equally good we all speak the same
languages if someone else speaks French
I can learn to speak French possibly
they could possibly willing to speak
English but our sentence structure we
will make sentences of approximately the
same complexity some of us have
specialized vocabularies but generally
we have roughly you know roughly the
same intelligence we share the same
daily skills in fact if we look at the
skills that we take as as signs of
extraordinary intelligence like playing
chess really well those are the skills
that computers can already do it's the
daily skills that they can't do so the
skills we all share are the skills that
really distinguish our intelligence so I
claim that we're all about the same
intelligence because our intelligence
comes from a natural process which just
has given us all about the same
intelligence when we can build
intelligence when we have AI that
exceeds natural intelligence possibly
we're enhancing humans and their
intelligence then we get I think a wide
range of intelligence levels in other
words that's where we come to the end of
the rough equality of intelligence if we
look at other artifacts like buildings
and vehicles the largest buildings are
much larger than the average building
and so on
and we can think of a social dynamic
that will work that way when your
intelligence depends on how large of a
brain you can afford to buy and the
amount of money you can earn depends on
your intelligence that will create a
positive feedback loop that will create
this divergence and intelligence levels
so we'll have this great divergence and
intelligence is the ultimate source of
power in this world that's why humans
rather than lions rule the world
intelligence is what rules the world and
there's this great quote I think the
guys name was Lord Acton he died in 1902
or something and he said power corrupts
and absolute power corrupts absolutely
and this topic has come up a few times
in talks about what are our intentions
you know certainly if I became super
intelligent I would have the best of
intentions nothing bad would happen
right well check back 15 years later
let's see so and so the question is what
about this and I think that AI really
ultimately is going to be a political
issue because if you have such profound
social effects that it's it's really in
the political centers what we're going
to decide what we're going to do about
it so we've heard a lot of talks about
and there's going to be more papers and
some very interesting papers coming up
in the main conference about what what
do we get if we say here's the values of
our system what does it end up doing
Steve gave a great overview of that and
I talked about that and there's going to
be some great talks so it's a very
complicated question but the important
thing is that there will be political
will to solve that problem no one is
going to want or no sane person no one
with any real political pull is going to
want a I to run a muck and do what we
don't want it to do so the wire heading
issue if there's a technical problem to
the wire heading probable a technical
solution to the wider heading problem
there will be political will to solve
that problem but
I think that it's likely or at least it
certainly could be likely that there
will be political will to team AI with
wealthy and powerful human beings
Hollywood loves to make movies about AI
versus humanity but that's not the
threat that I fear the threat that I
fear is a few wealthy and powerful human
beings teamed up with AI against the
rest of us and even if they don't have
the intention of being in its the rest
of us once they have the power power
corrupts it's it's it's a question it's
an issue I'm not up here to necessarily
give you the answer been asked me to say
something about open source so the first
thing I'm going to say about open source
is my t-shirt depicts John Paul the
second getting a demo of my open source
visualization software in 1992 which has
nothing to do with open source a I
accept that I'm an advocate for open
source ah open source is really a form
of transparency it's a form of making
everything you're doing open and obvious
to everyone and I think transparency if
there is a solution to this political
problem is transparency it is that the
public people who vote and occasionally
vote for people that we can't understand
why in the name of creation they would
vote for those people but those people
need to understand the issue of AI they
need to understand the possible threat
to them about AI concentrating power and
I mean that's what I think is the answer
and during the is that's the only
possibility now these I wouldn't say the
answer but the only possibility is for
people to understand this threat to be
made aware of it and to hopefully act
through the political system sounds
crazy but I can't think of any other
approach that's it
and now for something completely
different let's try this well maybe not
that right there that right there we are
okay the first question is can we
actually say anything at all about the
singularity with any degree of
confidence and well then got it um the
it turns out that there actually is some
scientific research on the question of
whether expert prediction of the future
is worth anything at all and tetlock is
is who's still working at this but but
this is a classic piece of work and it's
been mentioned in a couple of more
recent popular books the title here
refers to the old saying that the Fox
knows many things but the Hedgehog knows
one great thing well it turns out that
that what tetlock found was that the
average expert doing predictions of the
future and he he he made them write down
their predictions and tracked them for
years and tied them down to specific
predictions it turns out the average
expert is not significantly better than
random chance but he found that they
were doing ways that you could divide
experts into two classes the hedgehogs
as he called him and the Foxes the
hedgehogs were the ones with the great
one great thing they knew that some some
e day feex that they thought the whole
world turned on and it turns out that
the hedgehogs were worse a lot worse
than random chance and and the Fox is
the ones that drew and a whole bunch of
different knowledge sources and and
theories of the world tend to be a
little better than random chance but
that regression and extrapolation work
typically about as good as that as the
as the Fox type experts
um a bunch of recent work extends that
kind of thing to the people who are
actually doing the innovation and
causing technological progress and as
well as those who are simply predicting
it that like Kevin Kelly points out that
that things that that get invented tend
to be invented by a lot of people at the
same time Johnson has the same thing a
lot of these are about trade and
experimentation and so forth as opposed
to people with these these great
theories that actually come up with some
genius development and the the the Fox
version of history turns out to be that
it's it's the marketplace of ideas and
not any single great individual
intelligence that that is really
responsible for the way technology
changes even the arguably one of the
greatest geniuses we've produced said
the same things in his own case okay so
we take these ideas and they tell us
that we need to look at what history
says about the development of
singularity and technological
advancement and so forth this is a log
scale and you'll see that they're
basically just three different growth
modes here the first one is agriculture
the next one is what i call the
mercantile era which is inventions like
ocean going sailing ships and double
entry bookkeeping in the printing press
and so forth that happened in the Middle
Ages and the third mode is the
Industrial Revolution and there's a
there's a previous mode before
agriculture that's essentially flat and
what we want to do is essentially just
look at what the next mode is going to
be
so here's a proposition that doubling
times have been coming down the growth
rates have been going up and and I'd
like to propose that we're probably
going to in the coming century move into
a mode where the doubling time is on the
order of a year and the growth rates on
the order of a hundred percent and I'll
try and back that up a little bit in the
coming slides okay here's more solo this
is this is reycarts Wiles data and I've
added a few data points of my own but
they all they all fit the same curves
and and these are the fairly commonly
drawn end points where the thousand
dollars will buy you a human equivalent
computation or a billion human
equivalent computations and the two
curves I fit here is one that one is a
quadratic and the other one is another
exponential it would be as sort of a
double exponential and the idea is to
see if there's any great difference
between a fairly standard prediction of
Moore's law in the coming century or the
extra exponential this being a log scale
in the first place is supposed to
represent what would happen if you have
an intelligence explosion we're
intelligent machines are making machines
advance more rapidly the before and it
turns out that inside the coming century
the the times for reaching given levels
like these these two lines I have drawn
in here are not really all that
different maybe a decade apart or so and
I claim that what that tells us is that
the intelligence explosion isn't going
to do that much more for the rate of AI
and computer development then we're
seeing already the the the two curves
fit both of them as you can see fit the
historical data almost exactly the same
and they don't really diverge that much
inside
the century now after the century that
thinks may be different but trying to
take mathematical account of a double
feedback effect from from extra
intelligence doesn't really make that
much of a difference in the in the
projection okay before the Industrial
Revolution there was one technology it
was in fact information technology they
kicked into the industrial revolutions
growth mode a couple of centuries before
the Industrial Revolution and that was
the printing press it use complex
machinery at you machinery that actually
did production it had precision
interchangeable parts in fact it had
many of the same things that you saw
applied to all machinery during the
industrial revolution and which kicked
the the world growth mode into about 5%
but the growth mode of printed material
and scholarly work and so forth books
had had already jumped to a five percent
growth mode well before the Industrial
Revolution expanded that to cover the
rest of the physical economy but then
the economy adapted the same techniques
that had been used to handle information
to the production of physical machinery
and and the entire physical economy
jumped into that same five percent
growth mode thereafter I claim that the
same thing is happening now I claim that
the Moore's Law growth mode that we see
in information technology will expand
into physical technology by molecular
nanotechnology using the same sort of
digital techniques that we use for
information now apply to atoms to cause
the entire world economic growth mode to
jump into
a mode that's essentially similar to
what we see in Moore's law now and
that's what we're going to see I don't
think we're going to see an awful lot
more than that at least in the coming
century there may be more growth modes
to come after that but the example of
the printing press and the Industrial
Revolution leads me to believe that this
is the same kind of growth mode jump
that we're going to see okay all right
all right ai is going to get cheap Rai
is going to enter a Malthusian market
where they will be so cheap that they'll
be everywhere and no AI will really be
able to compete well enough to make a
living beyond its own absolute
subsistence chances are probably yes
will they compete humans out of the
labor market probably yes in fact almost
certainly yes on the other hand this is
what we want we don't want to work for a
living we want to sit around like the
upper classes have always done in
history and have them have the robots do
all the work so if the if the AI is get
cheap enough probably by sometime in the
middle of the the second half of the
century on it will be very inexpensive
to provide each living human with enough
a is to represent the industrial and
intellectual output of an entire country
of today and because the physical
technology will be popping into the same
growth mode sometime in the in this
entry we can say about the same thing
with the physical as is with the
intellectual productivity so essentially
by the end of the century I claim that
each person will be his own or her own
country but the interesting part will be
trying to get there from here
panel discussions of you so will now
have a panel discussion from this second
part of the future of AGI workshop so
florin and Alessandro should come up for
the panel discussion all right any here
any questions for these guys okay cosmic
talk louder please yes yes the change to
change in the complexity of you are huh
all right the entropy the entropy thing
no it's it's structural complexity so
you know you look on cargurus papers
you'll see that the description
complexity of any object actually it as
you as you compress the random part by
the separate random part from the
structural part is if there's a point at
which it starts to search where you can
meaning entropy doesn't count randomness
doesn't count just the structural part
do you not have time I should explain
this none yeah no no no that'll be a net
but but it's an upper bound right it's
how fast it can change so if you decide
to blow everything up right well that
might be might require an intelligent
way for me to think of how to destroy
something large but Sokka the media or
so could a you know a natural a natural
event a natural event could not create
the pyramids all right other questions
for you describe the
what will give world war are you okay
well right now we're just so you saw the
screenshot which I shall was the
simulation of a lunar lat sorry the
question ah whether we are building this
virtue of this amazing virtual world
which I was a was proposing well we're
there is something in development right
and it's a 3d visualization of
differential equations now just a word
about differential equations and the
different types of systems that they're
open Sam and all that stuff it's easy to
simulate an Eau de and even there's
multiple ways to and libraries which you
can do that things are complicated when
you have parallel link so this this is
this is really hard to simulate and you
need something that sets up a causal
structure of the differential equally
that's what open but it's one but that
like it does um so you can simulate a
lot of different things and but you vm
is a level of complexity which props
possibly we don't need but in modelica
for example you can simulate a a
twisting foil or a cube alright because
there are semi analytical solutions to
this or are approximations to the
differential equations which work so
this thing can be used also for
thermodynamics and also for fluid
dynamics any of these things that i've
seen so far could couldn't handle it and
of course the idea is that if you do it
on a server side all right and nowadays
you can download that stuff and everyone
can use it on their own computer if you
do it on the server side having a lot of
these deformable elements you know trees
blades of grass whatever that requires
quite a bit of computation and that's
why I think it should be done and you
know on the server side while the agents
themselves you know which use different
libraries in mission machine vision them
open cog if you want everything you know
those things can reside on a Linux
machine or aren't like you know Android
for example because that's you know said
you want to create a sandbox no internet
access
stuff like that but no physical action
you want to simulate sensors and and the
thing about modelica is that there's a
lot of there's already a large library
of parts available so you want a model
of a particular motor from it exists a
gear with backlash and all that stuff it
exists so rather than and one thing that
I'd like to do this in this friend of
mine at Stanford this is kind of stuff
it's not a muscle all right so you want
to talk about theories of motor control
you'd better simulate some some joints
and bones some some muscle of things
that you know of humans and animals that
are extinct and stuff like that so
there's some people that do that do that
as well any more questions yeah or is it
that you take whatever well yeah if I
well understood so we are asking how
this link between percepts and
representation in the ontology is it
direct or is something that because you
said a private ontology so in which
sense the proposed mechanism will go
from novel / sets to a pre-baked
oncology or from novel process to
another one okay both I mean you you
assume a kind of background ontology
like a general ontology like psycho
whatever but of course any new percept
could improve or populate let's say the
knowledge that you already have in the
background knowledge base okay so it's
both ways I mean you can have like kind
of
prebuilt ontology and his ontology would
be populated by new facts from the world
and trying to you know update the
knowledge that you have so the reference
ontology is used as a reference but is
not just yeah well I couldn't climb to
be sure but the end of Moore's law has
been forecast many many times over the
past 50 years and and hasn't happened
yet and we have physical models of
computational machinery that is very
likely to be achievable once we guess
that get the production machinery for it
that carries Moore's law out to at least
2030 at which point it's pretty much
cheap enough and and you will find
yourself in the middle of that even even
if it Peters out after that but my guess
is that people will keep discovering new
ways of computing I mean for example
imagine that the the quantum computers
start getting cheaper and cheaper as
well
and they're not general purpose but
they'll allow a general purpose computer
to do a lot more certain kinds of
computation and and I mean I can talk
about all sorts of interesting
architectures and interesting device
physics and that sort of stuff but but
the fact is that that people are looking
at enough stuff now that it it's very
reasonable to imagine that the that the
trend of the past century will continue
over the over the next century where you
think about why I think that pretty much
according to the anodized definition
we've been using nanotech for for
computing hardware for the past five
years but it's pretty clear that we can
carry that down to the molecular lee
precise gate level and in fact that the
semiconductor industry roadmap for
electronics looks very close to nanotech
by the early 20s they're talking about
you know nano meter gauge sizes and so
forth and and that's you know from
people have have no torch to carry for
nano per se it's just that that's where
they're going I just wanted to make
repeat a point which I mean I know this
sounds a little weird now but I don't
think computing power has anything to do
with it 20 watts is 20 watts if
computing efficiency become ten times a
hundred times what it is now right
that's way with computers are 100 times
more efficient that means you know
they'll have 2,000 watts so I I think
its programming it's not it's not the
massive parallel of nothing but that's
an opinion well if I cannot sounding
I think that my argument for visual
intelligence is more or less same
because you know you can have a very
fine grade detection of object features
and everything from a scene but the way
which the human intelligence actually
perform in the front of you point of a
recognition is not just putting power is
just try to have this the right scheme
under the right structures working in
extracted information so improving a lot
all these algorithms is good but there
are some kind of high level things that
can improve the overall situation I
guess no I haven't heard anyone argued
that better Hardware in itself but self
yeah the AGR problem I guess everyone
agrees that better software is it is
core to it except the question is do we
also need better hardware a lot along
with the better software which to me is
isn't a hundred percent clear that is a
more confident of it the fact is that
although I'm talking about actually
those numbers i was using were chris
wyles data and more vics intelligence
computational capability estimate the
fact is that a thousand dollars is
nowhere near as much as you would pay
net present value for a an intelligent
machine you can you can easily afford a
million dollars if you have a machine
that that's until intelligent as a
highly productive human and you can
build that today question rather
right so just to recap the question the
Moore's Law per se has gone well other
intuitively associate trends like clock
speed may seem to have stalled so some
of these trends have kept going some of
these trends that have tended to to
saturate and the question is if you take
into account the broad spectrum of all
these technology trends that are
relevant then what does the whole
picture look like when I told you so it
looks pretty good because we have at
least one model of intelligence that has
a somewhat lower clock speed and uses
massive parallelism namely our brains
and in fact that has come in as I have
expert opinion at about 20 watts so so
yeah I think that as far as intelligence
is concerned the clock speeds are not
going to be a problem and as for the
rest i don't really see a major
difference because we we are going to be
able to build massive numbers of
parallel processors and and that that
trend does not seem to have slowed down
at all another question okay I decided
in lionsearch like my ratchet up i'm
hiding behind peter norvig
alright so earlier everybody got scared
each other with this whole idea of armed
robots well how about this how about
that fact that a GI enhanced robots will
actually end warfare because Wars of the
future will be simulated as a point of
war is just to you know to make the
adversary obey so if you are simulated
robots win then there's no point in
resisting from the other side that's a
principle to turn and that's what
happened in the Middle Ages and earlier
when armies would go out in the field
and you know they would fight the war
and the city would surrender but you
know only 200 people died out of very
large Somali mortality was very much
shorter so maybe you know that's a whale
I'd like to make a point if I can hark
back to the previous session where
everybody is talking about morality and
so forth I don't think there's a there's
a huge correlation between the morality
of an agent and that agents own
intelligence of morality and I don't
think there's a huge correlation the
correlation is between the morality and
agent and the intelligence of all the
other agents it has to interact with the
smarter the people that I have to deal
with the better I'd better be and so if
everybody else gets really smart then I
have to be good and if if all of us get
very smart you have to be good and so
forth except that there will be a big
gap between the intelligence of
different people and so if you have to
be really smart if the other the people
you're dealing with are smart enough to
figure out what you're doing but maybe
they're maybe if you're a lot smarter
than they are maybe they don't figure
out what you're doing sounds like
Nietzsche with a master and slave
morality well I'm not very interested in
Nietzsche well the fact is that that we
live in a world where there are huge
existing inequalities in not only the
intellectual resources
but other physical resources between
actors ranging from individuals
corporations and governments and it's
certainly not a perfect world but at
least to date it hasn't completely
dissolved in nuclear fire well there are
big inequalities but there is this one
the most important thing in the world
the most valuable thing in the world is
a human brain and we each get one and
that I think that's a great equalizer I
think we think that works in cash means
that that society could be that works to
keep society somewhat stable somewhat
equal is true that we have enormous in
equality of results the wealthiest
people have a well thats a million times
greater than the average and so on but i
think that the fact that we each have
one exactly human intelligence is a
great equalizer and that's what I worry
about is one that yeah but with humans
are the substrate I mean the the active
agents in the world that are doing
things are not humans the active agents
in the world now or corporations and
governments and they are nowhere near
equal in intelligence or the resources
still it's still it's still the
intelligence of an individual that that
emerges you know I mean I'm not going to
bore you all with all kinds of examples
but I mean it's still it's still an
individual that that's the most precious
thing whatever weather whatever other
information processing things we built
in our society the key is a human brain
and that and that substrate another
question all right we're done with
questions so since since I'm we have a
little bit of extra time because one of
the speakers didn't show up here so I
want to try something a little rest here
for the next 15 minutes or so which is
to reading questions to solicit comments
from the audience on the future of AGI
in case any of you have interesting
thoughts that are not directly questions
for these guys
but is still relevant and then the only
restriction I like two places no one
should go on to more than like a minute
I don't want to long monopoly so this
does anyone have any comments today
they're not necessarily question all
right in the back corner so very simple
question and do we have these replies
right now I think it's fair to say that
everything shoes or they can formally
bringing up safety like that but that
seems unsafe to me so do you know it
it's are consistent like you know what
she's hurting age I was a dog anyone
have a good attitude
any other responses the trip wire will
be politics when when AI starts having a
profound enough social effects that
people get upset about it like you know
whatever that is getting going out of
work or financial crises and instability
whatever privacy issues it's going to be
those kinds of things that are going to
affect the buggy the trip wire I think
when I monopolize anything but I have a
question we talked at length about
robots becoming evil I've even talked
about robots becoming insane all kinds
of can be a Christmas can anybody
proposed directly a direct societal
benefit to to having a GI I mean
something that not Josh that already
right why I mean for specific
application doing all the annoying work
for us it depends on what part of
society you're talking about i mean the
foxconn the company makes all the
hardware for apple has just announced
plans to increase its robotic workforce
from about ten thousand to about a
million and essentially robot eyes its
entire operation now chances are this is
going to cause it to have better quality
and lower costs for the stuff that it
produces but of course it's going to
throw the people that work for it out of
work and i think the big the big open
question has nothing to do with robots
taking over the world or any of that
stuff stuff it's going to be what do we
do when any job that we can do any job
programming you know art as well as
flipping burgers can be done by a
machine better that we can do it and
well if we do it right yes i mean i
would love to have a million robots
working for me i could get a lot more
done but how do you get there from here
that's the key question who can tell us
how to get there from here you can
go for it so I want to talk about the
possibility of a viable wild AI so that
was an agent thing that could live today
apply the attributed system on internet
like we could construct and when in
order to be viable would have to make
money and then couldn't do like hire
lawyers for itself or Assassins itself
that we do by pain okay and but it's
quite feasible to imagine we could make
an AI program with your money no by
working the markets and then it'd be you
know liable here in 2011 we could have
an age of it the government kept shut
down good torrent yeah makes money lives
to be viable today and how to fold all
of us well yeah I think an AI financial
trader if it were not even an AGI in
every sense that the human is but with
some general intelligence and some
specialized intelligence for financial
prediction could if rapidly become a
trillionaire and shutting down the world
financial markets I think you can do
that using odesk online with basic
natural language capability and Amazon
Mechanical Turk and so forth right so
that that's a viable possibility not not
not this year but perhaps sooner than a
phone human level edgy on myspace
which is the critical well and yeah
Benson myspace think altavista the first
mover is not necessarily the winner
you
yeah I one of the issues I've monitoring
purposes of my little pet peeve so many
the other day yesterday why haven't we
had more success and I think the major
reason why we haven't had more success
is we don't have the hardware this is
basically you know the brain has between
10 trillion and a thousand trillion
synapses each of which represents
multiple fights and it twiddles those
things about once a second at each so
that's 10 to 100 trillion equivalent of
multiple fights of read-modify-write
second there's no super computer on
earth that can do that so there so my
it's my thesis that's been it for
decades but you can't do what the human
brain does without something within
several orders of magnitude of the same
level of hardware is the human brain I I
believe how I felt a lot of my interest
following micro electronics and third
some really promising things like
memristors that really make it possible
to to make computers by mid to end of
this decade that could probably be
manufactured for twenty maybe forty
thousand dollars sold for several times
that that would be roughly brain level
in many respects so I I think I think we
actually have solved a lot of the major
conceptual problems I've been going
around asking people and saying this is
my thesis give me a major conceptual
problem we don't know not engineering
there's a lot of hard engineering to be
done a lot of trial and error
experiments that have to be done once
this Hardware becomes chief and I human
level box can be sold for bathing sixty
thousand dollars 100th of that would be
much more powerful than most computers
that virtually anybody in AI has once
there are thousands of those out there
tens of thousands of projects being done
on these computers and people with a lot
of money be running running their
experiments on 10,000 things I'm
to explore the space I think then things
you're really going to start happening
Jordy you're in college is a good well
it often takes more hardware to do the
research then to run the system but I
was amazed when doing image compression
research why for doing compression
research you require such insane amounts
of computer space so it's really good
for trying to bed so we have a bunch of
research privateers thousand but strong
don't be able to do everything yeah
it is Dennis asaba city by the way if
you want to did you have anything to say
on this stuff you know about about
neuroscience with what do you think
about how to measure the capacity the
brain how it compares to various kinds
of hardware we have our single any night
yes yeah yes I said within several
magnitude are ya see I want to take a
different direction uh yeah that's
another question this is just a this for
fun to bring up the question that was
brought up earlier of what role does
neuroscience play in a GI and this will
come up with a neuroscience session yeah
tomorrow but of course now we can treat
it more speculatively I mean what do you
think about the potentials oh you talk a
little over yeah sorry I think from
there to potentially useful things that
systems neuroscience research one is
obviously inspire potential ideas for
new types of algorithms for things that
we don't know how to solve yet machine
learning so physical conception holiday
edition the other thing that's probably
a good look of it is as a validation so
why market with someone you know my
particular favorite algorithm is this a
useful component AGI and someone else
how to use know or maybe if we find a
great implement
so say take for example reinforcement
learning level would pretty much agree
now is potentially useful component tool
and a GI system we know that makes sense
because there's a kind of proof of
concept is not crazy talk about Toby
important learning example as one major
component of course there could be other
AG artistic you could wear that don't
involve reinforce that it doesn't do
that that certainly it's not ready to do
designing some system with wanted one
one thing that's happened is that
neuroscience has has come up with
information processing models for the
functions of various parts of the brain
and even things like the retina of the
eye and you can take existing computer
hardware and implement the same kinds of
algorithms that do the same information
processing functions and simply say how
much computing power does it use to
duplicate the function that that we know
certain part of the brain is doing and
that's how more of it came up with his
estimates which are about a thousand
effector thousand less than estimates
based on pure raw bit flipping power
from synapses and so forth just just
want so in this dis debate between you
know should we program it in or should
we emulate the brains to bees there's
one thing to say about it which is that
the brains themselves are created by a
program which can easily fit on a USB
stick right probably even much less
which is the generic program that makes
the brain alright that's a program and
that is a very short program I mean it's
not clearly known how much of the of the
curve of the chromosomes is regulated to
brain development not that big so if you
make the program that makes the you know
that automatically generates the
structures of the brain that cause thats
all
problems you know maybe maybe shorter
watching over there there's something
missing I propose that what's missing is
the environment it's through the
interaction with the environment that so
a baby born without without parents
without a world which which which
teaches it things intelligence in
without observation will not will not
develop into an intelligent person yeah
question back there
that's one of the best BM eyes that's
one of the that exists that's one of the
best BMI designs that has been most
successful it's a cochlear implants it
they really work no I mean supposedly
and the other comments questions yeah I
like to raise a question of the
efficiency of representation inhalation
or discussions yesterday is no good
women and yourself he was in and find
that he was implying that barca body
networks which somewhat equivalent to
safer for a law because it was a lambda
calculus and then if you raised at the
level of abstraction that you get more
of a no plan B caucus Trinity level of
probabilistic representation my own
inclinations versus say I assume that I
don't know probability blogging there
was a super similar marketing networks
not sure no mark of logic networks don't
explicitly represent quantifiers for
example which is which is a significant
difference in terms of their the rope
it's representational power okay then I
can't discuss your evidence is still
high one plaintiff and also to
neuroscience at all paola have worked in
that some but not up to claim any kind
of knowledge of the matter but I'm
inclined from just my intuition I tend
to think of things more like the people
look at representations more as a
particle distribution nonparametric
abuses at the post to 916 mathematical
things you have to think hard and study
hard and kilowatt understands circle and
you know abstract concept whereas
pictures are very straightforward and I
don't know if this is true or not in
terms of how it works internally but i
wonder if sometimes the level of volume
of neurons in the brain has some
relationship to ability to deal with
things on a more of a particle
distribution nothing bread that's
indicates an elegant elegant fashion
yeah vs don't think revocation other
thing we know isn't here today right so
I mean I think that the hypothesis
underlying work like Noah Goodman's or
my own use of pio and probabilistic
logic is we're trying to use some of
these mathematical formalism to model
some thought processes that are
unconscious and humans and will be done
even in small children
like to say that because we have trouble
mastering the rules of probability
theory our minds couldn't be using with
an unconscious level isn't quite right
because I mean we most people are bad at
solving differential equations but in a
sense every neuron does that well it was
it fires right perhaps the reason you
have trouble understanding circles is
that you're still using pi and stuffed
owl I'm not sure I got the dis to your
question big matrices what's the
particle partners you using versus you
know Farrah many distributions have a
sort of power oh they're very
inefficient so they're very
straightforward I sometimes wonder at
the what that means in terms of
achieving a lot of complexity well it's
an interesting issue i mean that's
relevant in robotics right particle
filters are used a lot and they've been
less successful in in cognition so far
but maybe they could be yeah could you
speak up sir
well that's really a question for a know
who's not here did someone have an
answer for that in those framework okay
it's exactly the right framework to use
because you can model the notice
according to him yeah actually he
actually discussed noise crash so let's
do much noise we came here
I don't think that his system would
suffer that problem but I mean we you'd
need to ask him to get the detailed
answer question what having been here
the one thing that was sort of missing
in North Star right there's other ways
that you can deal with representation
and with probable probabilistic
inference and that was missing from the
there's other things that exist out that
these groups there's people that do that
and that also fit data and responses of
human responses right so the the clear
from cognitive psychology point of view
is not whether it fits the data or now
would but whether it you know it how it
does much so much better and much
differently than than other approaches
are bayesian for inference approach for
for example is one of them um so there's
a lot of ways that you can deal with
with random aside up you know over there
I guess we should call this to a close
so we could take one more question or
comment there's no one there all right
wow you can go handle the noise logical
division dementia very clean
representation
alright well fact that thanks for their
very interesting discussion so we now
have an hour before the meal at seven
o'clock and continue it in small groups
and so forth thanks a lot</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>