<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Incremental State-Space Exploration for Programs with Dynamically Allocated Data | Coder Coacher - Coaching Coders</title><meta content="Incremental State-Space Exploration for Programs with Dynamically Allocated Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Incremental State-Space Exploration for Programs with Dynamically Allocated Data</b></h2><h5 class="post__date">2008-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HRgcpbGKJgo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so now we have dark Amarna and he wins
the longest title award okay did you
know that hopefully won't win the
longest talk award make shorter for
lunch yeah yeah we're hungry um okay so
he's gonna talk about some well I'll let
you talk about it but explicit state
model checking for dynamic allocation
okay thanks yeah i'll be talking about
something as john said the thing was
actually asking what we should talk
about here whether it should be a talk
accessible to a more broader audience or
just some research talk so that it's
fine to go with the research talk so
what I'll present basically is something
that my students Steve Waterberg
presented at the XE last month and just
one piece of paper it's nothing Brody is
effing not on software testing it was
originally announced in his talks it
doesn't have much to do with testing
he's actually to do with the model
checking so basically we talked about
the state space exploration which is the
basis for model checking it can use to
find bugs or you know verify certain
properties they say what it does is that
it systematically explores the program
state space so a lot of research in this
area has focused action speeding up this
state space exploration for a single
given version of a program all these
techniques I partial the reduction
symmetry duction and so on and we've
seen tefik presented some some work say
on modular checking by the obvious is
that you're looking just at one given
version of a program anyone to test or
check that version however in reality
the software evolves it's not that we
have only one given version in the fixed
version and that's the one we want to
check but actually software goes to
various versions and we have to repeat
all these validation activities for
these versions in some sense all these
costs accumulate over time and using
actually these costs across the entire
evolution is an active topic in research
say for for something like regression
testing there a lot of techniques being
developed and explored in this area
things like regression test selection
safe test
collection desperate ization impact
analysis creating unit tests from system
tests and so on so the main idea here is
that in regression testing you're going
to run a number of tests across
subversion server programs so instead of
running all the tests at once how can
you achieve some some savings by say
running only a subset of them or maybe
reordering them to run them in a
different way and so on so that's in
domain of testing and Colin was also
presenting some way in which you can try
to also save some time if you are doing
some kind of verification across
versions of the program how can you
reuse the results from one verification
one checking for another the question
that we asked in this specific work was
whether mole checking costs for this
evolving software can be somehow reduced
in a similar fashion and there has been
prior work on that came under the name
of incremental model checking have been
several techniques proposed for that
ranging for various formalisms and so on
some of the more recent work on extreme
model checking the has been also some
practical importance of that argued so
this paper by Cisco basically saying
that if these techniques are two to be
adopted more widely than they more or
less have to work in this incremental
fashion advice it may be too slow to run
them over and over again from scratch
but all these previous technique mostly
focused on control intensive properties
they mean by that is some kind of the
example that we've seen again in the
technics talk basically if you have some
kind of state machines and you want to
check that your your code goes through
these states in a proper way so these
these techniques did not handle well
some complex data so what you want them
to do in this work was to specifically
focus on such on such data so our goal
was to speed up the state space
exploration for evolving software that
does have dynamic allocated data so even
more specifically we wanted to focus on
explicit state model checkers for actual
programs and data intensive properties
so more or less here you can think job
petfinder or jpf that's where we also
did our implementation on and these
things are important because these
these kind of tools are used nowadays
they're used you know to find bugs in
some real programs they also used to
generate test and so on they've been
show practical in a number of situation
here's just a partial list of some of
these tools that people are actually
using so here's them basic how the talk
will proceed as a standard conference
talk just some example that uses this
technique some key observations about
the state space explorations Pacific's
of our technique some extra mental
aberrations we didn't just conclude that
so here's the example suppose that we
have this class kind of similar to the
hash table class that we've seen but
here it's a bit different we have this
binomial heat plus it implements the the
heap interface using these binomial
trees binomial heaps and the key point
here is that there are some nodes that
the linked in some way they contain some
values but there are these two methods
that we have for these values we can
insert an element into the hip so we can
add the value or we can extract or
remove the minimal value from the from
the binomial heap suppose down that you
want to check this implementation using
something like a Java petfinder well
what we can do is explore the state
space of this class so what happens if
you create an empty heap and then start
inserting some values and removing what
what kind of states are we reaching and
whether they are all correct or not here
I'm just going then basically to explain
how a standard state space exploration
proceeds or the goal here is to
introduce certain terminology that I'll
require to describe our technique for
those of you who know these things it's
just quite a standard way that any
explicit state model checking works so
there is that we start from some
starting state in our case of the hips
will start from an empty hip so just has
the size zero there are no values in
there and then we want to choose certain
method to apply we want to either insert
values one or two say or extract the
minimum value in this particular
expiration we are going to limit this
depth to up to three method calls so we
are going to see only what happens with
the states of this heap if you apply up
to three methods and the values for
these insertions will be only from the
set one and two
general there is also some property Phi
that we want to check on each of these
states but that won't be discussed here
so we need to choose certain transition
then we need to execute this transition
and obtain a new state so say if you're
inserting value one into the heap we are
going to get the new hip which now has
the size one and there is one node that
stores this value one because we are
talking about these complex data and the
actual execution of the code the point
here is that this execution can take a
lot of time of course clearly inserting
just the value one into a small tree is
not going to take the time but in
general if you're simulating something
bigger you know if you're talking about
network protocols and you're executing
some action there this can take a lot of
time the difference from say you know
model checking some of the hardware
things where the execution itself may be
may be very fast so because we are
talking about the software the execution
can can be quite costly then for this
new state we can check this the property
Phi and then we can compare whether
we've already seen this state or not in
case that we've seen the state we want
to stop the exploration in order to do
that we keep this set of visited note as
he here we keep the set of all the nodes
that we visited before say of those
states and usually we hash that so this
will be some hash value of the initial
state that we had there in this case we
get the new state s1 we haven't seen
this one so we added two to the visited
set and then we continue so we need to
backtrack we need to explore another
transition we obtain new state continue
in this fashion so here when we execute
this extract the minimum value from from
this heap because the hip is empty it
will remain empty so we've already seen
this and we'll stop the exploration at
for this particular path so fact we are
just getting a back loop let me restore
this state and again continue this
exploration see that we are obtaining
some states we proceed in this fashion
eventually this is the the entire state
space that we obtained in this case
because we've limited everything here
this is a finite state so we can finish
the exploration but the key point here
is to point out that there are different
transition types if you look at this
state space there are actually a number
of
ways in which we can reach the state and
they distinguish between these three
types there are these three transitions
which are marked here in blue and what
they do is actually they get us to a new
state there are also non three
transitions they're marked here in red
there are six of them what they do is
they're actually some kind of loop so we
are either going back into a self loop
interstate that with the state itself we
are going back to some state that we've
seen previously now also some of these
deepest transitions deepest means that
we're at the end of the exploration we
specify that we want the depth to be
three so when we execute the third
method we know that we are reaching the
end of the exploration this case this
happened to be going back to some states
we visited but that's not necessarily
true in a general case so now that the
question that we can ask is suppose if
you make some change in this code we've
had this class with us some undergrad to
implement binomial hip we've checked
that suppose that there was some bug and
now we ask the student to go make a
change in the cold now the change that's
made is typically going to be fairly
small so suppose now that we want to
check the new version of the code is it
really necessary to redo all the work
from scratch so if suppose that we just
changed these the extract min method and
using a traditional state space
exploration we would really need to do
this again from scratch and explore
everything so we need to execute all the
transitions we need to do all the
property checks all the state caching
computation state comparisons and so on
indeed if you change the extract min
this is what we do have to do for the
extract min unless we know some more
information about how the change was
performed if you don't know anything we
just know that there was some change
really need to execute that whoever is
this really necessary for add well as it
turns out this is not necessary for add
many of these changes that they're made
do not actually affect all the
transitions in an exploration so if a
transition was not modified if it did
not change the method ed then often we
do not need to actually execute even
this method add and we do not need to
check what happens with the new state
the code remains the same therefore if
you execute it on the old state we know
that it's going to get to the same to
the same state we've seen before so we
can avoid a lot of these
executions comparison and so on so we
can significantly reduce costs by
reusing some of these checks and that's
indeed what we propose so we propose a
technicality called incremental state
space exploration or for short is SC
which basically exploits this
information about the prior exploration
to reduce the cost of the current
expiration so it reduces the number of
these executions the transition
executions and those it reduces the
number of all these post-processing so
the state comparisons the property
checking and so on here now I'm going to
explain how this this technique works
and i'm going to used exactly the same
example with binomial hip and we are
just inserting values one and two and
want to explore this up to depth tree
the way that this technique works is
that it will use some additional
information so regular state exploration
basically just operates on the state and
keeps a track of this set of visited
states our is se is also going to keep
this what we call input and output input
actually comes from a previous
exploration and output will be the
information for the next one in our
example if you are starting this initial
exploration we don't have anything in
the inputs effective an input is empty
so we can ignore it now so now what we
are going to do is we are going to
perform the exploration as before as in
the traditional case but besides us
keeping track of the visited state we
are also going to remember the entire
explored state basically this the output
structure will have information about
the explored state space so we start the
execution as before we execute add one
this creates in some new state what we
do now in this output we remember
basically this information going from
the initial state of the empty tree and
executing add one leads us to the state
that has now this value one in the Indus
hip we do the same for add to you know
then there is this extract min so we
remember that there is some self loop
there and basically we continue this
exploration to the end now this is done
as before very traditional exploration
however the only additional information
is that we keep track of this output
data structure basically build all this
information the entire graph of course
in some encode
version not directly as shown here this
just illustration purpose so now that
was the initial exploration so basically
we want to do incremental checking but
the first time we check some program
there is no prior prior information to
use so we had to do everything from
scratch suppose now that we do make some
change we've done one exploration we
have all these the previous graph and
now say we go to change the extract min
method for the sake of the example we
are just going to assume that it's
changed all this code is going to remain
the same it will still have the same
transitions of course our checker does
not know that in advance so it will need
to execute this to check what's
happening however what it does know in
advance is basically this thing here
which now constitutes an input data
structure so this is the graph from the
previous expiration we know that in the
old one when the ad and extract min had
some previous versions of the code this
is how the state space looked like our
goal now is to check what what happens
when with the extract min being changed
so we start then the exploration as
before we start from the empty tree we
want to empty heap we want to insert the
value 1 we first check in the input
structure whether we already have
information about this transition in
traditional state space exploration we
wouldn't have any of this input we would
simply go and execute here before
executing which is quite costly we make
this quick look up into the input data
structure and ask do we have already
information about that here we do find
that when we execute this add one anto
on to that empty hip is going to result
in some new state h of s 1 so what we do
is basically here check that we don't
have this h of s 1 in the visited hence
we need to execute this and we need to
build this new state so we execute that
we do a similar thing for add 2 again we
know that there is some information they
are going to get this s 2 but we haven't
seen it in the current expiration so we
need to execute that now when we go to
execute extract mean this operation has
been changed so we don't even look up in
the input because it has been modified
therefore we have to execute that so we
are forced to execute there then we
continue this exploration now
going to execute add one on the state
test one well ed wasn't change hence
they can look up into the input what we
do find now is that when we execute ed
this was a loop previously therefore
it's going still to be a loop because
the code for ad didn't change we've seen
this already here and I visited what we
can do is avoid this execution all
together so what we do just is we know
that in this current expiration this is
going to remain the self the self loop
and this really the key point that
instead of executing this and doing all
the post-processing with that we just do
a quick look up into this input data
structure then we proceed in this
fashion and here's the entire state
space that we obtained and using this
approach for incremental state space
exploration actually in this example we
achieved the following reductions we
avoided executing 5 out of 12
transitions so we didn't execute them at
all we didn't make eight out of 12
property checks and also we didn't make
eight out of 12 hash computations so had
we not use the incremental thing we
would have needed to execute the all
these edges shown in this graph also
while we were doing this while we were
reusing this input from a previous
expiration we were also building this
output data structure for the next one
here then the crux of this the algorithm
of how it works if we have a given state
and the transition the first thing that
we ask is whether this transition was
modified whether the mod method was
modified if so we do have to execute it
and to have all this post execution if
if not then there may be a change that
we can reuse this result so for that we
have to ask whether we've seen already
this in the previous exploration whether
it's in the input if not we have to
really cute everything if it was then
there is some saving that we can achieve
if this is the last iteration if that's
the deepest iteration then then we can
just save everything so that is the yes
branch where we don't need to do
anything however if this is a state that
we haven't seen before we still need to
execute it only so here's some formula
that basically shows the
some analytical results for how much can
be saved for the sake of not being late
for the lunch i'm going to omit the
details of this stuff it's just basic
analysis saying what are the savings
that can be achieved I'm going actually
to proceed to the empirical evaluation
that shows what the numbers show and how
much time we were able to save using
this technique we've implemented this is
se technique in to model checkers jpf
and something called jasom which is just
the specialized for network protocols
I'm going to show some of the results
for both of them so for jpf we first
done a limit study so so the goal of
this limit study was not to measure how
much time get saved if we actually make
some changes but just to do some limit
study to see how much time could have
been changed if we actually do not make
any change so we are just here measuring
you know how good the technique can be
in in theory without doing the actual
the actual modifications so here the
results that that we obtained so this is
for a number of benchmarks that we did
so for each of them we have here three
bars the first bar this is in yellow
this is called initial it shows how much
overhead our technique has this is
compared to the traditional state space
exploration that just does the things as
always we do have some overhead because
we need to maintain these input and
output data structures so if you just do
the very first the initial exploration
we are going to have some overhead but
that's relatively low overhead what the
green one shows this is the best case
this is where we label that nothing in
the code changed course if you didn't
change the code you wouldn't be even
rechecking that but just for the sake of
the limit study we just said that
nothing changing this code and then then
apply this checking algorithm to see how
much time it saves as we can see you
know it saves sometimes from up to
twenty twenty-five percent where it goes
up to over ninety percent of the savings
it can achieve then the worst case is if
you label that everything changed and
the point here is that we want to
measure what is the overhead of our
technique even in that case it gets up
to fifteen percent or so so here then
basically these
the overhead this is when we do have
some slow down into ages between one and
fifteen percent and this is when we do
have a speed up it ranges between 20 and
and over ninety percent so besides
asking the question about the time you
know how much time gets say the it's
also interesting to see how the memory
changes and as you can see here using
our technique I said see there is some
more memory required so this graph shows
is the overhead of our technique against
the traditional state space exploration
that doesn't reuse any results we can
see that in most of the case we get
about you know fifty percent more memory
hover in the case of the file system we
obtain we require much more memory so
require like three or four times more
memory for doing this incremental
fashion ever that happens to be also the
example where we achieve the largest
saving so for file system we have over
ninety percent saving there so now
besides doing this the limit studies
we've also done some some experiments
with the actual code evolution the way
that this worked is we would just ask
some undergoes to go and implement some
code and then we would get their version
sometimes there would be bugs there so
we told ever the buggies they would go
and correct this bug that's how we
basically build this the versions of the
code to be used for the experiments and
then hear the results showing again
comparing our techniques against the
traditional one that does everything
from scratch and showing how much our
technique and save time basically if you
do this incremental checking the savings
that we can achieve range is up to sixty
two percent sometimes there is some
slowdown in that the case of the heap
array a there is some slow down there of
about five percent we also done these
experiments in in this other model
checker jasom state space explorer which
focuses on network protocols and we
obtained the similar results that you
know the savings of the memory we can
the savings in time that we can achieve
ranges up to sixty seventy percent oops
sorry ladies up to sixty seventy percent
and there are some sort of slowdowns of
you know up to four or five up to ten
percent also the memory shows some
increase but somewhat smaller just
because of different people
entation of JC men and JP f so to
conclude they basically proposed this
technique called the ISS see incremental
state space exploration it what it does
is focus on these transition executions
which are costly in software and it
tries to reduce the number of those and
also eliminate some number of this
property checking so it's implemented in
in to model checkers it was evaluated
for a number of these program
explorations and you know we've shown
that in most of the cases we obtain the
speed up sort of roughly about the two
times and there's two cases where there
was a slow down but it was a relatively
small so in summary it means that this
technique one can use always so you
wouldn't necessarily need to choose
between the traditional or this one but
in theory only you could use this
technique at all times okay ishes a talk
questions
um to which extent is your method
dependent on the way to determine
whether they actually has been some
change so if you change a method and you
know you have to change that method and
then but that this might have ripple
effects and other things mud so this
marked cause maybe other model checking
activities to find out what has been
changed okay that's a good question so
basically the question is maybe even how
we find what change in which of the
transition affected by which method so
for the sake of doing this experiment
this was all done manually basically
just by you know labeling that so that's
part of the future work is basically to
automate identification of these
modifications but all these techniques
in impact analysis that effectively do
that and find you know what is the
change that was made and which of these
executions it can affect and so on but
that's a good question because one
method can call others right helper
methods if you change the helper you
need to find transitively what invoked
what and so on there's also the impact
on eyes that's done at the level of the
basic blocks namely even if you make a
change in a method it may not affect all
the executions of these methods you may
be changing only one of the basic blocks
yet your transition only explored some
other ones in that case even though the
change was made that the method level
you would still not need to explore the
same transition so there are some
trade-offs they are basically talking
about the granularity of the change it's
part of the future work so do you know
why you got slowed down in some cases
yeah the slowdowns come because the the
the technique keeps track of these
additional data structures those things
called input and output so effectively
it you know remembers the entire space
graph that was explored and it just
requires more memory and more time to
maintain that's what if that never gets
reused then you would always get this
overhead but as I showed you on the
overhead is fairly small between your 05
ten percent so the overhead is not all
that all that big so I mean was it the
size of the examples that caused it the
overhead to go up you know in some
different proportion or you know what
was it about the examples that had
slowed down that
made them different um the examples it
had slowed down the only slowdowns are
fairly small I guess you are they they
don't differ much I would not know
exactly about the time what effect at
the time what I know about the is about
the memory with someone can ask why is
there so much more memory required here
for this file system and the reason
there is that the number of outgoing
edges from each state is much larger so
this sort of the fan out the number of
transitions that you can apply at the
given state is much larger so this file
system does these things like you know
you create some directories then at each
of them you can create new directory sub
directories delete them create new files
read write files and so on so so in that
case the number of transitions you can
apply as much larger therefore the graph
that you're obtaining is going to be
proportionally larger than just the
number of states that you have that's
why they are the speed up was the
largest on the other hand as I mentioned
what this means is that there is also
the most potential for reuse and for
saving time so here we obtain also the
largest saving in time but the fact of
what this technique does is trade-offs
memory for time you just say more memory
save more information on previous
expiration and you hope that to be
useful in the next one to save you time
okay lunch
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>