<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intelligent Assistance for Desktop User Tasks | Coder Coacher - Coaching Coders</title><meta content="Intelligent Assistance for Desktop User Tasks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intelligent Assistance for Desktop User Tasks</b></h2><h5 class="post__date">2008-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KfsWPHycogs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I am abend Jefferies and I went to
introduce today's speaker who's talking
about intelligent assistance for desktop
user cast so this is a anti temasek he's
director of the carnegie mellon
university master of science and
information technology very large
information systems i made it i hope the
bill actually made that fire while
you're saying haha his research is
currently unapplied machine learning to
the desktop as part of the CMU radar
program and his research has been an
internet scale databases federated
databases and the performance of
information retrieval systems and this
is collaborative work done with John
Zimmerman who's a professor in the
design program at seeing you so they're
sort of a machine learning database
aspect to it and the design aspect and
hear about buzzer so he's been at
Stanford in in Rio so he's wandered
around the world and got his PhD from
Princeton thank you thank you so thanks
for the introduction that characterizes
my background so actually the PhD that i
did was in performance of information
retrieval and most of my publications
have been in databases so my role in
this project really is to handle the
backend including the machine learning
john does the front end and frankly and
there are design people here so preach a
bit to the choir but for non design
people when i first met John I had no
idea how it could work with them but
after talking to him I realized that I
can't do any work without him the kinds
of stuff we're doing here really is a
combination of user interface design and
they're very subtle decisions that you
can make at the front end which actually
completely change the kinds of
algorithms that you're using in the back
end the kind of reasoning that you want
to do so to build these systems turned
out to be a lot harder than we
originally thought and there are many
long sequence of failed prototypes so
i'm going to show you two prototypes
one's called virtual information officer
and the other one is called mixer
virtual information officer is in the
process of being commercialized we're
right now plugging into salesforce com
and our target user our salespeople
the other stuff mixer is hot off the
press the data I'll show you at the end
of the slide is actually part of an
experiment we're still conducting so the
size of the sample is N equals 4 and
we're shooting for like N equals 12 so
here's the the overall perspective that
we've taken we see people workers let's
say people who are using IT systems as
caught between essentially two worlds
one is email and the other is these
back-end databases and there's a bunch
of stuff that we want to do to support
this user ok one thing that we want to
do is when you get a request to do some
kind of work that corresponds to a task
and here we have a very narrow
definition of tasks that you'll see we
basically want to help that person do
the task by predicting what is required
to do that task and suggesting it to the
user the other thing we'll do is and
that's vio the mixer work we're focusing
on again the same kind of problem you
have a task to solve but here there's an
information gathering phase so we don't
assume that the end the incoming message
essentially contains all the information
you need to do the task ok so let me go
through the virtual information officer
and this is really designed to give you
an understanding of the user experience
and both the user experience has been
written up and the backend machine
learning has been written up but I won't
go into any details are almost no
details about the back end ok so to be a
little more precise we found that when
people use the desktop they have this
behavior they get a very specific
request from someone else they have to
navigate to a form system search for a
particular record and then complete the
task and by completing that task we mean
editing a bunch of field values
submitting a form may be creating a
table you'll see that later on and then
of course they have the problem of
verifying that the work that they did is
actually correct so given that you're
doing that and an example of an email is
you know please change my phone
our 2555 12 and 24 for instance a person
who is maintaining a website in the
traditional scenario that person is
going to read that email their job is
essentially to identify the data in the
email and translate it into the right
form fill out the form form gets
submitted to the database instead what
we're going to do is stick an agent here
whose job it is is to read the email for
the person predict what values have to
be filled into the form show the
predictions to the user allow the person
to approve and perhaps correct what's
going on and submit that to a database
and will show that this shifted behavior
from essentially serving as this copy
and paste agent to someone who's
approving a form increases the
performance the efficiency of the person
doing this job and in fact gives them a
better experience so here's a real email
that we got we went to someone whose job
it was was to run a website at Carnegie
Mellon we said please give us all your
emails and it turns out this guy had
carefully squirreled away all of the
requests to change the website into a
folder because he only did this job part
time and any time his manager came
across and asked him how much work
you're doing on this particular thing he
wanted to be able to prove what he was
doing so this is not an actual message
because we get federal money we had to
be very careful to personal anonymize
things remove all the personal
information but when we did the
personalization we didn't change any of
the grammatical structure we change
things like last names and first names
titles addresses but the actual language
wasn't modified and that turns out to be
key for measuring the kinds of analysis
that we can do so if you read this
message it says it's from David
McCullough who of course doesn't exist
hi Blake my new title is research
scientist and then he gives an address
in a room number and then he says thanks
David and then he gives a URL and
there's a signature now if you read this
message you know clearly doesn't
explicitly say anything about what the
task is it's only the context of the
message and who the person is that you
can translate this into the actual thing
that has to be done which is
update this person's record so that's
the first problem it's actually hard to
build models about what the tests are
and then just to give you an idea of the
target without vio the experience would
be to navigate to the modify persons
form select David McCullough is the
record here you get all of David's
information you see that he doesn't have
a title he also doesn't have an office
location you would put in those values
in the corresponding slot here and the
implication from the design of the form
is that when you do a submit those new
values would replace the old ones and
that of course any blank fields would do
nothing okay so exact here's a little
bit of how the backend works just so
people who want a global perspective of
how we get this experience processed
these email requests come in and they're
submitted to a model to an analysis
program this thing contains the machine
learning models that we've actually
trained okay that analysis will run it
will produce a bunch of suggestions like
what form you want what instance you
want what field values you want to
change or add or delete or whatever and
produce a confirmation form we present
that to the user you get the email in
the confirmation form the user could do
some previewing of the website and then
the user will modify the form perhaps
add some new information and submit that
to an execution module the job of the
execution module and you for people who
have built web services this thing is a
standard j2ee you know java program that
submits SQL to a back-end database so
that's the submission to the database
but what we'll do is take a copy of
essentially the submitted form hand it
to the learning module with the original
document that the job of the learning
module is to understand where the data
occurred in the original message supply
that is training data to these learning
these learning algorithms which then
generate new models to go to the
analysis phase so the key problem here
machine learning is closing the loop
between the signal that you want and
building the models that you get
and if you do traditional machine
learning certainly if you're doing
machine learning experimentation that is
you're only interested in a scientific
performance of an algorithm what you do
is you get a corpus you go through and
write a book you hand the book out that
has the rules of what is a label and
what isn't you get a bunch of people to
go through and label everything you
compare their labels to make sure
they're correct that gives you a gold
standard and then you provide that to a
variety of algorithms to measure their
performance here we're not doing
anything like that we're extracting the
labels directly from user experience
okay so if the user went through and
every time you had a modify person
requests you selected the wrong form the
system would be very happy to learn the
wrong model so here's the experience
that you get in vio here's the original
message you saw before we've augmented
that message with a bunch of forms on
the right hand side and there's this
request here that are sorry there's a
proposal here that what you want to do
is select the modify person form so
what's happened is an algorithm has been
run and based on the experience that it
seemed from other messages it's
predicting that this thing is a modified
person experience okay or modified
person task okay and you could pick
modify person or you can pick something
else in case the machines wrong so when
we originally designed this page we
didn't have this right-hand side bar we
just had a line that said here click
here to do your task and then when you
clicked on that we would simply show you
the form which was the one we had guests
and then of course it was easy to
navigate off of that form to another one
we found out that that doesn't work at
all when you sit a user down and he
clicks on a link that says nan to your
task and he's presented with the add
news page when he's trying to do a
modified person he sits there for about
10 minutes trying to figure out what the
hell's going on so the only way that we
can figure out these kinds of mistakes
and design is of course sitting people
down actually using them that's an
incredibly expensive way to fix design
errors obviously with good experience
you can reduce the number of these
things that show up when you actually
build a system but
that was a real learning experience for
me I had no idea of the kinds of things
that would pop out and so now we're very
careful to follow I would say almost
rigorous HCI procedure we do contextual
inquiry zwi do very low fidelity
prototypes including showing people
pieces of paper and getting their user
experience from that then doing low
fidelity and then doing implementations
of front ends and then finally full
fully develop prototypes so after
clicking modify person you're going to
get this experience there the left-hand
side you have the email on the
right-hand side you have the same form
you had before but there's a difference
in marked in orange are all of the
suggestions that the system has
extracted that it thinks are relevant
changes to this particular form and
they're marked on orange on the right in
addition the system has not gotten the
room number RM space 390 a recognizer
that's associated with room numbers
doesn't function very well because it
hasn't seen a lot of examples of room
numbers and it missed it it didn't
suggest anything the user has typed in
our and 390 there that's marked in blue
so of course what's happened is the user
has compared the request he wants to do
with the right hand side form corrected
it and then submitted modify person all
these labels then are then used as
evidence to build new machine learning
algorithms so the system learns with
experience now there are subtle problems
even on this page it turns out that when
we actually ran a behavioral study our
instance learner that is the learner
that decides which instance you want to
modify made a mistake it thought David
McCullar was actually David Robertson
and then it's you know blithely said oh
there's a new last name here so if you
just clicked submit on this form without
looking very carefully at it you would
happily change David Rogerson's last
name to David McCullough so it's clear
that subtle mistakes in the interaction
or subtle assumptions that the
interaction designer has can have
disastrous consequences because this is
a really bad update and there are lots
of different ways of getting around this
one thing to do would be to build models
of unlikely
dates and then do outlier detection and
try and flag things that you found
unusual our current solution isn't to do
that our current solution is to change
this thing to say modify person David
Rogerson and it turns out that at least
our belief is that when you're reading
this you're going to know who's it from
that's in your mind and you're going to
read the wrong name and so it's very
easy to detect this particular mistake
at this step in the workflow okay that's
the way we've implemented it now we have
to run a whole nother study to figure
out whether that actually does reduce
errors or not ok any questions not yet
ok yeah if they do make a mistake and it
does its taste later and there's a
rollback warning
that's an excellent question so right
now what would happen is it wouldn't do
anything it would simply record both and
then the learner would be forced to deal
with the question of what that evidence
meant for its model now if you made one
mistake and then you did it right a
hundred times machine learning
algorithms are pretty robust to this
kind of error and they'll say oh look
you know one time he didn't choose
modify person with this distribution of
the input but the other 99 times he did
so yeah it's a modified person okay
that's a great question and there would
be a question about trying to go back
and figure out what the mistakes were I
think that's probably very hard because
you'd have to actually understand the
true intent of the message so is it the
fact that you moved you changed the
mobile phone number is that because he
got a new mobile phone or is it because
that you somehow missed the mobile phone
number on the last message something
like that I think that's a great
question I don't see an easy way of
attacking it but i'm going to add it to
the list because after great research
problems thank you there is another
question here this experience that
you've seen if you want to build it one
way of doing it would be to you know
higher PhDs in computational linguistics
and sit down and get a corpus of 10,000
messages and build yourself a very high
quality recognition system we don't do
that because we were interested in the
scientific question essentially of for
this particular domain can you get away
with doing something that isn't so
expensive so obviously if you have to
have a deep AI understanding of what
you're doing you need all of that
machinery and it's very hard to do and
you need complex models to the target
but could we build something which was a
much simpler model and it turns out that
for this to me and the answer is yes
we're just building essentially for each
interaction a machine learning model to
try and produce suggestions for that
particular interaction and there's no
explicit engineering or labeling so we
just took the default feature space that
we got with the machine learning package
and we applied it and yeah it's true it
does a really bad job on phone number on
numbers on let's say room numbers
because in the 200 messages we gave it
there were only 10 examples of room
numbers so you're not aided in that
particular part of the interaction but
it turns out for the stuff that commonly
occurs you have a lot of evidence it's
right most of the time and it ends up
helping so and here's the machine
learning we use for forum suggestion
it's cayla classification for field
suggesting we use conditional random
fields and for instance suggestion we're
doing a form of reference resolution
there's an entire paper that documents
all this but the question is how can I
actually know that this stuff works so
we measured it we took a corpus we
anonymized it it had a bunch of events
file manipulation news people in it and
then we simply sat down with an empty
system and used it for 189 messages so
of course the first time you actually
use the system it's not going to make
any suggestions and these learners are
very high precision and very low recall
because to suggest something that's
incorrect is much more expensive from an
interaction point of view you have to go
back and delete that particular action
and it and if it simply suggest is
nothing then you're simply doing what
you would normally do right which is
fill out the form so we go through fill
out the form for 189 messages run these
models and then simply test the held out
messages and count how correct they are
and we're going to run these metrics
incrementally there's a lot more data in
the paper and I've got more slides that
show you the results but the answer is
here it not exactly sure this looks like
in the mid 40s or something 75 or so
we're we're going to stop this labeling
procedure and run the algorithms and
test how well they do and you can see
that depending on the algorithm you get
a separation performance but they're all
climbing over time this metric over here
is mean reciprocal rank so if we suggest
the correct form first you get one point
if you suggest the correct form second
you get a half point etc third you get a
third of a point and then you just
average over all of the
test set to see how well you do and
we're approaching like 95 with the best
combination algorithms and this is
decision tree maximum entropy you know
the usual suspects here svm boosted
decision tree so it turns out that if
you ask sales people for instance how
many emails do they do in a particular
day it's like 30 you know is sort of an
average from one set of people we talked
with and so after a few days the system
is going to be suggested doing very well
and because it's high precision it's
actually going to be only producing
suggestions that are correct okay now
all that doesn't matter because it's
interesting to note that you can
actually extract labels from the
environment and run machine learning
algorithms to measure how well they do
but the ultimate test of course is
whether the system actually helps you
right if it slows you down or it's
irritating or something like that people
won't use it so we're going to do a
between-subject experiment we take 20
subjects these are people in the CMU
community not only students but other
people who sort of show up and do
experiments sort of for fun and we're
going to give them 20 training tasks
because we are interested in skilled
performance and then we give them eight
real test tasks and measure a variety of
things accuracy time their perception of
the experience that kind of thing one
thing that we found which was very
important was the incentive function so
if you got an undergraduate and you say
now here's ten bucks come use our
software for a while have a good time
most students will actually be very
conscientious and you say please execute
these tasks will do the right thing a
small fraction of the students will not
be conscientious and simply blast
through as fast as possible because it's
a time value of money kind of thing if
they get out of there and a half hour
instead of an hour they just doubled
their money so we had to actually change
the incentive function to give them
incentives for accuracy and time it was
interesting the impact so I'm moving
really fast here you can interrupt me if
you like
so this is sort of a summary the first
half of the talk in sort of one piece of
this is so the condition where you you
don't use the virtual information
officer is just a classical content
management system and that content
management system is exactly the forms
that you saw we just simply stripped out
the interaction tricks that we had and
stripped out the machine learning so
it's actually a pretty good form system
if you if your job is simply to do data
entry certainly far better than the
equivalent system that CMU uses at the
moment which was built in you know the
eighties or something is disaster so
then this is the rank of participants by
condition so this is the rank of their
total task times so this is the fastest
user in the vio condition and this is
the fastest user in the CMS condition
okay and you can see that if you order
people this way there's this clear
separation all the way along except for
this guy who of course was a complete
idiot unfortunately murphy's law says
that the complete idiot always ends up
in your condition not the other one but
you know essentially these lines are
parallel and our interpretation of this
is that you're getting a fixed
performance improvement essentially
independent of skill so you could sort
of interpret this as a measure of how
skillful you are and lo and behold it's
helping you everywhere along the
spectrum so if you're an expert user
down here this gap compared to this
represents about a thirty thirty-one
percent improvement and if you just
aggregate everyone together independent
of their rank you get a 17-percent
performance improvement and time and
those are both statistically significant
and there's no statistical difference in
terms of errors and there's a lot more
detail on a lot more slides a sort of
data that we've extracted in these two
papers which I encourage you to read or
you can just ask me I'll tell you okay
yeah
how did you measure errors was it just
scripted the number of hairs are you
looking at the sparing the types of
errors are there were oh yeah there's a
long explanation and a detailed analysis
of the kinds of errors they were making
and turns out that if you go back to
that original message of blake's and you
look at the form you know there's two
ways of interpreting the correct you
can't really see it here there's two
ways of interpreting the correct update
one would be to just change his title
and ignore the fact that he's got a new
room because it's not really clear that
that's part of the update and some
people didn't actually add that and we
decided to count off for it we decided
that you had to be a conscientious user
and use the most complete update there's
another example where there was data
actually squirreled away in the
signature there wasn't in the actual
message and again there was a question
about is this legitimate update or not
and we were we decided to be as strict
as possible just because we had to pick
some rule and that seemed to be the one
that was the most conservative okay so
now we're going to leap for well the the
original work for this was done about
the time that vio was done a little bit
later but we've gone through sort of
several revisions but the objective here
is to provide a way for people basically
to specify the kind of information that
they'd like to have to solve a
particular task and have that sort of
automatically attached to the message so
again if we went off and did a
contextual inquiry and ask people who
have office assistant jobs at a
university what they did and they do an
amazing amount of work that I find
horrible a typical example is what are
all the midterm grades of the students
in my degree program that's four hundred
and twenty students and it turns out the
IT system doesn't give you that answer
in a nice little list the only way of
getting the data is to look up each
person's individual record
that takes five hours for someone to do
and she does it every single semester
okay this kind of tool and this is a
quote from person who was in the study
who had this job she said with this tool
I could solve that problem within five
minutes and we actually think that's
true another good example which shows up
later on is the associate dean for one
of the program's gets an email about
once a week it's someone who's broke
their leg or you know got arrested or
whatever for whatever reason they're not
going to show up in class and so what
this person does is send a message to
every instructor of this student that
the student is unavailable for whatever
reason and the quote we get is that that
takes two hours and again they're
essentially if you know SQL and
databases they're simply doing a joint
across multiple tables but that
information isn't readily available and
they essentially have to repeatedly
navigate the form of the join by going
to various data sources okay so this is
what we want I'm sorry this is too hard
to read here we have a visitor from
Korea tomorrow he's interested in how we
teach though I thought I'd have him sit
in on 21 369 section a meets tomorrow
can you tell me how many Korean students
are in this class after using this tool
there's a script that's generated
effectively a program you can think of
it as a sequence of SQL queries that
will be recognized as relevant to this
particular message in the same way that
forum selection is done in vio it will
be executed automatically the results
will be attached now of course we're
going to make mistakes turns out the
penalty for a mistake here is completely
different all you have to do is ignore
the data so in vio you wanted to be very
high precision at the expense of recall
because if you made a mistake people
might have to type or do something here
you probably again we want to have lower
precision and higher recall and what I'm
showing you is a mock-up is the vioce
stuff is about ready to be
commercialized this is still in the we
have the front-end actually operational
with the backend is
okay so the question is how does it work
and now you're actually seeing the the
front end which we've built here's a
copy of the message and you get what is
actually you can think of as sort of a
mini Excel spreadsheet or a very stupid
Excel spreadsheet and it just says label
and value they're empty there's no table
name and there's a little thing that you
can hold here to drag you drag it across
and you fill in all of the columns with
the data that you you need to solve this
particular query so what's the course
number what's the section what's the
course title what's the students last
name what's the students for his name
and what's the country you don't
actually need all these columns to
answer this particular question and
there's some variety here about what you
could actually do so one of the first
questions is are people actually capable
of conceptualizing a table which would
contain the data that they need to solve
a particular problem sort of a very
fundamental question and we did actually
first paper prototyping and then a study
using Excel to actually convince
ourselves that they can actually do it
so essentially office workers who have
these kinds of problems who deal with
information systems have actually a
reasonably good model of what's going on
in their heads now it turns out that
there's all this other stuff that's in
their heads that you don't want to
acquire for instance we don't acquire
the aggregation function of counting we
don't acquire acquire the fact that you
want korean students okay so there's
this careful line about exactly how much
information you're trying to extract to
solve a particular problem and that's in
that person's head and the reason that
that's important is a lot of that
information is changing over time for
instance another person we interviewed
the the incoming request was please add
pen fan to my studio to course now it
turns out that seems like a simple
request it's not there's this
complicated bureaucratic procedure that
has to do with is this student a member
of my degree program or not is the
student on the waitlist does the student
take 30 credits or more if they do they
have to fill out a separate / separate
form so these complex procedures which
essentially is the job the real job
office assistant to maintain those
procedures and understand how to execute
them when they're given requests we
don't actually want to capture that
information it's too expensive it
changes too much so here we're focusing
on essentially a very narrow interface
that gets the most of the way to where
they want to be and saves them a huge
amount of time okay so back to what you
do what you do is you take the section
number you copy it into the course
number column and then of course you've
got to go off and navigate to the IT
system to acquire all this other
information which is what you would be
normally doing to answer this particular
question so here is a copy of the
student information system that we
reproduce because we couldn't use the
production one obviously you're
selecting class roster you're putting in
the course number and the section number
and you're getting a listing of these
people you're going to copy the title of
the course into the course title you're
going to copy the first name and last
name and a student first name and last
name here then you're going to select a
student and look at their bios screen
display it's it's amazingly bad
interaction but we faithfully pretty
faithfully reproduced what the actual
system does and then you get this other
page and lo and behold their nationality
is right here and then you have to copy
and paste that into the country field
now remember that clunky interaction of
four screens you'd actually be doing for
you know no matter what you're going to
be doing that anyways and then what you
get is this wonderful single line that
you've demonstrated of the information
that you want and then you're going to
use this fill in table button and this
works conceptually sort of like pulling
down a mark set of cells in Excel it
essentially says to the system you know
do what I told you to do over this set
of data and here it's like okay go fill
in the table right here I gave you an
example go do it and what we we've done
in the back end or we will and we've got
this working with a different front end
is we simply record the sequence of
database calls between the application
and the database that gives us a listing
of SQL
and results we actually can go through
there find all of the constants that are
relevant turn them into variables and
give us a program to execute because of
course that's the ultimate goal is the
program that the person implicitly told
the system they wanted to execute by
going through those navigations it's a
lot like a macro recorder just a little
bit smarter okay and then what they'll
do is they'll hit fill in the table and
the system will do exactly a procedure i
described generate this program and do
this retrieval and here you get all the
students okay and the stuff marked in
orange is essentially a signal to the
user that says there were multiple
possibilities in this particular
location so when you tell me fill in the
row and this thing those are the ones
that I'm going to expand tell them which
things done constant which things are
those various terms that you can tell by
looking at the script it's just the fact
that when you follow the variable that
appeared in a particular answer it ended
up in a result set of a query and so you
know that the next time you're going to
end it execute that query by replacing
some thing in the in the actual query
itself you're going to get a different
number of answers so you could figure it
so as they wouldn't done before
something example the question would
have been to them I need to know all of
the you know the classes but Barbara
Adams is in it would have gone about
doing that a different way yeah it would
have solved the different query and then
you would have gotten in fact that's
much simpler presumably the interface
would support that much more directly
one would hope but actually with it yeah
with whom with this system we're
actually not that sure um so and so you
could fill in the table here and it
turns out that from this interaction
there is something this is actually the
training interaction for the actual
experiment that we're running now but
there's a subtlety which is that if
there's a set of choices in the email
those are
legitimate ways of filling in a
particular row here so if you had to
section numbers then you would have
gotten an orange here or to section
numbers you would have gotten the same
course number but orange here and
presumably non orange because probably
the course title was the same for both
sections and if you had two different
course numbers it would give you another
set of rows here which are the other
course the sections the course titles
and all the students there and in fact
the reason that that's critical is
because people send spreadsheets to each
other and what we want to be able to do
is drive the execution of the actual
program off of rows in a spreadsheet
okays and that turns out to be a sort of
a very powerful next step and when we
went and talked to customers and showed
them vio they said oh this is great but
it's only point wise you're only doing
one update / email what happens if I get
a spreadsheet or what happens if i buy a
customer list and i want to update this
stuff and this invokes in my background
all this questions that are currently
being researched about federated
databases and applying machine learning
to federated databases problems data
cleaning that kind of thing anyways so
the idea of course is that if you get
another message here this is a bad
example because the text is identical
but if you get another message that the
classifier decides is the same script it
will do the extraction of the course and
section number in here execute the query
again okay so it turns out that we're
using end user programming which has
some great power but if you know the
literature there's sort of a long series
of programming by example car wrecks in
the literature many people have built
these systems but they're very very
difficult to actually deploy and work
because they've got these tricky
problems one is what you know how do you
get conditionals into the system you
know how do you get an if statement how
do you terminate the loops how to figure
out when things are terminated and we
actually have sort of solutions for
these questions but it turns out we
think a good paradigm for these
administrators who seem to be able to
understand how to manipulate this kind
of system okay one thing that we do
that's different is there's no
requirement that you get all the
exceptions right up front you can simply
execute the system and if it breaks at a
certain point the system will come back
and say I'm sorry I don't know what to
do here can you just simply demonstrate
a little bit more retrieval to filling
this part of the date of space and then
what it will do is take the two scripts
and scissor them together using a
conditional right you've where of that
or you've seen it before I'd like to
know where you've seen yeah but yeah
that's a hard problem and and another
example of this Korean thing where we
don't think the programming by example
is a good solution suppose you really
want it's smoking especially at 10,000
student park suppose you had a thousand
students and you don't want to read
through a thousand students to figure
out who's Korean you could just turn
this bar here into the list manager in
Excel which is this I don't know how
many people are familiar with this it's
sort of a subsystem of Excel we are
allowed to do searches and selections
and things like that so when appropriate
we want to stick in direct manipulation
okay so just one comment for non design
people design people beware very well
aware of this this is actually a
screenshot of a particular user trying
to fill out a form based on a message
and that's what we did to figure out the
basic questions of how to do the
interaction here there are other many
tasks that we think we actually cover
you know give me a phone number for
everyone in New York City that's
probably not such a great example but
this is something that's been mentioned
before how much money is left in the
travel budget that's a question I ask
every once in a while from my office
assistant and I'm sure that that
question and CMU is asked probably
somewhere at CMU every day and obviously
the scripts once you create them you
share them which we haven't done a lot
of work on we plan to do there's a
related project at IBM which is
incredibly good work called co scripter
where they've really focus on
collaboration more and this one came
from a student give
the yards carried last week for every
running back in the NFL he's a fantasy
football guy it turns out that he was
doing this complicated retrieval every
week now if you understand the backend
issues this thing turns out to be much
much harder to do because you need to be
able to scrape websites and there's this
whole question about extracting
information from websites which in a
corporate environment we ignore because
we have access to the JDBC driver but
that's a whole separate discussion about
sort of the where this functionality can
be deployed and here are some results
hot off the press there's a grade
problem which is give me the grades of
these students there's this sick
scenario which I described before get me
all the email addresses of from of the
instructors for the classes of this
particular student and what we do is we
give the first problem and then we give
the second problem so this is the first
task this is a second task where clearly
the mixer program is being invoked so
the amount of time it takes to do the
task is of course vastly different this
is not even really a fair comparison
because you have to go through and do
the thing manually here and the
program's being executed on your behalf
here but I think the really nice thing
about these results are that even the
first time you solve that particular
task it's faster to use the tool than it
is to do it manually and the key
question about these one of the key
questions about these systems is
adoption will people is the barrier the
initial barrier using the tool low
enough that people actually use it and
this has crushed many a system and we
think that this is a really good
incentive function if you can convince
people that it's not going to take them
more time to use the tool then not use
it and let any o ignore the fact that it
generated a script it's still going to
be faster this I think is a great
incentive and the reason this is true is
that it's going to take you a little
more time to build that table but that
calculate bros the extra time it takes
to do that is saved by the calculate
Rose button and here we r there are four
rows in the email so you're going to
have to do some kind of retrieval four
times so the trade-off is somewhere at a
size of around
items okay and that's it's obviously
complicated to measure tests but I'm
trying to give you some understanding of
where the break-even point is obviously
if you had only one retrieval to do the
tool wouldn't help you unless you
predicted that that particular retrieval
would have to be done again and then of
course you would get this benefit but
that would reserve require some
proactive behavior on top on behalf of
the user and now you get into this whole
sort of psychology of the user are they
mavens are they somehow is their
identity attached to using technology
and all that kind of stuff are they a
laggard in which case they won't think
proactively and we don't want to get
into that space we sort of want to
convince everyone that you know anytime
you want to do navigation just use the
tool okay and there's so much related
work here because we're drawing on so
many different areas I just wanted to
call out some things there's some
automatic form-filling work there's this
famous work by using forms and
communication from Malone look out as an
example of by Horvitz which was a an
Outlook extension that was trying to
proactively help you use male eager
which is one of the very early systems
and programming by demonstrate an
interesting program by example system
there's lots and lots of work on email
and personal information management
there's obviously these natural language
processing things and then this
reference here cleo is to a data
integration problem because going back
to this this is a real leap here for
people who aren't familiar with this you
can think of this as building a mapping
between a source set of tuples and a
target set of tuples and that's what
Cleo does in the database environment
and then I can talk a lot about other
things that are related one is google
auto link so if you some people might
not be familiar with google auto link if
you have a google if you have the google
desktop loaded and you're on a page
there's an auto link button you click
that button it scans the page for
addresses replaces the addresses with a
link to google maps
it also finds things like UPS codes
fedex codes that kind of thing so from
an abstract level it's the same kind of
problem you have natural language text
you have a model which you're applying
to it and you're presenting a form as a
result of course that form is a URL not
a bunch of field value pairs but it's
still the same paradigm obviously Google
Mail will recognize calendar events for
you ask them if you want you want to add
it to a calendar these are sort of all
related behaviors even Microsoft's
Clippy which is sort of a famous example
of how not to build these systems is an
example because it recognized Dear John
comma which is a natural language text
document input it applied a model and
say oh you're typing a letter and then
it presented a form in a very irritating
way that said yeah can I help you with
this and as you pointed out it wasn't
even clear how it was helping you and
then you proceeded to beat your laptop
to death because it was so irritating in
fact Clippy was such a failure Microsoft
ran commercials advertising the fact
that Clippy was not available at Vista
they were actually advertising the death
of one of their products to sell the
next generation of the products that's
that's an amazing thing or at least I've
seen YouTube videos of things that
convinced me there are professional
quality advertisements that we're doing
that so I believe it and then the last
one which is maybe the grandfather of
well not exactly the grandfather there's
something called QB query by example
which is a very famous system which is
Microsoft's access interface is very
similar to done by loof and here this is
not programmed by example users actually
essentially construct variables but it's
very so similar in sort of in its
interaction flavor in other ways okay so
I think I did that in like 30 minutes I
don't know what time it is any other
questions yeah
the features you are using forgiveness
yeah so for vio as I for vio the first
one as I said we're using essentially
the default set of features that show up
in the machine learning algorithm so
here for forum suggestion what's called
the wild label which is the interaction
label that you extracted is the form
that you actually selected and then we
have a process called domestication of
the wild label this is something we sort
of inherited which is generating the
actual label we use that's pretty easy
because you're just flagging that
category as the label and we're using a
bag of words representation for a
document here plugging it into a KOA
classifier I think we use naive Bayes
actually but you saw the experiments we
tried a bunch of different algorithms
and then here's the key thing you're
going to threshold this you're going to
compute likelihoods and then threshold
because remember it's high precision if
the system isn't confident and knows
what form it is it's much better to say
nothing because there's this whole
question about extra labor involved in
fixing anything that the system does
wrong and also building trust the system
is almost always right you're going to
tend to believe it okay for field
suggestion the field value that is in
the form so that RM space 390 room
number is then used as the wild label
and we scan the input message find that
string and label that string in the
input message as the gold label for that
particular extractor and then we use
state of the art here conditional random
fields over documents the conditional
random fields is state-of-the-art
sequence learning and then instant
suggestion here oh I'm sorry you asked
about the feature space so it's things
like it's a standard set of features
it's like this start this has only
digits this starts with an uppercase and
then has only lower cases this has
uppercase lowercase uppercase
if you read sort of information
extraction papers there's sort of a
collection of features that are
typically used now the rule here was no
specific engineering at all because we
wanted to avoid the game of secretly
adding features to improve performance
or not secretly but it's it's very easy
to look at the input data and say oh man
i just missed one thing here so we
banned anything we do make one exception
to that rule which is that we use a last
name dictionary in a first name
dictionary because it turned out it you
know doubled performance and so we we
broke that rule for that one instance
but for instance for titles like you
know research scientist or whatever what
we do is we read the set of titles that
are already in the database and use that
as a dictionary so that's how we get
around first name last name and all the
other fields and since you're asking oh
and then the last one instant suggestion
here you build a vector of all the
extractions then you take that vector
and compare it to every tuple in the
database and compute a delta between
each attribute and that particular
instance so for instance and score it so
if you have the same first name for that
particular attribute you'll get a one as
a score if you have a different first
name that has no overlap you get a zero
you do that for every single attribute
now you have a bunch of vectors that
tell you the difference between your
input value in each instance in the
database and then you can run you know
any machine learning algorithm you want
over it at that point because it turns
into sort of a classification problem
and that's just the general scope of the
algorithm that's obviously too efficient
inefficient to do in a scaling way we
have ways of making it much more
efficient it's very close to duplicate
elimination work that's done in machine
learning and since you asked that
question you get a freebie I'll give you
some more data here we are so here's
extraction performance for a bunch of
different categories this is BIOS it
turns out this is just a side effect all
the BIOS were almost
tentacle here's our ability to recognize
an email over time here's their ability
to recognize a first name over time this
is a last name here and then this kind
of effect here that just turns out to be
a side effect of the fact that the test
the the test set had only a few examples
so you're getting really high variance
and just to explain this this is the
number of examples that show up out of
180 messages so actually every message
here contains a first name but some
messages contain no last names because
this happens here and obviously if
you're on the left-hand side you have so
few examples you get bad performance and
if you get a lot of examples your
performance basically goes up not
surprisingly now the key thing here
about this is that even though the
performance is all over the map the user
still is more effective and there's this
underlying correlation between the fact
that the stuff you've got to move that
appears often in messages will obviously
end up being examples that occur often
so you get better machine learning sort
of focused on the areas that you're
actually manipulating okay so yeah if
some weird field is in that form that
you fill out one out of a thousand times
it's not going to be able to predict it
because it's not going to have a lot of
evidence that's not surprising given the
rules that we have okay another question
so i can give another surprise yeah mix
or question so oh did you car interest
in the federating databases are you is
there sort of a metal level where you
see that mixing they're basically doing
the Federation
across these silos databases right that
yeah that's nirvana right where you
would take the the logs of the access to
two siloed federated databases feather
scissor them together and run the
program across both of them yeah and
then I actually think that that's the
way to do integration now right and so
the next person that comes in that view
is pre created as that's where they
start on that view yeah yeah I mean that
would be fabulous thing to try we're we
actually tried comparing a previous
version of a mixer head-to-head with
Cleo which is a direct manipulation
interface where on the left hand side
you get this the source on the right
hand side of the screen you get the
target and the interaction is simply
drawing lines and we were trying to beat
that and it's not quite as fast so we
couldn't publish it but we actually
think that with a little bit of work we
can at least tie us you know an
engineered explicit expert interface for
doing data integration versus something
which you know the vast majority of
people can't understand versus something
that everyone does every day which we
think is a pretty important
demonstration that maybe people ought to
be thinking about the federated database
problem in a completely different way I
spent three years building federated
databases where the target was the
programmer and you were trying to give
him a better script but instead in fact
a lot of federated queries are actually
being executed every day by office
assistants right they essentially do it
by hand so why not acquire that labor
and use it but it's a you know or years
away from that and it turns out that the
what actually happens is right now we
use the JDBC driver the next version
will use an abstract engine so we'll
separate ourselves from the driver and
use an abstract engine and then you can
plug in operators that do fuzzy matching
and all that kind of stuff cuz you can't
do fuzzy matching in SQL it's almost
impossible you could bury it inside of
the database but people don't do it that
way they have application programs that
do it good question ok I've emptied the
room
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>