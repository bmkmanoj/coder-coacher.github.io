<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AGI 2011: Architectures Part I | Coder Coacher - Coaching Coders</title><meta content="AGI 2011: Architectures Part I - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AGI 2011: Architectures Part I</b></h2><h5 class="post__date">2011-09-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Rgjw8O3vLBs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody where my name is cavia
Snyder and I am member of the CCRC group
of the University of Memphis and today I
am going to present the lighter
framework several of you have been in
the tutorial earlier in this conference
so probably you know what this is about
ok software frameworks are our reefs
able a pieces of software that
implements part of the main structure of
a system the idea the main idea of
framework is to implement the common
part of an architecture and the user of
this framework can a complete of filling
the blanks with a specific part of the
problem and probably this is one of the
main advantages of frameworks the idea
that the developer only need to
concentrate in the domain specific the
important part of the problem that it
wants to solve it also frameworks also
promotes good code in the form of best
practices design patterns design
principles that leads to a good designs
of software these all of these speed ups
the development of new applications and
this kind of frameworks us have a
enormous success in the enterprise
application world yes and cognitive
systems are really
good candidate for this kind of
frameworks it's it's an idea that we can
strike from the software engineering
world and apply to this kind of
applications the lighter model is the
architecture that we develop in Memphis
I am NOT going to go in detail of this
architecture but is the base of our
software framework you can go online and
read about this architecture in detail
but this is a good example of cognitive
architecture or maybe an acei possible
architecture where you have several
modules that are interconnected and most
of this modules have different
implementation different algorithms as
part of its implementation so what is
the idea behind the lighter framework
the lighter framework is a software
framework lamented in Java so you if you
use it you can run it in almost any
platform this framework implements the
core of the light architecture and most
of the boxes that you have seen in the
previous slide are already implemented
you don't need to create from scratch
all these boxes of these modules and you
probably only need to do the domain
specific classes the domain specific
modules of this system another important
idea behind this framework is
that the customization and the the
change of the implementation of modules
of other part of the system should be
easy and in that way modules processes
even data structures are very easy to
interchange in the current fringle
implementation also even if the
framework provides implementations for
most of the modules in in the Lida model
you can change that implementations and
integrate in your application very
easily for example the current
implementation use sparse distributed
memory for episodic memory but if you
want to use a database for example it is
very easy to implement that module
integrated as part of your architecture
and of course we we use a lot of design
patterns and good practices in these
frameworks that again leads to a easy to
maintain easy to modify an easy to
understand a software design some of the
most important features of this
framework it use multi trading to to
execute several task at the same time
and we create a kind of transparent
multithreading using an element that we
call tasks and a task manager that
controls the execution of this task in
parallel also the architecture the asian
that you want to create
is definer using an XML file instead of
doing that directly in Java so first or
basic customization of you of Eurasian
can be done simply changing a XML
definition we also provide in this
framework a very customizable a GUI and
login mechanism that facilitates the
interface with the application and maybe
most important for this conference the
frame were itself done doesn't have very
strong commitments to the lida model it
was built in such a way that is very
easy to create different modules that
are not part of the Lida model and
eventually you can implement very
different architectures using the same
framework actually I ambition that if
this happen we can combine module four
different architectures and try
different combinations of the
architecture so again it's it's possible
to implement other architectures using
this same framework the main elements of
the framework are models that represent
the boxes that we saw in the diagram
before listeners to implement the they
are rose and the connections notes links
and no structures that are the main data
structure in the framework and as I told
you before task and task manager that
implements the behavior and the
execution of the modules in the
framework well this is a screenshot
out of the gooey of the of the framework
in one application again this goo is
completely optional so if for example
you want to use the framework to control
our robot you don't need to use the the
GUI and also it's dividing panels
different regions here in the in the
screen and you can create your own
panels for example here the hamburger
world that you see in the left it's a
module for one particular sorry sub
panel for one particular application and
you can create your own for your own
applications so summing up all of this
the this framework facilitates the
development of software asians there are
less time spent in generic part of the
applications you don't need to start
from scratch one and gain each time that
you create an applications developers
can concentrate in the specific problem
the pacific application that you want to
implement its highly customizable and
extensible supporting tools are provided
like the GUI and login and hopefully it
could be a general framework for HCI i
want to thanks a all members of our team
the cch-cch e group at the university of
memphis thank you very much
so we'll take questions in the panel
session at the end of all the speakers
are next up we've got Paul rosenblum
hello what I'm going to do today is tell
you about it an experiment in mechanism
reuse in a graphical cognitive
architecture in going from a memory
architecture to a problem-solving
architecture you to start with just to
touch a background on what a cognitive
architecture is so it's essentially a
hypothesis about the fixed structure
underlying intelligent behavior finds
the core memories the reasoning
processes the learning mechanisms and so
on the idea well so here's a quick
concrete example this is the sore
architecture in midlife essentially
versions three through eight it consists
of a symbolic working memory a long-term
memory of rules a preference based
decision procedure that decides what
operators or actions to perform the
ability to reflect on its own
performance when it can't make decisions
ability to learn from that reflection to
generate new rules and the ability to
interact with the world so that's that's
the thus or architecture kind of a
midlife when you combine the
architecture with knowledge and skills
the ideas did you get intelligent
behavior and the goal here is breath or
generality so by adding different kinds
of knowledge and skills you should get
different kinds of intelligent behavior
out of the architecture an architecture
can then serve as the basis for a
unified theory of human cognition as the
core of virtual humans intelligent
robots intelligent agents or is the
basis for artificial general
intelligence now the issue I've been
working on for the last couple of years
is something called a diversity dilemma
or how did the architectures that
combine theoretical elegance and
simplicity with broad functional
capability and applicability we're under
capability we'd like essentially a
superset of the kinds of things you see
in existing architectures not just
cognitive not just perceptual motor but
also motive social adaptive and all of
those kinds of things now the problem is
architectures often start out simple and
as they live over time there's push for
more and more functionality you get more
and more complex and you start losing
all the benefits
theoretical elegance and simplicity so
again if we look at the sore example
again up to saw rate it was a fairly
simple elegant architecture with one
kind of each thing when you go to soar
nine the push for increased
functionality led to considerably more
complex architecture there now three
additional long-term memories not just
rule memory but episodic semantic and
visual an additional working memory for
visual three new learning mechanisms
plus some additional stuff so that was
all driven by functionality what you can
one way to view what I'm trying to do is
to say all right I want to be able to
take that same level of functionality in
fact I want to go be a way beyond that
level of functionality but with the kind
of simplicity and elegance of the
original system by greatly generalizing
each of the individual components that
you originally saw so that's the the big
picture of what I'm trying to accomplish
what I'm going to talk about today is
one particular piece of this which is to
extend a graphical memory architecture
which I'll tell you about to store like
problem solving that is how does when
generate evaluate select and apply
operators internally within a memory
structure in order to do problem solving
/ sequences of possible actions in the
goal here is to reuse as much as
possibly of the existing memory
mechanisms which are based on graphical
models I'll tell you about that as well
in order to be able to evaluate whether
as we add new functionality to this
architecture whether it can stay simple
or whether we keep having to add new
boxes onto that architectural diagram
each time we want a new capability okay
see here's a brief intro to problem
solving in store there it's based on
three memories and four processes you've
seen two of the memories before long
term memory working memory there's also
a preference memory that usually doesn't
show up in architectural diagrams it's
considered to be a in detail but it's
critical for problem solving then there
are four processes three of them are
driven by rule firing generation
evaluation and application two of those
occur in a retractable fashion like a
TMS so the idea is that the generation
and evaluation operators is always
sensitive to the currents
situation and those adapt automatically
as the situation changes application
occurs by last rule firing the results
of that stay around until they're
changed explicitly kind of an implicit
frame axiom and then the actual
decisions occur by taking the results
from preference memory which are
generated by evaluation and applying a
separately implemented decision
procedure in order to decide what goes
into working memory for the operator
this to be executed now it happens by
some processes I'm not going to have
time for and there's also a meta-level
aspect for reflection but that's not the
focus here okay so the new approach is
based on graphical models I'm going
through this rapidly to get through in
11 minutes what graphical models are
about is enabling efficient computation
over multivariate functions by
decomposing them into products of sub
functions there are a number of
different variations on graphical models
there are for example Bayesian networks
which decompose joint probability
distributions into products of prior and
conditional probabilities they then map
that on to a directed graph with
variable nodes factor graphs are a bit
more general they're about dealing with
decomposition of arbitrary multivariate
functions and they map onto bipartite
undirected graphs what's particularly
interesting about graphical models in
general from an architectural
perspective is that the yield broad
capability from a uniform base in fact
they get state of the art performance
across symbol processing probabilistic
reasoning and signal processing all from
a single representation and a single
kind of processing algorithm you can see
on the slide I want with them different
kinds of algorithms which are all
essentially the same algorithm within
graphical models they support mixed and
hybrid processing so mixed is a mixture
of symbolic and probabilistic reasoning
hybrid is discrete plus continuous and
in fact some of the network neural
network models map on to them so they
have a broad broad uniform capability
I'll try not to hit that again the
architecture the memory architecture
that I'm talking about is based on on
facta graphs the most general form of
graphical models known at this point
plus the summary product algorithm which
processes memories on
and I'm not going to go into detail on
how this work but messages are
distributions over the domains of
variables those get combined by
piecewise products then you some out
variables that you're not concerned with
and all in all a single settling of a
graph then can generate marginals on all
the variables in the graph or it can
also generate map probabilities if
you're familiar what those are so that's
very brief introduction to graphical
models in the memory architecture one of
the key issues is what is the
representation used for the functions in
the decomposition and therefore the
messages that are sent around in the
graph now what's used here is a hybrid
mixed representation that it's based is
a multi-dimensional continuous function
approximated in the piecewise linear
fashions you break that it up into
regions and then you get a linear
function on each that lets you then
approximate arbitrary continuous
functions as closely as you want given
the cost of representing it you can then
discretize the domains to get discrete
probability distributions and symbols
and you can boolean eyes the range and
assign a simple table which is for the
programmers use and that lets you do
similar processes it turns out as far as
the factor graph is concerned it's all
continuous functions it doesn't know the
distinctions this is useful for us in
putting knowledge into the system but
the architecture itself doesn't know the
distinction okay the graphical memory
architecture was developed by creating a
general knowledge representation layer
on top of factor graphs and the summary
product algorithm it differentiates
long-term and working memory essentially
long-term memory defines a graph working
memory then our peripheral factor nodes
within that working memory is defined in
terms of a set of predicates again I
won't go into the details with typed
arguments and what the working memory
does is provide the evidence for a
settling of this graph familiar with how
for example Bayesian networks work
long-term memory then consists of a set
of generalized rules called conditionals
they're based on predicate patterns
conditions actions and contacts which
I'll tell you what they are on the next
slide and functions are mixed hybrid
over pattern very
and each predicate induces its own
working memory node okay conditionals
again very rapid so conditions test
elements in working memory and actions
generate them you put those together and
you get something that looks like a
classical rule and at the bottom is the
the factor graph for fact if you know
the read algorithm that looks a lot like
that contacts do both so you get
bi-directional message passing as needed
for probabilistic reasoning partial
match other kinds of things like that
functions then modulate the variables so
here's an example of a conditional which
is based on two contacts and a function
it essentially defines the conditional
probability of an object's weight given
its concept and then the factor graph
below looks somewhat like the other
though there are differences I won't go
into all four kinds of things can be
freely mixed mixed in conditionals so
then the memory architecture uses
conditionals to implement many different
kinds of memory capabilities in fact all
the kinds that you see and so are plus
plus more kinds so we have a rule-based
procedural memory which has things like
what you saw in the previous slide
semantic and episodic declarative
memories this is a view of the semantic
memory in fact the conditioner we looked
at is one fragment of this and
essentially that plus a bunch of others
define a naive Bayes categorization
memory or for facts and categories
there's also you can do constraints and
I've got the beginnings of an imagery
memory this is a 3d hybrid
representation for the eight puzzle that
uses to continuous spatial dimensions
and a discrete tile dimension in fact
that's used in in the problem solving
here ok before we get on to problem
solving in the architecture there are
three additional aspects of the memory
architecture you need to know about to
understand how the problem-solving works
the first one is a distinction between
open world versus closed world
predicates so in general that's a
distinction between when something in
working memory is unspecified do you
assume it's unknown or do you assume
it's false it turns out to be a key
distinction between declarative and
procedural memories and I can answer
questions about that but I need to go on
open world
allows changes within a graph cycle so
graph cycle is passing messages until
quiescence and then changing working
memory ok open world lets you do
generate results and retract them all
within a single graph cycle closed world
requires it across cycles second one is
universal versus unique variables
universal are like those in rules they
matched everything and generate
everything unique are like standard
random variables where you get a
distribution of the best value pick one
value and I won't go into that and
there's one other thing which is that
there's a memory and every link that
stores the last message it turns out
that implements some of the stuff that's
in the rematch algorithm but it's also
important for problem solving ok problem
solving in the graphical architecture so
again there are three memories but now
the link memory not only subsumes read
like things but also the preference
memory there are the same four processes
but now the distinctions that occur from
on them are not driven by problem
solving but driven by the memory so we
have open world versus closed rotal
actions to get retractable versus
latched we have the link memory instead
of the preference memory and we have
functions for doing things like
preferences again we'll skip over all of
that a version of the puzzle has been
implemented where functions and in
things like negated conditions the
arrows moved on the PC are used to
express the preferences and you can in
fact the code a full version of the eat
puzzle in this using 1919 conditionals a
number of 747 Boeing like number of
nodes takes about six thousand messages
over 9 decisions to solve a puzzle
problems conclusion since I'm running
out of time so sore like base level
problem solving grounds directly in
mechanisms in the graphical memory
architecture so the factor graphs and
the conditionals provide the knowledge
used in problem solving the summary
product algorithm provides the
processing of that knowledge the mixed
functions provide both symbolic and
numeric preferences link memories
provide preference memory the open world
versus closed world distinction
distinguishes operator generation versus
application and universal vs
variables distinguish operator
generation versus selection so it turned
out it was possible to implement problem
solving in this memory architecture
where the only bit of actual new
architectural mechanism was an
architectural a defined predicate for
the operator that's actually not used
for this it's used for the reflection
process so the memory processes were
general enough to handle all of this
this works is also progressing in a
number of directions some of them the
concern problem solving do have an
implementation of sore like reflective
problem-solving as well that does
require some new additions to the
architecture and also a very unselect
version of Palm DP based operator
evaluation which doesn't require any
extension to the architecture whatsoever
thank you ok this session in some sense
is all about convergence as we will see
I'm going to argue that general
intelligence need something like general
motivation and the motivational system
is what structures our cognition in some
important sense we are going to look a
little bit at motivational dynamics at
physiological social and cognitive
drives and we are looking at intention
selection and the control of actions and
maybe a little bit on how this can be
evaluated IGI has the problem that it
specifies a goal but not a method to
reach that goal and the existing
methodologies and AI have evolved to be
pretty much incompatible with the goal
that's five years sitting here and have
our own conference and are not all going
just to San Francisco next week and AGI
must break free from this methodology
ISM of AI of which pretty much has
overcome the original field and yet we
need methods and we need to integrate
over the boundaries into the other
disciplines and domains I think the
paradigm which should direct these
methods is something like cognitive AI
as opposed to logic based systems to
search to mention learning but also to
the strong and active business approach
in some kinds of robotics what we need
for cognitive AI what I mean by this is
we need something like universal mental
representations it should
compositional and distributed and in
this sense numero symbolic and we just
saw an example which is very similar to
what our own architecture does and in
horizontals talk we also need some kind
of general problem-solving or see my
general problem-solving because it seems
that humans are not able to solve all
kinds of problems but a lot of problem
classes very well and in order to do
that we need to have operations over
these representations we also need to be
able to do perceptual grounding on these
representations that is we need to be
able to connect them to a sensory input
and we also need them to inform our
actions and we need to be able to learn
on feedback between actions and
perceptions or we can model the world
and get some kind of situation image a
world model we need to be able to
transmit this or transform this world
model into a long term memory to a
protocol of past world models if be
abstractors we also get among other
things a model of the agent itself we'd
get abstractions of objects episodes and
types we also want to have something
like a procedural memory so we learn
what worked in the past and what didn't
and what happened and what didn't and we
also want to anticipate the future so we
can have plans and we have maintained
expectation horizon of events that might
or might not crop up in the future and
if we generalize this we have a
long-term memory a role model and
something like a mental stage on top of
that we need some way to select actions
of course and in order to select actions
we want to have something like a
motivational system because we cannot
expect our system to know all the goals
beforehand that it needs to have in the
world because the world is very complex
but we need to have a mechanism that
identifies goals in the first place and
this motivational system is what selects
intentions based on demands of the agent
well additionally you also want to have
emotional modulation and effect and I
think Ben is going to talk a little bit
out about this in the next talk we want
to integrate this into whole testable
architectures and
as we have seen in this session we have
a number of components identified we
want to have rain Berg's to test them we
want to put all those pieces together we
have an architecture which is pretty
similar to Lyda in in framework terms we
have similar representations as we have
seen and for rosenblum stalk and if you
want to learn more about this you might
want to have a look at the book on size
theory which is called principles of
synthetic intelligence okay today we are
just looking at motivation a little bit
and I apologize beforehand because in 10
minutes there's only very little I can
do so it's going to be very cursory and
there are a lot of entities that need to
be carefully argument for an icon cannot
do this so I apologize and please
approach me afterwards if you have
questions and complaints okay so all
goals of our system are there to satisfy
a hardwired demand if we do this so we
have completely flexible goals which
only depend on the kind of environment
which we are in but which always lead
the agent our to suitable behavior
suitable for instance in evolutionary
sense if you have a biological agent or
if you are an AI suitable with respect
to the kind of environment that you are
in so we need to define a set of drives
which correspond to a set of demands of
the agent and these drives and our model
are either a physiological social or
cognitive what does that mean a
physiological drive basically kicks in
if the autonomous regulation of body
processes fails for instance you really
need more food you need more water you
need to heal you need to get shelter or
you need to rest you need warmth or you
need to cool down or whatever whenever
this doesn't happen autonomously you
need to a trigger kind of behavior based
on these demands so you can escape
earlier situations this leads you
implicitly to seek physical survival
physical survival itself is not a demand
of the agent because it's very hard to
define what physical device or by other
means and how you rate this against
other things but basically this is an
emergent property of these basic
philosophy illogical drives then social
drives social drive structure our social
interaction for your own rationale
utility
affiliation is a internal variable
basically which is increased by
so-called legitimacy signals these are
occasional signals that you can get from
other people or from social groups or
from the environment in general usually
from other agents and it's decreased by
entire decade embassy signals and it's
also decreased attentively over time so
over time you need to replenish this by
seeking out social interaction this
allows groups to have non material
reward and punishment you want in a
social species as we are people to
cooperate without an immediate benefit
like a sociopath or Billick calculated
utility because otherwise you would
always have to mete out punishment which
decrease the fitness of individuals or
you have to give them rewards for their
cooperation which might not be very good
for the resources of your group so what
you have is a virtual currency which
delivers reward and punishment to incite
individuals to behave altruistically
with respect to the group and this
affiliation can be structured into
something like in external dichotomous e
which is a lots of group acceptance and
an internal one which is reflects the
conformance to internalize social norms
so you are behaving love nobody's
looking ok now the most interesting ones
these are the cognitive drives these are
what makes it curious which is explore
which makes us represent the environment
and interesting fashions the first one
is competence the drive for competence
means basically that you are able to
affect things and the way you want and
the first one here is epistemic
competence it's related to different
tasks that you have learned for instance
doing the dishes driving home or
whatever and to be able to do these
things to be able to program a new
computer language for instance creates a
pleasure signal and thereby satisfies
this drive for competence then there is
something like a general competence
which means that you are generally able
to behave well which amounts to
something like a self-confidence and
this measure is important heuristics
that the Ute a try something you whether
your are
fit to go into your environments and
take on new challenges or whether you're
in the world that is so challenging that
you should stick to routines then there
is effect oriented competence is
basically what makes the baby pull down
the laptop because it makes such a nice
noise and it's very satisfying so it's
directly proportional to the things that
you can blow up that you can make happen
in the world then there's uncertainty
reduction uncertainty reduction is the
different drive from competence it
amounts to finding out how things work
out what details are in things what's
going to happen next what's going to
happen if I do this or do that and it
amounts to some kind of novelty seeking
then we have aesthetics aesthetics is
the desire to seek out certain kinds of
stimuli if it's similar sori entered
that is for evolutionary reasons humans
preferred certain body shapes which have
no logical foundation whatsoever but
just evolution your reasons or certain
kinds of landscapes or certain kinds of
melodies and so on and this these
preferences are basically somehow
hardwired into our brains and then are
then adapted the death and build on and
we also have abstract aesthetics there
these are representation oriented they
make us prefer more elegant more concise
representations over more convoluted
ones so we derive a pleasure from
consolidating mental representations
okay so all possible goals of our system
correspond to at least one demand to a
physiological one social one or
cognitive one a demand is indicated by
an urge signal which basically just
measures deviation of the demand from a
target value and this gets associated
with gold situations i entered also gets
associated with subversive situations
that are detrimental to the demand for
in this case something to drink if you
need more water you might want to avoid
going out into the desert alone
California if you are bound to get
thirsty and don't have anything to drink
with you ok so you associate this by
learning initially you don't know this
all these things you only have these
hardwired demand in the agent and by
learning you can find out
what things are good to satisfy the
demands and what things are detrimental
to that and basically you do this by
measuring the change of the demand over
time if it's a change in a good director
it triggers a positive valence signal if
it's a change in that direction it
triggers a negative valence signal we
call these pleasure and displeasure and
directors reinforcement signals on
creating links between gold situations
the situations that lead to the
satisfaction of a demand and aversive
situations we do not only create a
connection to the goal itself but you
also strengthen the connection to the
goal in the situations which led up to
the goal situation so we are able to
memorize plans which lead to that
situation and we also uses these plan
fragments later to construct new plans
from scratch or not entirely from
scratch but basically out of situations
that let us to find something to drink
in the past for instance okay this is
what we call a motivator or a motive is
basically a connection of urge indicator
with a goal and a plant which leads to
that goal and intention is a particular
action leading action controlling motive
which we might select out of many
possible ones a motive is raised to an
intention based on this relative
strengths of a determined the
opportunity to satisfied the expected
probability of success of the plan so we
have heuristics which tell us how likely
the plan is to succeed and a selection
threshold the selection special it is
important to avoid oscillating behaviors
so if something is very important to us
we might increase the selection special
some kind of adaptive stubbornness so we
don't get swayed so easily from our goal
and we might for instance delay our meal
if you just want to finish programming
this part of the routine and so on okay
and this gives rise to a certain set of
dynamics we have internal modulator
parameters the arousal of the agent for
instance which corresponds to the
activity of the drives if something very
urgent is wrong in the agent for
instance it really needs to drink now
then there also goes up
or if it has an accidents or the desire
for our demand for physical integrity is
frustrated that also goes up in this
because this requires immediate action
if they're also goes up the resolution
level goes down which means we get
faster responses we think less we don't
look at details but our cognition is
basically sped up at the price of
resolution it also creative increases
the goal directed Ness and so on and it
also increases the selection threshold
I'm not going into all the details of
this because we are not going to do this
in this short time but this model allows
us to ground personality properties from
psychology in a functional model which i
think is a very good thing so look let's
just look at the famous Big Five of
psychology openness which basically
amounts the appreciation of Arts and
your ideas conscientiousness
extraversion agreeableness and
neuroticism which is something like your
emotional stability it's pretty
straightforward how to explain with this
functional model by showing how the
individual relationships are
parametrized how you can express this in
our computational model so we can do
high-level cognitive modeling of an
abstract theory which is grounded in
psychology and this might open up an
avenue for actually testing this kind of
theory what we are currently doing as we
are working together with psychologists
and have designed a set of
problem-solving situations and we are in
the process of getting them to the point
where we can of people have to choosing
strategies which correlate with their
personality properties that we accept
measure external leavis traditional
methods from psychology once we can show
that people with certain personality
traits prefer certain strategies in a
problem solving game over others we can
have our cognitive agent be part of this
game we can't let the agent play this
game and then we can change the
parameters in the agent and show whether
our model chooses the predicted
strategies so this is what we are
currently working at thank you very much
for your attention
so our next two talks are an open cog
and I think they're both bourbon okay so
there are two talks in a series on the
open cog that will be presented now I'm
going to talk about work that we called
open beside which actually falls onto
Joseph talk that you just heard about
some work we've done embodying some of
the same ideas from his AI framework
inside the open cog framework to help
open cog do motivation emotion and
action selection then uh Matthew oklet's
talk following on will be about
attention allocation in open Coggan some
new algorithms for that and this this
work was largely done but I got named
the genoise shy or shahji muahz as you
would say in the indo-chinese order who
work mate in JAMA and university is now
working on the open cog project in the
in Hong Kong so just to give a very
rough impressionistic snapshot of the
open cog system it's an integrative
system aimed broadly at human level AGI
currently were not at the human level
yet obviously we we have knowledge
stores corresponding to different types
of memory declarative procedural
episodic attentional sensorimotor we
have proxies that connect open cog to
virtual world agents and I'll show a
video that the end of the talk and also
to control now humanoid robot and in
order to get the robot sensorimotor
stuff to work well we're actually
integrating open cog with the itamar
Errol's a destined sensory processing
subsystem which would be the topic of a
different talk and open sigh it's kind
of hard to see but
this this box here is based on Josh's
ideas and sort of intervenes between all
these memory and learning processes and
the concrete stuff that that the system
does so fortunately since Joe Schad just
explained all this I don't have to go
over it again but you see a a blow out
of this box and in our architecture
sketch fits with the stuff that Joe
should just talked about the basic
architecture of our dietrich donors sigh
architecture and the the big difference
in what we're doing is that the
long-term memory box inside up at the
top there that in open cog consisted
this whole conglomeration of open cog
memory subsystems and learning systems
which is pretty different than then how
donor did it originally or than how Joe
she does it and for action selection
planning motive selection and the
various aspects of sci we use open cogs
knowledge representation and dynamics
but the basic structure and flow of
information is the same as what Joseph
and many of the the strengths of
Joseph's work and donors ideas carry
over for example just as they they use
various complex networks of elements to
ground comp concrete reference percepts
and actions and so forth we do a similar
kind of grounding tied in with the sci
architecture but our nodes and links are
a bit different than the ones in my
crops are or in Dorner's work so
microbes I as Jonah has been developed
which is a very interesting architecture
it gives a specific software
architecture building on top of the
conceptual saw model and it uses a
knowledge representation which in some
sense is a little lower level than what
we use in open cog and if you look at
josh's book principles of synthetic
intelligence which i'd recommend
everyone may describe some basic net
entities and units and how you wire them
together to give a sort of
nurul symbolic knowledge representation
which has a lot to recommend it in open
cog we have our own different sort of
knowledge representation which could
also be broadly conceived as neural
symbolic it's a fairly fuzzy term it's
something we call the atom space we have
a number of different types of nodes and
links they many of them are weighted
with probabilistic truth values often
using in precise probabilities instead
of spreading neural net type activations
around they spread around short-term and
long-term importance objects which
matically will talk about in his
following talk and then we think about
both explicit and implicit knowledge
representation as Joe she does in his
system as well will they explicit
representation being things that are
sort of transparently represented by by
nodes and links more in the manner of
probabilistic logic implicit knowledge
representation being representation of
all knowledge as attractors or other
patterns of activation in the whole
network and I think you need
representation on both those levels the
global and the local so we had a paper
kong this glocal knowledge
representation although I I've concluded
that that term will not catch on as well
as the term AGI has on an implementation
level all these different types of
memory and the learning processes that
act on them they're implemented in sort
of a manner similar to an operating
system metaphor so we have the atom
space is a knowledge repository and
there there are different repositories
tied into that to do specific kinds of
knowledge like sensory motor or
procedural knowledge then there's a
number of learning processes called mind
agents which embody different cognitive
processes it could be reasoning could be
procedure learning could be sensory
motor pattern recognition or frequent
sub graph mining and these are all
scheduled by scheduler acting on this
repository of of nodes and links which
sort of plugs into the long-term memory
in the sci architecture
I Graham except in my model that's where
most of the learning and thinking goes
on is in the kind of active dynamics of
that long-term memory we didn't have a
notion called cognitive synergy where in
the learning processes corresponding to
these different types of memories a
probabilistic reasoning for declarative
knowledge probabilistic evolutionary
program learning which is based on moshe
looks PhD thesis work for procedural
knowledge economic attention networks
which meta clay will be talking about in
the next talk for dealing with
attentional knowledge and the importance
values and there's been a lot of work
going into how these different
algorithms all cooperate together so if
one of them gets stuck the others can
can come in and help out using a
different kind of knowledge all
represented in a way that links into the
common Adam space representation so this
is easier to see if you read the paper
in the proceedings but we've we've made
a careful mapping between the various
aspects of the sci architecture from a
donor and Joe Shabaks work the memory
demands urges urgency pleasure goals
mode of an action selection and the
various modulators that Joe should
discussed and we've gone through and
mapped each of those into things you can
represent in terms of open cogs atoms
and open cogs can control architecture
the result is a system that has some
similarities and some differences from
microbes I'm in the basic the basic
logic of action selection and motive
selection and the role of the modulators
is arguably the same and it's modeled on
human psychology in the same as well as
what Joseph is done on the other hand
the knowledge representation is quite
different and the learning algorithms
used or are quite different so it's been
the not at all a matter of just plugging
sigh as a separate module together with
open cog as a separate module it's
really been implementing the site
conceptual framework partially within
open cog and then keeping the knowledge
representation and learning algorithms
more open
ish and this is just like a one and a
half minute video showing the psy model
implemented within open cog to control
the little robot in the unique 3d engine
and pretty much it's probably hard to
see the indicators in the corner there
but there's two demands here integrity
and energy and at the the robot has more
demands but this demo shows integrity
versus energy it feels more integrity
when it's in its house it feels more
energy when it gets a battery because
that gives an electrical power so pretty
much this shows a very simple
oscillatory dynamic where it sits at
home because it likes the integrity
there until it starts to run out of
power that says oh I better go get
another battery then once against the
battery its energy goes up and then its
energy demand no longer needs fulfilling
so it goes back home or it feels more
integrity I mean that's it's kind of a
trivial dynamic but that's what we can
show in one minute video that there's a
lot more complex interesting dynamics
you can you can get out of open sign
this this shows some bits of the open
side control panel which was closely
modeled on some parts of the microbes I
can control this blood just showing the
the fluctuations of some of the
modulators feelings and it's gone and
then and demands during the course of
that that simple simulation so let me
try to stop it in no I can't stop it
it's a so it's it's a complex nonlinear
dynamical system with the interactions
of all the modulators urges demands
feelings and so forth and it's linked in
with the complex dynamical systems of
open cogs Adam space with all these
different learning mechanisms working or
doing reasoning and trying to figure out
what to do what makes it tractable to
work with is the fact that we're using
it to control some pretty simple
concrete processes controlling a little
robot in this minecraft like virtual
world so you can see what's doing you
can see do the emotions that it's having
and then the way it's fulfilling its
demands using planning doesn't
makes sense in terms of what you'd want
this little guy to do in the world and
then so our plan over the next year and
a half is to get it as smart as we can
in the virtual world and in parallel
we're working on integrating it Amar's
Destin vision and audition system with
open cog working with the NAO robot and
then two piece those two things together
to try to get the little robot to do
with this little guy in the virtual
world can do which is all kind of step
one of a grander plan to build like a
toddler level intelligence going from
this little virtual robot and the NAO
robot and then hopefully assuming all
goes well have that go ascend the ladder
of pia jetan stages of cognitive
development and gets smarter and smarter
and then I'll turn it over to dr. clay
to talk about attention allocation if we
can get the other laptop to work this is
basically I'm going to be talking about
economic attention networks within the
as basically the attention allocation
system within the open cog system so bin
actually kind of started everything off
making everything easy because he went
through most of this but so I'm going to
start off well the first part was brief
review of open cog you just heard of
quite a little more in-depth version of
that but one of the things I really want
to start with our what are the goals of
attention allocation that's one of the
critical ideas that we were trying to
address with the series of experiments
that all briefly run through at the end
the one of the I'll talk a little bit
about what our attention or economic
attention networks and then
Tata all of the problems that we need to
work on that which I call the goal
traversal problem I'm going to follow
that up with one possible solution that
we've come across and that's using ideas
from an area and statistics called
information geometry and then how that
ties in to what we call mine geometry
and then I'll talk in brief detail about
some of the actual experiments that
we've done to implement in from these
information geometry metric ideas within
the cans or economic attention network
system so as been already covered here
open cog is an integrative a GI system
it's got quite a few different memory
types and different modules covering
things like uncertain logic the pln
system computational linguistics moses
says Moshe's moses program for
evolutionary program learning all within
a basic connectionist system for
attention algorithm the in essence a lot
of what's going on here is how do these
processes integrate to encourage higher
level emergence or merchants of higher
level structures so this lie basically
covers a lot of what Ben just talked
about it's a different types of memories
what are the specific cognitive
processes associated with those memory
types and the general cognitive function
has been also just mentioned the a lot
of so if we look at the attentional
system here that's going to be covered
by ECAM which stands for economic
attention networks and that's going to
cover things like Association obviously
attention allocation
but again this ties in with Josh's work
as well and that that's pretty much
guided by the goal systems going to be
guided by the size system so what are
some of the goals of attention
allocation obviously it's basically your
central process basically controlling
your going going towards your goals
you're going to be what are some of the
interests here that we're looking at it
has lots of knowledge so how do you
weight this knowledge the pieces of
knowledge to each other you're going to
be interested in both the current
importance and prior importance the
longer long-term important short-term
importance it's to guide your reasoning
system content creation and to identify
these high-level emergent structures key
key idea is obviously allocating
resources among the different goals and
guiding the system toward those goals
one of the things that really crucial
for any attention allocation system is
the ability to scale and its scale in an
accurate way and that's one of the
things that I wanted that our series of
experience experiments was really
related to related to so a little bit
about the ECAM system as the name
implies we're using an economic metaphor
for guiding attention allocation so
there's system of wages and rents it's a
monetary system so within the system
we've got two basic what we call
currencies that relate to the short-term
importance and long-term importance for
the purpose
is of the experiments what that we're an
arm we can think of this as a
conservative nonlinear dynamical system
that matches the space of input patterns
to the connection weights of are the
weights of some connection matrix that
connects the different nodes together it
contains a an essential notion of what's
called the attentional focus as again as
the name implies it's where is the
attention focused what nodes are most
relevant at any given time in the system
so that brings us to the goal traversal
problem which is so if you're in some
specific state right now and you're
seeking to some goal the question
becomes how do we get there so one of
the answers we came up with is the idea
of information geometry to try to
address this in an efficient manner we
can obviously try to scroll through all
possible states that that doesn't work
so what is information geometry so basic
idea is that it's application of
differential geometry except instead of
two physical spaces it's going to be two
spaces of probability distributions so
what it what it does is it treats a
probability distribution as a point on a
mathematical manifold or a surface some
curved surface and how this is curved
depends on the metric that you choose in
information geometry there's a key
concept called Fischer information which
basically is
a measure of the information about the
parameters which are our connections are
weights between nodes carried by some
observable variable and it forms the
basis for the metric that we'll use so
been already talked a little bit about
this although this is a will be covered
more in a poster session this evening
three hypotheses of mine geometry the
key ones for the purposes of this talk
right now are the second to which are
that intelligent minds tend to follow
geodesics or the path of shortest path
or paths of least recess resistance and
so if we think about the gold traversal
problem we've got some sort of current
state some sort of current probability
distribution and we're trying to get to
some sort of gold state and how are we
going to get there however what's the
path that we want to take to go from the
current state to the gold state to guide
us in an efficient manner and that's
where information geometry this idea
comes into play and basically it's the
shortest path which in is called
geodesic in differential geometry and
the second concept uh is this cognitive
synergy principle that Ben also talked
about which basically says that this
shortest path may require passing
through multiple memory types so talk a
little bit about the actual algorithm
the concepts are really pretty
straightforward the only real thing new
here is that we're in a space of
probability distributions so am
re-introduced an idea called natural
gradient learning on this space of on
this manifold
basically all that is is it's a
generalization of the idea of steepest
descent numerical analysis water flows
downhill at the fastest rate arm and so
basically now all we're going to do is
follow this natural gradient from our
current path to try to seek our from our
current state towards our goal state um
this idea was extended to cover
stochastic neural networks which is
basically what an e kin can be viewed as
our economic attention network although
Park and Amar'e and and the others
originally only considered this for
feed-forward neural networks the idea
actually holds through in a much large
for a much larger class I'm going to
pretty much skip through this thesis
details that are covered in the paper um
but the key concept is basically how it
because of the way the system is
designed is that the probability
distributions d couple and decompose and
that's what allows everything to work in
the space on the neural networks so what
we ended up doing is then performing
experiments we had our original economic
attention network system and then we
would do another experiment I ran an
experiment like that and then another
experiment where I would enter we've so
we do it II can step followed by a
natural gradient step to adjust the
parameter space and then go back to the
economic attention Network followed by
an adjustment of the parameter state
using the natural gradient and basically
the series of experiments showed a
pretty dramatic difference be between
the original ECAM system
and the coupled system with including
the natural gradient in a lot of in
every experiment that we're an arm so
there are some issues however that I'll
talk about future plans are how to
implement this in an efficient way um we
want to try experimenting with this for
other components of open cog and the one
of the big issues is when this it when
when I perform this experiment it was
basically a toy problem small numbers of
nodes standalone system so what the
first thing we really need to do is to
study this within the entire open cog
system I just have not had the
opportunity to do that it appears that
it solves a gold traversal problem quite
well obviously much more experimentation
needs to be done um and so I think that
covers it so we've got a pen Oh session
now where you can ask question swing of
the speakers or all the speakers and
co-authors also welcome to come up right
how will cloud computing impact your
architectures in the future well our
architecture right now works in a multi
threading fashion and it is not
implemented but it could be the same way
that we divided the tasks in different
threads it could be possible to process
this in distributed systems and of
course it could be done in the cloud
I think that most of us haven't run into
troubles due to a lack of computational
resources so we have only scaled up to
the point where we want to have several
computers be connected and local network
we haven't gotten to the point where we
thought this is not enough this might
happen in the future but so far our
troubles are conceptual and I think in
the future it's all computing might
affect us but probably more if you want
to have joint development with many
people in the world and find a way to
have some kind of collaborative
development I guess one of the big
issues is still with cloud computing
would be the network speeds that's I
mean on local networks you're going to
get quite a bit of speed up but as soon
as you start going to the network things
are going to slow down quite
substantially I just so in general lot
depends on the granularity in which the
parallelism exists within the
architecture so many of them have very
small grain parallel things I had six
thousand messages going that can be done
in parallel cycles but you need
parallelism that can handle the the
small granularity of that if it's going
to be effective then you have usually
the big boxes which are fairly easy to
paralyze and then you have multiple
agents within these which are even
easier so it's not clear if it's cloud
computing or parallel computing what's
going to matter but there usually is a
potential for parallelism but it's it's
usually hard to extract much more than
fairly limited parallelism out of out of
these things when you get down to it
seriously so it's common to have
architectures where we can represent and
work with knowledge and we've heard some
of those today but I would say that it's
much less common to actually be able to
learn that knowledge we can work with
the knowledge of once we have it but can
we actually learn the comparable
knowledge and I really mean learning
sensorimotor data the kind of data you
would have all the time rather than from
prepared data set so I think this is a
big weakness in what's been done so far
that when we don't really have a
facility to learn massive amounts of
knowledge where's the whole idea is to
take advantage of having massive amounts
of knowledge well in the case of our
work and open cog I mean it is learning
based on the experience we don't feed in
prepared knowledge I guess the there's
the question which I don't know the
answer to of how important is really
high dimensional high bandwidth node so
we're doing this work controlling a
virtual robot in a virtual world and
that's experience it comes into the
system as perception and it generates
action signals but of course it's much
lower dimensionality than controlling an
actual robot but it's still learning
from experience it's very different than
source something where you feed in
databases of rule so what what we're
trying to do is first refine the whole
architecture and get everything working
doing learning from experience in this
simpler experiential domain and then use
the same system later to control a robot
which has a higher dimensionality of
experience and you if you have a certain
point of view you might say that'll
never work you just need to be dealing
with like hard to mention all data from
from the from the very beginning but I
don't think that's demonstrated
philosophically speaking I think it's
important that you have the right
constraints realized in your nervous
system it's not that important how they
get there this is a technical question
and I'm completely agnostic yet whether
it's possible for instance to abstract
the knowledge that you need about
cycling for instance not by interaction
with the bicycle but by taking all the
google videos on somebody riding
bicycles and doing a very thorough and
very clever statistical analysis on this
I don't know about that in our model we
do the bottom-up approach so our agents
don't know anything all our
representations are grounded we did find
that if you have a complex well that we
need either to teach the agent
because some things are incredibly
difficult to get to all we need to equip
it with some biases so for instance if
it is hungry the sequence of actions
that leads for this anger to be
satisfied in a reasonably complex world
is so complex that you're not going to
stumble on it by accident if you don't
have some kind of bias for putting
things in your mouth or some kind of
reflex chain but this is not knowledge
it's just reflexes and all the knowledge
that you have in the agent is learned
from scratch at the moment I don't think
that's invalid to go another route and
try to work from that down because it's
going to be a long time until we get to
proper language for instance from the
era because we need to do much more
abstractions than we actually can do is
that approach so it's a methodological
question where you start but I think you
need to bear this in mind it's a very
good point so that I guess the shoreline
architecture which has show does have
four learning mechanisms including
reinforcement and episodic learning and
so on in my own work just starting to
get in the perception and learning stuff
so one of our most recent results is we
could we showed some relatively high
level perception using conditional
random fields that are essentially
implemented in the same factor graphs
and we're starting to look at learning
very interested in how you do pervasive
learning in combination with pervasive
prediction in architectures like these
but haven't gotten to that yet yes in
the same way that several of these
architectures lida a custom frame
premised that all learning should be
online so no separate stage for learning
and one for execution and of course as
Joshua said there are a background of
hardwired knowledge but most of the new
knowledge should be by experience and
online yes hi I have a question to the
last presentation about attention
mankind my question is like this how you
drive it how
you connected to the goal of your system
would you be able to do this are you
sure yeah so um let me get the questions
ray I mean where does the goal yeah come
from how you're driving the attention
mecca for example something comes into
view how what is the Meccans of the
driving the attention I think been a
system actually covered that it's
basically the incorporation of Joe shows
what are the motifs of that I'm not
quite sure what the question is but I
mean there's the attention of the system
is driven by the the self-organizing
propagation of body for knotts values
but the system has some top-level goals
and those goals each of them propagates
short-term importance values in open cog
and those the goals then spread
importance to the things that the system
believes based on the knowledge that
it's acquired will help it to to achieve
its goals but then the importance values
also just spread around nonlinearly so
it's not it's not extremely rigidly gold
direction but it's heavily gold guarded
because the goals spread out importance
values so what is driving the goalies
driving the attention or some kind of
miracle uh between those two I have to
choose the former so my question is
mostly about the sign motivational
system I can see a really strong case
for it as a scientific model of how
people are motivated what are your
thoughts on the sign motivational system
as an engineering tool for for sort of
giving a top-down goal to a system and
then having an achieve some complex task
in the world it depends what your world
is I think if you have an eight I which
lives in a completely virtual world you
probably don't need the equivalent of
physiological drives except if there are
constraints like bandwidth and so on
which you want to map on this if you
don't have these I do think that you
need some equivalent of the cognitive
drives if you have something that needs
to solve problems on its own so in my
imagination general intelligence amounts
to the capability to solve problems plus
having the motivation of doing so so I'm
curious about what level at what level
you're talking about when you talk about
your architectures so for example you're
building a computer you talk about
chipsets or you go even further down and
talk about logic gates and how
information is try and sort it at those
levels but when you're talking about
making a computer do something you talk
at a different level all together of
maybe programming languages or maybe
even higher nowadays so so there is a
level that you talk about the
architectures that but does that easily
map onto the level will we talk about
problem solving is there a direct
mapping there or is is it I mean I don't
know if you have thought about that in
detail so I start I'd say 40 years ago I
would have answered I'm looking at this
at a cybernetic level and today probably
would say you're looking at this at an
information processing level which is
not to say very much so we do have
implementation levels and above that we
have certain abstractions or on
information processing and goals our
information processing entities within a
certain computational framework so we're
not looking at individual neurons but we
are looking at for instance spreading
activation networks which embody some
kind of beijing formalism among other
things maybe this helps a little bit so
one of the classic ways are talking
about levels in cognition is Alan duels
diagram of scale counseling cognition
where you look at the different
phenomena that occur different orders of
magnitude of time he divided it up into
several bands the biological band the
cognitive social or a rational and
social I think most of the architectures
deal with
often the upper aspects of the
biological band and some aspects of the
cognitive and problem-solving usually
starts in the cognitive band and so some
of these some of the lower level
architectures might not directly hit
there but most of them I think actually
would if you're talking in terms of of
encoding problem solving in terms of
rationality that's often above what what
most of these guys are talking about so
my question is are there seems to be a
lot of similarity between the cognitive
architectures and this kind of when
there's differences but this sort of
convergence is sort of seen as a good
thing it is isn't there a danger that
everyone's doing the same thing and that
everyone will just fail together as
opposed to you know doing wildly
different architectures I my view oh
there's two comments first of all I
think presenting things in 10 minutes
with box and line diagrams may tend to
give a greater impression of commonality
than you get if you actually looked at
what's going on inside the systems but
they the other comment is I think the
AGI field is it's pretty damn diverse
with people going in so many different
directions I mean if you just if you
look at the three key notes we had the
first was engineering the second is
psychology the third is biology right
amen and I think there's a lot of
diversity and I'd say most if you pick a
random pair of AGI theorists the two of
them probably doesn't understand what
the heck each other are doing because
it's actually very hard to understand
someone else's architecture so I think
any movement toward convergence and
mutual understanding given the current
state of things is probably moving the
right direction I think we're a long way
from having too much convergence and the
small sort of ideas no I think that
convergence would be a good thing and
maybe it could be to task and paradigm
driver not necessarily architecture
driven so for instance a robotic soccer
has led to convergence of architectures
not because people just copied their
code but because
they had a problem set which they found
could be approached in a pretty good
manner by this in this kind of
architecture so they all coalesced it in
some kind of like four or five major
architectural paradigms and stuck with
that and I imagine if we find good
paradigms for during a GI experiments
for instance child developmental
paradigms and so on we might see a
similar thing if we had competitions and
so on where people were really need to
do results without hand waving without
just drawing boxes and lines and I do
think that he had similar influences the
many respects so that's why we do see
some convergence here but the individual
solutions that we find our pretty
different still yes I'd reiterate
basically what Ben and Joshua just said
I mean I was yes I on the first day with
the tutorial with the Lida I was in some
ways struck by a lot of similarities
except then you look at where the arrows
in point and and it's like and then you
start opening those boxes up and there's
almost no similarity whatsoever on the
big picture the the boxes may start
looking the same but soon as you start
opening up the muppets like a Pandora's
box I just had a variant on that it
seemed to me from from what I've seen
it's again hard to tell in these short
talks but there seems to be commonality
in terms of the kind of capabilities
people are hypothesizing are needed in
these systems in there for in terms of a
top level description in terms of a set
of boxes there also seems to be a just a
syntactic similarity in terms of you're
seeing graph structured memories in all
of these systems but what is meant by
those graphs are completely different
across them and then between those two
are not seeing a lot but that may be
where this Pandora's box is yes what I
like about a different vision i think
the architectures are similar not only
on
label of the boxes of course probably we
choose different implementations for the
boxes but those are just algorithms and
maybe slight different the differences
in the representations but what I want
to say is that if starting from
different points or almost not contact
and several architectures converge to
similar models well I think this is a
good signal that well we are going in in
a direction that converts from different
different points on Moscow for many
years I've been recommending that what's
needed to address that issue is a study
of the space of possible sets of
requirements the space of possible
architectures and the mappings between
them and systematic investigations of
that sort would I think be much better
than to try to focus on one subset or
one set of problems if return this whole
thing into something more like a science
so I have a segue from that to my
current question which is an engineering
question so what I'd like to do is apply
a cognitive architecture say either to a
robot or as family robots can you talk
to an implementation question that I
have which is the difference between a
real-time non real-time part of the
architecture so when you talk to you
scheduling or planning in my mind that's
more of a non-real time you get seconds
on order of seconds to do that there's a
real time component actually that needs
to be implemented all the time which i
think you refer to is this urged based
time step this time stepping this
emotion
give you say the real time component
that you're currently
go back to your attention okay so much
like what you were saying I guess I mean
in our work with the robot I mean that
there's code that runs on the NAO robot
itself which is fairly simple and then
the now talks by Wi-Fi with it with a
process code in choreograph which is not
the scripting languages that comes with
no but then that program since XML
messages to and from our open cog proxy
so open cog right now communicates with
the now proxy kind of kind of the same
way it communicates with the unity proxy
we use for the virtual world and it
gives more high-level commands so like
the open cog may give the robotic
command like take a small step forward
and then the robot controller knows how
to do that and the low-level robot
controller may it looks at the world and
then there's low-level vision code that
does edge detection stuff and it sends a
kind of sketch to open cogs and then
puts it in its space in its space
representation so what what we're
actually doing is using the same system
for the virtual world in the robot world
and we print a kind of proxy in between
the deals with all that nasty low-level
robot stuff and I don't think this is
the ultimate be all solution so what
we're trying to do with NMR is destined
architecture is build something to go on
that lower level between open cog in the
robot that's smarter and can accept
feedback from open cog but just from an
engineering point of view we wanted to
start by building something simple that
actually functions so we just abstract
it out on the low-level real-time stuff
and then even so it's a lot of work to
make things like learning reasoning
planning work quasi real time so it can
make sub-second judgments and decisions
with an open cog them we can do that but
not microseconds or something I would
like to address what Erin just said
there's a idea of mapping the space of
possible demands and possible tasks and
creating a relationship between those
two I think this would be a task for
philosophy of mind and I think that we
can say with some justification that
philosophy of my
has completely failed at that so it
leaves its left to us and the problem is
that the engineers in the field and the
scientists in the field do tend to
invent hammers and then they are only
looking for nails and this happens
consistently over and over I mean most
dramatic failure of that was behaviorism
and psychology they invented a nail that
was a hammer which was extremely
productive and they denied the existence
of everything that the particular nail
they they could hammer vez and in this
same same happens over and over so we
have people which honestly believe that
the solution or to AI is case based
reasoning or description logics or
whatever and they refuse to look at
other problems and I think that of
course we are all prone to that fallacy
that's why I'm asking for benchmark
problems and the good single robocup and
don't think that Robocop is a very good
paradigm for AGI because it leads to
soccer playing toasters very much as the
chest prom needs to assess chess-playing
toasters we need problems which we
cannot solve by hand waving the good
thing is that you can focus on robocup
on reinforcement learning only and just
borrow an architecture from sub from
last year's winner but you always have
to keep in the back of your head that
this architecture is important because
your agent is not going to play without
this architecture without all these
components that's why I think that we
need to find good benchmark problems
which refocus us and constantly to the
real problem there is to have an
integrated system that has all these
things and the good convergence among
this group is that I think that there's
some joint awareness on the breads of
components that we need to realize it's
not a single method there's not a single
silver bullet it's not a single paradigm
but rather it's a bunch of things that
the system needs to do and integrate
nicely and the difficulty that one runs
into as I said in my remarks on the AGI
roadmap workshop is even though we all
many of us have a broadly similar view
of the break down into high-level
functionalities that a human-like
cognitive system has to have each of us
has put more emphasis on certain boxes
and others each of us has a system
that's more developed in certain aspects
and others so when you get a bunch of
people
AGI researchers and try and decide what
scenarios benchmarks and tasks are the
best ones to focus on each of us
naturally gravitates towards those
things that we've thought about most and
our architectures are best at which is
it's not to say that it's infeasible do
it what Jojo has been suggesting but
it's a challenge it's an interesting
challenge that I hope we can meet maybe
you shouldnt generalise too early band I
guess this is because you and me we both
got big egos but not everybody is like
this and that's it I know it's actually
there are some people where it's
possible to convince them so Robocop did
take place even though there are some
people which don't play soccer and
people do converge on sometimes on
paradigms if they perceive them as
interesting and productive it's not all
just you and me I think in the original
proposal this was one of the things
which I wanted to have the original
biker proposal had one third of the
airport dedicated to finding benchmark
problems okay
I think this relates to Aaron's point
actually but I I have a bit of a problem
with benchmark problems which is that
there seems to be the potential for
going against the very idea of general
intelligence it seems to me that the
point of general intelligence is that
you don't know what the problem is in
advance and as the moment you start set
up a collection of benchmark problems
you're already putting a box around
things and making it not general
intelligence that you're that you're
tackling it will a the IDS not to have
only one benchmarks but a collection of
benchmarks that try to a cover a broad
broad a spectrum of a possible problems
if you look at the original father of
all the benchmarks the curing paper he
tried to define discourse recent
discourse the ability to understand what
somebody else is saying to uh to make
itself understood and so on as a
benchmark he might spot some limitations
and if you take it too literally we get
to something like the lib no price where
system is rewarded for faking this most
convincingly maybe and this indeed is a
big problem and I think that the search
for benchmarks is a very very difficult
problem but I don't see a shortcut or a
way around it because everything else
without really solving problems leads us
to the point where we cannot put our
ideas to the test and as computer
scientists we know if we don't put an
idea to the test it's our solutions are
not going to work because they are going
to be full of box so we do need some
things like this and we need to need to
find something which is where we cannot
have a shortcut so I do believe that
child performance of fighting your own
weight Howard's intelligence goes an
interesting direction but so I agree a
little bit more with the attitude of the
questioner but I think that having
having common environments and
Dario's within which to qualitatively
compare different a GI systems would be
would be really valuable it'd be really
interesting to have all the
architectures proposed and built by all
the people in this room like acting in
the same world controlling the same
bodies and doing the same sorts of
things I mean even if you don't boil it
down to who can get a better score on
this particular measure because that
that has some strengths as Joseph saying
it also leads to problems like we've
seen the machine learning community
wherever it just bangs on like can I get
point two percent better accuracy on
this thing so it may be that the
measurement and competition isn't the
key thing but having a common
environment to qualitatively see the
strengths and weaknesses or whatever in
system is doing I think that would be a
very valuable thing because it's
frustrating now you see my system doing
something on one problem someone else's
says from doing something on another
problem how those problems are set up in
detail is technical and we require a lot
of study to even understand so it's it's
hard to understand what someone else's
system is doing because we're all
evaluating and testing them so
differently so that it's clear to me
that shared environments and tasks are
valuable and I to my mind there's pluses
and minuses to qualitative benchmarks
and competitions so uh I think that so
we were well over time so we we can can
you continue this discussion over lunch
now we get me back here at two-thirty
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>