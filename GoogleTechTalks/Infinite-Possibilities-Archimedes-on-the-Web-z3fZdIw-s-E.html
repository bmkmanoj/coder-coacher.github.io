<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Infinite Possibilities: Archimedes on the Web | Coder Coacher - Coaching Coders</title><meta content="Infinite Possibilities: Archimedes on the Web - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Infinite Possibilities: Archimedes on the Web</b></h2><h5 class="post__date">2008-09-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z3fZdIw-s-E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome thanks everybody for coming
it's my pleasure to introduce Mike Toth
and dog Emery who working on a vehicle
project my cough is the program manager
of the Archimedes palimpsest project and
Jack Emery is the data manager and the
two of them have been working on the
project for several years Mike goes back
as far as 1999 it's a really cool
projects welcome Mike and Doug thanks
Donny we've enjoyed working with you and
look forward to continuing to work with
you I'm Mike to--the I'm the project
manager on this project have been for
about nine years now and Doug and I are
really representing a much broader team
and we'll discuss the breadth of that
team during the course this presentation
in particular will null who's our
project director and Abigail quant whose
are the chief conservator at the Walters
Art Museum and the image scientists dr.
Roger East and dr. Keith knocks and dr.
bill Christians Barry and so will will
discuss their work and of course we have
to thank the owner of this manuscript
who lent it to the Walters Art Museum
for the study over the past 10 years
back just a little history on this
program back on october twenty ninth 10
years ago 10 years ago seemed to be a
key date not only for this program but
of course for google this this text the
earliest known copy of Archimedes work
was purchased at auction for two million
plus a commission so total at 2.2
million dollars it contains writings
that were transcribed from papyrus from
the original Archimedes texts onto
parchment and since then was overwritten
with a with a book of prayer it's a
pretty ugly manuscript it's badly
damaged there's mold damage there's some
charring on the edges and what we've had
to do is take this
and transfer this into a format into
something that's accessible to everyone
we've been working on this as we noted
for over 10 years just this weekend we
put our latest release of data up there
at Archimedes palimpsest dotnet this
includes all the original images
includes the transcriptions all in a
data set that Doug's going to discuss in
more detail I should point out that all
of these images all the data is being
put out there on the web we think this
is a first for a program like this
really for a scholarly program for an
imaging program where we've put all the
data available for free use by anyone
it's under a Creative Commons license
and we've made this available or the
owner has made this available for anyone
to work with this so whether it's the
images the manipulation of the images
the processing of the images the
transcriptions what the text actually
says there's opportunity for anyone to
access this on the web access this
create gooeys for it do whatever you
want with it and make it either
available or to make your findings
available to customize a product to your
needs and the needs of a broader set of
users and and Doug will discuss the
layout of the data because we've put it
in a format to try to make it as
available to anyone as possible what
we've done really is we've taken science
and technology that's been used for
other purposes whether it's national
security studies or medicine or particle
physics and we've applied that to this
document in particular on the imaging
side we've taken advanced imaging
techniques multispectral hyperspectral
imaging and we've taken the original the
original manuscript take an image of the
images of those in various spectral
bands and we've processed those through
to reveal the
under text there in the same way with
there's four pages in here that have
forgeries on them that were put on in
the 1930s and we had to read underneath
those forgeries we were up at the
Stanford Linear Accelerator Center in
fact when we were last year in 2006 and
we use x-ray fluorescence and I'm not
going to go into a lot of detail with
the x-ray fluorescence it's in our
previous tech talk in March of 2006 but
what we were able to do was to read
underneath those forgeries using the
synket Ron at the Stanford Linear
Accelerator Center and to get this text
out which was key to understanding
Archimedes original works with regard to
sit floating bodies I think it is was
underneath this so we've used a number
of different imaging modalities to get
this under text now of course when we've
been doing this has been during a very
dynamic environment with regard to
technology as a whole and information
technology in particular of course 1998
not only was the the manuscript
purchased at auction but of course
Google became a public company then in
fact I guess 10 years in a day now is
what it's been a camera technology has
advanced considerably we've gone from
what was commercially available a 1
megapixel camera to higher than 10
megapixel cameras now the internet
itself has changed considerably with the
the ubiquity of data whether it's mobile
or whether it's back then it was mainly
wired your access to data well so too
has our program advanced during the
course these ten years as we developed
standards for our metadata for example
working with HTML and then XML the
imaging methods with with imaging
systems that have advanced and the
knowledge of what is in this manuscript
with papers that were produced on
Archimedes method
on the stomach Ian and other manuscripts
that were found within this poem sis
commentary on Aristotle hyper I ities so
over this ten year period we've had
continued discoveries continued advances
in technology and continued access
ultimately this has brought us to the
last two years where everything was so
accelerated we had another imaging
session weary image the entire
manuscript we then put all that data out
on the web we've encoded the
transcriptions all for a data released
the final data release at the end of
next month so what I'm going to focus on
here what Doug and I are going to focus
on is what's happened since 2006 since
march of 2006 when we last presented a
tech talk here at Google if you want
more of a history of the polym cyst some
of our earlier imaging some of our
earlier information handling I'd suggest
you look back at that previous tech talk
will null presents the history far
better that we can do and the imaging
scientists of course can get into more
detail as far as the imaging science now
back when we presented on March seventh
of 2006 we said hey we wanted your
thoughts as to how to make these in
images available we wanted to make them
available to his broader group as
possible you of course working with John
Trowbridge in Chicago have come up with
what your we're calling Google polym
chest with a way of getting large
amounts of data out there and now
working with Google Books google maps
and others we've been been talking with
Vint Cerf out on the East Coast and
various others and basically putting
this out here for you all to use the
data to make the data available to a
broader set of users whether they're
scientists or scholars so since then and
back then we talked about you know
geospatial data that you have google
maps and we said hey there's got to be
something here with because we're
linking all
of our data spatially each of the images
have their own coordinate system each of
the transcriptions are mapped to that
coordinate system but we're not putting
the GUI out there what what do you feel
you could do with it I think and so
you've got a range of capabilities there
now back then we were doing what we call
production imaging and and Roger
presented how we used a basic monochrome
camera we used both the tungsten light
and the ultraviolet light and then we
merge those to get a processed image and
we found we were there were some details
we really needed we could get the
diagrams fairly well but there are some
key lines of tax some key letters that
we weren't getting and of course we went
with the the x-ray fluorescence and that
gave us more detail not only on the four
forged pages but also on the the front
page which had been badly worn and we
got the the colophon we found out who
had actually inscribed the over text the
you glow gian on this but we felt we
needed to go further with the imaging
itself we did some experiments the
imaging scientists did some experiments
with other imaging techniques building
on work that had been done at the
National Gallery in London working with
advances in light emitting diode
technology with LEDs came up with a
different scheme which we experimented
with back in two thousand six in an
imaging session where we had what we
have here is a box with LEDs in it and
then this light fiber that takes these
lights and brings them to bear shines
them down on the manuscript underneath
the camera and this had tremendous depth
of detail there it provided us a broader
spectral range but also narrower
spectral bands and we were able to
process this better
and after we we first pioneered this
weave course took it to Hollywood and
then they made a movie out of it no the
if you saw national treasure two they
just use some plastic fiber but they
apparently use this I haven't seen the
movie but apparently used it to good
effect in the movie so we said well if
it's we can be used in good effect in
the movie we will use it on our program
actually was the other way around but
bill Christians Barry who's shown in
this image then looked at putting all
these LEDs on a panel and instead of
going through the light fibers shining
them directly down on to the the
manuscript and it's really a great
engineering capability here that he put
the UV LED and we have six of those
there and then the visible LEDs the the
red the Greens the blues and we have
seven of those and then for infrared our
LEDs and we have been talking with
people we didn't get good response on
the infrared earlier but we found in
some of the parchment that it didn't all
go to singularity with the the infrared
and we did get a decent response there
so we went with the infrared as well so
we put all of these on to two panels
integrated them together and we use that
for an imaging session in august of last
year and what we ended up getting was
all these peaks in the various spectral
bands that we could also work we didn't
really do this but in future you could
work across by turning different lights
on and getting truly a spread across the
spectral bands here in all these
wavelengths so we ended up with we
worked with Stokes imaging in Texas with
this a very large format camera that
blue used a piezoelectric motor to get a
an even larger format image and we could
only get a color camera we were we were
shooting for monochrome but we wound up
with a UV image
visible images and then the infrared
wavelengths this whole data cube if you
will so we took the pollen cyst which
was this ugly hunk of parchment and
produced this matrix if you will of
different spectral bands now you'll note
i cited 12 earlier and we have 16 here
these on the bottom are raking light
because we also found and and with those
we could process through the through the
various spectral bands we could process
those together sorry the advancer seems
a little slow there we could process for
example the UV and the red and get a
pseudo color image where you can see the
under text here running horizontally and
then what was originally the book of
prayer in orientation running vertically
now I mentioned that we had raking light
because if you look closely here you can
see there were what looked like obscure
ins an under text and especially if you
look with the raking light look closely
you can see what looks like original
letters that were scraped off and as we
looked and processed that through we
found its ad on das which gave us
greater insight into the hyper IDs text
which was a letter on d on das so we've
got the raking light we've got the
multispectral bands and we then have the
the images and then provide those to the
scholars for work and what we wound up
doing was integrating the work of a
broad range of people we have as I noted
will an Abigail conservator there's the
owner and some of the people he's worked
with and he was not a hands-on manager
but a key points here we received good
guidance and one of the one of the key
points he made to us was to make this
data available as broadly as possible
make it available through service
providers such as you
not just put it in a library somewhere
but make it broadly available on the
internet and make it as flat make the
data as flat as possible so that it
could be preserved over time it's not
dependent on any one format it's not
dependent on any one provider that this
data will be extant hopefully a hundred
years hence at least ten years hence in
this fast-moving information technology
environment we have the imaging
scientists Roger Bill Keith bouvet
Bergman we have dug on the data
management side we had a broad set of IT
support range of scholars around the
world and part of this was bringing
scholars and I tea together and this is
represented i think in budapest by laws
little horv off and his brother Zoltan
who provided us not only good input on
the scholarly side but also on the IT
side we had people a broad range of IT
support Carl Malamud of course has been
key in hosting the data and then people
just been providing day-to-day support
in some areas result in one of the
libraries we are working with folks at
the Walters just making sure that this
data is available so ultimately trying
to bring knowledge to bear to this
program so I'm going to turn it over to
Doug I was going to as I said when we
last presented we had you know 250 gigs
of data when we put this datacube
together we ended up with about two
point five terabytes of data data
management is key for this doug has been
key to this project going to turn it
over to him to discuss what you're
getting what you get when you go to our
communities pollicis net what it looks
like and what you're going to be what
you will be working with and what you
could do with it Doug Emery
hi I'm Doug Emery and I've been with the
the project since about two thousand six
when I was asked part time to work on a
small database for their imaging at
slack and so I wrote a small database
with the collection of the metadata that
was gathered while the slack imaging was
going on and about a year ago Mike and
will tricked me out of my day job and
almost full time now I work on the
Archimedes palimpsest project and what
I'm going to do is talk about the the
final project that we've generated the
ideas behind that and hopefully well
yeah so let me talk about the the final
project we're generating and the ideas
behind that so our project goals are
threefold first we want the the digital
data set that we need to produce that we
produce to serve as the authoritative
digital data set of the images in a
standardized format we also want to
provide information in the context of
digital images transcriptions
essentially and I'll talk about those
and then also to offer a standard
product which will be sustainable by
users in other words what we're
providing a registered images spatially
mapped transcriptions and a documented
archive structure go duck an archive
with a documented structure so I'm going
to talk about each of these in turn
first the registered image is it's
essential to the project that all of the
images are registered together these are
images that originated in the august two
thousand seven imaging session the first
to ultraviolet image a red image and
then a pseudo color image that's
produced out of those we also have a
number of other images that are also
registered to the same dimensions what's
important here is the integration of all
of the pieces together so the images
themselves especially the 2007 well the
2007 images are born in a fashion that's
in it that is integrated with the rest
of the project
with each other so all of the images are
registered to about eight thousand by
ten thousand pixels the registration is
done based on images that were taken in
2007 August of 2007 and any other images
that we have there are XRF images that
Mike talked about there are photo there
are images that were made from high
bergs photos taken in 1906 of the
palimpsest all of these are manually
registered they're scaled and warped to
the august two thousand seven images
typically this is done to the
ultraviolet image the image is to image
details they're fairly simple they're
all TIFF 6.0 images they're all eight
bits per sample the original images are
typically 16 bits per sample the
resulting images or either monochrome or
24-bit color and the resolution is
approximately 33 pixels to the
millimeter of the the parchment document
we as Mike pointed out we have several
image types there are the august two
thousand seven images these are for all
of the folios we have ultraviolet
visible infrared raking and then
processed images that are made from
those the visible light images we have
XRF images of selected folio so those
folios that were done at slac those are
included they have depending on the
image and particularly depending on the
folio and the specific needs of the
folio different elements were detected
during the xrf imaging we have Heiberg
photos in 1906 Heiberg had photographs
made of certain pages of the palimpsest
i believe that there are 65 Heiberg
photographs that correspond to 60 of the
disbanded folios Heiberg was taking
photographs of the book as it was opened
we're imaging the disk bounded book so
that you know the actual under text
folio so a lot of those images are
reassembled to match the a lot of high
berg's images are reassembled to match
under text folios there's one leaf at
Cambridge this is unfolded it's somehow
ended up in Constantin Tischendorf
sprocket in about 1837 and was sold to
cambridge university in 1879 from tish
endorsed estate so that is also included
in the data set and then there is a
negative that was taken in you know the
date of the Chicago negative Mike in the
1930s there was a page was taken to the
University of Chicago where it was
imaged and we also and there's a
negative of that and we have one image
of that that was done in visible light
in back in the fall of two thousand
seven so the metadata the this is the
cover of the book the Archimedes codex
by william knowland reveal nets and my
copy is signed by way of null and
William no wrote in the inscription to
my book to dougie Murray who's critical
contribution to this project goes
unrecorded in this book sorry metadata
doesn't sell thank you so much will know
and while metadata may not be
particularly popular and it may not sell
it's still important to the project and
very early on Mike to--the and Bill
Christians Barry worked very hard to
establish imaging metadata standards and
standards for gathering metadata and
they relied on existing standards one of
the primary was the dublin core metadata
initiative element set which serves as
our core identification data they also
employed the content standard for
digital geospatial data which informs
the the space which is the basis for the
spatial information that we collect for
the for our metadata
so the our goal for the project data and
for the metadata is the long-term
viability beyond the lifetime of the
data set beyond the lifetime of current
technologies and it adherence to and we
do this by adhering to broadly accepted
standards and using simp simple flat
metadata records so we wanted both to
adhere to standards but we wanted we
wanted simplicity so that 10 years from
now 20 years from now when when some new
when some technology that's currently
existing is no longer is no longer
available we're no longer known to
people the data will still be accessible
to them and also it was very important
that we integrate the metadata with the
images and the transcriptions so that
the metadata the data that explains what
the objects are is always traveling with
them we have six types of metadata
elements identification information
spatial reference information imaging
and date imaging and spectral data
reference information primarily
scientific data about how the images
were made data type information
including including not only file type
but also the type of processing that was
done to create the image data content
information this is keyword data but
also information about that it relates
the object relates the image to the
object folios information and then
metadata reference information including
our extensions to the metadata standard
for XRF images so some of our sample
metadata fields these are pretty basic a
lot of this is dublin core data
identifier creator date some of this is
exif standard exif data aperture setting
and then some of these things are
specific to our project light source
light source wavelength information and
foliation scheme we record both the
prayer-book foliation of the image of
the object and the under text foliation
we have about a hundred three core
spectral and metadata elements and 53
xrf metadata elements and here's a
sample of our metadata format so this is
just the beginning of one of our
metadata records they are flat records
this is the dublin core information for
this image 2000 which ever one image
2000 is or 20,000 so the way that we
integrate the metadata with the image is
we store the metadata in the TIFF image
description tag we thought we talked
about this for a long time and decided
that we would use this tag because it's
a very simple common tag all TIFF tag
aware tools can access the image
description tag it allows us to
integrate the metadata with the image
and it adheres to an existing well-known
standard we also with each one of the
with each one of the images we pop we
supply XMP sidecar files that contain
exif and tiff metadata as well as as
well as our own Archimedes palimpsest
metadata so the next part of the the
delivery Oz is our mapped transcriptions
and the idea behind the map
transcriptions was to have the
transcription as a guide for the image
not the transcription published as a
transcription but as an assist as as a
help a support for reading very
difficult to read images or for
accessing very difficult to read images
and the scholars told us that this was
important for us to have and the way
that we ended up at ensuring achieving
acceptance and longevity for our
transcriptions is through adherence to
transcription standards in the field of
classics and adherence to international
text encoding standards so our early
efforts
there we are we began with some
handwritten transcriptions and we also
had word transcriptions and we knew that
we needed to get these transcriptions
into a into a shareable format and we
chose XML for that and we made a very
early effort at creating XML mapped XML
transcriptions I think it's coming and
it was it was fairly crude the the xml
file had our exit headed the metadata
for the transcription it had these the
spatial coordinates of the line on the
on the image and provided the resolution
of the image these were earlier images
that were smaller than the ones that we
have now and then some and then someone
who is very helpful suggested to us that
we use ascii character code ascii
character entities to indicate the
unicode characters and we took these
results we took our plans to the 2006
unicode conference in washington DC and
there are some people there who varying
gently told us that there might be a
better way to go about doing this and it
was there that we came in contact with
debra anderson of berkeley and we she
put us in contact with Leonard Mulder of
the Center for Hellenic studies in
Washington and Cambridge and also we got
in touch with Neal Smith Holy Cross
University and Chris Blackwell at Furman
University both of whom work with the
Center for Linux studies on the Homer
multi text project and after through
conversations with them after speaking
with Neal and Chris and a number of
other classicists who were involved in
text encoding we generated our
transcription integration plan and this
is an October of 2007 and the result for
this was that we chose a unicode
encoding for greek we expect that we
would use we chose unicode normalization
form c for the transcription we also
selected the text encoding initiative
tei p for release with and the epic
which was developed by Tom Elliott for
the text encoding and we also had an eye
that we were looking at tei p5 which was
coming out in the following month so
that we made these decisions in 2007 but
we knew that te ip5 was coming and there
were some things that we liked about
that the fact that it was based on
schema based xml for instance and the
one of some of the other points that
were important about our about the
transcription is that it would focus on
the physical layout of the parchment it
was always important to us that we
weren't interested in creating an
edition of archimedes we weren't
interested in focusing on the underlying
structure of the content of the document
but in fact on the the physical layout
because these are serving this is
serving as a guide for the images
themselves we also decided that we would
use placeholders for figures we knew
that we didn't have a way of rendering
the figures that are in the text the
figures are extremely important reveal
Nets his work is primarily based on
looking at ancient mathematical diagrams
and also we would mark non grammatical
elements in the text this was important
because it would allow the scholars who
are working on the text to be able to do
grammatical analysis and testing of the
transcriptions without it being
interfered with by non grammatical
elements and we did this with it with a
consultation of with an international
team of classic scholars we worked with
Peter het which we spoke with Peter
Heslin at the University of Durham in
the UK we worked with gabi Bedard at
King's College in London also neil smith
at Holy Cross Chris Blackwell at Furman
and Tom Elliott who then was with
University North Carolina Chapel Hill
East since left there and so our
activities the transcription activity
since november of 2007 have been putting
together a digital transcription team
and this work was done
through folks working for the Center for
Hellenic studies Neil Smith at Holy
Cross Chris Blackwell at Furman and
their students as well as Alex Lee who's
a graduate student university of chicago
and alex is a student of rebbe ale nets
is and also one who is very
technologically capable and we have
since also moved to working since moved
to using te ip5 and one of the biggest
challenges in the in the transcription
effort has been the coordination of the
creation of the tei transcription and
verified verification by the original
transcriber on the one hand we have a
group of very tech-savvy classicist and
on the other hand we have a group of
classicists who are not technologically
very they're not technologically focused
and for us alex lee the student at the
university of chicago has been extremely
important in his ability to bridge those
two those two worlds so the
transcriptions that we provide there are
essentially two transcriptions there is
Jael hi Berg's 19 10 through 19 15
addition of Archimedes which includes
his reading of the readings of the
palimpsest and then there's the
contemporary transcription of reveal
nets and nigel wilson which is based on
hi Berg's reading and the new images in
some cases because of the deteriorated
state of the palimpsest the Heiberg
Heiberg had was able to see things that
are now lost to nets and wilson and in
fact Heiberg saw and recorded Heiberg i
believe i meant i did mention that
Heiberg had about 65 images his
transcription of the palimpsest is based
on a larger number of folios than he
actually had images off so he has data
in his transcription that reflect the
palimpsest that are not in the photos
and are not now available to us and so
some of our readings are some of the
readings are supplemented by this quite
well our digital transcription we have
decided to maintain these
two separate transcriptions so we have a
high berg transcription and we have a
nets Wilson transcription both of these
are done in Te I and it means that we
can create different views of the
transcription as needed by doing
transformations of the XML
transcriptions so the digital archive we
were during the time that we were
imaging the host during the time that we
were imaging the palimpsest completely
in august of 2007 we were visited
visited by Vint Cerf who is a friend of
the owner and he brought with him Adrian
hook Adrian hook is ah the man who works
with Vint Cerf on the interplanetary
internet project at NASA and Adrian put
us in touch with Don Sawyer and his team
there that were working on the working
on the open archival information system
of reference model for long-term
archives of digital data and this comes
out of the Consultative Committee for
consultative committee for space data
systems this the reference model
requires the inclusion of certain types
of data in order to maintain the
long-term the longevity of the of the
archive one is representational
information the description of the
actual bits that make up the file
preservation description information
content information that describes what
the data is that's contained within the
archive packaging information
information that describes how the
different pieces relate to one another
and descriptive information data that
allows both humans and machines to
access the data that's in the archive
and we've tried to follow these
principles in the construction of our
archive itself and so the result then is
a standard archive structure with
documentation and metadata to ensure
access so the archive at the archive if
you go to ww Archimedes palimpsest net
you will see this page and what's on
this page is the core of our
archive we have there at the very root a
file list in a readme file the readme is
a brief introduction to what's in our
data set and it doesn't tell you where
anything is and the file list tells you
where where all of the files are there
is a data directory which contains our
core data and I'll talk about that next
we have a documents directory which is
all internal and external documentation
on the data set the Supplemental
directory I'll describe in a moment the
support directory those are all XML file
I mean those are XML schemas cascading
style sheets this sort of thing these
are data file these are secondary data
files secondary files that are used by
the by other files within the data set
and then research can't rib research
contributes for important data that
doesn't that hasn't been integrated with
the core data set so for instance we
have there's a graduate student at
Dartmouth Gabriel Weber Weaver who is
working on diagramming for working with
ancient mathematical diagrams in XML
that data which has not been integrated
into our data set will likely go into
research can't rib so the data directory
is simply one is simply one folder one
directory for each one of the underlying
folios the folios themselves are done
the foliation is done based on the
prayer-book folio so to recto one verso
is one folder to verso one recto is
another folder of the folio to in one
combination what this the reason for the
the ordering of the number indicates
that to recto is the top half of the
page of the Archimedes page 1 verse o is
the lower half of the Archimedes page I
don't you may not have mentioned this
but the the underlying text of the
palimpsest is at a right angle to the
text of the prayer book so the way that
the prayer book was
creating was a larger manuscript was
taken cut in half palam zested rotated
90 degrees and then bound back together
to make the prayer book and so we have
dis bound the prayer book and have the
original manuscript pages together and
so this foliations this affiliation
scheme in the directory listing tells
you that two recto is the top pay top
half of the Archimedes page in cases
where we do not have a conjoint as with
100 are an 11 with as with folio 100 in
folio 171 we use 0 as its place holders
to indicate that that part portion of
the page is missing within each folio
directory or all of the files that
belong to that folio here's a close-up
of one section of that this is the folio
this is folio 81 v where's mine this is
81 v88 are and these are actually the
files that belong to three separate
images the ultraviolet LED 365 image an
le a blue LED 445 445 nanometer image
and a these sort of green the 470
nanometer images and we have a standard
file structure that we use for each one
of the images the first that all of the
sections r / underscores the first
section of the filename gives you the
prayer-book foliation the second section
tells you the foliation within the
Archimedes text so this is Archimedes
folio 3 verse o Cynar this is the type
of camera that we that was used in the
august two thousand seven session and it
tells you what kyle's us what session it
came from the light tag we sometimes did
multiple series of the same image so
this is from series 01 and this tells us
that the final tag pack eight tells us
how this images image was derived from
the raw image each one of the raw images
who has 16 bits
per channel and the image is reduced for
distribution these are all all of the
tiffs are they're all 8-bit Tiff's and
they've been they've been stretched into
a bit format by a pack image program
along with each each TIFF is a JPEG a
very small jpg image about 100k an md5
checksum for the TIFF and then in XMP
sidecar file each one of those images so
within each directory or all the court
images of a folio side raw images
processed images and the not well I saw
as perhaps the wrong word is the wrong
word to use images derived from the raw
images directly from the raw images
process pseudo color normalized you be
so called Sharpie images true color xrf
and high Burke images where they're
available also XMP sidecar files for all
images the tep 5 Nets ways Wilson
transcription md5 checksums note that
all of the images were registered and
all of the transcriptions are going to
be mapped line by line to the images
here's a shot of included metadata in
one of the four one of the folios and
here's another here's a shot of a TI
transcription the Supplemental directory
we have in it we have folio by folio
transcriptions with for each one of the
folios that's in the data set the
scholars themselves do not work the
transcribing team does not work folio by
folio the transcribing team actually
works for the complete work so they do
in a complete transcription of floating
bodies methods fear and cylinders fire
aligns tamaki on and so forth the way
that and that's the file that we start
with they create folio by folio
transcriptions by using XSL transform
transformations and so in the
supplemental directory we
apply their source documents this is the
internal documentation in the internal
documentation we have a description of
the software that we use that this used
to process the image is a list a
description of our file naming
conventions a folio index that maps from
prayer book to under text folio our
metadata standards and a little how-to
on using md5 files the external
documentation is a complete
documentation of all the is a complete
documentation of all the standards that
were used for the content of the data
set so we have for instance the unicode
unicode specification and code charts
for all of the unicode text we also have
the TIF standard which is extremely
important as well as a number of other
standards dublin core relaxing schema
specification and so forth the research
contributor is critical data that is not
integrated into the core for instance
non-core valuable images high-resolution
close-ups of certain sections of images
experimental processing of certain types
the diagrams that I mentioned earlier
and then eventually it'll also have
conservation data a great deal of data
was collected in conservation for the
data set so the product what it is it is
a complete man is a complete manuscript
data set is a data set adhering to
common broadly accepted standards and it
is an integrated product data and
metadata images and transcriptions what
it is not is an application or a
prescription for users we leave that up
to other people and to others to do and
we hope that we provided the the hooks
and the open architecture that will
allow other people to do that I'm going
to hand it back over to Mike who's going
to talk a little bit about manuscript
studies okay thank you dug dugs other
title on the program in addition to the
Data Manager is her Doug the Lord of
minutia because he keeps us straight to
make sure we have all the detail that's
needed whether it's
the imaging scientists or by the
scholars but in terms of a product this
really is changing manuscript studies
and not just this but some of the work
that Center for Linux studies and others
have done whereas it used to be a port
over the original manuscript or maybe
some pictures of the manuscript and now
you have this broad range of data and
you're relying not just on libraries not
just on universities but service
providers such as Google such as
whatever the data host may be the
perception of Google in in the scholarly
world and in the archival world such as
this document by the Council on library
and information resources is you know
akin to the the alien ships and
independence day and part of their
concern is the fact that part of us a
control issue you know they don't
control the data and this is something
that that we're going to have to deal
with we're releasing our data out there
people can ads the data people can
manipulate the data but we're giving it
up and we're making that's part of
making it available to everyone but part
of it is one person's treasure is
another person's trash what may seem
like an encumbrance to the data may be
very important to a preservation
scientist or to a conservator or to a
scholar who's trying to determine what
is the underlying text there and so as
you work with this data it's it's
critical to consider as you as you do
with most your users you know what are
the needs of the users and of course how
do you make this most broadly available
what we have here is really a heresy
that we're saying that the digital
artifact especially in this case is more
valuable than the parchment itself
itself and reveal cited this in a radio
radio interview he gave where he said
the parchments gone as far as scholars
are concerned there's no parchment you
work from the digital images on the
laptop so these images are priceless to
these scholars
and we all have a really a covenant to
preserve these over time and to make
this information available as available
as possible in a form that's as usable
as possible so as we transfer from the
ink to the digits to we have to preserve
these digits and make sure over time
that as we go to New new operating
systems as we go to new data formats as
we go to new standards that they are
this data is available there are a
number of related projects are a number
of projects we've learned from British
Library is has a number of projects
underway including the Codex I on
Atticus that they're working with a
number of other organizations bill
Christians Barry has worked with the
oxyrhynchus and the Herculaneum papyri
with Oxford University using some of our
same camera system the Homer multi text
project with the Center for Hellenic
studies and and the British national
gallery so we believe that what you do
with this data what you do to this data
will be applicable to other data just as
an example we've been doing work with
the library of congress on the vault see
muller map the first map to show America
same type of thing as we did with our
committees different camera firm called
megavision out here in California
because we needed that monochrome camera
we didn't want the bear array that's
provided by a color camera same thing we
got the various spectral bands here and
then we have the raking light put it
together with the the LED lights that
bill Christians Barry with equipoise
imaging put together and we got some
good products we could see down to the
original print Brock block really come
back with some of the advanced
processing techniques to see some of the
printer techniques also to enhance some
of the original red grid lines that were
on this map so some of the same
techniques we've applied to the
Archimedes palimpsest with the imaging
with the illumination with the data
management apply to this project they
apply to a range of other projects
because we've used
broadly accepted standards so we feel as
you use this data that's available out
there now as I said we just had a data
release this weekend thanks to carl
malamud and his folks who are just
cranking away over the weekend to try to
get this data hosted taking it from doug
from the imaging scientists from the
transcription and coding team will have
our final data set released on october
29th of this year we think there's
opportunities as you work with our data
set that you will be able to apply some
of those whether it's a GUI whether it's
a data handling capability whether it's
storage to some of these other projects
so look at it October 29th look at it
now we're turning it over to you we're
turning it over to you google we're
turning it over to you as
representatives as a broad range of
information technology providers whether
it's in terms of a product in terms of
data management you aren't the only ones
it's available for downloading across
the web other people are doing it and we
are turning to you all we're not
providing the gooeys we're providing
these flat files these simple files to
be preserved over time as parchment
lasted for a thousand years it's been
through Wars it's been through mold it's
been through water and it survived by
the fact in part because it was over
laden with something that was a value a
book of prayer how this is going to be
preserved in the digital era over time
as a challenge you have to face is a
challenge we all have to face so we look
forward to to working with you your
cohorts across the the information
technology community and we'll we'll
take your questions
alright so if you have questions please
let us know and then we'll repeat the
question for people on video to hear yes
have the scholars that want to use use
this have a suggestively
the the scholars what kind of what kind
of interfaces have the scholars cited
that would be of use to them some of
these are imaging interfaces with the
ability to be able to scroll across an
image and zoom down into an image as
they get to a specific piece of text
there and sometimes it's a it's a very
fine mark which is why where we've put
these original TIFF images out there
they're really big but we believe that
using that as a basis for a data set
will allow you to get the degree of
granularity you need in terms of working
with the transcriptions do you want to
discuss that Doug well one of the with
with the trim with the transcriptions
what's valuable is that the text is
accessible its encoded in a way that you
can find the elements that you need and
doing that you could I think that the
scholars would be able to like to would
be able to like to be able to collect
any number of locations where a certain
form occurs where whatever their
particular interest is and then find
that in the images and be able to go to
those go to those pieces so it really
comes back to an integrated product
where they could have their
transcription and look at the
transcription scroll across and mind you
these are spatially length scroll across
to say in omega and at the same time it
will bring you it can bring you to the
omega on the image and you can see both
and then zoom in on that Omega
all the images that are available for
that that is correct the question is
presumably all the images so not only
the the processed image which they're
working with Keith Knox's algorithm that
takes the various spectral bands
combines them and provides that pseudo
color but also XRF also the individual
spectral bands the Heiberg photo perhaps
the Chicago or Cambridge whichever leaf
it may be the rigging light image
perhaps if there's a case and there are
many cases where the scholars are
working at the very margins of what they
can see and so in this case you never
know which particular image is going to
be the best source for finding the data
there whether it's going to be the
pseudo color image or the pseudo color
that I referred to the Sharpie images
and these are pseudo color images that
have been rendered monochrome and that
over text has been stripped away and so
depending on the person's need which
images best changes so they're really
looking they are integrating large
amounts of data just just mentally just
taking in large amounts of data and
someone like Revell netsol see something
in a heiberg and something in a certain
illumination right now it puts it
together from different things he pulls
up on a screen you would like to be able
to look at all of that at once in one
layer and be able to drill down its then
other questions
questionnaire this was the
representation available and Unicode for
all those modern and ancient Greek
characters sufficient were to do come
work with Unicode
new things in there was the
representation and unicode sufficient
for the the ancient Greek characters or
did we have to work with the Unicode
dunno the short answer is yes everything
that everything that's been needed is in
Unicode there are some interesting
ligatures medieval ligatures so there's
a character a stigma I believe it's a
it's a ligature between a towel and a
sigma and this is a common medieval
character and that's available in
Unicode as it is now so I've not heard
they've not said that there were any
characters that they had to fabricate or
that they needed added will be at the
Unicode conference here on in san jose
tomorrow so we'll be chatting with with
Debbie Anderson and others or I've run
into similar challenges with other green
text other questions well thank you the
data will be at it is out there now as I
said we just put this big data release
out so we welcome your comments you can
drop them to us there's i'm not sure if
there's a comment section on the website
but 2w null at the Walters org is is a
good one there and he'll pass them along
but we really welcome your comments or
through through Tony passing along to
Tony and he'll pass and toss but that's
how as we go to this final release on
the twenty-ninth of October we're not
going to make any big changes now but if
there's some things that you see hey
this would be better this way or that we
welcome that input so what so thank you
very much appreciate the hospitality
Megan to thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>