<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Artificial intelligence and digital media | Coder Coacher - Coaching Coders</title><meta content="Artificial intelligence and digital media - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Artificial intelligence and digital media</b></h2><h5 class="post__date">2008-02-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i78P-K1RhjY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon it's my privilege the
SATs
introduce Steve dipaolo a graphics
worker that I had the good fortune to
work with many many years ago at New
York Institute of Technology where we
had the opportunity to participate in
some early pioneering efforts and
graphics steve has done a lot since then
mainly in the field of interactive
graphics and I'm quite as excited to see
his recent work as I hope you are thank
you very much hi everybody I'm going to
talk about artificial intelligence and
digital media that's quite a big range a
title so i will be talking about a
subset of that and i immediately discuss
what subset i think is somewhat
reasonable my background is I I was at a
i'm now at a time fraser university at a
school that actively mixes a scientist
an artist so we're we're kind of a
computer science school that allows
artists and designers in little less
math little less computer science but
other than that it would be that way but
we do have a very significant masters
and PhD programs what really is trying
to show it interdisciplinary
cross-disciplinary research can do i do
have a was down here seven years ago for
seven years in industry a bit at running
a part of the advanced technology group
at EA in foster city i guess it's in san
mateo now and then and some startups
doing VR world so I I readily admit with
that AI name at the top there that my
background and my strength is more
interactivity graphics and simulation
and some of that simulation has put me
in some parts of the AI space and I do i
do find i make things and then make art
with those things and I learn from both
ways and I'll discuss a little bit of
that so what was on the abstract was out
there to kind of poke a little bit by
saying by using parameterised techniques
which model a knowledge space of a given
social or cognitive process it is
possible to use AI techniques such as
neural network
genetic programming to create new types
of things and those things are quite
wide but here i have visualization
creation tools search tools and
expression tools and notice at least i
use that word tools or symbol or systems
because that's that's one of the
benefits i think that these kinds of
parameter asian techniques help with
that they create a space and within that
space as long as you have a little bit
of knowledge of that space you can move
through it or I'll have your user move
through it in slightly different ways so
the disclaimer again on on AI again it's
it's a it's a big and beat up field in
many many ways and I surely get beat up
daily on parts of it so I wanted to at
least clarify what I do and where I come
from and I don't really like it but I k
tionally use the term computational
intelligence and at least that that
actually has a definition which fits me
for my Triple E which as you can read
kind of favors this more biological
linguistically motivated paradigms so it
emphasizes and again I've taken this
right from the definition and the things
in yellow can you see them as yellow not
really ok so there's orange and yellow
up there but I think there that's a
little bit of everything the things that
I mote mostly involved in his neural
networks and genetic and evolutionary
systems a little bit of fuzzy logic
stuff another definition kind of says it
chives away it's as rejects here but
what you say shiz away from statistical
methods so wow I would push that is kind
of bringing up this kind of Turing test
side of things which is from the
biological side I'm kind of interested
in what really happens and mimicking
would say a cognitive system so I so I'm
interested in that even even if it does
it very simply it is in fact trying to
be intelligent as opposed to appearing
to be intelligent so that I think that
would be my definition I be very clear
that that doesn't mean it's better than
just satisfying the Turing test because
usually in trying in in trying to be
intelligent
doing it in a much simpler way and
that's and Lisa on the bottom here are
some of the groups that are involved
with things like that and and people
that I'm working with in Cambridge it's
the rainbow research lab at UC at
University College London it's a Peter
Bentley does a lot with evolutionary art
systems and I stole in a good part of my
genetic system from from York so this
idea of parameterised because that's the
heart of at least the kind of style that
I try and do so it's imagine that
there's a soft knowledge space of
anything but let's you're sitting on
chair so let's say modern chair design
the space of all types of modern chairs
or the space of face types that there's
some domain and within it there's
there's a in some correlated way all
face types or the behavior space of
wells which is a little bit more tricky
to analyze or the emotion space of music
those last three at least we'll be
talking through a bit so to do that you
want and first have to get that
information which which is in art all in
itself and have some papers just trying
to get out of either a scientist or an
artist you know what they do whether
it's deep understanding of wells or how
they paint the painting but once you get
that in some soft way that you need to
quantify it for in a computer system and
the tech and there's many techniques
there and this is where I'm starting to
limit space and the technique that I
used because it's actually quite big in
the facial graphics why I came from and
generative systems as well is is
parameterised techniques where you try
and define a set of factors whose values
determine the characteristic of the
system so you're really making these
these axes you're climbing that ok these
are the really and if there are some
parameters that really speak to the want
and need of a beluga whale this would be
a good way to limit that and what's nice
about that is a it can be quite a if you
do it in a certain way is quite a
complete space you're not interpolating
data in between good data points it's it
all should be good data it all should be
resolution to dependent i could pick
anywhere in this space and get an
individual which let's use the the face
technique
idea that it these parameters could
literally be the types of muscles that
you need for for facial animation and
with that you can get a face with a
particular gesture in that point whether
you can pick anywhere to do that again
this parameter is technique surely has
some strong historical mathematical
perspective to it I come in from
genitive systems in CG again there there
are some other areas that also use this
term that I'm not doing as much so
principal component analysis and I climb
at least that's a little bit more
statistical than this knowledge side
that I that I'm trying to do so I'm
going to be very semantic knowledge
based content driven so I'm going to
back up one more time and say that as it
says in my bottle I'm an artist
scientist so so I'm going to be a little
bit and for speed because I'm going to
try and go through a lot of things I'm
going to be a little bit light with
these terms if you want to scream out
something right in the middle of my talk
or talk to me afterwards so note that I
don't know the full range of the
audience so to try and jam a lot of
stuff out you I'm not going to get into
deep details of what the differences are
but feel free to correct if you the
artist side of me to educate the signs
side of me so again why I like it it's
complete it's mathematically rigorous at
unitized so I'm not trying to make these
low-level parameters so they're they're
good for users to use I'm actually
trying to create the lowest set of them
that would be the words that I can make
sentences out of with that I know
there's no exception rules there's no
errors there's no dead space in the
resolution I usually make them unitized
so they're very easy they are
associative very good properties I could
just use them over and over again and
put more and more on top of them and
generally I don't have to worry about
them breaking that that's at least what
I'm interested in with that again in the
idea of hierarchical parameter space so
here we are again let's claim were in
this space of faces now how low level do
you go this is where i push this
cognitive or perceptual level I don't
actually if we're talking about facials
faces muscles might be a good place to
go there's a finite number of
if you had all of them with some other
biological ideas of how faces work you
wouldn't need any more that's the key is
when you're doing something complicated
you don't want to have to add new
low-level parameters so how low do I go
well because I'm really doing I'm
interested in perception and cognition
way I don't go to individual muscles why
we can't move individual muscles you
know ekman who's who's right up here at
of a ucsf prove long ago with the facial
action coding system that perceptually
we cannot we tend to work in a series of
muscles that makes sense then for me to
borrow as a computer scientist and say
that's low enough for me because I now
can extract data from from other sources
biological and psychological with that
said I would say we have corner mouth up
and down so what would be this higher
level is a well let's say we move up to
the next level rather than a word it's a
phrase that phrase could be something
really obvious I mean a semantic raised
in this case would be smile so I at
least could so smile as moving the
corner up maybe bringing the nose out
opening the eyes slightly so you can see
that I simply have an expression here so
this way this is the hierarchical notion
that i could build up higher and higher
level semantic constructs from these low
levels that's why it's important to make
the low level you know as as complete
and compact as possible now i'm right a
next level would be joyousness so how
would you do Joyce's damn that's
happiness and smile over time reacting
to other parameters so at least the
point is I can keep moving up this and
know that let's just claim at frame time
over over the wire I'm only the
semantics really can happen locally or
on the server and I'm always only
deriving back to these to these
low-level parameters sometimes though
it's in a multi-dimensional space so
I'll show you some work that I did for
the sims where I implemented a version
of this and they were in a phase space
but they always said oh this is like
spiro agnew with a gangster and they
would trade that with somebody else and
people thought they were in gangster
space so that knowledge space is a
stereotypic superhero gangster kind of
space and they they would hope and they
move these axes they would be moving
through
space in fact they weren't they were
moving much lower but we could build
that on top and you could imagine many
mother many many others valid face
spaces all of them learning from each
other but multi-dimensional in that they
don't they don't just hierarchical down
but in fact gangster space is different
from hey you know we're all out of
Africa it's quite being proof now and
you can get your blood tested in fact
you can see migration and with that
migration you literally can't see how
faces change that would be a whole
nother face that surely would have where
you could move between that and gangster
space but surely those would be
uncorrelated but would move down to the
same so that's what i mean by
multi-dimensional as well so that
knowledge i only do in a particular area
the area that i'm interested again is
more this human and social centric so i
like to think of it as expression
systems this communication but
communication with a little umph with a
little emotion with little reasoning in
this human way can be considered
expression or other things so with that
again more cognitive living systems
approach I'm interested in character
systems but as well as encoding social
and human expression so that would be
voiced gesture expression emotion then
you can imagine some of the dimensions
kind of above that or creativity
personality interesting once you or in
spaces like that you can map them easily
to each other so you can go from one
data set to another one so that's this
this idea of remapping implicit
knowledge and then this is some of the
areas i do it with i pack the slides
kind of heavy knowing that bill be
around and i wanted to go more wide in
the talk so I'm going to blow through
some slides quickly so you see something
so you can either read fast or a look at
it later is an area that's more
interesting to you so obviously this
kind of work is into this blurry it sits
heavily on computer science in my case
graphics and AI and math but that that
makes a system that I have to pour
content in or at least under that's the
knowledge part so I work a lot with
cognition with psychologists and
sociologists and I tend to need a design
process
to extract data because in fact they
don't give me well data exactly away my
neural network and action selection
system works so and they're busy there
sorry there's urologist worrying about
these whales so some of the techniques
is also how to how to get them to open
up in a certain way by the way the
problem with quote scientists is the
answer back i get almost all the time is
we don't know that yet so I in the case
of the whale stuff I go his name is
Lance as well I said lands I've done my
homework there's only eight of you in
the world in that you run a research
center in a very large aquarium where
there are eight beluga whales so if you
don't know no one knows and I'm just
modeling so from nothingness to ant to
Beluga which do this again explain to me
the biomechanics of the fluke because
you have to know something often they
know it and they've seen it I've seen it
and they'll say well that's in captivity
I know I know but we can extrapolate
from maquette you know so scientists
tend to want the real answer where I'm
coming in as you can see kind of
top-down artist by the way which I do a
lot of work with to tend to talk about
everything but it's 00 so how do you do
that jazz saxophone thing well you know
I eat a good breakfast I get up the
magic comes and then I go okay so let's
go back to the magic part can we can we
talk about that a little bit more yeah
it comes okay good i'm so so it isn't
there and it caught you know i mean even
comes you can say okay so it so it's
fast okay I get that so it's you know
and is it based on you eating well or
going to the desert feel so they so some
of them don't mind it some of them we
throw you out of the room because you
are now challenging their muse and that
muse might go away if you ask every
question I play a little bit and if
somebody wants asked me why I do that
funny pinky thing that sounds pretty
good again this is a cognitive issue for
me to stop and have to go down and think
about that pinky thing that's you know
again a lot of this from from from
psychology and cognition work actually
our cognition how we think is that is
that a hurts that is slower than all the
things we can think about so our brain
is actually getting plenty of
information deciding things and only
some of that goes to our awareness so
the tree
the awareness is trying to keep track of
way too much stuff so if you kind of are
poking the awareness to kind of go down
and tell me about the pinky thing when
in fact it's somewhat automatic and what
the awareness is doing is I'm at
carnegie hall and this is going good and
i'm going to change it today if he has
to remind himself that I reminded him
that he does that pinky thing that no
one else does he could lose it right
then and there so that's an issue the
other thing they tend to talk in their
craft so you know with artists i bring
this up and they go well you know I use
sallow blue in the endless bristle brush
and I said well you're using the blue
lights and every one of your pictures
because the one before that is on the
other side so you're doing cool to warm
colors that's your rule but they go or
whatever you know and they won't so
sometimes you have to figure out how to
extract that out so so there is a paper
if you're interested if you've if that's
been an issue for you too there is a
there is a paper with the whale stuff
and with artists on more of a design
paper on that design process one way I'm
going to show it to you is with a work
that I have a lot in but i'm going to
try coming through it quick but at least
demonstrate is a facial systems so so if
i have a facial system and i have to
pour and I don't just want a facial
systems about the polygons or or the
pixels of faces but actually faces that
are emotional and alive and aware and
have moods that's what I'm interested in
with that we can get expressive user
interface and and better you know and
other things i find that the data isn't
there so one of the things i'm doing is
building these systems and giving them
to psychologists and four fundamental
work and from that fundamental work in
face communication and expression and
meaning i get good data back i get get
papers just for doing that alone and i
get good data back so i find i think you
guys are familiar with this here at
google it sometimes you really are doing
both you're getting some fundamental
data even though you're using it within
your systems and then went in that it's
it's it's good for a number of learning
systems and games and i'll show you some
of that again it uses this technique its
knowledge-based right i it's it's the
postscript of faces postscript
revolutionized the desktop printing by
saying it's not all just dots there
something specific something
semantically special but a line and text
why don't we actually object-oriented
leave right for that so that's what
we're doing for face I have a paper just
on facial multimedia object where I'm
trying to claim just like video is an
object why is it a face an object
computers are at a level now where we
can now talk semantically and move
semantics pneus around rather than just
trying to keep the semantics in our
heads and kind of right in in buffers
and data structures so then the face
area and the features actually dictate
so I would less would less resources
with polygons less CPU happens in the
forehead that happens in the mouth
because why would because that's
actually how it is in our systems as
well so again you get these low-level
right you build up these they're
encapsulated it's clean I've done a lot
of this especially during my boom your
time down here in in startups dealing
with agents and avatars and in it muse
we did a full 3d browser that had that
could put you know Google and anything
else on the walls and have characters
that work is out there if you're
interested I'm going to shy away from
that because it's less AI oriented and
I'm going to talk at least about putting
a I into the system a little bit so the
first place that i did and i'm somewhat
proud that I think it's one of the first
commercial applications in a game of at
least a kind of a newer AI system which
was for the sims so in the sims I was a
TA and left and I was at Stanford this
time and will write called me up and say
you want to do a face system for us for
free and I said no and we negotiated and
and it and if this was an academic
audience because they don't think it's
possible at least I have this down here
and EA is one is really hard hi EA out
there if this is on YouTube they're not
their game companies as well as other
companies are somewhat control oriented
so the idea that it might be open source
and that in fact I'd want to that I'd
continue doing research of it was an
issue but we did get monies out of them
i don't know that they'd i'm not saying
what that k-means so that's so you can
really kind of work within
again you do this stuff all the time in
other places this this is hard to do it
was actually quite hard actually we
finished the entire product will write
and I because he's really into by the
way the AI side and Willie was a
contributor we finished the entire
project before yay was able to write a
contract that was a non-exclusive which
means I could still use it and they can
still use it so it was about but that
that work is around from that and I
think nothing to do its poor but I think
it did affect folks with that you don't
have to build so in the old days of
gaming if I could say it that way before
this stuff you got lower craft an artist
mail or craft you had to be lower Croft
now with a number of user oriented
systems you can pick who you want to be
which is good for them they get user
creation it's good for you because it's
exactly who you want you don't know how
to be know how to build phases or laura
croft ness so the point is to get in an
art or an expression system talent from
the artist but then the user moves
through it so I know you guys are
somewhat familiar with this for speed
I'm going to leave out the system it's a
I could bring it up as a standard kind
of curl shims oriented genetic system
with it I'm able to move so then imagine
now a space of all the possible faces of
the level of the sims at the time that I
can move through it in different ways i
can start here and kind of wig my area
around it's a very different they're
actually searching rather than creating
faces it's quite good because they tend
to make their own face and they make the
thing they make the face they think they
look like as opposed to you know what
they actually really do look like and
I'm always saying being a face guy and
they're always saying well just make it
really like them I'm always saying in
the morning at night when he used to
look like what his fans think he looks
like you know this idea that that
reality is in fact not reality that it's
that there's even an optical capture
which which people consider reality
video and photography is just optical
it's octal archive it's how we look in a
mood in a light scheme you know and uh
so part of it is to try and move around
that what's great about this is
thousands of people were using this
when they did find that gangster they
would give it they wouldn't be giving
the picture of the gangster or the 3d
model of the gangster they would be
getting the the pointer into gangster
space which allowed other people to then
go find other ones you could take these
and you could breed them together so if
somebody made something interesting they
breed it with other ones so normally i
explained genetic programming for time i
think most of you know it i might talk
about it in more detail and something
else but just imagine now that so the
idea then a space is correlated it's
complete it's you know it's algorithmic
again it's a it's easy to customize and
make a goal oriented with that
multispace idea the low level stuff
always is there but you could build
these outer layers that you can play
with a little bit so the low level gives
you full range the high level is where
you can start putting more cognitive
constructs on so this isn't clear enema
try it one more time jazz saxophone I
want to do this trick how am I going to
do that with John's hacks front well
even though there's this guy who's mr.
jazz saxophone with I used to say tret
I'm old enough where i used to say
trumpet and bring up Miles Davis and he
was alive and but like so I've switched
the jazz textbook even though he does
the same thing all the time none of that
information is sitting in the facts
phone right it's all on his side now
it's sitting there because the saxophone
gets used to get swears in certain ways
and things wouldn't it be nice if some
of that again this idea of a system
could go into the sack so I always do
just do that thing and I can go on a
little bit more automatic all that
automatic is actually in the lower part
of your brain doing the finger that
their muscle memory and all these other
things but some of it could go on the
system so how would you build something
like that well the way I would do it is
I'd be incredibly scientific every sound
that could come out of a jazz saxophone
I would sample I would sample a little
bit out of the screech to this I would
understand it in some space so now I
could make a space of everything that
could ever come out if I did that space
randomly over time so that you might
call that music at least in every one of
those spaces is every song every created
from that jazz saxophone it's worthless
so now the next step is I got words so
now I go to the John saxophone guys hey
thats screech thing I knew only you do
it so
tell me about that because now I'm
trying to build up an expression right
it's really hard to get right which is
why I use this techniques get the low
level slowly build you know get credit
and then move it up so that again that
that really is important for the whole
rest of the talk because that at least
is the technique I'll use for everything
I do in a motion space and we talk about
face type but not facial emotion and
expression again this idea of a photo oh
you know that we have a paper and this
idea and I think if I could throw things
occasionally going to be saying things
that don't typically say knowing them in
front of a Google audience of very smart
people saying that I think this is
important this idea that you you decide
that there's a semantic object that
you're doing any way but and there's
some data structure and ability to do
it's time to start calling it that
semantic object and rethink everything
data structures and resources about how
that object makes sense I can't you know
I could just say in some funny way I
can't believe in the year 2008 with all
of us evolved in living and breathing
and marrying and breeding based on face
communication and how long this computer
has been around that we don't have a
tool that does everything about faces
and is actually married that way when
we're still kind of have one on desktop
metaphor and other things so I I think
there's probably other really
interesting spaces to think through that
and then think about standards so we
really somewhat tied to the mpeg-4
standard it doesn't give us enough and I
we have a so the idea then if we can
have this system that knows everything
about faces is a very different way than
they make faces at Pixar in and game
companies now and I'm down here because
I'm at the game developers conference
talking to two gaming people about this
kind of stuff we claim we can make any
face with any emotion and we can move it
from and they'll know this this kind of
cartoon but 3d guy talks out of the side
of his mouth and has a big mouth and a
big job because we're not just poinsett
interpolating or anything like that you
put any animation from anywhere on him
and he should conceivably do the right
thing so in this case we have this I
think this what i call this neutral
maybe so his neutral is still kind of
weird dopey
right so that doe penis is not in the
animation it's in the character right
and you can see that oh yeah so there's
a this newer I Tripoli paper talks a
little bit to standardizing some of this
stuff there's an MPEG 7 thing coming up
that does this a little bit better but
there's papers out there on this um
people have so people have moods and
personality so if if I'm a happy excited
guy that's my personality if I've given
too many talks this week my mood and i'm
tired and i'm at GDC and it's just too
many parties the mood is going to affect
that but this is transient right if in
fact i'm being a sales bot system the
knowledge is get to know the guy find
out his likes and dislikes gediman
conversation uses likes and dislikes to
figure out what kind of car he wants and
and what kind of persuasion you're going
to use it and it's kind of standard so
that would be the knowledge like you
know if we were saying it's a car
salesman but he might do it in this kind
of hippie kind of way you might just
show the personality is different and
the idea of separating these and
actually a lot of some of this research
was borrowed from Barbara Hayes Roth
here it up at Stanford who's done a lot
of this quickly I should show you things
moving so if this stuff works forget
about the faces this whole idea of
parameterizing so so again if we had a
picture of a face that's nice it's just
pixels and pixel don't know I mean they
know their pixels then they know if a
blur of routine comes down and then you
can do some other statistical things but
they're not they're not faces if we go
to the next level would say up in
parameterisation we go at least vector
so now or at least vector we can do some
pulling and pushing now if we had smart
vector we have even more so imagine
moving up that scale so if it really is
smart I should be able to know about
facing this so one test is I should be
able to poke it and instead of poking it
and it blurs if it was pictures or
whatever you want to do it should act
like a face one way to poke it is with
data so I'll send data through it and
the data all centered for speed here is
is voice day
since that actually matches so real time
on an older laptop it's going to be a
delay things are breaking we have a
newer system that's a bit faster and
better looking but here we go la so
that's me talking through the face and
you know when 10 milliseconds I'm doing
a lip sync but I'm also doing some level
of gesture and I'm talking way too loud
because it really is looking at energy
and it's overly excited cuz I'm giving a
thought so if I talk lower and
occasionally just push something well
just did that eyebrow things so it
actually finds some some qualities of
voice and this is one way of talking I
said any behavior so let's switch this
behavior and it's go to alien still my
voice still this face so am i there yes
I'm not looking at you anymore I've come
to take over your planet and I'm just
acting a bit different than i did there
you go there was just funny weird not
really paying attention kind of neck
things if I went nervous it's not a
great nervous say grad student art
programming nervous it's very easy to
kind of do something inside us and
you're going okay do we have any
psychological validation that this but
anyway but one thing you do it nervous
is you're going to be nervous yeah is
you don't do much back and forth you
hold your neck muscles tight so it's a
little bit more up and down in your
blank so this is at least the idea for
it so like I said it's then it doesn't
matter the character type i can do it
for any character type and in fact I
don't even have to be keep it human if I
don't want to so I'll go to cartoon oops
I went to I went to I went to cartoon
that had that mixed half of
african-american woman and that's why it
looked weird because it didn't
completely clear the buffer so there's
cartoon so here i am i'm at stanford i
pick any face i want i'm a grad student
i hit on the buttons to call mom because
this could be it's just a just a tea
floats goes over though matter how much
we make it complicated in the end of the
day it's just the low-level things and I
say Emma I'm cartoony today so there's
squash and stretch in there it doesn't
matter but it's being affected by the
voice and you know it's expensive huge
Stanford and I could I could really use
your money so so I don't know how to say
this but send me money now and and if
you don't I'm going to turn into Buzz
Lightyear and I'm going to fly over
there a Pixar way down the block and but
please send me money all fade away so
i'm actually just hitting keystrokes
that map the things but just to be clear
this is just data so those keystrokes
could be programmed control that could
be commander so-and-so saying get out
now open the door they're coming and you
don't so then you can get louder still
and we could even know if that
particular guy who picked is more stoic
rather than screaming he would go wow
and you would know oh crap he really
means it so so people have different
personalities we could map that all
under program control the hope is we
could make games yep I've learned
learned that no one ever listens to a
thing I say if that thing is still
talking especially nervous going like
that so the hope is we can make
dramatically subtle emotional faces like
in movies and really change what the
game industry is it's not a question
gotta say it loud
Avenged
it's it's hard to put on visual
communication problems but it seems like
this would be
to be more useful
informations right so so so so I would
say this is middle did you hand the
question sorry what could you repeat the
question yes I think I kind so this is
interesting but it would be better if
more of the semantics of what someone's
trying to communicate is also compressed
not just the face side of it was that
would huh that's that's it so that you
record the facial expression because
that's real that's the person is and I'm
here to tell you that all the power to
you it's just not the way I I could
argue with you forever over this that
that is not the person the person is the
soul you know you have you have a you
got somebody's real belief in his real
soul and then somebody else and a small
wire and you're trying to get the soul
of that over that wire and I don't think
and I think it's been proven with with
early video telecommunication systems
that unless you know that person which
therefore you kind of know their soul
you're not reading a lot into that
because you have this especially
sometimes off a computer because they're
bare they're not very moving very much
right so you're not getting as much data
so i would agree with you if you can
compress their soul which is a bit of a
which is something this conversation
about cognitively what is that if it is
in fact their soul today under
particular lights using a camera with
the baby crying in the background of a
webcam that's why i would disagree with
you that that's more they're so so in
the case of scientists which we're
starting to do with the aquarium i'll
show you in a second that i will show
you now so here's this bottom one so if
you go to a monterey aquarium their
stuff I mean museums art museums in
aquarium and zoos there's things those
are monnalisa or well or carved mask and
there's a sign next to it and people are
not always reading this on because
they're this is research we're doing
it's an informal learning space
how could you make those signs come
along how can we can make that more
emotionally involved one way is you go
to the aquarium there's a cool Ridley
turtle and you could say gee whiz I wish
I can know more about that turtle I wish
the the the best expert in the world on
that turtle was in fact here in front of
me now so your thing is well he's
somewhere let's get a camera on him and
see what it does I would claim he
somewhere as a scientist and in fact the
reason there's you know there were
certain kinds of people like Dawkins and
and and Carl horse calls last name there
are scientists who can talk about
science and ones that prefer to do
science and they surely don't like to
comb their hair they don't like to
actually have cameras on them so I claim
that's not who they are in fact the data
coming off their face is probably not
the best way to do it those scientists
and this is the work we're doing those
scientists though do field recordings
all the time so that's voice so I'm
trying not to bother them get a little
bit of their soul because it does come
out in their voice and in fact they
don't even use recordings anymore they
use laptops and they record right there
so we're doing something with the
Vancouver Aquarium where we're taking
that and every two weeks they talk it
goes to the aquarium they you know
museums have very little production
staff they can't even afford video you
know good-looking video systems they
take that they listen to it they type it
in they clean it up they put it with ten
other voice things and then within an
hour it's out on the show floor so they
can say hey I heard it's raining up
there and Silicon Valley if it's if it's
a local place here it rains all the time
down here so really current stuff the
soul of what he's really trying to say I
would least argue with that might be a
better way to do it and it's more
private and secure that it's not his job
to to he might want to be anonymous when
he walks through the aquarium we could
put them on as it says here a
constructed persona it's kind of a
scientist and it's kind of the
educational staff and there's some
ethics of where that deals with so I
completely agree with what you're saying
some ways but my pushback is at least my
talk push back which is it's about
perception and there's ways to play with
perception to make a better hit there's
also ways to play with that emphasizing
some things and de-emphasizing things
like what they really look like and that
they're sweaty in the Amazon right that
might be important might not be that
that's worthwhile doing so in the case
that's exactly what we're doing with
this kind of work with this one we could
have a native ours to actually talk
about their masks turn into their masks
most state of Carver's are actually
performers too so they can perform right
into it so these are these are ways to
deal with this side of so why is all
this at least this side of it and I'm
going to go on to some things that I
think are more relevant to the audience
is at least trying to talk about social
communication versus info so very clear
if you're at an aquarium or zoo it is
really hard to read any sign you got
this yep the coolest you know tiger or
looking at you and you're supposed to
read this sign it's not going to give
your kid pulling on you you barely can
look up the sign that says what time the
beluga show is next so to think you
could do other things strictly so can we
keep you in a social space because
that's what you're in and instead bring
a scientist and says hey I see you
looking at the turtle I'm actually down
here in the Amazon so this is a this is
a way to do it it's more of a programmed
way I claim that the video way is one
way but it's it's sharp into a
cinematography kind of way where this
this at least way is changeable and
programmable so I do want to keep moving
on in the AI side of this so once now so
I got a face system that that is
programmed and understands emotion and I
showed it to you very quick if you're
more interested plenty of other demos a
lot of work and in elevators we're
working with autism right now with
autism folks trying to understand using
a phase system there sorry my computer's
just we get out here intersect
I want to show you how once data is in a
parameterised way you can remap it to
other data so this is specifically I
would call it an aesthetic stream like
music isn't it it's a stream because it
moves through you're here at one
particular time and it's aesthetic
because it means things to you animation
is similar I can now write a system that
I can extract in this case I'm trying to
extract emotion out of music tons of
papers on emotion in a music lands and i
was talking that cope here in UC essay
is is really strong on it how can we
quantify some of that information so we
can pull it out everyone has seen a
painting that seems kind of moody but
heroic and there's a person you can
imagine is moody heroic can you extract
moody and heroic pneus out and for some
period of time is it sitting in some
heisenberg box where you could you know
actually have moody and emotion
separated for a second and then move it
to anything you want so I'm using music
the emotion is the stream and it's going
to emotional face but it could be
anything I'll show you what that looks
like again sometimes when I'm making a
system and it's fun but not sure how
accurate I call that art and and it goes
to an art show and this was at siggraph
in LA and this was in a big gallery in
New York or at least one version of them
but I learned things from it and that
goes back to my other system because to
produce it for art you have to make
somewhat of a rigorous system to let me
show you that so this is a fuzzy logic
rule-based system that extracts emotion
based on going to again rules fuzzy
rules because it's not very clear and
they conflict and again we've proven
with with Craig Reynolds and claw
converting that simple rules that
conflict with each other make nice
complex data but sometimes controllable
so this is the string quartet so that's
more different stringed instruments all
of them are creating the space nobody
hand animated this place and I'm going
to stop it and tell you just quickly
because it's going to come in music
especially western music it's all about
getting home home is is getting back to
the root the more you go dissident you
go off the the third and the fifth it's
distant but then you go home and it's
nice so that's a kind of a standard
thing if you decide on your way home to
go home high rather than low that can
come out as you might call it angelic
which is da da da duh so we ended higher
rather than low so we wrote the system
that you could map that that's been
mapped to face angelic we could do
research and what that really means in
the case we can give it to an artist and
say it's a tool you decide in that case
angelic is feel this pull your head back
close your eyes feel the Sun and I think
he did it slightly differently so that
will just show up I don't know where
it's going to show up you play different
music it'll show up in a different place
it's pretty complex stuff it's tracked
for different tracks so
right here so that's why the eyes closed
new piece that is closing the eyes it's
in a major key it's staying smiling it's
going to go out of that it's going to go
a little bit more off-key so the mouth
opens in a different kind of case so
there's a lot more on this to this is
where ever one of a number of them it
brings up this issue I would call it in
in worlds that you might be at more than
I min it's a form of knowledge mashup
right rather than kind of straight you
know either pixel mashup or data mashup
its Brigid semantically up and then mash
it up at some semantic metal if you can
agree on this remap like here's the
matchup right here right papers on that
it's useful for gaming by the way it's
it's a the current application is in
Vancouver there's a really great theater
very modern prevent Cooper's an average
sized city somewhat like San Jose is
let's say so there's a million of these
really cool innovative theaters that
wish they could be more than they
currently are but they can't compete
with London and New York with
animatronics and fireworks so you know
they rent out a lot of the songs and the
costumes the talk is now let's get them
digital projectors and we'll have maybe
some movable scrim they called the
movable fabric or something to project
on and then the entire set is now
programmed in fact you could read that
too right so that's the idea so this
brings in this idea of rear as it says
they're reactive NPR or reactive set
design that just like an actor or a
dancer might change things slightly
every night based on the music this is
possible with the system like this too
I'm going to move on to neural networks
in action selection and where that fits
so these are beluga whales we have a lot
of work on this is an advanced layer
that's the action selection system
whales and dolphins are quite tricky
they actually are hard and one of those
of their hardest because they have no
idle state there
they are in a constant state of of
correction which makes them really fast
but really hard to make so we actually
in our physically-based animation system
that was a drag d system which is really
good for planes and flocking anything
that seems to stuff comes out the back
and it moves into banks that's good we
go to the aquarium you look at these
huge whales this Wells hanging up upside
down just hanging out and kind of going
all the it's never going to work we
moved over to a lift based system it's
much harder to control looks a little
bit better so this is the way the action
selection system is there's other
belugas there's dynamic objects that the
audience number one thing at the
aquarium with whales is to swim with the
whales that's what it says on the
servers can't really have them do it
what if the whales can tell their story
you see something that well does you go
to the other side of the room and you
could actually try it out you can do
what if so quickly to decide do I got it
collide with it well give it because I
gotta hurry and do that because I really
do think like that they're constantly
that you got to get right to the like we
have a very quick neural net to how I
move and I can show you that in a second
but it's also no i don't but it is my
brother or my calf or the exxon valdez
bearing down on me so it's important
that an object it decides based on to is
it is an aggressive mel but I'm you know
really I really need to take a breath
and then it goes into an action
selection state so the neural net is the
fast one it might not be too easy to see
there's these rays coming out these
razors literally go right into the net
because it's just got to be fast so this
this advanced layer sends in this is the
way I'm moving a sense or a very quick
logic to say how could I avoid things
and of course they don't just see things
in a void they actually turn around and
do some really nice thing and it's
affected by speed so it actually
stretches out but gets less resolution
as they're going faster which is
something we learned really happens nice
thing is once it looks good we can start
doing the magic we can turn it off and
show you how the heartbeats are their
sonar works so
this is done in conjunction with Bill
Kraus whose evolutionary biologist
turned programmer turned NASA genetic
programmer at NASA he lives up in Tahoe
and he's done most of the genius with
this and more the animation design guide
okay we got it on to screen so this is
going to go into the Vancouver Aquarium
soon it's going to be huge scale matters
the bigger you show this the cooler it
looks so when people think that scale
with the skin just because scale is
quote free in computer systems doesn't
mean it doesn't fat so this is not a
movie this is the three wells they live
in a world of sound first story is it's
just done that you said that that
interesting left vision and sound are
continual with a whale almost is there's
very little differences they see things
if they put on echolocation that means
they get more detail in their site we
don't actually think it's separate so in
fact if you're if you a school of
zebrafish and you do your thing to be
confusing they wham on their
echolocation they see the mass is inside
you so all of a sudden they can make out
your slightly bigger or slow one Pretty
Reckless by the way the second they
paired on echolocation everyone else
sees that same thing because in fact so
it's kind of weird because we don't
think like that vision private
echolocation vision everyone sees it and
you're basically saying hey it's a big
juicy one here so you don't turn it on
to it matters by the way they dropped
they drop up these
steel balls that have different very
very different hollow and they give them
treats based on it they immediately can
tell the difference between steel balls
all the time so when people you know you
see these new shows I just saw one is is
do animals have a sixth sense to know
about when earthquakes happen you know
more at 11 it's like no they have the
same sensors turned on differently it's
not magic it's not weirdness it's you
know there's no difference between you
know the same thing sound is the same
thing as feeling also with these animals
as well too so so I'll show you a little
bit what's going on here that we can
move this I can click on this ball and
moving told me the females which are
here will come near me the calf will try
and keep up but can't it will do it it's
scream which actually came from real
wells at the aquarium all this is based
on real data we have an aggressive male
here it's probably this guy yeah I could
almost tell by the way he turns qoq was
laughter like he's gonna go right now
and bump gear just shot gig ever calf is
spinning around which would be too much
would normally do that so we're building
this up more and more eventually this is
going to be in the aquarium the real
ones going to be in one side I'm going
to make a table on the table you could
put this stuff down how does this really
work tell me about these words and
sentences thing again I will click on
the mail and turn off its automatic I
just there he is you just stopped dead
in front of us because he's under mind
control now haha he becomes invisible so
they start going right through the side
one is if you do this to the feet though
female did the cast is following the
calf just spins around because the
calf's sensor knows it's there but just
doesn't see it so anyway so I'm going to
stop it till just stopped and I'm going
to go forward and then going to go
reverse and maybe pitch right left I can
affect the head controller so when I do
talk about a space because normally you
don't think of action selection in his
face this is the low-level space this is
how belugas get from A to B and do some
thinking on that we're building up
regionally they all do the same
then eventually we made sure one was
more aggressive and that was a male and
the one followed and had an issue and
that was that was mom so I'm going to
finish off with talking a little bit
about creativity moving up okay so i
want to mention one quick thing before
going creativity is two kinds of
visualization you can scream at me I'm
just trying to make it easy one is
scientists know about it and they want
to teach regular people we call that
like the weather there really is no L&amp;amp;H
but it's a good way to explain it to
folks there's another kind of scientific
visualization is we don't know about it
and we're trying to visualize it so we
can get that that would be I'll
exploration you want to keep the oil
exploration real data so something
shoots out it didn't become firm like
very you know it didn't you know it's
right you want to keep this stuff
goodwood wells don't get that close
together they don't do certain things
but you want to teach lessons we're
climbing that this system is right in
between that we can do both if there are
things that scientists can do and I
think one I got a chance to be at Google
one thing that I'd at least a little bit
push is this could be so so the that
baby whale that cried that crying came
up from a one-year-old she died at the
age of three last year no one knows why
big protests should you really have
mammals in captivity huge ethical issues
could we possibly put sensors some in
the wired while of a beluga or frag the
tiger and actually make one of these
systems so this would be your issuers is
video enough I would claim no no we want
to censor these other things but that's
a space to so I was actually suggesting
that the video was not the important
thing that you use this as a recording
device to get at the essence of what's
going on ok transmitters ok good thanks
you both helped me to make that other
weird point and this one which is even
the better one which is I do think so
they have now things called CableLabs
you know they used to go out into the
deep ocean and film everything now they
go into the deep ocean put in this thing
and go back home
here and just watch all the stuff so I
believe they haven't started but I
believe they will start doing it with
data so again I think there's other
applications that might happen in
buildings like this where you could take
data from other places put it into an
intelligent system take a little bit
about it's learning an entertainment
value again the belugas don't that get
that close but if you would need it to
see it and use it that way so on that
taking data and maybe playing with it a
little bit is this last point which is
on creativity so back to genetic
programs so GP is you have a function
set you ran again very quick you
randomly put that in individuals you
test blindly those individuals in
another room the ones that do well move
on and those strategies go and that's in
a space it's a way to search through a
space well that's good for optimization
but I was interested in exploration
getting a computer to be creative so
what we did is again just went to the
the new cognitive psych data what's
going on in in a in human creativity
everyone knows creative people have a
very associative they're putting wonder
fr MRI scanners now and it turns out
again if I was to make a mic I'd say Oh
Mike that sound waves sound waves is
like the alavÃ©s in the ocean I'm going
to make something that looks like a wave
that's an associative way not everyone
does that everyone knows that the other
thing that creative people do though is
they go doggedly focused and they say
I'm not washing my hair I'm not doing
anything I'm just solving this and then
they go wide again and if you could ever
figure out how they do that you can do a
number of things so this is one attempt
at that based on the research so we
decided to only do portraits face and a
little bit of the art side is that it's
Darwin himself using dart so we're using
this very famous picture of Darwin we're
using Darwinian techniques to get the
ghost out of the machine or ghost being
creativity blah blah blah by the way
this image just got in the journal
Nature in a in an article on Darwin so
at least that that that cycle made some
kind of sense so in this case
a one thing about art is quite wide and
hard to do okay okay i'm gonna i'm going
to end in one minute sound good 50
seconds Oh 30 seconds now so I'll just
leave you with the this tries to go wide
in an art space and go thin and kind of
deal with that fluidity there we have a
new paper on this and that's just coming
out in genetic programming and evolved
machines and if you're interested you
should look at that I think well we did
it in this kind of fun art space that
it's quite useful in a number of spaces
we're doing it in a more detailed way
for art and now I have a cognitive art
system that can take a regular picture
and start doing paintings not just like
a painting of a particular style of any
style because I'm I'm trying to model
cognitive space of painters so these are
some of the results i'm getting there's
a paper on that if you want to look in
it what that shows in which the entire
talk shows is that artists know how to
take data and de-emphasize what isn't
important and emphasize what is and
while reality likes not to do that I
think that's a good approach in all
these systems and I find making spaces
and using AI systems allows me to do
that thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>