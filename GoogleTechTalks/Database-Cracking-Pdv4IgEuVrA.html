<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Database Cracking | Coder Coacher - Coaching Coders</title><meta content="Database Cracking - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Database Cracking</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Pdv4IgEuVrA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we already here my name is Eunice Carson
I work here at Google and I used to do
my PhD a number of years ago in
Amsterdam his my professor martin
kirsten who has been doing databases for
quite a while and done a lot of
interesting things and the
specialization is in main memory
database system and data mining and
highly efficient processing of slicing
and dicing and today we have two
speakers one at one o'clock and one at
two o'clock and first we're going to see
Stratus videos who is currently a PhD
students at Amsterdam and he's working
on self-organization of database systems
in terms of data structures and how to
autonomously make the database handle
partitioning and indexing without any
user needs to specify how to do this
thing previously he was studying the
systems group in crete doing p2p
databases and today he's going to talk
about database cracking and hope you
will enjoy it thank you okay thanks so
hi I'm Stratos yep this is a joint work
with Martin who's over here and Stefano
monocled my advisors in Amsterdam so
this is the base cracking and you will
hear about self-organization in database
systems the problem we are looking into
is dynamic environments so environments
where query and data upload is
continuously changing you continuously
get new data different different data
and your queries different queries so
they will have some hard questions to
answer some hard decisions to take like
what kind of fetuses do we use if you
want to improve the diaxes when do
create an index when do we do open index
if it's not useful anymore and at which
part of the data do we are creating this
is because if the query workload is
continuously changing different parts of
the data we are becoming interesting at
different times so typically we have
data buys experts that monitor the
system or some or
more recently some special tools that
try to recognize behaviour patterns in
the workload and give advice make
predictions make assumptions you can
imagine that this this is a hard problem
in in data basically huge data sets
because there for example the cost to
create an index is even higher or the
cost of answering a query without the
proper index is again higher so what
we're trying to do is give a
self-organized flavor to the database
week on the database to be able to adapt
itself to query and data workload the
basic idea that we're using is called
database cracking and it's it's like
this it's query trick is physically
organization for database so that the
next quiz can be assured faster and we
have we have done so far is that we
design and implement the system that
proves this case by using the debates
cracking and be able to show a clear
self-organized behavior we work on top
of magnetic bead monitor beat the system
that we developed CWI database system
and one of its characteristics is that
it's a columnar Eddie database which
means that attributes in the code in the
database arc are represented as columns
so we'll see examples so with this
simple example I will try to give you
the basic concepts of the debates
cracking so assume another Beauty new
database represent the sakhalin and the
symbol range query so let's see how the
cracking DBMS will answer this query it
will write the partition of the column
such as the result is in a contiguous
space so first we have all the tuples
with values lower than that of the
result so you see values 342 that are
outside the result for this query then
we get the actual values that are in the
result and finally happens with values
that are higher than that of the result
so what we have now is three partitions
in the middle have a result
observe the following without within
each piece there is no specific order so
for example in the first part is no you
see we have values 342 there's no other
but the pieces themselves are ordered so
for example every tab in the first piece
has a value lower which is lower than
every double of the second piece or the
third piece and so on and this is the
property that we can heavily explore to
improve the taxes for the future ask you
Mack we for example that requests values
lower or equal to 5 then we can just go
and search in the in the first place in
the blue piece so you can imagine that
this is a pretty useful thing when it
comes especially when it comes to shoot
databases this this self-organization
this reorganization step continues with
every query so let's see what happens
with the next way you can see that this
will request everything between 20 and
50 if you observe now the column on the
left you will see that this query needs
to touch miss to analyze the first and
the third piece the middle pace is for
sure within the result we know that so
what the cracking DBMS will do is that
will first it will further partition the
first space into two new pieces so get a
new blue piece and then you read a
Greenpeace and observe that the
Greenpeace is now within the result the
blue is outside we get the orange piece
we don't have to analyze think about
that and similarly the last piece is
further partitions it into two new
pieces so what you have now is again the
result is in a contiguous space but this
time it's a collection of pieces and
what is the main observation from from
this second step that we did is that the
more we crack the more we learn the more
we physically reorganize the column
based on what the users want the battle
cancer future queries
and this is exactly what gives us this
self-organized flavor in the system now
you may wonder how this is how this
compares to some different strategies
like sorting or indices so since we are
giving this ordering the column why not
immediately short the column and then
use binary cells which is pretty fast
and the answer is that yeah you can do
that if you have the time if you have
the resources and if you know with the
other goods you gonna short if you have
this luxury go ahead a new sort or go
ahead and use other indices if if you
know how how you want to prepare the
data so this list strategies for
completely dynamic environments with
completing no knowledge about what is
going to happen we have to cracking
algorithms to algorithms that physically
reorganize columns and that's all we
need so as you saw in the previous
example if you if you remember we had
one algorithm that splits a piece into
two new pieces and one algorithm let's
place a piece into three new pieces and
that's all we need we implemented
various different strategies for for
these things but at the end we ended up
with some symbol with the most I think
the most simple algorithms which were
very easily to implement very
efficiently and the main idea is that we
read the piece with tuples using
pointers from the directions and we try
to exchange tuples to get to get them in
the proper position and the whole the
whole effort is in exciting as less
diverse as possible into it the Nestle
stops as possible ideally once per
tablet
now in this slide you can see the basic
design that you have on top of milady be
such likely is the first time that the
query needs to touch a column which
attach an attribute the system will make
a copy of this column this copy call it
the cracker column of the given other
good and then it's time acquitting it's
to tads the specific attribute we
physically reorganize the column such as
the result isn't got the key space as we
saw in the examples before for its calm
Fritz cracker column there is a cracker
index which is enabled during the curing
implementation and helps us navigate
very fast through the wash pieces of the
cracker call now increase when we wanted
to create the first quick glance for
cracking the Select operator was the
Select operator is the one that first
touches tablets so this is what this was
the operator where we went plugged in
physical or organization for example the
symbol Select operator the knife Select
operator simply scan cycle and and tries
to find the correct values for a query
the new Select operator that were
created for for cracking it we'll first
search the ocular index re-organizing
pieces that it finds update the index
and then return the codec you serve as a
result and now let's see how this
behaves so here's an experiment where we
have a column of 10 million doubles and
we fire a hundred thousand range queries
in the x-axis you can see the series of
quiz in the y-axis you can see the
cumulative cost after it's really has
been executed and it's logarithmic so
the right the red curve is sewing this
cancer leg and this of course it's
scheduled in early then the green curve
shows the sorting strategy which is sort
the column up front and then the binary
search so you see that we have
a high initial cost but then the cat was
almost flat so quick and guys are pretty
fast and if I remember correctly it goes
in the order of a few microseconds then
we have the blue curve which is cracking
and now you can see that we don't have
such a high initial cost we don't have
to invest and also observe it the more
quiz we answer the more flat the curve
becomes so we ask investor faster and
faster a little time and the reason you
can see in the in the right graph where
you see the amount of tuples that the
cracking quiz have the touch it's time
and you see that this thing is it's
coming down all the time and that's what
that's because cracking learns and
continuously restricts data access now
here you can see how cracking scales
couple the shorting so it's it's the
same experiments before and here you can
see for 20 20 million double and 440
million double what's the difference and
you can see that cracking is becoming
it's better compared to sorting and
that's explained because of the
complexity sorting is in end Logan
operation cracking simply depends on on
the amount of tablets that we touch
every time this experiment is in memory
experiments tablets containing the
integers but we expect that out of
memory experiments should be should be
bettered for cracking again because we
can simply use a recursive eric FC
behavior to to to come lot of memory
experiments and here you can see an
experiment where we use the previous
experiments were just weird simply
comparing operators here you can see an
experiment where we're using the
complete software stack and we're asking
a full query so tpc it is a standard the
database benchmark
the query six is equivalent selects from
a table using ranges from three
different attributes and then it
projects some other attributes and we
compares cracking with some standard
well-known database systems like
postgresql mysql also using indices and
on the spondee on the attributes that
are used in this query also you can see
the green green line which is milady be
a standard male dB and you can see the
gray line which is cracking that it is
way below and the observation is that if
you see what happens to the first quiz a
little bit slower than the green line
but then it quickly cuts down it learns
and quickly cuts down and performance is
almost one order of magnitude faster the
last line that it's even more faster
it's another system will beating at CWI
multi big hundred and son we'll talk
about that in the next talk but this one
is using prepared data so we have done
some preparation on the data which is
not visible as a cost so this is sort of
the ideal because that you can get if
you know what you expect on your quiz
and now i'm going to give you a little
bit a flavor of how you can use updates
in this in this architecture so that i
will show you that it's not something
that it only proves quit bossing but it
also proves crossing during updates so
we have two structures the black yer
colum's aggregating Dixon that's what
the craft update and go to that in a
self-organized way so again without
external ming station without any other
words experts helping us without any
knowledge about the workload the query
workload in the data workload so we have
two issues when to do that and how to do
that answering the one question
we will do that during query processing
so like we like we plugged in fiscal
organization in query processing we plug
in updates in query processing so when
an update arrives it is not executed
it's it's staying aside in in separate
columns for each other yet and it will
be married it will be merged in the
cracker columns only when acquitting is
that so happy we made a new version of
the Select operator that before
performing the physical organization
step and the selection it first updates
the Graduate column if needed with the
requested values now this shows you what
is the goal so in the in the left part
you can see a typical example of how
cracka column could be and assume we
want to insert a new tab with a value 9
and you considered we in the world in
the right part we went and wind we
plugged in value 9 in the first in the
first partition which meant that we also
have to change to shift down the other
two partitions so how can we do that
efficiently we have a technique that's
called hopping and it's a pretty simple
thing and works as follows we take from
the last partition one value and we put
it at one dublin who put at the end of
the call so we made space in the column
for the neva following a tableau we
update our index of course and we do the
same until we got we we are in the part
with the partition where we actually
going to put the immutable so another
space for value 94 w with value nine and
we just put it there so we didn't shift
that was all the way down to the column
and everything we just rearranged a few
a few tablets in the call
which is a pretty more a pretty cheap
operation compared to just shifting
everything down now have a bunch of
different strategies one idea is that
when a query needs some of the pending
updates we just go and melt everything
another idea is that we just merge the
values the tablet with value to qualify
for the Cuban query then there is the
ripping that is trying to do exactly
what is needed for the Cuban Quay and
nothing more you will see a similar
example the next slide another idea is
that since this or this is our auxiliary
data structures we can just throw away
the curriculum index update the cracker
calm and then start the whole project
from scratch well just partially delete
the index so here you can see the ripple
so we on the right you see depending
accompanying assertions and on the left
an instance of a cracker column and the
query that selects the host select
everything between seven and and 14 from
the pending sessions you see that double
with value 9 qualifies for this query so
we need to insert in the crack home the
value 9 we make room just just a bit
after the first partition where
Valentine should be inserted so we take
that the tableau evaluating out we put
nine there eating is going back to Japan
insertion and the credit column is
updated and the crackle indexes are
plated and here you can see that this is
even faster compared to the previous
album that I show you now this I hope
will give you an impression of how the
different statuses behave
in the baseline so starting from the top
left corner you can see the scan select
that's an experiment will have a 10
million tableau a 10 million column
sorry and ten thousand run completely
random queries that select ten thousand
doubles every time and every thousand
queries we have a thousand insertions so
the red line is is this can select
continuously scan the column to get an
answer the Green Line does the code the
graph below is representing the cost of
having an AVL tree on top of a column so
you can see that this is a pretty
chipper with just a small pics a few
small pics when inserting new values
then the blue line is representing the
this delete strategy that I told you
before where you continuously when you
have a new give values you delete the
crack your index and you start building
again so you see behavior where we have
some pics and then we quickly learn
again and clear not gonna learn nugget
and on the right side you can see the
merge strategy strategy that they try to
merge into the cracker column the new
values so first on the top right corner
you see the the strategy that completely
that when even single value is needed
from the pending updates it just merges
everything into the cracker column so
you see that a response time is
continuously very low at first is a
little bigger but then it learns and
then it's very low and you just have
some pics when we actually have the
insertions so if you if you see then the
next figure what we improved which
represents the gradual case so melts
only what is needed every time what we
improved is that we don't have this high
picks so we improved the average
response time
but as you can imagine by licking both
graphs they at the end the cumulative
cost for the gradual case is a bit
higher and there we have the four that
we have the repo strategy which is at
the end where the difference is that we
always starts what is needed and if you
remember we had to for example to insert
one value we just do one operation one
shifting and that's why you get this
very high performance with without pics
without nothing so that's that's the
basic that's a basic performance I get
from these algorithms so database
cracking may sound like at first like a
crazy idea because nobody would think
that it is very reasonable to physically
organize the data base while answering
queries but this this system so that it
has some some potential it clearly saw
some second self-organized behavior you
can receive their taxes and there is a
bunch of research opportunities for
cracking for example this of course a
lot of optimization questions cracking
can be explored in more operators like
join Chris aggregate queries and
databases you can have cracking
histograms you can use the stability
cracking so you can imagine that if you
have partitions the database that are
needed for different crews we can just
throw the different partitions in two
different CPUs different nodes and so on
and we had the paper which represented
in two days ago three days ago insider
2007 asilomar so you can go ahead and
download it and read this paper if you
like so that's it thanks
thank you hmm so be open the floor to
questions then I'll have any questions
No
you can use this one so now we open the
floor to questions so it's very
questions here feel free to Oscar and
speaker will be available afterwards
salsa you
yeah so sana was asking if at some point
in the repo strategy episode if there is
a point we can just mess everything
directly into the glidecam that's what
you're asking well the answer a thing is
that if you detect the trees a tilt I'm
not queries no updates then of course
you can do that yeah
for the schedule local scale
losing
we hope so i have a question about when
you
after while when you start cracking a
lot and he had a lot of queries suddenly
each value will be its own element is
own partition right so how efficient is
that in storage wise and very altri you
need to access all this part yeah yes so
you can see the first bullet here which
says that this is future work so the
intuition is that we won't let that
happen I won't let having such small
pieces ideally a piece could be a cache
line size the size of a gas line so you
can efficiently read the right space and
of course there are trade-offs there
nothing needs to be studied please
you know
like the question is how well does it
scale I don't know if you were here i
saw this graph that shows how well it
scales within the memory so you can see
a 10-20 in the 40 million column and it
is compared with sorting so you selected
scale is pretty well compared to sorting
so you see that then the 10 million
calves they meet after 100,000 queries
but then have a distance to have a gap
but outside of memory yes okay okay I do
not see a wider table with columns
multiple columns is not is not an issue
because this is a per column operation
so multiple columns operation is not an
issue but we think it's column if you
have concurrency you have multiple
clients then the idea is that you will
look the Select operator that performs
the physical reorganization and you will
lock it in terms of the cracker index so
if you are accessing the same area the
same piece then you will lock this piece
but it should exist in different parts
of the column you can reorganize it all
right any more questions the speaker
will be available in this area and two
clock we are meeting sander Herman and
he's going to talk about running
database system on modern hardware so
it's taking into account cache lines and
how to optimize for cpu usage because
nowadays we know that we main memory is
actually a bottleneck compared to the
cpu ability to process data and it's
going to talk about compression for
superscalar cpus all right thank you
very much thanks
you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>