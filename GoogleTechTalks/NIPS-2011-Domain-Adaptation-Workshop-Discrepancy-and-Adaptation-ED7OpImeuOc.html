<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Domain Adaptation Workshop: Discrepancy and Adaptation | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Domain Adaptation Workshop: Discrepancy and Adaptation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Domain Adaptation Workshop: Discrepancy and Adaptation</b></h2><h5 class="post__date">2012-02-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ED7OpImeuOc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the title says discrepancy on adaptation
and get is more and I can tutorial on
this topic so much of learning the
following assumptions which I think are
meant for an ideal world this is a world
where the distribution for training and
tests and where all of these are first
are natural assumptions without some of
those in fact you could say is it even
possible to learn if you come to some
other workshops here you would imagine
you not able to make those assumptions
but the real world is really quite
different this is the ideal world of
learning Huy and much of past learning
theory and algorithms and the entire
space otherwise is the real world so in
fact in practice when you're trying to
type all the new
you never hear almost so what is the
domain so this is a part of you dealing
with a real-world problem the source
domain that you are that is available to
you is quite different from the
testimony and really the main reason for
that is in fact the dollar sign the
reason is you want to learn for a
scenario learning out of a brand new
debate but you just don't have the
resources to have label data for that
human so you're doing the best that you
can do with whatever you have the label
data for it for a source domain another
one is drifting distributions change
over time so the classic example for
that is spam where spammers actually
change their distribution to change the
way they are producing spam but in fact
you see this in a variety of other
problems as well
by the time you're finished preparing
your learning algorithm you have a good
result set up its go problem things I've
changed already if you're working for
you know companies were data keeps
coming data keeps coming and by the time
you've finished something there's
something else things have changed so
how do you manage to adapt over time
this is another dimension of adaptation
and then there's another one which is
that of sapling
so I mentioned Heidi sampling but this
sampling of what whatever sampling is
different from the ideal sampling you
have adaptation photos there are other
axes that are not mentioning here which
are for example but it meant you may
have several sources sources all three
of these access using so let me start by
mentioning what the domain adaptation
problem is I think I've seen this
already it's the case where the source
domain is different from the target and
you see is in a variety of other
problems domain movies books music but
you have maybe no label of course they
travel so you want to make use of label
data here to make predictions where a
new domain that will be travel and then
classically in fact in the national
language processing adaptation has been
a problem for a while because this is a
natural language processing is a place
working back internationally a lot of
work like quite often learning ideas are
coming from there so in language
modeling Paris which Devine statistical
parsing speech retention computer vision
which is in all of these areas the
adaptation problem has been addressed in
some ways but perhaps not as much in a
theoretical way which option was talking
about before and much more in a sort of
you know a hardliner and in some ways I
would already start criticizing some of
the work that has been done here in
language processing for example for
adaptation well although you might work
in practice
part of it has no principle okay there's
actually no theory for for why it should
work that way so it's basically you see
that how do this by also figure I'm
gonna say so there should be more
careful so I do want to mention one
thing giving a solution to these
problems is pretty some people think
that adaptation it's just a little
probable whereas many people are trying
to come up with a new problem but maybe
some if you it's a major major problem
if you don't address it it's not gonna
work it is just terrible and for all
three of the axes that I mentioned so
let me just formalize this a little bit
more and I'm going to talk about a
domain even source tab in in a target
domain the source the lady's made of
their care a distribution Q over the
input space the target function is sub 2
which is the labels that you receive for
that domain and it's similarly a target
distribution key and a labeling function
f sub T which are kinda like the two
labels you wish you could ever see and
the problem is common in the following
way you're receiving a label sample
pests drawn from the source so drawing
from this distribution for input and
with this the labels that are from
executes and typically if relatively
large are labeled sample from their
target because on maple sample is unable
the points are cheap so you can imagine
that this one is
and the problem consists of finding a
hypothesis H in some hypothesis survey
in general range that has a small
respective lost with respect to the
negative a so that means with respect to
the distribution key so this is going to
give media it will be finder notation as
well I'm going to denote by the
calligraphic l sub t the expected loss
with respect to distribution P and then
of the loss of the first element with
respect to the second element which is
really what you care about it should be
clear that this is a challenging problem
it's at least as challenging as the
usual learning problems but it's more
because giving a data from so there's
been a lot of work in adaptation as
actually not so mentioned already before
in a variety of domains I'm not gonna
cover the previous work here but only
talk about some of the theoretical work
that has been done here started with the
work of shy and John mid sir here and
several others were the first to tackle
this problem by giving vc-dimension
bounds based on a distance I may turn
that's of age that is not accessible
that is not possible to these are really
nice because this is the first time I
guess as promised even addressed and
particularly the use of the yeti Spence
which is related to these two things is
very
there's a bit of an issue to say but we
protesting a three times they already
should be this balance which basically
means that it's three times in some
Network began learning balance for this
allocation problem based on the notion
of discrepancy which generalizes this
and that I'm going to describe in a few
minutes and our problems are also based
on the quantity that sometimes you
cannot specimen which is related to the
optimal hypothesis it has the same issue
from that inspectors manga age but
they're favourable there are possible
assumptions with respect to some of
these previous grounds and we also gave
some pork pies loss guarantees which I'm
going to describe here which i think is
actually one of the most important and
more recently shine with other
colleagues have given some negative
examples for adaptation in binary
classification is a basically cases
where adaptation would not be possible
some of these examples are really
examples to make corner but really you
know illustrate the fact that the
problem is that there is a traditional
way of addressing the problem of
adaptation using what's known as
importance waiting this is basically
ignoring the loss function or the
hypothesis and sort of trying to make
the distribution that you're having your
training are similar to the target and
we have tried this and often it doesn't
work in fact it's not that it doesn't
work because people who are not working
in will estimate it will be nice it's
more than sometimes it works sometimes
it doesn't
so that's really worse so we tried to
analyze this because in fact the
importance weighting is used all over
the place in a variety of problems let
me also say that adaptation and
importance we can also related to
boosting in fact you can do lose the
universe very much in those terms and so
we try to analyze in what cases those
would work and try to suggest some
possible algorithms based analysis
simpler and more general learning paths
than those described here with
algorithms for actual practical
algorithms for tackling this problem so
let me try to so illustrated the
descriptions the problem is the distance
that I'm going to talk about and the
mismatch between distributions that is a
problem in adaptation this is just a
simple figure but should already give
you some idea of what the adaptation
problem is so basically this is the
support of your source this is the
support of people
and really it should be clear that for
example these new supports are destroyed
it's not much you can do how did you
learn from data that has nothing to do
with the target so really the first
reaction should be that most of the time
I'm a patient should not be possible
okay so the question now has been what
cases could you actually and then these
two distributions are going to be
different not just their support and the
question is to measure the difference
between those distributions and really
one way that should matter is to take
into account not just the distribution
itself but also the hypothesis set that
you're using and the loss function this
leads to a particular distance which i
think is really tailored to the problem
of adaptation and which discrepancy this
purpose is a generalization of the
what's known as a cache I really made
clear the connection between that and
adaptation and then also so the
definition is been following the
discrepancy of two distributions p and q
given a hypothesis of age and a loss
function l is the max over any two pair
of hypothesis in an age in each part of
the expected loss of HTH climate age
immeasurably spec to t minus that
expected loss with respect to
participation cubed
why should that be the right way to
think about this well first thing that H
prime is the target suppose H prime is a
target function okay so really what
you're been is that the loss of your
hypothesis H with respect to the target
measures on the true distribution
compared to the loss measured on your
source distribution so this is really
what you care about so it's natural to
look at this difference but of course
you don't know the target distribution
but if you assume that the target
distribution maybe is close to the
hypothesis set then you can be placed
assume that H prime then would be
average okay so this is this is what I
this is the natural measure of the
distance of these two distributions for
adaptation so this is clearly a
symmetric definition it is also
verifying the triangle inequality simply
because like its absolute value of
verifying that it has the triangle
inequality property regardless of the
last function but it's in general not a
distance you know but you may have it
may be possible that the discrepancy of
P and Q will be 0 but P and Q are
different this actually it's one of the
problems that you would see in some of
the counter examples for example that
right has been possessing some previous
work where you you might wish to think
that in fact the world is beautiful your
discrepancy is zero but in fact the
distributions are still quite different
and that comes from particularly choice
of the hypothesis certain under
inspection so to speak a limit about
this in a few minutes so this general
definition calls for any loss function
and in particular it helps realizing the
DA distance to the case of elke losses
and arbitrary losses and one crucial
benefit of this discrepancy definition
is that it can actually be estimated
from finite samples so for example when
this is just a special case for a case
of losses losses you can show that with
high probability the discrepancy the
true distribution is usually between P
and Q
it's very close to the discrepancy
between she happened to hat I'm gonna do
you know but you haven't cured the
empirical distributions other
distribution corresponding to unlabeled
seem simile for their source so it means
that these two are very close provided
that the harmonic complexity of the
hypothesis set with respect to the
sample pets that you see for the source
and solely for the target and would be
reasonable so you can think of these as
being if for example the hypothesis has
finite VC dimension this may be of the
form square root of G over m ok so all
of these are basically going to zero you
could compute your discrepancy given an
adaptation problem and based on that
trying to see if you a favorable case
it's important so now that we have this
notion of this frequency and its
preliminary ideas but the rotation two
types of beautiful guarantees could be
thought of one is just like the standard
generalization bounds problem what will
be the difference between the average
loss of the hypothesis H on Q versus
another one which you can think of as
being more the ability problem but I
think is very closely related to what
you learn in an efficient is what is the
difference of loss between of course
measured on key which is the description
which you care about what is the
difference of loss of a hypothesis age
obtained when you're training on what
you find what you have Q hat if you you
had is the empirical distribution versus
the hypothesis H prime you would obtain
how do you train on them in a target
distribution so some data are drawn from
the target and the corresponding label
function really that's what you care
about it because how could you dream of
doing better than even obtaining data
from the true distribution if you work
that would be luck right and so both of
these problems are interesting problems
and of course it's also just the
question of the usual efficient learning
what could you even do if your
hypothesis how well could you do with
respect to disability but also just
standard problems okay so all try to
address both of these problems I'm
quickly gonna say if you worry about it
so first I'm going to present very
simple generalization bound for loss
functions that obey the triangle
inequality it's going to be generalized
to even to loss functions that do not
obey the triangle inequality but a some
relaxed person alright that's quite
simple to do to do this particular all
happiness
and let's see what this when we first
defined some rotation H star q for me is
the best thing class hypothesis thank
you thank you
nervous is the one that minimizes the
loss when the loss is measured respected
you and some of the H star P is the best
thing x with respect to t and so what
this clearing says is that the loss of
your hypothesis h minutes vector of
people which is really what you care
about is bounded by the most of your
hypothesis we will expect to the best in
class plus the loss of H star Q
inspector FP this one you cannot do much
about right this is basically just
related to how well your how good you
have officer service plus the
discrepancy of P and Q plus the loss of
the best in class for Q are the best in
class let me just make a few comments
about this this one as I said is
something that is always going to be
there it can never be that one this one
is natural it's basically if H star Q
work post if cute and without it just
your usual loss that's the discrepancy
term that you find here and this one is
a term that is more problematic because
it's not clear that the best in class
for human the best in class in P would
be always closer but again that's - you
cannot observe and you cannot measure
okay so let me just look at some special
cases of this
if for example there would be an H star
a star Q star P were equal let me also
mention that these do not need to be you
need the best-in-class is not unique so
if you worried that case about
simplifies to the forward which again
this term is the natural term that you
would have in general this one is the
discrepancy and this term is just the
approximation error of your hypothesis
so it becomes natural in that case to
think that you would want to minimize
your error with respect to the source
plus a term that depends on the
discrepancies shows up in this in the
balance and then of course if you made a
very special case where on top of that
the problem is consistently no was the
target labeling for him isn't the
hypothesis but in fact the difference of
the last with respected ready but you
care about me speak to the AFP - the one
measurement measurement e - the one
laser gun q is in fact paralleled by the
disturbance it's really not a
description becomes the crucial so these
were all that sort of simple balance
that I wanted to derive and they did you
already inside but really what I think R
is going to be more interesting is to
try to look at the second problem that I
was mentioning that I've tried to see
what happens when you train on some
distribution cue to produce some
hypothesis H using a particular
algorithm versus what you would have had
are you spraying on the true
distribution under hypothesis H value
to do that I'm going to look at their
general class of algorithms these are
algorithms that are minimizing your
singing probably most of the algorithms
that you see around all this time
other things that are minimizing a
quantity of this kind
lambda norm of H in some Hilbert space
divided by a positive n symmetric kernel
K squared plus the empirical error of
that hypothesis speech for that
distribution Q that you have seen okay
this covers a lot of algorithms support
vector regression support vector
machines reads we question the variety
of other algorithms are based on the
same type of regularized objective
functions so currently the key here is
there put a little bit so much of kernel
this is the moment to the most recent
kernel Lund eyes it is strictly positive
parameter as I said this is just the
intercalary so the question here is what
would happen if you measure if you could
what could you say by the loss of these
two hypotheses H Prime and H and here is
the first learning bound that I would
like to discuss with you this one says
the following if the loss L is such that
it is Mew Lipchitz respect to its first
argument this is not a strong condition
again it calls for all L key losses and
a variety of other cases for example the
hinge loss so it holds in
loss functions not the zero one loss and
if you assume and this is it is the
assumption that I will compact if you
assume that the the target functionality
is in your hypothesis set then it says
that the loss
h1 that you would have obtained how do
you train on the true distribution - the
loss of the hypothesis page that you
obtain when training on the distribution
that you have that loss is bounded by a
constant nu R times something that
depends on the discrepancy between the
empirical distribution P - Q hat and ETA
which is the maximum difference on your
support on the training points that you
have between the labels that you receive
and the true labels you would have had
let me emphasize this that there's not
much you can learn if the labels you
receive on your training set are quite
different from the two labels you would
have had it's really it should be clear
in Utley right it's like it I could give
you just random labels is no way to come
up so you should hope that this distance
this loss between infinity on your
support on the training course that you
have at least should not be too large
okay now if that is the case if you are
fortunate enough that this is
sufficiently small but really what this
theorem says is quite strong actually
because it's not even a generalization
bound of the standard form that you see
in learning theory this actually says
that the loss point wise loss for any
pool
any X&amp;amp;Y the loss of that each point the
one you would have had had you trained
on direct target - the one that you had
when training on the source this loss is
bounded by something that depends on
this term toss hopefully something
that's small here take an expectation no
okay so you this the same loss because
you will think of this analysis often of
being a point wise loss and trying to
look at a maximum for class loss you
could do the same thing in expectation
the only difference that you would get
is a talk about the expectation it's a
question that you ask me if you want
this if you have this learning bound
it's quite natural don't you think is it
possible to minimize this term to
minimize the discrepancy between the two
of empirical distribution
I mean basically here if you could even
bring this discrepancy to zero and if it
I was really really small he really
would be guaranteeing that you are 16
annotation the last respect to H prime
of H very very small so this leads
immediately to an algorithm which we
refer to as being the discrepancy
minimization algorithm and that can be
viewed as an adaptation
that's the new here so it's not usual
because the same trait of you see
instability bounce but if it's lined up
for a fixed lambda because you could if
you imagine that it's the same lambda
you will be using had you had the same
quantity amount of data then so this
leads to an algorithm which consists of
precisely seeking to minimize reportedly
that I showed before minimize the
discrepancy between the target
distribution P has and gave the one that
you observed you have how could you
minimize this there's not much you can
do the distribution that you received
you the points that you receive are are
there you cannot change those ones right
well you can not change the points but
you can't change the weights you put on
each one of those points so you can see
instead the distribution little Q this
support is the same as the support of
jihad or included in that one but but
that puts different weights of those
pots and so it's possible that there
would be a queue whose discrepancy with
respect if you had will be smaller than
the distribution of Q hat respectively
so you would be looking for so I'm going
to get up by Q star that distribution if
you have a distribution C to minimize
this once you have that distribution Q
hat you can then go and we wait your
training set by placing weight Q star of
X I at every point instead of the one
over m standard one over m weight that
you had for each loss and then the
training is basically similar to what
you would have in general so most most
algorithms can be used in fact in a
completely similar way by simply
multiplying the bars that you have here
by Q star X so so this is a discrepancy
minimization algorithm and according to
the theorem that you saw before they
should really quite often succeed modulo
those assumptions so quickly if you're
in the particular case of the square
loss then you just to give you a feeling
of how this I can find that minimizing
distribution if you call it Q prime this
would be searching for a Q prime that
minimizes this quantity the deposit is
did the discrepancy the surface is the
max over a V and W Prime in this case of
the expectation of this square gloss -
the other one you can rewrite it in this
form and then say that in fact you can
replace W prime - value by any vector U
and if you do that it gives you the
following form which you can then
rewrite by using a matrix we define a
matrix M Marcy which is an affine
function of a constant matrix and zero
that constant matrix M 0 is basically
the average of the right one matrices
that you have on the table points and
each one of these M eyes matrices
or just the exotics when I transpose is
for the label points at the sea-ice here
are precisely the weights that you're
looking for these are the ways that you
want to put on each one of them so what
it means is that the problem of
searching for the algorithm can be
written as a semi definite program which
is the follower
it's minimizing the norm squared I'm
sorry the note2 of MRC where a maps is
an affine function of C under some
conditions the fact that C of course has
to be a distribution so the Z's are
non-negative is sum to one and these are
the definitions of our dimension this is
a standard SDP in fact a lot of SB
pieces one of the most standard is the
piece that you can think of and so so
what we think in fact it's impossible to
solve it efficiently I'll come back to
that in a few minute but before that
what would be also interested in knowing
if you could use kernels in this city
which is one of the standard case for
these algorithms and in fact we have
generalized this in recent work by
showing that actually if you're using
kernels almost exactly the same SDP
needs to be solved you just have to
change the definition of the matrices M
0 ok and then as I said this is a
standard a DP and actually apply this
and try to see if it would work but
using the standard solvers not even the
best ones you can use more than a few
hundred points so so this is which is
based on yeah these are approximations I
won't have time to go through this with
Bay City this is the pseudo code of the
argument it's very simple you could have
been so simple quadratic optimization
problems if you just directly use it
here and yeah it is to replace is based
on the norm to of the affine matrix M
approximated with another function that
is smooth it's basically because this
function is not differentiable it's
known to be because when the eigenvalues
are the same for the matrix then you
won't be able to differentiate ok so
there is this algorithm is actually
quite efficient and maybe I can already
actually is the best public solver for
ATP's that you find for this problem and
if you try to run it this is what you
would get is this red points here so
basically after I don't know about 800
points I think we just couldn't run it
we just instead the blue ones correspond
to what you get
using the Ann Arbor I just mentioned and
you could run it for data system 10,000
points or more so this algorithm
actually works this gives you basically
a general tool for doing a rap session
it's an algorithm you aren't have any
adaptation algorithms actually there are
based on theory there's so this is one
that is supported by the analysis that I
mentioned before assuming making some
assumptions
so let me now try to relax those oh so
that algorithm rising beagle of whatever
epsilon but let me try to go back to the
adaptation come and try to say a few
more words about that try to look at the
most general case what general cases
that is the case for the target function
if so he may not even be in hypothesis
and so it's still looking at the same
family of regularize algorithms and now
the Jo guarantee for the court wise loss
of H prime minus 10 over H can be
bounded by the following term it still
has the discrepancy don't know I've
tried to write it in a way that would
not be to copy of it so maybe a bit so
I'm going to go through it with you your
help it's it looks a little bit like
discrepancy it's the expectation of H
minus f2 where H is the hypothesis you
somehow think that you're going to be
looking at basically you're gonna
minimize the range this is the
expectation of H minus FQ times v sub Q
Phi sub Q is a feature mapping
associated to your kernel function this
is the expectation of this quantity
minus the expectation of almost the same
quantity except that if Q is replaced by
Phi sub K is a feature mapping
associated to your kernel function
sure north into place this is a vector
it's a fictitious the norms of kid I was
it's the norm of the difference of
expectations of two letters and these
vectors actually if you're in the
particular case where F P and F cube
would be the same even if there's the
same actually your undies on your
training data if that would be said it
would be the same vector there will be
the expectation of the same vectors one
measured with respect to Q hats one
measured with respect to t Hat's it
becomes very very similar to a
discrepancy the only difference is that
if P is not in your same flavor in the
sense that it's a difference of two
expectations for the same quantity in
that case one min spectacular so that's
interesting because if you are in the
case where P - Q hat and sorry if
kinetic you for example are the same
which is a strong condition but it would
hold if you're doing sample bias
correction it would hold in some
approximately in some cases as well
possible case that's going to be
interesting because think about the
following the algorithm that I just
described to you can minimize the
discrepancy between P - Q hat suppose
you can actually minimize this to the
point where if you have enough unlabeled
layer this what will come really really
small in some cases when this quantity
becomes really small it's it's you can
show actually that the expectation with
respect to Q hat and the expectation
respect to P hats some family of
functions would also become very fast
when that is the case
mr. actually when you're minimizing this
term you're almost also making this
other term smaller so I'm going to
discuss this in a second so when the end
discrepancy grows
remember that little bit that additional
suppose let me cut sure
so they have different supports and you
could so there's a lot to discuss here
this discrepancy when you try to
minimize it actually in some cases you
can show that it can become really close
to zero but that will depend indeed on
the support we have to support of so of
course begin if you're in a bad case you
will not be able to make this small but
let me actually make this in more
general terms in the in the previous I
mentioned you minimize the discrepancy
once you have minimizes you actually
look at the values that you're trained
if the value of the best improve of this
discrepancy that you obtain is actually
still not very small well you're not in
a good case actually you should not do
adaptation there this is another message
for this work actually you shouldn't be
in some cases we do you reject it
adaptation in many cases should be just
rejection
don't try it's not gonna work
it's for the particular this I ever tell
you that no no it will be for this is
it's still a quiet family about so so
what I want to say here is that in some
cases for some hypothesis set and some
loss functions and I should be able to
make this very small if you make this
very small actually you might also make
this other term very small this is
interesting okay because you don't
really have access to the label
unfortunate but because the P hat and Q
hat might become very close actually
that expectation like that difference of
expectation could become very very small
it's a really good news partition what
the menu over age because you can
actually choose this best hypothesis
here to to make this as small as
possible I could have just chosen I
could have just used as just say the
best in class for key people the best in
classroom but you can make it as small
as you want to choose the best one there
you know it su in spirit but it's
actually different than this there you
have a some here is actually a
difference you don't get it exactly you
actually avoid that exactly you can see
that right you can you avoid it because
actually this has been become 0 if you
get clear thank you tacos so this
actually is a nice little so let me let
me show you be able to take just the
expectation there as well right yes
because again so we just briefly tell
you but one more thing and then I I do
want to mention that in some cases which
is actually a standard case where people
are using their algorithms for this kind
of
functions the case we're using Gaussian
kernels for example then actually
discrete easy distance images and when
this reverse is a distance what it means
is that if you would really minimize the
having Q hat down to almost zero
in fact those distributions would become
the same okay so I don't have time to go
through the proof of this this is what
because there's a huge cost because
you're doing it using Gaussian kernels
which would give strong from your table
but nevertheless let me just be clear a
lot of people are using Gaussian kernels
in practice right so it's what about you
if the algorithm that you're using no no
so the discrepancy between if your bogus
discrepancy might actually become very
close to zero depending on what what
setting you are so what's important here
is that this shows that it's a distance
but what's more interesting is that if
you manager you can bring the
discrepancy this which is allowed to
epsilon but you can show is that
actually then in that case they differ
some expectations between those labeling
functions that I mentioned as well if FD
is equal to FQ would also be down close
to the epsilon we also very small then
you really are making both quantity so
ok so I'm just gonna stop here there's a
lot to discuss on these learning bounds
to think about cases this would work we
have done some experiments using dinner
administrative John for certainly
several domains books DVDs and kitchen
to compare to see how this algorithm
actually works the one that I mentioned
to you under the assumptions that we
well basically speaking it shows that it
actually works in many of those cases
this would be the ideal error that you
would have and the error goes down as
you get more and more unlabeled points
okay and this depends on different pairs
of domains some domains are more
difficult than others but this is again
related to the discrepancy of their
distributions there's a lot to say still
about adaptation lots of other problems
that were open out there one of the
things that I wanted to say is how this
new PC becomes a crucial notion in this
analysis another one is that not
everything is negative so even if you
are you know so in some cases very bad
case and as I said you should reject
adaptation should not just not do it at
least with those algorithms but you also
see that the balance are directly
depending on quantities that are
favorable or not depending on the
labeling functions and depending on the
difference of the distributions which is
what you should expect so I don't have
the numbers here but basically in this
cases when you see that and for example
for this test this is adaptation to
books so the red one here is what you
would have if you were just training on
books it's not doing very well it still
does better as you get more and more</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>