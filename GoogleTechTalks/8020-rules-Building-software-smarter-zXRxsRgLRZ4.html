<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>80:20 rules! - Building software smarter | Coder Coacher - Coaching Coders</title><meta content="80:20 rules! - Building software smarter - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>80:20 rules! - Building software smarter</b></h2><h5 class="post__date">2008-10-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zXRxsRgLRZ4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks for coming we have a pleasure of
hosting Eric Peterson here today and
Eric has been working in software
development on different roles for
better part of the last twenty years and
he was just flying back really from
conference on agile in LA and stopped by
over here and offered to give a talk
talking about 8020 I've already heard a
couple people mentioned that it's it's
more like ninety ten or it's more like
in my case it's more like ninety nine
one but you know that's a different
story
so without spending any more time on
this here is Eric I don't know whether
you want questions as people have them
or save them to the end up to you yeah
questions as you have them yep okay
thanks cranky I'm based in Melbourne
Australia I've been involved in custom
software development for most of the
last 20 years so a lot of what I'm
talking about relates to custom software
development you know originally agile
with a small a before agile with a big a
came along trying to get things done as
quickly as you can so over the years
I've discovered the 80/20 rule is quite
a common thing behind a lot of what we
do with software development so I'm
going to talk about some formal and some
informal approaches where we can utilize
the 8020 rule first off a picture here
anyone have any idea what this could be
a picture of it's actually MGM whirls in
Florida in Orlando has anybody seen
anything interesting in this picture
Mickey Mouse how many people can see
Mickey Mouse ah good good good okay the
normal photo it's actually a lot harder
to see Mickey Mouse I'm sorry who can't
see Mickey Mouse excellent this is good
I've actually played around with the
photo by putting this bar across the top
right across the top of the ears you
actually see Mickey a lot easier I've
given this talk in the past and you'll
get like one or two people putting their
hands up saying they can see something I
think this is a great metaphor for
sometimes something can be right in
front of your eyes and you might not
really appreciate it
and that's what I think the 80/20 rule
really is okay I'm going to show a slide
with a question on I'd like you to raise
your hand if you think you know the
answer but please don't call out the
answer okay so we have here
okay can you raise your hand if you
think you know who this man is okay okay
a couple okay
don't don't say anything yet we'll find
out in a couple of slides if you're
correct
this person is an engineer and a lawyer
and he discovered the 8020 rule so let's
think a little bit about the 8020 rule
the 8020 rule is pretty much behind
almost everything it's like a very
organic rule and there's a guy called
Richard Kosh who wrote a book in 98 and
a quote from it is this rule can
multiply the profitability of
corporations and the effectiveness of
any organization it even holds the key
to raising the quality and quantity of
public services while cutting their cost
Wow
sounds pretty revolutionary if anyone
goes on a time management course
typically one of the things they'll
teach you about is the 80/20 rule so
what is it basically it's when you have
a group of causes 20% of the causes are
typically responsible for 80% of the
effects and for whatever reason it seems
a common rule or law in any sort of
organic system you know it really does
prove that quotes God does play
favorites and here it is visually
typically 20% of something will account
for 80% of something else it's a bit odd
that we actually call it the 80/20 rule
because typically we think of it as the
20/80 rule if you go searching on the
net you'll often find some people will
say oh I've just disproved the 8020 rule
I did an analysis of something and it
was actually 55 you know 63 therefore
80/20 doesn't work it's an indicative
trend it's like you know logarithmic
relationship it's basically saying that
typically some things are more important
than other
an early example of the effectiveness of
the 80/20 rule IBM in the early sixties
did an analysis of their big iron
mainframes and actually found that 20%
of the instruction set was being
executed 80 percent of the time so they
went back and they re engineered that
20% to make it blindingly fast and they
got exponential improvement in the speed
overall of the operating system and for
a long time this was a very tightly held
secret within IBM that this was the
secret behind their efficiency so as far
as I know that's one of the first
examples of using the 8020 rule in
technology and really leveraging a
business benefit from it so who is this
person who discovered the Pareto
principle put your hand up if you think
you know what his name might be now okay
it's obviously someone called Pareto and
this is vilfredo pareto he actually
studied economics in Italy and he
realized that 80% of the wealth was
concentrated in 20% of the people in
Italy and he remained relatively obscure
and then another guy came along and his
name was actually Joseph Juran and he
studied quality in American industry in
the 1930s in the 1940s and he actually
proposed this idea of a generic rule not
just a rule in economics he described it
as the vital few and the trivial many
and he didn't actually named it after
Pareto there was a bit of a mix-up he
published a book and one page had a
chart that said Pareto charts which was
the charts that Pareto had done
originally with his research and then he
had his quality charts on the opposite
page and he didn't really name them and
then when people started reading this
they started calling it Pareto analysis
even though it was actually proposed by
Jaron he was a very meek and mild man he
recently died in January 2008 at the age
of 103 so he's been around for a very
long time if
you search for Mia Koopa and Joseph
Juran he actually wrote an article where
he explains why he decided not to jump
up and down about this Pareto analysis
that wasn't named Duran analysis but
recently a lot of quality organizations
have started pushing to call it Duran
rather than Pareto Duran did a lot of
work outside discovering the 80/20 rule
another little survey just to make sure
that you haven't fallen to sleep yet
which of these do you think Joseph Juran
could have been responsible for fitness
for use as a definition of quality the
concept of cost of quality or the ideas
of total quality management so can I
have a show of hands for fitness of use
definition of quality yeah okay couple
cost of quality okay are lots of
enthusiasm for cost of quality okay
total quality management yeah a few okay
he's actually quite an amazing guy
because believe it or not he's
responsible for all of them and and in
my opinion you know in 50 to 80 years
this guy will be seen as one of the
Giants of not just software quality but
quality in general an amazing guy okay
sweet spots in in sports where I come
from we have a sport called cricket and
a lot of Indians relate very strongly to
cricket and I used to have some great
start to phone conferences with Indian
teams where we'd be discussing who was
the best batsman at that time you know
was it session Tendulkar or was that one
of the Aussies and depending on what
their averages were that would change
but if you had a cricket bat or a
baseball bat or a tennis racket or a
golf club sportsmen know that there's a
sweet spot where if you hit the ball
properly minimum effort maximum return
and that's what we're talking about with
the 8020 rule you're trying to find the
point of focus where for the minimum
effort you can get your maximum return
so how do we identify these sweet spots
we use what's called Pareto analysis
named for Pareto by Duran basically
consists of looking at the main causes
or the main classifications of something
to link this to the properties and the
results so you try to establish what
these relationships might be there's
many many criteria for Pareto analysis
whatever you're interested in you know
it would be your point of focus and how
do we work with this we then move on to
what we call a Pareto diagram so what's
a Pareto diagram again named by Quran
for Pareto typically a graph of results
of causes and sorted by most to least
and most people will have seen a Pareto
chart I'll give you an example in a sec
you can use them create them with you
know most spreadsheets or graphing tools
now quick diversion we have their three
cartoon characters in their late teens
that we would be familiar with as pre
teenagers they're very famous cartoon
characters as pre teenagers this is like
the slightly bizarre teenage version
this guy here in the yellow t-shirt is
typically very neurotic and very
insecure this guy here is normally
holding a blanket and this woman here
does psychoanalysis of this guy here
this guy's bald and he's got a big curly
hair anyone starting to get a feel for
who they might be yep okay in Norwegian
its cluck now who can we go for the
English peanuts of course yes so we have
all the characters and peanuts now I
know that some people get obsessed with
things but this is actually the lid of a
laptop you know I'm not sure what this
would say about you professionally if
you walked into a business meeting with
a peanuts laptop in fact it's quite
bizarre I'm not sure what it's trying to
represent you've got people lined up at
a bus stop and then you've got people
lined up and the bus stop has moved and
like a lot of them are duplicate
they're dressed in different things and
then the bus stop has moved again and
there's this really really weird
character that I'm not sure what it is
it looks like sort of a a you know
extremely obese relative of Snoopy and
down the bottom you know they're all
waiting at these three different surreal
bus stops and down the bottom there's
tiny little bus and I don't want to
speak ill of the Japanese but I think
this is probably a Japanese concept when
it was marketed it just doesn't yeah it
loses something in the translation I
think but the clever thing for me is
because it's a lid of a laptop it's
basically public domain so you know you
can see it and I can't be told off by
mr. Schultz and his relatives okay so
why would I be looking at this well I am
going somewhere with this how many named
identifiable characters do you think
there would be in peanuts or I can't
pronounce the Danish anymore but yeah
zero to 20 20 to 40 40 to 60 or 60 to 80
now this man was drawing this cartoon
for almost 50 years I think so hands up
if you think there'd be 0 to 20
characters okay quite a lot gee you're
easily misled there were more than 20 on
that slide before 20 to 40 okay about
the same 40 to 60 or fewer okay 60 to 80
okay
there's a few okay it's amazing he you
know most cartoons you'd think they'd
just be a few cool characters but there
were actually 54 characters that were
named and and you know appeared
repeatedly in in peanuts so you might
think why am I sitting in a talk about
the 8020 rule and this guy's talking
about peanuts well there is a link there
was an Internet survey done of people's
favorite peanuts character and over a
thousand sorry over 11,000 people
responded and I guess you know to
respond to a survey on who was your
favorite peanuts character you had to be
relatively involved and had it been
available at the time you probably would
have owned one of those
it's laptops but these are the results
so I'm cutting out at about sixty
ignoring the sundries that may have only
had one or two votes and when we graph
this it looks like this so this is a
classic Pareto chart so you see we're
ordering from highest to smallest and we
have here the count of how many people
voted for each of these things then this
blue line is the classic mark of a
Pareto chart it's basically a percentage
line so as you move from left to right
it's mapping what percentage of the
total have you reached so a classic
Pareto relationship is about the 80%
mark and you can see if you come across
from the 80% mark you end up about here
so 80% of the total votes we'll do it
just for three characters Snoopy Charlie
Brown and Linus so this is a classic
example of the 8020 rule in play okay
real-life sample you'd graph it and you
can find the the 8020 trend so you know
poor old
Marcie or Pippin I was actually quite
surprised that peppermint pattie got up
quite high and Pigpen isn't that great
there must have been so many you know so
many people who don't like cleaning up
after themselves who voted for Pigpen
you know he was the guy who was always
perpetually dirty so this is an example
of the sort of analysis you can do so
you know if you're if you're trying to
study something you work out the
criteria that you're interested in you
create the Pareto graph and we'll see
that if you're trying to get any sort of
process improvement or something similar
the obvious place to start is in this
area here where all your results are
coming from okay and we're going to see
different examples of that as we we go
through here's a quote from dr.
contrarians guide to the universe it's
on living by the 8020 rule you'll miss
the glorious world of timing luck and
surprise all of which lurk in the
shadows not the light of life it's fine
to understand life in terms of the
Pareto principle just don't live it that
way
I think gee that sounds pretty bleak you
know and slightly chaotic and to me that
that reminds me of a typical IT project
so I'm thinking wow okay if you don't
want to live in chaos and the only 20
rule helps move your way from chaos then
maybe that's a really good thing for
people who work in IT and so it is
proved I first gave this talk about five
or six years ago at which point I hadn't
really discovered agile and now that
agile has come along and one of the
agile principles is actually based on
the 8020 rule and it doesn't take much
thinking to think of ways that agile is
basically built around the concept of
the 8020 rule
you know the classic thing is you know
we're delivering something of value to
our customer what is it what is the main
thing that they want to use so you've
got some informal Pareto analysis
happening near you're doing
retrospectives you know what are the
main things that we're doing well what
are the main things that we were doing
not so well let's try and improve those
main things you've also got the classic
thing of stand-ups you know are we going
to sit down for an hour as we go through
this 90 page action item list or are we
just going to say here's what I was
doing here's what I'm hoping to do he is
where my problems are you know classic
Pareto type stuff just the main focus
you're also using it in test-driven
development and paired programming to
some degree you know where are we going
to start writing this program what's the
main thing that we have to start with
and then you just go through and add
different things so a key part of agile
development let's go for a slight
variation on this here's a definition
from Oscar Wilde the English poet and
playwright experience is the name a
person gives to their mistakes so what
can we learn from the experience of our
mistakes our defects how many people
here have heard of bug clusters yeah
that's that's really freaky that's
probably I don't know 5% it's
when I give these sort of talks and talk
about bug clusters and typically you'll
get five to ten percent of an IT
audience will have heard of them how
many people have heard of the definition
of that you have to write a test case
before you actually execute it yeah
that's scary because people have heard
of that one but they haven't heard of
this one okay most system testers you
know who are aware of functionality
across an application know implicitly
that bugs seem to cluster okay and and
it was always fascinating me for a long
time that you know how come nobody else
seems to be writing about this so I did
some research and I found that quite
recently this was documented in 1976 and
the scary thing is this guy Glenn furred
Myers was out of IBM so IBM with taking
lots and lots of figures and statistics
and they they were able to analyze lots
of their applications and identify bug
clusters
he wrote this software reliability book
he then went on to write a book all
about software testing and in it he has
a series of axioms and one of his axioms
is as the number of detected errors in a
piece of software increases the
probability of the existence of more
undetected errors also increases now the
sad thing is this book also includes
axioms that say things like write a test
before you run it and almost everybody
knows that one but they don't know the
really useful one as an extension of
that Myers went on to say as you
discover clusters of bugs pause what
you're doing and write more scripted
tests in the area that you're finding
the bugs now I've worked on dozens and
dozens of software projects in my time
and I have never ever worked on one
project where that happened has anyone
here worked on a project where as you
find bugs you stop and you rewrite more
tests where you're finding the bugs yeah
no it's quite sad because the whole idea
of writing a script before you run it
relies on writing more scripts
you find the bugs and one of the key
things you'll you'll find that I'm
talking about is feedback you know as
you run a test you want to see if it
worked or failed and based on that
you're going to do something next and if
all you're doing is writing running
scripted tests you're never going to get
that feedback loop so for whatever
reason people have forgotten this the
people who knew about bug clusters great
now the rest of you know it you know
hopefully it'll maybe not change your
lives but you know make you just
development life a little bit easier so
how can we do this analysis well we can
use a Pareto chart of the defects we can
plan you know graph typically where we
found these defects functionally and
again you can use a spreadsheet or some
similar tool to generate the information
so I'm going to now present a short
presentation about a project I'll call W
I've had to change slight details on it
it was a small web project it had nine
functional areas varying from you know
typical thing log on internal homepage
some administration a staff log a search
make a variety of appointments have a
list of suppliers in their details and
we found that again we found about 70
defects now this wasn't an agile project
okay we found about 70 defects one
severity one and seven severity twos so
what did the Pareto diagrams look like
so let's look at the high severity
defects first and you can see this is
what we typically expect with software
there was one module that we found a lot
of bugs in and there were two others
that we found one bug in and so you can
see clearly you know there's a like an
8020 rule thing happening there so that
a small amount of the functionality
accounts for the bulk of the high
severity bugs now let's look at the
graph for all the bugs and you can see
surprisingly okay we've still got our
8020 rule here
but then it sort of tapers off to
nothing and when I started seeing this
sort of stuff I thought well this is
weird
you know so I started to do some more
research because this is not a normal
photo relationship you know a normal
part of relationship as we saw before
slowly steps down to zero doesn't just
cut off like that
so is this typical and the amazing thing
is yes Victor bacilli and Barry Byrne in
I Triple E computer in 2001 printed the
results of a whole lot of analysis and
research they did they called it the
software defect reduction top 10 list
nothing to do with David Letterman but
stealing a good concept and two of the
top 10 irrelevant for us number four
basically said about 80% of the defects
come from 20% of the modules which is a
standard Pareto relationship and the
second bit was really interesting about
half of the modules are defect free and
this was found repeatedly in studies of
software now you might think how could
that possibly be now this is that system
test typically okay so you've got some
sort of unit test process and the
presumption is that unit testing is
going well and is done properly and when
you hit system test all you're finding
is this concentration of bugs in certain
modules and not everywhere else but when
you think about it it sort of makes
sense you know because there are parts
of an application that are pretty
straightforward if you're building
reference tables for example you know
reference tables are typically just have
a code have some value and then just add
them and modify them and delete them
it's not that complicated and if you're
a skilled developer you should be able
to do that almost in your sleep you know
and you do have parts of an application
that are very straightforward at the
same time you do have parts of the
application that B might might be more
complicated or not fully understood and
that could be you know where your errors
are coming from so they basically found
the range was about 60 to 90 percent
okay and 80 percent was the
meaning I've since spoken to some load
testers and I said you know just in your
in your experience intuitively do you
think this holds for load testing and
they've basically said yeah maybe forty
percent of the modules might have sixty
percent of the defect and a similar
thing apparently for security testing
the second one that's relevant and again
this is more relevant for non agile
projects they found that ninety percent
of the downtime from traditional large
software packages was accounted for by
ten percent of the modules so there
clearly was this idea of you know part
of the software is a lot more
error-prone than others and some authors
have actually suggested development
authors not testing authors once you
find these things throw the module away
and rewrite it from scratch but
unfortunately that's not always possible
so what are some of the implications of
this defect density idea once you find
defects in a particular module or area
functionality chances are that there's
more defects there okay
if you're testing something and you're
not finding much then okay there's a
chance that that might be relatively
free of defects now you have to link
this in with risk analysis a lot you
know if you've got a module that's
incredibly important you have to make
sure that you've got good coverage but
yeah it's an interesting interesting
concept the other interesting thing is
this suddenly starts to cast doubt on
the whole traditional IT model that says
you have to write detailed scripts for
everything because if you're being asked
to think about return on investment and
potentially half of those scripts that
you're going into detail on won't find
bugs you know if you're on a mission to
really really focus on finding bugs are
you going to get the return on
investment that you really need so how
can we do this as we're actually doing
our software development we can do some
ongoing Pareto analysis again you really
should be trying to link this in with
some risk analysis so that
you're testing the most important things
as you start so you're not just randomly
you know I hear some defects you know
there is some logic behind it and then
once you start to find these sweet spots
that's where you can focus on for your
exploratory testing or your scripted
testing or say you know test-driven
development you know you could feedback
and say hey we're finding a lot of bugs
and this may be your you know unit tests
weren't that good can you do some more
work if you've done your agile stuff
properly
hopefully this shouldn't be an issue it
could also be a suggestion for where you
might need some refactoring and you know
if you've got some legacy code or
something another part of this and I'm a
systems tester focus but I am you know
an X developer but now the part of this
was the fact that you know if you've got
a traditional system and it's down 10%
of the the modules are causing 90% of
those outages so how could you improve
that sort of quality well we can work on
our sweet spots while that we're doing
the behavioral testing but what's the
easiest way that you could improve the
code so typically you want to get the
best structural testing you can at unit
testing and integration level you can
also look for code smells okay and if we
leverage the idea of bug clusters into
code smells it should be reasonably
straightforward to say okay where we're
finding some code smells chances are
we'll find more you know if this 8020
rule is holding an interesting aside I
was involved with the review of the art
of agile development that Jim Schall
wrote recently and there was a lot of
mail mailing this discussion and I was
pretty much the token tester and there
was a lot of very vigorous discussion
about the whole nature of bug clusters
and Jim Shaw and a lot of the other
developers were basically saying no no
no bug clusters don't exist but we do
have complex areas of code so I think it
was part of you know two sides of the
one coin that the developers focusing on
on individual modules and they're
acknowledging yes some modules are more
complicated than others
whereas
system test resort of seeing the whole
thing and tending to see the world in
terms of bugs rather than code so
another way that we can find these
deeper defects a guy called Rob Sabourin
in Canada worked with a guy called Kim
Davis and what they were doing was rapid
analysis of bugs as they were finding
them and as they seemed to would
discover a cluster they then pair in
that area and as well as fixing the bug
they just found they'd look for other
bugs and they they did a little bit of
experimentation in this field and they
basically found typically they were
finding certain defects for every ten
defects that had been reported so that's
another technique you can use go
straight to the code it's a little tip
we have for building smarter tip one
when you find bugs or big smells look
for others nearby one issue with this is
you're not going to find these pareto
relationships until you've actually
started testing so you really want to
know about it beforehand so what is it
you can do with it can we try and
anticipate where these bugs are going to
be and I've already mentioned risk and
risk is one of the best ways that we can
do this here's a quote from the software
engineering Institute today's risks are
tomorrow's problems so if we can
identify by risk where we think these
bugs might be occurring that's a great
starting point before we actually start
physically testing the code so how can
we do this in terms of identifying our
risks well we have to understand our
users and and what they want to do so
that's an obvious spot to start to try
and focus on to make sure that we won't
have any bugs and then where we might
have problems so where things are
functionally risky so we can do some
analysis and say you know just
intuitively where do we think the most
complicated things are or you can do the
traditional risk analysis you know
what's the likelihood what's the impact
what's the surprise factor you know how
quickly could this become a risk also
you can look at it in terms of
structural risk so where
these things more likely to break so
where are the new functions that popped
up late where are the things that have
lots and lots of interfaces where do we
have functions that are very very
complicated you know or have an ongoing
history you know the classic situation
is somebody's been working on this
module and almost finished it and then
they go and leave and someone else comes
along and inherits it
now if the TDD is being done well that
shouldn't be too much of a risk but if
it hasn't you know you've got all sorts
of possible communication issues another
way that you can measure this because at
one stage I was talking to somebody and
they said what if the developers you
know if you've got sort of a test in the
development team what if the developers
just don't want to tell you this
information what if they don't want to
do this sort of analysis is there any
way to get this sort of information and
I thought oh no I don't think there is
and then I was talking to someone later
and they they sort of smiled and thought
you haven't thought about this enough
and I said well what do you mean and he
said if you can simply go to something
like the checkout records you know which
modules have been checked out the most
that should typically mean that they're
the ones that has had the most problems
and because of the way the 8020 rule
works it should be quite obvious they
should be you know a small number of
modules that have been really checked
out a lot another measure that you can
have is once it's been coded which
modules have the largest number of tests
okay because in terms of complexity more
tests should mean you're covering off a
lot more complexity in the code and
hopefully you can feed the structural
lists risks into your functional ones
another aspect of this and I was
speaking at a conference in New Zealand
once and talking about this you know a
woman put her hand up and said we had to
create a new system for our users and we
asked them which of our existing systems
would you like us to model this on and
they pointed to a particular one that
was the buggiest that they had it was
really really buggy and the developers
couldn't understand while the users were
saying we want a system that's like this
bug you want and when they talk to them
more they realized it because it was the
most user-friendly one so even though
there were bugs in the code because it
was easier to use
the user soared as higher value so if
you're in a situation where you're
basically at a fixed level of quality
and it's very hard to make the quality
better one approach is to identify what
are the key modules that your users are
using most of the time and typically you
know the 80/20 rule holds for that and
then really really focus on making those
as usable and simple and straightforward
as is possible and that way you can
actually get the users for giving you
bugs so it's a bit like smoke and
mirrors here you know this is really
usable you don't notice our bugs an
important part of that though is to make
sure that the number of tests in each
area reflect you know the importance of
that particular area so tip number two
spend time designing and testing where
your users spend their time another
approach is trying to reduce our risk so
we might build a prototype you know
using extreme programming or other agile
methods and reducing the risk where we
may have problems typical things
schedule the riskiest work first
okay classic agile principle and always
be revising your risks as you get new
information
another thing is where we've got the
structural risk where we're trying to
reduce our risk you know do your pair
programming refactor as much as you can
do Pareto analysis of your you know
design or development issues now an
interesting thing is there's often a lot
of animosity towards what I'll talk
about a little while later the the CMMI
you know and a lot of the the high rigid
process approaches of the software
engineering Institute but one of the
interesting ones that Watts Humphrey
created was the thing called the
personal software process now if people
here heard of the personal software
process yep okay whew the the wonderful
thing about it is it's it basically says
okay one of the key things that we
should be able to really really work on
is develop a skill at estimating Hellen
it's going to take to do a program and
understanding what sort of errors they
make and so the PSP is all about a
series of small exercises where you
estimate how long it will take you to
write a program
and then you keep track of the errors
you make so over the space of writing
these small programs you get much better
at your estimation skill and out of the
bugs that you make you do a Pareto
analysis and you find there's certain
sorts of bugs that you make more than
others and you create your own personal
checklist out of that so where what's
didn't quite get the idea right was
because he was a process guy he wanted
people to keep doing this forever and
you know again it's the 80/20 rule
you'll get the maximum return from your
initial stuff and after that it becomes
a bit of a pain and when what couldn't
understand why developers didn't want to
constantly you know keep this going
he created a thing called the team
software process which basically said
manager make sure your developers
constantly keep these stats going and
the team software process didn't work
either
so you can you know you can see there's
great value in doing it once but I'm not
sure about on an ongoing basis so risk
based testing you can do this across
everything you know whether it's
usability
system acceptance performance one
interesting thing though that a lot of
people fail to realize that they'll do a
lot of this risk analysis but reality
always replaces risk so you know if you
think the high risk areas are here here
and here and you start testing and
you're actually finding bugs in areas
that you didn't regard as high risk then
you know I think you've got your risk
analysis slightly out of whack so you
can use spreadsheets or test management
software there's a whole lot of free
test management software now that's you
know very very useful for this sort of
stuff and if your software isn't safety
critical with these sorts of approaches
you can get quite a good quality level
quite quickly and like anything if
you're trying to have you know behavior
driven development or you know a whole
series of functional automation it's
very hard to automate everything but if
you can identify say where the bug
clusters are or whether very important
modules are that's a great spot to
automate so anticipate where the bugs
will be and look they're first in design
build and test the largest room the
great quote the largest room in the
world is the room for improvement and I
would say that the Pareto principle
belongs in
middle of that room so can we leverage
these 80/20 relationships in general
process well the CMMI the capability
maturity model from the software
engineering Institute one of the key
techniques it uses is the idea of the
8020 rule and it's actually quite
interesting that there was a lot of
synergy between agile utilizing the 8020
rule and CMMI and there was a lot of bad
blood at the recent agile '08 conference
because a lot of people were putting up
discussions of agile in a CMMI context
and none of them actually saw the light
of day and Scott Ambler did a survey
from dr. Dobbs readers and there was
actually a very large overlap between
CMMI and agile and I think that's one of
the main reasons because the 8020 rule
is so important in both so we found that
you know diffic select diamonds you find
them in sort of you know specific spots
not everywhere so can we use defects to
help us improve our process so instead
of just analyzing developer by developer
with the personal software process for
example can we do some sort of team
analysis well again there has been a lot
of work done in this area
orthogonal defect classification came
out of IBM this is a very good process
and lots of different companies have
different ways of doing this and it was
invented by Rome chilla Reggae in Adobe
M in 1990 this is a very IBM flavored
talk but for a long time you know they
were gathering all this sort of
information I was actually quite lucky I
gave an early version of this talk at a
conference and found out later that run
was actually in the audience and ended
up having dinner with him that night so
that was a nice little buzz basically
was being used by a lot of companies it
classifies defects in terms of what
caused them and we'll see some examples
of this soon and it reduces your root
cause analysis cost by a factor of 10
the issues tend to be in training you
know and consistency in the ratings of
what you're doing but with a lot of the
80/20 stuff
you know providing you can catch the
main trends that's the the most
important thing so let's have a look at
a project from Motorola that I'm going
to call X here's a Pareto chart and this
is based on code review results so the
first release they analyzed their code
review results in terms of orthogonal
defect classification they found the
major issues there were checking an
assignment now providing you had
reasonable skill at doing this you can
see you know you would see these trends
pretty easily so out of the whole code
for this particular project most of the
issues were in checking an assignment so
the obvious process improvement is to
focus on checking an assignment for the
second release and that's what they did
and you can see the proportions here for
the first release suddenly have dropped
significantly for the second so by
focusing in on where the problems were
using the 80/20 analysis they were able
to get a much better quality for the
second release and release the main
causes of defects by around 15% of the
total another example and we're getting
a little bit more exotic with their
pictures here Joseph Juran always seems
to appear dressed in this suit in this
bowtie he was evidently a very
functional man you know so this was an
example I new features being added to a
second product release now again this is
not an agile project but it's it's you
know typical of many things so you've
got the timeline here here was the plant
deadline and here's what was happening
and you can see you know if this keeps
going they're going to miss the deadline
by miles so what they did was some
Pareto analysis on the first release
defects and this isn't the next Pareto
chart but it shows you the trends so
they're finding most of the issues in
timing and interface so they then went
and rejigged their testing and focused
on those two areas and suddenly their
work rate increased exponentially
okay they missed the deadline but they
weren't that far off okay
and without that 80/20 analysis telling
them where most of the problems were
this would have been much much much
later in terms of delivery so you can
see we have sort of a bit of a quandary
here that you've got to do some level of
analysis to find these 80/20 rules but
if you're like on a true
you know agile with a capital A project
and they're saying I don't track defects
they're evil you know just put them on a
card you know we've got some interesting
quandary okay leverage the 80/20 rule to
improve the design build and test
process at all levels test reporting um
when I first put this talk together I
was really really upset I guess is the
word because you know I was able to go
and give this talk and give that survey
how many people have heard of bug
clusters and typically it would be five
to ten percent you know and I thought
this is crazy because just knowing about
bug clusters can improve your you know
your working life so much so I was
jumping up and down about it for a long
time and I thought how can i how can I
increase the knowledge of bug clusters
now nearly anybody who studies software
testing and does a course learns about
the eight to nine test documentation
standard from I Triple E and they've
just released an update in 2008 and for
whatever reason I think I got the
highest number of review comments and I
jumped up and down and I wrote this semi
sarcastic comment that said Glen furred
Myers was talking about bug clusters
back in 1976 shouldn't we mention it in
the 2008 testing standard and sure
enough it's now been adopted so if you
get the current standard it says one of
the purposes of testing is to look for
bug clusters except they've called them
anomalies for some anomalous reason and
also that test summary reports should
include details on these clusters now
test summary reports you know what a
test summary reports good for they
basically tell you oh this is what we
thought we were going to do that this I
guess they're like a mini stand up this
is what we thought we're going to do
this is what we actually did and in here
some bugs you know and
it's an interesting historical document
but where's the value the value is if
you go in and say hey here's where we
found our clusters and so you know in
terms of your analysis of what caused
the bugs or where the bugs were so that
when you hand over to maintenance that
knowledge is really going to empower
keeping the quality nice and high so
hopefully more and more people will
start to learn about clusters so another
tip use knowledge of where clusters are
for aggression and maintenance one of
the interesting things about reviews is
I don't know how many people have been
reviewing a document or something
similar or some code and you review it
and you think I found all the issues in
this and you go into the review and
straightaway you know somebody says ok
let's start on page 4 and you think page
4 I didn't find something until page 15
and as soon as you go to page 4 and they
point out what the issue was you think
oh yeah that's so obvious you know how
how was it that I couldn't see it and I
think that comes back to this idea of
sweet spots everybody has different
sweet spots so I think this is one of
the powers of things like paired
programming you know that you have these
different focuses you're able to
leverage off each other skills it also
seems to occur with peered exploratory
testing so and this is an overly
scientific apart from me calling it a
theory but I have this idea that if
you're working collectively on a task
you know if you have a good
cross-section of people on that task you
will get a much better result as a you
know the impact of the the different
sweet spots combining and was quite
interesting to me I heard John Sarah
whisky at the agile awake conference in
Toronto talking about the wisdom of
crowds and that's very very interesting
stuff where you survey you know a large
group of people for some independent
question and as a group they can come
out with a very accurate result of some
sort of calculated value that each of
them individually might not be able to
do and again I think that's to do with
sweet spots and that probably also
explains some of the benefits of a you
know a United team in an agile project
so another trick many cooks improve the
broth when there's no recipe and there's
a sort of a very long-winded paraphrase
exploratory testing there's often a big
discussion about oh no I can't do
exploratory testing I need skilled
testers before I can do good exploratory
testing is it true
a guy called Jakob Nielsen who does some
usability testing research basically
found he could take a novice user put
them in front of a simple web system for
an hour typically say you know just play
with it for half an hour and then do two
15-minute tasks and in that hour they
could find 30% of the usability issues
now that goes counter to all our
definition if you know you need to know
lots about computers to be a good tester
he also found that if he had five people
doing it he could find 80% of the
usability bugs now that's really really
amazing stuff so people who are just
users of software not necessarily you
know developers can find lots of bugs
without too much problems and I think
that goes into the fact that most models
in software are quite simple and our
brains are built to understand models so
how can a novice tester achieve it
through the ability of you know
understanding these models and having a
sweet spot that lets you do this so
another little theory 8020 rule is an
explanation for the skill of a novice
tester people have innate
problem-solving and modeling skills that
lets them find these discrepancies in
software now these are relatively simple
straightforward discrepancies you know I
look at a screen and and something's out
of alignment or something isn't
consistent with something else
now defects concentrate in particular
modules following the 8020 rule I said
before Glenn fat Myers said once you
find defects you should stop and rewrite
scripted tests doesn't happen so what
can we do exploratory testing and one of
the great things about exploratory
testing is it's based on feedback and
the classic thing is as I'm testing I
might be finding bugs so you can use
that feedback to concentrate your
exploratory testing where you're finding
those defects and utilize those sweet
spots and
you learn more you build up better
failure models you understand more about
failure and you can get into more
advanced failures where if I do this and
this and this and this in sequence then
I might have a bug happen and you need
to be an advanced tester to have that
sort of skill so basically the 80/20
rule seems to explain the reasons for
the power of exploratory testing I know
myself you know many times in the past
with a traditional project you could sit
down at it at play with it for maybe 15
minutes and get it to crash you know and
who knows how you were doing it it was
just all the you know your your inbuilt
knowledge of failure patterns and
failure models and I think that's one of
the reasons this whole idea of the sweet
spot so another trick this time use
exploratory testing and test projects
where the mix of other techniques is
required and explain to any skeptics
it's an example of the power of the 8020
rule
so in summary many cooks improve the
broth when there's no recipe believe in
the power of exploratory testing oh I
thought I'd got rid of the rally monkey
okay when you find bugs or big smells
look for others nearby spend time
designing and testing where your users
spend their time anticipate where the
bugs will be and look they're first in
design build and test and leverage the
80/20 rule to improve the design build
and test process at all levels and I
would argue that the 80/20 rule is build
smarter rocket fuel okay making sure
you're still awake any idea what this
shadow is on that tree the thinker the
think it okay
it is the thinker the thinker was
actually a fantastic example of the
80/20 rule in practice world famous
statue rodent was actually quite a
businessman he cast lots of these he'll
actually find one on most continents of
the world and he did big ones and little
ones I think in Scotland they could only
afford a little one you know so they've
only got a little one this big does
anyone know if this is the focus point
what the other thing is that the thinker
is just a small part of
has anyone ever seen this that's the
thinker up there
and that's everything else around it and
this is a great example of what we
should be trying to do this is called
the gates of hell great metaphor for a
software project Rodin proposed it in
1880 as the gates for a big art gallery
that was going to be built he whipped it
up in plaster have a guess how long it
took before it was actually built the
original intention was five years it
actually took more like 50 and
effectively it never really did what it
was designed to do because the building
never got built so it was built as gates
but it was actually stuck on a wall but
Rodin was a master developer and what he
did was he took commissions he'd take
commissions for bits of his gate so he
gradually build these things and he'd
actually died a long time before the
gate was finished again the gate is in
various places recently they moved it
from France to England for a short
exhibition so this is a great metaphor I
think for what we're trying to do we
have here the gates of Hell so hark back
to dr. contrarians guide to the universe
you know
chaos awful things happening the 80/20
rule helps you move out of the chaos you
know moving to something that's more
predictable so if we focus on the
thinker then we're able to bring a lot
more common sense to our IT projects by
utilizing the 80/20 rule the interesting
thing about this one
is this guy's actually made of
fiberglass and he's designed to go in
your garden so again if you search for
him you could have your own thinker on
your doorstep okay some last words I've
been a little cruel to vilfredo pareto
in this talk he's basically just popped
up as a photo every now and then and we
haven't really seen much content from
him so here's a little bit of content he
commented on Kepler the astronomer give
me fruitful era any time full of seeds
bursting with its own Corrections
I'd like to paraphrase that slightly
give me fruitful speak sweet spots
anytime full of seeds bursting with
80/20 benefits so hopefully I've given
you a quick walk through the 80/20 rule
formal informal and how it can improve
your building of software and hopefully
you can take these hints and go away and
have lots of fun with it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>