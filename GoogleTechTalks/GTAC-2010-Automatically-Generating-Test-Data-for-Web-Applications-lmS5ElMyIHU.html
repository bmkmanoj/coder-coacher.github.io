<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2010: Automatically Generating Test Data for Web Applications | Coder Coacher - Coaching Coders</title><meta content="GTAC 2010: Automatically Generating Test Data for Web Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2010: Automatically Generating Test Data for Web Applications</b></h2><h5 class="post__date">2010-12-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lmS5ElMyIHU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I want to say it's it's really an honor
to come here I've heard of GTECH before
I've heard of the company Google a
couple times before
and it's I mean it's really it's really
a pleasure to come here and I tell you
something that was that's really been
exciting is I found that every single
talk yesterday was interesting and I
learned something and that's I wasn't so
sure that would be true coming from you
know as an academic researcher coming to
a more industrial conference but it's
been fascinating good good talks or
interesting subjects I took a bunch of
notes of things I want to look at as
potential future research problems so
really I want to get through my talk
quickly I've cut out a lot of slides
because I want to sit down listen to the
rest of you all the talk after mine by
the way is fascinating by a brilliant
young scientist who by the way has had a
great education I'll tell you more about
that later so when I when when Google
first asked me to come to a G Tech I
said well here a couple of things I
might talk about and they said well this
one is a very interesting and this one
is and this one is can you do both and
so I thought well can you give me three
or four hours they said no only James
Whittaker gets gets three or four hours
of gee tag so they said but you need to
combine those and also fit it in to fit
into an hour so I I think I've done that
at least I've done the first part the
other thing that's really pleasing to me
is on the plane over here I was looking
at my slides and I was think there's one
part that I'll get to in a few minutes
that I thought well a lot of testers
aren't going to get this because it's
fairly technical low-level really relies
on program analysis that you know
requires a lot of programming knowledge
and then yesterday I thought geez I
should add more to that section because
that may be the most interesting part of
the talk for it for a lot of you I know
I do want to make one other point by the
way my book has never been recycled in
the diapers either for children or
adults I'm proud to say that it was
printed on recycled paper and I'm not
sure where they got that paper by the
way now I have some clue now so let me
get to it so that they're kind of two
real ideas I'm going to talk about one
is more related to web apps than than
the other and there really is this
section 3 and 5 and my mini outline and
I'm going to start off with some
motivation I think as a lot of people in
here are testers you probably don't need
a lot of motivation you may have seen
some of these but then again some of you
may be able to do what I do which is
steal some of the some of the facts and
use them to motivate other people for
what you're doing nothing else there's
some some interesting stories some
things to think about so I've been doing
this for a while my I finished my PhD in
88 and that was on the subject of
testing and what was frustrating in the
90s was I always felt like I was
teaching something or selling something
that most people didn't really care
about because in the 90s it this quality
of your testing didn't really have a big
impact on the bottom line for most
companies right it was not really
competitive but in the 21st century
we're going through major changes and
that's pretty exciting to somebody like
me a big change is we have a lot of
things in our civilization that are
being controlled by software and that's
pretty exciting and because it's sort of
controlling fundamental infrastructure
it has to be really good the other thing
is compared to the 80s and 90s we have a
much bigger market it's more competitive
we have a lot more users you know there
are maybe a few million back when I
finished my PhD now they're several
billion I don't there's something like 6
billion people in the world I don't know
what percentage of them using software
on a constant basis but it's way more
than half it's it's very high another
thing that's I think is really
interesting is how often we put softer
in places that we
really think about so I have this little
thing I have this this little thing is
software and you know I gave up my
slides a few minutes ago this is there's
a fair amount of software on here
then I was thinking in my room last
night I was thinking about what I
brought with me well don't laugh I'm a
bit old-school in some ways so this is
an old Palm Pilot it was it was good
when I oh my god it still works a lot of
software embedded in there I have to
listen to music especially on you know
17 hour plane rides my phone of course
which is it's not a very smart phone but
it's still a lot of a lot of software in
there
I brought a camera umm this even has
some software so if my hands shaking it
will still take a decent picture that's
pretty clever embedded software and
gonna realize even even this brick to
power at my computer it's got some very
clever software that allows that that
converts to 40 into 120 volts so when I
travel abroad so if you just think of
look in your pockets and think about all
the software you have it's probably more
than we had an entire world 30 years ago
and all that software has to work very
well because it's not the software that
we're caring about it's the device that
it's embedded in and then the one of the
big changes in the field now is agile
processes and I'm like a lot of people
I'm still kind of open minded whether
agile processes are going to work or not
but one thing I know is it puts testing
front and center and from my perspective
that's a good thing so we're we're in
the middle of a revolution and it's
changing dramatically changing what
testing does to the success of the
software and the bottom line of
companies and that's very exciting to
somebody like me who's been a researcher
for years and an educator and in
software and now a good friend of mine
named Mark Harmon I don't not sure if
you can see that down there gave me this
quote and I just love this quote that we
have a civilization with the skin now
and the skin is software and you think
about just think about the amount of
software it took
for us to travel from our homes to
Hyderabad to make reservations airplane
reservations to get our luggage here to
check in at the hotel to check in at the
airplane even I mean I drove to my
airport with the car that has over 100
chips on it it's a skin that surrounds
us all the time and I just thought that
that was a wonderful metaphor for what
software is doing and all that software
has to work well here's a kind of a
scary example of what happens when the
software doesn't work very well so this
is a Airbus 319 and I got this example
from a friend of mine Mary Jean Herold
who was actually on a plane when this
happened once the pilots are up in front
of the plane flying from this was from
Atlanta to London so some were over the
North Atlantic in the middle of the
night they lost their autopilot okay
that's an inconvenience but think they
still can fly planes without autopilot
then they lost their flight deck
lighting and the intercom which is
pretty disturbing then the next thing
that happens they lost their flight and
navigation displays and if you've ever
been driving on a dark road and you turn
off your lights you can imagine what
that feels like when everything goes
black especially when you're out in the
middle of the ocean in the middle of the
night so what do you think the pilots
did any guesses pilots are trained not
to panic easily so I hope they those are
the planes we don't know what happened
any other guesses yeah that would be a
good idea I think the Air Force pilots
would do that no actually they did the
same thing that you and I do when our
computer screen goes blank
they held the button down and then they
prayed I don't know if they're Christian
Muslim atheists but I know they pray
because they're flying a glider in the
middle of the night over a very cold
ocean with 500 lives behind them and
they push the button and indeed the
software came back up and everything
worked fine and they made an
announcement to the passengers we're
sorry for the inconvenience for the
interruptions here in flight
entertainment service we will try to put
you
you back where it was when we had the
slight interruption and most of the
passengers never never knew what
happened this has happened on this plane
several dozen times in the past few
years and they still haven't solved the
problem but they know it's software but
they haven't solved this so the manual
now for this plane has us as a page that
says how to recognize this problem and
what to do and I'm not sure if the
manual includes the prayer because I
don't think it's actually necessary at
that point but but but they have that in
there last night by the way I read a
short article online Nissan is recalling
several million cars why because of a
software problem so that was that was
just announced yesterday here's some
other software failures that have been
documented with some money attached to
some of them so there's this Miss NIST
is a US government agency National
Institute of Standards and Technology
they did this detailed study and found
that we're throwing away billions of
dollars every year because of bad
software and they estimated that if we
just tested better we could cut that in
half that's a fair amount of money some
of you may remember that this was
northeast of North America around the
Great Lakes region started in Canada and
propagated all around the Great Lakes it
was a small software error that caused
that in the alarm system that caused
that caused one power station to go
offline and that propagated and cost I
think it was something on the order of
30 or 40 million millions dollars damage
to various systems this is one of my
favorites is this do we have any people
anybody from Amazon here yeah this was
great one of my friends got a bonus with
this so it was a buy one get one free
offer except there's an if statement
that was written backwards so if you
apply to coupon to get one free you
could still get the second one free so I
had a friend I was actually a student
who actually got two items like that I
don't know how much they lost probably
not that much because I'm sure they
fixed it quickly but that's it's a very
small thing what Big C change occurred
2007 so Symantec tracks software
security vulnerabilities they ask
many years and they found that in 2007
we crossed the line most security
vulnerabilities are now due to software
errors not the network problems or
database or cryptography it's now
software so if you don't test your
software you can't have secure software
and then there are these estimates about
financial services and credit card sales
applications where and this is just in
the USA by the way these losses every
hour millions of dollars and that's
passed on the consumer so I don't really
know what the worldwide monetary loss is
but it's staggering and it's probably
between a five to ten percent drain on
the world economy just because of bad
software now who can who can improve the
situation it's people like you right I
can only have a mild influence people
actually do things that that can make a
big difference so how do we do this this
is a an idea that came to me out of out
of the the text book I wrote and this is
really a process kind of view and I'm
going to talk about this briefly and
then say how we how we fit the more
technical aspects of testing in here so
this this may look a little bit strange
I'm gonna walk you through this graph we
I look at testing as activities that we
perform down here I call the
implementation the abstraction level and
up here at the design abstraction level
so we take some softer artifact there
may be the source code it may be a UML
design document or requirements or a
user manual there's some something that
describes something about the software
lots of artifacts can be used to test
from um and we go through some analysis
and it creates some model a graph or
logical expression something along that
we actually have four models we define
then we apply some engineering
principles to create requirements on our
tests that say our tests have to do
something has to cover every edge and in
a graph for example so those
requirements are the design describe how
the test should be designed we also have
this sort of other path where we look at
our software and we use a human based
approach to develop test
requirements that are separate and the
interesting thing is you these different
kinds of approaches will detect
different kinds of faults and there are
some faults you can't really get to with
criterion there are some faults that
you'll never get to with the human based
approach a human based approach if you
only is that will also tend to yield
lots and lots of tests and fairly
inefficient testing those tests are
sometimes refined into something more
detailed depending on exactly what those
what the requirements look like then we
generate values and that comes back down
out of this design abstraction level
what I call it so that's where we get
actual values up here we're essentially
doing math just like real engineers
right a civil engineer uses out mostly
algebra and calculus to model things
about structures like a building or a
dam or a lake and or an airplane and
then they use those models though that
most calculus models of the artifact
they're trying to build to do all sorts
of things compute what kind of materials
are need of what safety is security
issues etc this is the same kind of
approach it's really traditional
engineering using mathematical
structures up here to do some of our
design work in an abstract way it makes
it more efficient then we once we have
the test values we had some additional
values largely to satisfy the kind of
controllability and observability issues
that that Bob talked about yesterday
we ought to make those into test scripts
execute them evaluate them and the
results down here will provide feedback
appeared we need more tests or maybe we
need fewer tests so we need better tests
so there's that that kind of feedback
loop through here these these activities
it turns out can be grouped fairly
readily into a and a couple of cat into
a few categories test design at the top
test automation down here test execution
and then test evaluation
so what we're doing by this separation
is we're separating the tasks in the
different kinds of activities that can
be performed by different kinds of
people and the interesting part is the
kind of knowledge and skills you need to
do the test design up here are very
different from the kind of knowledge and
skills you need to do a test automation
and that's very different from the kind
of knowledge and skills you need to
execute and evaluate the results of the
tests okay so we need different people
to do those and in any test organization
if you take someone who's really good at
this test automation and have that
person design tests you're probably not
going to get good tests you're not going
to have a happy happy employee and
you're gonna waste a lot of resources so
let's just pure that's poor management
of your human resources and what happens
eventually is you have people who are
good at this doing this kind of work
they leave they they want to go over to
development do something more
interesting so separating the tasks
allowed allow us to sign the right
activities to the right people and
that's just playing good people
management not that I'm a manager in
fact I stay in academia partially
because I'm afraid a company would make
me manage but doing this separation
allows us to raise our abstraction level
and then this process of test design by
being separate from dealing with values
we're just dealing with mathematical
abstractions it makes that process much
much simpler just like the algebra and
the calculus does for traditional hard
engineering fields so this is a process
that I've been talking about a while for
a while every company I've talked to
that is that it started trying this and
every manager project has found that it
helps them get more tests faster and
cheaper and their employees are much
much happier in their job and that's
very important because here's another
graph that shows the cost of not doing
the right kind of testing at the right
time this is something I pulled out of
the report
from the sei and I redrew the graph
because it took me about an hour to
understand their chart but they
documented a number of projects it was
something like 30 or 40 projects and
calculated the costs of what happened
when when tests were found when over
when false faults appeared in the
program when faults were found and the
relative costs of finding and fixing the
fault so let me just walk you through
this the yellow here is when faults were
originated when they were put into the
program so requirements design
programming then the green here is when
we were actually able to detect those
faults so a lot more false were detected
during system tests 20% during program
unit testing and integration testing few
during requirements a few during I'm
sorry doing design a few during
requirements and then not very many in
production but the real key are these
red bars the red bars represent the cost
so the yellow and the green they're
percentages the red is a unit cost so
unit cost is fixed at one for finding
and fixing a fault during or early early
in the process by the time we get to
integration testing it costs about five
times as much to find and fix the faults
and software by the time we get to
system testing it's ten times and then
if a prep fault gets through to
production like all the examples I
showed a couple of slides ago that's
about 50 times the cost of finding and
fixing the faults early on they're not
as many but if we just assume something
simple $1,000 unit cost a hundred faults
just to make the math easy then get
these costs and you can see 6k or
finding problems during requirements 20k
during unit testing and then 360k and
250 cakes so the bulk of the cost is
actually out here in system test and
production even though they're very
relatively few false found in production
the cost per fault is so high that the
cost of finding those false starts to
sky rock
so my view as a teacher and as a
researcher is a big part of my job is to
take these green bars over and design
program unit or unit testing integration
test and pull those up by finding more
false there and thereby taking these
green bars and pushing them down so that
then the cost starts to change that
starts to change so these new circles
are the costs if we push those down you
know I just I just took some estimates
of how we might be able to do a better
job testing you can see that we wind up
spending a little bit more money over
here but we spend a lot less money over
here so just with these not are sort of
arbitrary numbers that's a huge cost
roughly a third of that of the cost gets
saved just by finding more faults
earlier that's a big win now I know
companies that don't do any testing
until the system level what do we call
those we call those companies that
produce bad software right and I know
companies that spend a lot more time
finding tests early but there's a lot
more we can do so how do we how do we do
that how do we do how do we get better
tests well one thing that's really clear
is we need better tools when I look at
the tools on the market from my
perspective of seeing all the research
results the last 20 years I'm very
disappointed almost as disappointed as I
am in the quality of PowerPoint which
hasn't really improved much in the last
20 years but not quite we also need to
do to have better practices and
techniques and the interesting thing
that I've learned about Google is that
Google is doing a lot of this a lot of
companies aren't we need more education
that's partly my fault as a as a
professor and we need different ways to
organize our management strategies the
other thing it happens a lot of testing
QA teams don't have much technical
knowledge you know how do you get on the
testing QA team if you get a degree in
sociology and you want a job or you know
you do
hired by the developers and you're so
bad they ship you off to the testing
group that's not always true but that
happens far too often and I live in a
place where a lot of government
contractors and they're famous for doing
that they're very slow to adopt anything
any new ideas in fact we need more
expertise and when I compare that to the
development the amount of knowledge of
programmer needs today is vastly more
than what a programmer Newton needed ten
years ago so that's been increasing and
testing knowledge required is going to
be increasing the same way we also need
more specialization like the the chart I
showed you a minute ago we had a lot of
specialization and development that
occurred in the 90s and earlier in this
decade that needs to happen now and we
also need to reduce the manual expense
we're doing a lot of work by hand that
could be done automatically and one of
the biggies is getting the test theta
going through that design process at the
top of that chart and then finding the
values that's largely done by hand right
now a lot of that could be automated so
I'm going to talk a little bit about
automatic test data generation and a
couple of techniques for doing this so I
had some students look at a couple of
look at some look at some tools I'm
going to mention there's some rights to
fairly small studies and just to give an
idea of what's going on with some of the
tools so one student wanted to evaluate
some some automatic test data generators
and we had some constraints so they had
we wanted to try it with Java program so
that was one constraint Java classes we
wanted to we didn't want to spend money
on the tools because we didn't have any
so they had to be free so that's a bit
of a limitation and we evaluated these
by seeing mutants to represent faults
and seeing how many mutants were were
killed or how many faults were killed
and we also added a couple of test
criteria random tests stated generation
which is really really simple so she
wrote was actually partially by hand and
partially with the tool that she wrote
in a couple of days and then edge
coverage which we did by hand on the
control flow graphs of of the classes
not a really big not a really big study
but the results were interesting she
came to me with these results and said J
crasher is the best tool I said it is
there's not a lot of difference but
there is some okay but that's not the
interesting part she said what do you
mean and I said okay go add random
testing and edge coverage and she said
why and I said just just do it so she
came back a few weeks later and said
well J crasher is still the best edge
coverage did pretty well random I said
you're missing the point what are these
three tools that you got doing they're
doing exact almost exactly the same that
random test data generation is doing
right you can stand here and throw darts
at a dartboard without looking and get
the same results that these that these
three tools are doing are getting but
yet here's the simplest dumbest test
criterion edge coverage way
outperforming though six eight percent
isn't that impressive when you're
talking about finding all the mutants in
a program but it's still way better than
these so they're essentially generating
random values that's what they're doing
I had another student had a couple of
students do a fairly similar study but
with a slightly different intent they
wanted to look at different criteria so
I don't know if you know all those I'm
not gonna spend any time describing
those there's that I can recommend a an
out-of-date book if you want to read
about those and we generated tests again
for Java classes and this time hand
seeded defaults because one is that one
of the criteria were looking at was
mutation on again not a huge study and
and these were we're looking at
individual classes so fairly low level
eighty eight faults and this is what we
found so the green bars this is how many
faults out of eighty eight were found by
edge coverage edge pair all uses data
flow prime path is a way to extract a
finite number of meaningful paths from a
from a graph and then mutation and well
if you're really interested in test
criteria you've thought a lot about it I
think they actually the most interesting
thing here is this blue bar beside
mutation the blue bars represent the
number of tests that were needed and
it's actually
formalised so that they fit on the same
graph because it was it they were fair
amount more than the actual faults that
were found but the fact is we needed a
lot fewer tests with mutation and if
you're familiar that criteria that's
pretty intriguing if you're not don't
don't don't worry about that but what
this means we have some really powerful
criteria that's that's sort of the
summary so if we look at these two
studies I mean it can be compared
directly but we can sort of summarize
them together we have some test data
generators that are out there that
really aren't very good and they're all
three of those are widely used by the
way we found many dozens of companies
that are using those thinking they're
good tools edge coverage is the one of
the weakest criteria that we've ever
developed but it's much better than any
of those tests so we have a long way to
go the hardest part was generating those
test values okay and the good thing for
me out of this out of these studies is
that we need to test better and we know
how we're not using all the ideas for
how but we actually know how to test
better so that leads me to one way for
getting the test values that was the
hardest part is getting the values this
is an idea that's been around a while
called dynamic domain reduction so what
does that mean well automatic test data
generation tries to find inputs that
will be effective at finding faults
there are two two things that a test
data generator has to do it has to
satisfy the syntax requirements on the
inputs the right the right range of
values the right type I mean has to put
an integer for an integer X for example
and some semantic goals like a coverage
criterion or what it whatever you you
want your tests to do on the program if
you're a theoretician this is all these
problems are formally undecidable
so that frustrates the theoretical
people a lot I don't think it matters to
somebody wants to test software the
syntax depends on the kind of level
we're testing so satisfiying syntax
requirements for unit testing is very
different than force for system testing
right we have well-defined parameters
for methods for method calls in a class
but we have a very different input
language for something like PowerPoint
semantic goals also can vary from I want
to some random values maybe I want
special values or invalid values or I
have a test criterion I want to satisfy
I'm going to talk about this one method
that is really applied for unit testing
to satisfy some test criteria and this
work act this research actually started
way back in the late 70s with Fortran
and Pascal individual functions with the
method called symbolic execution which
has now used quite widely and compilers
for things like optimization and they
would create constraints that described
values and then use something like
linear programming to solve those
constraints so this worked pretty well
on very small functions and usually
didn't quite satisfy something as simple
a statement coverage and I don't know if
you can probably can't read this but if
you want to look at the slides later
those are some references to some early
papers I think the first one I found was
1975 so this started a while ago then in
the early 90s we came up with some
better techniques some heuristics for
solving the constraints instead of the
lp solvers which has some really severe
limitations some some better algorithms
that were called a symbolic evaluation
instead of execution it's a kind of a
subtle difference that led to allowed us
to test larger functions edge coverage
got easy data flow we started we started
them pretty well on that and reasonably
reasonably good on on mutation this is
actually when I came into this research
area as a PhD student then later in the
90s we developed an idea called dynamic
symbolic evaluation now there's that
there's that concept called calc which
is the same idea but a new idea
something combination of concurrent and
symbolic I think that's that you may
have you may have heard that name and
then a technique I'm going to tell you
about called dynamic domain reduction
which solves the constraints
in a fairly effective and efficient way
and this allowed us to handle things
like loops which we couldn't before
arrays pointers anytime you put things
on the stack and give very high mutation
scores so these other test criteria were
solved pretty easily and now we actually
give very high mutation scores
so let me I'm going to talk about
dynamic domain reduction but the thing
that's happening now in this area is
people looking at using search based
procedures like genetic algorithms etc
those have promise and I'll tell you why
in a second they're based they're a lot
simpler it's they may scale higher but
they haven't actually they're doing
about as well as these techniques did
right now so they haven't they haven't
really gotten gotten that solidly
good-good yet so let me walk you through
dynamic domain reduction the the problem
with the previous techniques before this
is that they would get these systems of
constraints that would explode very
quickly and reasonably large computers
would start to run out of virtual memory
so you were pretty limited in the size
of the methods you could you could test
because it would this systems of
constraints that describe the test we
needed were described completely though
dynamic domain reductions says instead
of keeping all that can instead of
generating all the constraints than
satisfying them we're gonna satisfy them
on the fly so it's a it's a more dynamic
approach so for each input variable we
define some input domain so that's the
the the range of values that it needs to
have okay so for an integer maybe
negative max sent to max sent or 0 to
100 depending on depending on the
problem then we pick a test path so
instead of solving all test paths at
once we solve one test path at a time
then we walk through that path
symbolically evaluating it and at each
step instead of keeping the constraints
we use the constraint to reduce the
domain of one or more of the variables
and fill that constraint away that tells
us how to take that edge we hit
expressions we evaluate those with some
domaine symbolic algorithms that also
reduce the domains of the variables and
when finish if we have values we know
for certain those values will ensure
that that path is executed if it's empty
then we have to reevaluate the the path
we may have to make different decisions
let me show an example this is a really
simple example very small method that
takes three integers and decides which
one is in the middle so we start with
initial guess and we have a lot of
decisions if Y is greater than equal to
Z we go this way y less than Z we go
that way so let's let's start with our
initial domains and just to make it
simple I've centered these around 0 from
negative 10 to 10 3 3 integer variables
and let's pick a path so let's say we
want to take this path 1 - 2 - 3 - 5 -
10 so we want an input that will take
that path that's comes out of a test
requirement we have to get down to here
so how do we do that well we start with
the first branch to take this first
branch from 1 to 2 y has to be greater
than Z so we adjust the the symbolic
domains of the variables Y and Z so that
all of the possible variables satisfy
that constraint and we do something but
that's called choosing a split point so
in this case we choose right in the
middle so that both variables are
balanced with approximately the same
number of possible values so we split on
0 so then wise domain is now negative 10
to 0 Z's domain is 1 to 10 and so all of
the values in here will ensure that I
take this edge that's a guess right we
chose a value to split on and it may
have been a wrong choice so if we get to
the bottom we don't have any solutions
we have to go back up and we make a
different decision so this has some
built-in searching process and the
decision in the algorithm that we built
was used something called interpolation
out of numerical analysis where you
guess in the middle then halfway between
the beginning and the middle then
halfway between the Midland
you keep bisecting it until until you
find something or you run out of your an
out of effort or you run out of energy
to keep searching it doesn't always work
okay but it always terminates and if it
works we know we have a good solution so
then the next branch is two to three X
is greater than equal to Y we choose
another split point for x and y negative
five in this case
so now X's domain is reduced to negative
five to ten y's domain is negative ten
to five we choose another we take the
next stage as three to five X is less
than 0 then Z we choose another split
point leaving this domain negative five
to two negative 10 to negative 5 and 3
to 10 and then the last edge 5 to 10 is
always taken so there's no constraint or
decision associated with that so our
final result is this set of domains here
and any value from those will ensure
that that path is executed for example 0
negative 10 8 so this works when you
have paths for a relatively large number
of values will will satisfy that path
this is a very efficient algorithm when
that's true if only a small number of
values will find that path you have a
good chance of finding it but sometimes
you need to do more searching so for
example if you have a decision that says
if x equals 5 then you have to set X to
5 at that point which is a very small
domain and that may cause interference
with the other variables that it may be
compared with later ok
but you but it does eventually terminate
and it actually works very very well for
methods with 50 to 100 lines which is
actually a fairly large method by
today's standards not a system-level
technique a unit level technique ok so
this the the hard part about this and I
didn't get into the issues of loops and
pointers and arrays that makes it more
complicated but these algorithms have
ways to deal with
those again not complete not assured
that we will always find a solution but
if we find a solution always works there
very complicated algorithms but they're
actually very very powerful and I've
seen there may be more but I've seen
four companies try to build commercial
tools based on kind of similar
algorithms if not these two of them they
failed they couldn't get the algorithms
written correctly and they generate what
are essentially random values one I got
a chance to analyze very carefully on a
consulting and some problem is they
couldn't make a business case which was
lucky for Google because the founder of
agita are now works for Google and makes
funny videos that one of which you saw
yesterday and the tool is now owned by
McCabe's software and I they won't let
me they won't let me look at it there's
also a tool that Microsoft is developing
called pecks I haven't actually used
this but from the descriptions and the
research papers and like it's actually
it's very similar he's using similar
technologies but I don't know the
details the search based procedures that
are being worked on now they're much
easier the algorithms are much easier to
build so as an example that the tool
that implemented dynamic domain
reduction was significantly harder to
build than a compiler okay so this this
is not simple stuff and not a little bit
harder but significantly harder than
that then a compiler for language like
Java so but we're looking at you know
easier algorithms but but they're still
less effective the problem with this
approach is nobody's found nobody's yet
found a way to make a business model
work out of selling these kind of tools
partly because it's really hard to build
these tools so another question is that
works for for Java classes what can we
do at a sort of a higher level for
example if we want to test web
applications and generate test data
automatically I came on to this question
through an idea called input validation
testing so an input validation testing
you have some domain of inputs that the
software is expecting and you want to
make sure that
the software processes those inputs
correctly and not inputs out of the out
of that domain release it deals with
them in an appropriate matter shouldn't
crash it shouldn't return incorrect
results if you give it a value outside
of the valid range so if you're a wise
programmer you check your inputs before
you use them right and what I say wise
programmer because there are good
programmers who don't but wise
programmers do because if you don't
eventually it'll cause problems and
there's some interesting there are some
hard questions in this how do you
recognize invalid inputs and then if you
find an invalid input what should you do
with it right should you just throw it
back to the user and say I don't like
this do something different and there
are some other options you can have
that's not really really what what I'm
focusing on it turns out it's not hard
to validate input but it's really easy
to get it wrong and some of its
practical some of its really very
fundamental and here's here's something
that makes it really hard to check my
inputs and I think of this in terms of
how do we represent the input domain I
think about gold domains right a gold
domain is what we want to have and
they're often very irregular so if you
think about a credit card
what's a valid credit card number it's
more complicated than we might think the
first digit identifies the industry and
there's some digits that are valid some
that aren't the first six digits and the
lengths specify who issued the card the
final digit is a check digit so there's
a formula for all the previous digits
that should yield the check digit as its
last as its last digit and then all the
other digits specify your account a
specific account thanks for turning off
the the air conditioner I think my voice
feels better now so there if you want
interested there are more details in
that link that's where I got these
details so that's the goal domain but
what do we often see in the
specification somebody writes down well
we need you to check that the first
digit is in is one of these and the
length is
between 13 and 16 which is American
expression visa what's the common
implemented domain what do programmers
usually do I check to see all digits
numeric all digits or numeric
that's what we usually that's what most
software checks for not even not even
this thing and by the way this isn't
fully correct so if you're if you're
traveling on a military ID there are
lots of lots of websites you can't use
because I think the first digit is 7
maybe it's 2 we see the 2 or 7 and a lot
of web applications won't accept that
that number is being valid so how do we
represent these well sort of at an
abstract level our desired inputs or a
goal domain it's kind of irregular right
there are all sorts of bumps and looks
and crannies in the region the specified
domain is similar but you know they're
valid values that are not accepted and
they're in and they're invalid values
that are accepted and then we have what
programmers often do a very smooth
circle to make the software very simple
or all the digits integer which is close
but it's not exactly right so as a
tester what does that mean we have this
region around the edge of our input
domains where we can expect to find a
lot of problems and this led to led me
to this idea I call about my past
testing oh and by the way we'll also
find a lot of security vulnerabilities
here sort of an accidental side effect
that I hid that I didn't think about
until somebody pointed out to me at a
conference so what is my test testing
well if you think about when you're
using a web application we're sitting
here on my client I'm sending sensitive
data to a server my credit card number
my address
etc and it's being checked partially on
my client partially on the server right
so there's some checks in the HTML and
in JavaScript running on on my computer
if bad day 2 gets through to the server
all sorts of bad things can happen the
database might be corrupted the server
might crash or might have security
issues and the thing is what I'm doing
it
okay but they're bad guys out there who
might bypass all the checks out here
that have the ability to do that and
send malicious data onto the server and
by the way my next-door neighbor works
for the CIA and he has assured me yes
bin Laden is a Mac guy he hasn't updated
in a while it's hard to buy the newest
than those technology when you're living
in a cave but he is a Mac guy then we
have maybe these botnets or crazy people
thinking let's see what I can do and you
know other kind of dangerous people
sending malicious data sometimes on
purpose sometimes accidentally but the
point is we can bypass all the checks on
the client a lot of that's done with
JavaScript or with HTML users can turn
all that off right I can disable the
JavaScript I can modify the HTML and
what bypass testing does is it does that
to intentionally validate as many
validation constraints as possible
the first way this happened is when
we're out what one of my students was
was automating some tests of a web
application I think using HTTP unit and
came to me and said should I embed the
JavaScript in the HTTP unit and I
thought oh wait a minute there's my
input validation it was one of those
lightbulbs I thought oh you don't have
to run the JavaScript we're bypassing
all of that so this validates whether
the input validation is done well it
also checks how robust the software and
there's some security evaluation this is
not a complete security solution but
there's something there so one of the
things so the first paper was I
mentioned here I had a master student do
a build a tool and do a case study on a
bunch of on a bunch of web applications
so how does this so we'll look at the
date how does this work well first we
look at the visible input restrictions
so that's on the client in a web app
right the HTML tags especially you know
if it's a radio button that specifies
the
values that can that can come in and the
attributes right there you can specify
the length for example of a text field
those are HTML attributes that's that
restrict the input domain and then we
have checks in JavaScript running on the
client then we model these as
constraints on the input they said okay
we've specified in HTML that that this
field can only have the value 20 30 or
40 because that's what the radio button
values are so we describe these as
constraints or model those then we
intentionally violate those constraints
so instead of 20 30 40 we send in 0 or
100 and we have some rules for violating
the constraints that are sort of
mutation like if you're familiar with
mutation and it's easy to tune this to
get more tests or fewer tests right more
violations fewer violations depending on
how much effort you want to put into
your testing then these are encoded into
some sort of test evaluation framework
like HTTP unit or selenium whatever and
that framework bypasses all of these
checks right because you're not sending
it through the user interface through
the HTML you're sending it through
sewage through a call from a java
program running on your client that is
sent to the server so I had a master
student build a tool to implement this
and he came to me and said what should I
okay the tools running it doesn't do
everything we want but it does a lot of
it what should I try this on and I said
we don't need the source right no we
just need the URL to the front end of
the program I said trying on some
commercial websites and he said well
which ones and I said which ones to use
and he said well he's a bank who's
Google Amazon it's okay go try it on all
of those and as he left the room I said
oh the city owes whatever you do don't
login and he said why not and they said
well what happens if your programs
causes the bank to dump a million
dollars in your account they said well
that's that's not so good because they
come get me with me
I said yeah don't login so let me just
describe these results so start on the
right here to short at the short story
is the blue is good the red is bad so
the blue is valid responses the
some sort of invalid response and I
didn't cook this by the way I didn't
make I'm not trying to flatter anybody
Google turned out looking very very good
this was the main search engine page and
some options we didn't try Google Mail
so I don't know if that's as good Amazon
did very well our cable company wasn't
too bad my service is bad but their
software works pretty well but then if
we kind of go down here
here's his life insurance company about
70% of the tests we ran found some kind
of failure 70% this is production
software been deployed been used for a
while 70% of the tests found a problem
no matter how you measure your tests 70%
of your test finding problem is
spectacular efficiency right as a tester
you're jumping up and down I know how to
find faults in software but this was we
weren't this wasn't under test this is
way past test the details over here we
divided up into fault and failure where
the software accepted the the bad inputs
and did something with it and then
exposure where it crashed and sent a
message back that said you know error in
line 25 of program bla bla bla bla as au
as most users find that annoying and
frustrating and we go to another company
but the bad guys that's information they
used to crack into the system so that's
that's actually a really bad thing so
you know here's here's some other
examples the his bank was 12 or 13
percent of the test found errors that's
not that many except that's a bank and
he didn't login right so there are some
things he wasn't able to test so because
we didn't log in this is kind of
conservative the other thing that's
conservative about this study is we
didn't have access to the backend right
remember the Bob's discussion of
observability yesterday web applications
have somewhat low observability because
it's hard to see what happens in the
database and other back-end you know
storage artifacts memory or
long-term storage we didn't have access
to that so we may some of these us may
have done bad things that we don't know
about so they may have found actually
more false then then showed up in our
study we weren't working with the
companies we were just using their
software and found all these faults so
what this tells me is we have a lot of
really bad web app software out there we
worked with a company of aia to help
them learn how to implement this in
their process a year or so later
so they had some production-ready
software software that was finished they
turned it over to production which put
it in the right package figured out how
to deploy it and pushed it out to all
the customers and the software is
something that would notify people of
problems on a phone switching Network so
it had algorithms for who to notify and
how to notify them again the tests here
are invalid inputs and we expect some
kind of exceptional behavior not some
not just a success we did again we
didn't check the back end and we went
through six of their screens for this
software and generated this many tests
for each of the screen total of 184
tests
92 of them failed 63 unique failures so
33% of the tests found problems they
thought their finished testing the
interesting thing is the developer was
very pissed off and he spent a lot of
time yelling that nobody would actually
give inputs like this Lily didn't have
to worry about it
and the manager fix it so this is no
matter how how you count that up six you
know one third of your test founding
finding failures that's a very effective
testing okay so how do we get this so
here a couple of ideas that haven't
really got got much traction in industry
and once 15 years old ones just a few
years old
they haven't been used a lot but how do
we get there I was on a panel at a
conference a couple of years ago and we
were tasked with coming up with reasons
why some of the I
isn't testing aren't being more widely
used and we came up with these four so
lack of test education there's a there's
a guy out in West Coast somewhere
Washington State he has some small
company out there that has a that was
quoted an article as saying half of our
engineers or testers our programmers
spent half of their time testing I don't
know if that's an exaggeration or not
but that's a lot of testing effort three
he says that three-quarters of
Microsoft's time is spent on testing
there's some art some character at a
conference last year tell me that people
at his company is some search company
they look for they'll people look for
things goggle something he claimed that
they spent half their time doing unit
testing that's a lot of testing I teach
at a university in the US you know how
many US universities require
undergraduate the computer science to
study testing zero yeah and this is
something like three thousand you know
you know institutions of higher learning
a lot of computer science departments
none of them require a class on testing
what about master's degrees in computer
science zip
ya know University in North America
requires software testing to get a
bachelor's or a master's in computer
science yet these guys say that that's
all that's half that's going to be half
their job when they graduate but what do
we teach and we teach them one you know
week long lecture about about in a
semester-long class about how to test
based on books that were written 20-30
years ago so they don't learn anything
about testing in fact you know how many
undergraduate testing classes there are
in the u.s. about thirty we actually did
a survey in 205 and found fifteen and
that was I'm pretty confident it was
reasonably close there are more now
three or four being created every year
but that's still a tiny number compared
to the universities interestingly when I
asked my students on my graduate classes
how many people took a class and in
testing as an undergraduate more than a
quarter of them say they did
and guess which quarter people from
India so universities in India seem to
be teaching testing and about half of
our students of my university or
graduate students are now from India so
a lot of them actually took the class in
testing but none of the people who
studied in the US so that's one problem
we don't teach people how to test and so
they're not doing a very good job in a
lot of cases another problem is the
process when you adopt new strategies
you have to change a process and that's
really expensive especially for a big
company most of the companies that are
using these ideas are sort of small
startup companies it's really hard to
change the process especially in a big
in a big company another problem is a
lot of the tools we have are really hard
to use and people and companies buy the
tools and to three people use them and
then they get stuck on the shelf and
they get dusty what's the only tool
that's widely used for software testing
is j-unit right that I'm sure it's by
far the most widely used tool and
probably by a lot but for oddities you
actually have to know the theory you
have to take a graduate course in
software testing to use a lot of the
tools that's best poor usability so I
drive a car all the time I don't know
how that engine works why should I know
how testing tool works we have a lot of
people programming that have no idea how
compiler works why do you have to know
how a testing tool works to use a
testing tool because the usability was
designed poorly and then the other thing
you know I talked about this a little
bit with my examples we have a lot of
very bad tools tools that just aren't
effective they don't do very much but
people don't know what they actually
think they're pretty good and one of the
key technical problems is generating
those test values and very few tools
help you design or generate test values
right that's a major issue so something
like j-unit it's a box it's a very
useful box but it's a box what do you
put in that box well you put in
hopefully good tests how do you get good
tests well we do that by a very slow
process everything by hand why haven't
we seen more automatic test data
generation
well the
fools are either very weak or they're
really hard to use they're very hard to
develop and you know hedge ATAR found
out companies don't want to pay for this
they they haven't concluded that the
return on investment in this kind of
tool is worth it to their bottom line
the data that I've seen out of SDI and
this shows otherwise that that that is a
good return on investment
another issues is folks like me we want
theoretical perfection when I first saw
a guitar or agitator I thought they're
ignoring all the theory right they're
not solving all of the all of the
criteria they're just making guesses and
it really bothered me and then I looked
at the results I thought but they're
creating really good tests yeah I
thought well but they're skipping all
the theory but you know they're creating
really good tests and the engineer and
me finally said that's a good thing
creating good tests and I read that I
found this little book I don't know if
any of you all saw this the way of tests
of us let me just open this up and
randomly no an imperfect test today is
better than a perfect test someday and
most most of academics just can't accept
that that's a pretty good book you know
I'm going to throw my book away and use
this book but won't take my students
very long to read it either that's
that's good okay that's all my problems
so the testers have to understand all
this stuff and that's just too much
what do practical testers want I had a I
gave a talk last year that said those
titled testers ain't mathematicians
ain't is sort of my vernacular
from Appalachia for it or not I don't
know I don't know I don't know if you
st. Anne in India but testers a
mathematician and it's true they're not
and they don't want to be and we
shouldn't expect them or require them to
be but that process the model driven
test design process allows one
mathematician to serve a lot of testing
so you need not very many mathematicians
and the rest don't have to be so what do
we need we need to integrate eighteen
automatic test data generation with
development
the unit tests the unit level tools have
to be designed for developers and be
easy to use and they have to give good
tools but as test of Estelle's is not
perfect - not perfect tests so here's
what I think a unit level tool should
look like for automatic test data
generation first this user should not
have to know much about testing because
their programmers they don't want to be
testers second it should ignore all
those theoretical problems it took me a
while to be able to say that out loud
but I've I've made progress it should
just ignore those it's engineering right
it's not science it has to integrate
with ID so if you using eclipse it
should be an eclipse plugin I should
automate with some test framework like
j-unit or well if you have another
favorite test test framework that's fine
and the process should be finding faults
as semantic problems in your software is
the same as finding the syntactic
problems compilers come back and tell
you your syntax mistakes why don't they
tell you your semantics mistakes as well
they're not going to find all of them
because we're ignoring all these
completeness and feasibility but they
can find a lot of them very quickly
especially sort of the basic ones so
after my plat my java class compiles
cleanly or C++ if you're you know
working in the 90s then the automatic
test data generators should kick in and
start and produce tests automate them
run them compare them against an
expected value and come back and show
the results to the programmer and say
okay here's your next set of problems
that you get to deal with so then you
can start debugging it's not going to
find all the problems that's not going
to be complete but then we can move
those bars up of you know during unit
testing and move system testing job down
so we have fewer problems to deal with
at the system level at the system level
well we should be able to generate tests
based on the input domain we should pull
that out of the user interface we should
not need the source right and the test
should be automated but we have to have
a way
for humans to come in and add some tests
and I have been starting a collection of
faults I found in software that I don't
think any criteria could find and I have
a few I I'm not going to go into those
because you know next guys want to talk
soon but you have to have a way for the
humans to come in and add additional
tests for things that the criteria are
blind to if we can integrate that
together where there's a language that
human can put in test requirements that
then gets satisfied automatically that
reduces a lot of that manual effort as
well saving money so the process as soon
as I integrate my system check in
everything to the library then those
tests are created and run it should be
part of the integration tool so instead
of making the testers do all the work it
should support the testers oops
allowing them to do you know the work
that requires a human brain so here's
the sort of the global issue of test
design we have human based test design
where you have knowledge of the domain
the testing and intuition and you have
to generate values then we have criteria
base design where use engineering
principles to cover you know generate
values that cover things like the source
or requirements a lot of people go
around saying that you have to do one or
the other and the other is wrong and in
fact I did that for a while then I heard
a talk by a guy who I really associated
with human based testing I thought oh he
never makes any sense and I heard this
talk and I kept thinking he makes sense
but he's wrong but boy this talk really
makes sense but I know he's wrong and I
finally realized he's not wrong I was
wrong and maybe he was wrong because
they actually root for both so Ken
campaigner actually improved my view of
testing enormous ly by teaching me that
these are actually both he doesn't I'm
not sure if he knows that I didn't tell
him that but there's no reason to be
competitive we actually need both so to
be able to test efficiently and
effectively more effectively efficiently
we have to be cooperative with the two
and that's actually pretty pretty hard
to do so
to summarize this researchers like me we
always want perfect solutions we took
all this theory and computer science
undergrad right we had to take three
semesters of calculus four or five other
math classes at Amida theory algorithms
so we think theory is important but you
know we're teaching what's the degree
they get computer science what's the job
they get software engineering
I think we're teaching them all wrong we
need less Theory more engineering and
industry needs engineering tools and
they need engineers so we actually need
to teach more of that engineering kind
of thing and you know the bottom line is
we've got some really good ideas for
automatically generating test data it's
ready for transition and I think the
tools should be free and preferably open
source I haven't seen anybody go to that
much effort the hard part is it's a lot
of effort it's not in building J unit
for free was much easier than building
something like this that's that's a
major that's a major headache so my
contact information and you know as far
as I know this book has never been used
to make diapers and I tried to find one
in my trash can but I think it has
already been recycled so I was I think
that that Alberto really did fill my
book away because I had one okay so I'm
done do I have time for questions or I
should ask the next speakers so we will
just do a couple of questions because we
are running short of time maybe you guys
can take the questions later offline
yeah Jeff so automated test data
generation mutation and data constraints
these are essential parts of fuzzing and
most of fuzzing is always done at system
level rather than at a unit level so I
would like to understand how your
concepts of best data generation
mutation etc translate into the fuzzing
domain that's that's an interesting
because the ideas of fuzzing they've
been around for four years I mean
they're its it comes out of turn out of
the concepts we've had for things like
mutation and general rules for violating
the input domains right into n valid
values stress testing things like that
and suddenly there is this term fuzz
testing nobody knew the previous ideas
but suddenly everybody knows fuzz
testing so what's there I mean that's
what fuzz testing is it's using these
ideas but it's a it's a kind of a cooler
term right
just like the ideas for j-unit I mean I
was having students build projects like
that in the 80s it's class projects not
a sophisticated a you know mind you but
the same the same basic idea and they
weren't being used until somebody came
up with this really cool name and they
started marketing marketing it heavily
called J units so so yeah that's that's
what fuzz testing is incan colleague
testing is the same ideas of symbolic
dynamic symbolic testing with with a
little bit of tricks that they use some
assertions in a slightly different way
and it's actually works better than some
of these ideas develop more recently and
so fuzz testing is associated with con
colic testing as well but it's the same
way it's the same thing yeah the reason
I asked this question is that what you
demonstrated in that the flow of the
code is known so that the data
constraints can be known and then you
can come up with the efficient test data
in fuzzing only the protocol which the
data follows is known not the code which
is going to process that the way you
demonstrate it about web applications we
don't know what is happening on the
other side so I was under trying to
understand that how our concepts are
automated test data generation your
algorithms could help in automated test
data generation when only the protocol
is known for example you could do
network protocol fuzzing you could do
file fuzzing so is there any translation
is there any research work done on that
well the fuzzing actually looks a lot
more like but like the bypass testing
ideas then the dynamic domain reduction
you're right you need to you need
some structure like the code for that
but but the bypass testing you don't so
the the fuzzing is is semi formalized
rules for for creating for creating data
if that can be encoded in something more
specific with rules for what what the
values look like which is not hard and
I've seen a couple of papers that
actually did that then it those are
rules that you can start to embed in a
tool and create the values and so there
are ideas and fuzzing that that aren't
in the papers that we have on bypass
testing but they can they can be used in
exactly the same way and there's I'm you
can also have some randomization where
you have some rules where I take a value
and I randomly change it in ways and
that's sometimes that can be very
effective and in fact agitator did some
of that when it was having trouble going
down a path it would randomly change
some of the values that got close to the
path that wanted and often get down that
path and then there are search
procedures that actually do that in more
clever ways that use the path
constraints as as part of the
optimization functions which part of the
part of the solution for things like
genetic algorithms
so he's asking these techniques where
the expected results come from that's
actually pretty hard some of those
you're gonna have to have a have the
person decide there's a fair amount of
research going on right now to see if
with these kind of techniques at the
unit testing level can I come up with
expected output or at least approximate
expected output
but that's a problem that has not been
fully solved at the bypass testing level
it's actually much simpler to to come up
with expected output because the
expected behaviors you get a message
that says something like this values not
bad
but at the data at the unit level that's
that's much harder yeah
failure was either not getting a 4-3 or
not getting a message that said your
data was invalid so it behaved as if it
was normal behavior as if as if it was
valid data that was a that was invalid
behavior was there another question
should we go on okay
okay okay well again thank you all for
having me and I'm looking forward to
resting</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>