<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Generating Trading Agent Strategies | Coder Coacher - Coaching Coders</title><meta content="Generating Trading Agent Strategies - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Generating Trading Agent Strategies</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YU9M2rjpDXY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">please publisher Michigan we just
conditions be able to see the plank
movement on Annie Palmer's of game
theory and he's going to be talking
about Thomas thesis work quick that mean
thanks for good okay so you're all
presumably here to learn about how to
generate trading agent strategies I'm
going to spend most of the time on
analytic methods for infinite games but
also tell you about the empirical
methods for large games everything I'm
presenting today is joint work with my
advisor Mike Wellman and there are some
pieces especially towards the end when I
talk about the the killer app for all
this trading agent strategy generation
methodology the trading agent
competition there are several teammates
and co-authors for that work okay first
the big picture my grand research vision
and the ultimate goal of my thesis work
is a strategy generation engine that
reads in a description of a game
consisting of game rules and a
distribution from which private
information is drawn and it outputs a
strategy which is a program that takes
actions based on private information and
observations about the other agent
actions so in a sense the goal is a
program that writes programs that play
games and then although I'll focus
almost entirely on games that involve
auctions of one kind or another the
framework is applicable to more general
kinds of games but before i say more
about games let me say what i mean by a
game it's really any circumscribed
interaction between multiple agents
where each agent is trying to maximize
an objective function that depends on
the interplay of the agents actions the
agents here are captured by their
strategies that's the output of the
strategy generation engine and I've
depicted here one shot game in a
multi-stage Game agents perform actions
and then learn something about the other
agents actions and then that becomes
part of their information before
performing the next action the whole
eventual action history plus the private
information informs the payoff function
and we assume a finite number of rounds
by by infinite game I'll mean that there
are an infinite infinitely many paths
actions for example bidding a real
number if there's any inherent
randomness in the game that's captured
by a dummy player nature the players
private information is also known as
their types or preferences for example
in poker your hand is your type in an
auction it would be your valuation of
the good being sold the output of the
payoff function is of course the payoffs
of the utilities of each player so agent
who not fare so well here if an agent
only has one possible type than it that
would be called a game of complete
information but in general we're talking
about incomplete information games this
captures the case that I may not know
what your payoff function is but we
assume that if only I knew your private
information then I would know so we
always assume that the global payoff
function as well as the probability
distribution from which the types are
drawn our common knowledge with an
common knowledge is actually a Harrier
assumption than it sounds if you're not
sure why ask me about blue eyed monks
afterwards but otherwise this can be a
quite realistic model of real
interagency legion interactions I'm
mostly talking about artificial agents
but this can be applied to humans too
and in fact game theory is even useful
in biology in that case not so much for
advising clever squirrels on hoarding
strategies but but as describing evolved
strategic behavior in nature okay a few
more key definitions my my best response
strategy is my optimal strategy the one
that maximizes my payoff if I knew
everyone else's strategy Nash
equilibrium is just a profile of
strategies that are each best responses
to the others Nash himself proved that
for any finite game as long as players
can use mixed strategies that is
randomized between their actions then at
least one Nash equilibrium must exist
Abbes Nash equilibrium is the natural
generalization where players are
simultaneously maximizing their expected
payoffs given the strategies and the
known type distributions of the other
players by expressing a possibly
multistage game by enumerate apostle
strategies any game can be converted
into a one shot
name of complete information and that's
called the normal form of the game and
finally almost all the games I've
studied are symmetric and that means
that ex ante before the types are
determined all the players are identical
for example we might assume that there's
nothing to distinguish different poker
players until the hands are dealt a
symmetric profile is simply a
homogeneous one all agents play the same
strategy which in a symmetric game we
might well expect they would symmetric
equilibrium then just refers to an
equilibrium profile that's symmetric
Nash also proved that symmetric games
have symmetric equilibria and one last
definition the epsilon of a profile is
how much better I could do by playing my
best response to the profile instead of
what the profile actually dictates so
that's 0 if and only if the profile is a
Nash equilibrium and it gives us a
measure of how far from equilibrium we
are otherwise any questions about any of
these game theory concepts I'll move to
the meat of the talk okay here's what
you've really come form I'll first
described my analytic approach to
generating best response strategies in a
class of one shot to player infinite
games of incomplete information and use
that to find Nash equilibria and that
works for many simple games i'll give
you examples of those for more
complicated games i'll describe the
empirical approach and it's applicable
to two monster games in particular the
trading agent competition and
simultaneous ascending auctions I'll
talk about those briefly at the end so
here's our class of two player one shot
infinite games of incomplete information
the type distributions must be piecewise
uniform so that captures pretty general
type distributions the payoff functions
of my type and my action and the other
agents type in the other agents action
are of this particular form where these
Greek letters are all parameters so that
class of games turns out to be pretty
general and captures really most to
player 1 shot games that you can think
of by appropriate settings of those
Greek letters I here are the parameter
settings for a host of games some
well-known like first price and second
price sealed bid auctions and a
we made up namely the shared good
auction and joint purchase auctions I'll
describe those shortly okay so games can
now be described by a set of parameters
and if we also specify a piecewise
linear strategy like this and remember
in a one-shot game a strategy is just a
mapping one dimensional mapping from
from type 2 action then we're ready for
my main result for this game class okay
namely that for payoff matrices of this
form this parameterize form along with a
specified type distribution and a
piecewise linear strategy of this form
oops then we can compute in polynomial
time the best response strategy and it's
also a piecewise linear strategy so just
to give you the barest taste of what the
the proof of that theorem is like we
have a function that gives our payoff in
terms of our type and action and the
other agents type right we're assuming a
known strategy for the other agent the
other agents type is a random variable
from a known distribution so we need to
find our own action expressed in terms
of an arbitrary type for ourselves that
maximizes our expected payoff or
maximizing that expected value so in the
complete information case you could then
apply any kind of numerical maximization
technique and get your best action but
here we end up with this nasty
expression involving T but it turns out
that the optimal action is always linear
and T in any T neighborhood so if we
partition the type space in the right
way we end up being able to express the
optimal action as such and such linear
function of T if T is in such and such
rage and such and such other linear
function of T if using some other range
in other words it's the best response
strategy is piecewise linear and it
looks like like this sorry like this so
the great thing about this is that it
means that we can now iterate this best
response procedure and from from some
arbitrary seed strategy and if we're
lucky enough that it converges in other
words reaches a fixed point then we have
a strategy that's
that's the best response to itself and
is a Nash equilibrium so so the
theoretical result is the best response
finding showing that the best response
to peace under strategies is piecewise
linear so so let's apply this to do some
simple games a very simple example of a
game in our class kind of the canonical
example is a first price sealed bid
auction so in this game the players
types are their independent private
valuations we'll assume they're drawn
from uniform 01 distribution and the
actions are the bids so your payoff is
your valuation minus your your bid if
your bid is higher and nothing if your
bid is lower and the winner is chosen at
random in the case of a tie in that case
it's the average of your type Minister
action your valuation minus your bid or
0 so this game has a well-known
equilibrium of shading your bid by the
 your bid down by the number of
players so in the two-player case did
one half your valuation that's the the
unique symmetric Nash equilibrium
strategy and my algorithm finds that
equilibrium by computing iterated best
responses from most seed strategies for
example the best response to truthful
bidding where you just did your
valuation is in fact this Nash
equilibrium here's another game that we
call the supply chain game so we have
two producers in in series a consumer
that we're not treating as an agent that
only two agents are these producers they
each have the option to produce the
output in their piece of the supply
chain if everyone does if both these
producers produce their output then the
final output of the supply chain is that
G to which the consumer values at V and
will pay anything up to vie for it so
the way the game works is that the
producers submit a bid saying how much
they want to receive if they're going to
produce their good as long as the sum of
their bids are less than or equal to the
consumers value V the this all goes
through the good gets produced and the
payoff to the producers is the bid what
they get assuming that the the deal goes
through if the sum of their actions is
small enough minus their cost which is
private
information to them okay so this game
was studied in a paper on supply chain
formation by Bill Walsh and others and
they proposed a general strategy for a
broader class of supply chains than then
this simple one but for this simple game
their strategy works out to do this and
as you can see it has this nice
piecewise linear form so we can feed
this this published strategy to my best
response finder and we get the strategy
in blue and after a few more iterations
of best responses we seem to be
converging to this green strategy which
is actually an equilibrium that that
after that original paper on supply
chains was published Bill Walsh and I
thrived this green equilibrium by hand
for this game and our algorithm of
course if you put in this strategy it
confirms that it's an equilibrium as it
must but that's not the equilibrium that
we converge to when we start from that
initial seed strategy from Walsh and
company rather we end up with this
asymmetric equilibrium which is
basically the pair of strategies in
which we each ask for half of V
approximately unless that's not enough
given our cost in which case we just
kill the deal so it's pretty easy to see
that that's an equilibrium if I know
that you're asking for X then I might as
well ask for V minus X anymore and we're
both going to get nothing right V are
some of our actions has to be less than
V for us to get anything at all and if
you're asking for X any less than V
minus X and I might as well have asked
for more so so in fact there's a
continuum of equilibria of that form
although the iterated best response
procedure here does always seem to
converge to reasonably fair ones where
both agents ask for about half here's
another game this comes under the
heading of public good or provision
point mechanisms I'll describe a variant
that seems not to have been solved in
the literature before namely two agents
want to jointly acquire a good that cost
C for which they have private valuations
they submit a sealed offer and the good
gets bought if and only if the sum of
the offers exceeds that cost C in which
case the excess is split evenly and
given back
there are variations where the agents
don't get the excess back that's just
lost or where they don't get their
contributions back at all they submit
their offers and if it's not enough
they're out of luck that's called a
contribution game okay both of these
both of those last two variations are in
the literature and they have very
different equilibria from from this one
this one actually is very similar to the
the well-known equilibrium for the
bilateral bargaining game also called
the sealed double auction which my
algorithm also finds I talked about that
in the paper and I wanted to mention
I've suggested that most to player 1
shot games are that are in this class of
games we're dealing with with this
particular parametrized space of games
of payoff functions but one potentially
useful one that isn't is a variation on
this where instead of splitting the
excess evenly we split it in proportion
to how much we contributed which is
arguably a sensible thing to do but that
game that variation on this we cannot do
so this is just the one that's because
that introduces some nonlinearities and
that in the path of four types and
actions but for this one we we can solve
it and this is the Nash equilibrium of
this game two-thirds your type plus C
over four minus the sixth so now suppose
that we've we played that game and
jointly acquired some some good but now
one of us is leaving town and we can't
split the good in half so we need one of
us to buy the other out so my friend and
colleague Kevin Lochner and I first came
up with this this game to to decide
which of two roommates should get the
the big bedroom and for how much more
rent that person should pay and since
then we've actually used it multiple
times to to allocate undesirable tasks
for which we both had joined
responsibility it's they're actually
pretty useful mechanism it's it's kind
of like flipping a coin but more
economically efficient okay the auction
rules specify that each agent submits a
sealed bid as usual and the high bidder
gets the good but pay
half their bid to the loser in
compensation so that's how the mechanism
works it was designed such that if you
played truthfully the surplus would be
split evenly but playing truthfully is
not in fact a Nash equilibrium but we
can find it using the best response
solver we can give truthful bidding as
as a seed strategy and this is what
happens it's to essentially shade your
bit down two thirds of the way to the
lowest possible valuation and this is
assuming uniform distribution on the
private valuations between a and B so
there's a picture of it so of course the
nice thing about having this game solver
for for humans using these mechanisms is
basically we're leveraging the the
revelation principle and playing the
modified game where agents submit their
true types to the game solver so this is
this kind of meta game that has the
solver wrapped around it which then
plays the Nash equilibrium on their
behalf so two people playing the shared
good auction assuming that they believe
the type distribution can simply submit
their true types without strategizing at
all and this also mitigates the problem
that that we have no guarantee that the
equilibria that the game solver finds
are unique but since the game solver
finds this particular one that makes
this one focal and if the new mechanism
is you submit your two types and it's
going to play this Nash equilibrium then
by nature of Nash equilibrium no one has
an incentive to deviate from that by the
way the plotted points here are with
their bars are simply from verifying the
analytic results with Monte Carlo
simulation but I won't say any more
about that now one other game I wanted
to mention is a variant of the the
Vickrey auction the interesting thing
about a Vickrey auction or second price
auction it's called that because the
winner pays the second highest price is
that truthful bidding as a dominant
strategy dominant just means that it's
your best response to every other
possible strategy so reassuringly my
game solver returns truthful bidding in
the in the usual Vickrey auction for
every possible seed strategy but the
variant is called vicious vicious
victory because it adds a terms
payoff function for my utility for your
disk utility so say we're competitors
business competitors and I don't want to
only maximize my profit I I want to
minimize yours right so so now I want to
bid possibly more than my valuation in
hopes that if I lose I'll at least force
you to pay more than you would have
otherwise okay so this turns out to be
the the equilibrium for for that game as
you can see with and this K is a
parameter that says how much I care
about your disutility so so one special
case is the usual Vickrey auction where
K equals 0 I don't I only care about my
own profit I don't care about yours at
all in that case now you can see that
bidding your your type is what falls out
of that and once again my iterated best
response Oliver can find that
equilibrium for specific values of K I
should mention okay to conclude the
first part of this presentation we have
an algorithm for computing best response
strategies in a broad class of two
player infinite games of incomplete
information used it to confirm many
known equilibrium in the literature many
known equilibria in the literature
concert confirm some that we've derived
by hand and discovered equilibria new
games like in the joint purchase and
shared good options the most interesting
and useful aspect of this is of course
not the actual best response finding
though that has its uses for example if
you have a particular strategy you think
that the opponent's going to play or for
automating the proof of that a certain
strategy is a Nash equilibrium but the
real win here is iterating this to find
Nash equilibria from scratch and it
remains a goal to cat to characterize
that class of games may or may not be
our entire class too in other words
characterizing when that process really
will converge because it's possible that
it won't okay what about games that have
more than two players or have multiple
rounds in other words most realistic
games I call them monster games because
they pretty much they're pretty much
untouchable by my standard game theory
for it
but we're not going to find the Nash
equilibrium of the full game of poker in
the foreseeable future although Nash
himself and others have have solved
highly abstract adverse of poker or the
problem of bidding in multiple
simultaneous auctions which is a problem
we've looked at in a couple domains
another one might be you know bidding
for a set of Google AdWords example
bidding in multiple simultaneous
auctions so i'll show you my general
empirical game methodology kind of a
collection of computational techniques
for finding good strategies and games
like that for all of these i'll use a
simple first price sealed bid auction
again as an example and to help verify
the methodology broadly there's several
parts to this methodology i'll focus on
the first few the first is about
determining a set of candidate
strategies that is restricting the
strategy space this is the most drastic
way in which we can cut monster games
down to size the next is game simulation
estimating the restricted game going
along with game simulation i'll talk
about standard variance reduction
techniques for monte carlo sampling in
particular the method of control
variates for which we've done some some
controlled experiments with first price
sealed bid auction FPS b and also
applied in the trading agent competition
player reduction is a kind of complement
to reducing the number of strategies and
it's another way to radically reduce the
size of a game to make it more tractable
and without generalizing generally
without generally sacrificing too much
in terms of solution quality once we
have an empirical estimate of a game we
can apply various off-the-shelf
techniques for solving it I'll mention a
few of those and finally I'll briefly
talk about a couple methods for
assessing how well the solutions how
well the solutions to the empirical game
approximate solutions to the underlying
game of interest and I'll focus on toy
examples and and then talk about the
monster games at the end so let's start
with our old friend FPS b which is by no
means a monster game in fact it's
unsolved as we know but it has infinite
type in strategy spaces and non-linear
payoff function
and so it has many of the attributes of
games that are analytically intractable
so it's going to serve as a good as a
good test case so I've already described
the game this is the the two-player case
the generalization to end pyres is very
straightforward we all all end of us
submit a bid the winner pays their bid
this time the the Nash equilibrium is to
to play n minus 1 over N times T that's
that's the one half t in the two-player
case for our purposes now we'll pretend
that we can't deal with such a rich
strategy space as all the as all
functions from type 2 action right all
one-dimensional functions on 0 1 so we
restrict the strategy space by imposing
the constraint that strategies must be
of a particular parametrized form ok in
general the way we do this is to pick a
baseline strategy and introduce
parameters that generalize it for FPS be
the most straightforward strategy
although worst possible strategy without
actively throwing money away is truthful
bidding just bidding your valuation that
guarantees you zero surplus but if we
generalize that strategy with a shade
factor K then the strategy space now
actually includes the real Nash
equilibrium and minus 1 over N times
times the type if we didn't know that we
could have also included say a
translational parameter B or allowed a
piecewise linear strategy with some
finite number of pieces and those are
all ways to come up with a finite set of
parameters to generalize the baseline
strategy ok but the point is even if the
baseline strategy is awful as is the
case for F guess be as long as the space
of strategy is allowed by the
parameterization includes include
smarter strategies and they need not be
identifiable as such a priori then our
methodology has hope of finding them so
as we'll see introducing a shading
parameter and FPS be without knowing a
good setting for it allows us to
approximate the unique symmetric Nash
equilibrium of the game first I'll
quickly show some theoretical results
for this restricted version of FPS be
with shading before showing how we
manage when the games are too
complicated to admit any analytic
results at all
first we derived a closed-form
expression for the expected payoff for
arbitrary symmetric profiles and
unilateral deviations so this is my
expected payoff for playing case of I
when everyone else is playing k remember
k is how much you shade your bid okay
maximizing that with respect to K sub I
gives us a closed form expression for
the best response my best response if
you're all playing k we're that C is an
expression of N and K anyone want to
guess what that looks like starts with a
cube root of n ah yeah so anyway from
but from this from from this last term
here we can see you know bidding have a
K of N minus 1 over N is a best response
to itself so we can see that also we
that the best that the Nash equilibrium
in the restricted game is the same that
you know we've captured it it's also the
equilibrium in the unrestricted game
where you can play any strategy any
function from type 2 action and with a
bit more effort we can show that that's
unique symmetric equilibrium just as it
is in the in the unrestricted game we
also derive an expression for the
epsilon of an arbitrary symmetric
profile and remember that epsilon it
just means the the greatest gain I can
achieve from deviating from a certain
profile all right this is if everyone
else is playing the symmetric profile k
you're all shading your bids down by k
then that monstrosity tells me exactly
what I should get in response to that
and these seas are again that at crazy
expression from the last slide so so
that's a little ugly but but we've got a
closed form expression for it so those
results are nice for for comparison but
we can't get those any kind of closed
form results for the real monster games
so instead the next step is to further
restrict the strategy space by
discretizing the parameters so here I'm
discretizing the strategies in the four
player restricted FPS be gained by 40th
yielding 135,000 some strategy profiles
right we could all fit truthfully or I
could be truthfully and you could shade
down by a fifth then you can shade down
by forth all the possible come
nations of those up to symmetry I
simulated 100 games for each strategy
profile to construct the empirical
payoff matrix which we typically
represent this way each column is it is
a specific strategy profile this is a
much smaller version than the one with
135,000 profiles which is a little hard
to read this this graph here shows the
epsilon for each symmetric profile based
on that empirical payoff matrix the one
that we gathered from 100 hundred
samples per profile okay this this is
enough to see that there's likely an
equilibrium somewhere around point seven
something right where remember that when
epsilon is zero that's a Nash
equilibrium if we overlay the exact
results from the previous slide the
closed form expression we can see that
this is in fact giving us a reasonable
idea of the solution to the underlying
game and by the way if you're wondering
why all the plotted points are always
above that exact epsilon anyone I don't
know if that's obvious to people that so
the reason is that the empirical
epsilons are based on having based on
the sampling noise from the hundred 100
samples so since the epsilon calculation
takes the max of a bunch of these noisy
estimates it's typically going to find
one that's anomalously high and that's
why I all those will be above the true
the true epsilon ok and I'll talk about
reducing sampling noise next but to get
a more accurate estimate of the solution
to this game using just brute force
Monte Carlo I just upped the number of
samples to 36,000 and at this point we
still actually can't estimate the unique
symmetric Nash with with very high
fidelity but it's clear that anything
you know in this in this range here is
going to have very low epsilon in in the
underlying game so it's going to be very
close to an equilibrium Chloe and in the
sense that i'm saying close in the sense
necessary of proximity to the actual
equilibrium but close in and how much
you could gain by by deviating that's
that you have an epsilon equilibrium
okay so this brings us to variance
reduction the idea of control variance
which is a standard technique for Monte
Carlo simulation is to adjust the
sampled payoffs for lock for example an
FPS be we expected an agent's evaluation
correlates positively with its surplus
if my valuation for the good is very low
then then there's very little chance for
me to make very much profit if it's
worth a lot to me there's the potential
that I can get it for cheap and make a
big profit so the higher my valuation
the higher my expected surplus so what
we do is just bump up an agent's payoff
when it has a low valuation or type and
scale it down when it has a high
valuation such that these positive and
negative adjustments average out to zero
then by sampling these adjusted payoffs
it will tend to take fewer samples to
converge to a good approximation of the
true expected payoffs and for any
exogenously determined estimation
function g and i'll explain exactly in a
minute the average of the of the
adjusted payoffs will always be unbiased
and it'll have less than or equal to the
variance of the unadjusted samples so
for f gisby we can drive a sort of best
case control variable namely the exact
expected payoff for an agent of type T
as a function of T playing strategy k
against an arbitrary set of other
strategies and that's what these
expressions given that there's some
special cases I've left off but the
point is we can drive that analytically
for this for this game and so of course
in more complicated games we we're not
gonna be able to drive anything like
that analytic result but instead we can
estimate a function using machine
learning methods so for for FPS be with
one-dimensional types that's very
straightforward for example we can just
use linear regression but in general
with multi-dimensional types including
other sources of randomness in the game
it may not be obvious at all how the
random elements influence the payoffs in
fact the dimensionality doesn't have to
be very high at all before it becomes
very hard to empirically determine
meaning
relationships between types and payoffs
for example imagine a game involving
bidding for many goods with with agents
type being a vector of their valuations
for all the goods so depending on the
specifics of the game we might expect
that the sum or the max of the vector
evaluations to correlate with with
payoff it would take a pretty
sophisticated learning algorithm with a
lot of data in other words lots of game
simulations to rival the simple simple
linear regression from the max valuation
or the sum of evaluations to pay off so
in other words when we have some
sufficient domain knowledge such as
knowing that the summer the max is a
good summary statistic we introduce
control variates manually and we've done
that for for the the training agent
competition and some of the monster
games I'll mention at the end okay
returning to our fpf PSB example this
graph just gives a visual sense of the
adjustment via control various these are
CDF's so the more squished together it
is that the less variance just in the
interest of time all kind of glossed
over this that you you get the point
that introducing these control variates
reduces variance this is the kind of
best case control variate for ref PSP
the analytically determined one and
actually we can even use the for every
single sample knowing the types we
actually have a closed form expression
giving exactly what the expected path is
so so we can apply that in 12 area in
the course that well nail the the true
expected payoff every time so I was just
kind of a sanity check to put that one
there okay so this is the unadjusted one
here I'll leave it at that and just
mentioned some other variance reduction
techniques that we haven't done these
kind of controlled experiments with so
far but we expect them to be a big win
in game simulation so so just to mention
them in case anyone's taking notes on
how to apply this methodology to your
own monster games Kwazii random sampling
and importance
playing are ways to tweak the
distribution of types that you're
sampling from to reduce variance in the
sampled payoffs adaptive techniques
combine various methods and adjust the
parameters for them automatically as you
as you get samples implementations of
all these techniques are available as
part of the new scientific library and I
also refer you to my forthcoming paper
on how to deal with nature when applying
these results remember nature is this
dummy player that we use to introduce
other elements of randomness in the game
okay the next method for taming monster
games i call player reduction and the
idea is very simple we can approximate
an end player game with one of say and
over two players where each player in in
the new reduced game gets to pick a
strategy for two players they pick one
strategy for two players to play in the
original game or in general reduce it by
down to pee players and q is n over P
here so since Game size is exponential
in the number of players this this can
drastically cut an impossibly large game
down to size and we'll see it was
critical in the trading agent
competition to do this now that's an
eighth player game before reduction so
another question is whether the reduced
game bears any similarity to the
original game and of course in the worst
case it won't we can make up
pathological examples where the payoffs
vary in any kind of erratic way you can
imagine but our hypothesis was that for
any that for many natural games the the
degradation would be graceful and that's
borne out for FPS be this is for player
FPS be with the Nash equilibrium
three-fourths and that's the epsilon for
other strategies if if you just consider
the two-player version of it instead
that has as we know an equilibrium of
one half those the epsilon is in that
game if if playing the equilibrium in
the two-player game was your
approximation and see your you have a
pretty lousy epsilon in the true
underlying game
this is the four-player game reduced to
two players that you play a reduction we
don't have a closed form for the epsilon
so we do have a closed form for the
fourth at equilibrium that's sorry
that's the equation there but the point
is that both in terms of epsilon and in
terms of actual proximity to the
equilibrium we're much better off with
this this two-player reduction than the
actual two-player game and we have some
theoretical results to generalize that
to any number of players so we proved
that in FPS b if you have an end player
game but computational you can only
handle p players then you're better they
are always better off with the p player
reduction than the actual p player
version both in terms of absolute
closeness and epsilon n for FPS b
solution quality degrades monotonically
with more severe player reduction so
those are reassuring reassuring results
for FPS b but of course we don't
actually need to approximate FPS b we
can solve that for any number of players
so to further evaluate the quality of
this reduced game approximation we turn
to other natural game classes of
potential interest local effect games
fall into the category of congestion
games for example deciding what roads to
take when when you have to trade off
taking the most direct route with the
possibility that many other agents will
choose the same and the right will be
slower henst congestion so just to
summarize the conclusion player
reduction does does well approximating
games in this class as well and again we
find that the solution quality degrades
gracefully with the degree of reduction
and i'll discuss player reduction in the
context of the trading agent competition
shortly it was very critical there in
getting any kind of strategic handle on
that game okay everything so far has
been about estimating an empirical game
once we have that we have a standard
normal form game with a finite payoff
matrix and we can apply any standard
game solving techniques just to mention
the one we once we've used gambit is
considered the state-of-the-art solver
for finite games but it doesn't explain
symmetry so it often blows up on games
that are otherwise very solvable
replicator dynamics is one one that does
and this idea of using replicator
dynamics is not new to me and my
colleagues in fact it's originated as a
model for for how animals evolve towards
Nash equilibrium strategies but we're
the first to our knowledge to apply it
as a solution technique for large games
just briefly the ideas you create a big
population of agents initially here we
have five strategies labeled 16 through
20 they're initially represented equally
in the population 150 each each
generation you take a random sample from
them play them against each other and
then adjust their proportion of the
population in proportion to how well to
what kind of payoff they get so and the
nice thing about this is if this reaches
a fixed point the populations become
stable an evolutionarily stable strategy
profile strategies is a Nash equilibrium
is that corresponds directly to a mixed
strategy Nash okay finally the last
phase of our monster game taming
methodology is assessing the solution
quality with respect to the von der
Leyen game of interest or at least with
respect to the exact restricted game
after reducing the strategy space and
possibly the number of players so to do
this we we first need to estimate a
distribution representing our belief
over the space of possible payoff
matrices because the the payoff values
we get are based on simulation and so
there's there we have confidence
intervals on those so I won't go into
how we do that but we come up with a
distribution for the payoff matrices
based on that sampling data and then one
method of sensitivity analysis is to
just see if enough samples from the path
matrix distribution all yield the same
equilibrium in which case we can
conclude that our equilibrium results
must be fairly robust to sampling noise
so one way to operationalize that is to
repeatedly sample payoff matrices
compute one or all of the symmetric
equilibria and then observe the
empirical distribution of those
equilibria and so that's what what this
represents here these are CDF's on those
mixture probabilities from this game
here so we can see that for this
particular exact payoff matrix
um the the you know our max likelihood
payoff matrix in other words what we got
from actually sampling has you know 16
ending up with point seven something in
the population this tells us that
there's you know some some non
negligible confidence interval around
that we can do the same exact thing for
for epsilon sample from the payoff
matrix distribution compute the epsilon
of a particular profile so so this is
just a histogram of those those epsilon
this is from a different game but we can
say looking at this fifteen percent of
this probability mass is at zero that
means there's based on the sampling
we've done so far this profile has a
fifteen percent chance of really being
an equilibrium and maybe that mean
that's we want to do more sampling to
become more confident that's an
equilibrium or maybe it's good enough
that the epsilon is very likely to be
less than 400 in this game this is four
hundred dollars in the trading agent
competition which actually is pretty
significant so we probably want to do
more sampling here okay so to conclude
the the monster game taming methodology
portion before and then I'll just
mention briefly that the real killer
apps of this that the trading agent
competition especially we're restricting
the strategy space we're reducing the
number of players we're simulating game
outcomes and we use the that's where we
use the variance reduction techniques to
speed that up drastically then we
analyze the empirical game and then we
assess the solutions to the underlying
real game okay so so on to the the real
application of monster game taming we we
meeting our research group my advisor
and I on another students created the
trading agent competition travel
shopping game in two thousand and it's
been growing ever since it's the whole
research communities built up around
this a large body of literature it's
it's a really interesting domain for
testing out trading agent strategies
starting in 2002 the swedish institute
of computer science took over the actual
running of the game and so we've been
competing in it ever since the game pits
eight travel agents against each other
all trying to put together travel
packages for hypothetical clients does
anyone know about the trading agent
competition already other than John Oh a
couple people okay so i won't get into
the interest intricacies of the game
except to say that there are 28
simultaneous auctions that the agents
are bidding in auctions of various
different types flights hotel rooms
entertainment tickets one of the key
strategic issues is the strong
complement complementarity between the
hotels if you have a client staying in
the towers that's the hypothetically
nice hotel on day one and they don't
leave until day 3 then then that first
room is useless to you unless you also
get a room in the same hotel on day two
you have to keep your clients in the
same hotel for the length of their trips
so that introduces complementarities
between these goods and actually it's a
bit messier than that since you may be
able to shuffle your clients around
shorten their trips if you haven't
bought their flights yet etcetera it's
all sorts interesting optimization
problems and underneath this but
fundamentally we have a problem of
bidding for complimentary goods and
simultaneous ascending auctions and the
other domain that we studied at just
distills that problem out and we call
that simultaneous ascending options sa a
just a very abstract abstract ified
version of simultaneous auctions
situation okay the name of our agent is
Wolverine from the Michigan mascot and
the 19th century french economist Valois
because the first foundational idea of
our agent was to predict market prices
using a simple market model namely well
raised in equilibrium the reason price
prediction is important is because of
that exposure problem suppose I don't
care much about about the nice versus
the cheap hotel but the the current
prices are low so I start bidding for
the nice rooms for all the nights of my
stay and remember I can't switch nights
switch hotels during mid trip now
imagine that the nice rooms start to
skyrocket I could drop out of the sky
rocketing auction but then I'm I'm stuck
with the one if I was I'm winning
another room I'm stuck with it I can't
use it unless I get all of them that's
what the complementarity can really kill
you if I'd predicted which rooms would
get expensive than I could have
rearranged my trip when the flights were
still cheap or just bid for the the
cheap hotel from the start so price
prediction is is key
and we've done a whole study on price
prediction in this domain and the just
briefly the conclusion there our
strategy does using this simple ball
raisin economic model with no historical
data at all does as well as the most
sophisticated machine learning
approaches using using historical data
but back to the game methodology how the
supplies to tack the just like an F kiss
be where we started with truthful
bidding and parametrized it generalized
it with with parameters we do the same
thing here we start our baseline
strategy now is this fall rays Ian price
predictor and then we we introduce
parameters like variations on hotel bid
shading for example introducing a shade
factor just like we did with FPS b or
other ways to to do shading in hotel
auctions different entertainment
strategies can be swapped that in and
out parametrically we have this
complicated decision process for buying
flights for the timing of buying flights
that we parameterize with a few
thresholds but the conclusion as we end
up with a bunch of parameters we sample
very sparsely from that space and come
up with 40 candidate strategies for
Wolverine with 40 strategies in the full
light player game there are hundreds of
millions of possible profiles and this
is where the player reduction is really
critical we really decided it was it was
completely hopeless each game takes 12
minutes by the way to simulate so we've
had a testbed a cluster of servers
running these games with variants of our
wall doreen playing against itself 24-7
for over a year but even doing that the
full game was was just out of reach we
can sample a very small fraction of the
profiles in the four player reduce game
the two-player game we can get a much
better handle on the one player game we
can get a great handle on but that
defeats the whole purpose there's no
strategic interaction then okay so I'll
just gloss over the how we we use this
to come up with our final strategy to
actually play in the tournament but we
did the game analysis on these
on these paths pitch and these
empirically determined path matrices
came up with some metrics to rank the
various strategies we actually tried
them in in the the seeding rounds and
the qualifying rounds the tournament to
see how they really did against the
actual other players and conclusion
walgreen officially came in third this
year but I just have to mention if you
notice these 20 games and 10 0 games
there there was some various technical
difficulties in the organizers of the
competition actually published these
unofficial results unfortunately
unofficial where we we take but at the
significance level p equals point 17 so
okay so to sum up the strategy
generation the the very first part of
this was the algorithm i described for
best best response strategies for
infinite games have been complete
information the next big piece for when
44 games that don't don't fit that class
of games either have more than two
players have multiple rounds is this
empirical game methodology for applying
these this game theoretic analysis too
much larger games than previously
possible i talked about theoretical and
experimental evidence focused on FPS b
and the applying the game empirical game
methodology to FPS b even though we
didn't need to since we solved that game
stop the analytic version then the the
real application of it was to the
trading agent competition where we
started with our price prediction
approach to strategy generation in
simultaneous a sock simultaneous options
for complimentary goods parameterize
that baseline strategy and and then
applied the empirical game methodology
to come up with a good variant on that
to play in the trading agent competition
and found it did very well that
concludes my talk
sup recovery switching off for questions
are
when you're playing the games against
each other sounds like you're playing
trying to play all hostile parameters
against all possible parameters I won't
give you a very big explosion right I
was running there's any way to sort of
play sort of representative samples or
samples against each other and defense
actually what we do so if you remember
here we well we came up with this fairly
rich parameter space and that actually
had millions essentially unlimited
number of possible games and that is
completely hopeless to try to play to
try to simulate something for every
possible strategy profile and so this
was really done in a very kind of ad hoc
way to just pare it down to 40
representative points in this attribute
space so it's an extremely sparse
sampling of public space and it was this
kind of done some by manually as we as
we gather data and we kind of saw which
strategies were tending to do well then
we've introduced variations on those so
actually the next big piece of future
work is actually to kind of automate
that process actually trying every
possible every possible profile
strategies is is not realistic at all
but but we do want to automate the
process of picking them so these 40 were
picked semi manually as we just watch
the experiments unfold
and of course koreff get speed what we
did just by picking the right level of
disparate ization
over here
this is discretizing by 40s and this is
playing every possible profile against
each other and you know we can do that
even though if this gets into millions
and other games because each Sam each
sample we do is essentially
instantaneous so it's a very drastic
difference from the training major
competition where every sin the sample
takes 12 minutes
the general questions
thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>