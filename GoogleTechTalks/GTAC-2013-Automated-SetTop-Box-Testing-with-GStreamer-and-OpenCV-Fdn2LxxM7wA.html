<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2013: Automated Set-Top Box Testing with GStreamer and OpenCV | Coder Coacher - Coaching Coders</title><meta content="GTAC 2013: Automated Set-Top Box Testing with GStreamer and OpenCV - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2013: Automated Set-Top Box Testing with GStreamer and OpenCV</b></h2><h5 class="post__date">2013-04-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Fdn2LxxM7wA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">now we're going to go ahead and enter
into our series of lightning talks each
one of these is going to be 15 minutes
including QA and so we're going to keep
these pretty fast-paced first one up
here is David Roethlisberger and I'm
going to start a rumor that like he's
related to someone on the pittsburgh
steelers so he says he can get everybody
free tickets so with that he is from
youtube and he's going to talk about
automated set-top box testing which will
be faster hi thank you I need that okay
um starts you view not YouTube oh sorry
oh you view if so if we could have my
own laptop up on the on the screens
please okay so at you view in the UK we
make set-top boxes and to test our
set-top box we have scripts running on a
PC sending infrared signals and
pretending to be a human user pressing
buttons on a remote control and we check
the video output from the set-top box
using video capture hardware and image
processing to ensure that it's done the
right thing of course we have rather
many other types of tests as well but
there's the most interesting one to talk
at a conference like this so today what
I'm going to show you is how you might
go about implementing such a system the
command line we're looking at here runs
GST launch which is provided by
gstreamer gstreamer is a set of
libraries and utilities for handing
audio-visual media if you use linux on
your desktop your media player is likely
to be totem which has both ng streamer
just to give you one example so let's
run this
GST launched Texas that's command line
argument a GStreamer pipeline
so these exclamation marks here G stream
is equivalent to the shells pipes so
this pipeline has a video test source
element generating a video stream with
this test pattern and as output is piped
to this color space conversion element
which converts each frame to a format
understood by the next element in the
pipeline which is X image sync a sync is
an element that consumes video and this
particular one renders it to an X 11
display GStreamer ships with a ton of
different elements such as this one v4l
stands for video for linux it's an API
for drivers and default resource
supports any device with video for Linux
drivers such as my laptop's webcam here
or could also be a external video
capture device we can customize the
behavior of individual elements by
setting their properties so if I go back
to video test source I can set its
pattern property here to something
different and we can see it's generating
a different video pattern now here's
what gets interesting I'm going to add
this template match element and template
match is a thin wrapper around an open
source image processing library called
OpenCV the CD stands for computer vision
open CV is original by Intel and
template match takes a path to an image
and I'll show you what this image looks
like it's this white circle and all
black background and when I run this we
can see that template matches drawing a
red border wherever it finds a match in
the video stream now the CPU overhead of
the image processing is introducing a
little bit of jitter into the into the
video stream which causes some time
stamping problems for the sync
so just tell the sink to ignore timing
information on the stream itself and
just display frames as soon as they
arrive and it's a little bit smoother
right and each element can post messages
to the gstreamer bus
so I'll ask GST launched to print those
messages until we can see that template
match has posted a message for every
frame that it's processed showing us
whether or not it found a match and the
x and y-coordinates of that match so I
hope that you can see how all these
pieces fit together and how easy it is
to develop a video capture an image
matching system of this type all these
components are open-source so we can
really take control of our test
infrastructure we're no longer beholden
to proprietary systems now I consult to
a company in the UK called you view and
you've used the joint venture by the BBC
and other major UK broadcasters and ISPs
and you've you make the set-top box to
test the set-top box we've developed s
TB tester and we've open sourced it so
it's no fun these components that I've
just demoed and so it supports any video
capture hardware with video for low NOx
drivers or indeed any
gstreamer source element and it uses GCM
as Python bindings it allows you to
write your test scripts in Python and
they look like this
set-top box tester dot press sends an
infrared signal wait for match searches
for the specified image and raises an
exception if it doesn't find it so the
script navigates try a network and
Internet settings menu and we've
encapsulated that into a separate Python
functions that can be reused across
scripts then we press down until we find
this image and I'll just ask my editor
to display those images in line
so I'll remind you this is just Python
and those were just string literals it's
my editor that knows how to and display
the images online at some Emacs before
anyone asks so so we press it down until
the submenu selected we press ok then we
press right until this automatic option
is selected then we press down and we
assert that the next button has been
highlighted we press ok and within 30
seconds we expect to find this image so
as you can see it's very simple it's
very readable it's entirely procedural
and it reads much like a manual test
script written in English so
non-programmers on the test team have no
trouble understanding this and relating
it to their own requirements test
coverage matrices and so forth but at
the same time it is Python so it's very
powerful and you can do anything you can
imagine really so just show you a couple
of quick examples of other stuff we've
done this is a video I recorded earlier
of an STB tester script that knows how
to navigate through this double carousel
of players so I've told it to find BBC
iplayer and now that it's found it on
told it to find 4od so again the red
rectangle is showing us where s TB
tester has found a match for what it's
looking for and now it's time for idea
I've asked to find demand 5 so it's
looking for this long thin blue
rectangle to identify the current
selection it looks for an image of the
unselected player to find where it needs
to go and it figures out what buttons
that needs to press to accomplish that
and I'll just play that again while I'll
show you the source code implementing
that logic I won't go through it but it
just to show you that it's fairly simple
as you know it's barely two pages of
code and most of that's doc strings and
doc tests although have removed error
handling but if you're interested in
seeing the full code I've posted on STB
test icon as an example so essentially
your script would just call find player
pass in an image of the unselected
player
to know what it is to find an image of
the selected player to know when it's
got there is another example this state
machine is you've used setup wizard so
each each image in this diagram each
node represents a possible state that
the UI can be in and each edge
represents an action that the user can
do from from that given state this
diagrams generated entirely
automatically from some Python code
we've written to describe the setup
wizard each image you see is exactly the
same image that SUV tester uses to
identify that the UI is in that
particular state and each edge each user
action is a Python function that carries
out the action and you can click on one
of them and it shows you the source code
implementing there and there's all fully
hyperlinked so you can drill down as
deep as you like it's very helpful to
you know if non programmers can still
follow the flow of each of these
functions here so so you could write a
test script or you explicitly call each
of these actions and the order you want
them or you could do something smarter
you know we do after all have this
representation of the state machine so
we can randomly generate random walks
through it or you could have a test
script that takes a given path and just
tries cutting the power to the set-top
box at every possible state just to see
what happens you know this kind of stuff
that's incredibly tedious to do manually
especially for each software release
I'll show you the full state machine
they're all done
so if you look at this in a certain
light it almost looks like a wireframe
II kind of UX design document and really
what we're aiming for is fully machine
checkable specifications and this is all
generated from plain text files so you
know it's version controllable you know
all that good stuff that we're used to
for our code as developers we can't have
for our specifications that's worked as
well it's very exciting
before I quickly take some questions
I'll just point out the STB tester comm
has loads of documentation we've got
introductory material some videos to
help you get started and there's mailing
lists if you have any questions and we
try to do the development of it as
openly as possible so thank you for your
time
great thank you David all right we can
go ahead and pull the moderator if you
have questions you go to either side
here in terms of asking questions it was
very fascinating the way you did the the
sort of image matching and so forth um
I'll start off with a question of my own
how complicated does the image logic
have to be or is it just very pixel
perfect in terms of matching and looking
for elements so since we capture video
directly from the set-top box we're not
going through cameras or anything like
that we have fairly high fidelity images
but we do have video capture hardware
that does h.264 encoding in the hardware
so we do get some artifacts from that
and so our image processing algorithm
does handle that and it's got a few
knobs that you can tune either globally
or for a specific image if you'd like
very cool you know he also reinstalled
my faith in Emacs as being cool the fact
that it will embed the images for me
okay I'll take a question right here off
of the moderator it says does having
images and test scripts or test scripts
caused flaky tests when styles change so
I wouldn't call it flaky tests I'd say
that the tests start failing predictably
if the style changes and so yes it's the
answer to that question as you hopefully
gathered from some of my examples most
of the actual image matching we actually
pull into library functions which the
test scripts call themselves so very few
test scripts actually read like one full
of images that I showed you at the
beginning so it's just a matter of
changing the common functions and all
your scripts are working and you you can
do things like match any of these images
so that your tests continue to work
across different software releases if
you need to still be testing you know a
vision that's in production that's got
different images then a development
version wait
clearly this next question was written
by somebody who has done this it says
how do you manage the image repository
without sucking the soul out of some
port
engineer um well again everyone seems to
be fixating on these images to be honest
the main problem we've had is not with
the image repository as for flakey video
capture hardware so I guess the answer
to this question would be much like the
previous one where the image repository
is very fairly small compared to the
number of tests that use it and we also
have a lot of unit tests of our tests
we've captured a lot of screenshots and
anytime we want to make a change to the
image processing algorithm we run all
those unit tests against our collection
of previously captured images to make
sure that everything continues running
properly great was is this a live
question
okay sure go ahead we have time for just
one more ok so just wondering if you
used your framework to measure
performance let's say such as latency if
you click on something how long does it
take to go to the other view such things
like that okay so so um so when we when
we're doing the image processing on a
full-sized you know 720p or whatever
full size video stream even with a
fairly powerful computer we can't
process do the image processing in real
time so what we do generally is we just
drop frames if we can't process them but
for testing performance we we flick a
switch in the test script just just for
a you know we use Python context manager
to have the supply to adjust as portion
of the script where we queue up every
single frame and and then we then we can
measure things like that like smoothness
of animations or or latencies latency is
a bit difficult because we've got to
take into account all the various
latencies in the system the video
capture device the encoder the infrared
emitter and so on so as we're working on
it we're getting there great and with
other thank you David thank you to an
experienced worker</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>