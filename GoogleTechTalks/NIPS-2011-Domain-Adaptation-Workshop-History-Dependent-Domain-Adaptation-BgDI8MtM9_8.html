<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Domain Adaptation Workshop: History Dependent Domain Adaptation | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Domain Adaptation Workshop: History Dependent Domain Adaptation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Domain Adaptation Workshop: History Dependent Domain Adaptation</b></h2><h5 class="post__date">2012-02-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BgDI8MtM9_8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so thank you I malamulele
presenting history dependent domain
adaptation and this is joint work with
co-authors from google pittsburgh matt
booty Nathan Ratliff and discovery who's
here today so the manor give this paper
is that standard methods in machine
learning are often too myopic for the
domains they're applied to so typically
we're focused on minimizing errors now
and in the future but many times machine
learning is applied to systems which
have an expectation consistency over
time so I'll start by giving an example
and now I'll formalize the problem just
a little bit we'll go over some of our
proposed solutions and then we have some
experimental results taken think of the
system we're employing a classifier that
gets retrained periodically over time in
between each free training we get a mix
of old and new examples you can think of
these as slightly perturbed examples or
maybe we just want to test to see if our
classifiers learn something new but the
key is that we have a small additional
cost for making the same errors we've
already made but a much larger cost for
making new errors and one intuition for
this is that humans are manually
correcting errors or some process so if
we think of two of these systems one
which has a classifier which makes
consistent errors that is errors between
retrains are the same more or less and
we think of another system which uses a
classifier which every time we retrain
makes a distinct set of errors there's
going to be a big difference in the
amount of human effort to maintain this
system so we can go this blue rectangle
as our feature space and these pink
circles are errors made by classifier
previous free trainings and the red
circles are errors made in the current
classifier if we have a system with the
classified mates distinct errors over
time we're going to make errors on many
more data points so this is going to
represent a huge human cost for
maintaining this classifier and if it's
bad enough we might as well does not be
doing classification whereas if we have
consistent errors in the classifier
we're going to make many fewer
incremental errors and over time we're
going to get a much smaller space of
misclassified examples corresponding to
a much lower human cost so in general we
have a loss function which depends on
our previous classifications and
specifically we've looked at the case
where there's a low cost to repeating
errors let the key is that we have
incomplete feedback and that humans
corrections human corrections take time
so even if we do get Corrections for
points which is definitely not certain
it's going to be delayed quite a bit and
we may need to retrain several times
before we have any feedback so the
question we wanted to ask is can we
learn while minimizing new errors even
if we don't know what the old errors are
so our first method is quite simple it's
a good baseline we just took a linear
combination of previous hypotheses and
exponentially weighted averaging is the
most trivial to implement and we were
using linear models so averaging weights
is equivalent to averaging
classifications and this gives us a
simple baseline it's also a fairly
intuitive method that we can think of
classifications as a random variable and
by taking a linear combination we're
reducing the variants so that's going to
decrease the chance that we're going to
change our classification we also tried
several kinds of warm starts so the idea
is that we have some hypotheses and we
want to make some updates to it but we
don't want to update it too much so we
can use fewer optimization steps or we
can use smaller step sizes and more
generally we can use any online learning
algorithm with the caveat that we want
to we don't want to update too much in
general online learning would say we
have a function and we want to fit it as
well as we can give it this new data
whereas here we're saying we want to fit
the function a little bit better but we
also want to stay consistent so
effectively we're using a different loss
function we're training with standard
loss function and our actual loss
function re weights the errors that we
may we also try to wait near this
constraint so here we're doing a full
optimization but with a hard constraint
so we can start out with a prior
hypothesis WT we train a small update
with link say at most Delta and then we
can add that to a previous hypothesis
and get this constrained update
finally we tried adding several
regularization terms to the optimization
so we have two different things we tried
one is the square there which says the
predictions of the current model should
be as close as possible to the
predictions of the previous model we
also have a hinge term which says the
predictions of the current model should
have the same sign as the frictions of
the previous model with the maximum
margin this is actually equivalent to
visual examples in the training set so
instead of using the true classification
of the point in the training set we
would add points with the classification
given by the previous model and these
are going to be weighted in the sense
that if we have some coefficient of the
regularization term then that's also
going we want to use on the virtual
examples horrible two wks one of the
very what is the attitude change w to
perform the TC vigil to learn to you can
think of WT plus 1 as retrained from
scratch and then so we have a full list
of weights that would refrain from
scratch and we just want to make sure
that we're close to the previous weight
vector
an HD flv this Sonya seven people dead
oh that's the so we can think of
hypotheses or weights so the previous
hypothesis would be including averaging
so we're not just using the previous
weight vector so we're using it with
averaging four not everything sorry I'm
in the wrong coming of age but uh yeah
it's just the classification of the
previous nice offices and that's
actually classification not inter
product as far as evaluation goes we
actually have two things we're looking
to optimize vs food we want to look we
want to discriminate discriminative
model and this is sort of instantaneous
performance so you can think of in
comparison to a baseline we want to make
sure that when were constraining the
model updates that we're not
constraining them to the point that
we're inhibiting learning so we want to
do well in comparison to an
unconstrained model in terms of
discriminative ability but at the same
time we care about the consistency of
the system we measured this with
cumulative unique false positives and it
is false positives and not just
cumulative error he has a great analogy
to trying to drill oil wells so if
you're predicting which places are good
to drill and you have a false positive
this could be a huge cost if you
actually drill down and test for oil but
once you've already drilled there's no
extra cost to having a classifier which
tells you to fill here again these are
probably not going to go back
drill another well false negatives also
have some costs but there's not the same
permanent cost to correcting them so
this is why we used cumulative false
positive well the actually reason we
used it it because at Google on this
data set we determined that the cost was
higher but that's a good analogy and
this is sort of a measure of overall
performance of this system and the exact
definition is if we look at the sets of
false positives made by the hypothesis
each of our hypotheses this is just the
union of those false positives in either
case we're allowing hypotheses to be
trained on all of our previous data
we're only going to test them on our new
data to aec would be calculated just on
the most recent set of data that we've
seen and we're only going to update
cumulatively false positives for that
newest data
as far as their actual data goes we used
a google data set which is advertised
verse aerial advertisements this is a
sparse and a very non dimensional data
set which is one reason we use linear
models here we also unfortunately that
did it that's not public so we also use
malicious URL identification data set
since by putting guided by Justin ah and
this is qualitatively similar but it's a
public data set so as the actual results
so each of these plots the x-axis is the
number of times with retrained and the
y-axis is the performance of the models
relative to a control so the thick black
line is are controlled and this is
percent difference that's at zero on the
left we have the accumulative the false
positives which is a measure of the
system performance as a whole and this
is our instantaneous discriminative
ability they can see that weight based
methods did quite well we get about a
forty percent reduction in cumulative
being false positives on this data set
and we actually increased AEC slightly
but in general we're just hoping not to
change it too much so that was a little
bit surprising well we're also
surprising is that our regularization
terms did not work out didn't work at
all on this data set and one hypothesis
we have is that it's not difficult to
come up with a hypothesis that is close
to a previous hypothesis on the training
data while still giving wildly different
results on test data so one way to fix
this would be to actually use unlabeled
data
to get a better estimate of the
regularization term and actually avoid
overfitting it that's another future
work as for malicious URL classification
we see similar very similar results so
the weight based methods did quite well
the regularization terms actually worked
out a little bit and here we are
decreasing AEC which is slightly
comforting but we're not doing it to any
extent that's not trivial so this is
actually a fifty percent reduction in
the cumulative any false positive rate
so you can think of the cost of
maintaining this system in terms of
cumin time required with about cut it in
half without seriously changing ABC
that's a really interesting result and
just to summarize we've presented the
problem of history dependent domain
adaptation where our loss depends on our
previous classifications and this has
many real-world applications we've
evaluated several solutions and we got
up to a fifty percent reduction and
cumulatively any false positives while
maintaining a very high ase let there's
a lot still to do so there's obviously
very little theory in this talk why do
certain methods outperform others and
can we do better because I don't know
with any day that says that there's an
absolute trade-off and indeed put a lot
of these methods we found that there
wasn't an absolute trade-off between
instantaneous
performance and overall system
performance so that would definitely be
an interesting area study and also where
can we make use of unlabeled data so I
gave one example of our regularization
terms we think there may be a couple
other places we can use unlabeled data
thump that's it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>