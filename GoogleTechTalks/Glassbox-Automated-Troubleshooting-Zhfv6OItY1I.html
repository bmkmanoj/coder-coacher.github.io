<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Glassbox: Automated Troubleshooting | Coder Coacher - Coaching Coders</title><meta content="Glassbox: Automated Troubleshooting - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Glassbox: Automated Troubleshooting</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Zhfv6OItY1I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm pleased to introduce Ron bodkin and
Dave Pickering from glass box I met Ron
a few years ago we were both in the
aspect-oriented programming community
together busily trying to make aop
something that was usable by the average
developer and we took a little bit
different tax and I'm proud to say that
wrongs is one of the first successful
products that you can actually download
and drop into your server without
knowing very much about aop so I won't
waste too many more of your seconds of
your time here's Ron and I'll let him
tell you more about glass box thanks
Nick and thank you all for coming today
as Nick said we're here to talk to you
about glass box which is an open-source
application troubleshooter for Java so
as you can see from this illustration of
the web client that we use glass box
provides you a different way of looking
at running job applications to help you
find problems we'll look at an example
of that later so what glass box is doing
it really provides a kind of automated
diagnosis so it looks at what's going on
in a running server and it looks for
problems in the application suggests
things that might be causes and rules
out things that are not indicated by
what's going on so it's got used
throughout the development lifecycle in
development it can save a lot of time
troubleshooting especially things that
are not easy to isolate in unit tests
you know interactions race conditions
threading issues in the QA environment
it's it can be very good for again
testing out integrations things that
might work incorrectly sometimes it
helps even in terms of isolating common
requests URLs parameters that might
cause issues and in providing more
actionable data so that when reporting
an issue you're not just stuck thing
will something worked incorrectly but
providing some useful data and as you
roll out into an actual production
environment it also is designed to be
low overhead and work well so that you
can monitor applications and identify
issues that happen to more quickly
resolve isolate the issue and and
resolve them reducing downtime
so some of the key features the glass
box offers are it's got a drop-in
installation so unlike many tools in
this category it's designed to be
relatively easy to get it up and running
in a new server and it's easy to use so
you can have a web application that
makes it easy clicking around to get
data about what's going on glass box has
an out-of-the-box discovery capability
uses aspect or no programming it looks
for common api's so that it learns an
application up and can provide useful
data without any configuration of course
there's also more you can do if you do
some amount of investment in
configuration but it doesn't require you
to rewrite applications to monitor them
and we think that's a big advantage and
another big thing the glass box does is
it provides a clear description of
what's wrong with some supporting
evidence so that you can take action it
comes with a notion of a service level
agreement that's simple it doesn't
require a lot of configuration that can
be tailored so that you basically say if
if a user request of an operation takes
more than a second five percent of the
time that's slow and there's a range of
different exceptions of failures that
are just problems and get reported as
failures so as I mentioned before it's
low overhead it's designed to minimize
the actual end end response time
overhead that required to capture the
data so there's some overhead on startup
but once the server is up and running
the overhead is quite low you know we
think it's less than 1% from our tests
of course you guys want to test any
system that claims to be low overhead
and it's it's designed to be easy to use
and keep up as you evolve applications
so a lot of it is really the benefits of
automation what we see thus far as a lot
of times when people are trying to find
out what goes wrong in a system they
have two bad options one bad option is
to do a tremendous amount of manual work
and to dig through capturing thread
dumps or pouring through logs to try to
figure out what's wrong and then or the
other bad option is to to not use tools
but to just do a lot of experimentation
in code and and these are awful
practices in the best case and and often
to up in a minute this amount of time
especially
when as is all too often the case it's
not clear whose fault it is that
something's broken and we'll talk more
about that so the automation angle what
a glass box could do by automating is it
helps in each phase in the development
right you in development you're spending
less time chasing down bugs less time
dealing with in a high priority issue
that you can't reproduce in QA it's
easier to report something and make it
actionable and in operations it's easier
to identify what's wrong right and the
the list of benefits here is
suspiciously similar to that in the last
slide so I won't go through that again
you know so the summary is most
organizations spent a lot of time
monitoring their applications of their
infrastructure but there's this this
challenge that they face on the one hand
you see that there's a lot of ability to
measure from a business standpoint
things that aren't working well things
that outages you know blank pages
unacceptably slow response time but the
hard part is you take this data and then
you say well what's causing it you know
we know that there's something wrong but
how do we we drive it down to take
action so there's a traction problem on
the other side technically there's a lot
of monitoring going on and people have
data about you know bugs and things that
are trending badly taking longer disks
filling up but which of these issues is
translating it to actual technical
problems that affect the user so you can
this gap where you have lots of data on
both sides but you have a hard time
correlating it and putting it together
and you know the other angle on this so
one is technically be able to correlate
the other is its organizational you can
have a problem report and somebody's
trying to identify well what's causing
the problem they escalated up to
operations and they can't reproduce it
goes back to support and then of course
you have a conference call because
nobody can figure out what's wrong well
you know you had a database
administrator or what do you call a
person who administers a MapReduce
system I don't know what you'd call them
but maybe that would be a better term
here at Google so you get the the data
administrator how about that wakes up
and they think well it's a code problem
of course so that there's a developer
who's responsible but they didn't write
that piece of code so
they don't know what to do meanwhile
we've got an angry or customer and you
have another con call with more senior
people yelling at each other and at all
people involved and of course it's
always amazing to me you know on a
normal day when you deal with an
Operations Group you know they're I
aming six people they've got pagers
going off and they're talking on a cell
phone and that's just you know things
are normal then when you know in this
situation things really get exciting and
you get you know managers yelling in
both years is it fixed yet so finally
you know things have escalated to the
point you get the guru who knows how to
troubleshoot this thing off they pour
through some they pull out their
favorite whiz-bang tool dig through
piles of data and finally 12 hours later
and it unknown cost of the business the
problem is resolved right so this is a
traditional way of resolving the problem
and of course starting with the
everyone's favorite way of identifying
problems in production which is a
customer phone call and then we've
talked to organizations where they
measure problems by how many thousands
of angry customers call in to indicate
something isn't working well right so
what glass box is trying to do is really
work with an 8020 rule so we think that
most of the common problems most of the
business impact from outages or are
caused by a relatively small number of
relatively common things and and that
it's worth optimizing to fix those first
likewise eighty percent of the people
involved in identifying a problem can't
deal with complex low-level tools you
know they may be very smart people but
they haven't they don't know this
particular piece of technology or this
particular system intimately to pour
through the detailed dump of information
from it and eighty percent of the
expense and difficulty in
troubleshooting comes from handoffs
miscommunication trying to get on the
same page it's hard enough when everyone
is is just operating normally let alone
when there's a crisis and and things are
not running well to do a good job and of
course the other thing is most people
are not the best troubleshooters under
the best of times there's this very bad
human tendency I've done it myself I
think all of us do to jump to
conclusions you see a little bit of data
and say well this is the issue and then
start pursuing evidence to support this
high
offices and of course that's a great way
of getting wasting a lot of time if your
guess is wrong right so instead going a
glass box does is it more automates some
of the troubleshooting process and
looking at a variety of different
measurements so it's important that the
diagnosis be accessible to many that it
doesn't have to be a specialist and that
it produce an output that's clear enough
that it can't be miscommunicated so that
people from different groups with
different perspectives on the problem
can agree on an objective fact and take
action based on that so with that what I
thought I'd do is I'd switch over and
give you a demonstration of blast box in
action so I'm going to minimize this and
what I'm going to do is I'm going to
start up a tomcat application server on
this machine and I take a few seconds
have some slow starting applications on
there to illustrate what's going on so
here we go we start it up and what I'm
going to do is I'll go ahead and just
pull up the homepage of the server and
then we'll deploy glass box to the
server let's see what I do see well the
server is up that's an error page so
let's go ahead and take glass box is
distributed as a web application to war
file you can simply deploy it everyone's
favorite way to deploy stuff for tomcat
in spite of all of those admin tools is
probably this copy files over to a web
apps directory so that's what I'll do
it's a little easier than clicking
through an admin tool and it's deploying
and then what you have with glass box is
you have a an installer so you deploy
the web application and it guides you
through an installation process so we'll
go ahead and well I think I jump the gun
it hasn't finished deploying yet
disadvantage of demoing live things is
you have to have a few stories as
servers go ahead and do their do their
thing so we'll just wait a second well
if tom cat does a deployment
and he's always take longer when you're
demonstrating them live don't they so of
course the I know that the google's app
server of choices is a customized
version of an open source server is it
based on tomcat is that right you'd have
to kill me if you told me okay it's got
them all together I'd stop that started
all right bizarre okay of course just
when I stopped that's when it started it
responded that's well it's now deployed
so I can start up and just have it
running all right here we go deploying
done all right all right so here we are
now we'll start up glass box and you can
see it pulls up can everyone see that by
the way so there's an automated install
page it's identified that I'm running
tomcat with a son 15 vm so i can just
click through to install i can generate
a rapper script that starts the server
up with the the extra vm arguments
required to have glass box watch what's
going on so here i'll just pick for
convenience i'll pick the script that i
use to run it from the desktop and say I
want to wrap that and then I select and
it's finished so I will minimize this
and then what i can do is i can just
stop the server and double-click the
newly generated rapper script to start
the server up again and now what I'm
doing is I'm starting up the server
having deployed a a monitor jar and load
time leaving with aspectj so basically
it's it's added some vm arguments so
that glass box can see what's going on
on the server as it's running and that
allows me to to get more visibility into
what's going on in the application so
it's starting up the server right now
and deploying or running and then
redeploying some applications and what
we'll do is
as soon as it comes up so it's now
displaying the build I'm going to click
we have an automated verification tool
to make sure that everything is running
so it's up and running I click verify
everything is running correctly and now
I can click to the web client so the
normal way that people look at data
inside of glass box is through an ajax
web client you can see here on the top
hopefully you can read the font it's a
little hard to read probably from the
back of the room but it lists the
different business operations that it's
observed so at this point it's
monitoring itself the application is a
glass box web client and it gives some
data about average times and executions
thus far there's nothing terribly
interesting going on because the system
is running normally so glass box as well
everything's okay so what I've got here
for you was a couple of example
applications to illustrate monitoring
code that we didn't write the first one
is everyone's favorite is a pet store so
we've got the I baddest J pet store open
source example application written with
struts and we've added a couple of
things in that don't work quite as well
we didn't change the application at all
to make it monitored by glass box it's
the same standard code we just added a
few common programming issues to
illustrate how glass box can help you
when you run into these and you're in
real code so here we're browsing through
the pet store we're looking at fish and
I click on this one and it's taking a
while and then it listed it and if I
come back over here the glass box web
client it refreshes and you can see here
it's said well that's a slow slow
request it was slow in the database and
it's if I click on it I can see an
analysis below you can also open in a
new window by hitting control click and
you can see here it's analyzed this is a
slow operation because the database and
it gives me some basic information it
took two and a half seconds and that's
identified a specific prepared statement
that was slow this prepared statement
was slow on on a database at this URL so
now I've looked and again this is all
without modifying the application it
just watches things like jdbc calls and
is able to correlate them I can scroll
down and get more data so as you go from
the higher level overview of what's
happening into more details for the
people who are responsible for specific
component so looking inside the database
the slowness it gives me the prepared
statements that exceeded my threshold
again I haven't configured with the
default of it take of something takes
one second five percent of time it's
slow this query took two seconds so it
was too slow and it also told me which
prepared statement parameters were slow
in the slowest cases oftentimes what
you'll find is things are occasionally
slow under certain data sets so it's
important to know when they're slow to
make it easier to isolate the issue it
also will be able to it also tracks
what's going on in the server so that it
gives it can give a thread snapshot of
what the server is doing in this case
it's telling me that it's blocked on a
socket Meade I can expand it out and see
get a stack trace if I want to see
exactly where in the code is that slow
query coming from you can see here
that's the line of code it's in a run
cash query method on line 78 it
collapsed that too and then the last
thing that is presenting is for useful
information as it gives me an exact URL
that was used to hit the slope behavior
and if I have post parameters it would
would list the post parameters as well
again making it easy to reproduce and
track down what the issue is provides
some and then below the web client
provides some common solutions for
database low database calls and outlines
things that it ruled out so that's an
example of how glass box analyzes and
presents a clear indication of what's
going on when something is working in
correctly I'll show you a couple more
examples in this and the pet store
application so our lizard link is
notoriously unreliable and when I click
on it I get an unfortunate error page
not a very well-crafted one even and if
I go back over here to the web client
you'll see now a red line indicating
that this operation actually failed I
can expand that and it tells me it had
failures connecting to a database and it
gives me the database connection name
what URL it was and similarly gives me a
stack trace and sequel state and error
codes that tell me what exact issues
happened on connecting to the database
so it makes it easy to again
troubleshoot and I can see which URLs
are causing it to fail so that's
a second example and then one more
example from the pet store of another
thing that we can detect is I'll go
ahead and I'll pull up a saved order it
asks me the login so here's an order
this is normal but they added a
whiz-bang feature you with web service
and when I click on that you can see
that the thing is a little bit slow
turns out that we added in a common
problem which is chatty web services so
if I come back over here that day is
identified that there's a slow remote
call I can click on it and it's
identified a URL of an endpoint that was
slow and just like with databases it
indicated which which requests were slow
and in this case there were no
parameters but it again provides more
data to help narrow down the issue so
that's that's a few examples I mean it
also looks at thread contention for
things contending for locks and if you
wanted to see me run a load test on the
system I could illustrate that problem
for you as well the last thing it's
worth looking at is we took the open
source to do application which isn't
much of an application but it's about
the best open source Ajax application
that's out there which I guess says
something about how much easier it is to
talk about something and is to actually
roll out code for it so here we are this
is to-do lists and it's a beautiful Ajax
app that that lets you manage to do
lists misspelled for some reason so you
can see here i can do beautiful things
like click Edit and it pops out a inline
thing i could cancel it i can change you
know all the the nice Ajax things you
might want to do it's got old-school
monitoring built in with the kind of
thing that we don't think people want to
deal with it's kind of a long list of
monitors with lots and lots of data to
wade through but not telling you much so
that's certainly not the way we like to
monitor things but then over here when I
look in the glass box web client I can
see that in fact I think everything
managed to run under the threshold so
I'm not seeing a lot of slowness you
would hope that Ajax app that is only
managing to do list wouldn't exceed a
second
it it barely cleared it had eight
hundred millisecond as the slowest one
but what you can see that's interesting
is it has in here a number of different
operations that are coming from the gwr
framework which is an ajax framework for
java that does remoting it it lets you
marshal requests from JavaScript into
Java and then return results seamlessly
so it's identifying the those Ajax
requests from DWR as operations and it
can look at things like database access
and so on to diagnose those so we've
started to implement some Ajax support
with dwr and think that there's a lot of
opportunity there because we're pretty
confident that from past history that
people will find ways of writing slow
chatting Ajax apps that are inefficient
and it's an important area to diagnose
so let's say a little demonstration of
how glass box works any questions so far
so far so good question yeah
so I rush home at this stage we have a
global threshold and there's a
properties file you can edit that you
specify two things what's the time
threshold for something to be slow and
what percentage of time does it need to
exceed it a natural next step would be
to allow you to configure things in
groups or by packages so you could have
more fine-grained fine-grained
configuration that's something that
we're probably going to do relatively
soon there are other options something
we'd like to do later on would be having
more of a training mode where you could
run the system once under sort of normal
load and say this the system responded
like I'd expect here and then if it
deviates tell me and future so at this
stage it's a global one and looking to
drill down into having more
configuration on the individual
operations yes so we don't you the
question is how do we detect what
database is slow and you don't configure
it you don't have to to change glass box
instead what we're doing is we're we're
instrumenting the application using
aspect donor programming so we use load
time leaving as classes get loaded in we
see okay this application is making a
web service call or it success in a
database and we correlate the different
calls so that we're able to determine
what prepared statements run what
database you're connecting to etc
non-invasively
so let's get a little bit stronger the
you don't need to recompile you don't
need to make us in you know drop a seat
on top of your already existing app that
everything's cool right so the Dave
wants me to re-emphasize that you don't
need to make infrastructure changes to
recompile to put glass box in or to add
API calls into the application or to
reconfigure so it's very much designed
to be something that you can you can
deploy it with an existing app and get
useful data and with you can put
additional investment in if it's adding
value for you to get more out but out of
the box you can get the kind of results
that I showed you here where you were
able to see common problems like slow
database misconfigured systems and get
useful information to troubleshoot those
yes this instance is fulfilled
romantically situations because it gives
up
best estimates
attention saying it with everything the
databases so
there is a focus
Oh see so how do we save the data so
glass box is rolling up aggregated
statistics so it's not it's not saving a
transaction trace for each request
because that would be him an
overwhelming amount of data so the way
the thresholds work is if something is
slow once in a blue moon we're not going
to flag that is necessarily an issue you
could certainly change it to like point
0 0 1 percent of the time slow is too
slow and then you know we'd flag it if
it were ever slow and but we save data
about the things that are exceptions so
if there's a failure or a slow behavior
we're gonna save some data about that
but if there are tens of thousands of
normal requests that go through we don't
save data about it because they're not
the focus you're not trying to
troubleshoot those errors me we keep
like the last five failures we don't
keep thousands and thousands of them's
again for the same reason that we we
want to help you narrow it down if
you're running into a situation where
something is happening thousands of
times and say an exception is happening
then I would submit our they've got a
lot of problems or else that's not
really an error in your application it's
relatively easy to tweak it we haven't
run into a lot of cases where people
have said okay the system is identifying
thousands of errors here but you know
they're certainly you certainly could if
you really cared about just this one
error you know I think the right the
right way to handle that would be more
of a user level trace we've talked about
that it's not too hard to implement with
what we've got now where you could
basically turn on a bit in the session
and say watch this request and report on
it separate from the others so if you
wanted to identify a very specific
problem that's how I would evolve the
technology to go after it I mean and
there's another part of your question
that it also is you know in a clustered
environment how can you look at what's
going on I'm glass box does have a way
of configuring connections and saving
them so that you can aggregate data
across a cluster on a single machine
it's not very interesting but you know I
can I can show you an example i can pick
between jmx or direct rmi and I can
connect again to the same server this
time using a remote connections
of a local connection and it will it
will present data for me about both of
those connections so and clear that
refresh and it should pull that up my IP
address is probably changed because I'm
jumping around networks are mi is really
awful at dealing with changing networks
but of course that's probably not the
biggest emphasis when you have servers
so I could restart it or turn off my a
network connection anyway but so that so
in a connected mode you can use that to
configure these different connections
hopefully two different servers so you
can aggregate data across the cluster
for what's going on yes j2ee
implications like we said let's chase me
children so the question is do the
applications we're monitoring have to be
j2ee specifically servlets and jsps so
we monitor a number of different API
some of them are j2ee now java ee api's
some of them are popular open-source
standards like struts or jax-ws as a
j2ee standard so it's it's so that any
of those different AP is that we already
understand on the box if you implemented
them will recognize them JDBC etc now if
you have your own custom API I'll show
you how you it's relatively easy to
extend glass box to understand you know
your framework your dispatcher patterns
etc without having an instrument code
everywhere so you can define fairly
succinctly this is what it means to be
an operation or a remote call etc and
then any applications is following that
framework also we're able to fit into
the glass box analysis framework yes
anyway
session or contact our history
where you know here's this problem and
happens when
you know this sequence of operations
occur
call stack for this specific operation
we have a way of keeping track of
session history to identify what's the
full session that produces the problem
and and that's certainly a good feature
request and one that we've thought about
you know we currently let you say here's
the state of the request that generated
this issue but it a natural next step
would say okay let me look at a series
of interactions a session state etc that
led to this relatively easy for us to do
there's also though the attention that
you know it's easy to aggregate more and
more data and throw it at somebody so we
don't want to overwhelm someone with
details that might be relevant you know
we really think part of it is we want to
make it easy for somebody to see what's
happening immediately the same time you
know there's certainly value in in
making accessible information that we
can easily track so you can investigate
if we take you this far and you want to
see well one more thing you know that
it's available so it's a great feature
idea so one of the questions that often
comes up in any system like this is
what's the performance impact and what
we've found is that there's very low
overhead at runtime so that it's it's we
think it's quite suitable for production
use and have some some customers
organizations that are using the
technology that are testing it with the
plan of putting in production where
they're typically what we'll see is the
the end and response time increase is
about one percent and the reason why is
because we're much more selective in
gathering data so systems that want to
instrument every method that executes
sand capture build up detailed data
structures to provide profile profiler
like data have a hard time achieving the
the often quoted five percent overhead
number in our case we're really not
doing have the instrumentation and we
see when you want to dig deeper that
it's more sensible to use a spotlighting
approach instead of gathering data
across everything and when we do want to
look across many different operations
and look what else might be slow we use
thread sampling so on a job of five vm
every hundred milliseconds glass box
will look at the thread a thread that's
running a user request and say well
what's it doing and that lets us
identify other places in the code that
we did
anticipate that might be slow without
putting a lot of overhead in the one
place that we do have noticeable
performance impact is is really on
startup so we use aspectj load time
weaving and our measurements say that
it's about 50% slower for class loading
for initialization so as bite get loaded
in when you're starting a server that
that's noticeable and there's about a
twenty percent overall memory increase
typically its data that's used when
you're loading classes so once the
server is started up that is no longer
in the working set and can be paged out
to virtual memory so unless you have are
running up against the virtual memory
limit on the machine it probably won't
have a performance impact but those are
the main areas where we do see
performance impact so I know the glass
box is now all open source glass box 20
is now in beta and it really brings
together the aop approach to gathering
data with using jmx and other together
especially vm level data and then
provides it to an analysis engine that
runs inside of a web application so that
it can correlate and produce summary
findings again with a focus on
identifying common issues so that you
can easily resolve them and you know as
we continue to advance we keep looking
at what are additional issues what are
additional things that we can help with
it's under an L GPL license it supports
Java 13 although Java 13 testing is
pretty limited so 14 is recommended I'm
guessing you're probably using job of
five anyway right so a slide is actually
out we already are n data it's early
September yeah
that's just too many calls to the
database one takes a little time good
yes yeah the question is well what is
death by a thousand cuts death by a
thousand cuts occurs in an almost any
kind of a remote resource the tendency
to to make an excessive number of
requests none of know each one of which
is relatively quick but they add up and
you know this is a common anti-pattern
with database people are using our
mapping tools will often find themselves
inadvertently stumbling into this say
they map a collection that gets loaded
lazily and as they iterate over each
request for a new row generates a
database request it's a popular way of
slowing down a system with with web
services you know you write a lot of
fine-grained web services calls it's
going to be a popular way of slowing
down an AJAX application to make lots of
fine-grained requests for data and treat
it as if it's a local call yeah I'd be
interested in seeing how you show
a case of that
okay do we is it i'm trying to think of
our example makes it easier but we've
definitely if I ran the load test until
maybe afterwards I'll try to pull one up
for you I don't want to try to do it
while we're videotaping everyone's here
and then during the talk but I could
show you an example afterwards
definitely I mean the summaries it shows
you a list of the ones that have notable
times so you can see all of the
different ones that run with the request
that caused it and that gives you a
pretty good trace for you know what's
the sum total of things that are
happening to help you reason about which
of these things need to be changed death
by a thousand cuts is one of the harder
problems to fix because it's there's
usually not a quick fix you can't go in
and add an index to solve death by a
thousand cuts you need to rethink the
design of the operation but at least we
can help you identify what queries are
causing the problem or are other
statements so some of the things that
glass box won't do maybe I should just
go to full projection mode here it won't
solve problems that haven't happened yet
so it doesn't try to anticipate future
problems it's more going to report the
things that have already occurred it we
don't claim that we're going to diagnose
automatically every problem instead
we're really trying to focus on the
common ones the ones that cause the most
problem that being said certainly we
think whatever whenever there's a
problem we'd like to give as much useful
data to start with as we can so will
tell you as much as we do know to help
diagnose it and for the ones that are
really common and that we understand
well we can really make it dramatically
simpler you know we're not trying to be
a tool for all people we don't want to
become another date of Ewing you know
crunching number crunching tool you know
we think that there's room to integrate
with monitoring tools and analysis tools
to provide good output but we want to be
more focused on the initial
troubleshooting and it's not workflow
automation so you know and talking about
eighty twenty common problems and how we
can solve those when we started the
project we spent a lot of time looking
at examples of things that had failed
from our own experience talking to
others who'd spent a lot of time running
and debugging large-scale server
applications and you know we categorize
them
like this so we looked at things like
hardware problems configuration problems
application server problems etc and and
try to organize them and say you know
what are the most popular things that
people do that cause applications to
break and then you know what can we do
to automate tests to simplify fixing
those so this fishbone diagram is called
illustrate some of the ones that we've
run into and one other thing that's
worth noting in addition to providing
the web client there's also you can use
jmx remote to access glass box data so
the jmx management API for Java allows
you to make remote connections in and
you can connect into a running server
running glass box and get data out so
I'll show you a quick example of that
here we've got the server running and
I'll just pull up a J console which is a
tool that comes with Java 5 it lets you
connect to remote servers and look at
jmx data you can see here there's an
additional topic here so tom cat has
lots of jmx data built-in glass box also
exposes a statistics tree so you can see
here organised by at the top level
application I can see the various
different operations the Jeju
application has or I can look in the pet
store and see a nested tree inside of
action servlet we filtered out to pick
the actual struts actions is the things
that are interesting so I can look it
down here at view order action and see
database access and you can see all of
the different pieces of database access
that we monitored that we're terribly
interesting so we didn't identify them
calling out but we were watching and you
can get more detail through the jmx
jconsole if you want to dig in and look
at sea well what exactly happened here
so it does expose low level data in this
format as a way of providing additional
information when needed but we also
don't think that this is a great UI for
overview and monitoring and top level
troubleshooting it's a good resource to
dig into if you need to so another
question that we talked about briefly
you know how can i extend glass box to
understand better an application that's
it's not the
not using maybe all the API is that
glass box currently understands I mean
it's designed to have a very good
plug-in architecture so it's easy to
extend to added support for new tights
to plug them into that infrastructure
and some of that comes from aspect Jay's
load time weaving support so you can
write something about this simple this
piece of XML that says I'd like to
extend my notion of an operation to be
anything that's inside of the car my
code service package or at sub packages
then any types of now in that package
the operations inside of it will be
considered to be a reported on as
operations by glass box so it'll show up
as an operation so it could be as simple
as writing that much XML or writing a
small amount of code that extends the
library and then deploying it alongside
of the standard glass box library so you
might build another jar or deploy this
XML fragment in a classes directory or
inside of a web application in order to
to get additional data so it's designed
to be extensible now the overall
architecture is that inside of your jvm
we're using load time weaving in jmx to
gather data so we have a monitor jar
that captures that data well around any
applications running and then that gets
put into the the web application that
does analysis on it and exposes it both
through a jmx remote interface and for
through an ajax web application and that
lets us of course monitor the
interactions with back end web services
and databases and a lot of a lot of this
is based on the fact that job is used as
a hub for integrating data across a lot
of different services and a one thing
that we currently don't do is we don't
look at what's going on in front of the
app server so if you have issues running
on apache or a load balancer in front
we're not currently set up to gather
data and analyze those although that's
obviously a good direction to move it in
the future so you know one of the things
that underlies the analysis is the
notion that the end of the day you've
got really four kinds of problems right
at a high enough level you can have
components and resources and you can run
out of components because you use too
many of them or
there weren't enough to begin with and
you can have components that just fail
or that consume too many resources and
ultimately troubleshooting is all about
taking these these abstract categories
and drilling them down so as we continue
to develop this box more and more we
want to make it easy to define the
components and resources so have
out-of-the-box definitions like we've
already supplied but make it easy for
you to plug in to the analysis framework
so that you can drill down in what
components matter in your organization
so that you have the right way of people
looking at issues so you know the use of
aspect owner programming enables this
kind of very non-invasive monitoring so
you don't have to maintain changes
throughout a codebase you don't have to
rewrite a codebase to gather application
monitoring data and that makes it easy
to update that lets you selectively
apply monitoring in the right areas and
it leverages the advantages of a popular
open source tool aspectj so you know
it's not the glass box project that
wrote instrumentation code that you have
to trust but it's it's a project that's
been around for ten years now in five
years since the the 11 released it's the
basis of a load time weaning engine so
there's a lot of experience and many
different organizations committing to
the the load time weaving support of
aspectj and we think that that's a real
advantage as well as and of course the
other thing that hopefully you've seen
so far as you don't have to dive in with
both feet to aop to get benefits from
from the technology you can use it you
can you can deploy to a system you can
make small additions to it with and
learn a little bit about aop but don't
need to be to rewrite your applications
in order to use it so this is another
example of if you wanted to go in in
more of a code style instead of an XML
style how you might write a an extension
to glass box to monitor something so I'm
not who here is familiar with aspectj so
I won't try to explain all of aspectj
and its syntax to everyone here but the
basic point is that what we're doing is
we're saying here we want to pick out a
type mail transport and execution of
methods inside of that type
and and that will let us monitor access
to those as a remote resource so with a
very small compact piece of code like
this we can compile it distribute it in
a jar and then extend glass box to
monitor email and then from a framework
standpoint the code that supports it is
listed here you know we have an abstract
reusable aspect a reasonable type that
you can extend and it uses a response
factory API that's flexible to make it
easy to plug in different
implementations you know with spring aop
you know even with manual
instrumentation if need be as well as
with aspectj so with that thought I'd
finished with a few minutes of just
discussion of features and ideas for
things that you might that we might do
going forward and get some input from
you so before I dive into that I'd like
to see if there's any more questions
from that that first section yeah so if
you want to use glass box in a web
application is there just like a jar
that you can kind of
during the classpath and have it mother
thing else is just stupid amex earned it
so you can use glass box the question is
could you use it in something other than
a web application can you just use a jar
and yes you know you can use the glass
box monitor jar if you have that in the
aspectj weaver jar on your classpath
with the proper vm arguments you can
gather data about what's happening in
your running application normally in
those situations you're going to want to
write some kind of a monitor to say
here's here's my unit of work because it
won't be any of the web the
model-view-controller frameworks that we
know about and you will you can
certainly get jmx data but you also if
you run it in that mode you might want
to still run tom cat and and connect out
remotely to that running app through jmx
to give you more analyzed data so you
can run it it's a little bit of
configuration to do it but it's not hard
so that's definitely a good way of
running the app we've already had people
running glass box in that style as well
yeah I'd like you to test your memory
and name all the things that are
monitored
because I think some of them work we
lost a slide or something and we missed
uh-huh I think some of the things that
we troubleshoot work on there right well
you know maybe the easiest way instead
of testing my memory is I can show you
the list of things that we rule out as a
way of over providing an overview right
so we look at in addition to database
connections database calls we look at
threads that are running to find
contention where you get synchronization
that slows the system down because
things are locking each other up
failures as well as slowness and web
services DJ bees and other remote calls
things that use too much cpu error pages
and exceptions in java processing
database calls of being slow as well as
failing and time spent in The Dispatch
layer so those are some of the different
things that we monitor rule out all
right let's let's look at some of the
things that we think are also important
going forward so one of the things is
most organizations have invested a lot
in having a good systems monitoring and
infrastructure and we really see glass
box is providing analysis and
application specific logic too much
better job of analyzing what's going on
inside the app so we think that there's
a lot of value in integrating glass box
into systems monitoring and doing a
little bit to extend it to do even more
to monitor your applications so that's
an area that's exciting another scenario
that actually came up earlier is this
notion of filtering by user or by
customer where somebody has an issue
they report it you could you could set a
trigger say in the recession and when
they they run an operation again you get
specific data about what's going on for
that session for that user so it can
really let you isolate an issue and in a
system with many users running at once
in production that we think that's a
very valuable way of slicing and seeing
what's going on for a specific problem
you know another thing that we see a lot
of potential around is is having more
component owner focused reports so
what's an analysis of what's going on
from
database standpoint I own this part of
the application I won't understand how
my stuff is working sometimes even just
understanding which pieces of the puzzle
are involved so thus far this request
use these four components and not these
three all of these things you know I
help with the goal of narrowing down who
should be looking at this problem and
providing data for them so different
user focused reports we think it's
important from it training so the idea
that you can start the system up and run
it with a test load or run it under a
certain mode and say this is good normal
behavior or this is good normal behavior
but this this and this is unacceptable
and then that and so instead of having
to configure everything you can train it
that way another way is of course just
letting somebody look at reports of the
data and say well this is actually too
slow or this is acceptable and letting
people interactively configure it you
know one of the big things though the
reason we started with a global
threshold was we think that the worst
thing you can do is require people to go
in and configure a million things that
we want to start off with something
simple and and with useful defaults and
then if you need to extend it a little
bit you can another thing that we often
have requested of course this is more
historical views and our philosophy on
that is that we like to have a kind of a
telescoping view of history so you have
data about the last five minutes but
then you have summarized data about the
last hour the last day the last week and
a lot of times what we believe is the
best predictor of what ought to be
happening is what happened a week ago
because things tend to be cyclic in the
business world predominantly on a weekly
basis so Monday morning should look a
lot like last monday morning but
probably nothing like yesterday sunday
morning and likewise you very useful to
do things like baseline okay i'm about
to do some significant event like
pushing out a major release or
integrating a new component or upgrading
so i'd like to compare how things have
changed between baselines and then
there's lots of interesting things when
you when you move into scenarios where
you're not running in an interactive
application where you've got back end
processing of message queues or services
and and really we think one of the
things there is
there's different service level
agreements then response to single
request that matter in many we've been
talking with different organizations
with requirements there throughput
becomes an important issue in some cases
fairness time to go through all the hops
and get an end result to a user so we
think there's interesting things to do
to enhance monitoring and reporting on
and and and processing and then of
course there's lots of different
technologies that would be good to add
more monitoring for so more monitoring
of Ajax frameworks is high on the list
there's a lot of web frameworks and it's
relatively easy to extend them you know
more monitoring of caching more
monitoring of jndi and o our mapping so
there's lots of additional pieces to
monitor and certainly one of the things
that we've designed is to make it easy
to extend the system so that anyone who
has a need for one of these could easily
could make a contribution back and share
it with the community so that we're not
writing and debugging monitors for every
frame work in the world but it becomes
very easy for the community to
contribute and maintain its own set and
you know we talked about briefly being
able to reach out and have more data
about system health I think that's going
to be important going forward with glass
box as well more doing more with
clustering you know at this point we're
doing client-side aggregation with a
little bit of configuration we think
there's more we can do another thing
that we're working on now is email
alerts so when things pass the threshold
you can get an email out and say that
something would awry that's a valuable
thing and then lots of different
analysis slices so there's lots o you
can do ranging from rules to statistical
analysis you know our philosophy on the
different analysis techniques is to take
a look at specific problems and say you
know what's the simplest way that we can
reliably predict this thing a lot of the
value in the analysis is also it's
really important that it not be some
strange Oracle that just tells you
here's the thing that happened you have
no way of questioning or finding out so
it's important that if if the system
comes up with a conclusion it's clear
why so you can trust it so those are
some of the future directions and you
know would love to hear from you
you know your thoughts about how this
might be helpful any questions comments
get some curious people have been
looking at correlation that should
behavior and their testing efforts in
terms of the unit
so are people looking at correlation
between how things behave in production
and how things behave in tests I think
that's a great example of something you
could do with a base mining feature and
say you know what's deviating here I'm
not aware of it but I think it's a great
direction to move in it's a classic
problem right that things behave very
nicely in task but it's different in
production so what motivates a why is it
different what's salient that's a great
question to dig into yes so how can we
help diagnose memory leaks so we haven't
done a lot of work on memory leak
detection although there's certainly a
number of techniques that you can do and
that we would welcome you know
collaboration opportunities to work with
with users on you know it's so it's not
in the 20 release but there are
different techniques you can use
detecting memory leaks in a java
application is its I would say it's not
a scientific process it's it's a little
bit of a black art but that's the extent
we can automate and make it simpler we
want to do that yes when it detects
errors or failure conditions or whatever
is it something that it just passively
puts in a queue and then waits for
something that call and say give me a
list of errors or is it
jenya does it have a interface we
basically saved you know and finally
when you come across a new problem so
the question is when their errors or
failures are encountered does it wait
for someone to pull the data or can it
push it out and alert you so we're
working on an email interface to allow
you to push alerts out when something
fails or shift status from okay to not
okay in sudden respect and we're closed
on that and configuring email and making
sure you can do that correctly so that's
that's coming soon so the current
version you go to the web page and you
monitor it but email alerts is coming so
you didn't want to run it in a web
service just one of the kind of log when
something happened you just spit it out
some text log just at the end of the day
look at all the exceptions are kind of
popped up that's something that would be
possible after you do email which is a
that's completely separate so the
question is is there a way of having an
exceptions log and it so happens there
is a feature that's in the system that
will generate a log of exception so a
request that's failing or exceeds the
performance threshold it can write it to
a log it's a logging topic you configure
in your logging system so if you wanted
you could tail that log and alert based
on that any other questions all right
well well we'll stay here offenders any
more informal questions afterwards
thanks a lot for your time enjoyed the
chance to talk to you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>