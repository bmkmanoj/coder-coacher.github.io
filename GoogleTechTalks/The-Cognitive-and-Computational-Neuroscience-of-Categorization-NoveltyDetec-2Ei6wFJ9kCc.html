<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Cognitive and Computational Neuroscience of Categorization, Novelty-Detec... | Coder Coacher - Coaching Coders</title><meta content="The Cognitive and Computational Neuroscience of Categorization, Novelty-Detec... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Cognitive and Computational Neuroscience of Categorization, Novelty-Detec...</b></h2><h5 class="post__date">2007-12-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2Ei6wFJ9kCc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm very pleased to introduce dr. mark
luck who's a colleague of mine at
Stanford University and the Calina
psychology program having left Stanford
I went off to computer science and Mark
went off to further academic efforts but
both of us are interested and have been
interested in the way the mind works and
hopefully mark will give you some
insights into what he has been doing in
the last few years
mark is a professor of neuroscience at
Rutgers in Newark and he's co-director
of the Rutgers memory disorders project
he's also published a newsletter memory
loss in the brain and he works in the
interface between neuroscience
psychology and computer science where
his research focuses on the neural basis
of learning and memory he is the
co-author of gateway to memory and
introduction to neural network models of
the hippocampus in memory I'm sure
you've all read that and he also is
about to come out with a undergraduate
textbook learning and memory from brain
to behavior he has won a number of
awards including the distinguished
scientific award for early career
contributions from the American
Psychological Society and the Young
Investigator award for cognitive and
neural sciences from the Office of Naval
Research mark has also done some really
interesting work on used to told me
about years ago about detecting
potential flaws in helicopters and other
sort of interesting things so
interesting to see what he tells us
about today I'd like to introduce dr.
mark luck so my everybody hear me good
mic so what I want to talk about today
is some of the work in our lab at
Rutgers that as Eddie said is at the
intersection between psychology
neuroscience and computer science and
gonna focus on how people learn
associations how they learned to
categorize the world and particularly
how they learn to generalize what
they've learned in one situation to
other domains and the most of the talk
I'll talk about the sort of applications
to the biology and the psychology trying
to understand how the human brain does
these and how do how we can infer the
algorithms that are used to do this and
then the last part of the talk briefly
touch on some of the
applied problems in machine learning and
pattern recognition that we've worked on
and hope that perhaps some of these
applied aspects of our work might touch
on some issues of interest to the people
here at Google and I'd love to sort of
interact and talk with people afterwards
about how some of the things that we're
doing might be irrelevant to you so part
of the core of what we study is how do
people categorize what they know in the
world how does a student of
impressionist art learn to tell the
difference between a Monet and a MANET
and there may not be any simple rule but
you can begin to develop associations
between different clues that suggest one
category or the other so that one might
learn that this image should be
categorized as a Monet and that image is
a MANET and we're interested how do
people form these kinds of categories
how do they learn from example ours and
how did it end generalize this to novel
instances I'm going to talk actually
primarily about two brain regions here
the basal ganglia and argue that it's
critically involved in how we learn
about feedback from the environment
about the consequences of our behavior
when we make an action we get some
feedback from the environment positive
or negative and it influences our future
behavior and that we've argued is
critically involved with the basal
ganglia and then let me throw the first
half of the talk in the second half of
the talk I'll talk about the hippocampus
which we've argued is critically
involved in determining new stimulus
representations for information that
comes in and those new stimulus
representations are the encoding scheme
depends on detecting regularities in the
environment and these two structures
work together one to develop how to
represent information the other to use
those representations in order to sort
of change our likelihood of making one
action or the other and I probably won't
talk much about the frontal lobes in
this because I'm trying to keep it the
talk shorter so the approach that we
take in our lab is multidisciplinary we
use functional brain imaging patients
with focal brain damage genetics
comparative studies of lesions and
transgenic animals and neuro
computational modeling and so to bring
these all together to provide some
converging evidence for what these
different brain regions are doing in the
context of learning about concepts and
categories in the world so the first
question that I want to start with is a
psychological one or a philosophical one
going back even further what are the
princes
which govern the learning of new
associations so the earliest writing on
istic we traced back to aristotle who
described two principles one of
contiguity when two things are close
together in time or space we tend to
associate them and when they tend to
co-occur we tend to associate them and
these principles still today sort of
define much of what we know about when
it is that we tend to associate one
thing with another and these principles
of Association led in the in the mid-50s
in in madness in mathematical psychology
to the development of try to develop
algorithms to describe how animals and
people learn and the approach here was
to try to come up with mathematical
equations which would take information
about the the contiguity and the
frequency and other factors and develop
quantitative predictions for behavior
and learning and Clark Hall was sort of
the father of this and although holes
work itself is not really relevant
anymore his work led to some very
important work in the late 60s and early
70s by Rescorla and Wagner who developed
what we call an error correction model
of of classical conditioning of basic
associative learning and they had two
key ideas and the first idea they had
was that in addition to the contiguity
and the frequency that what's critical
is that cues provide useful and reliable
predictive information about expected
outcomes that is not just enough for two
things to co-occur but one of them has
to be a reliable and useful predictor of
the other and they argued that one that
the way that animals learn this even the
most simplest of animals learn this is
through trial by trial changes in
weights that correct or seek to minimize
prediction errors and the idea and the
prediction error is the difference
between what an animal expects and what
it actually occurs is in a sense a
measure of surprise and the basic
principle of error-correction learning
characterizes three different situations
that are of interest one is if one has a
cue and it predicts nothing it's a
neutral cue and something occurs so then
we have a positive prediction error and
the Rescorla Wagner model says you want
to increase the associative weights if
you have a cue that predicts an outcome
and the outcome occurs then there's no
prediction error there's no surprise and
you leave everything the same and
finally the
if the cue predicts an outcome and it
doesn't occur you're disappointed then
you have a negative prediction error and
you decrease the weights and for those
of you familiar with neural networks
this is basically the least means square
algorithm for minimizing expected error
over a set of patterns of inputs and
outputs the wid roll-off rule in fact is
what it's called in engineering so
here's an example of how we study error
correction learning in people we teach
them to be tarot card readers gypsy
fortune tellers and we present them with
many trials that have patterns of cues
like this one and we say do you think
this predicts rain or sunshine tomorrow
and that they'll push a button rain in
this case and turns that it is a rainy
day and so they get positive feedback
and then from this learning of this
pattern they may see another pattern
with other cues and think oh well maybe
this is also predicts a rainy day but in
fact it's a sunny day and we give them
many many trials like this may fifty a
hundred sometimes even two hundred
trials and the way in which the
experiment is set up is that there are
different for different cards which
occur a concurrent any trial and they
have probabilistic relationships to
different outcomes so the card with the
squares at the top is associated 20% of
the time with sunshine and 80% of the
time with rain and what we what we're
looking at is how do people learn these
sort of probabilistic rules these
associations between cues and outcomes
and back when Eddie and I were graduate
students at Stanford working with Gordon
Bower there Gordon and I had argued that
the way people learned this is
fundamentally the same as the way that
animals learn classical conditioning
like Pavlov's dog learning that the cues
predict food and that one could capture
this at an algorithmic level in a simple
connectionist or neural network that
associates the cues as well as
combinations of the cues which the
different outcomes good weather and bad
weather and that trial by trial the way
that people adjust that their underlying
knowledge of these categories is through
this kind of error correction procedure
that that's found in animal conditioning
so that the learning on any trial is
governed by some learning rate beta
times the prediction error the
difference between the actual category
rain or sunshine and the degree to which
the person expects these two different
categories and we showed that at a
psychological level one could account
for
range of data on people's choice
behavior and probability estimates and
so forth so this form the background for
some of our current work and let me just
give you a brief interim summary of what
I've discussed so far
so one contiguity and frequency are key
to associative learning to the cue
outcome learning only occurs when a cue
fails to predict an outcome and that the
Association weights changed to correct
the prediction error and three this same
error correction principle that was
originally developed as studies of
animal conditioning also apply to how
humans learn probabilistically defined
categories so now let me turn to the
basal ganglia brain structure which i've
argued is critical for how we learn from
feedback about our actions so the basal
ganglia are shown here and what's
critical about the basal ganglia is that
they are modulated by projections from
deep in the midbrain which send dopamine
a neuromodulator which is critical for
the functioning of the basal ganglia and
the reason this is a particular
relevance is that there have been some
studies of these dopamine cells in
monkeys and I'm going to show them to
you right now and you'll see why they're
relevant
so in work done by Wolfram Schultz and
others they showed that if you record
from these dopamine cells these cells
which project dopamine to the basal
ganglia during conditioning where a
monkey is being trained that different
cues do or don't predict a juice reward
if you look at the outline to insert the
red dotted line that shows what what
those cells are doing at the point where
the juice either does or doesn't occur
and what they found is that those cells
are firing in proportion to this the
error signal the the error term the
prediction error from this restore low
Wagner model so when the monkey has does
not expect the juice and the juice
occurs there's a positive prediction
error in the dopamine cells fire when
the monkey is well trained that the cue
predicts the juice and it expects it
there's no firing and if you look you
can see it's a little bit subtle when
the monkey expects the juice and there's
no juice presented you'll see there's a
dip in firing there's normally a
baseline level of firing in these
dopamine cells and when the animal is
disappointed it shuts down a little bit
so we see here that there is this
mapping between these algorithms these
correction learning algorithms enduring
learning and what these dopamine cells
are doing in the brain so this work was
all done in in monkeys and our interest
was how does this help us help inform
our understanding of how people learn
more complex cognitive categories and
one approach is to look at patients with
Parkinson's disease and Parkinson's
disease although it's primarily known as
a motor disorder it actually also has
cognitive components as well and what
happens in Parkinson's disease is that
these cells in the substantia nigra one
of the regions that's projecting
dopamine to the basal ganglia die off
and in fact by the time someone first
presents with the symptoms of
Parkinson's this the tremors and the
shaking of a stiffness they've lost
about 70 to 90% of these dopamine cells
so it gives you an idea of just how much
redundancy is built into the system so
our first expectation was given that
these people Parkinson's patients have a
loss of these error cells we de might
expect them to be impaired at learning
from error correcting feedback and
that's exactly what we see when we train
Parkinson's patients compared to healthy
controls on this weather prediction task
we see that they are impaired and that's
exactly what you would expect if in
these sort of error correction models if
rather than a full error signal you have
a significantly reduced error signal
because these error term these error
neurons are have lost about 90% of them
so another approach is to look at
functional brain imaging to put people
in a magnet and have them do the task
while while solving this problem and
what we found is the following can't the
is that early in training the medial
temporal lobe which is a brain region
I'll talk about later starts out high
degree of activity and drops off and the
basal ganglia that can't see so well in
the light green the basal ganglia a
particular region of it called the
caudate nucleus starts out low and
increases so as as the person is
learning this task the basal ganglia are
growing stronger and stronger with
exactly what we would expect if the
basal ganglia is critically involved in
this sort of learning from feedback
we've also looked at trial by trial in a
brain in the magnet at the trials where
people are either getting positive
feedback or the trials were they're
getting negative feedback so where
they've either made a correct response
or an incorrect response and asked where
in the brain
is the activity the most different on
those two different types of trials
subtracting one activity selecting the
trials where people got it correct from
the trials where they got it wrong and
the idea where there'd be the biggest
difference is where you'd expect the
brain to be encoding this or the error
between positive error and and no error
and in fact indeed it is these midbrain
this area of these dopamine cells which
is where in the brain you see the
biggest difference between negative and
positive feedback trials so two
different ways of sort of looking at the
brain imaging evidence of the role the
basal ganglia and these dopamine regions
another approach is to look at the
genetics we've looked in schizophrenic
patients at a particular gene that
controls dopamine function in the brain
and there's a bad version of this gene
called the s allele which is involved
which leads to impaired dopamine
function and what we see is that in both
the healthy controls as well as in
schizophrenic patients they're slower so
even stream forgetting the fact that
their clinic that they're impaired even
among healthy and controls it's how you
have this dopamine gene that that
determines to some degree your
performance so brief interim summary
we've seen evidence from clinical
studies of Parkinson's patients from
brain imaging studies and healthy
normals and from genetic studies in
healthy normals and schizophrenic all of
which provide converging evidence that
the midbrain dopamine region and the
striatum which is the the main part of
the basal ganglia are critical for this
kind of probabilistic category learning
so this leads to the next question how
do rewards and errors chain back in
sequence and by chain back in sequence
I'm referring to the following question
so you have here on the left a mad
scientist who's working late in the lab
the question is why does he do this why
why are you here and because back in the
university they don't have free food in
the cafeteria so why is he working late
well one way to understand it is look at
the chain of reward so the scientist
works late in the lab then his paper
that his work leaves two publications in
science this leads to a lot of grants
from NIH and NSF which allows him to pay
himself summer salary
which allows him to buy a sexy car which
drives the girls wild which in turn
leads to the primary reward so we see
here that there's a a chain
of a reward from behavior to reward
through many intermediate steps and if
we go back to some of these studies from
monkeys and these dopamine cells we see
very much the same sort of thing this is
the same type of recording I showed you
before of monkeys who are being trained
that a cue predicts juice and what you
see is when there's an unexpected juice
the the the cells fire in response the
reward but when the cue predicts the
juice as we said before the dopamine
cells no longer fire to the juice but
now they were fired to the Q so now the
Q has this sort of reinforcing property
that the juice used to and if you have
another Q q2 which predicts the q1 then
you see the dopamine activity goes
earlier and earlier so what happens is
you get this chaining backwards a reward
through a sequence of cues which
ultimately lead to some primary reward
so we asked does this what we then
expect to see similar involvement of the
basal ganglia in humans and how they
learn to sort of chain rules chain cues
to get to reward and the way we've
studied that is in a task where we train
people to make their way through a house
and get outside to get to the the gold
reward so you would be here for example
if you're an experiment you'd be in a
room that has a blue red and a white
doors you would learn to press the blue
door you'd exit from there to another
room which has a green yellow and pink
door once you're in that room you then
press the pink door and that gets you
out to the goal so you've learned this
chain of responses in each room to get
from one to the next and the way in
which we we train people as we start off
with the simplest of training them to go
from one room to know which door leads
to the reward once they've learned that
we bring them back a level and train
them for another door and all the way
back till by phase four they've learned
their way from room to room to room to
room with three sets of rules to get out
and what we found is when we test
parkinson's patients by de novo this
means patients who've never been
medicated so they've they've just
presented with the disease but are not
yet put on medication that as the length
of the chain increases and it becomes
critical to have sort of a sequence of
these rewards that these Parkinson's
patients are very significantly impaired
which is what we expected compared to
controls who are able to do the task
quite well
again genetics provides another way of
understanding how the different brain
regions are involved in this kind of
learning if we look at people with a
whose are healthy normal people who have
a particular genetic variant a gene that
is a risk factor for Parkinson's but are
otherwise healthy those people who have
the risk factor show the same
qualitative deficit they're impaired at
learning they're more impaired at
learning this this chain of sequences
and this is a gene it's known to be
involved in dopamine production as well
so brief summary we can see that
behavioral studies in Parkinson's
patients genetic studies and normals and
another study I didn't talk about here
all suggest that dopamine plays a
critical role in sort of this guiding
the sequence learning of how we chain
back from rewards so is this learning
the next question is is this learning
really selective for feedback learning
or is the basal ganglia involved in all
forms of learning so people don't like
the weather prediction tasks it gets a
little boring so we have another version
which is the mr. Potato Head task where
we have mr. potato heads who have
different features hat glasses mustache
and bowtie each of which has a
probabilistic relationship to an ice
cream flavor and it's the same basic
structural task but you're basically
playing a baskin-robbins counter clerk
trying to predict whether a customer is
going to ask for vanilla or chocolate
ice cream and it perceives the same way
you see a customer you asked which
flavor does he want you say he looks
like a vanilla lover and in fact you get
positive feedback and you learned
otherwise just the same and I'm this
kind of learning we see the same sort of
incremental learning over blocks of
trials that when we train people they
get better and better showing higher and
higher percent correct responses so
that's the feedback learning that we've
talked about so far another way is just
to stand outside Baskin Robbins and
watch the people come out and just look
at what kind of ice cream cone they're
they're eating and we see here we just
so we train people that way they just
look at these people with the ice cream
cones they press next to see another
customer and they go through like that
and there's no response required at the
very end of this sort of observational
training because we're not collecting
any data then we ask them to classify
people classified the potato hit mr.
potato heads as I
yellow vanilla or chocolate and what we
see is regardless of how they're trained
whether they're trained on feedback
whether the train by just observational
they show the same overall performance
on a transfer task to classify them so
behaviorally it looks like the learning
is the same but the question is are
these people really learning this the
same way even if their performance is
the same and we know from the past
studies that that the feedback learning
uses the basal ganglia the question is
what other brain region is involved in
this observational learning and what we
found is we compared these two types in
in a brain imaging study we compared the
feedback learning and the observational
learning and asked which brain regions
are differentially active in one versus
the other and as we expected the
striatum which is the main part of the
basal ganglia is more active and
feedback training consistent with what
we've seen before but the hippocampus
this other brain region that I've
mentioned and the prefrontal cortex are
more active in observational learning so
even though we see the same overall
behavioral performance it seems like
they're being learned by two different
brain regions so we've noted that that
since the observational training
recruits two hippocampal region not the
basal ganglia then and and Parkinson's
patients have damage only to the basal
ganglia not the hippocampus you might
expect then that Parkinson's patients
should be able to learn this dismiss
categorization if we encourage them to
use their hippocampus by presenting the
information in an observational
framework rather than a feedback and
what we found when we replicated the
study with patients is that as we've
seen before Parkinson's patients are
impaired the PD patients are impaired at
feedback learning just like with the
weather prediction task but when we
present them with the observational
training the deficit is remediated so it
suggests one way of remediating some of
these deficits by training people in
ways that recruit other brain regions
that aren't damaged by the disease so in
summary the brain imaging suggests that
feedback learning recruits the striatum
from the basal ganglia observational
learning the hippocampus and the
prefrontal cortex and that in
Parkinson's patients we see consistently
that feedback learning is impaired and
observational learning is okay so that's
four
sort of the end of this or the basal
ganglia part taking about 20 minutes so
now what I wanted to is shift down to
the hippocampus which we've argued is
involved in developing new
representations of the world
so is there more to category learning
and how we learn about concepts than
just error correction or as Gary Larson
would say stimulus response stimulus
response don't you ever think and back
in the 50s but a little bit of sort of
history of psychology here when there
was this big movement of behaviorism and
studies of associative learning there
was a rebellious behaviorists or the the
origins of cognitive psychology and
Edward Tolman and he said well not all
learning is going on because you know
you're giving the animals juice or
you're presenting them with food that
animals are trinsic lee motivated to
learn about the world he argued that
that they form cognitive maps of their
environment without any specific
learning and that he argued that even
without rewards or punishment late
learning this was the implicit learning
about our environment in the regulation
environment goes on naturally and
automatically without necessarily being
reinforced in one way or the other and
one example from an animal paradigm of
the kind of learning that that he's
referring to is called latent inhibition
and in latent inhibition there are two
groups of animals one group of animal
just sort of sits in Phase one nothing
happens and then it's trained that the Q
predicts the u.s. the u.s. is the
unconditioned stimulus and in psychology
parlance it's something like the food or
the shock the the significant thing
you're predicting and these animals are
just learned normally and he compared
them to an animal that had been pre
exposed to the Q so in phase one the Q
which might be say a tone is just
presented randomly the Q occurs every
now and then the tone occurs nothing is
followed by it and then in the phase two
the animal tries to learn that that Q
predicts the outcome and it's much
slower it's as if in that first phase
when it was exposed to that Q in the
environment without predicting anything
the animal learned that this Q is
irrelevant and therefore as you see at
the bottom that animals that are exposed
make many fewer correct responses in
Phase two they're much slower to learn
and this is not accounted for by the
error correction learning because if you
think about phase one that Q is a
neutral Q it predicts nothing nothing
occurs so the error correction
notion of learning doesn't account for
whatever is happening in phase one where
the animal is learning to tune out this
irrelevant cue and it's such a way that
it's slower later to learn about it so
what's missing from the risk or doe
Agner model this error correction
principle what's missing is latent
learning learning without responses or
rewards such as latent inhibition or
observational learning standing outside
the basket and Robbins and just learning
by watching people walk out as well as
what Tolman described as learning the
cognitive or the psychological maps of
the world are our ability to sort of
automatically understand our environment
and try to map it internally and what's
particularly interesting about these
what's missing from these this sort of
error correction principle is the fact
that these same behaviors are also
missing in our missing in animals that
have damage to the hippocampal region so
if you take an animal and you leash in
the hippocampus or as I'll show in a bit
if you have a human who has damaged the
hippocampus these sorts of behaviors
that that are beyond the scope of
error-correction learning disappear so
it suggests that this hippocampal region
may well be critically involved in this
sort of latent learning that Coleman had
talked about so if you've taken an
animal and you remove the hippocampus
simple acquisition is normal the animal
can learn you know Q predicts an outcome
but if you do something like latent
inhibition what you see is that the
control data is what you just saw a
minute ago but animals with hippocampal
damage don't show that effect in fact if
you compare the hip exposed condition
the animals that have been pre exposed
to the Q in phase one you'll notice that
the hippocampal lesion danimals are
learning faster and better than the
normal animals so it's actually a very
sort of unique case where the brain
damage is actually improving performance
in this case because normal people tend
to tune out these cues and have trouble
learning from them animals with
hippocampal damage don't tune it out so
they're actually faster to learn so you
might think well that it's going back to
acquisition sort of learning simple cues
for a long time people thought that well
the hippocampus isn't involved when
you're learning something sort of simple
Association tone predicts shock or
something like that but in fact even
though there's no effect of the
hippocampal lesion on these animals if
you look inside the brain
the hippocampus in particular is showing
lots of activity which models the
response which looks just like the
behavioral response in this case a blink
to it to a cue so it suggests sort of a
caveat that even though a brain region
is not needed
it clearly participates in even the
simplest form of learning and the
question that we pose is what is it
doing it's clearly involved in this
latent learning its ears doing something
in the simple acquisition even if it's
not evident in in just the trials two
criterion learning and so let me give
before I sort of talk about some of our
thoughts about what the hippocampus does
let me give a brief interim summary
latent learning is learning about the
world without explicit consequences such
as reward or punishment
one example is latent inhibition this
task I talked about where this is pre
exposing to a cue latent learning is not
explained by the risk or low Wagner
model of error correction but
hippocampal region damage impairs latent
learning which suggests that something
about latent learning learning from the
environment learning from cues you're
just exposed to is critically involved
with hippocampal function and finally
the caveat that the hippocampus isn't
necessary for simple acquisition but
it's clearly involved somehow so what
does the hippocampus do this has been
for many years the $64,000 question in
the neurobiology of learning and memory
what does this brain region do everybody
knows it's important for learning in
memory but but to actually pin down what
is it's algorithmic function in the
brain has been difficult and so in
psychology when we're faced with the
problem that troubles us we remind
ourselves which is a reminder to think
back to our ancestors and ask ourselves
what would William James do the William
James was the father of American
psychology he was the first professor of
psychology at Harvard University and he
wrote the first textbook of psychology
and introduction to psychology and in
this textbook he he has the following
quote he says if all cold things were
wet and wet things cold if all hard
things pricked our finger and none
others did so would we come to
distinguish between coldness and wetness
and hardness and pungency respectively
and what James was saying in this in
this paragraph was that there many
things in the world that tend to
co-occur coldness and wetness there are
a lot of
that are cold and wet through a lot of
things that are hard and pungent what
we've now called sharp that co-occur and
he was arguing that when these these
features in the world tend to co-occur
we have a tendency to cluster them
together to treat them as some unitary
hole and it's a principle we've
described as redundancy compression
we're done in an informational sense
when two cues are informational
irredundant
we tend to compress them and treat them
in unitized fashion James also described
another experiment that he did at
Harvard back in the eighteen hundred's
where he initially was not much of a
wine expert and claret and burgundy to
him tasted just the same and so he
decided to train himself to see if he
could distinguish them and so he sat
with a bottle of wine and a bottle of
the other and although initially they
tasted the same as he drank from one
glass and then the other glass then the
other glass and the other glass and so
on and so forth before he passed out he
began to sort of extract out the sense
of what it was that that made the
distinguishing between a claret and a
burgundy and this is a principle which
one can think of his predictive
differentiation that initially when
things may seem very similar that if
they're mapped to different outcomes or
in this case they're mapped to different
bottles or the labels on the bottles
that you could you learn to distinguish
them in such a way that ultimately they
seem much less similar and we talked
called this predictive differentiation
so the idea is that when a Q it predicts
two different outcomes will tend to
differentiate these Q's so where does
this occur where does redundancy
compression so this was James described
as a high over 100 years ago as being a
psychological theory of how our
understanding a representation of the
world changes where does this occur in
the brain so one way is to do what I
would call a brain imagining study is I
put myself in a magnet and asked what is
it where can you see redundancy
compression and predictive
differentiation in the mind of a New
Yorker like me and this is what a New
Yorkers brain looks like in New Yorkers
map of the world and there are a couple
of things that one should note about in
New Yorkers view of the world that if
you look up in what we call the dorsal
region of the map you'll see redundancy
compression so New Yorkers tend to view
all states in the Midwest that begin
with the letter i' is being functionally
equivalent on the other hand if you look
down in the what we call the ventral
region you see predictive
differentiation
we know that the best Thai restaurants
are a ninth Avenue and there's nothing
on tenth Avenue and so we tend to we
tend to expand out that this region of
our brain and so this suggests that the
hippocampal region we've argued is
critical for these sorts of distorted
maps that they create mental
representations that expand
representations that need to be
differentiated and compress over those
that are functionally equivalent and the
way in which we've argued that this
takes place in the brain is through an
interaction between two different brain
regions the hippocampus which is
monitoring the world and this sort of
latent fashion taking all the
information in that comes in and
developing new representations that look
a bit like that New Yorker cover which
are biased by by the regularities in the
environment the redundancy compression
and the predictive differentiation and
that those are then adopted by other
brain regions and in one sense from a
psychological perspective one can see
this as sort of mapping to different
traditions into two different brain
regions that the the cortex and the
cerebellum where long-term memories are
stored are capturing the sort of
learning that Aristotle talked about in
halt and restore Lynn Wagner the sort of
learning of these associations of
stimuli to outcomes and behaviors and
that the hippocampal region is capturing
more what Tolman was talking about when
you talked about latent learning and
James with these changes that is sort of
how we develop our representations of
the world and how we alter what's
similar to what and that they work
together and how can these P be
instantiated in the brain I want to give
sort of just a very brief sort of
characterization of some of the kinds of
Network models that one can develop to
capture these principles and this is not
necessarily how the brain explicitly
does these sorts of computations but it
suggests a way in which a complex
associative Network can begin to develop
associations and learn mappings using
these principles so a very simple model
which we developed suggested that one
could think about the long-term memory
the cerebellum or other brain regions as
a simple feed-forward network of
associations from the stimuli to the
output and that what the hippocampus is
characterized as is what we call an
autoencoder it takes everything in the
world and maps it to what's essentially
the next step of everything in the world
so all the
Hugh's mapping to all the Q's plus the
the prediction of the US the sort of
critical thing we're trying to predict
the food or the reward or the shock and
that it does so to a narrow channel so
essentially what this is doing is sort
of what the similar what happens when
you do a compression of a data file so
if it's compressing out the redundancy
through this narrow channels developing
a new representation but because this
representation has to be able to predict
the next step the next relevant outcomes
it's it's compressed except it also has
to be differentiated based on the things
that are relevant for you to
differentiate and what we argued was
that this sort of kind of architecture
this what's called an autoencoder
develops representations which are
compressed and predictive and that other
brain regions use this and what's
critical for this sort of learning is
novelty detection in other words that
you the system is constantly sort of
building a map of the world through this
network on the right and when something
comes in that it doesn't recognize it
encodes it and decodes it in this in
this two layer network and if it doesn't
match it says we need to adjust the
weights because there's something new
and different in the world what happens
when you remove the hippocampal region
in an animal or a person and I'll talk
about the ladder in a second what you
get is basically a very simple error
correction network left that that just
uses whatever the fixed representations
that it had originally and this
approximates the sort of risk or love
Waggoner error-correction learning that
I talked about a minute ago so this is a
very brief overview of one kind of
connectionist architecture that gives
you that and we showed that this model
is able you know we will compare the
intact model with the lesion model to
the data and as you saw before we see
the model accounts both for the fact
that simple acquisition is unimpaired by
the lesions but in latent inhibition you
see a facilitation that the lesion in
the lesion model is actually faster to
learn in Phase two
and the reason it's faster to learn is
that what's happening in Phase one when
when the model is exposed to the queue
is it's not just exposed to the queue
it's exposed to the background context
what in the animal experiment would be
the box and the lights in the room and
because the queue and the and the
context are co-occurring and they're
redundant they tend to be compressed
together so what you're actually seeing
in
model is that it's it's beginning to
treat that q is part of the context to
compress it all down together and treat
it all as the sort of unitary irrelevant
context and so why learning is slow in
phase two is that the network has to
RiRi organize the representation so as
to extract out the cue and differentiate
it from the background context and it's
that necessity of re representing the
information that slows down the learning
in the intact model and explains why the
intact model and intact animals are
faster to learn are slower to learn and
for those who are interested in learning
more we have a book which Eddy referred
to which describes in more detail some
of these kinds of theories of the
hippocampus so the interim summary the
hippocampal region is involved in
developing mental representations that
reflect regularities in the world bias
by redundancy compression and predictive
differentiation these are then used by
other brain regions that store long-term
memories and the loss of the hippocampal
region is associated with learning that
takes place with non adaptive stimulus
representations of a rigid view of the
world so what are the implications of
this for people with hippocampal damage
one way we get people hippocampal damage
is people who've had an anoxic episode
they've lost oxygen to the brain and
this basically destroys the hippocampus
it doesn't kill them and we study these
people these people like you saw the
movie memento the sort of someone whose
amnesiac they that all their old
memories are intact but they can't learn
new information and new facts and we
train them in two different types of
experiments they're all the experiments
have two phases one in which they're
exposed to some regularity where we
expect that if they had that a normal
person would be developing a
representation that encodes that
regularity and then we either have a
positive transfer where they have to
learn something that uses the same
regularities so the pre the phase one
should be helpful or we shift it so that
there's a different regularity going on
they need to learn and if they were
exposed to regularity early on and they
learned it that would mess them up a bit
and what's particularly interest is
these negative situations like latent
inhibition because it suggests that the
brain damage should actually facilitate
learning because you're giving the
brain-damaged person an exit from making
having a mistake in reorganization that
the normal person will do so learned
irrelevance is a paradigm which is
basically the same as latent inhibition
except that early in training you're
exposing people not just to the queue
but to the queue and the outcome the CS
and the US but they're uncorrelated so a
tone might occur occasionally a shock
might occur occasionally but they're not
paired together in any way in phase one
and then in Phase two the tone is paired
with the shock and you look at how long
it takes an animal to learn tone
predicts shock so the human version of
this involves training people with a
task we call Merlin can you predict
whether there's a rabbit under the Hat
and you see these trials and in this
case there is a rabbit under the Hat and
the question is how do you learn to
predict that and the way in which we do
the study is there's a phase one the
exposed group similar to the the animals
that have seen the queues uncorrelated
there's a word a magic word in this case
bleh which tells you whenever the
magician says bleh there's gonna be a
rabbit under the Hat and all other words
there's no rabbit and the colors of the
balloons vary and are irrelevant and
then in Phase two the colors become
relevant and in fact there's now a
rabbit under the Hat whenever the
balloon is red and we compare that to
people who get the same phase two but
they're not exposed to the color in
phase one they're learning that bley
predicts the rabbit but there's no color
so it's functionally the same as a
situation with the animals where you're
either exposed to a cue or not exposed
to a cue and then you have to learn
about that cue and what we expect is
that healthy controls should look just
should show this learned irrelevance
effect and learn more slowly in Phase
two and that's exactly what we see that
this in this case we're looking at
errors that people who are exposed in
exposed condition make many more errors
in Phase two on the other hand and
magics are learned faster than the
exposed controls in the exposed
condition so we see here that they're
doing better again like in the animal
conditions
these amnesiac patients were overall
massively impaired are doing faster in
the the phase two and they're completely
normal on the phase one another way of
looking at some of the implications of
these representational changes in the
brain is a situation where there's a
positive transfer where something that's
relevant in phase one applies to Phase
two we have a task that's similar to the
card games that they play in the city
where you're trying to figure out where
is there a peanut in this case where
there's a smiley face and the smiley
face you might guess left and in fact it
is underneath the red octagon and we
train people on many different pairs
like this and in some of the pair's
there's a color rule so that there's a
red versus yellow and the shape is
irrelevant it's constant and in others
there's a shape is relevant so this case
Square Green Square beats green triangle
and and the the color is constant in
irrelevant and we have four of each and
then later on we shift them in Phase two
once they learn phase one to this which
they've never seen before and given that
you've never seen it before you might
just guess randomly or you might have
extracted the relevant rule from phase
one which said that that red beats
yellow in which case if you had
extracted that relevant rule you had you
would guess correctly so what we
basically have here is concurrent
discriminations with the rule and the
rule stays the same from phase 1 to
phase 2 but the irrelevant aspects
change and what we're looking at is our
people when they're learning in phase
one are they just learning about the
specific items that's good enough to
solve phase one or they extracting the
general principle that allows them to
apply it in a broader range of
situations and we expect that the
hippocampus is critical for this that
it's critical for developing these
appropriate representations and so what
we see here in these amnesiac patients
is that everyone is at both the controls
and the amnesiac Tsar perfectly fine and
during phase one they're able to do
simple learning but in phase 2 the
amnesiac make many more errors it's as
if they're starting over from scratch so
and although they still remember that
the discriminations from phase one which
we test otherwise but it shows that
however they learn phase 1 although it
seems normal they haven't learned it in
a way
it allows them to apply that knowledge
more generally when some of the features
change another population that has
hippocampal damage is people who are on
the route to having Alzheimer's so
before you actually have Alzheimer's
you can see in people the beginning of
shrinkage of the other hippocampus and
it's a very mild degree of shrinkage and
in fact if you test people
neuropsychological a with memory tasks
they look normal and our question which
had a lot of clinical relevance was
could we develop a behavioral task which
picks out these people who from imaging
we know have the beginning shrinking of
a hippocampus which is a sort of a
warning sign of getting Alzheimer's but
before they actually show any behavioral
deficits on standard neuropsychological
assessments so here is a standard
neuropsychological assessment this is
just read a paragraph five minutes later
ask people if they remember the facts
and you can see that people who are
these elderly who have a little bit of
hippocampal atrophy that's the yellow
the H a hippocampal atrophy they show no
deficit on this delayed paragraph recall
on the other hand when we take the same
group and we do it on our discrimination
transfer task what we see is that
qualitatively these people who have are
completely normal behaviorally look just
like our amnesiac s' that they learn
fine but they show a significant
impairment when it comes to the transfer
so what this suggests is that if you
lose your hippocampus all of it there
are these massive deficits in learning
new information that are obvious but
they have just a little bit of damage
that the first thing that you start to
see are these generalization deficits
and we've done some other work we've
followed up these people five and
sometimes eight years later and what we
found is that the people who did poorly
on our transfer task independent of how
they were sort of characterized
clinically are the ones who are the most
likely to convert five actually I take
it back this is two years later most
likely to convert two years later to
either MCI which is sort of a mild
version of Alzheimer's or to Alzheimer's
itself so suggest that these sorts of
behavioral measures might actually have
a clinical relevance in predicting
cognitive decline the sequence learning
task I described to you before when we
take these a population of people who
have a MCI so a MCI are people in this
early sort of pre Alzheimer's stage who
are showing amnesiac deficits the
showing memory loss
in this case they're there obviously
people who've come into a clinic because
of this memory loss they're very likely
to get Alzheimer's in the next few years
they're quite they're totally normal on
this task so that's one of these
interesting that even though these
people are much more demented than the
de novo Parkinson's patients they're
unimpaired at learning the sequence
tasks on the other hand we did a
transfer task which I didn't mention
before which is after you do the
sequence learning task we gave them the
same sequence but we changed around the
distractor doors and in fact in some of
the rooms we've put one door which was a
correct door in another room and as well
as a totally incorrect one so we changed
around the context of the distractors
and then what we found is that the
Parkinson's patients who had been very
impaired at learning they weren't
affected at all by this but the amnestic
MCI patients these sort of pre Alzheimer
patients who were completely normal at
learning it they broke down on the
transfer so we see that same pattern
that damage to the basal ganglia slows
down learning but doesn't impair your
ability to use the learning once you get
it damage to the hippocampus will not
impair simple learning but we argue that
it's that you're learning it in a
dysfunctional way that doesn't
generalize so an interim summary here as
predicted by our model you see these
transfer generalization deficits on this
learned irrelevant the Merlin tasks on
the concurrent discrimination task on
the acquired equivalence task and the
question is why do you see these these
deficits on transfer demo different
transfer generalization and we've argued
the reason you see the deficit in Phase
two isn't because of a problem in Phase
two isn't because of a problem going on
in the generalization it's because of a
problem that occurred back in phase one
when people were learning these tasks
but they were learning it in a way that
didn't have input from the hippocampus
and therefore was dysfunctional in some
way and let me give you an intuitive
understanding of what's going on
in our model that provides the
interpretation for this so the question
is how does the hippocampus improve
generalization and in our model the
hippocampus is essentially providing a
support role as developing the
representations that are used that are
used to create the rules that are used
by other brain regions so one
if thinking about an brain network or a
simple mathematical model of a network
is in terms of the state space so every
possible state of this network is is a
highly dimensional space in terms of all
the possible different weights there
could be on every single link well
simplify and think of a two-dimensional
space here and so every every possible
state of this network is a point in the
space when the network begins it has
some initial status there and learning
in in this geometric representation is
simply moving from one point in the
state space to another as you adjust the
weights as you change the rates you move
to another point in the space and so
learning is getting from a place where
you're not performing well to finding a
point in the space we are able to
perform in most the kinds of tasks
because you have such a high dimensional
space of possible solutions in these
networks in the brain the training
problems under constrain the possible
solutions there isn't just one Network
solution in most cases there's a whole
sub region of the space that will solve
the training task because the training
environment under constrains the
possible solutions and what a network
will do as it's trying to reduce the
error is it will basically find the
closest point in the solution space and
it will move in that direction directly
and as soon as it gets to one that
solves that it will stop because it's
doing this sort of error correction
learning and once it corrects the error
anyone will do so learning without a
hippocampus we've argued is basically
doing but what network theory is called
gradient descent it's moving to the
closest part of the solution space
however that part of the solution space
there's a subset of that solution space
for the training which is the solution
space which is one good thing is the
most parsimonious the solution space
which not only solves that the training
task but is the most likely to
generalize to a broader range of
situations that haven't been experienced
yet and so what we've argued is that
what happens with the hippocampus is the
hippocampus actually makes it harder to
learn because it says it's not enough
just to get to the solution space and
and solve it but you have to sort of dig
deeper and find the region of the space
that's going to be have other
constraints and in particular this
couldn't be a constraints that that the
representations use to solve it have to
satisfy these constraints
of redundancy compression and predictive
differentiation so basically those
constraints redundancy compression / key
differentiation are added to the problem
in training and they therefore constrain
further the set of optimal solutions and
what we've what we've sort of argued in
these experiments that I've shown before
is that without the hippocampus you can
learn fine but you don't transfer well
because you've found a suboptimal region
of the solution space for the training
tasks so let me just skip here and talk
a little bit about how does some of
these ideas map on to some apply the
issues some some problems of machine
learning because I understand there's a
lot of interest here in machine learning
so we've done a bunch of work over the
years with the the military with the
Navy and with DARPA taking asking how is
it that we can take these brain systems
for pattern recognition for novelty
detection for classification and begin
to apply them to real world problems so
one we worked on is sonar classification
we have a lot of data on sonar signals
that have come back from brock's versus
Mines different categories from
biological signals versus submarines and
the question is how do you sort of
classify them into the different
categories obviously a problem of
relevance to the Navy and this is not
very high contrast I don't think I need
another thing I'm going to use green
anymore here so can people see that
graph there so what I'm graphing here is
we have a body of data that's
categorized we start with 25% of the
database and we train it using a simple
that this BP net is a simple back
propagation Network a simple
feed-forward Network and what we're
graphing is over training the mean
squared error which is sort of a measure
of the global fitness the smaller the
error the small the better it's doing on
all the possible sonar signals and what
you see in a typical graph like this is
a cross training this is 5000 blocks the
error graph goes down that's exactly
what you expect but the problem is that
each point in training we said well at
the network at this point how is it
doing on the other 75% of the sonar
signals that it's not being trained on
and what you see here is in fact it's
actually getting worse
and this is that I mean it starts out
here and as you train it gets worse and
worse and this is a phenomena that's
familiar to statisticians known as over
fitting that what's happening is that
even as it's getting better on the
training signals the error is increasing
on the generalization because it's it's
overfitting the training data it's
picking up more and more of the
idiosyncrasies of this small subset of
the data and it's making it actually
worse to generalize in comparison we
looked at our cortical hippocampal
network which is very similar this back
propagation network except that is
constraining the solutions that are the
internal representations so that they
are additionally constrained by
redundancy compression and predictive
differentiation as you see much like we
saw with the the patients there's no
different for so the simple learning ok
the error graph looks the same but the
difference comes when you look at the
transfer generalization that what's
happening here is as you continue to
train on the 25% of the training sample
that you're getting better and better
and better it transferred and
significantly better than with a simple
Network so what we see here in an
engineering application is the same
principle we saw with these amnesic and
Alzheimer patients which is that adding
these hippocampal constraints it's
similar in some sense to just to put it
into the local vernacular you can think
of the hippocampus then is determining
the PageRank of different solutions that
there are a number of different possible
relevant solutions and rather than just
sort of coming up with any number of
ones that are going to work the
hippocampal region is creating a metric
of sort of optimal solutions given given
what's the input for training and that
metric is helping it identify the
subsets that are going to be of most
relevance and most interest when you
come to generalize to something new so
that's one application another
application is the problem of novelty
detection I mentioned that the way in
which our system works it uses this auto
encoder this sort of mapping from the
input to a compressed representation and
back out to the input and develops these
representations and for anytime there's
a stimulus that it doesn't recognize the
the encoding and the decoding are not
going to match and you'll get it you'll
get a mismatch between the input in the
output of this network and that's a
measure of novelty so so the error that
the mean squared error on these output
nodes is a measure of the novelty of an
impasse simulus and
the quest
determining novelty is a wide range of
applications for example if you're
flying a helicopter and the gearbox is
making a funny vibration that's
something you want to know about you
don't really care why it's vibrating you
just know that if this is a vibration
it's never made before this is not a
good thing and there are a lot of
problems where people generally love
think about sort of pattern recognition
but novelty detection is a very relevant
domain where it may be very hard to get
examples of a novel system so it's very
hard to collect data on what a how a
helicopter gearbox vibrates when you're
flying it okay you collect a lot of data
on good helicopter gearboxes that's easy
but not many pilots are gonna want to
sort of fly a helicopter that's impaired
just to collect data for your neural
network thesis so one of the things we
did is we worked with the Navy on the
actually this is a problem with
submarines come back to helicopter a
minute where we're looking at the pumps
on submarines collecting data on
training them so we took all the
submarines that the good the good pumps
and we trained it so that ultimately
there was sort of on the training that
these are all sort of no fault pumps
good working puffs and then what we did
is we looked at test pumps that were
either faulty or no faulty and what we
found is that the faulty pumps generated
a much higher novelty score in our
hippocampal network so the idea being
that if you train the system to sort of
recognize the environment of a of a
healthy pump and then when you present
it with something that's not healthy its
aberrant in some way you don't really
care what way but its novelty signal is
different so you can use these sorts of
autoencoders as a way to build
effectively statistical models and we've
also done a lot of work with the Navy
with helicopters and in fact we had a an
incident where the Navy had sent us a
whole bunch of data including what they
say were good training helicopters good
training data from recently rebuilt
gearboxes on the ch-46 helicopter and
one of the databases just looked way out
it was a big outlier from all the rest
and so we sent a message back to the the
7th fleet in the Pacific it would send
us this saying we have a problem with
this particular helicopter data it
doesn't look very healthy
no no that was just rebuild three months
ago back in San Diego but nobody wanted
to be the guy who sort of ignored it so
they took the help they took it that was
actually out in the Pacific and fleet
maneuvers they took the gearbox out they
shipped it back to San Diego and sure
enough when they had rebuilt the engine
someone had screwed in one of the parts
wrong which ultimately would have been a
catastrophic fault if it had happened at
sea so there's the kinds of applications
where you can see that novelty detection
plays a way of sort of building a model
of your environment and recognizing when
something goes wrong so that brings me
to the end
any mention there's a book we have a
book that's actually coming out this
next month if anyone's interested in
understanding the brain mechanisms of
learning and memory models of learning
and memory and how they break down this
is a new book that will just be out so
thank you it brings me to the end so I'd
love to hear from all of you
particularly you know not only serve
general questions but also these sorts
of applications of machine learning and
generalization and novelty detection are
there any sort of problems you know that
you're working on here for which those
might be relevant approaches
No yeah hi I was wondering if you could
elaborate on the link between your auto
I encoder and the back prop network it
looked like there was there was a line
but a control sure I just skimmed over
that in fact I usually skip over those
slides but for Google I put those slides
back in so the way the model works is
that you have this auto encoder that's
developing these new representations and
then those new representations become
the training signal for the
representations in the back prop net so
basically what's happening is the back
prop net is learning to mimic actually
it's learning some linear transformation
of them so that basically the hidden the
hidden units from the back from the auto
encoder become the training signals for
the hidden units in the multi-layer
network so what's happening in this
long-term memory network is it looks
like a typical back prop net but in fact
the two layers are being trained
independently that the bottom layer of
weights are being trained by input from
the hippocampal region which is telling
it how to represent it and the upper
layer of weights are being trained by
the environmental feedback and that's
your standard error correcting feedback
so when you present training data do you
guys I can't hear you with all the noise
out there
sorry um when you present training data
do you train the auto encoder in a block
and then train the back problem note or
is everything's being trained
simultaneously okay so but what's
basically happening is that the in the
intact system is the long-term memory
Network is learning well it's very well
while the representations are evolving
which is one of the reasons why the
intact model takes longer to learn
because it is it's representation is
moving around and in fact one of the
things you see in in animal literature
is that although the hippocampus is
needed for complex tasks especially
nonlinear tasks like the exclusive-or
that on simple tasks hippocampal lesion
animals do better and part of the reason
we've argued is that it's because an
intact animal is learning more than just
the just the training tasks it's
learning to develop this appropriate
representation and that representation
is is evolving during the early stages
of learning if I could just share it
sure I was asking because I was
wondering if you had low
that sleep and the role of sleep in all
of us because it seems absolutely
absolutely just so we have some studies
that were just that are just about to
come out we've been working with Bob
Stickgold at Harvard Sleep Lab and what
we've been doing is actually have the
data here but never mind I'll just
describe it so what we've been doing is
we've been training people on these
tasks either at 9:00 a.m. and then
testing them again at 9:00 p.m. or
training them at 9:00 p.m. and 9:00 a.m.
and asking what is the effect of sleep
on this learning and there's been some
past work by Bob Stickgold that's argued
that REM sleep is critical for
hippocampal dependent learning but not
basal ganglia dependent learning so what
we expected then if that was the case
here we expected that feedback learning
that we described should not be improved
by overnight sleep but observational
learning which we argued is hippocampal
dependent should and that's exactly what
we found is that is that when we test
people with overnight sleep that the
next morning those who did the
observational training have actually
shown an overnight improvement while
those who did the feedback training did
not accept if we train people for just a
few trials so you saw before I talked
about how I showed briefly that this
basal ganglia activity increases during
learning but that even in feedback
training to sort of an early phase of
hippocampal activity so we train people
just on the early phase just enough
trials so they're presumably still have
a very strong hippocampal component in
the model we'd argue that's because the
representations are still being formed
that early hippocampal activity is is
the developing of the representations
and those people train on just a small
amount of feedback training show an
improvement over night so in both cases
we see that aspects of learning that
recruit the hippocampus are improved by
sleep and moreover when they use the
hippocampus you see more REM sleep the
next night so in fact in fact there's a
correlation between how well people do
and the percent of REM sleep the present
of REM sleep after they did the training
so the REM sleep is essentially an index
of how much you have to encode in memory
and so it suggests a sleep system which
has this homeostatic control that you'll
get more REM sleep if you have more that
you've learned using your hippocampus
that you need to in
that was probably much more than you
wanted to know about sleep that's a
whole line of work that we're doing and
ultimately of course the question is
heck can we come back to the models and
to get to incorporate some of this
consolidation and sleep it seems like
there's another group coming in here so
mark and I going to be having lunch out
in front of Charley's afterward if
anyone wants to join us please come by
and thank you very much great thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>