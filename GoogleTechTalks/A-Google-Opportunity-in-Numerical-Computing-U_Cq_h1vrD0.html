<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Google Opportunity in Numerical Computing | Coder Coacher - Coaching Coders</title><meta content="A Google Opportunity in Numerical Computing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Google Opportunity in Numerical Computing</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/U_Cq_h1vrD0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody thanks for coming my name
is Bill Clark that's a great pleasure
for me to introduce bill bolster I've
worked with briefly in the past and
hopefully will do more in the future
bill is going to be talking to us about
I guess presenting a business case for
why Google should be doing work on
interval computing thanks Bill thanks
Bill delighted to be here as bill said
it seems to me as though there's a big
opportunity for Google in numerical
computing in this talk I'll make some
statements about applied mathematics
numerical analysis and computing that
might be new to you for some of you
anyway I don't know how much time we'll
have to go into great detail kept the
talk sort of at a high level but
everything i say is of course true and
i'll be happy to answer questions either
now or at any time about any of this so
let's begin with something i believe you
will all think is true namely that
google is a leader if not the leader in
providing its users with access to
computers in ways that make them
productive increasing user productive
productivity has been a constant
motivation for innovations in computing
over the years early on in the history
of computing and that sort of continues
productivity was and has been primarily
achieved through increases in speed but
speed alone doesn't make users
productive with increased speed more
resources get to be devoted toward ease
of use examples early on started with
Fortran higher-level languages we're big
increase in productivity then came C C++
Java Python and others in addition
there's been a been constant progress in
operating systems as well as symbolic
mathematics starting with maxima reduce
maple Mathematica and new pen the
graphical user interface or GUI was a
watershed that provided easy access to
computing for many non-technical users
however long sequences of mouse clicks
can be a trap power users tend to still
want to use procedures and scripts to
automate things unfortunately many
applications don't have both a command
line and a GUI interface which sometimes
can be a problem but nevertheless with
all these innovations and advances and
tools and operating systems came added
complexity in the form of layer upon
layer upon layer of options while
options create flexibility for users and
revenue for vendors they can also create
daunting learning curves for beginners
what's needed in user interfaces is
flexibility so that new users can start
with a GUI get productive work done
quickly but then as they need more
options they can find them and use them
and then finally when they need to be
quote unquote power users they can
automate their work done well automation
can raise the level of abstraction used
to perform work that is when sets of
tasks are identified that have a small
interface a new task can be created out
of them this process can then be
repeated and layers upon layers of new
constructs can be developed that have
are more power increasing the level of
abstraction and which work is defined
and performed is one of the most
important characteristics of mathematics
and numerical computing because it's a
key to increasing both productivity and
creativity people can not only work in
higher levels of abstraction but they
can think in them as well so user
productivity continues to be a constant
driver of innovation in computing no
wonder Google appears to be focused on
user productivity Google is leading the
way to the next level of increased
productivity by providing simple
easy-to-use web-based applications in
these applications only those features
that users require need to be provided
because Google's business model appears
to not require a constant stream of
feature releases that users might or
might not want moreover google also
appears more than capable of providing
sufficient speed if not superior speed
at Sun we used to joke how it's faster
to find internal Sun sites using google
than to use sun and turtle search tools
so what will be the next opportunity to
increase productivity and how can google
benefit from it in spite of all the past
advances in speed and ease of use what
is possible to numerically compute has
remained fixed for almost 45 years since
about nineteen sixty four when IBM
introduced floating point arithmetic
shall I repeat that for almost 45 years
what's possible to compute has remained
static fixed why
because a fixed precision floating point
number contains no information about its
accuracy none word length has nothing to
do with accuracy in fact people can
argue and I have argued that prior to
digital computing astronomers and
engineers that used did computing with
paper and pencil knew more about the
accuracy of what they were computing
that we do now we're very fast but we
have almost no information about
accuracy so what are some of the
consequences of this this is why
numerical analysts at the time back in
1964 warned that switching from fixed
point to floating point arithmetic was a
mistake because doing so you threw away
information about accuracy this is also
why in the fort ranch standard there's
not one word about numerical accuracy
even for the result of evaluating an
integer expression in addition this is
also why symbolic and numerical
computing have diverged into separate
products symbolic computing automates
mathematical proofs without great
difficulty nothing can be mathematically
proved using only floating point
arithmetic finally this is also why
computer manufacturers include
disclaimers and customer warnings in
their hardware and software products
that they are not designed for
mission-critical applications in which
there might be serious or even
life-threatening consequences so exactly
how inaccurate can floating-point
computations be there's a famous example
at least in the interval community due
to a man named rump in Germany and the
problem is to evaluate 00 pushed wrong
button evaluate this little expression f
of a and B
where a is this integer be is this
integer and all the constants in the
expression for F our machine
representable okay so there's no
rounding errors on input everything is
exactly machine representable to start
with a conventional wisdom which I'm
sure most of you have heard is that well
if you're worried about accuracy do it
in double precision and see if you get
the same answer and the assumption is
that if you get same answer in double
that you got in single then you're safe
well in this example using I Triple E
754 round to nearest floating-point
arithmetic you get in single-precision
this answer and double precision this
answer notice this rounds to the same
value and then in quadruple precision
you get exactly the same answer okay let
me write that well no unfortunately the
sign is wrong okay the answer is
negative so what this illustrates is
that you can't trust conventional wisdom
and that is in one seemingly innocuous
expression evaluation you can lose all
your accuracy you can start out with
every input value being exactly machine
representable and lose it all now while
this is a contrived example to
illustrate a point it does illustrate
how risky finite precision floating
point computations can be and that
conventional wisdom can't be trusted
even small rounding errors can silently
accumulate and compound through what's
known as catastrophic cancellation to
create essentially unbounded and unseen
errors I mean the worst kind of an error
is a silent one that I mean I'd ret
you'd rather have your machine crash and
burn and blow up then to have just a
wrong answer and no warning at all that
it's that it's been so unlike this rump
example real-life uncontrived
floating-point errors can be costly
in this example all the Patriot missiles
failed to hit a single incoming Scud in
the first Gulf War in one case 28 US
soldiers were killed the cause was a
catastrophic floating point cancellation
followed by following a routine rounding
error another example is this Aryan 5
French rocket that failed on its maiden
liftoff its development cost was seven
billion dollars its payload cost a half
a billion its crash was caused by a
floating point two integer conversion
error that nobody detected many more
real uncontrived examples can be found
on the internet and by the way if you
get a copy of the slides all of these
URLs here are hot if you have a decent
reader so you just click on them and
they'll pop up on the Internet the root
cause of all of these failures is the
fact that floating point numbers contain
no accuracy information if they did when
people were developing the software
they'd see the problem this is why the
focus in the industry is always on speed
you can see speed you experience speed
you never experienced accuracy because
it's not in your face there's nothing to
see that's one of the beauties of
interval arithmetic is it makes accuracy
visible because of this increase speed
can cause increased risk there are more
and more opportunities for unseen
numerical problems a petascale machine
performs thousands of trillions of
floating-point operations per second so
think of the opportunities for numerical
problems to arise as in the rump example
rounding followed by cancellation can
occur even when all inputs to
computations are exact typically they're
not almost all sigh
tific and engineering computations begin
with fallible data that come from
physical and/or other measurements so
what's the solution to these problems
well anybody who knows me will not be
surprised that the answer is interval
arithmetic very briefly interval
arithmetic is a method of computing in
which every interval is guaranteed to
contain the set of all possible answers
in any computation so to start with an
interval push the wrong button in
interval denoted a be like 12 is the set
of all values between and including
including the endpoints of it intervals
there's nothing mysterious about that
what interval arithmetic does is perform
operations on intervals in such a way
that the resulting interval is
guaranteed to contain the set of all
possible values for from performing the
operation and question on any element of
the argument intervals and operationally
on the machine if for example this lower
bound is not machine representable I
mean say a is 1 and C is 10 to the minus
15 right so it falls off the accumulator
so when that happens what you must do is
round down to the next machine
representable number that's known to be
less than a plus C similarly the upper
bounds always have to be greater than or
equal to the true upper bound of
whatever the computation is you're
performing so that the very basics of
interval arithmetic are really quite
simple and straightforward again if we
have more time at the end i'll be happy
to go into more details but for now
let's plow ahead one of the most
important things about intervals is the
ability to represent uncertainty or
error in
values and there there are basically
five ways that intervals work in order
to solve all these problems that I
mentioned with floating-point arithmetic
and solve other problems in addition
first intervals are constructed to on
input to be bounds on whatever your
input values are so you know price of
gasoline this year somewhere between 250
and 450 a gallon so that's an example of
an input where you don't have much
certainty to begin with but nevertheless
any computation you do with that
interval takes that fact into account
rigorously throughout the entire
computation a more subtle example is an
input value like 0.1 that's not machine
representable the decimal number 0.1 is
a machine representable so when you
enter 0.1 then the compiler needs to
construct a binary interval that is as
narrow as possible and contains that
true decimal value ok so that's the kind
of mechanics that needs to be built in
to tools compilers for people to work
with if input values are stochastic
they've got some probability
distribution then what people are doing
is using what are called probability
boxes or p boxes which are interval
bounds on cumulative distribution
functions and then they use interval
arithmetic to rigorously compute
functions of random variables bounded by
those interval cumulative distribution
functions so this enables people
numerically to do statistical
distribution theory that is impossible
to do analytically I'm a statistician by
training and so you know Gaussian linear
you know that's kind of it for a lot of
the statistical theory but this enables
you to
dude do lots and lots of distribution
calculations that would be impossible
otherwise and do them rigorously second
item all arithmetic operations and
elementary functions of intervals are
constructed to produce mathematically
valid interval bounds guaranteed to
contain the correct result or the set of
correct results if there's more than one
the third item is the fact that an
interval is a continuum of real values
this continuum property means that when
a valid interval bound on a computation
is produced information is provided over
the infinite set of values in the
argument intervals not just machine
representable points that's a real
important point just because the
endpoints of an interval our machine
representable floating-point numbers
doesn't limit the fact that that
interval represents the whole continuum
and so through an interval you have
access to information that normally
you're totally is totally inaccessible
on the computer because normally the
only thing you have access to is this
finite set of machine representable
numbers and the derivation of all
interval arithmetic operations and
functions takes that into account so the
fourth item is what's known as the
fundamental theorem of interval analysis
and it guarantees that using interval
arithmetic to perform any programmable
computation on a computer produces valid
interval bounds in other words valid
interval bounds are produced by
concatenating interval operations so you
take any sequence of opera numerical
operations and if you've implemented
them using valid interval operations or
elementary functions then the result no
matter what it is is guaranteed to be a
valid interval bound on the set of all
possible results that you could have
gotten by performing that computation
fifth item
together the continuum property and the
fundamental theorem are the basis for
numerical algorithms to fully solve
nonlinear problems that have always been
thought to be numerically unsolvable in
principle in other words that there
would never be a way to solve
numerically solve nonlinear problems
chief among these is solving nonlinear
systems of equations and globally
solving optimization problems
optimization problem is to find the
minimum of some function and global
globally optimizing some function is
finding the global minimum the minimum
of all the minimums the design of
anything can be viewed as an
unconstrained or constrained
optimization problem so this is an
extremely important class of nonlinear
problems now this next chart can be used
to illustrate the the continuum idea and
the fundamental theorem if I evaluate
this function over this interval here's
the function and I get a lower bound
upper bound what it says is that no
matter where I am in this interval
whether it's my machine representable
point or not the function may not go
below this lower bound and may not go
above that upper bound I've trapped it
and this is true for any function that I
can create from any sequence of
operations that I can program on the
computer or in mathematical terms it's a
composition F of G of X now the the
optimization algorithm works the
following ways suppose I found this
local minimum here and I've evaluated
the function at or near that minimum
value and I got this green lower upper
bound for the function at that point so
it's some some place doesn't matter
where that I've got this upper bound
least upper bound on the objective
function which functions so far
and whenever I get some new lower upper
bound I save it because here's what I
can do when I evaluate the function over
this interval and if the lower bound
over this interval is higher than the
least upper bound that I've ever seen so
far what have I done I've proved that
the global minimum can't be in the blue
interval because everywhere in the blue
interval is greater than some value I
know so i can delete the blue interval
never have to look at it it's gone and
the globally the algorithm works by
proving where the solution can't be by
deleting deleting the leading and then
subdividing and the leading of the
leading and deleting until what you're
left with is a small interval or a small
set of intervals that have to contain
the the global solution and another
important point about this is that if I
have a problem and I subdivide the
solution space up into sub intervals or
sub boxes if it's multi-dimensional and
I send them to different processors
every processor just gets a new problem
just like the original problem only it
has a subset of the original domain of
possibilities to work with so I can
subdivide subdivide subdivide subdivide
and it's an embarrassingly parallel
process where the amount of
communication required between
processors is minuscule relative to the
work being done by each processor so the
kind of large parallel architectures
that were blessed with these days I just
love because I know exactly what to do
with them here's a little example of a
optimization problem it's this little do
it again this little function here
you're trying to minimize over the
interval X in the interval minus 1 to 1
and the interval wine the interval minus
1 to 1 it's got a lot of
oscillations and local minimum because
of all the sines and cosines in this
expression and these three pictures are
just zooming in on where the global
minimum is the actual answer is here to
more than 10 decimal digits for x and y
and the value of f and it was done in
less than two seconds on a single
sunblade 1000 so the algorithm works ok
and you can use it
interesting aside Russians I used to
manage Russian projects for son part of
one of my jobs and I had a contact with
one of them who's translating a book i
co-authored with Eldon Hanson into
Russian and they are in the process of
using the solution to nonlinear systems
of equations to design a Russian air
traffic control system I don't know
about you but I prefer to fly under an
interval based air traffic control
system floating point one the idea is
you have all the telemetry for a plane
which is uncertain right but you can
create a cone of uncertainty out in
front of every plane about where it's
going to be in time and if two cones
don't intersect they're safe but if they
do then you need to take some kind of
action so that's that's the idea behind
it now there are a number of different
applications that have that have been
done some of reasonable industrial
strength and again every one of these
URLs is hot if you get a copy of the
slides don't have time to talk about all
of these right now unless we have time
at the end but there's two that I'd like
to mention in particular one is this
graphics rendering algorithm it's poised
to completely eliminate any direct x
based polygon triangle rendering
algorithm it's much faster and produces
picture quality rendering this is this
means Pixar and everybody gets blown
away but this little upstart company
that's now in beta and it's all
interval-based and the way it works is
that the problem for rendering is to
decide on what red green blue intensity
should be for each pixel in your display
device
so with intervals what you do is you
compute bounds on red green blue
intensity for every pixel and once those
bounds are narrower than the resolution
of the display device you're done you
know more work to do doesn't matter what
you do from then on you can't help
because the display device display
devices resolution is stopping you okay
so got a little handheld device a
gameboy with not much resolution you
don't have to do much work you know
you've got a fancy iphone you know with
more resolution then you got to do more
work but the point is you don't do
unnecessary work and you know when to
quit see what was there something else I
wanted to say about that the year I
think that's it there in the in their
first release what they've got is is
motion blur with local illumination for
those are your graphics people motion
blur is you know you've got a shutter on
a camera it's open for you know a tenth
of a second or so if something's moving
fast then it you get a blurred image
this causes fits for the people using
traditional rendering tools like 3d
studio max and whatever they do they
have to do all kinds of hand massaging
in order to get things to look right
that's why you see casts of thousands at
the end of ratatouille and other movies
you know it's all these guys doing hand
massaging of things to get them to look
right well with intervals all I goes
away it's automatic you get perfect
motion blur motion blur on the shadow of
things to see their key to key to speed
is knowing when there's no more quality
to be achieved the key to quality is
knowing the red-green-blue intensity of
your display device okay the second
example that I want to talk about is
this numerical proofs and there have
been a number of numerical proofs that
have been done
using intervals now these are real
mathematical proofs the first one is
called smiles 14th problem and it's to
prove that the Lorenz differential
equation has a so-called strange
attractor for those of you who know
about that kind of thing the problem is
one of a set of selected to be the most
important mathematical problems to be
solved in the 21st century and this was
the first one of the set to be solved
and it was solved using interval
arithmetic the next one is Kepler's
conjecture it was the oldest outstanding
unproved conjecture and discrete
mathematics and it was proved using
using intervals it's about stacking
spheres like they haven't in oranges in
the grocery store that that's the the
densest way that you can pack spheres
originally the generals gave it to
Kepler because they were tired of
counting cannonballs by picking them up
and moving them they wanted to build a
stack measure the size of the stack and
know how many cannonballs they had in
the stack so he came up with this
conjecture about what the number was but
nobody could prove it and it wasn't
proved until the late 90s using
intervals and finally the double bubble
conjecture and that's that this soap
bubble with membrane in between is the
has the smallest surface area that
contains that has two compartments and
contains a given volume and proving that
had to be done using it using intervals
so in addition to solving all the
floating-point problems that we talked
about intervals can open the door to
numerical computing productivity by
permitting numerical proofs to exist
with nonlinear solvers and by permitting
problems to be stated and solved at a
higher level of abstraction because if
an engineer can solve his design
optimization problem by just writing
down the equations that define the
problem he's done
so as with computing in general
productivity is the ultimate figure of
Merit for numerical computing raising
the level of abstraction in which people
can work and think is exactly what can
be done with interval nonlinear and
other solvers numerical productivity is
difficult without the guaranteed
accuracy information provided by
intervals so this has not been totally
unnoticed there have been some early
adopters Sun Intel maple Mathematica
matlab so given the fact that there are
these huge potential benefits from
computing with intervals huge problems
with floating-point arithmetic their
existence proofs that huge successes are
possible computing with intervals and
the fact that this has been recognized
by people like this why has computing
with intervals not taken off like a
rocket the difficulty is that computing
with intervals is still hard it's
difficult why there are some things that
are missing
most potential users don't even know
that computing with intervals exists
some of you might not have before you
came here today there are no
introductory textbooks with included
software and examples interval successes
have tended to be rather technical I
mean SH males 14th problem isn't going
to make you know the popular press so
they have not hit mainstream press as
mentioned graphics rendering might be
the first application that makes a
splash in the regular press because when
people see some new movie that's you
know whiz-bang much better than anything
that they've seen before that might get
people's attention developing this so
the second reason is that developing
practically useful interval applications
and algorithms is still too difficult it
can require interval and numerical
analysis expertise that the typical
application developer does not possess
finally end users who are unfamiliar
with interval computing can find it
difficult to access interval methods and
tools well designed and implemented
web-based tools to make computing with
intervals as accessible as games do not
yet exist so how can google I mean I've
set this up so how can google benefit
from changing the interval computing
potential into a practical reality by
providing interval computing to end
users and developers of the miracle
computing algorithm so I was trying to
build just before this morning I was
thinking about this this difficulty and
I came up with the idea that where we
are with intervals computing right now
is sort of like in the 60s and 70s with
ARPANET and the internet before there
was a browser you know if you talk to
people about well what's the demand for
the internet you know I said oh well you
know there's some guys you know sending
messages text messages with with this
thing but it's you know
kind of hard you have to be a geek to
use it you know you have to get a tip
that's right you have to get a tip for
those of you or remember that and but
they didn't see the browser coming ok
and so I think that where we are with
intervals with all of this pent-up
opportunity being blocked by lack of
access is exactly analogous the
potential user base can start with every
junior high school student in the world
who has access to the Internet and who
needs to compute truly useful and
realistic answers to homework problems
students love to know more than their
teachers about new technology it's one
of the reasons the computers are so cool
for for young kids as they know more
than they're than adults about computing
similarly upstart companies and even
countries love to leapfrog the
establishment using knowledge and
technology and technology google can be
the provider there's no upper limit to
the level of user and developer
sophistication or to the complexity of
problems to be solved numerically
solving nonlinear problems and many
different disciplines led me in one
paper to conclude that computing with
intervals is the mother of all paradigm
shifts it's a paradigm shift in applied
mathematics numerical analysis numerical
computing as well as all the disciplines
that use numerical computing every
engineering discipline science the new
and technically sophisticated eyeballs
thereby attracted if this were to happen
should fit nicely into Google's business
model although I hasten to add your
business model is not my area of
expertise so if the above is even partly
true what I've outlined so far what's
required to realize this potential both
for Google and for safe numerical
computing in the world
well it turns out there's only eight
things but some already exist so it's
it's not really that bad okay first at
the present time hardware support for
set based interval instructions is not
required I'll save a minute in a minute
what i mean by set based nevertheless as
demand for interval computing speed
intensifies the business justification
for interval hardware support will
become compelling set based interval
instructions permits symbolic and
numerical computing to be united if time
permits I can answer some questions
about this it one really interesting and
important thing it does is eliminates
all exceptions because there are no
undefined set based interval operations
or functions division by zero operations
on infinity they're all defined no
exceptions so all the hardware and
software exception handling apparatus
can be thrown away in that kind of a
system what it does is it makes it safe
to bring symbolic mathematics inside a
compiler let maple diddle with your
expressions safely the reason you can't
do that is for fear of creating a an
exception that's a result of a
singularity or an indeterminate form so
I'm slipping into that area that I won't
have probably much time to talk about
okay so second item language support
that's syntax and semantics for interval
data types will be required work on this
has already been done in fortran c++
matlab these can service templates with
some small additions for this set based
interval data type so this is
essentially done ok so the hardware
isn't needed to begin with and the
language syntax and semantics have
already been defined compiler support
and Fortran C C++ other popular
languages and in some all existence
including mathematic and maple are
critical in other words you want
interval data types in the symbolic
packages as well this can be
accomplished by the open
our community and renew compilers
existence proofs already are available
in sons support for interval data types
in Fortran C++ other academic
implementations exist for example in
MATLAB and Excel the work can be done
with little cost by open source interval
enthusiasts in this connection many
opportunities exist to hide the use of
nonlinear solvers under simple familiar
tools such as a spreadsheet the fact
that Microsoft is rumored to be adding
interval support to excel and that you
now have a spreadsheet product creates
an interesting opportunity fourth item
an integrated mathematical development
environment where most of the Ides are
java based and you know for those kind
of it's not an integrated mathematical
development environment with which
libraries mathematical software can be
developed documented and maintained
because this will increase the
productivity both of interval and non
interval mathematical software
developers this can be a model for good
application user interface design and
implementation the next item is based on
that set based stuff static at compile
time and dynamic at runtime integration
of symbolic and numerical computing set
based interval instructions make this
possible it will make the task of
developing high quality solver libraries
and end user applications less
time-consuming solver library the six
item is solver libraries using the best
available interval algorithms to solve
frequently occurring mathematical
engineering problems this will make the
task of end-user application developers
less time-consuming and demanding of
interval analysis expertise the seventh
item is lots of end user applications
the interval graphics rendering
algorithm mentioned earlier is an
exemplar it can seamlessly replace
existing rendering engines so end users
are oblivious to the change except of
course for the increased speed and
superior image quality they experience
the last item is the educational
materials in the form of online and
physical books with software and sample
codes that can be downloaded executed
and cloned these can target various user
groups starting with junior high school
students who want to become the interval
application end users and/or developers
before concluding let me say just a few
words about these eight items the
language support compiler support and
educational materials with end user
software are sort of must-have items to
begin demand creation for computing with
intervals you have to get people
teaching this stuff in school and
universities I am the integrated
mathematical development environment
compiler optimization solver libraries
and other applications can be developed
in parallel however the sooner the
integrated mathematical development
environment is available the sooner it
will speed the development of solver
libraries and applications interval
application success stories need to be
widely publicized and educational
materials need to be kept current as new
tools and solvers become available so in
conclusion it seems to me seems too
clear to me that there is a large
opportunity for Google to use its
traditional expertise to provide
high-quality easy-to-use access to
numerical computing with intervals in
the process Google can acquire large
numbers of technical eyeballs and create
newsworthy events in the process of
fomenting the mother of all paradigm
shifts be happy to take your questions
yeah sure Paul yeah I think a couple
questions so first of all just a
technical question what happens if my
interval contains a singularity ha well
let's take a look at division by 0 1 0 0
so I have an interval start start with
an implement just manager 00 ok ok so
our degenerate interval generating
interval 1 degenerate interval 0 what is
it well think of 1 over X if X
approaches 0 from the positive side you
go up to plus infinity if you go pro 0
from the negative side you go to minus
infinity so it's not that one over zero
is undefined it's the union of plus and
minus infinity ok which is a set it's
not a point the reason singularities and
indeterminate forms are undefined is
because they're trapped in a point
system where the answer to everything
has to be a point it's like like asking
a flatlander to visualize something in
3d hey but intervals are sets so in
principle there's no problem
representing the result of a singularity
or an indeterminate form like 0 / 0 or
plus infinity / plus infinity
representing those using intervals and
that's the fundamental answer to your
question I ok that makes sense ok the
other question is if an interval is a
range of two numbers what types do you
envision those those individual numbers
is being 0 does it matter well know that
typically what you do or what we've done
so far is you have single precision
intervals double precision intervals and
you know quad precision intervals so
their end points or floating point you
could also think of having integer
intervals where the endpoints are
integers and you'd always round to the
next integer if you want when you were
performing some operation and there are
contexts in which that turns out to be
handy think I can dredge it up it's in
temporal what are the things they anyway
it
in the top time things tend to be if you
model time in days okay then it's to
street okay so then if you use integer
intervals then that turns out to be
handy yes you've mentioned by the
typical high school school student as a
potential target yeah let's take rups
example you had before I'm putting a
using floating part library for interval
arithmetic I put this in and I get back
the result is somewhere between let's
say minus 100 plus 100 how is a high
school student would I like that
compared to using a symbolic library
that gives me back the exact result well
you're assuming are you assuming that
the inputs are intervals or i'm assuming
i'm using one of the libraries you
mentioned and they're usually based on I
Triple E so you're rounding up and down
so if you have a nasty function like
rock you get your intervals get very big
they inflate very quickly right bar
which has been the problem with you know
layman's adopting interval arithmetic
for many decades part of the of what's
needed here is tools to use
sophisticated analysis that the user
doesn't have to know about to eliminate
unnecessarily wide interval results I
mean his question to repeat was you know
repeat aren't people going to be unhappy
when they do some computation and get
you know really huge wide intervals well
the question is whether that's what they
should get or whether those that
interval with is is unnecessary and what
you want to do is in the tools eliminate
the unnecessary interval width so you
get nice sharp bounds and hide the
complexity of doing that from the users
and that's part of what I'm assuming
gets done in making these tools
available and easy to use does that
answer your question on the other hand
on the other hand suppose you have a
numerical instability suppose you have
an expression that is very very
numerically unstable because it's
written in a bad
way well you want interval arithmetic to
expose that so you could say oh my god I
lost all my all my accuracy what's wrong
is there a way to reformulate this
expression so that it's numerically
stable and I don't lose all my accuracy
the question is whether you want to be
ignorant about what's going on or do you
want to be informed you also mentioned
getting a widely adopted right but
there's so much that can be done to make
computing with intervals so much more
easy than it is now and thereby greatly
expand its accessibility that I mean the
opportunities from my perspective are
just gargantuan question what about
complex numbers in number hood computing
right and grant what neighborhood
computing not even an interval a
neighborhood of a complex number ah
right with complex you you can represent
complex numbers in a couple different
ways real and imaginary parts or
magnitude and phase but whichever way
you want to do it or both you can use
intervals to bound that set now one of
the things you so magnitude it with real
and complex a complex interval is just a
box in the complex plane right and so
one of the things that that gets
interesting about working with complex
intervals is the so called wrapping
effect in other words if you take a box
that has sides parallel to the real and
imaginary axis and you rotate it then
the new box has to grow to accommodate
that rotation okay so it's been a lot of
work done with Taylor expansions and
different techniques to avoid the
so-called wrapping effect but again this
is the kind of thing that can be put in
fact that that technique was used in
that first example
for modeling the largest particle beam
accelerator in the world and they had
these huge differential equations to
integrate over 3000 turns of a particle
and keep everything under control and
they are able to do it using this Taylor
modeling technique and using intervals
so and i'm not exactly familiar with
what you mean by neighborhood computing
but let me say one thing about branch
cuts branch cuts are really interesting
because when you have an interval that
spans a branch cut then you want to
allow it gracefully to cross over so it
turns out that you need this is even not
in complex but just with trig functions
and stuff you need to allow for interval
angles to go from something less than
minus PI to something greater than then
minus PI and conversely from something
greater than PI to something greater
than something less than PI to something
greater than pie so you got to allow for
both possibilities and do all of this
kind of work under the cover seamlessly
so users don't have to deal with it but
it's once you start doing it the the
power of the system and having all of
the knowledge that you have about what's
going on is you can never go back to
floating point once you've computed with
intervals it's it's completely addicting
yes yes you mentioned that the problem
was the problem was conversion from
float to an inappropriately side to an
appropriately sized integer and I guess
the question that I have is if you were
to have used interval arithmetic I'm
assuming again the the target integer
size would remain the same how would
this have prevented the resulting
failure from the overflow because I'd be
using integer intervals
but the and so I would see the the
interval width and if I had if the if
the word length of my integers was too
small to represent the floating point
value then I would you know blow up I
get you know minus infinity to infinity
as an answer and I would see immediately
that I had a problem what happened to
them was they had a large floating point
value they mapped it into an integer it
wrapped around changed the sign and you
know they had no clue that they had
complete garbage and what they've done
this is part of the reason why there's
no requirements for accuracy even for
integers in the Fortran standard I mean
originally that came from control data
because they have a 17 bit loop index
and they had a 60 bit word and so but
they had this or was a 48-bit 48-bit
loop index register that they use but
they they weren't careful about
converting back and forth and so when it
came time to discuss in the I Triple E
are in the Fortran standard meeting well
what about an integer at least an
integer accuracy requirements what CDC
said no no no we can't have that so
that's sort of the way that Club works
you know the you have least common
denominator and nobody nobody does
anything that rattles the cage for any
other vendor but I'm not sure how it
would it change that outcome because
what you're describing is that ok if the
interval is set to indicate that you're
grossly out of bounds arm similarly with
with testing they could have noticed at
some point that they had a negative
value for an integer so I'm not sure how
we have changed the outcome of the
flight if they but what you would do if
you were doing interval programming in
that situation you'd have first you'd
have an interval for the floating point
value right and you'd have integer
intervals for the for the integer value
and you would naturally put in the the
check to see what happens when I can't
represent this abound on the floating
point value with my
integer intervals because what you would
do in the conversion routines would
automatically return minus infinity
infinity for the integer interval when
you can when you couldn't do the
conversion so you see you that you'd
naturally put an if statement you know
if you know the integer interval is has
infinite width then you know I've got a
problem and you did you do something
you'd increase the word length for the
integer right or do something
appropriate the problem is that when you
have the information available about
what's going on and it's in your face
the natural thing to do is then to to
deal with the different possible
contingencies what happens now with
floating point is that you're not forced
to think about what can happen let me
give you another example suppose you
have a sequence of relational tests
if-then-else kinds of things and when
with relational tests on intervals what
you do is you set them up so that if an
interval is empty there's such a thing
as an empty interval if I take the
intersection of two intervals and
they're disjoint then you get the empty
interval like the empty set okay so any
relational test on an interval that's
empty is false right so I have a an
exhaustive sequence of relational tests
exhaustive in the sense that I've taken
into account every logical possibility
then there's an else at the end ok now
that else should never happen except if
one of the argument intervals is empty
and then that's exactly what happens as
you fall through to that to the else
case but you know you're not normally
provided with those kinds of tools to
build failsafe programming
hi so I'm wondering a couple of things
one is that you were saying how the
result of the division by 0 1 over 0 is
going to give you plus and minus
infinity but this interval is going to
include all points in between so does
that cause any problem sending line
here's the way we deal with that there's
such a thing as an exterior interval
that wraps around through plus minus
infinity okay and that's exactly what
happens when you divide by an interval
containing zero so suppose I take one
over the interval minus one plus one
okay what is it well I first saw a way
to think about this is to say well I'm
dividing by the interval the union of
the interval minus 1 to 0 and 0 to plus
1 all right so crack those apart so
what's the first one well the first one
is the interval from minus 1 to minus
infinity the other one is the interval
from plus 1 to plus infinity take the
union of those two is this exterior
interval you represented on the machine
by just flipping the end points so that
when the left endpoint is greater than
the right endpoint then that's an
exterior interval that wraps around
through plus and minus infinity okay so
so that so the answer then 21 / 0 using
an exterior interval is the interval
plus infinity comma meissen minus
infinity okay that's sitting right there
that at the top of the projective circle
you know what and I also have one other
question dessert and it seems like you
could think of these intervals as being
just you know probability distributions
right a uniform distribution over this
range so then why not just think about
distributions generally and they're not
though okay because the uniform
distribution is very different than an
interval interval says that you have no
information about the distribution
everything can be at one end point
everything can be at the other end point
or any kind of distribution in between
so they're not uniform distributions all
right now if you want to work with
uniform distributions then you can with
these probability boxes but but that's a
mistake some people have
interval has no information about the
distribution of what's going on inside a
table however let me just mention one
other thing that there's this so-called
dependence problem that in other words
if I have the interval X minus the
interval X ok I have to treat that as if
it were the interval X minus y I would
like that constants or two separate
intervals but what if I really have the
interval X minus X where the interval X
stands for some value that's wandering
around inside that interval okay the
interval X minus X if I know that every
occurrence of the interval X is
dependent right then the interval x
minus x is 0 all right and I can take
that into account with some language
constructs where I declare intervals to
have a dependence attribute so that
every occurrence of x is an interval
that contains the same value so they're
dependent that's not statistically
dependent it's mathematically dependent
okay but this is a huge thing because
this dependence issue when things are
really dependent but you don't get to
assume that they are is a big source of
this unnecessary interval width that he
was talking about and but the way to
avoid it is to allow for intervals to be
dependent yes or I'm sorry that was your
question okay that he you mentioned you
mentioned relational operations and
intervals yeah so what happens if you do
X less than Y and they overlap there's
three three different kinds of
relational operators when you start
dealing with intervals one is certainly
so if one interval is certainly greater
than another then there's no overlap ok
if it's possibly greater than there's at
least a possibility of an element in one
interval being greater than another okay
so there certainly possibly for all the
different relations and then
when you write code you need to say with
intervals you need to say what it is you
mean you know are you trying to protect
yourself from some thing that possibly
could happen or are you wanting to
guarantee that some state is true with
respect to two intervals so you write
CLT for certainly less than or PLT for
possibly less than then there's another
another kinda dorset set relational so
that two intervals are equal if they're
set equal so as sets so there's and so
those are all documented and worked out
but it's a very good question and
something that did cause some people
some consternation to begin with yes oh
if we get that guys who haven't had a
chance yes um when you mention the
fundamental theorem yeah two intervals
do you get back in interval or do you
get back a collection of intervals with
the fundamental theorem it depends on on
on what you what you're doing when you
divide when you divide by an interval
containing zero then you can get two
disjoint disjoint intervals and then
depending upon how you want to pull them
together as an interior interval or an
exterior interval or what you want to do
you know is your choice the ideal thing
to do would be to have another data type
called sets of intervals so that you
never had to include anything from
taking the union or the Hall of two
intervals and include anything that you
didn't want to include and that's
perfectly consistent with these
embarrassingly parallel algorithms where
what you tend to do is split split split
subdivide into lists of or sets of
intervals and then operate on them so I
don't see that as as any difficulty the
fundamental theorem originally applies
to interval arithmetic operations where
what you have in is intervals what you
get out is intervals and the it works
but it the extension of it to this new
set based stuff also the the fundamental
theorem extends to this set based
interval stuff in which you could get a
set of intervals as the result or a set
of values for that matter and there was
somebody back here had a question so in
first year physics we learned about
error bars which has some resemblance
but not identical so I'm just wondering
about your sauce of using that handle to
introduce it Tara bars you mean like
epsilon delta and engineering know for
like you run an experiment and you plot
a graph you have a point and draw a
vertical bar I mean the possible values
usually that's like a standard deviation
like one or two standard deviations and
statistics when you do that but if they
were bounds if those error bars
represented bounds then they would
exactly be intervals and then when you
operate on them you do some other tricks
so we learn a bunch of your tricks that
were strange but wondering you can
squeeze in introduction of interval
arithmetic into such curriculums might
be interesting don't I I don't know
there is a lot of work going on in the
intersection of classical statistics and
fuzzy logic and fuzzy arithmetic and
intervals so those three domains are
sort of you know working together in a
seething cauldron of new research so
there might be something related to your
question yes okay
so it seems to me that this is the kind
of thing that would work a lot better in
a statically typed language than in a
dynamic language and the reason is
because in a late bound language you
know each mathematical operation is
happening somewhat in isolation worth it
whereas in a statically language you can
sort of take an entire expression and
analyze it and it seems in order to do
the kind of thing you're talking about
both efficiently and properly you need
to look at the whole formula and not
individual mathematical operations
indeed and one of the other attributes
other than dependence is what I call a
symbolic attribute so if I declare a
variable to be symbolic and I have it to
the left of an equal sign what I'm
saying is that I'm defining a macro for
that variable so if that variable
appears later on i can replace the
variable by the expression that was 22
it's right in the assignment statement
and so then i can expand that expression
and then do algebra on it to apply
identities do cancellation analytically
rearrange it in different ways and one
of the tricks for example that people do
with the intervals is to rearrange an
expression in different ways and they
have very different numerical
characteristics so one way will have a
sharp lower bound and a very loose upper
bound and another expression will have a
sharp upper bound on a loose lower bound
and so you do them both take the
intersection all right so there's all
kinds of tricks that interval analysts
have developed over the years but now
they're in their heads they're not
automated in tools and all of this can
be automated it can be automated safely
because of this set based interval
system where there are no exceptions no
singularities are indeterminate forms so
in other words you're saying that that a
lot of the efficiency comes from being
able to do lazy calculations yes
actually yes right okay well that could
be done in a dynamically work or even
even at runtime I'm
you should be able to depict because a
lot of times I don't know how I want to
rearrange an expression till I'm
confronted with the interval endpoints
that I'm using that I'm evaluating it
over okay so i have to wait I can't do
everything statically at compile time at
the you know used jit compiler type
technology so that it run time I say
wait a minute I've got this interval
that straddles 0 and you know so I need
to do something different then I I would
if it doesn't know Christians anybody
else did did I get your question
answered yes okay great okay well right
thank you very much oh thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>