<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kyoto University Presentation | Coder Coacher - Coaching Coders</title><meta content="Kyoto University Presentation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kyoto University Presentation</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-U6w2baiIRQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everyone we're very pleased
today to have professors and students
from Kyoto University in Japan here
visiting Google we are going to have
katsumi Tanaka give us an overview of
the department of social informatics
graduate school of informatics research
and then we will have professor Toru
Ishida give us a overview of the
research at the laboratory for Global
Information Network department at the
school of social informatics professor
Tanaka my name is katsumi Tanaka from
Kyoto University and thank you very much
you kindly accepted our visit to google
and today I'd like to briefly introduce
the research activities in the area of
web search of Maya in my lab and first
of all this is a list of students and
professors and also researchers from
Japan okay and I came from Japan Japan
Kyoto University and the professor
Ishida also came from York University
and we have some re researchers from the
Japanese governmental research
laboratory in ICT and also there are
many graduate students of guilt
inversely here
okay so I hope somebody in Google is
watching me okay and my topic is this
towards next generation search engine
and browsers okay so this is my image of
next generation of search engine okay
maybe in two debris the next image of a
web search engine severe search beyond
media types and places you can see that
this this horizontal axis this means the
place of content storage right and the
vertical axis this is this access did
all the media type of context okay so
now we have a text search engine and
also you made such a change in the video
search engine and now Google is already
offering several types of our content
certainty so you are now going up I mean
not only text data but also image
retrieval and video with Reba right so
this this one this is one direction of
conventional will search in G right and
the neck is horizontal axis this is very
interesting I mean currently our website
changing covers of course our web
content including bro and also desktop
contents right and maybe now our
conventional web search engine is going
from left to right slightly because of
some search engine is now able to
recover not only with not only personal
content on your desktop but also
external database were encyclopedia or
tis content
now we are interested in this area I
mean maybe a recently had television how
to disc and DVD recorder that they can
store many contacts right so then maybe
sometime we will need some search engine
to third the content stored in hard disc
and DVD Rocco and even the search engine
for PDA content or a digital camera
right so this is another axis so then in
order to image the next generation web
search maybe we will need integrate
search technology and web content TV
program contents into wave like context
such kind of video conversion technology
will be necessary very fortunately web
content has hyperlinks and so our google
was successful to give a very new
ranking algorithm called page rank but
unfortunately Google uppity be prone
content see how to describe it they
don't have any hyperlinks right so then
we may need some new non linked is
ranking mechanism
okay so they're from now I will briefly
sketch an overview of our research
activities in the area of certainty or
such tech nerd and one direction is the
integrated search and this right shows
this is a TV program and while watching
a TV program you can automatically
obtain the related webpage in the air
time and I hear that the in Google
research it up maybe some researcher is
also engaged in this kind of research
right so this is one example of
integrated search I mean while you can
watch TV program you can automatically
obtain related webpage at the same time
this is another example of integrated
search this is a combination of GIS
contents and web content and this system
automatically detect some landmark
phrases from web content that is based
on data mining technology and then
landmark press is a very famous phrases
in town or in any area okay and
furthermore based on those landmark
presses the system automatically did
Reeves webpages concerned with those
landmark braces so this is another
example of combination of GIS contents
and web content the third one is a
example of Image Search and I hope some
people in Google listen to this story
okay this is the example Google image
search okay and google image search now
the precision ratio of email search is
very good pretty good but the ricoh
ratio of google image search is not so
bad now if not so good and this is one
example so you can you can try later
okay by using the google rebates ing why
not input three just three keywords
Mount Fuji and sunset and snow okay so
then the answer of google image search
is there I mean the dumbo of heat is
zero okay okay so then can you believe
that there's no images concerned with
Mount Fuji and sunset and snow in the
world wide web big information space the
answer is no there are many many images
concerned with Mount Fuji and sunset us
know so then how do you improve the
ricoh ratio of your image search engine
okay this is our basic simple idea our
idea our idea is death we will reject
deluxe this query keyword okay so then
we will select mount fuji and sunset
only these two keywords is input for
google image search and the third key
word is input to ordinary a text search
I mean web a google search and then take
an intersection of these two result so
then you can find many many relevant
images from Sun with the Mount Fuji and
sunset Oslo okay so then you can you can
discover many many relevant images of
this screen this is our idea to improve
your google image search and especially
to improve the ecole reason
okay and this is a another example of
integrative search we have already
developed a search engine to retrieve
not only web content but also TV program
content and this is the one example
ok
now you can see the image is a video
image of our search engine which tries
to retrieve not only web pages but also
TV program content for your query now
are they sorry this is Japanese but the
user is now put the keyword space and
space shuttle right so then this is our
answer and you can see this is a web
page this is a web page but here this is
a TV program content store do you know
how to describe you okay so then once
you give put your keyword query you can
retrieve our web page furthermore you
can retrieve the TV promo content and
also you can browse the returned answer
now the user is now focusing off of this
answer this is the TV program content
and if you do them up then you can see
the detail of the TV program content
and also are very listen to ya young
people in Japan why are they watching TV
they are also using pc and internet and
especially they are communicating by
online chat system so this is a another
example we interviewed search which
tries to integrate not only TV from
program content but also online chat
information
this is also very brief introductory
video of this system and they said use
your TV program okay and maybe this is
the user interface issue if you turn
down you know zoom zoom out then you can
see not only the TV program content but
also here the closed caption data and
furthermore here's of our online chat
information concerned with this post on
the video too so this is another example
of interested search and online chatting
and this is also another example of
integrated search we already explored
developed summer browser which can
concurrently browse multiple websites in
a concurrent okay suppose that you are
reading newspapers so then you can in
this system you can read mark through a
web news site content and if you picked
up if you pick up some your favorite
news then the related news article from
other news site is automatically
retrieve and so this this window is
automatically synchronized with this
window so you this is the image I mean u
uq on your desktop you can put two
newspapers and then compare the related
news articles
okay and this is a ranking algorithm
issue okay country even please run
PageRank algorithm is very new and very
very good algorithm to run each web page
right our idea is slightly different why
do you run web pages page by page our
idea is our to rank the correction of
pages I mean we make pace fears from
answer pages of units of foreign key so
that the units for ranking is not each
single page but they're all pieces okay
so here's some example suppose that your
queries a UC Berkeley and Stanford this
means our maybe you want to compare a UC
Berkeley and Stanford University okay so
justly put the keyword UC Berkeley and
Stanford right so then the google search
engine will return these pages as a
candidate of the answer okay and some
page there is much more description
about using Padre but very few
description about town
and here this piece this page describes
a many description about you see battery
but very few know ah this page describes
Saffold very much and very few
description about you see battery okay
but maybe the intention of this query is
the user wishes to compare you see
Barbara and Stanford right so then fire
for them to make up their of these pages
so that is our idea making a pair of
pages by this and this right and this
TRPs may be much more relevant to your
pretty down each single page that is the
idea of ranking pages page fractions not
page by page
right so then I almost are talked about
i pricked this is a quick review of our
research activities and also are we
explored some new type of browser
especially browsing full browsing
multimedia content ok and usually every
day we are now using internet explorer
that is a web browser right and also now
every day we watch TV ok this is very
rude but our idea is the rivers why not
watch Steve Webb why not browse TV in
order to do that okay so some kind of
media conversion technologies needed I
mean transform web page into TV program
rival world conversely transform TV pro
contents into web right pace right ok
this is a very are watching or acidic
this is very passive man to get
information right and browsing is very
active of course our internet explorer
every day we are free and we scroll up
and down and even we read the text on
the web page but sometimes if when
we are a tire right maybe sometimes we
wish to just watch and listen reference
to learn conventional internet explorer
interface it is a very active sometimes
we may we may wish to her Maria passive
until I
here's a some example ok this example is
in the no voice so sorry but this one is
a example of transforming some news
article webpage into TV program right
content these funny characters speak
each other the topic is from some news
article in some website right so then
users can just watch this something like
a TV pro this is one example if somebody
can't understand Japanese this is a very
funny dialogue but anyway this is in
Japanese in front of nope no boys and
maybe our this technology can be used
for mobile phone or awesome PDA because
mobile phone the PDA of course there's
very small screen we do not you know
behave so actively I mean prepend
schools throw up and down you know so
then maybe much more passive man to read
web page may be necessary so then this
kind of technology can be used
and this is the rivers come back from
buzzing TV from content into wave-drive
cases okay i will show some sort them
this is a very sore demo but this
program is running on my pc now and this
is very old news from t be given of who
he is but anyway okay so this is a news
program but now suppose that you are
tired you are boring to see this news so
you want to search another news stored
in your hard disk recorder but your
heart is the building's huge so it's
already record maybe a one-year or the
TV programs on one not one year but one
week right so then i want to search
quick research some TV news stored in my
how to describe you so then our
interface is this our interface
automatically tries to convert this TV
program into wave like pages just
zooming out if it's oom out right so
then this TV program is you know would
multiply transfer form into something
like a web page and this text and this
text these texts are extracted from
closed caption of TV program and the
furthermore what might be some
hyperlinks is generated okay so then you
can put pre browse the whole content of
your hard disk report and you can select
your favorite tools news article and
then again you can if you zoom in that
you can give the watch
you
okay finally we are now interested in
the trust of web search we have just
started at this research the problem is
to what extent can we believe the result
of waves are changing right even if I
your google image search engine or a
google search engine they're very good
ranking aerosmith existing but but then
to what extent can we believe that the
top top one page is based or not that is
the problem of trust of we've searched
and in order to consider the trust of
web search engine maybe we have we
should consider three items the one is
that concerned with the content itself I
mean the side the third page so how does
the search page or for fair information
in order to analyze this of course we
can use several data mining technology
right and the second one second axis is
a sorcerer acceptance I mean if you have
some web page other such as out right
then how do people evaluate the web page
this disease are not so new I mean
google pagerank are willing this is one
way to represent the degree of social
acceptance of web page right but maybe
we may be able to explore as or
technology in order to consider the
trust of such treatments and the sudden
accesses are also reliability this means
that if you are given some web page that
is a top plan
for your query but you cannot know how
we also arrive early to create a web
page or bookmarks so then maybe some
technology will be needed to guess how
can we trust the authors of the web page
this is very important ok so I have no
time so I today I have some materials I
mean by papers so much more details if
you're interested in you can defer you
can see so anyway
okay so this is my conclusion in in
order to imagine the next generation 30
days I pinned down several issues
especially are towards next generation
maybe cross media search beyond media
types and praise this is very important
eyes and so then maybe the browsing
style may be different or may become
much more but variety and the first of
all trust of search will be much more
important right so then I know that to
realize this kind of our image I also
been down some basic technologies we are
now exploring okay so thank you very
much for coming here I'd now like to
introduce professor Toro Ishida from the
department of social informatics of
Kyoto University who's going to talk to
us about language grid which is an
infrastructure for intercultural
collaboration professor good afternoon
I'm told Rasheeda from Kyoto University
and I dragged to talk about my research
plan it's not a research result but a
plan for language grid and
infrastructure for intercultural
collaboration so let me start with my
motivation
so we have done their so-called
inter-cultural collaboration experiment
from 2002 and so I want to talk about
why I want to start a language great
project and then I will talk about in a
language calida architecture including
language service ontology and language
web services and I want to work with
various npos in Japan including hospital
support for falling patients University
playground Universal playgrounds for
kids around the world and muttering a
radio program for disaster management so
we will work on this project with the
three and POS okay here is in a
motivation the question is do we lily
share information on the web it seems to
us no standard languages on the internet
now this is the online language
population survey in September 2004 from
this survey it seems English population
is thirty-five percent European
languages population is more than twenty
nine percent and Asian languages is more
than twenty six percent so we have to
learn a lot a lot of languages to
understand web information but it is
because it is impossible we want to try
to use in machine translation and if we
use machine translation we get such a
result if human if human translator
translate don't worry it's nothing then
machine translator may say not killing
trivial problems are good so the
question is what happens when we use
machine translation in
the cultural collaboration and we did
that experiment in 2002 and are still
continuing this experiment also in 2005
and so that experiment in 2002 is to
develop open source software in Asian
countries in our first languages and
five universities from Asia joined this
project including shanghai jiaotong
university seoul national university
honda university university of malaysia
and kilt universities and in this
experiment team members never meet in
person but complete software with
multilingual communication tools like
web and VBS with machine translations we
did in a fairly long experiment from a
blow 2002 to december 2002 and language
services were unavailable but we had a
hard time to organize to create the
salon which services are for this
experiment this is so called the
translation pentagon we used in 2002 we
used five languages japanese english
chinese colion and malay and we need the
machine translator to cover those
languages a lot of questions were there
how can we collect translation engines
to cover five languages how can we
understand they are contract it's the
contracts differ and sometimes it's
really hard for us to understand and how
do we evaluate their services there is
no quality assurance in machine
translation how much should we pay for
coupling the five languages it's a lot
so usually a million yen for each
language pair
and how can we customize provided
services and then we decided to start
the project called language glade we
believe that language is still the
biggest problem in the in intercultural
collaboration though English becomes a
world standard language people don't use
it in it in local activities the
language barrier is Silius especially in
Asia because we are not told our
neighboring languages so I mean that
Japanese are not told Chinese work
aliens and in China so people are not
told Japanese or Korean and so on and
language services and often not
accessible and usable only big
organizations like Google can buy
services and create their own services
but if so people in any POS our
universities want to create their own
language services we have a lot of
difficulties to access and use those
services and so our goal is to create a
language callate as an infrastructure of
the internet and we want to improve
accessibility and usability of language
services to too late to develop our own
language services so here is in language
glade architecture we have an ax to
different goals one is the one is called
horizontal language glade to provide
standard language services worldwide to
create composite services by connecting
existing language services on upon users
request and 2d blow up service ontology
to standardize their interface and
another goal is vertical language
callate to create community language
services to support inter cultural
activities
so this is an language glad architecture
so we have in a horizontal language
callate connecting standard language
services including water net it's a
English Dictionary provided from by
princeton university or EDR or this is
provided by your nict in Japan or
Chinese dictionary your machine
translations between the main languages
and also we have in a vertical language
glid to support community activities
including it's like medical support
interpretation support in local
hospitals so we will work in a language
service ontology to standardize api's of
existing language services and tip and I
mean that language services is including
it language resources and also a
language processing functions like
translation palletizing and so on and we
want to create community language
services easily by using those service
oncology's and we also work in the
language web services so now as you know
the standardization is in progress for
web services and research in progress
and semantic web services our goal is to
create an human agent collaboration too
great composite language services and we
want to generate semantic wrapper for
nearly newly created language services
so Achilles the language web service
architecture including three layers the
bottom line is language service layer
including anatomic component and
composite component and so on the second
region is a scenario execution layer so
this is semantic web services using a
BPL wsdl uddi and all and top lion is
called scenario collaboration layer we
will make in a repository for service
analia and the semantic weapons and we
are now implementing language clade
prototype on hope free by the end of
March this year so let me introduce in a
few fieldwork fear the studies we are
planning with any POS so we are planning
to work with any POS are especially
three purposes one is hospital support
for falling patients the second one is
universal plague land for kids around
the world and the third one is mulling a
radio program for disaster management so
let me quickly review the slick cases
the first one is the medical
interpretation services at local
hospitals and the name of the Nepean is
Center for multicultural information and
assistance located in Kyoto so this NP
or started a medical interpretation
service from September 2003 to assist
falling patients and at this moment
Chinese and Portuguese are highly needed
and in this case translations should be
very accurate and machine translation is
not useful for this purpose because the
low quality it's low quality and so we
need to use mulling out parallel texts
and they want to develop their own
language resources useful also useful
for local hospitals
so this is an image how we will use
language Glade for this purpose so
suppose hell is parallel mulling a polar
text for medical use and npl also wants
to create multilingual parallel text for
some local hospital use and if we have a
similarity evaluation program for two
sentences we can easily create a
composite services by using workflow to
assist interpretive volunteers the
second case is this the NPO the name of
NP on is called Pangaea and they want to
create an inverse a playground for world
kids and the NPO is was launched it in
tokyo by researchers from MIT media labs
and activities and ongoing in tokyo and
kyoto overseas branches or in Kalia and
kenya and australia austria and so on
and they are now collecting pictograms
drawn by kids along the world and that
means they are developing their own
language resources so pictogram
repositories and grounding grounded on
the world net so this is a pictogram
language resources grunting on the ward
net so they are trying to connect
pictograms to the concept of zin the
ward net so this example shows and how
pictograms differ different in the
different countries so so for example
this one this pictogram the meaning is
the morning in japan
but it seems that this pictogram doesn't
mean morning or in Kenya in Kenya the
mornings should be like this so they
started to to ground the meaning of a
pictogram using the word net so this is
a new language associated created by an
appeal so we have an ax language callate
and our people can put their own
language resources and the language clit
then suppose if we have any standard
language services like a japanese korean
translation colion morphological
analysis and then we can again we can
clear it easily create and work for to
create new services on like this so
suppose the japanese kid kids input a
japanese sentence here and then this
workflow can translate it into a
japanese 10 sentence with pictograms and
then translated into a colion sentence
with pictograms so the important thing
is this mechanism alone in appeals to
create their own language services by
using their own language resources with
standard language services so third case
is the name of the NPO is koto kamo
community radio this NPO started in the
march two thousand three the first FM
radio station by an appeal in japan and
the radio program production workshops
are organized by falling lessons from
may 2005 to make lady or program in
various languages and especially they
want to gather and broadcast information
in various languages in case of disaster
like bigger ohh squeak
so here is an example so suppose they
are different peoples from different
countries using a different language to
create an a radio program protection so
so they want to need some mark linger
blackboard system and again so they can
easily create all using available
standard language services like a
Japanese English translation and English
more morphological analysis or english
hindi dictionary and so on the point is
again they can create their language
their own language services for their
own purposes okay here is an assembly so
I introduce an architecture and of
language Glade to increase accessibility
and usability of language services it
includes two different kinds of language
grades horizontal one for collecting
nations standard languages and vertical
one for creating community language
services and we hope that an impact of
the language gland is fairly big
language services will not be created
just by professionals but by local
communities I think we want to make an
appositive spoilers of creation usage
and the standardization of language
services okay thank you very much so
Achilles and contributors this is fairly
multidisciplinary work and some people
are from different areas including
natural language processing AI agents
and sociology's and collaborations and
so on okay that's it thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>