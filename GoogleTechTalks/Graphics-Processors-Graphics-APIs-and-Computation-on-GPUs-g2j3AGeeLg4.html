<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Graphics Processors, Graphics APIs, and Computation on GPUs | Coder Coacher - Coaching Coders</title><meta content="Graphics Processors, Graphics APIs, and Computation on GPUs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Graphics Processors, Graphics APIs, and Computation on GPUs</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g2j3AGeeLg4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thanks so as daniel said yeah i'm going
to talk some about GP programming but i
think the way i'm going to go about it
is i'm going to kind of just run through
graphics pipeline I'm kind of what it is
graphics hardware I'm going to go
through this pretty quick because I've a
feeling most people here I've at least
some familiarity with it some I can tell
have a great deal more probably than
even I make at this point I'm going to
talk a little about the graphics API s
which is how you how you how you
tradition at least gotten at this
hardware and then I'm going to talk a
little towards the end about a TI's new
sort of initiative to be able access
this functionality more effectively for
for computation okay so just to be clear
I try to sort of be clear what I'm
talking about before I start talking
about something so when I talk about
graphics hardware I'm talking about this
stuff in the blue box all right and so
and this this is sort of the x x 1000
series where I x1k from from a TI okay
those are people of those of you are
familiar with these things e to the X
that's 1600s 1800s 1900s these sorts of
things but don't worry about that and so
this is how the graphics hardware sits
and sits in your PC sits in your system
okay it talks to this memory controller
for the cpu called the Northbridge
through this pci express 16x bus inside
this thing there's a host interface
there's a 3d pipeline and a memory
controller that goes out to graphics
memory which is on the card and this was
a very quite quite a wide bus 256-bit
bus okay now I'm really good i'm going
to stick to the 3d pipeline into some
degree the memory controller there's
other important graphic stuff in here
i'm not going to talk about things like
two deep litters MPEG decoders or things
that support MPEG decoding gosh i'm
forgetting other important things too
but since since this isn't where i spend
my time it's over there i guess it's not
surprising but there's some stuff i'm
leaving out just just realize that ok so
the 3d pipeline this kind of just comes
out of a graphics textbook i suppose in
some ways there's a command processor up
at the top it sends data to this vertex
processor which does processing sort of
on geometry
then that data is bundled up into what
we call primitives those things would be
triangles or line segments or points
they get rasterized which means the
pixels correspond isn't responding to
them gets spit out but actually I'd like
to distinguish between pixels which I
think of is stored in the frame buffer
and fragments which haven't gotten to
the frame buffer yet so we call those
fragments instead of pixels those
fragments get processed to find out what
color they should be when they get in
the frame buffer this is where a great
deal of the computation ends up
happening then there are some per pixel
operations to incorporate those
fragments into the frame buffer and
finally things go to the frame buffer
okay we're at the point now where the
speeds of these things have gotten quite
hot you can do 1.2 billion vertices per
second okay so you know think if you're
rendering every thirtieth of a second I
mean that's many many millions of
triangles because each vertex can define
a new triangle using the last two
vertices and the current ones that's why
the number of vertices gives you the as
critically just used to say the max the
the not to be exceeded rate for the
maximum number of triangles you can draw
and then with these the 11 billion
pixels per second okay is that the right
we're at actually getting these numbers
of course is a different matter but if
you think about what you know this can
allow you to drive the screen you know a
thousand by a thousand screen that's
what a million pixels I mean you can run
even at a 30 30 second you can draw that
over many times in one frame these days
okay so there's a lot of stuff you can
do okay we now have these programmable
vertex and fragment processors and they
allow beyond allowing sophisticated
shading getting really pictures on the
free screen there's there's there's sort
of more stuff that you can do now than
you used to be able to so you can have
this high depth complexity that has to
do with being able to draw the screen
many times over itself do these multi
pass algorithms where you again you draw
things multiple times we also have
floating point frame buffers so you can
do things like high dynamic range i'll
show a couple examples of this and
anti-aliasing okay and then also you're
now we finally get to you can you can
because of the programmability and all
this sort of high-speed it starts
becoming interesting to do computation
on GPUs it has nothing to do with
graphics potentially okay so lets me
look just talk for at the high level of
ati's current hardware so that in
there's eight vertex engines and 16
fragment engines okay
Jem right these are the vertex engines
go up in the vertex processor the
fragment process and fried manages go in
the fragment processor here ok they do
the sort of three component vector plus
scalar so it's sort of a four-component
multiply add on every cycle I Triple E
32-bit almost are Tripoli anyway I see
we have a few ok few troublemakers in
the audience and on the ninth down this
1900s we actually have sort of three al
use / / fragment engines so there's 48
of these ALU cords that can do these 4 x
32 bit things on every cycle there's we
do dynamic flow control on the program's
okay by dynamic I mean you can do if
some condition computed by the program
then and else as opposed to if some
static condition that never changes then
else which is kind of boring okay then
so now we can do dynamic flow control we
have these fairly large memory
configurations this amount of memory on
the board these things running about 650
megahertz for the for the processors 775
megahertz for the memory remember and
this is running a 206 big bus back and
forth to the chip okay all right
so I'm going to run through this
pipeline I'm going to try and go pretty
quick and just to talk about what the
different pieces are so the first thing
is there's the command processor is at
the top and it one of its
responsibilities is to control the rest
of the pipeline so the only question
here is whether that pipe whether that
control takes effect immediately when
you send the command or whether it gets
pipelined meaning it goes in behind
anything else that's already in the pipe
this is a deep pipeline okay and so you
know you may have already switched to
the next scene but the back end of your
pipe may not have yet and so if you send
a control signal down to the per pixel
operations and change the blending
function to be you know blending
function 12 now you're probably saying
that too early right because stuff
hasn't drained through so there's this
question on control about whether it
actually just goes through with like
like the rest of the stuff through the
pipeline or whether it happens
immediately that's the only real issue
there is there with that and some some
kinds of controller so complicated that
you can't really pipeline it through and
so you have to do this you have to wait
for the pipe to drain before you can do
it okay so now we come to actually
processing some data there's kind of
three ways to get the vertex data that's
the Defiant geometry you're going to
process okay the most straightforward
ways for the CPU to just send them okay
this is the old immediate mode then the
CPUs to send stuff back back you know
these days if you have a lot of data
that might be kind of slow another thing
you can do is store the data on the in
graphics memory and and then the CPU
just sends indices to say which vertex
it's supposed to be okay and then
finally the third way this is also sort
corresponds to the way history kind of
went and doing this stuff is to sort
both the indices and the vertices on the
graphics card and have the CPU just send
the command it says start okay so these
are the three ways to get ahold vertices
all right and they depend that sort of
where you're storing them okay then then
comes the actual vertex processing and
so when you have these vertices what do
you know you do with them there's
there's obvious stuff that had to be
done that has to be done you have to
transform them so that they're there in
the right orientation for you to be
looking at them have to do the
perspective effect there's a la bunch of
other stuff okay so this is sort of a
forward reference they they look a lot
like these fragment processors which
I'll come to again they have these these
four component product engines
you do for clocks for vertex / engines
are you this is how we end up with that
radar showed on the first slide of 1.2
billion vertices per second that in the
650 megahertz rate okay these things
around 32-bit floating point they have
these things that these are arithmetic
instructions like multiply add you know
one of Rex instruction 1 over square
root of x you can do comparisons or you
know set on less than those sorts of
things and then you can use this those
comparisons and flow control
instructions so you can do both you know
calls and returns and looping and so
forth but you can also make them
conditional okay now once you're done
processing the vertices there's some
final steps that have to happen these
are typically hard-coded well there's
usually a combination of hard coding and
programming so I'm not going to spend
much time on these these are sort of
this this clipping is an exceptional
condition where your your polygon ends
up against the edge of the screen at
least in some cases you have to figure
out exactly where that isn't produce a
new polygon that's been clipped by the
edge of the screen this is we try and
avoid this because it's slow and it
breaks the flow okay but it but it has
to happen you also have their parameters
that get sent along with vertices I'll
talk about those a bit in a second they
have to be clipped as well there's a
prospective division that has to get
happen to take place to to get the
effective perspective viewport
transformation to scale the final
results to to the screen or to the
window you're drawing into and then
finally you have to assemble these
vertices into something either a single
one might be a point two of them two
could define a line segment three of
them to find triangles we don't really
go beyond three because if you go beyond
through then you can just call them a
bunch of triangles okay stuck together
somehow okay so now I guess I should
have thought this is a mistake i should
have lit up rasterizer here this is the
stage now where we take the geometry
that's been produced and and figure out
what fragments are corresponds to okay
and this is done on modern hardware on
an api server in particular in a to
two-step process where we do a course
rasterization first week we figure out
which eight by eight blocks this
triangle is in ok and then once that's
done you figure out which two by two
blocks within that and with and within
each two by two exactly which fragments
are being
okay and that's done that's done both to
be sort of to make to be cash friendly
okay because these things we have these
caches that are set up with this kind of
blocking structure in them and also so
that we can reject whole piles of pixels
at once that we are pregnant at once
that we know we're never going to hit
the frame buffer okay so you can work on
a whole late by a block and go we don't
even have to look inside this one right
well this one you do actually have to
look inside I don't have one here you
can't but you can one of these ones over
here you don't even have to look inside
right and if you do maybe you only have
to look inside a quarter of it okay that
stays work later okay so in addition to
actually figuring out which pixels to
light up you have to figure out what
these what parameters are associated
with them okay you know they're x and y
coordinates but there are other things
put along with them like colors texture
coordinates for indexing into a texture
and in general they're just parameters
and so you have to figure out what their
values are all right and it turns out
that the depth value you don't the depth
value is just a linear combination it
but to get the other ones because you're
in perspective you have to do a divided
every pixel of a linear combination of
two things okay that's just the way the
math works out so this is done using a
plain equation to obtain these these
linear combinations here and then a
division in each pixel on the fragments
on the parameters which is necessary and
then as I sort of referred to in the
last time there's some pre-testing that
goes on that that you know you can tell
beforehand by looking and by the frame
buffer also has this hierarchical
structure and it can you can get a value
back from there and decide once and for
all that some large group of pixels or
even some particular pixel isn't going
to make it I into the frame buffer
because what's are you there was already
in front okay so you never you don't you
don't even have to bother all right and
this is done hierarchically again to
just to save really to say bandwidth
down here just have save less stuff
coming through here okay
alright so here's a picture of a
fragment processor which I could have
drawn for the vertex processor but I
didn't want put up too many hardware
looking diagrams because Franco the
vertex one looks quite similar what
happens as fragments come in here okay
and they can get written into one of
these these registers of which there's
128 for wide okay for x 32 bit that's
what 128 128 all right then the Yale you
can operate on them okay and it can it
can read and write its own set of
registers and there's constants that are
that are set by the by the host before
the program gets executed okay through
some register interface this is the
control interface I talked about before
okay you know you can operate on things
and it can send stuff to an output it
has for up to again this is on current
age I hover there for possible outputs
each each for wide okay and so you can
send us up to four different locations
are out and frame buffer memory okay
there's a sequencer that controls this
whole thing and then there's this thing
in Greenwich I've just drawn is texture
there's actually a lot in there what
happens is you can send out an address
to the texture unit and what comes back
as some value read from your texture map
but there's a lot that goes a lot more
can go on in there there's there's
filtering that can happen automatically
again is set up by the host but happens
automatically it's a big deal what
happens in that texture okay but
basically you I mean the way the program
receives this is is kind of like this
where you have a three input ALU and you
can read stuff from registers from
texture from Constance and you can write
one of four outputs okay and these are
kind of this the speeds we're at today
just based on clock rates and so forth
he's not to be exceeded rates again okay
so one thing that's important about the
way the fragment processors work is
there's a notion of threading so what
happens on modern graphics hardware is
when a fragment program hits a stall you
want to switch to something else that's
ready to go so for instance we look back
on this thing this texture when I go out
and ask and fetch something that's in
texture it may not be in cash and even
if it is actually it takes a long time
for to come back okay as far as this
thing is concerned I mean this thing's
running at six undred 50 microts you got
to wait for that data to come back well
you could just sit there and wait but
what happens instead is you don't I mean
is the program you don't notice this but
what happens is the hardware says oh
this guy's this guy can this glog this
guy's block now let's switch to somebody
else who's not blocked all right and so
some so you switch to some other thread
that's not blocked and it continues on
its way I remember you're typically you
processing you know hundreds thousands
millions of pixels so there's always
somebody who's ready to go right or
almost always yeah so to the programmer
it seems like a texture fetch only takes
one cycle when in fact it takes a lot
longer so you get this latency hiding
effect all right that's such as to the
program I mean it's the program itself
seems to take only that long all right
except maybe at the very beginning and
at the very end all right when things
are starting out and it's important I
mean this isn't like sort of hyper
threading that you hear about on intel
processors or whatever this is there's
hundreds of threads and they're very
lightweight I mean it's possible even
thousands okay so the only trick is that
you have to store the stalled fragments
data someplace and so what we do is when
you start your fragment program remember
this this thing's got up to 128 of these
for 4-way registers right when you when
you start your fraggin program you say
how many registers you use and if you
use all 128 well it doesn't leave you
much storage for other fragments data
okay turns out there's actually backup
storage beyond 128 but just forget about
that presenter but if use like only four
registers well and do 128 / for you know
that's how you can do that many threads
plus you know x by the extra factor so
the fewer fewer registers you use the
more threads you have therefore the
greater latency hiding that's available
okay so finally get to the per pixel
operations in the frame buffer the stuff
that goes on here is the application of
fog so you can have a fog color that
front you know you're trying to simulate
being in foggy atmosphere or something
things very far away or just going to
look white things close to wrapping them
you look less so you can just do this
linear bland to get that effect with a
fog factor there are these tests the
death test is for doing hidden surface
removal to find out what's what's
closest to you and there are these other
tests that are used to do various
rendering tricks to do things for
everything from shadows 2222 polygons
that look like trees but are actually
just polygons there's all kinds of stuff
you can do with these tests then you
also there's also this notion of
blending the incoming color with the
color that's already there so if you
have something that's translucent you
want to take some of the translucent
color and some of the color that's art
in the frame buffer and blend those
together and the important thing here is
we have this 32-bit floating point frame
buffer that you can use you don't have
to use it they're also fixed point
formats but it's it can be useful and
let's see I think so I've got a couple
pictures here and I'll show a little
demo in a second look you do with all
this stuff well you can make these nice
pictures and of course they never look
as good on a projector as they look on
the screen but but you kind of get the
idea i mean this is pretty this pretty
complicated scene with pretty soft look
and stuff and you know this is one frame
you know that's rendered at 30 or 60
frames a second right and so why would
you want the 32-bit frame buffer well
here's again it's a little hard to see
maybe on this projected like this but
you can do this high dynamic range stuff
where you you draw things right if you
only have eight bits you don't have very
much dynamic range for your lights its
but but if you're if you're able to draw
things with a lot of dynamic range you
can draw things into the frame but for
that are really really bright and things
that are really really dark in the same
picture and then when it comes time to
actually display it it's like setting
the aperture on your camera and you
decide well are the really really bright
things going to get you know the dark
things going to get brighter and so
they're really bright things are going
to get completely over exposed or vice
versa right so you can decide how to do
that but if you didn't have the high
damage
dynamic range frame buffer you couldn't
do the first step which means you
couldn't draw pictures like this okay we
can also end again you know these we can
do this anti-aliasing which means
essentially well there's different ways
to do anti-aliasing but it's to avoid
these these jagged artifacts along edges
one way to do it is to use a lot more
screen area than you've actually got and
then you just shrink the whole thing
down that's maybe the obvious way but
there are other ways as well and again
because we have all this memory
bandwidth and all this computational
power we're able to do that makes things
look a lot better and you don't see
these little jumpy crawly things okay so
let me take a minute because every
graphics thing we have to have a I got
to have a demo oops so this takes a
second to start up
this is this was this was developed by
our developer relations group just to
kind of show off the sorts of things you
can do with with this level of graphics
hardware I guess the thing to remember
about it is that in the beginning
especially it's all being rendered at 30
to 60 frames a second okay there's a
it's not them it's not a movie what
you're watching
and we'll just hopefully how'd it do its
thing it's almost ready here and I guess
oh I didn't plug in the sound oh I'm not
gonna do that now so here we've got you
notice this effect of rain and lightning
and puddles alright with with moving
ripples and again it's you know this is
I'm moving the mouse now right and I can
do stuff with it
10
and I didn't you know all this stuff
here you can ouch out maybe I'll when we
get a little further along I'll show
that you know you see all this
complicated stuff your most of it's not
most of it's just a few polygons and
it's all done with texture mapping and
and again texture mapping isn't just for
putting images on things you can also
just use texture mapping as a sort of
filter lookup table so you can use any
kind of data you want the texture map
including lighting data bump data for
how bumpy walls are supposed to be all
kinds of other stuff anything that you
you might want to have / fragment okay
and so and so there's you know there's a
bunch of a bunch of fancy stuff going on
these these these cobblestones the
cracks between them are modeled with a
with a very simple kind of ray tracing
technique it's possible that's that's
that's tractable enough to do every
fragment let's see I think yeah the
streaks running down the window here
these are these are being those aren't
run by the CPU at all there's a little
algorithm that runs on the GPU that you
know that moves moves a little water
droplet down every frame or figures out
how much to move it down and you know
randomly perturbs it back and forth to
get these little streets okay there's
all these other similar stuff going you
know that the curves to fund that the
wires yeah these catenary curves and the
wires here those are also calculated on
the GPU not on the cpu all right I've
I'm getting to the other part of my talk
so ok so i guess that kind of hopefully
that that gives some idea again where
this is all you know happening at 30 60
frames a second ok so
think well oh that's enough of that
ok
ok so now I'm going to switch gears and
talk about graphics programming
interfaces are a PRS all right so this
is I told you about all this great
hardware which I'm sure and a lot of you
already know all about how do you get to
this stuff ok so what what oh what a
programming interfaces graphics program
eaters have to do they have to provide a
software interface your graphics
hardware all right that's kind of what I
just said hit the lowest level what
you'd like to be able to do is expose
all the functionality of the hardware at
full performance ok on the other hand
you'd like to hide some device specific
details and you'd like to email the
limit the interface changes from
generation to generation of the hardware
ok and you know clearly this this first
bullet point in the second two are
almost always in conflict and so you've
got to kind of figure out where the
balance is all right at the higher
levels you want to simplify application
programming or which I treat is somewhat
it's not providing a software interface
to graphics hardware hit the most basic
level anymore it's making it easier for
the application programmer to write
applications ok and so the large classes
of these things are scene graph
libraries and shading languages to kind
of completely different things I'm going
to talk to scene graphs libraries were a
big deal a few years ago i'm not going
to talk about them at all these days
there's a lot more interesting shading
languages so the low level interface
sort of historically what what what what
happened was there was this fixed
function pipeline I mean that's the way
the hardware was was it the vertex
processor did certain fixed things right
rasterizer all still does fix things the
fragment processors did fix things we
didn't even really have notions of these
processors they were just these were
just stages in a pipeline all right
until OpenGL and direct3d kind of took
two different approaches to this OpenGL
required all the functionality in this
there was there was in this pipeline it
was it was fairly had a lot of features
and you had to go through software path
if you didn't have the features somehow
ok director ed took a different approach
which was to use these capability bits
which would say which which things were
in there in which weren't with directx
10 this is all become a lot more
stringent so so dx10 is sort of almost
gone
now we're you better have all
functionality and you better not doing
the software either okay both of these
provide sort of a vertex and fragment
part or work they eventually did provide
a vertex and fragment program assembly
language kind of thing I put it in
quotes because except for maybe one
brief moment in time that assembly
language correspondent to no actual
hardware so to me in assembly language
is the ASCII equivalent of a machine
language there was no equivalent machine
language so can't be an assembly lines
but it looked like it looks like an
assembly language directx 10 has even
gotten rid of that okay so you can't in
directx 10 you've got a program with one
with one of these higher-level languages
okay so let's talk about these higher
some of these higher-level languages
sort of the grandfather or something
grandparent of them was this thing
render man which was used in the steel
and heavy use in the animation industry
it's it's really it was it was designed
to do shading it was designed quite
quite some time before programmable
graphics processors were even a twinkle
in someone's eye I think this was done
as a software thing for doing the
animation rendering and it wasn't
designed for hardware and wasn't wasn't
intended for not nuts i mean the render
man is actually a great model I mean it
was very pat hanrahan knew what he was
doing so then there are these other
these other languages that have come out
to be sort of more hardware I mean more
amenable to hardware I guess is the
reason for them there's a high level
shading to hlsl which comes with DirectX
from Microsoft glsl GL shading language
of OpenGL and then there's a sort of
thing somewhat higher level thing called
CGS what was supposed to the idea with
c4 graphics from Nvidia ok which runs on
both DirectX in OpenGL these all
provides see like languages they're
there they're reasonably general in the
computation they admit but they they
expose some hardware they're sort of
tied to the hardware in some ways like
like they call out specially three and
four elements as one example glsl is the
only one that that suppose that
supposedly virtualizes the number of
passes if your programs too long it's
too complicated for to run in one pass
and glsl will look like your program for
you and run it in more than one pass as
a practical matter this hasn't really
come to fruition it's not so easy first
of all and it just hasn't hasn't really
taken off and these these are sort of
becoming
our or April we have have been becoming
the only real means to get at the
programmability okay the the actual
vertex and fragment processor
instruction set is just not exposed the
hardware companies including mine don't
tell you what that is okay so the only
way you can get at it is by using one of
these higher-level languages and this
contrast that to the CPU world right
where the CPU instruction set is
published can you can write in that if
you want to you can't hear ok so i guess
my idea about this from some time ago
and this I guess this picture reflects
that it was some time ago because I
don't have all the lines on here there
now exists is to sort of look again at
what the hardware abstraction is all
right so OpenGL originally was not
programmable it wasn't meant to be and
graphics memory wasn't accessible really
wasn't directly accessible in fact you
had different kinds of graphics memory
for the frame buffer for for texture
memory for storing vertices if you had
such memory but now it's all the same
memory ok sort of special purpose not
not directly accessible so the changes
have been that now we have
programmability and where we have this
kind of flexible use of graphics memory
where one one time you know the first
time through your graphics memory is the
frame buffer the second time through its
a texture you know use a texture to do
your next pass and so on you use draw
something in your first pass that you
use as a texture and your second pass to
draw the second one ok so if i do that
then I sort of come up with this idea
for a new new low level interface which
recognizes that these stages in the
pipeline over here are all programmable
now I put in where I put program will
hear this may be stretching it a bit the
vert certainly the vertex processor is
the command processor I've called that
programmable in the sense that you can
it's not like you write programs for it
but you can decide you can tell it how
its how what what formats data is
supposed to be and is very very flexible
so you can / essentially programmer to
say how it's supposed to fetch its data
ok or what what the format is and so the
idea is I want to distinguish two things
here we've got this sorted we got a data
path all right and and so it's the
routing of the data and then we have
these parallel data processors all right
and we have some of these some fixed
function stuff that's always going to
happen
as well so if we once we expose
programmability I don't know why we need
fixed function anymore okay so all the
stuff that was in opengl like to set
transformation matrices and two
transformations or two to set a
particular function to use when you're
doing texture mapping all these things
why do you need that anymore why have
that since you can write a program and
that's that's what that's what our
drivers do anyway they they when you say
when you asked for that kind of stuff
they just stick a program in that does
what you ask for so why not let the
application do that too all right and
then and then I guess the idea as well
okay let's just go ahead and expose the
Machine language if you don't like
programming in a machine language well
don't use some higher-level language
just like you do want a cpu most people
don't program in x86 anymore use a c
compiler fine but if you need to use x86
are you you need to find out where your
program is going slow it might come in
handy okay and then you use libraries to
implement the fixed function stuff em
and what you really want exposes the
memory capabilities in the routing and
at least to this kind of stripped-down
interface I just one of the thing i
should say here right I've drawn this
line here because sort of above this
line is that is the world of geometry
and sort of streaming data where
vertices are coming through and you know
one vertex comes through and them about
the back some other vertex comes to or
and now I've drawn this put in this
primitive processor here because directx
10 allows you to not only process
vertices but to process the primitives
that get put together from those
vertices okay and so and so so that
we've got sort of the streaming thing
above here and then below this the
rasterizer just blows up these these
these bits of geometry into fragments
okay that you can think of as just being
as running these parallel computations
are each each fragment is running in
parallel with a bunch of other fragments
so now in this world here this is much
more the sort of data parallel world up
here we're kind of streaming here we're
data parallel okay that's why i drew
this line here
okay so this kind of fits with these new
GPU applications as you see where I'm
leading to probably so we have these
recent applications that up until
recently have been mostly the purview of
academics where people have been very
interested in using the power of these
graphics processors to do up your
fingers from things other than graphics
okay and and you and if you want to do
that it kind of makes more sense to talk
about this thing as a processor rather
than is a graphics pipeline with with
graphic state that needs to be set okay
so these are kind of some of the kinds
of things that the people are doing and
then it even includes you know some
reason some new graphics applications
right where this this pipeline that I've
shown it's good for doing a particular
Klima graphics Z buffered render and
z-buffer hidden surface removal with
texture mapping I suppose right ray
tracing is quite a different deal yet
now people are trying to do ray tracing
on these same processors even though
that's not what they were built to do
okay it's just a sort of recap of the
compute performance I've already we've
already talked about most of this stuff
okay turn 40 giggling our quarter of a
teraflop is not to be sneezed at I guess
at least if you can really get it and
memory bandwidth kind of the same thing
and also very high much higher than most
CPUs are going to give you we have this
you know fair low low low latency for
forgetting for floats out of out of the
cash and here I'm just talking about the
fragment processors okay this isn't even
the rest of the chip right okay and then
we have you know we can we can transfer
data quite quickly to and from the GPU
memory okay so now I come to 280 is what
we call ctm okay which is our new
interface for computation
so yeah right ctm stands for close to
the metal what we do what we do is we
expose the fragment processors and we we
try to stop using graphics terminology
but you'll see here I haven't completely
weaned myself of it and sometimes it's
easier for people to hear the graphics
terminology and if I say though the
computing when they're like what are you
talking about I said texture oh now I
understand so so they'll be a little mix
up with that but anyway the idea is to
expose these data parallel processors
just a fragment processors okay we don't
worry about the rest of the pipe yet and
memory all right and so we specify the
actual processor instruction set you can
open up the manual and find out what
what instructions the processor actually
runs and you can program it in machine
language your assembly language if you
want all right because there's an end
there's then there's an ABI application
binary interface as well for loading
programs into it all right and it leaves
memory management entirely up to the
application seem the graphics API is
right you don't you don't really talk
about memory you talk about why one
loaded texture now where I want to set
up this frame buffer and the driver
somehow you know besides behind the
scenes how that corresponds to memory we
don't do that we say here's memory do it
as you will again more much more like a
CPU ok so an important thing is that it
it does have this device dependent
component that's the instruction set
architecture right that is going to
change or is there is certainly the
likelihood that it will change with with
new new GPU incarnations ok but there's
there's this control hardware around it
that doesn't have to change ok so
there's a stuff about how you know
that's setting up the memory and setting
up the program that can be that can be
abstracted and can be device independent
ok so we provide a model of the GPU
command processor I'll show you a
picture in just a second we try to hide
details about the graphics pipeline that
aren't interesting to people who are
doing computational programming ok but
you still need to have them set writer
things won't work and again this control
stuff is architecture independent so
we're focusing on computation and as a
result we don't we don't we don't export
the whole GPU
in fact we don't even explore the whole
GPU right around the areas that we are
exposing so for instance right now we
don't expect it suppose texture
filtering even though that would not
wouldn't be difficult and there's we
don't we don't suppose vertex programs
in a number of other things okay we do
support multiple GPUs in the same system
so here's here's a here's a block
diagram what happens is the inner the
application talks to ctm I mean you can
think of ctm is sort of as a third
divided graphics driver we've got open
jail we've got direct decks and now you
can think of ctm as being another way to
get at the hardware okay so the model
Ford is the application talks to talks
to CPM through a very tiny interface
with only four calls in it you can open
a connection to a device you can close
the connection to a device you can
submit a command buffer to the device
and your you can you can find out if
that command buffer has been consumed or
not okay so what this showed what this
exposes is that there is in fact a
command processor okay inside the only
way it exposes what it abstract seni way
there is a command processor that you
send commands to and i'll show you what
the classes of commands are in the next
slide and then that thing is connected
up to a bunch of memory both memory on
the host PCI Express memory and memory
on the GPU okay and inside that memory
are things like maybe you can pull
commands from inside this memory and
through this memory controller instead
of sending well that is actually I'm
sorry that is the way they get pulled
through okay this thing just has these
four commands I mean these for our API
points instructions for your fragment
programs are in here okay Constance
inputs now those are textures outputs
those are friend buffers okay so these
are just memory now and I want to make
clear here that there's there's in a way
there's two things going on there's
there's commands that come into the
command processor and and send control
through this thing control around this
thing and it also tell the tells the
program's when to start the programs
that this thing runs are not these
commands they are these instructions
over here okay
so examples of not let's see tonight now
i guess i didn't put in the commands
which is too bad but okay so some
examples of commands would be things
like start program okay or set input
address to something okay or set
constant 57 to you know three four five
six seven something like that okay those
would be examples of commands and then
instructions or things like multiply add
sine cosine stuff like that okay get run
by the actual program alright so now how
do we generate code for this thing these
are the instructions over here okay so
that's we leave that up to the app on
like the graphics drivers we leave that
up to the application okay so you could
write your own compiler if you want you
could write directly to assembly or
machine language if you want but we
provide some tools and we have a source
code for a sort of non optimizing
compiler then also a TI has an
optimizing compiler it doesn't that
accepts a sort of intermediate level
language that we can also give you too
if you want optimized code as well the
only thing about that's opaque though
because it contains some some real
intellectual property okay so that's how
you can actually program this thing at
any level you want we're so we're trying
to encourage people actually outside of
a TI to do compilers and in other kinds
of things that you'll need to do this
kind of programming like debuggers
profilers things like that okay so when
we can sort of contrast ctm with some of
the graphics api's some of the problems
with graphics API czar that the
application has to manage this graphic
state which typically application isn't
care about and plus it can be
complicated to do write the code
generation is by design hidden okay
which which can be which is fine i guess
if you don't care but if you're trying
to really find out where your program is
going slow and why did you do this in
the first place you wouldn't even bother
if it wasn't for the performance you get
so if trying to find where the programs
running slow it's a little bit hard to
do if all you have is a high-level
language and a slow program okay the
memory managed format management their
buddies there they're hidden in the
graphics api's we don't hide those again
because we figure while the application
what he wants to do with the memory we
don't want you as an application writer
probably don't want the graphics API
deciding oh this should be in host
memory now I'll copy it out a GPU movie
memory and sticking on host memory or
vice versa these things can go on
without you even really knowing except
that they affect your performance and
all of a sudden why is it so slow at
this point so we don't do any of that we
leave that to you and another problem
this is actually happened to is that at
ati course we're really concerned with
how well you know games run on our
machine right and so somebody's writing
some GPU application in stanford or
wherever and they write up something and
then they get a new driver releasing
they go great a new driver least maybe
that'll fix my bug they download and all
of a sudden their program it was running
so great before except for maybe a
little problem runs twice as slow why as
we put in some optimization that was
super important to make dhoom dhoom 3 go
fast ok but but destroyed this poor
person's a application ok and and so we
get rid of it but by making the compiler
sort of not part of the driver anymore
once you compile your code you can be
sure it's not going to change ok so and
you know and it sort of it goes on and
on api's arm you but mediated by the
window system and you have to worry
about all that stuff I in the driver and
that can affect your performance where
you don't even care about what's showing
up on the window if you're writing one
of these things so why should it matter
all right you don't want to have to your
application couple to display policy if
you're not using the display ok and so I
mean this is you know I performance in
functionality may have you don't have
predictable performance and
functionality and it's it's a problem
for some people or a lot of people ok so
I think I kind of I went I went through
most of this except maybe the command
but for packing and submission yeah I
think right so you also have the ability
to pack your own command buffers instead
of the driver doing that for you and so
you decide when your program starts you
decide when the right time is to
invalidate caches or things like that
okay rather than some driver thinking it
knows what you're doing because it
thinks you're doing graphics deciding
that for you so and I think the big
point for me about this is that graphics
API is a abstract the graphics pipeline
in particular one ok ctm we try and
extract the actual process or a piece of
the processor
okay so here's some sort of examples of
these are speedups we've gotten by
programming ctm instead of programming
in OpenGL all right so on matrix-matrix
multiply we got a factor of four speed
up and this is because we can access
loops we can we can get the features
that are either inaccessible or or not
or more managed in a way that that
doesn't allow us full use of them in the
drivers okay so we're able on Major's
means model by were able to get a huge
feat of I mean we're running at a 110
gigaflops or something which is which is
pretty fast i mean that's so that's a
lot faster most abused
I like to know is
as in one day
and we are
that's if I got yes so right so this one
is easy to the matrices are in memory
okay so they don't come down through
that pipeline chain so the matrices are
either in pci express memory which is on
the host on GPU memory ok so it is not
really a notion of a frame buffer or
passing something in there just a memory
memory yeah we're in our memory yes and
so 110 gigaflops for both matrices in
GPU memory if they're in CPU memory
through them you gotta go for pci x he
expressed transaction to get everything
on the graphics card yeah that's correct
yes that's right this is that's right
this is for that when I see that's why I
probably should have kept my mouth shut
about the numbers that's why this light
doesn't show numbers the point on the of
this slide is showing why you want to
use ctm instead of opengl okay but i'm
sorry so book why I want I don't want to
stop your questions get to the left yes
being able to move data high rates Brown
back through the holes that's right
we're also driving
so much vehicle
that's right and are today actually ctm
does not expose the ability to do a DMA
at the same time computation is going on
even though chip the chip can do that
and that's something where it's a almost
at the top of our list at this point so
that would allow you to do that but
today no today it's got to be serialized
essentially but there's no reason why
you can't why you shouldn't be able to
do that anyway so these you know you
guys get the idea these are this GPU I
think this is a ray tracer that was done
at Stanford a simple ray tracer and then
this Q julia is a Julia set render and
done by one of our people okay and again
we we get these speed ups by like being
able to get get ahold of features
directly that we can through the
graphics a POS okay i'm almost done here
i feel like i need to probably some of
you have heard about nvidia also has an
initiative for they've also got a new
that their new generation of hardware is
also out ours is not yet they have an
initiative for doing GPU programming as
well for people who want to do
computation in art graphics you know I
guess I'm violating a rule here I'm
probably not supposed to talk about my
competitors product or something but so
I'm not going to say much about it
people have more specific questions feel
free to ask me afterwards but it really
specifically for GPU computation it too
is sort of like you got OpenGL you got
directx you got CUDA it's it's what it
the programming model is is they give
you a slightly augmented version of see
which segments it enough so you can
express some stuff about threading and
and in that that that seems very
attractive but they do not expose the
actual processor is a or the sort of
command processing nature of the way the
thing works it's it's a it's a much
higher level I say much harlot ladies a
higher level abstraction than what we're
providing it doesn't doesn't tell you as
much about the underlying hardware i I'm
I'm biting my tongue not to make a bunch
of judgments on that but if you want to
ask me go ahead otherwise that's that's
what that allowance anymore someone from
Nvidia to tell you more about this
so so I'll finish up I guess the
conclusion all this is you know the good
image quality and requires a lot of
computation and gosh well you know these
gpus a block on computational power and
you can actually use them to do things
to compute stuff it might not be graphic
stuff okay and it's not just the court's
number gigaflops it's also this very
high memory bandwidth graphics API are
known as a good fit to expose the
computational power particularly for non
graphics things real-time graphics has
changed and it's going to continue to
change all right so the big changes have
been sort of this program ability and
single memory but I think what's what's
the changes that are starting to come
more is that the line between
computation and graphics and blurring
you know he's blurring ushered in that
toy shop then some of the stuff it was
doing was was was pure sort of in a
sense pure computation but the result
was graphical right so you're doing some
simulation to find out how water runs
down a piece of glass all right so so
what's come let's come what'swhat's
graphical and what's not starts to
become not quite so clear and you know
people are doing things like game
physics on GPUs ray tracing on GPUs
which is sort of the opposite way around
where you are doing great like I said
before you're doing graphics but not in
a way it was intended and we're going to
see I think the use of the CPU and GPU
in a much more finer grain use than we
have in the past you know against you
know some of you may have heard that AMD
is announced we're going to put a GPU
and the CPU on the same die by I think
the end of 2008 so you're going to start
you know my opinion is that you'll start
seeing a much tighter coupling and that
will lead to doing some things in a new
way not only in for for computation but
for graphics as well so that's a that's
what I had and take some questions yeah
yeah once you start you
yes it is
and we happen to work
okay are we here constant there's a
classic paradigm the reincarnation of
graphics technology writer first you
have done frame buffer then you put a
little processing and then you get these
maksud processors and then it will get
sucked back into the cpu again how many
times have you spun round and you think
it's still turning
how many times has gone round I'm not
sure how many times it's gone around do
I think it's still turning you I will
ever stop probably not i think what what
character I think there's some stuff
that the character Isaac I mean there's
still some things that are very
different about GPUs and see if ism and
some of those things if you want to
continue to do graphics well can't
really change you have to have some way
to do a lot more computation and then
you can on a cpu and the way we've done
that is to these parallel ISM right and
you have to have a way to get a lot of a
lot of memory bandwidth so so that's
that's not really going I guess I me
north or that you so if you if you could
do that on a cpu than fine but but today
it's you can't really and even these you
start to see moves towards multi-core
and so forth and there the you know they
start to go down that road but there's
there's still a ways to go before they
would actually become GPUs again my
opinion there's also this idea of the
rasterizer which i think is really sort
of architectural e what distinguishes
GPUs from cpus and as long as z-buffer
graphics is i don't know a preeminent
way of doing graphics i don't see that
going away either it's possible we might
you know I'll decided yeah it's time to
do ray tracing we're done with this e
buffered rendering and junk but until
that happens how do you need of the next
as you say
when I am the footage accuse into their
she kills with
clean in the turn we're back to
effectively dumb frame buffer dirty car
OIC yes that's right uh-huh yeah no I
mean yeah I mean if you it's true if you
divorce that if you if you look at GPU
is a long processing pipeline and then
there's a little bit of thing at the end
that does video all right and you just
take off the you cut off the video thing
now you've just got a pair a big
powerful processor it's got this weird
architecture so yeah I mean you're right
you stick that on the same guy the cpu
while i have just got a heterogeneous
processor and that's all it is yeah what
can I don't say about that I know all
about nowadays
I am
they
they here to get the pen
for
you
shame
and hi I can't you know I keep these are
all I've said is what's been announced I
can't not not that i know tons anyway
but i can't send anything more than than
that about what you know details about
how it's how it's all going to work you
can think I mean but maybe the thing to
look think about is integrated parts
right and how those work I mean I think
that's probably the better analogy then
then some high-end thing in the
beginning but I don't know frankly I
think we have to see where it comes out
yeah go ahead back here
no way
recently
our serve you
worth of
I guess my opinion is not really because
well it's well it's true that vistas for
instance is going to use a lot more
graphics processing than anything
Microsoft has put out before it's still
not very much compared to games or or
even even mid you know even mid-level
games and it can't be that much frankly
because they have to be able to go out
on not very powerful graphics processors
so I I don't I don't really think so now
I I again I I shouldn't I could imagine
there might be some some wizzy desktop
feature that it becomes very exciting
that they will drive some something but
I but generally it's hard for me to see
that that's not going to do somebody
else out watching you
regards of unified shader model
currencies are constructs are exposed
ok so the front I didn't hear their game
for just a unified shader model yes as
an impacted regards using perfection
processing price within
and geometry right okay so as long as
some of you obviously know direct that's
well next section doesn't mandate this
but we certainly seen a hey there's
there's been a trend to to combine all
these to combine the 30x process of the
primitive process in the fragment
processor in the same hardware okay
logically they still are still are
separate in this pipeline but the actual
hardware that's used to run each of
those is the same so the question is
with that does that allow for or what
effect does that have on safer text
processing for ctm the answer is it
doesn't really have much except that now
you get to use not now you have even
more power available to you because you
can use all the processors to do your
process and instead of just the
11 well no because if it's the same
hardware like we look at xbox 360 it's
the same hardware we just we would just
expose the instruction set architecture
that machine you do what you want now
again and see TM is exists today we
don't we don't expose this rasterizer
for I mean come up afterwards if you
want to know why why we didn't decide to
do that in the beginning until we do
that we can't expose all the power of
the machine okay so then there was
another question about threading
mechanisms present verb
right now so so again maybe you're
familiar with with and with Nvidia's new
hardware yeah so again so he's asking
about what kind of inner thread
communication there is now right these
remember you know I said these these
things right there's 16 of them and
they're all running in parallel and
stuff can they talk to each other no
okay and that's just the car our current
hardware does no say it doesn't allow it
it turns out that we do have someone
who's figured out some wacky backdoor
that we would probably couldn't expose
to the public that does allow you to do
in some strange way but but it wasn't
designed for that I can't talk about
upcoming products but it's true that
Nvidia does have a product that allows
some form of internet communication with
shared memory yeah
pipeline you can never lead back from
the grave operation shade
so does that have an implication on
because essentially you can't say when I
re with my current result
the standard pipeline is a part that
restriction of not being able to read
from the frame buffer and a fragment
program is really a one input well it's
one imposed by the drivers I mean
there's nothing wrong with you and you
can do this in CT emphasize to set your
your frame buffer address and your txt
read us to be the same thing and write
to the same area memory you're reading
you might not do what you want because
they're these caches in the way that are
kind of are going to act strange unless
you're being careful how to use them or
you're careful use on crash reads and
writes strange things will happen but
that's no that's not a that doesn't even
go I mean I can't it doesn't even
stealing and think about things that
were in CT m yeah
windows vista interface another
so the questions about sharing sharing
resources okay so in the right for
graphics drivers right direct the way
direct axis directives has had sort of
an exclusive that you want one directs
Apple directx application that's it
always d 3d application OpenGL has had a
different taking a different approach
where you can have multiple ones none of
that changes here the way on the way the
way ctm works is when you make that
initial call to open this manage
connection you can say how much memory
you want of these different kinds and it
will try and give you that when you come
back if you ask for all the memory you
could possibly lay your hands on there's
not going to be anything left for
anybody else so you're not being a very
good team player but there's nothing I
mean right now we have no there's no
virtualization of those resources right
because we don't want we don't want
memory copies going on under under
behind people's back am i answering your
question I'm not sure if I am yes well
that's right so you can so you can do
that right so you can have say you could
have a couple OpenGL applications
running in there taking up some memory
then your ctm application comes along
and says oh I need you know 30 megabytes
or something because ok you can have 30
megabytes that's not being used right
now and then you go ahead and do that
and you up of course you're not you know
you're really being time sliced just
like you want to see for you except the
mem you know you got your actually
holding these pieces in memory all right
so there's there's something stopping
you from doing it and there's nothing I
mean the way OpenGL works today is all
that stuff's managed for your underneath
out sorry that if you forget about ctm
you can run multiple OpenGL clients and
if there isn't enough memory on the card
it'll copy stuff back to the host or
keep shadows of it on the house pull it
back in when it needs to like a virtual
memory system so you can imagine doing
that as well and this actually has some
support for doing that for graphics the
virtual memory
so I think I vanets are probably too
much prep time here on chair muncher
yeah it's like easy performance with a
small application colonel been with a
black paint no doubt about that way so
this stuffing used on something this
size you like the weather simulation
there yeah it's starting to be there's a
company called peak stream which is
right around here a startup company and
they've they've actually they've had
since they they have some customers most
of them I believe are there some are
financial and some are doing seismic sup
for oil and gas and they've had some
success definitely but you're right as
with anything when you when I just put
up these little things they're also kind
of not to be exceeded number and the
real issues are not how how many
gigaflops the thing is has but whether
you can really use all the memory
bandwidth and how fast it takes to
upload and download things and how big a
think computation you can run before you
have to read stuff back so you're right
and so yeah there is there is there
starting to be some successes there but
we're yeah there's well there's a lot
more to get one more question it's
almost I Triple E yeah can you tell us
what the differences is an issue
forward moving more towards
general-purpose uses is there any drive
to make it more standard to add double
precision yes sir yeah so the questions
about I Triple E and I let slip the
comment that were not perfectly i triple
e we we don't have different rounding
modes so we do we do round to nearest
even we treat d norms as zero okay and
they will turn into zero except in
certain paths through operations that's
that's it there's a mode in which we
don't treat Nan's correctly but that's
for some graphics and you can turn that
off that's it otherwise where I Triple E
except there's no signaling man's
because these things don't have
interrupts and again for some
applications that's an issue but now
right and no double precision today but
there's definitely I think in videos
already announced they're going to do
double precision sometimes within a year
or some that some some upcoming parts
going to have it I think that we're
probably going to move that way as well
so yes we're moving that way some you
know the Dean arm support I don't know
when that's going to happen signaling
man's that that's a ways off because
that requires these things be
interrupted which I know let's thank
mark
Oh
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>