<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Radioactive astronauts: images worth a thousand experiments. | Coder Coacher - Coaching Coders</title><meta content="Radioactive astronauts: images worth a thousand experiments. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Radioactive astronauts: images worth a thousand experiments.</b></h2><h5 class="post__date">2008-04-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/A2dwkZ8-PDE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you know alpha inviting me today
it's a pleasure to we had google and
actually see the campus first time for
me and today that the talk is going to
be about there's really two fold in the
talk i'm going to try to bring up the
technology and the type of thing we've
been involved with that links well with
palimpsest and actually Google's
technology and at the end i will try to
link it back to actually the type of
work we've been doing and show you where
those needs could play a row but they
don't play a role yet but and i will
show you a bit about how we do those
things so before i go into the biology
and about the the projects of the nasa
project i'm going to talk about the
technology a little bit and the first
question is in the early 80s people
started realizing for the longest time
people have said that the human eye is
the best the best pattern recognition no
tool that exists and it's true we are
extremely good at recognizing features
because we grow in an environment that
has features so we have grown to
recognize them a computer is very bad at
this it's going to getting better but
they're not as sophisticated as we are
and they're done it very good at
quantifying things in a very and in a
very predictable manner so you know if
you go to the doctor and let's say you
you have to go get a biopsy East Oh
pathologist will get something like this
it's an image and you see those nuclei
here which is a you know shown in blue
or it should be blue but it's a it's a
dark thinning here and the nuclei
looking at this pattern a pathologist
will decide what type of disease you may
have do you have a normal t-shirt you
have an abnormal tissue and they're very
good at this but now the one thing
they're not very good at even though the
expert in recognizing pattern is to
quantify and absorb a lot of information
at one time and that's where computer
becomes more powerful so to illustrate
this that was done in the 80s I'm just
replicating what has been done in the
past early eighties someone challenged a
lot of people were saying can you
recognize the different patterns so we
regenerated those things here in those
images i created five different circle
with five different diameters so it's
five units and we mix them in a random
manner and the question is can you with
your eyes decide if those four
populations
are the same populations or in fact they
are maybe there are some of them the
same and some of them are different and
i would say putting that to anyone you
know when people have been tested on
this they it's really hard to tell
anything and in fight in these images
there is two groups so a and c are the
same population and they basically are
you know the majority of those circle
that you have the median sized circle
whereas the B&amp;amp;D actually have two
populations in there not something
really obvious by the eye but it's
really there and this is what we're
saying about quantifying biological
image I think this is the type of data
that starting with a convincing bulges
that they should go after quantitative
to understand involving a lot of money
and the end development trying to
quantify those images so our work we're
not imaging species we do love imaging
but our work with is to quantify data as
much as we can image-based and then
integrate them into some models to
actually predict behavior of human and
how they respond to radiation so
fluorescence microscopy is a growing
trend in the US and actually the world i
should say if you look on google and
search fluorescence microscopy on
publication peer-reviewed publication
what you see is a big jump in the 90s
this is when the first fluorescence
microscope became available I would say
affordable and there's a big jump where
people start getting on the on the boat
and sign producing a lot of those images
and then since then it's been going up
non-stop and and the technology is
getting better and faster we're getting
we have now broken the the resolution of
a microscope it used to be point 15 mark
micron now we can go below that using
4pi technology so there's a lot of
technology that's coming up around the
corner we're generating more than a
higher resolution there for a lot more
we need a lot more space and just to
give you an idea of the type of market
with dealing with just in the US and
just looking at the university if you
consider this about 2,600 accredited
university in the US and most of them
have at least one image in core facility
each imaging capacity usually served
5,200 people you can imagine immediately
compute it's about half a million to 1
million people that deal with this type
of images every
and that's only in the Academy it's on
only in the US so this is something
that's growing and it's just going to
get harder and basically what we start
seeing in our lab for instance is a we
getting a bottleneck in terms of how we
deal with the data we we're trying to
not process all the data because we just
have too much and we're not giving we're
not you know giving a good time on the
line and basically we're not giving the
when I extract extracting what we can
from those data because we just
saturated so the outline of the talk is
the imaging challenges we've been facing
over the past five years at the NASA
projects so NASA edited five
universities I should say five national
lab in the US and LB now is one of them
so that we were given a lot of money to
actually study defective additional
human we do one component of the project
and there's five other universities in
the u.s. that does that and under the
nasa project i will talk about the
effect of cosmic creation astronauts
really imaging oriented type of talk and
on the imaging challenges will go over
how we sort and are we browse through
our data right now how we do
segmentation how we deal with
registration and how we deal with
pattern recognition and again we're not
imaging species so if your imaging
expert you might think our approach is
fairly nice but we try to being a
physicist we we're really talking to
many different group at the same time
and we try to integrate we do quick
imaging approach that gives us fairly
quick answer so we can link them back to
the models and I have results for the
for the biology so it's kind of a weird
niche where we are so this is type of
data set we get usually you get a
gallery mode where we can see as much as
you can it's really hard to see the data
but basically all those blue things are
nuclei there are stand for DNA and the
different colors mark different things
such as DNA damage for instance and on
those gallery mode this is one software
called metamorph we can go and click on
anything and then immediately the
annotation of the image pops up so we
know what we're looking at then this is
one way we we have a quick view of our
data then what we have is we use MATLAB
actress so that we use many different
software in the process it's not
smooth at all under matlab matlab is a
great system to actually do a lot of
prototyping so we put type all of our
work on under mat lab and what we've
been developing is tool to read
different imaging format because
microscopy unfortunately has different
imaging format they all teeth based but
then each company because we're dealing
with five dimensional images there's XYZ
then you have channels so the channel
can be up to 32 channels at this point
in microscopy so you can acquire 32
different colors so that becomes a
dimension then you have time so those
five dimensional images becomes pretty
hard to handle and so they have created
those embedded TIFF system and so they
you know Zeiss has created zvi and NSM
metamorphose created STK nikon has
created ICS and so we have to each time
we have to go and and read their special
tags and have them under mat lab so we
can parse because the beauty of reading
those images and reading the information
and images we can start sorting and
parsing through things such as for
radiation biology what we're looking for
is that those we gave to the specimens
we want to know how much it got we want
to know when we stop the specimen why
was it fixed so the time it takes after
radiation is an important factor so the
longer you wait the other type of
endpoint you're going to be interested
in the type of level you're looking at
so are you looking at DNA are you
looking at DNA damage some proteins the
type of cells are looking at so all this
is usually a noted in the image at the
moment of acquisition and can be taken
out and then we also also do one thing
classic thing is we always do automatic
segmentation of the nuclide this is the
one object that's always wanted in an
image we want to know where the nuclei
are individual cells so we can then ask
question for each of those nuclei so
this is done on on a batch mode as well
so nuclear segmentation nuclear
segmentation if you're lucky you get an
image like that it's great nice uniform
amo genius background you all you have
to do is threshold it and you get the
contour it's not very it's hard to see
here now that's a bit harder multiple
nuclei they overlapping with each other
multiple intensity multiple pattern and
so when we tried segment is it becomes a
bit difficult
and we don't have a great working
solution nucleus limitation is a field
that's been done for I think 30 years so
there's many algorithm and everybody
came to have the best system so we know
in the business of the nuclear summit
you only one is actually have something
that is fast enough and that gets us
through the data and so those are
different zone of problems ii
overlapping high intensity so one of the
prime is the background for instance
variation of background so in the semi
major you have a background that has a
high intensity versus a low-intensity if
you were to threshold this if you
special low you'll miss some or if you
special hi you well if you threshold how
you miss those guy but if you set your
low you're gonna start picking up stuff
here so you also have within each
nucleus patterns that tend to be
punctuated sometimes and how you deal
with this so the approach is very simple
first to go fast again we subsample the
image we always do nuclear segmentation
on the sub standpoint much because we
don't need that much accuracy for
identifying the object so it's one a
little trick that we use when we
subsample the image we can then pass it
through a classic filter like Gaussian
and median filter which can kind of like
make the system more modulus then we
threshold get a binary mask and then
through iterative process we can
actually find the seeds of the multiple
objects in one mask and will tell you a
minute how we do that and finally we use
watershed technique to regrow from the
seeds and we get our full nuclear
segmentation interpret it back to the
full size obviously so the iterative
process is very simple like I said
there's many more advanced technique but
that one is actually very quick and what
we do is we just do multiple erosion and
tea on a binary mask until we separate
two objects so if you do on multiple
level you can separate and it's you know
I'm not trying to claim we have the best
system here you can see how it actually
didn't do such a good job we separate
that one very well but we missing some
of those guys and the reason is really
for something like that you really got
to go with a knob shape based type of
algorithm you threshold again this is
not going to cut it but again this is a
very extreme case and we have ways when
we do the prep to minimize this type of
events so we can grow the cells and stop
the cells at a moment
not touching each other when they don't
grow on each other so so the batch
processing matlab so what we do with
matter then we can identify the nuclei
and we can also identify spots for
instance so in this case this image
you're looking at here those cells were
traversed by cosmic ray so each track
here is a sound is a DNA track those a
DNA damage those low dots so what you're
seeing here is human cells breast cells
thus this is what we work on breast
cells the great model for radiation
because they tend to have cancer easily
with radiation so this is our mobile
human breast cells and what we see when
we put them on are on a beam you they
create those tracks and those are DNA
damages so we generated first we get
those huge gallery and then we do
automatic parsing to know what is what
so that image for instance gotta iron
particle you got was one grade as to
those and let 30 minutes after radiation
then you can so if I will go back and
forth you can then segment the new crew
so negative and axial so you can
identify the tracks and those are label
images so you can identify different
spots in the track and then we can go
ahead and do that over all our data and
if we go back to the product show you
the computer knows that this book for
instance is a 50 centigrade that 100 and
that one 300 centigrade and then on the
fly almost with matlab we can create a
text file that will come and generate
those those graph and big surprise what
you see is what you expect which is like
the higher the doors the more DNA damage
you see it should follow a linear trend
you double the dose you double the
damage you double the number of damage
that's what you measure perfect the
slope itself is a very interesting
factor and that's what biologists are
interested in why is that slope
different than this one because this one
was obtained with a certain type of
radiation that one with a different type
of relation a tradition I have a
different way of inducing breaks so this
is the type of endpoint that the budget
is very interested in having they're not
really so much into all what we've done
but they were very interested in this so
how does that link to go I think here at
least as a you know personal user of
Google you know the one tool that comes
to your mind is picasa because if you
stopped because on your computer what's
amazing is it will go through your
computer sort everything not
on scientific parsing but I mean
scientific data but still will parse and
classify your data and then you can grow
through it I think it's a great tool
that does not exist in scientific
community all the company's eyes and
Nikon they have not developed system
like that they're not very smart in
terms of broaden through the data and
then in terms of searching through that
it's even more messy if you use one of
those software nikon or zayats because
they don't really plan for this so i
think this is something i would love to
see in panama sites project is a way to
really do a lot of what we're doing
digitizing design in such manner so
against a plug for my own interest here
but linking it to google so in terms of
visualization let me show you that so
again visualization we have to use a
different tool so we juggle with five or
six different software and each chapter
actually is about 20-30 k so we have
only one software usually for the lab
and we have to share the machine where
the software is on because we just can't
afford them any machines with those
software but so metamorph what we do is
we just nuclear segmentation so we can
do and what I love about metamorph is
the interactive link between the data
and the images so for instance if you
can start getting your data so this is
the area of each nucleus in the
segmentation and they are visualized
here so you have a color system where
you can say well I want to look only at
the one about 100 they showing green the
100 are shown yellow I can get to the
last I want to only want to keep those
nuclei that are size between 100 and 250
and here it is and then after I can get
again out of that population I'm
interested to see which nuclei are
fairly Iran so then I go for the shape
factor so I go click here shape factor
and then i say i want to shape factor
that's above point 75 up to 1 and now I
get the more spherical nuclei this is
just an example of how you go through an
interactive but i think this feature is
really useful because it gives you a
handle in your data very quick and you
can design interactive mode between the
data and and the images and you can
really tune it and that's where you use
the best of both world use the best of
the human because the human is so good
at asking question that extracting
pattern and the computer is extremely
good at giving it to the person so if
you have that nice
dialogue between the machine on the
human it it becomes very powerful now
one thing I didn't tell you yet is those
images actually three-dimensional images
so there's multiple slices and so if we
zoom on one of those nucleus this is
what actually what it looks like so
again that nucleus got travers by
actually got two tracks well i would say
at least one track here so that was one
damaged we're looking at two different
DNA damage protein so red and green are
two different ones that's why you have a
yellow color and then that's the way we
visualize 3d images we have the little
cursor that you can move back and forth
and here i basically section the nucleus
about that point so that's the XY view
that's the YZ and that's the XZ and then
I can so that's bit princess different
software again bit plan can do very cool
stuff like I can do a maximum projection
by simply moving those two lines here if
I expand them I can actually now do a
maximum projection on my XY view so if
you go back and forth you can see how
this guy now shows up here so there was
another track he actually ok so it's a
way to visualize data it's pretty nice
and and visit the data so all the way to
deal with those derailleurs to actually
do volume rendering Lorimer during makes
pretty images but it's only useful if
you can really play with the system and
zoom in and out so you can do I so
surfacing and actually extract those
spots using different color spheres and
you can make movies out of that so so
that's the same thing now and she wants
to work I guess
hmm
I'm sorry about that i think i'll pass
on on this one
all right let's try again
okay let's go so anyway so what's the
volume rendering of this and how you can
rejoice m data so the last thing I want
to talk about tools is pattern
recognition that's something we're just
trying to get into if you see here
there's a three different nuclei and
radiation tends to induce a change in
the nucleus nuclear structure we don't
really understand it yet well but you
can do it with different things like if
you put salt in the media instead so if
you put the cells on the different so
there's an automatic reaction and you
can basically under high soil condition
you actually condense the new crews it
will lose its water and I will look like
that are under hypotonic solution which
is if you remove the salt in the media
the cells going to start swelling and is
going to look more like this and that's
no more looking nucleus and so we wanted
to see if we could just by simply
looking the signature of intensity see
difference and actually we will be
disappointed to see that only the hyper
tunic tend to stand out if once you have
normalized the intensity which you have
to do you are normalized for the
violence and the end I mean you're going
to see actual you two peaks for those
guys for the opportunity but the I pool
and the normal really you can't separate
them anymore so even though they are
different so clearly this a new project
we're not sure how far we going to go
with that but obviously we're going to
have to do in this that's what we've
been talking about is doing with PC
analysis and using multiple features and
only intensity but also size and shape
of the nucleus would be another feature
that could be used to separate them so
anyway so I wanted to cover all this now
we're going to move to NASA project so I
wanted to give you an overall view of
the of the technology first and so
hopefully this will work so NASA is
interested in the effect of cosmic
vision human and the reason is so
interested is that in animation you can
see those solar particle actually they
are protons and hitting the the magnetic
field of the earth and actually what's
interesting is the Earth's actually tiny
thing here what happened is the earth of
that incredible magnetic field is really
weak but it has a huge range and because
of that we don't see any of those park
on earth so the things enjoyed I'll just
show you we don't have them on earth we
and so we have no data whatsoever on the
effect of those particles on human
because we never got hit by them
we have a lot of exposure to photons
well you know the atomic bomb was many
photons and neutrons but nothing on
cosmic ray they don't come here so
because of that beautiful magnetic
protection so you can imagine the we
working for the Mars the mission to Mars
on the mission to Mars they're going to
have to leave this nice protected area
and even yes turn right now working in
orbits they don't get damaged compared
to what they will get once they get out
and go to Mars they're going to receive
a huge amount of those rays and the
proton is a predominant particle in
space but it's not such it's not the
most dangerous when the most dangerous
one is iron and iron is produced by
supernovae and the supernova proof so
much of that that you see a lot of those
particle heating the human when they go
on the mission to Mars so we were
interested in in studying the effect of
iron particles on human and so we do to
get where do you get cosmic radiation on
earth well you got to go to an
accelerator and not mini Exeter can
produce the type of energy use in space
so we go to Brookhaven National Lab in
New York that's the alternate
synchrotron and basically nASA has built
an extraction beam line which is shown
here and then what we do is we're going
to in the beam so this is the control
system this is a whole key system with I
recognitions that when we go in the beam
we can't get shot I've been better we go
in the cave that's the cave the beam
comes from here those are our detectors
so we put a bunch of different detectors
to quantified in one of a of a floor
affluence of particle going through the
specimen the specimen is throwing an
incubator so you can stay nice and warm
and then you get an image like this so
those sales human cells again got
travers by tracks and the first thing we
did is we wanted to actually notify the
track so what we did is initially we
develop particularly where you can
roughly drawn an image very quickly the
nuclear you want to study and say okay
the tracks went through here here and
here and then we find a search and the
computer comes back with track addiction
so the way we've done that to give you
an idea is the following it's a very
simple idea we do some projection of the
specimen so index in this case the gray
matter to show you if you project it in
nangal that is not along the track
you're going to get a profile that looks
like this you get a few peaks
corresponding to some of those parts but
overall you get a you know kind of a so
so proud a profile now if you hit it
right right on the angle and so I forgot
to mention something our beam is always
parallel so when we expose the specimen
all the particles are going straight and
this so heavy and so fast their beta is
point nine seven which means they very
close to the speed of light and so they
take about 12 centimeter to stop so they
go through our specimen without any
interruption they just and if you get
travers by then they will basically
purse you right through you won't even
you don't you don't sense anything they
is so small but they are parallel so one
thing that's good about our specimen is
we know we're looking for power lines so
by doing that when you do some
projection when you hit the right spot
you're going to see the only a few pick
and they're going to be very high pick
and again if you use another angle even
in this case where you have those two
guys you're going to get a peek but the
pig will never compete with the right
track so by doing that all we do is we
do those different projections and keep
the projection that gave us the minimum
number of peaks and the highest peaks
and once you have that you can look at
the center and project them back on the
angles and you have the track so that's
how we generated those guys so using
those tracks we had a great so I'm a
physicist by training so I really wanted
to extract something more interesting in
the data so once questioned there's a
lot of controversy about those proteins
were using to recognize those DNA damage
people say they are DNA in a managed and
not DNA damage the more complex so one
thing we said is like wow one thing we
know for sure is that at the moment of
the damage we know exactly by the
physics what is what should happen and
what should happen is the following if
you get a track here you're going to get
a DNA profile that's the blue color is
the DNA so you see you know this more
DNA here there's less DNA here and
basically what you expect to see is on
average break should happen where
there's more DNA it's a trivial
statement if I take it to the extreme no
DNA no damage you can have a DNA damage
if there's no DNA so in actually do the
physics it's very simple it's
proportional is directly proportional to
the amount of DNA so knowing that what
we said is that what you expect to see
on each track if I get a DNA profile I
can actually
and I'm told here in this DNA profile
they were for damages I can take them
and run Omni distribute them on the
track on the profile and if we do that
many times it's a multi-car approach if
you do that many times you throw them
randomly following that profile you
should generate an average DNA damage
profile that matches what you expect
from the physics and we did that using
all that tool and we did that we got
those results the blue curve is that is
the distance distribution of those four
sides so if you look at a track that's
different for sy and we're looking at
the distance between each for sy and
we're generating those distribution what
we see is the blue curve is what we
measure and now what we measure if we do
the randomization is a Poisson
distribution it's the person is cut here
because a microscope hasn't we losing
the resolution here so we can't get the
tell the person because we don't have
infinite resolution but that's fine we
still get the personal shape when we get
more like a kind of a Gaussian type of
thing here and the big difference is the
predominant the most favorable distance
between two force I theoretically should
be you know points point 3 micron and
actually measuring 1 point 2 micron so
what we're seeing is that those DNA
damage protein that were using then not
the DNA damage are not where they should
be they have moved and they're moving a
very interesting way this seems to have
excluding each other you don't see that
many clothes by DNA damage and this is
getting worth 35 minutes
post-irradiation so that was a big red
flag when I presented this first in the
community they were like no way it's an
artifact in imaging and okay so we had
to convince them something was really
going on and so we really said well we
have in creation from randomness and
there's an exclusion of clothes by force
I so where are they so I kept going on
this one and NASA I gave me a green
light to keep going on this one so I
went on and I'd say okay can we can we
find out where they are and we came up
again with a again very simple imaging
tool what we did is I said in the image
i can see that the break seems to be
where there's less DNA which is contrary
to this should be where there's more
than able in in fact in the images
visually I would see that so I said okay
we're going to measure it the way we
measure it is this is a car
well this is a real nucleus image but
those little red dots I place them just
to illustrate the point and if you put
those dots in a high DNA density region
versus a load in an estrogen can I
measure it in a quantitative manner and
the way you do that is simply by looking
at the sum of those signal at those
location normalize by the mean of the of
the signal over the whole new cruise and
when you do that when in a bright region
you above one when you'd imagine you
under one now the other thing we notice
is that a lot of those breaks we're seem
to place themselves between the bright
region and the Dean region interesting
so for that we took the gradient of the
DNA which gives you those kind of
looking new brand looking like images
and actually what you see that the
interface here has a high gradient okay
it's classic the the gradient will
actually have we will be bright where
you have a change of intensity and if
you do the same type of computation now
you'll see a value above one when you
are on those edges so you think of those
two parameters our DNA and our gradient
we went back to the images over that
huge data set here we're dealing with I
think about 400 gigs of data right there
summarizing that one graph so the five
year is the number of experiment want to
brookhaven to repeat so those are repeat
what you see is within the first 30
minutes after radiation you have our
gradient that's above one and our Dean
has below one which tells you that
basically those bricks are happening not
what you expect because what you expect
is that graze on here so they have the
gray zone but on top of that we we
created a signature where they are
happening and basically if you see that
slice here and that track if I do a
topographic map for the data for the
nucleus you see those basically the
higher the more DNA and then those
valleys is where there's less DNA what
you see is love those breaks a key are
in the valleys where there's no DNA or
very old in it and top of that what's
interesting is those brakes are those at
the interface between the high scope of
those profile you know this is just
visual of those just to get an idea what
it means and so the concrete we publish
that in plus which is a fairly good
journal and and what we concluded was
that basically DNA damage
are processed in some very specific
region of the nucleus and that's never
been shown in human and the imaging and
the modeling was the key to come up with
that it's still controversy people still
believe that this gotta be an expression
to our data but now it's out there that
we have at least release only yeast has
been shown right now to be able to when
you have a damaged the yeast will
actually cluster the damage into one
place and repair and that's a big deal
for NASA because if there is really
damage is being collected in one place
for gamma exposure when you get those of
gamma for instance you get breaks a bit
everywhere the kind of parsed so they
will probably get repairing individual
repair center when you get a highly
t-track like that I mean a cosmic ray I
love the a lot of the damage like close
by so they're going to end up being
close to each other and actually be
repaired together and guess what
happened then what happened is that the
DNA gets confusing when you repair DNA
you start putting one chromosome with
another one's called translocation and
that's a precursor for cancer maybe
that's the expansion why iron is so
carcinogenic because we know on mice
studies that when you get exposed to
iron you get a 40 fold increase in
cancer versus other type of radiation so
it is ongoing debate and we're still
working on this but one thing to solve
the debate was to actually go for life's
imaging so now we're moving to four
dimensional images we have ways now
using a green so people have extracted
from jellyfish the fluorescent protein
that is first entering the jellyfish has
been extracted and now we can encode it
into a cell and we can make the cell
fluorescent so we did here we took the
protein of interest that was the DNA
damage protein and we refused it to the
person the DNA damage protein and women
movies out of them so we we go that's
New Haven again that's our microscope
that's think you better will keep the
cells and we image them here let's type
of slide we're using so the specimen are
in there and then I hope this is going
to work
let me see I really like to show you
that one but if the computers on one let
me see
that p unregister
I know why I did that anyway that's a
nucleus after radiation and it's moving
so the first thing we have to do is
register the image so the way we do that
well for time purposes unless you
interested I will pass on the the
registration is done active through a
third party software that we got on
matlab so i don't have much to say
anyone this but once you have registered
the image is gonna ask me again for the
direction so bear with me that one is
that p register
so after registration that's what it
looks like and so what I do to give you
an idea of volume is we are under bit
plain we can rotate as we play the movie
so now there's no more movement ok so
you rigid is a 3d registration which is
kind of a heavy on the computer and so
now for saira edge but
alright so now what you see is actually
DNA damage movement so this was kind of
the key for us we haven't published this
yet is coming out because we want to do
more experiment but basically what about
requesting that was impossible is
happening which is that they are really
moving we're not really sure exactly
where why and that's what's going on
right now in terms of the project but
what's really remarkable is that
everything started with fixed specimen
and using the heavy duty imaging
processing and all these quantification
came up with this and then we went back
and we could justify enough to get more
money to do this study on the lifestyle
which so much more costly to these these
studies so I think again and here this
is a plug to go again but youtube for
instance has the movie compression
serving online system which is I think
very useful for those four dimensional
images and i'm going to show you i would
deal with the third dimension the Z but
usually a maximum projection is the way
you do it do maximum maximum projection
you get a 2d movie that weight so
there's ways or you do volume rendering
so that's what I was trying to show you
the type of what it looks like on this
on the commercial package we use right
now this is the type of images we get
and I think again this would be nice to
intervene palimpsest eventually if we
want to look at those data so to last
slide basically one thing I think also
that links nice to Google is and that's
really more in the future i think but
one thing we do on the microscopy is we
can acquire the low magnification a
specimen and then really the specimen at
a high mag and that's very useful to get
an idea what you're dealing with and
then pinpoint towards region of interest
so what we can do is we can actually
store those large low magnification
images on the server and I three we are
able to pull out from the freezer the
specimen put it back on the microscope
we can home the stage and can basically
with the coordinates I can go back to
the same specimen and if I'm given the
coordinates I can go and reimage this
exactly the same way so with that in
mind I think would be amazing to
actually have some type of low
magnification storage of specimen have
people barges go on their computer visit
the specimen and then ask okay I want to
go back
and pinpoint region of interest where
you go back now I do a high mag and if
if I show you that so again those are
human breast cells so the project the
reason why lbnl has been selected by
nasa to those studies because lbnl is
expert in growing human breast cells and
not only we grow them on a dish we can
grow them in a gelatin-like and so what
happened is when we do that we can grow
the cells and they make those aggregates
and those aggregates are like mini
breast duct and actually if we give them
hormones they would secret milk human
milk so there are so as far as we're
concerned us the best in vitro system
for humans to the radiation because
we're looking at a functional organ a
mini organ in a gelatin that actually
works exactly like the breast just add a
smaller scale so this is the reason wine
as I was so into having albina working
on this because we've been using this
type of system now if we focus just on
the imaging part those big bloody are
like mini mini cells and inside the
blood days milk but we can do is people
are interesting those features here
those kind of like branching so that's a
low mag image 10 x I can go on the
computer and visit that image and this
is actually the montage if I pull out
the full resolution of that image on 10x
this is what I get but now what we did
I've in the coordinate I went back to
the specimen that was in the freezer
take it out of freezer and I say okay I
want a 40x image in this region this is
what you get so again really there's a
lot of things that still out there that
still not done and I think that the
central committee will benefit a lot by
some type of collaboration and I want
you to conclude on I think we need to
integrate better acquisition data
storage and that's the reason why we so
interesting Panem sets also the one
thing to remember is that the storage
solution should all stay ventually good
visual sorting and organizing
capabilities and I think this is what
Google is really expert in in all those
levels so visualize fact the images
might be the one thing that google is
not so expert in it's kind of a special
feature the basic tools registration
segmentation I am pretty sure you have
better tools and we have interactive
link i think i hope i convinced rates
vary
wait to go back and forth with your data
now one of the annoying feature is a
fighter's multiple format they're not
very hard some of them are actually you
would need agreement we need a with
special agreement with the company to
let us access to data its non NDA we
have to sign those things so i'm not
sure exactly i would work but anyway
multiple microscope format is actually a
problem right now and obviously the one
thing that you really need is the
metadata in the so that you can parse
and actually generate on the flag graph
like i show you so kind of like data
spaces you were mentioning this is where
it would fit nicely and i think one
place where everything is done would be
great and to give you an idea what i
show you today was made with five
different software it's not as smooth as
it look like and it's actually one of
our expertise is to know what tools is
out there and what we can use and so of
course expanding our tool kit would be
great the software i very closely and
and also when we go from software
software there's no api whatsoever
except for bid plan where we they
created a plug for matlab which is great
so we can call the function and actually
have them talk to each other except for
that one software the rest is you're on
your own you go visual basic or you go
with some type of macro usually it's
more macro and no api so once you leave
the software is saved under their format
and then you go to rebate it into
another so you duplicate data left on
the right it gets really when you have
gigs of delights it's really annoying so
again a place where everything is would
be the ideal situation and I management
the chair of the inner core project
nastas picture art center research dr.
barliss off those are my collaborator
and NASA Francisco not exactly the
director of the of the project is the
one funding all the different projects
and is very interesting our data because
he's doing a lot of risk modeling so is
using our data to do risk modeling and
people at lbnl and if you have questions
or want to talk more be glad to talk to
you
cattle they knew
variation of the time
he had two older
situation is safe
so the question is if the imaging looks
different how we deal with it
you want to take a guess for details
North we do we actually so we actually
stole all of them and we usually have a
time course that goes from zero minutes
three minutes to the first hour is
fairly well covered we're about five
minutes ten minutes 20 minutes 30
minutes Hannah 45 minutes one hour and
then as we go further in we start
changing the scale and we go up to 48
hours and then for other SI then we have
different questions because the looking
at DNA damage they are all gone by 48
hours they have been repaired to destroy
the cells have died there's a process
co-op of ptosis for the selbst actually
kill itself if it's healthy so but we
store everything so this is actually
what Panem sets is going to be storing
is all those data so we could go back
and do the real primary now is we don't
have the manpower to we store all those
data but we only can look at specific
endpoint and and and I don't certain
limited and we have limitation what we
can look at so if you could come back
and say you know why we should look at
this then it's really hard for us to
restart everything you got to pull out
the nuclear segmentation again and and
because it's not a usually are
eventually our data archive so you got
to pull them out of the archive and few
things like this that makes it did
answer your question no yeah
what in terms of data right now so we
have generated about a terabyte so it's
and a lot of it is duplication from all
those processing so and I think I'm
palimpsest what we plan to put more is
like 2 or 300 gigs I think the lifetime
aging actually takes a lot of memory
because now you look at it if you do
this tag over time it gets it gets
really bad quickly
another question no
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>