<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introduction to MacLibre and OpenTouch | Coder Coacher - Coaching Coders</title><meta content="Introduction to MacLibre and OpenTouch - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Introduction to MacLibre and OpenTouch</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EeTQtF5qqvQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome everyone I'm Peggy and I'm happy
to introduce how well he's been Summer
of Code students for two summers in a
row two thousand six and two thousand
seven working on my flavor and open
touch we had the opportunity to host him
back in Europe in Hamburg during last
fall actually yeah and now I happy to
have any amount of you to give a bit
more detail of his project so everyone
welcome hello thank you very much i'm
really glad i can see you here so today
i will give you just a short
demonstration of the mock libra project
and the open touch project might both
google Summer of Code code project but
before I start I would like you to give
you just a short view at the city I came
from it's called broad swath it's
actually I'm from Poland and yeah
there's a lot of really nice places you
can go and the city just it's the
fastest growing city in Poland actually
and there's a lot going on even that
today and during during the night
there's a lot of events out there so if
you ever gonna have a / to 'not e to be
in poland just try try to be in inverse
with sake now and so I'm from Brussels
university of technology I'm studying
computer science out there at the
Faculty of electronics so this building
is pretty nice looks like cheese with
this little hole yeah so just to give
you some quick look wife where I'm from
and where I'm studying so today I'll be
talking about two projects first the
McCleary one I was doing during the
google summer of code 2006 and then the
open touch which is right now just like
in design phase because i will be doing
this
during this this summer in 2007 so just
a quick agenda first I will talk about
Mach Libre what is Mac Libre how does it
work what can we install with it some i
will show you some screenshots and and i
will talk about future work and then i
will switch to open touch i'll think
about multi-touch screens what is it how
multi-touch screen works and i will show
you my hard work prototype of one of
these screens and then i will go through
some available software that's available
to work with this kind of devices and
then i will describe open touch concept
and in the modules inside i'll show you
some basic guesstures and my range of
duties for the google summer of code
because open that is a really really big
project so i won't be able to do all the
work during only the summer but I picked
up some some of the some of the modules
i will be working on so yeah let's start
with mock libre Soumik Libra is a new
way of open source software distribution
and Mac OS X it was started at google
Summer of Code 2005 by Francois perch F
for hoops working for win Libra
mentoring an organization and I was
working at Mike libera tu ab google
summer of code 2006 so I did some bug
fixes and doing improvements and I bring
my cleaver up to date so actually what
my clipper is so my clipper is an
open-source software distribution for
mac OS x it's simple supposed to be
simple intuitive with application that
you really need so it's just a selection
of applications so our main goal was the
simplicity that's just like just like
Albert Einstein said make everything as
simple as possible but not simpler so we
kind of decided to go that way
so it's a software installer which
supports the dmg images and the zip
files there's a lot we can write your
own container for other formats but
actually we're we're just thinking about
only about binaries just to have some
sort of package management only on
banaras we don't want to go to source
code and to all this compile compilation
process so the application is looking
for the app folder inside of the dmg
image or zip files and based on that it
just copies and the packages he
downloads to the application folder
there's also our other distribution
generator so you can make your own mac
liberal distributions let's say games
Libre or office liberal or whatever you
want to call it it's just like set of
applications you want to distribute and
you can have offline distribution or
online distribution and with Oakland
distribution you have everything inside
your dmg image before or with online
distributions you do the xml file with
package descriptions is downloaded from
from the server and based on that based
on XML parsing and we we have we build
both a package tree and you can choose
whatever their whatever software you
want to install so this is this is a
simple how does the xml file looks like
so after the loaded there's a
distribution inside we have category so
it's at least one by the distribution
there is then there is a package of
course at least one description inside
and homepage of the package and
installation tag file and dependents for
the optional as an option i will show
you some basic it's
it's the old cyberduck but you can have
a view how does it look like so this is
a description homepage installation size
on the disk the md5 sum and we can say
that for example this version is only
for the mac OS x let's say 10 39 or and
this one starts from 10 30 to 10 38 and
based on that we built this package tree
so you can choose whatever you want to
install so what kind of applications we
can use to well a lot of applications
that are open source application that on
Mac for example Firefox blender adium
Thunderbird of Vienna I RSS reader
fallen see I term and player yeah so we
are working on just the various
selection of applications we don't want
to give user a lot of applications
because he can it will complicate his
decision about choosing the right
application who want so some quick
screenshots so this is the installation
process and that's how the mock Libra
the first screen looks like and you
choose choose the packages from the tree
actually the application is written and
VX pytam not in pure objective-c then
you confirm your selection you can have
a break for coffee or something it
didn't while it downloads all the
packages and at the end you have the
summary which part which applications
have been successfully installed and
which not and why why not
and yeah that that's tea it's the
application so right now what we are
working on is some translation internet
internet signalization I'm working on
the Polish version one guy is working on
the Spanish version is also my mentor
was it was from France so he will do
working on the France translation yeah
that's that translation part what we are
also working on is to create apps
updates notification using grow so we
can inform user about some new updates
on the application he just installed
we're thinking about integration with
spotlight to create a plugin for
spotlight so you can type in some
application that is in muck lib regions
and just press ENTER and install it
without any problems we want to
implement the sparkle software updates
so the update will be really easy to the
new mac liberal version and right now we
have to prepare those xml files alone
just by my side have to do it by myself
but we want to create automatic apps
update tool so we can i update the mac
lyrics mfi really fast using some for
example the data from version tracker or
mac update and we are also think about
admin and maintenance tool for Mike
Libre so we can do some fast editing of
this installation XML file and the last
thing what I just came up with a mock
libera file system using Mac fuse which
well it's just in my head right now but
what I wanted to do is to create sort of
package distribution in your file system
so you can go in Mike Libra folder and
have all this packages sorted by by
category and just by copying the file on
your to your application folder you can
have the
if you it's just installation process so
yeah I think that will be nice but it's
still work in progress and just it's
still in in my head yeah so that's just
a quick overview of the mac liberal
project and now I would like to switch
to the open touch which is which
supposed to the open source framework
for multimodal input devices it's like I
said it's a it's in design phase i will
probably start working around the code
in about two or three weeks it's a
project for google Summer of Code 2007
also for foreign librium and tarragon
organization it's more complicated I
will start with what actually the
multimodal devices and how the
multimodal interaction is described so
the multimodal interaction provides the
user with multiplied modes of
interfacing with system beyond just the
traditional the traditional keyboard and
the mouse for example the example device
might be I don't know how many of you
are familiar with the multi-touch
screens but this is just an example
device that can be used as a multi-model
device and that's what I want to use for
the open touch right now so using the Oh
multi touch sensing we are able to
invent actually the new new kind of user
interface new user interaction
techniques and yep and for the
multi-touch screen what it's actually is
the history it's like in 1990s there
were some design of multi-touch screens
but actually the CPU was so slow so the
image it's also it's mostly based on
image processing and the image
processing was really slow on the
processors out in 1990s so there's only
a touchscreen with the single point of
contact and right now we have a lot of
different devices for multiply of
contact which is a multi-touch screen
and though there was this researcher at
the new york university jeff han who
presented in 2005 multi-touch screen
based on FDI our technique which stands
for frustrated total internal reflection
and I'm doing my prototype based on this
technique which is really simple I will
show you in a minute how does it work of
course there are other techniques for
example iphone is using different
technique there's a react table and of
course just release the microsoft
surface which also is based on some
infrared cameras and the image
processing so how the multi-touch screen
really works so we have a hand we touch
the screen and we can have a multiply
points of contact so let's say we have a
piece of acrylic and some infrared LEDs
and we kind of delight from infrared
that shines into the acrylic and the
light inside just bounce bounce inside
and whenever you touch the screen and
the light is reflected and there's a we
have a ir camera which has a pass filter
for the visible light so the camera only
sees the infrared light we have a
projector which shows that our
application on the acrylic and light
from the fingers girls just to as a
input to the ire camera and as you can
see on the image from the IR camera I've
done lived in this computer we see some
light will light blobs and using image
processing we can have the exact
coordinates of those out of fingers and
based on down we can do other stuff that
will describe later so my prototype I
just start with some lads
then some testing this is just the ire
camera without the visible light filter
but you can see those really light blobs
there are some lads at the top and yeah
when you touch the screen yarra tourism
input 40 camera then I created some
aluminium frame and some circuit to make
it look better and it looks right now it
looks similar this is just a screen with
with the lads and of course it's not all
because we need the infrared camera we
need the project or right now I'm using
some mirror to get clean clean image on
the on the on the multi-touch screen and
so this is my work this is a work in
progress but actually that's how it
looks like right now now it shows
youtube video there so of course it's
not just hardware you really have to use
you need some kind of a software to and
control this kind of devices so there
are some there are some project that are
available right now so you can use with
this kind of application with this kind
of hardware the mode the most popular
one is called touch sleep which was
written by one guy from New York his
co-founder of natural user interface
group which is community behind all the
multi-touch technology and he wrote this
application about a year ago and that's
the most popular one and a lot of
students that are doing their own
multi-touch screens use it and there are
also some other like a processing
environment
with additional blob detection library
and there's a vvvv with blob detection
fetch disorder the project that you can
use for some simple blob detection there
is this reactivision which is used with
react table in interactive table this is
open source project it's not actually a
blob detection but it might be used for
for multi-touch screens and there is
opencv library and which was released by
Intel couple years a couple years ago
it's the open computer vision library
they have blood extraction library which
allows to extract plops from from the
input image so this is what we can use
right now and my goal is to create a new
project will which will looks like this
so we have a multi-model input device on
the bottom we get an input input image
and input device sense video to the end
track module and interact turns video
stream into blob coordinates and send
sends them to aunt core module and
anchor converts the packets from the
those data structures to the OS OSC
protocol oh POS SI stands for open sound
control which is a protocol message
based protocol you it uses UDP for
sending packets and then uncle n core
calculates war such as pressure distance
and passes this to the gesture or passes
input data straight to some client
applications if it is not a gas sure
such as X or in grid coordinates then
the N gesture receives data and runs
gesture detection algorithm
and the end guest your actions or
performed via for example Java Virtual
Machine sockets or inter process
communication or avt robot or any other
specified API and so an guest is
actually a library called from within
the end core and this allows us for
extending an gesture into internal
applications allowing for different
deemed email applications to have
different gestures setups so we can have
we can use and gastro with the external
applications like for example Google
Earth to do some zooming like like this
or some out or we can create our own
internal applications for example some
image gallery when you can move objects
around and I also do some zooming or
some other type of guesstures so I'll go
through all those modules so the a
tracking module which is called n track
and this is a basic image processing
techniques are performed on this Cameron
in output to identify the points of
contact and the computer vision
techniques are used to interpret the
motion of contact points as discrete
touches or strokes so an tracker will be
responsible for tracking multiply input
and we will do the blob detection and
tracking this is what I gonna do for the
google Summer of Code right now but the
end track also will be doing motion
detection and tracking so we can and
like to development it will allow us to
create sensitive or interactive floors
so you can go through and there is some
water effect or something like that and
also if we will have fiducial the
fiducial detection and tracking and in
this module we have input device
calibration second module yen core
module is in charge of the framework
comments and settings the
is of course includes calibration
settings also guess your module settings
chosen method of communication with
internal and external applications it
also does some blob data processing some
calculations of the dose vars like
pressure yeah like pressure velocity
sighs distance acceleration in this
module we'll have a framework
configuration and settings and the OSC
packet management which is the open
sound sound to control protocol
management we will use we can use a pure
OSC protocol or there is also a protocol
on top of the OST which is to we oh and
this is all for a tangible user
interfaces and actually for this it's
used for the reactable I was talking
about before so we can use both of them
at the plant and then there is G and gas
sure module and we'll manage gastric
conversion and recognition from a stream
of data from the OSC messages from n
core for example gesture recognition
would based on the shape comparison and
certain vector changes and so using the
vector of two coordinates of the same
finger between couple frames will be
able to determine exact location and
moving path of the finger so what I want
to do and gas sure I would like to
implement a single point gestures a move
multiply points gesture sort of mouse
gesture but using your own fingers and
the emoji will be also responsible for
guest your actions happening and
forwarding to the internal applications
and external
vacations and basic gestures let's start
with the rotating objects we can do
rotation using one finger stationary and
the other people that pivots around just
like that we can also do do it with two
fingers that people around there at the
center of the gravity just like say like
that and we can move objects using one
finger we can move using two fingers it
just all depends on the configuration we
can select one object or we can select
multiply objects we can draw draw a
shape around some objects to select them
we can toggle giminy somehow we have
neither we need a gastro to toggle the
many even the system mini and of course
there's a lot more guesstures for
example zoom in and zoom out using two
fingers just like intuitive just like on
iphone using to those two fingers to
together zoom in or zoom out so for my
google summer of code because the open
touch like is like i just said it's
really huge project and this is the my
range of duties i will be doing for this
year google Summer of Code so what I
want to do is I would like to do an
image as position from Eire camera then
I would like to work on blob detection
and tracking using a blob there's a blob
detection library written in Java so I
might use that but I also found a really
good paper about lining linear time
component labeling outgrowth using the
contour tracing technique so it'll will
all depends on the blob detection result
and if that goes okay I will probably
use blob detection but I might implement
both then I will do some image filter to
get
background separation so I can get a
clean image of the fingers of the blobs
then of course there's the OS OSC
management there's a lot of Java open
source libraries that implements all
open sound control protocol and then I
will do framework configuration and the
input input of the camera and video
samples and calibration of the of the
screen which not it's not so easy then
of course the blob data processing to
get those pressure wars the velocity the
extra grid coordinates and do the
forwarding over the US OSC protocol and
some basic gesture recognition based on
those data that I got from the anchor
module and of course that's all behind
that we we won't see that so we need
some sort of demo application for
example a simple image gallery so we can
show show you
how does it look how the gasser works
how the how the blob detection works so
we need this demo application now will
try to to do a simple image gallery
which shows all the all the koechers and
and how the hope in touch framework
works so you some couple couple links
for you so Mike Libre web web page
mccleary com the open touch web page
which is on my to-do list it's not yet I
just got the the domain but the open
touch project will be at the open touch
that info and the natural user interface
group at the WWE group com this is this
community I was talking about community
around the multi-touch screens and multi
touch sensing techniques and there is
also my my mock liberal summer of code
2006 proposal and the open touch boo
Summer of Code 2007 proposal at my at my
blog and PDF format so thank you very
much for attention any questions
well not yet yeah i was thinking about
it but right now i support just a red
install so you can reinstall application
with when you when you have a new
version but yeah that would be a good
good feature well it's supposed to be
simple like try to have a normal user
and tell him to install thing you'll be
like that's could you install it for me
because it's it's really complicated and
what I wanted to do is just a simple
intuitive application for know normal
regular user Mac users so they can
really fast installing a new a new
software yeah but i think i will go the
you know the muck muck libre FS way so
we can use the mac fuse and that would
be really cool any other questions ok
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>