<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Re-Configurable EXASCALE Computing | Coder Coacher - Coaching Coders</title><meta content="Re-Configurable EXASCALE Computing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Re-Configurable EXASCALE Computing</b></h2><h5 class="post__date">2011-02-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zTr4bepr5Xc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm pleased to introduce our guest today
Steve Wallach has been involved in in
computing from from many computers to
super computers for a long time he
started in the in the 70s working on
native generals MV 8000 one of the
architects of that system which which
has the distinction as far as i know of
being the only computer development that
was the subject of a fairly well selling
book in the general market that even won
a pulitzer prize he went from there be a
little detour to found convex computers
which which was probably the worst first
of many super computer companies and
were the first far as I know the only
really successful one it eventually sold
out to HP where he stayed for a little
while he's been through a couple of
ventures since then and about three
years ago started conveyed computer
which was was sort of in response to DoD
do ii studies of exascale computing and
various things there which will hear a
little bit about today he's one he has
won a number of awards and other honors
the most recent of which is the 2008 I
see mark gray award for innovation in
high-performance computing and today
we'll he's going to talk about exascale
computing and things related to that
Hell's Gate thank you I like to keep my
presentations is interactive I realized
usually you have questions at the end
but if someone believes they have a
question or a critique and one would
like to start a discussion or debate
after slide to gopher hey so acknowledge
when I did this and I also work with
someone who now works at a oak region as
you can see we were perhaps overzealous
what we did so I'm going to discuss
first hpc software and then how that
leads exascale computing up the old
times we were told beware of Greeks
bearing gifts remember that well today
in today's world we can contemporize it
is beware of geeks bearing gifts and
what I mean by that is most of the world
in high-performance computing has been
very floating-point intensive working
with Fortran and C etc but today the HPC
world is now moving to what people
calling data intensive and
data-intensive is very different one you
cannot have any floating point or
minimal secondly the paradigms are very
different than the classic hpc and i'm
not sure when this is good or bad for
general HBC because all the people will
be thinking about solvers and
floating-point are now thinking more
about how do i do graphs how do i do
multi threading and everything else and
we'll see that a little bit later so
what problems are we trying to solve you
can see what they are the major thing is
you need processor performance is
leveling clock cycles are kind of
constant so how do we get more
performance obviously is through various
levels of parallelism as a parallel
processing multi-threading to me this is
deja vu and based on the audience maybe
fight people the London no yogi berra
was to Yogi Berra is credited with
saying it's deja vu basically the same
problems we're trying to solve today
people who try to solve in the early 80s
except this with the backs how do I make
a vax went faster
as to how do I make an x86 run faster
well how do I make it on 150 and what
we've seen is the more performance so
people look at GPUs they used to look at
IBM cell fpgas so we basically have is
heterogeneous computing again and some
of the reasons that they both succeeded
and failed in nineteen eighty people
were not old enough a fall into the same
traps again as they did 30 years ago
discuss some of them current languages
Fortran C I was telling Jim how many
people here under 40 I've ever
programmed in Fortran 11 and a half okay
I prove my play today we're going to
check driver's licenses afterward the
plate here is Fortran which is still in
many cases to standard especially for
oath older code for scientific is not
basically taught anymore in school
compilers and many cases enough newer
compiles are not dealing with more trick
always laugh a lot of code that's
written in Fortran but of course today
we have C C++ until the Z star or a
c-sharp is Microsoft stream cupc etc but
we have a bump in a row the standard hpc
benchmark is matrix multiplying any
machine the first thing you test with a
vectorizing compiler or whatever is how
well do you do on matrix multiply so
this is an example of programming in
CUDA which is a language developed by
Nvidia to do high performance computing
so this is an example of programming of
Fortran generating cuda and what is four
lines of fortran because it's an
attached processor you have to move the
data back and forth you have to do
mallets you have to create explicit
thready
etc this is for a simple program you
know if you have 50 thousand lines of
code it's basically impossible to do
this so as a way of perhaps showing my
distaste for this I developed the term
point a graphic program you can't define
it but you know when you see it and
Cooter's is an example of that for me so
this is something from a colleague at
Los Alamos gave me permission to use
this the slightest presentation as you
can see there are three people getting
to the end of the hurdles and one person
who's tripped over every hurdle so he
says buying the accelerator so that's
the accelerator now it goes find the
programmer that's the program so there's
always a trade-off between programmer
productivity and cpu performance and the
question everyone has to ask is where do
they want to be in that trailer as
computers get cheaper and cheaper and
people get more expensive either to hire
or productivity you really want to
emphasize more computer user cycles not
computer sciencecomputer cycle is
becoming throwaways so what's the
program today of course we've moved the
way we just don't have Fortran and C we
have Java JavaScript service side things
you all know and the reason I had
tongue-in-cheek beware the geeks bearing
gifts as a colleague found from this
website the following chart of and you
know it statistics you can draw your own
conclusions that showed the language
that's on the fastest Rises of
city well the reason is simple I have an
iphone when I come out of college I want
to start a company into a nap program a
program something for an iphone or
android as opposed to anything else and
you can see the other languages so this
is the top 20 and what's interesting is
Natalie I were driving for like a lot is
a interpretive base matrix language and
you can see how it issues the bottom 44
and what's interesting is Kobol is
higher than Fortran so again you know
take these statistics with a grain of
salt but it shows you where the effort
isn't even RPG most people don't even
want RPG is it means report generator
for those who are old and would like to
know a piece of tribute
RPG was as I may infer cause but of the
point here is to see which languages
taken her face right but it makes sense
that languages like objective-c etc
would be on the rise were used in other
languages so here's another statement
about languages and then we'll move into
some hardware some of you I'm sure went
to UC Berkeley and they have had Kathy
elica as a teacher so she was out of a
keynote speaker at the shallows and some
years ago she put the slide on first
when vector machines working at peril
languages with lube annotations that
means ignore vector dependency then we
had simply machines we had to create new
languages then we had shared memory we
created new paradigms so at the end
clusters we created MTI so tan line is
we've been at the mercy of partner will
the architects listen now so my
colleague had a keep me from standing up
but if you were to let me stand up
loader said no and what this means is
when you design a computer system from
scratch you really like to have a cold
design weirdest offer when the people
here surprised to see we actually work
together a date of general and it pretty
much was a cold design and a network and
the reason it worked is one who was a
team of maybe 30 40 people we trusted
each other and we had a common objective
and goal in mind it was not an
adversarial relationship though other
people may try to make it that way um
and it worked out well so the key here
is sometimes when we do define new
languages we don't necessarily take into
account but the consequences on the
hardware that may run too slow or the
software may not be as resilient as we
would like because the hardware is not a
good match for the software so now we
get an exit scale the department of
energy i was at several workshops
created their view is they'd like to get
to exascale by the decade into the
decade 2020 and they have asked for
potentially a billion dollars to help
develop the new technology to do this so
my view is I'll do it for a lot less and
i'm going to show you my take on how to
do this and the key here is what's in a
lot of people is they believe to get a
nexus care they're going to have
1,000,000,000 independent thread so you
talk about embarrassing levels of
parallelism I think a billion is more
than embarrassing than what the right
adjective would be so part of their
summary is this says 29 theme they want
to peek up an XO flop it will consume 20
megawatts system memory will be 50
petabytes particular note is ten
teraflops and you
see all this oh but here's the his the
Gacha MTBF is 24 hours so
tongue-in-cheek they say reason has to
be so fastest so you have the answer
before it fails I'm sorry yeah well part
of the problem is when you run something
too sophisticated this it's not clear
you know when you get the wrong answer
other than running the problem three
times remember you have a billion
threads but it's that one application so
it's a time to solution of one
application that could take a billion
threads and that's a major part of the
research is how to building resiliency
for these applications so let me tell
you how I'm gonna approach this UC
Berkeley and actually i did is fighting
the penalty said you know something we
can take all these applications and put
them into 13 bins which we're going to
call a motif and his the URL of the pub
so they said it's finite state machines
come tutorial graph traversal structured
grid MapReduce etc that's the Rose the
columns are various applications speech
music games database and said rather
than just haphazardly design an
architect architectures which have very
application specific approaches and
contrary to what people may think rather
than a hundred different paradigms we
can reduce it to 13 that's pretty
significant because doing 13 paradigms
as opposed to 100 ism is a lot more
tenable so quite independently ie took
their chart and I know pattinson
reasonably well I said no you gotta
extend it to take your paradigms but
then it's what memory systems do you
need to get out to the performance so
certain applications like a structured
grid can deal with caches but draft
graph traversal generally doesn't want
it
because it's all over memory so there's
another third dimension if you will and
then of course you have compile of
complexity from single instruction
single data send mmv and a full custom
personality so if you really want to do
a good job at this this is this is you
know what I think is a reasonable
approach a lot of other people are she
had the same thing so how do we create
architectures to do this when to create
a full custom architecture could cost a
billion dollars in five years so what
happened is when I got involved as I
said I think I know how to do this it
here's what I did I started a company
convent the first company was convex you
know there's no greater let's take X go
to watch those certain former employees
had no should have been done Beck's go
on and on have fun with that the convex
environment was looks like this pretty
much a fruit so what we did is we
started out with the x86 is a and with
Intel's approval until to the best
reflect on our company we create
different what we call personalities
that look like extensions to the x86
architecture and this somewhat mutually
exclusive so we have instructions that
just helping data mining so what he
intrigued but you're not going to use
that for computational fluid dynamics
and things that the logical etc I'll
show you certain examples of this and
show you the performance you obtain so
what we did is we actually have our own
compilers which we generate the x86
instruction set and what we call the
custom is a and because we're shared
virtual memory unlike could be they go
back and forth its cache coherent
virtual memory no different than every
other mission ever it is
floating-point units etc this is what
we've been shipping this for 18 months
it's a to you box the bottom is a
standard Intel's on your server board
second box is a coprocessor with an
attachment on right now on front side
bus inside the way we get a lot of our
performance is we have a memory system
that doesn't use caches highly entally
memory system and it's 31 the prime
number 31 went way in to leave and the
reason is I got sick and tired of
recoding FFTs for power to and as I was
discussing other people most people
create a raise at 256 byte 256 byte 256
and those who have any experience making
the in dimension to the seven runs four
times faster and so we have a very high
bandwidth memory system i'll show you
some benchmarks and this is works the
cache coherent with the x86 member now
what we've done to help people develop
their instruction sets with some of our
customers or we've done this ourselves
we create what we call a PDK which says
let us define them interface to memory
to the x86 etc because you don't want to
worry about that we have a whole bunch
of logic designers in either pen and
they won with our compilers it's
initially based on open 64 get into that
we let you define in a table your
instructions so the compiler when it
sees a construct a equals Google one bc
to automatically generates the
instruction so to take this one step
further we're now doing the following
when the problem will do in doing that
especially if your compiled person on
the standards you have no instructions
you don't know what the side effects are
can the pet can global flow go
the instruction does it modify anything
else so what we've done is created a
compiler where you define what the graph
transformations can be done with that
instruction which means it makes the
development of unique personality pretty
straightforward supporting a compile and
go model with C C++ or for travel
probably shouldn't mention Fortran
occurs here programs a portrait but C or
C++ which means in a relatively quick
way you can add new instructions that
are optimized sharing all of memory and
compile and go to get the benefit of the
acceleration um well let's see how
complex once you're trained to use it it
can take a day or two per instruction I
don't think I'd want to have hardware
engineer do it you know if you think the
question is how complex is the
definition if you understand what it
means to have side effects how many
operands where the result goes you know
things like that it's relatively
straightforward so here is an example of
a benchmark this is just simply load and
store memory where the indices are
sparse as opposed to strike one or
whatever so because we actually have its
31 31 into the or jealous for the moment
let's skip it on a cash-based machine as
the strike goes beyond one the
performance basically flat lines to
wanted two gigabytes to say because
you're breaking cash because we don't
have caches and this is against them the
hailing Signal Corps we basically have
flat at forty five gigabytes a second
and of course when it's destroyed is 31
or 62 the performance drop step but in
actual operation or in running user code
this doesn't happen all that fruit most
in time we are over here this is an
example of custom personality to do a
search colonel for bioinformatics while
at the max is a lot of 40 min searching
take a genome we looking for certain
tears and other things so we did this
for our beta test customer at UCSD san
diego and we created fetching substrings
updates etc we have 440 what we call
state machines and as you can see the
benchmark with performance is at some
cases approaching over 10 times in eight
core intel override requires the signal
quarters it's as we yeah I can do that
out the living today right now well hey
look I'm going to go back I understand
trust pens ta MEK question okay let's do
it this way
it's the same virtual address space we
implement virtual memory in the
coprocessor is a 64-bit virtual memory
is identical to the x86 64 we don't do
the i30 to EE or this other stuff its
cache coherent you do a write from Intel
and if we have the data the updated and
vice versa so from the viewpoint of a
compiler it looks like an SMP the simple
take away it's an SMP did not answer
your question it does with the leading
automotive questions or read help
maintaining Pegasus and my plan lame-o
other numbers any doesn't solve the
answer is 0 there's no software
protection this is the team who built
this is has been with me for 25 years we
built smps we understand all the issues
of outdoor water execution strong
watering week ordering you can go on and
on and on the answer is it's an SMP
period look there's no exceptions if
there's an exception we fix it and one
of the ways we able to do that to be
quite candid it's an intelligent
investor we've had access to let's say
data and how their stuff works that
unless you have access to them there's
no way you'd ever get that right so we
understand to do certain things if you
don't set csr 10 with 5 problem quickly
by csr 1553 you won't work if i can give
you examples no no it's like an SMB
period still matter if you are the
memories face yes
so how's the software that's my name is
station right now a question about theta
mu bintu power consumption oh there's no
magic we give you practice to say
whether they be should go I've yet to
see a compiler algorithm that says put
it here versus here the virtual memory
cause it the real data can some power
consumption I'm sorry is when you access
a particular memory not moving it but
running that benchmark where you get 50
gigabytes a second because you have old
memory working overtime that's where the
power consumption here's an example of
something we just released for graphs
and what we did is we create a
personality that can support up to 8,000
threads simultaneously since our memory
system kids to put out an order
execution going to your question with
weak ordering we can we have tags on the
data coming back so if you reference 1 2
3 4 5 6 and 4 comes back we know we're
in the queue before it goes because it
has it because that memory reference has
a tag okay so what we've done is create
something for something called it the
broom graph which is something used in
bioinformatics when we did where we have
hash tables going to memory to look at
the overlap of segments this is
bioinformatics and the memory system is
the same is it different personality and
the way we do this is we have fpgas
actually doing the execution so for each
personality we create a different bitch
file for the fpgas and that's how we
create these different instruction sets
that are mutually exclusive so now how
do I take this to be an exhale system
you know most people say well we'll take
Moore's law and 18 years it's going to
be 10 times faster that's what they'll
do that's the wrong way to do it so what
I did is I assume a whole bunch of
somewhat independent ver
floating-point IP how many arithmetic
engines language directed design and
they did a basically what you do
Bayesian decision analysis to see how
this factors out so everyone knows
Moore's law that says every two years
twice the larger not necessary twice the
clock rate or anything so i'm going to
say by 2020 on the zoom a mean factor of
seven sigma plus or minus two so seven
times perform insane clock rate same
internal laundry a lot of people never
heard of rocks author rock was the
venture capitalists that started income
and he said that the course of a
semiconductor chip their doubles every
four years and in fact that's kind of
happening and that explains why in some
sense you could argue the number of
independent labs are going down because
the quest is over Spencer that unless
you have the volume you you can't have
your old bear so we have boundaries like
TSMC seven so this is most people never
heard this but this is sort of what draw
is the anomic aspect of most lawyer so
application-specific a standard
benchmark and hpc is Lin pattern which
is basically matrix all when people had
vector machines like NEC creddie this is
going back to nineteen ninety three they
got ninety five percent to pee or ninety
percent of people well it's called the
earth simulator with 5100 processors at
eighty-seven percent in the last impact
of impact it's got a lot of press the
Chinese mainland Chinese had the highest
linpack out of 86,000 course but only
got fifty three percent of people so it
was a brute force way of getting the
performance as opposed to efficiency so
you talk about power consumption that's
a lot more power efficient because was
in an inefficient
to solving the problem so if we can get
ninety percent to pee we actually have
better power performance so how do you
do that one thing we're doing a conveys
is we're creating matrix accumulators
you know vector machines had vector
accumulators and you hit a term vector
processing but all the applications are
really matrices the reason was called
adaptive processing because when it came
out let's say with the Cray one where
there wasn't enough physical memory to
really have a matrix it was really one
the into the processing now that's not
the issue so if you have the major
secure a tur you can get much more
efficient Cody this is example what I
mean oh I'd rather put the s rams into
application specific machine state as
opposed to cash and let the compilers
dealing with matrix accumulators or some
other machines structure that could be
appropriate to an application so it's
under your control so in this case it
does a stencil in one operation it's a
very typical operation for a lot of code
and if you do that you actually get a in
excess of ninety percent efficiency
right now floating point is a hot ID we
hope in the future and tomorrow making
presentations Eiling so they should get
it a giggle there that would get more
performance then you can take trade off
some of memory and put arithmetic units
in memory more and more you hit a motion
of pin processor and memory that is
let's put the processing closer to
memory because the latency and going to
physical memory so this would be similar
to that type of mechanism so my view is
since as you say I'm very much
interested in what compilers can do a
programmer productivity I said his is my
matrix multiply written in UPC you
explicitly say they're sixteen thousand
nodes and i believe the compiler can
take this and generate the code directly
if all my nose have a shared
remember that's not cash go here we have
sixteen thousand dollars i'd only cache
coherence that i can I don't afford to
and by having a language like UPC where
you say how many nodes and so its global
physical global virtual but not cache
coherent that's where a lot of the
industry is moving in that direction you
can develop a compiler that can
automatically paralyzed and dec / eyes
that without going to any language
extensions so you do all the math Mazel
or matrix arithmetic set cetera you get
a mean of 800 times what is today
best-case 2300 worst case are 448 and
the system what it looks like is uses 24
megawatts 32 terabytes of memory / notes
of 288 petabytes physical memories about
sixty percent of the power but that gets
you an exascale machine the way you hook
it together I believe each node will
have optics coming out to the
interconnect so I actually use the slide
five years ago when I was the keynote
speaker at supercomputing and people
thought you know this is another I was
crazy with another with a metric of
point one bites repeat flop or just
recently IBM announced that they
developed basically that technology in
the research which shows the processor
memory and optical rowdy going off chip
the general consensus is if you want
high bandwidth going distance you have
to go out of this now this is not a
product yet but it just shows you the
type of effort that's being spent to in
fact do something like that so old only
an extra flop system could look like
this sixteen thousand nodes you have to
consider that ten meters is 59 a second
delay and an optic
so before I conclude these are some
things I've been saying heterogeneous
here to say smart of memory systems etc
now they take a total different argument
and to make myself which I do quite
frequently someone has to be a year and
if I was doing yet another column convex
conve he does its thing you know X wall
is Lee and I in 2009 I presented this at
work shopping and hapless mirror so I
said well if I'm into a convex computer
I want to design the iphone 6 0 that's
where all the action is an Android so we
have to look at the user interface the
processor external communications now i
get i did this a year ago so my dear the
antenna that goes away my phone antenna
issues so i said what's going to be in
2020 well if you're a smartphone the
power budget is 300 milliwatts typically
i believe lee that be are more ia64 I
think all other I essays will either be
gone or niche players there'll be a
64-bit virtual address space since early
that's true hair and on has announced
you know publicly that that's in
development this is now in a smartphone
two to four gigabytes of physical memory
and then fpga coprocessor to add special
functions you may have a terabyte of
flash you may have ten to twenty
gigaflops of real star rating
performance for 3d video drive you to
the SP performs in some sense you know
what exists on a laptop will exist on a
swan if not more so I don't think
there's any debate about that so if I
have this technology
what do I do with it well xilinx just
announced in essence something similar
an arm dual core with the FPGA which can
have common accelerators integrated to
within the instruction set of memory and
this is a simple chip now the question
is if I want to build a nexus scale
computer so I build it first play with
optical memory or should I you know put
a million of those guys and I think the
answer is you may have bubble because
certain applications may look better
with a million of those certain
applications may work better with 60,000
high performance though now this is
something I throw in and 20 Perry
downloaders here so we'll get a kick out
of this I honestly believe 64 bits is
not enough in the virtual address space
up when I find interesting is the
communications people taking a lead on
this when they ran out of bits and an
ipv4 they said let's just end this
Reverend r.i.p v6 and have 64-bit you
IDs and pipe becomes on the full
hopefully maybe whenever we're born much
like a Social Security number will have
a ipv6 and AH you know when people get
point that you know they do it today I'm
going to get one they get a Social
Security number and a frequent flyer so
I'm surprised with privacy you should is
another issue will have no ipv6 level
but it happens in Agra I don't know it
makes sense so anyway it's a unique name
and if we do that and have a virtual
address space that lets say has ipv6 do
we can actually unify communications and
computer because we represent
the same way of referencing whether it's
on a cell phone or on a computer system
or on a network and I think that really
helps the whole programming productivity
and everything else and in fact there
was a patent issued in 1987 which kind
of discusses that so it's not a new idea
it's just a question of it hasn't been
implemented so just finally I always end
with Dilbert because though it has
smarts and everyone in this building as
a leading software engineer I'll give
you the first unit of our 10,000 copy
production run wow I wish we decided
with what the features listed on the box
that have been awesome I'll put this
with the other reminders of how life go
to the next thank you speaking pretty
fast to make sure I have time at the end
questions we have any question so many
common observation is so tell me
something I don't know if you're not
pushing the edge from luck where I come
from you're not doing a good job but
someone comes in to me said oh I've done
that 554 I've done Hui certain things
that's fine it's like something else
going on I'm not pushing him or her or
no I find that the smartest people are
the ones we use your turn push as he
what gets my juices going says no one's
ever done that before and we really
would like to have it done
the Queen was that got to be careful not
to exclude people end up in one of these
situations in Paris now this file save
your time we can't do on that key I
understand you asked me a very general
question i'll give you a very general
answer i have a saying a separate
presentation i was saying that the first
ninety percent is easy it's the second
ninety percent that's difficult and what
you're saying is your address in the
second that you don't want the second
lighting presents grew up the first
ninety percent so i totally agree and
all my experience on the designing
computers for 30 years when you ship a
product you're lucky if what you ship it
achieves eighty and ninety percent of
the objectives who started out with so
if you don't kid yourself and when you
started purchasing this project
mentorship should have ABCDEF hardware
software at the end put a check mark or
make it grade yourself I would be very
surprised if you get more than ninety
percent of that list I mean if you mock
it fairly the gentleman is naughty
and Arthur I people Tyson Allah s peace
they are things called power mechanical
issues how could you please help me with
what variability means that was
asthmatic listen ATM assistant here is
performance outfit ok my colleagues at
Intel when I have this discussion with
them it's generally trust us ok I know
that I know that's not an answer you
wanted but I do not have a PhD material
science or physics so I'm not sure I can
give you the right answer it's very
clear one of the reasons why they have
to go through four billion dollars and
eight billion dollars etc is to address
some of those issues how do i go from 28
nanometers to 22 to 18 yo etc and one of
the ways they do that and i still have
reliable products is have blue process
technology that could cost billions of
dollars to develop and some of these
machines I've seen them if you look
around if they're here are a particular
way for tests or that I've seen it's as
big as a posse it's 50 million dollars
and have multiple because they act that
both and that's replicated you know n
times let alone if you ever walked in
the fam / I've got in a bunny suit you
know you won't dress down this is
serious business it may get to the point
it's only one set tongue-in-cheek not
made the main enough to put a fan on the
moon with is no gravity because the
deposition may be affected by
gravitational force
if you don't know you know one of the
things is like i mentioned to people
just like asked about how many people
know for trade in 1960 there was a whole
school of papers called designing
reliable machines built out of
unreliable components a lot of people
have never seen those papers because
unless they were scanned where you went
to school I did it you never knew people
wrote papers like and it's amazing like
I never once at a conference discussion
maybe we should go to your giardi vote
logic or threshold Roger what do you
mean you know that it's not it's not
gullion but it's a rep it's a
duplication within a logic gate itself
or not approached and we may have to do
that I honestly I'm sorry say I have the
school I have this belief to beat my
candidate I want to make the hardware
work if the hardware complexity reduces
software complexity that's I wanted it
so like when he asked the question about
cache coherency because of the example
they would Kudo I don't want that
because that ends that doesn't help I'm
sorry yeah I took a whole DeStorm I said
like boys look at me this
5h you can build condos and let's get
this is the math I used several years
ago I did this analysis for some people
in the government about using limp act
as a predictor of Moore's Law and when I
took the published numbers it was much
more than doubling every two years
that's it so i looked at the micros the
micro width went through 16 bits of
32-bit to 64-bit so it was a memory
bandwidth and how fair she could do a
multiply went from eight cycles to four
cycles till I could pipeline so you
can't just use games so what I said is a
factor of seven is morally a factor of
four is using matrix our cards vs make
vector arithmetic a factor of eight is
having hardware flow as opposed FPGA
float another factor was putting
processor in there that's what this line
is use a visible pipelines preneur so
you take 7 times 4 times 0 point nine
times 8 times 4 and I did this again
because when I was in the audience like
this the first thing I would do when I
would see this as I multiply it out to
see if the presenter got the wrong
answer and you get nominally a mean of
800 x multiplied what the number is out
because in the current implementation
using fpgas where you have to use lutz
to create the multiply and the pipeline
is like 13 cycles etc if you have hard
by finding custom logic to do that that
drops down my factors orders of
magnitude really does if you want
that's right and so I'm saying about fph
but FPGAs have custom logic islands like
a DSP as custom logic so find a custom
logic 64-bit fuse multiply and I would
see that benefit hi well fauna so I can
tell you this that is not a random
number it's based on a lot of detailed
analysis yeah okay the question is the
is the IBM that example of the substrate
part is on yes or no it's not predicated
on what iBM is doing but I firmly
believe that to get the family if you're
doing high-level compute there's several
metrics of how much bandwidth per node
you need based on flops the desired
bandwidth is point one bytes per second
per Pete Pete fly if you work out the
numbers if I want to get caribidor so
out of a node sure i can use copper
maybe but or single lambda topics if i
can use that term but that becomes more
difficult to build we are today long
haul if i go from San Francisco to New
York come over a terabit fiber that's
using W DWDM dense weight division
multiplexing I there's no reason why
that technology but no reason is cause
but from a technology perspective that
technology appropriately reduced in size
of mosca just as usual to be done note
for note and there are benefits of
optics generally in lower power and they
don't have RFI I recall I remember my
first company we had optical lens and
they were put over for rest lights are
you crazy because when the topics so
there's a benefit in the resiliency ask
not just the power and therewith and
nitin even though it's not the same
people who say I'm saying the only thing
i can use off to the links between my
receivers yeah it's a very little
bandwidth but it's still optical and I
think you see more and more what happens
the dot-com bust hurt the use of optics
interviews because a lot of technology
being put into optical transceivers of
stuff and when the dot-com bust happened
a lot of that investment went away
pretty rattled gentleman back so the
room is back briefly to the I mean this
kind of inside the NFL but nevertheless
we recommend you still looking at a much
lower issue in terms of their custom
operation well okay rather than trying
to repeat the question the way you get
the performance let's just say yes step
back if I have a vector computer 1
instruction issues actually hundreds or
thousands of look of equivalent loads of
scores so yeah and so this too let's do
character by character one is a Cynthia
approach we your degree one instruction
generate hundreds or thousands of loads
so the instruction issue rate is not is
relative it's more the upper ambition
rate the other approach is
multithreading we're like an example i
gave with the graphs we have eight
thousand threads running on the same
time so in that case what counts and
performance is not the instruction issue
rate but the thread synchronization and
how many threads can i go can the memory
system
right if the question is how can you map
kernels into instructions once its
efficiency whatever ideally you'd like
to have one kernel you'll be responsible
for ninety ninety-five percent of the
execution and most sometimes that
happens sometimes it doesn't right I
understand so the reason I show the
example of the graphs is that's an
example where it's let's call it a flat
profile that is one kernel does not but
it can't be multi-threaded so you get
the benefit of the hundred X speedo
because now you have eight thousand
threads executing at the same time
hashing into memory so that's an example
of having think of it as 8,000 x86
threads it's not x86 with so therefore
the profile is flat among the
instructions of the x86 but your
application at a higher level is
embarrassing parallel between threads
and that's fine and that's what we do
with the graph it think it's not a
colonel it's the application is
multi-threaded that's the if I can use
to use your term that's the colonel so
how do we create a moment multi-threaded
environment and that's what we've done
Danny I'm sure do not answer your
question okay right well okay without
knowing the test I obviously can't
answer I can only tell you I was having
a special gym when we have looked at
graph problems for the one case I showed
where each kernel each thread is doing
hash look up to memory it scales
linearly another approach for graphs
which is different than threading and
certain applications can use adjacency
matrices where you have bits so someone
for example may want to have a bit
matrix that's a billion rows in 64,000
columns which is a different way of
representing perhaps a network which is
what you use it for graphs and with our
let's say limited experience but we do
have actual experience and the tie
unfortunate I can't go into the
inappropriate to go into the details
there are certain phases of the program
so to get to your question out kernels
there may be phase a of of the program
that may work with threads and graphs
face being made with the jason c major
cities because is nice and wealth isn't
back and forth or for application at you
through a in application be do the other
approach and um
the only thing that's common among both
of them is if you don't have a high
performance memory sister that can deal
with thousands of outstanding loads and
stores it doesn't work it doesn't scale
I can give you some more answers but I
can but yes you can write about the
conflict a lot of the conflict is a
result of the way you program is so it
you know it's garbage in garbage out if
I can use that term if your program in
the program right the best kampala can
unravel and we can tell you you know
this doesn't look at I can't do this
optimization of this but I can't
restructure and in my experience doing
this for performance if you build a
computer as amaris start with the
members of this sooner or later your
application has been everything limited
I don't care a loser for freedom so how
do you build the memory system that
could have thousands of outstanding
Moses the Ronettes cables so the first
step is if you have a cash-in probably
those over because these threads are not
going to have kashyap it will leave that
if you have worn in this case then you
have all our designers who are working
in for 25 years we just this is normal
collector the truth it so happens that
memory system could be used for each
other
that person i can i can tell you a lot
of customers only production
applications using that approach in the
case i show rather than the threads
being a instructions it was a finite
state machine but it's irrelevant it's
more of the way we see things up in
crete and create the threads etc that's
really i've been asked that question a
thousand times in the last three alarms
and show me the code it will depend I've
seen cove where fifty thousand lines of
code an hour later runs I've seen fifty
thousand lines of code we're three
months later it runs I mean was a
visionary I have a saying when you bench
marking machine you tend to benchmark
the analysts as much as your benchmark
the system and a lot of the tools
compila tools and debugging tools many
cases are used or by the analyst and the
end user and I've had many cases of
responses you know that i lo should do
that and if you have a small team you
pick you pick up you go a Harry and Joey
won't come here for seconds sighs you
see this that's not really good you want
to fix that but Steve is unity of my
lips when you're going to have that
optimization
and it happens that's what you have
highly motivated people Wednesday and
that's no good reason to be included but
if you're in a high-performance game you
have to have that type of in power if
you don't need us because if you saw by
this bullet user productivity that we
should which is used to program the
world I've been saying that 30 years and
it's absolutely are for my first proper
convex thought we made a vax compatible
compiler we could take people's hundred
thousand lines of bax code and in an
hour have it running that came to us and
said you must be building the backs of
Honolulu she were in the suit no we're
not I remember the compiler guys coming
to God do we have implement this way
back she's doing true enthralls it
violates the standard like yeah that is
really terrible please do it on what
else to say I was on Electra bleak
committee so I used to go to Berkeley
and come on I won't have cocoa line we
actually first the idea how a pc has we
actually have one person is for that
thank you can't have round book i
answered hopefully you more than one day
could be candid oh one of the things I a
lot of the stuff it is the question
about coverage resiliency we still buy
the D range we have North impact no pick
up the go by I am for micron who never
if sixty percent of the logic is as
derails yeah we can do ECC us awesome
but if you have two errors or whatever
we should love a micro which we have no
control over we got potential that I
suppose I said I said I know he'll say
we do have potential control
but given a lot of known cases of when
you have systems especially not at sea
level but at 7,000 feet and talk about
giving another example once my wife and
I went to ye busy maui and at the
telescope lie on a mountain it turns out
i didn't know this was ten thousand to
two hundred feet and computers only
expect at 10,000 feet so the their
workstations did not meet the the spec
if you will so if they wrote it was no
warranty i I so there's a lot of issues
that come up like that sorry right but
there's certain things guess we're
trying to say that environmental issues
you know if it's a 10,000 feet or
Colorado or wherever that could have
impact on today's systems let alone and
it certainly chosen once it fact shall
is it someone from Intel I had a photo
microgram that overlay a virus on a chip
that is some sort of cold virus whatever
the virus was two equivalent of like
hundred games or so that was his way of
saying hey guys we're getting so small
that we're dealing at some virus medical
virus level science an offer anything
under that it's well known I assume the
process people that's part of their
specification
while doesn't know anything pilot simply
sees this as as if they anointed regime
i'm going to say the cache coherency the
shared virtual memory is well done in
hardware we run linux we had to modify
dozen linux kernels with bios and stuff
to deal with those issues it's real
simple you can take an alpha be as clear
as I can and we actually create fat
binder so when the compiler would
generate the wall x86 code or x86 code
coprocessor file and execute the AFO if
he doesn't see the coprocessor just
excellent but that fighter if it sees
the coprocessor innocence core processor
instructions which look like extended
x86 penetra it goes will tell you how we
do that because wow it's not here it's
there go start that it's
it can either be done instruction by
instruction or sovereignty nice
generally that's when you're subroutine
myself rather discussion be either one
works okay well I thank you I this hour
there's thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>