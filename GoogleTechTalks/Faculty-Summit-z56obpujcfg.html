<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit</b></h2><h5 class="post__date">2008-04-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z56obpujcfg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">can you hear me everyone I think so good
morning where we r 46 seconds late today
which is at the beginning of the M
because some things everyone assumes
you'll be 46 seconds late and then
they're minute and 15 seconds late and
that it's probably some exponential
decay but we could actually measure this
at Google as we could actually have some
system which somehow measured the
arrival time of everyone and check the
pattern to see if it really does follow
some exponential curve over time up and
of course that would be our philosophy
as you'll hear when I give this
presentation so my name is Alfred
Spector I'm going to tell you about
research at Google I think research at
Google means research within Google and
also what our hopes are for partnership
with universities and other research
organizations for an extra mural focus
on research from google so I'll try to
discuss both of these my background is
actually kind of at the mixture of
university research and industrial
research and commercialization I was a
professor at Carnegie Mellon in the
1980s I started a business which got
acquired by IBM and I had a chance to
run pretty large IBM business units and
ultimately be the IBM CTO for the
software business but I also had a
chance to run the IBM software and
services research unit so this job is in
many ways just the most wonderful job in
the world for me because it's a mixture
of all of those google is a large
start-up or a new big company i'm not
exactly sure which we are extremely
technically focused it's our founders
never are almost never saying well i'm
not sure if that's strategically
sensible i don't know if we can do it
they're always pushing the limit on g
could we do that technically and they're
always looking at the technical angle of
what's feasible and why can't we do what
we're always being pushed for more m we
are as you heard from a lot of our
policy and culture things somewhat like
a university was mentioned to me this
well from Israel that we seem like a
university and some of our ideas of you
know how we do reviews it looks like a
you know assistant professor review
committee within a university that it's
a peer and kind of thing done by more
just other faculty members may be
somewhat more senior ones so anyway I
love the place and let me tell you what
I have to say so first up while it's a
tiny bit repetitious I won't spend long
the mission and delivery model of the
company have an extraordinary impact on
google and what we can do so I'll
discuss that through the first couple of
parts I'll discuss our research
philosophy which is somewhat different
than the research philosophy of the
typical industrial research organization
and I'll describe that I'll discuss some
of the areas of research that were
involved in and then the question is
exactly how many key research results
will I talk about so I have you know a
modest number of slides on the broader
topics of research management and
philosophy and I have a lot of slides on
some research projects and we'll see how
that goes I don't expect to go through
all of them and of course I'm not the
world's expert on any of the individual
projects but I can illustrate some of
the things we do and then I'd like to
conclude by kicking off the discussion
of Google's relationship with academia
and other research organizations I mean
kicking it off because we're pretty
young and we want to learn what to do
we'd like to learn what you would say we
should do and we hope to listen to you
during the rest of this event as well so
as you heard and as you know our mission
is to organize the world's information
and make it universally accessible and
useful and that's a very broad statement
there is all different kinds of modes of
globally shared information increasing
amounts of video an image for example
today map information you name it but
there's increasing amounts of private
information that we should make
available to people as well with
appropriate privacy so for example one
could consider health information health
in the United States
two point one trillion dollar industry
it's an extremely large percentage of
the economies in Europe as well although
not quite as much as the US and there's
a huge amount of information that would
benefit everyone in making decisions if
that information were available and
indexed and of quality and universally
available so you look at the amount of
information that's out there and what we
could do in the class of problems
associated with this it's really
remarkable so what do we do about this
so first we aggregate ever more
information so that automatically leads
to many interesting research topics just
the scale and size associated with the
word aggregate we have to make that
information more useful to more people
so take enormous numbers of video
without appropriate indexing it's
extremely inefficient to look through
videos with good indexing it's extremely
useful so we have to think about how to
make it useful we have to provide access
in ever better ways so today access is
traditionally maybe by a browser that
might be the most common form on a some
form of a display with a 14 or 15 or 20
or 30 inch display what's the future of
that and we know that that will change
not just in mobile but in many ways and
then we have to provide indirect access
what I refer to as indirect access via
ever better applications so it isn't
sensible to for example just to say
we're going to show you the raw data of
an of you know an mp3 file as a human
being we can't do much with that we have
to decompress it and see it so we have
to be involved with the visualization
the presentation of information and to
some degree to create the applications
that allow the creation of information
so we have to be involved in do
everything in that we don't provide
every application in the world nor will
we ever but we have to be involved to
make sure that the information that we
have is usable No so what do we focus on
architectural II given that so large
scale data aggregation as I've said
fusion so how do you put together
information from many sources to enable
you to put together a coherent
answer to a question or to use the
knowledge of the behavior of our users
to help us figure out what to present
we're extremely interested in
distributed computing or cluster based
parallel processing they're all these
words associated with it it's subject
that I've been involved with my entire
career up how do we use now today the
availability of zillions of CPUs
connected together by fast buses with
lots and lots and lots of storage and
well this was something that many of us
thought about decades ago it's something
that would be likely to happen i'm
looking at mark shapiro in the front of
all all known this is going to happen
it's here we actually have fascinatingly
big scheduling problems know that we
might have talked about decades ago but
they're actually here and they're
fascinating and important to solve there
are many components that we can reuse in
system so as our architecture their
interesting components filtering
components for example how can we take
filtering components or anti-spam
components or a variety of things that
makes its security privacy components
and put these into our architecture and
then we have to interpret information to
people and we have to figure out what
that means that's a very carry thing we
have to do extremely carefully as you
all know as what it means by that so
there are large architectural pieces and
there many more probably that I could
decompose what we do but it's not a bad
starting point now the delivery model
has implications on research as well so
we have a strong reliance on services
delivery from what now seems to be
referred to as the cloud but we could
call them clusters of machines I think
just as well or distributed processing
that is somewhat some degree centralized
or virtually centralized cloud seems to
be the word that the public has picked
up on its this is made feasible also
fairly recently it was well well thought
about for decades that distributed
computing it made sense to put
computation wherever it made sense to
put it and if it made sense to
centralize things one could do that and
access via remote procedure call or
request response or
host and what have you so that's been
known for a long time but suddenly with
the ability to have very high
performance quality computing a quality
communication across vast numbers of
people this has become feasible so
Google started at the right time when
there was a significant move towards
broadband communication that was broad
this was very hard to do in the late
1980s even if we knew the technology and
of course the distributed computing
technologies of managing clusters and
distributed file sharing and these kinds
of things the university research world
has been working on for decades and we
thank you for that for producing an
enormous amount of expertise that let us
build these clusters and we have relied
heavily on that work at Google and if
you look at some of the systems work
that it's done it's been extremely good
at Google but it we've built on the
shoulders of giants in this so the
benefits of the of the cluster approach
are numerous um it's very difficult to
aggregate data if everything is
distributed on a desktop it's just a
very very much harder problem to do
sensible data aggregation it's in theory
feasible with infinite speed
communication but practically you're not
going to do it so because of the data
aggregation it pushes us towards the
cloud we can get astounding benefits and
this will get back to that in a minute
there's a very important issue that I
think that is one that speaks to what
should be our long-term ability to
innovate is reduced combinatorial
explosion and software development when
you develop for the traditional software
world where you have to distribute
software to run in a customer
environment that's highly variable the
complexity of building the software to
run in every possible customer
environment which is kind of required
because of the economies of scale needed
and software results in extremely large
overhead and software development so you
know I think about the folks who develop
you know the main new releases on
popular
platforms I wouldn't be surprised and
I'm sure you all would agree maybe
ninety percent of the work goes into
dealing with the complexity of bringing
that software forward from previous
release to the new release on an
enormous number of alternative platforms
different databases different hardware
platforms backward compatibility the
need for AP is that have been used 20
years ago to be used again there's just
a tremendous complexity to that given
that we ourselves assemble software on
our servers if we are wise we will have
significantly less heterogeneity and
significantly more control over the
architecture and bringing things forward
uniformly know we have to work really
hard on that we can be subject to the
same problems ourselves but what it
means is that if we stay reasonably
clean architectural e we can roll out
new things faster than the traditional
industry can do and that's a real
advantage of this cloud-based computing
and it's of course a great advantage if
you think of a research team in Google
you can try something much more easily
than you can if you have to think about
making it work on an operating system
variants and M databases and why systems
management products and Z security
management products and the like which
is as you can tell an allusion to what I
had to worry about in my past life usage
complexity also declines because you
don't have to install you can see the
immediate and benefits of doing
something and that is a great benefit
and I think I've mentioned the launching
new products a part of that so the
implications on us are that the mission
yields many opportunities we can
capitalize on communication computation
storage and usage we have lots of data
we get lots of feedback from usage these
are incredibly important in fact we can
ask the question now what can the world
teach us about almost everything we do
and this is maybe why started out with
the question saying we could figure out
the arrival time of peep
as a function of the initial delay and
do experiments of that form when I got
to Google I would say the single biggest
difference from any previous job I had
was the immediate understanding that
what everyone focuses on is measurement
measurement of what how the system is
used by people with the primary
implication that we can make the system
better by seeing whether people like or
don't like every interaction we can make
the system better by looking at every
interaction and looking at the
implication say on a previous
interaction as perhaps shedding light on
the meaning of that previous interaction
and this is extremely broad and relates
of course the topics of machine learning
and relates to topics of how to do
complex AI problems it is this notion of
crowd awareness or crowd knowledge what
can you gain from the knowledge of a
million people a billion people that are
using the system so it's really a
fascinating kind of thing here so as I
said our mission yields many
opportunities for innovation not skull
troid up it could be that you would
think gee we're pretty good if we could
take our cloud and think of it as a
uniform system or maybe the cloud and
the browser and some lightweight apps
and think of that as a uniform system
and design that coherent ly that's not a
sufficient focus the focus must be the
user community and the software and the
design of the system capturing both in
mind and that's a little bit different
than saying user centric design that of
course would have been preached for
decades in our industry it's not just
user centric design it's the design of
the system recognizing that the user is
always teaching the system and
maximizing the amount of teaching and
maximizing the amount of value we then
can provide to the user let me just
before anyone asks a question during the
talk if two people mind does anyone mind
that were
filming this in fact let me put it this
way if you don't mind that we're filming
this and could conceivably put it up
don't ask a question till after the talk
all right because you might get filmed
and I think that's a fair disclosure in
this is that okay with you do you mind
being uh okay then you happy to take a
question though yeah i mean if
understand correctly were you aiming
aiming it then the most obvious question
is do you have a convincing privacy
model that you know i mean i understand
that it's very convenient to develop to
adopt this software development model
because it's much better than what was
before cloud computing in the senses
were effective but on the user side that
i mean if you talk to if I talk to my
colleagues everyone is concerned about
the fact that sooner or later Google we
had we know everything about us that's
that's I mean it that's an obvious
concern is nothing extremely hard to
figure out okay but you must have some I
understand your question so the vsync
privacy model behind you could you state
your name just for the record watches of
Yankee okay great so the question is is
a fine one on on privacy and I think
it's a I think it's a fascinating and
important topic and Google does too so
I'm sure you would believe that
certainly now at the stage we are all
well intentioned you know our mission
statement to do no evil we really are
well intentioned we really think this
adds enormous value we use the data we
collect in every instance I know of to
make the experience of the user better
all right and as we get into other
things that is always our objective is
to use the information that we get to
organize the world's information and
make it more useful to people so that's
our mission and people have found that
to be you know a good thing to do with
us we have good market share people like
our products but the issue with privacy
is a very interesting set of questions
as to how society will handle trade-offs
of the of the rational concern that you
bring up and I think it's worthy of
further research let me just give you an
example I'm on the National Academy in
the United States
and I was at a computer science and
telecommunications board meeting which
is sort of a policy planning committee
of the national academy on where the
government needs to focus its policy and
scientific funding etc activities and we
had a meeting out in California just
about a month ago and we asked a number
of the Bay Area research leaders what
they thought one of the fundamental
problems would be going forward that our
society and I think this includes all of
you as well need to address and the
futures is not just an American North
American statement and the the thought
was that was I provided the sectors
provided by Andrei Broder who's a friend
of mine but at Yahoo research he said he
thought privacy was one of them but he
actually didn't think about it from your
perspective he said well you know it's
really not in Google's interest to go
and ruin the reputation of a great
company by doing something that would be
frowned upon with user data google will
have to try and Yahoo by implication and
Microsoft and the normal things we worry
about we'll have to try extremely hard
to not lower the trust that consumers
have in our brand and that's true we
really we really work very hard on log
safety and all this stuff that we do log
security but what about all the cameras
are going to be out there what about all
the YouTube videos that people do of
themselves so you know and there
instances now of you know major
actresses that have videos that have
been seen that ruin their careers would
never have been existed before the huge
numbers of cameras they're just so many
things that you know situations where
someone's seen doing something when
they're in college that they wouldn't
want to have seen when they're running
for presidential office or stuff so I
think in general the thing you bring up
about companies like ours hospital do
you name it as well as just the whole
question of what we're going to do with
this amassing of private data that's
that's reasonably going to occur on
systems people are going to do
themselves how we're going to get
through
that and come up with kind of a new
culture in society to reflect our
understanding of that I think it's a
very important problem so and I don't
know the answer to it and I I don't
think anyone knows the answer and I
think it's going to evolve over time so
i think i think this point is clear so
i'll move on to the next one so on
research so like every company I'm sure
every company says rapid innovation is
essential it's clearly true at Google
one of the philosophies that are we've
had at the business which I just love
since day one is that great talent is
needed in all aspects of producing the
services and products that we do so we
can't say that great talent is needed to
think the great thoughts and anybody can
program the stuff we do not have that
attitude we've never had that attitude
and I suppose if you think about who the
founders were of the business you can
probably see why that came about and
there are chill thinking their initial
hiring people so we believe the talent
needs to be distributed across the
organization so we have I'm not exactly
sure what we say publicly but roughly
speaking two-thirds of our entire
engineering team has master's level and
above degrees so it's a huge percentage
that just would not be found in any
organization of our size around the
world with that much talent and we're
selective as we've said before so this
is a very interesting implication on
research that we have that much talent
across the entire engineering team so
what we find is that we do have a
separate research team in Google that's
relatively small order of magnitude 100
plus people but then we have research
done without question in the broad
engineering team in Google as well and
that will be something they alluded to
that the different model then the way
Bell Labs was set up it's a different
model than the way xerox was set up it's
a different model than the way IBM
research was set up it
a different model than the way Microsoft
Research was set up and we're proud of
it and we don't want to change it so you
know you could you could say we put you
know Rick ratchet here from Microsoft
and was a dear old friend of mine he
could say offered you need to go you
know double Google research every year
to be as big as Microsoft within X years
and I'd say Rick we don't want to play
that game what we're not trying to do
that you can stay bigger as a separate
research organization you may not stay
bigger as a company doing research we'll
see the market will tell our
achievements will will dictate that
because but we're going to have our
researchers to a significant degree in
situ with development so why is that so
first we think we can do that too if we
do do that a lot of the technology
transfer problems are lessened and
that's one of the big issues at
universities and it research labs as
well even in companies how do you make
the work relevant I think at many
research labs and companies one of the
primary demotivators of the employees is
they feel their hard work isn't really
impacting their company it's not being
taken seriously enough by the
development teams and that's actually
not really an issue at Google it's quite
interesting that that's not true there
is um there there's one more important
reason and that is so much of the
research that we do relates to data and
scale so data and scale will not be on a
toy system owned by a tiny percent of
the company data and scale is on our
core cluster systems and we provide
access throughout the business for
research purposes as needed properly
carefully to core data so that we can
actually do better image processing and
learn the algorithms on algorithms of
size makes for great fun um we don't
believe we live in a vacuum you heard my
comment earlier that I believe we've
built on the shoulders of giants and the
business when we started we do and we
will continue to we are but a small
percentage of the global
science and IT structures in the world
and we need to work with everyone else
all right so but people that said that
we sometimes appear to be a great vacuum
is that we attract great talent and are
never seen again and I understand that's
probably a degree of truth to that it's
probably related to the startup
phenomenon when your heads down really
trying to be successful early on so I
think we deserve some understanding for
that for many years we have published a
lot for company of our age so I'm not
sure exactly how visible the subtitles
are on this but algorithms in theory AI
and data mining audio video and image
compilers not too much they're
distributed parallel systems education
HCI web information retrieval machine
learning natural language processing
other scientific disciplines security
and privacy and software engineering so
we've published quite a bit these are
not these are numbers that's the best of
our knowledge that exclude the
publications by people we've hired
before they came to Google is that your
question ok so we've handled the
question so yeah we if we included my
publication list and the publication
list of everybody else that we hired at
Google this would be a gigantic number
so we don't take credit for that it's
always a humorous actually to look at
the nobel prize lists of universities
that they they'll do anything to list
them nobel laureate even if they got a
25 years earlier in a different
University in a different topic than
they're currently working on we don't
we're not doing that here at least we're
not trying to i can't say there isn't
one mistake or a boundary condition but
it's approximately correct and we
publish that so and we've written some
very good papers now I'm a systems
person so I can attest to the fact that
in the systems community our paper on
the cluster infrastructure on gfs the
Google file system and that's actually
one of my areas of research in the old
days on the Andrew file system on the
MapReduce programming model on our big
table scalable you know record oriented
random access data structure that runs
on clusters with high availability and
high reliability these are considered
top papers in their class all right I
think they've influenced what the
current research agenda is on
so I think adding that and if I looked I
started to look through and select
papers and machine learning and to
illustrate and I decided I couldn't do
that and I figured I would just you know
annoy many researchers at Google for
sweet picking the wrong papers and I
decided not to convene a team of people
at Google to go and decide this but I
believe we have great papers and the
other domain as well of course everyone
you know talks about the core algorithm
that Larry and Sergey brought with them
and stuff but there's there's a lot more
that's happened since then all right so
I've used about 25 minutes of time so
let me quickly go through just a few
topics that show you the kind of things
that we're doing internally that makes
sense so empiric example of empirical
systems work analysis of disk failures
all right so this has always been an
interesting topic to my way of thinking
system failed system failures are
usually software induced or disc induced
that's what I always felt or maybe our
operator operator induced I guess is a
third category so disk failures are
clearly one of the big three so we care
a lot we've got a lot of risks if you
look at a data sheet on a disk if you go
to one of the websites of seagate or
whoever you'll see mean time to failure
statistics and by no means does that
tell the whole story it would be really
good to know a lot more about
distribution circumstances under which
disks fail and the like knowledge would
really help we feel and in fact there's
a lot of conventional wisdom which might
or might not be true typical disk drive
failure rate is less than one percent
per year is that true does temperature
increasing increase failures when you
really move the head around a lot is it
more likely to fall off it seem that way
but many things are not necessarily true
so we have in our system with zillions
of servers a reasonably well architected
system for collecting all sorts of event
data and aggregating that data as I
mentioned we are statistically driven
and we try to apply this pretty much
everywhere in the system so we can
collect lots of stuff we can
put it into big tables we can process it
by you know partitioning the information
and running parallel algorithms on it
and then come up with analyses and the
interesting result in this a for example
this is a distribution that you see in
the middle of the of numbers of drives
running at certain temperatures that's
what the the semi normal curve is in the
middle and then you look at average
temperature and failure rates as a
function of average temperature and you
certainly don't see you know this sort
of clear thinking that you have a very
strong effect on failure rates as a
function of temperature in fact it's a
pretty pretty unusual curve but it
declines initially so this is something
that you can tell now why is it good for
Google to do this with lots of disk
drives we have real usage conditions
manufacturers don't typically have the
usage conditions and they have lots of
drives but they don't know how they're
used and most organizations that could
do the work your university research
team doesn't have enough drives to do
the statistics probably so this is a
good piece of work there's a lot more
kind of results in this that are
counterintuitive for example that you'd
like to see in fact dance work at CMU
did work on this a long time ago I
believe you'd like to be able to talk
about prediction but in fact fifty-six
percent of the failures have no strong
failure indicators in advance so even if
you are monitoring all the events and
jumping on them fast more than half of
the situations you can't figure out in
advance which is somewhat worrisome so I
think this is a good example of many
systems research projects we have to
undertake it's intellectually
interesting it's a really valuable
problem that's valuable to us it
requires some interdisciplinary thinking
a small team effort measurement and
scale and often iterative solution
Google is very big on iterative solution
we we try hard to avoid having to get
into situations where we solve the
entire problem first because we know the
amount of time it takes to do that in
the likelihood that we're right is not
that high so other things going on now
there's an enormous amount of in
in the company and machine allocation
and scheduling you know one percent
improvements in that have a significant
effect on power consumption and capital
plant of the company we're fascinated by
response time measurement analysis and
automated improvement of those one of
the key indicators of customer
satisfaction is response time and if you
know you can add new bells and whistles
to an interface but if the response time
is really fast that's probably the
single leading digit on customer
satisfaction so as we add more and more
sophisticated things into the system we
can we can hurt response time very
easily so we're really interested in how
do you how do you work on that and we're
interested in more security which
relates somewhat to the privacy topic as
well how do we add security in the
system but still allow aggregation very
interesting questions in that and I
could talk about more so let me just
mention a few other current projects
going on this was a piece of work we
published here are some things going on
speech translation so here's a very nice
simply OSIS between a product the and
also speech records speech reco is the
basis for the 800 number the toll free
411 or directory access for business
telephone numbers in the United States
it's certainly a rich problem domain for
speech recognition and speech synthesis
because every city has different
collections of businesses it's not a
small vocabulary you're doing this often
from cell phones so you have noisy
environments people want the information
quickly it has one interesting
characteristic you often know when you
get it right so the system is to a
degree self-checking if a user says yes
to something and wants you to dial it
you have feedback that you got the right
answer so if you put that back into the
whole notion of user feedback that I've
been bringing up over and over again
this is a great example where user
feedback should really be helpful in
tuning the system so there's a very
interesting set of technical questions
we want a model using these hit Markov
model systems
that we have as much as we can about the
vocabulary and order and things of what
people say where do we get the data so
Google has lots of data but where do we
get it do we get it from training data
from you know situations we have we pay
people to go and use the system do we
get it from the web how do we improve it
how much do we have over time etc so
they're really very interesting
questions in doing this well so in fact
we're using three kinds of of training
data we're using web queries so what are
people typing on the web to get
information and you can learn from that
that if people type a compound not and
then as a business name over and over
again that compound known as a business
name speech transcriptions so we are
doing it from that way and they're also
listings you can buy or get access to a
business listings so we're getting these
three sources and we've looked at how
well the system is the correct
acceptance rate versus false acceptance
rate which is what typically one looks
at in these situations with different
kinds of training and guess what the
combination of the three is best I guess
everyone would expect that but it's
remarkably better so you'd like to train
on as many sources of information as you
can and combine the results in the
language model that we use and that's
what we're doing to get roughly speaking
you know sixty percent 60 something
percent accuracy with relatively small
numbers of false acceptances that as we
misunderstood something is what that
means all right now is this good enough
as this as far as we want to go it isn't
we want to go further but it's not bad
and works pretty well so one of the
questions is how can you get more
training data from usage so one thing to
do is to have lots and lots of people
sitting there transcribing and then
adding to the system but that's
extremely expensive you really want you
know two orders of magnitude more
information to make this work so you're
talking about
spending a hundred times as much in the
future as you spent in the past on
transcription if you do that but what if
you only use the recognition results
where the user clicked yes dial this
number and you trained on that now
intuitively the system has already
gotten that right so you would think
that training data isn't so useful you
would think the training data on things
the system got wrong is the really
useful data but I'm surprised by this is
that actually using the and I'll explain
this there's one small mistake on the
slide which I apologize for explain in a
minute but if you look at the curve and
green the results the improvement that
we get on large amounts of additional
training data for even the good results
is valuable so what that means is you
can do training that is effectively
mostly unsupervised and you as the
system gets more and more use if we can
get millions and millions of callers a
day using the 411 system will get
millions and millions of elements per
day to add to the system to keep
training the speech recognition engine
and it will happen dynamically and it
should converge on whatever the
asymptotes will be for this type of
speech record so it's kind of
interesting I don't actually have the
new semi-supervised data and to be
honest I don't know why on this chart I
don't even know what it is so I'm sorry
I can't answer that if you ask why there
isn't but I don't believe it's
confidential or a secret somehow it's
just not on this chart and I apologize
for that oh it's what oh I say it's one
you're right that's correct thank you
for interpret it was one point you're
right I guess there's no other point but
alright well we'll get new data we'll
work on it come back next year the year
after or something so up translations
another topic so you know Google is in
lots of languages today and there's a
lot that we could be doing in this we'd
like to be able to train
late of everything to everything that
would really make Google useful I mean
if you think about it from the
standpoint of say users in countries
that don't have a very large corpus on
the web and they're actually an enormous
number of people that are in languages
that don't have very much web data if
you could translate their query into for
example English or Chinese which another
large source and then do the search in
that language and then transfer the
result back into the language of the
user you'll get an enormously large
amount more information so there's an
immense amount to do we handle many
things today mostly English to something
and something to English but we do do
German to French and we'll do more we
want to handle very many more language
pairs so we think of the problem in
translation as being in two dimensions
one is how well can we do in any
language pair can we get as good as a
skilled translator over time and to how
well can we do in reducing the cost of
this so that you know in the fullness of
time there's no prediction of one will
get there you could do a hundred squared
languages or whatever the number is and
that's an enormously impressive
undertaking so our team is really
focused on on the breadth of in both
dimensions there's a lot of optimism
it's really night for Google that the
statistical approaches you know 10 12 14
years ago started becoming dominant here
as they became dominant in the world of
speech recognition this came a little
bit later and this again plays to the
strength of Google with a lot of a lot
of data that we have we've done well
this is the kind of typical score I
won't there's a blue score this was
invented actually at an IBM team while i
was at IBM research that is a sort of
automated system for approximating
measurements of a quality of a
translation and as we increase the
amount of data and
improved our models we got very rapid
success there's been a NIST evaluation
this year of systems I can't say how we
did at that but two years ago we won
those evaluations where we competed and
I think that the fact that we have a lot
of data is indicative to the community
of the importance of this data and will
continue to be lots of lots of graphs
that show as you get more and more
training data of those benefits there
there's some questions how much data
should you use how much can you use how
do you get it all how do you manage all
this data I mean this is huge amounts of
information we're not training on you
know the information you can store on a
single server this has got to be done on
a parallel cluster with huge amounts of
storage how do we help universities do
this how do you achieve fast cycles we
have put up an API for Mt research on
our website and I'll give you that
little bit later on in the talk and we
can give you the end best lists for some
language translations and you can start
looking at how to pick among them and
come up with new algorithms for deciding
which ones might be right this is just a
start we'd like to do more and that
would like to figure out how to provide
more data to people because it's hard to
do it because we'd really like this
problem solved this would really benefit
the world if this were done better um
image processing is a really growing
area in Google to make of greater value
all the image data that we have it's a
significant fraction of our traffic you
know we've been scanning in books we
have google earth with a lot of
information we have map data we're out
driving around roads getting images of
things as well so it's a lot going on
and there's enormous numbers of classic
vision or an image recognition problems
that are relative relevant to us the
easiest one is a recognition can we find
objects landmarks and a knob and people
in in images can we match images can we
combine images if we get images of all
different forms and we want to provide a
good and well structured model of the
physical world can we combine images of
many types and bring them together so we
get aerial photographs from satellites
but street view pictures and who knows
what users will want to augment all this
with and 3d models and bring all of this
together into a coherent whole so but
you really have a virtual space on the
computer not that some game world but
since the real world and and many more
things in geometry and the like so there
are lots of challenges here a picture
maybe a thousand words a query only has
a few so what do people mean what is an
image contain so how do we find and
identify the objects these are problems
we've heard about for years they're
important how do we get rid of
pornography it's also obviously
important to a consumer company like
ours finding people in images this is a
testing problem how do you how do you
you know people look different at
different times and we're very
interested in people search as a problem
that's one of the most important kind of
queries that we get is you know get me a
picture of Obama or something like that
and you'd like to find all the relevant
and reasonable and recent pictures of
him and he looks different at different
times this is an example of trying to
fuse information from the world based on
panoramic data and what can you do with
those panoramas to construct useful
situations and whatever the modeling
world that you're looking at so a lot
there let me turn we're going to get
through this pretty fast finishing about
five minutes of information extraction
so here the classic AI problem so
there's a lot of stuff on the web right
we know that how do we get a any kind of
a a map or ontology of entities and
relations from all this data what can we
learn from the web so if we have
articles and we have sentences and we do
some sorts of natural language process
what can we begin to learn now we
recognize that of course NLP is not all
that accurate today but if we have a
gigantic corpus can we in fact come up
with you know a billion entities and I
don't know a billion to the something
power relationships between entities or
a billion maybe some multiplier of a
billion relationships so we actually
doing work on this extract him we don't
know where this will go to be honest
this is pretty open-ended the others you
really understand the business reason
it's our intuition that if we had good
ontology zand good mappings of things we
could augment search queries and do a
much better job with search for people
and we could do a better job of
organizing results I'm not going to go
into this in enough detail just to a
lack of time the last one I wanted to
talk about is is the deep web indexing
the Deep Web is interesting the Deep Web
is all of the information on the web
that's accessible only through HTML
forms so typically in order to
materialize that data you have to
actually enter something into the system
so you have to act you have to actually
like enter I'm interested in a citroen
from 2004 and when you put that in then
you get back a form of available
citroÃ«n's from that year in Zurich and
if we don't materialize the information
or find some way of materializing it we
can't search it and yet there's an
enormous amount of data there and that
data that tabular data also has a lot of
semantics associated with it right it
says car name how old the car is car
price car quality car location so
there's an enormous amount of of
semantics already associated with it it
seems like it should be a really
valuable place to actually get data so
there are many challenges for example
how do you decide what inputs to put
into this into the into the pages when
you materialize things early on there
were questions of if we
that in an automated way will we start
purchasing items by mistake so people
have to have to be very clever and
careful as do web developers to make
sure that we don't actually use you know
click on this to buy or something like
that and cause havoc but there's a lot
of possible things that actually can be
done in this and we're doing it here's
an example where if you go and you type
to google citibank ATM and a zip code in
the united states we can actually
extract the information from the Deep
Web and put up a map of where the ATM
machine is rather than just giving you a
link to the city bank site where that
information exists um other areas of
continued of growing focus algorithms at
scale obviously auction theory there's a
track on that here today and you'll talk
about that optimized resource allocation
in general HCI end user experience is an
important topic programming language and
systems traditionally we've not been so
involved in that but we're wondering
whether to given how much programming
we're doing now and how much systems
were running if everything we're doing
is right I mean it's well known we use a
lot of Linux and we use a lot of C++ and
Java other better things to do in the
models of computation that we're using
than these traditional languages you saw
that we think it said one programming
language paper was published I have a
feeling that won't be true in five years
from us software engineering machine
learning algorithms privacy so there's a
reference to that point data call I'm I
mean one topic I don't really think we
understand well is how do we is there
anything we can do to help users
understand the quality of the data
that's on the web that we're providing
other other than for example the fact
that others have found it useful there's
something we should be doing in machine
learning to be able to highlight issues
of data quality this could become very
important in healthcare data for example
and there many more so let me turn now
away from this sort of dive into some
areas of research we do desire and
that's of course why you're here
a better and stronger relationship with
a Kadeem we tremendously value
everything about akademi the values the
people the education the research that's
done we have to date and likely we will
continue to prefer a bottoms-up approach
if you will to collaborating with
universities so we'd like to collaborate
with faculty for mutual benefit that
makes sense right that's a good
long-term model that Google shareholders
will never be concerned with that that
always sounds good and it's true what do
we have to offer well I think we do
understand challenging problems now and
I think and I don't know at least it was
true for me coming in to google that the
Googlers see things in ways that are a
little different than the rest of the
world now and I think it's very
important that university people have
the right problems to work on one
concern frankly I had as an academic is
that there were too many papers that
marched in the same direction over time
because some subgroup got interested in
something and they pushed it to the
limit with you know incremental advances
I think companies like ours and others
might see the next big problem areas
that are relevant to help reduce the
risk of that we have skilled employees
to talk to we have opportunities for
internship and sabbatical and we have
limited amounts of money I don't think
we're going to compare with the EU
funding sources or the National Science
Foundation but we have some money to
help in these situations the university
of course you have faculty and student
skills breadth and depth of perspective
etc I'd like to emphasize again
internships and visiting faculty we have
I don't know thousand or more interns
you know huge numbers of interns that
come to Google and summers and I think
that's an extremely valuable way of
getting people to understand each other
the students moving back and forth or a
terrific communication vehicle much like
mailing a disc i suppose and getting
high bandwidth communication up
the we do provide university research
grants we have roughly Jeff's is about
right roughly 100 something of that
order a little more than 100 Jeff will
talk you'll talk more about this
tomorrow yeah right sometimes we
anticipate growing the number in this
region and what we recommend is
proposals developed with the advice and
perspective of Google employees and the
reason for that is we'd like to do
things that are mutually beneficial and
a without our employees acting as a
conduit of what we're thinking and what
we have available and our employees
thinking what you're doing is relevant
it probably won't happen so you know if
you you know have a fantastic thought in
the elevator tonight and you write it
down and mail it to us that's great but
it'd be really good to talk to someone
at Google about it and you know refine
it a little bit and then you know get
their support and then send it to us we
have some special projects that we do
they're not exactly in that Bottoms Up
realm that are if you will are more
strategic or broader you'll hear from
Christoph tomorrow Christoph about cloud
computing universities have been
concerned that if the future is the sort
of coarse grain parallel structures
these clusters like we have and that's
where and in some frontier of computer
science is going to be and certainly in
systems but also the capability existing
in all the machine learning and AI areas
they may not have these machines so
we're looking at how we can provide
access to cloud computing I don't think
it necessarily makes sense for every
unit of fact I believe it does not make
sense for universities to buy ever
bigger machines with all the maintenance
and power and stuff your whole budget
will get used up running this stuff but
access to these things is very valuable
so we'd like to improve that and make it
possible for people to use them and
you'll hear more about that outreach we
mentioned yesterday we are very
concerned about the fact that
kids don't seem to be excited about our
field as we are and I mean the one thing
we all feel I mean whether our
competitors or ourselves all of us just
don't get it in a certain sense we think
we're you know right at this wonderful
point on the curve where there's just
massive growth opportunities you know in
the early days it's always hard going
the first few computers and now you know
we're really on this point we're just
fascinating things are happening and yet
we don't see the excitement we see
students that would rather be lab
technicians and biology then people that
are launching new systems for billions
of users on you know Google or
developing new software for someone else
so we don't we we sort of get it a
little bit and that we understand that
maybe you know the model of someone
going to work at eight in the morning
crouched in front of a computer having
never showered for days debugging
something in isolation with you know
some manager whipping them to get all
the bugs out of it is a bad model and
you can try to fix some of that here we
have a shower in the building i don't
know the the innocent does not have a
whip so so we understand that but but
still we don't really understand how to
fix this and we'll talk about that
Lenore is going to talk about that and
I'm happy to say actually I was happy to
be at a party and I agreed to give a
talk mostly to young high school women
Hunter high school in New York which is
one of the top public high schools so
all of us are thinking about it we try
to act in this we have some programs
where we're helping in this in high
school programs and there's a lot more
we have to do um we want to in specific
areas help people actually adapt what
they're doing to this parallel
structures so there's a big speech
conference and workshop that occurs in
the summer at hopkins i think in
baltimore we're going to provide a
cluster for that or access to a cluster
to help them understand the paralyzation
and dealing with large corpora we have
some growing sites i think they will
improve a lot this year they're listed
here you can find
course materials say on MapReduce you
can find some access to some of our
systems like translation with AP is for
that you can find our publications list
on these sites and you'll find more as
the year progresses and we get a little
bit more organized on IP and I think
this is pretty worthy of saying pretty
much the entire industry does not like
dealing with universities on IP issues
and all of my counterparts in my
previous life we all hate it I mean it's
just it's you know the lawyers on both
sides you know the universe is well
something great come out of this that
could make us rich right well right so
I'll tell you what our so so you know
the so the comment was made that the the
academics don't like it either so yes
there is some very small chance some
amazing patent will occur that's worth
you know 50 million euros or a Swiss
francs or what have you but it's pretty
unlikely particularly it's not so
unlikely in biotech but in our field
it's been remarkably unlikely so you end
up with massive amounts of people that
are out protecting each other against
things that essentially never happen and
it's it's it's it's really silly and our
attitude is we'd like rights to it we
don't want to own everything we'd like
it all to be public will depend upon our
you know first mover advantage if we can
get that if you know because well what's
going on will move quickly we're pretty
agile we have some scale and a good
brand we prefer grants with up contract
and we prefer open-source kinds of
publication and distribution and that
works best for us and of course we're
interested in your feedback so that's
that's we would prefer so conclusions
and then I'll take a few minutes worth
of questions I think we're vibrant we're
non-traditional and we're proud of them
we have uniformly strong talent across
the team so what that
one of the benefits is we should be a
consumer of you know one of your
products which is important for you I
mean I think Google must do something to
raise enrollments the fact that we exist
and are a good place so hopefully some
people are going into computer science
with the hope of coming to work here or
at least that thought in the back of
their mind so we're dedicated to hiring
a lot of smart people and with a blurred
boundary between research and
engineering we will however we organize
ourselves that will publish we part of
the greater community and will provide
opportunities for people with the
benefits of both research and
engineering that's what we'll tell our
employees and I believe that's true that
is consistent with my own what I
personally believe where I've had fun in
my own career whether it's programming
or writing papers or leading and
research ideas I think we can provide
those broadly to lots of employees I
hope that will benefit from our mission
and delivery model and will attempt to
use our capabilities to foster
relationships with academia for mutual
benefit so I want to thank you and let
me see if there are any questions that i
can take seem to be hands popping up
quickly so i'm going to go from left to
right since i was standing over here I
apologize to all of you on this side but
the click button was over there yes oh
you have the mic oh well that settles
out okay and who's in control not i I'll
take control of that don't know thank
you very much that was great talk I'm
Wendy hall from the University of
Southampton's great talk do we get
access to the video that's not my
question but do we what so I was
interested to hear what you said about
your people in publications because your
founders of course published their key
algorithm in the world wide web
conference and the growth of Google was
hugely synergistic to the growth and
even hugely important to the growth and
evolution of the web the two are very
very synergistic and I was very
interested to hear what you said about
the deep web and indexing that and so
I'm interested in your comments on the
evolution of the data web or previously
called the semantics where
and encouraging people to use the
protocols semantic web protocols that
are being developed and how you see that
may be rolling out over the next five
years so all right this is a Semantic
Web question primarily am I still on
over here ok so the ok yep I should be I
should prove that I'm courageous and I
can stand next to the questioner ah so
I'm really first I'm not truly an expert
in that as you know I'm a humble systems
programmer by training but but i've had
i've been interested in text analysis
and quite a bit and particularly when i
had been at IBM the perspective of i
think most of the folks in the community
that that google is a part of that IBM
research was a part of and that are
looking at how to extract information
from the web is that it's going to be
very hard to come up with ontology that
everybody uses for describing their data
and that in my in my view I mean
certainly the initially initial kind of
goals of the universal ontology I I
don't believe in that it just doesn't it
doesn't make I think early early on it
was more in your right and you know
notice how i said this europe on it had
that ring to it and it's become much
more relaxed in my judgment over time so
i think what what we would like to see
and i'm not deep enough to answer the
question probably as deeply as you want
as i would like to see a lot more
metadata associated with information ok
and how that's created is and how its
generated whether it's generated in
authorship time whether it's generated
by machine learning technique
I don't really care but I would think a
lot more metadata is valuable and
frankly we can deal with metadata and a
lot of formats we're not afraid of you
know of looking for it in many ways we
have to deal with spam metadata of
course because a lot of people will add
incorrect metadata for negative purposes
but I think that would be extremely
useful so we we are interested in like
the pragmatic ideas behind the Semantic
Web and some of the less pragmatic
things that are going on I think
probably don't make too much sense to us
but beyond that I think you'd have to
talk to some of the really deep thinkers
at Google like Aloha Levy and others
about this and and get there get their
perspective all right and I don't know
if they're there other people here today
but be happy to put you in touch with
them yep okay to give could you announce
your so i have to come over that way
next I apologize but it's working we
hear you
I'm really sure Google two huge place so
I I don't actually know I would tell you
we are generally I mean in general we
are worried about what people will put
on on information whether will be
annotated accurately and to a large
extent the culture of Google is to learn
what we can from the base data from the
base material that seems to be the
predominant culture of the company is
learning but I i think it's it's
inevitable there will be more metadata
that is that is generated and stored and
used and and I think we have to be
supportive of techniques to do that we
do have to think about how to make sure
it's reasonably accurate okay I had a
question over here but I've got to take
you've got another Mike great
yes your honor and who are you could you
name your name and weave them
you
sure we want to do better on many fronts
and we are always trying to do better we
are greatly increasing the amount of
information that we have available so I
don't actually know the percentage I'm
not sure if we publish it or not but I
do know that the amount of web data that
we have has grown enormously over even
the last couple of years so I think we
would like to index everything so we
like that idea right the universal is in
our mission statement we want to do it
more more quickly so we would like to be
ever more rapid in recognizing change on
the web but we have to do that carefully
as well because there is after all no
atomicity model in the web that says you
know you don't want to get things that
are partially updated or that are
inconsistent and such so we have to be
clever about that as you get faster and
faster you'll come up with more if you
will consistency anomalies in the system
so the combination of those things are
very interesting projects for us
you
you're not on anymore but this is this
is the second use of this conference
room tell you from stand-up i dono must
work someplace the idea is good cook
will be listed in the ranking of let's
say pages so that you don't have to
crawl all the time all the pages around
the world that's the point so I I'm the
Guru of search quality there are people
in this room that could probably answer
that question better but I think if word
predicting is in it and you know
learning from past behavior something
about future behavior we're interested
in almost any signal that we can find
that would make results better so if
there's some signal out there that would
enable us to do less work and to do
something better I think we would want
to consider that and I you know whether
that specific thing you mentioned I'm
not sure there's enough detail to really
know exactly what you've said whether
that would work but but we're interested
in any manner of signal that comes in
okay so next question mark
it's interesting it guess it doesn't
work below two feet or something alright
so when we make dat available this is
this is a great question it's really a
terrific question i was on the might
audible no that doesn't work okay
alright so i see well alright whatever
the three here i I'm a systems person if
you have three something should work the
probability of one of them not working
is I assume they're independent failure
modes of course so so that the question
is data and I think it's a great
question and it's something that as a
community in addition to google we have
to think about this so i was on the
phone with randy Bryant i would say
about a year almost a year ago this is
when I was kind of retired and staying
at home with my kids and we're having a
discussion about about this cluster
computing and CMU and and randy said as
the Dean of the school at CMU and a
smart cookie he said gee you know we
really need a cluster because you know
we're going to be left behind and I said
and he was talking about it at the time
frankly more from the perspective of
computation and I'm not sure that was on
purpose he may have been thinking data
as well but I kept bringing up I said
you know it's really going to be every
bit as much about data you know bear
computer without a lot of data is maybe
going to be useful for some research and
machine scheduling if you come up with
some benchmarks or something but it's
not really going to be that good without
a knowledge of what real computer
programs do on them so we've been
talking about this we just actually had
a discussion again because now as we're
making available you know some cluster
computing in the states and hopefully
here soon
Oh where's the data so first is we
clearly have a lot of data but you know
what it's not exactly clear to me I've
been at Google three months how easy it
is to make it available for example
privacy issues contractual issues are
big so i think it's a it's it's
problematic i regret to say that in fact
i gave a version of research at Google
and slightly different versions not very
different to an internal audience
yesterday and the same question honestly
came up saying well if you really want
to work with people in the university's
you have to give them data so it may not
be that so that may be true and I think
we have to think more about it and I'm
taking back and so far I have for action
items from this trip I hope not to have
very many more but one of them is to
really try to convene a group in Google
to think again about what we can provide
on data the second is what we can do to
help universities and research groups
aggregate data on their own so you know
should should someone on the cluster be
doing a crawl that we provide if we
provide cluster computing should someone
do a crawl no it won't be as good as a
commercial crawl from one of the big web
search companies it's just not possible
but if you did somewhat of a crawl you'd
get a lot of data I think we what we
provided there's some Wikipedia stuff we
can provide when we do the cluster but
that's that's relatively small in
comparison to even a modest crawl the
web so it's it's a very interesting
question and I I don't know it's a work
in progress but I hear what you're
saying and I think you're correct okay
what may give you this dick
okay so i think i think we understand
that point so just in the interest of
time I'm not afraid of the point you can
keep bringing it up but I think I mean
if I if I brought up the point that
machine learning is important and will
do certain things in this and you
brought up the point that you need data
I think that's it is clear so let's make
sure we use our time as effectively as
we can yes
what are the main challenges perceived
at Google what are the main research you
single or the main challenge is in peril
and distributed computing yeah exactly
i'd go with specific person well so i
mean just so some of these that come up
11 is efficiency right efficiency is a
big deal in very big centers you know we
worry about our carbon footprint we
worry about the cost of capital so the
efficiency of how these systems run is
an interesting topic and I use that word
carefully because efficiency could mean
how do you manage the processor speed
how do you manage the amount of memory
how do you structure disk to to
processing requirements how do you
allocate jobs how do you worry about
issues of you know loaded caches and and
you know stickiness when you want to do
the same thing in the same place how do
you worry about appropriate replication
across sites but that provides high
availability and high integrity so
there's a whole question rep there is
and I think that when one of the things
we've observed and I think it's true in
systems research that a when you go one
or two orders of magnitude and scale
it's often a qualitative difference and
to that and I think you'd agree I've
always believed this as a CMU professor
as well that when you're forced to solve
a problem in reality you're forced to
solve in many cases a broader problem
then you can when you have to solve just
one one axis of it so you know so many
systems papers over the years solve the
problem but ignored security and then
when you think about security in it the
solution is really much much harder
where you think about manageability
another thing is is this notion of
manageability of systems right as these
systems get bigger and bigger you really
need to make them ever more automated in
their management and for example that
relates to a performance management as I
mentioned earlier
so you know what I think I would get to
I think I could prove to you on the
system's researcher because i think i
would give you back all of the systems
problems that you probably already know
about and and so i would probably pass
my systems qualifier still which is a
good thing I wouldn't pass the program
in qualifier I regret and I could not
get a job as a programmer at Google
quite sure but but what I think the
issue here now is apply these two
problems at scale under realistic
circumstances okay oh yes question thank
you very much on a couple of occasions
as a topic for for future research so
I'm quite curious as to what you think
the major software engineering
challenges you're you're facing and I
perhaps I ask that also in the
reflecting on what something I caught of
the tome of the comments in the earlier
talked yesterday where is it where you
know specifications and gantt charts and
such things where we use the perhaps to
get a cheap laugh would be too strong I
was going to hide wait we need a bigger
lectern so that the speaker can hide in
the future let's just make a note of
that here so let me answer the quiz on
where in gineering community has to
recognize there is to date quite
honestly a divide between two modes of
thinking one is this agile programming
thought of rapid prototyping and
iterative refinement done by small teams
and assembly and without the sort of
rigorous waterfall esque even you know
with appropriate you know refinement etc
waterfall I know is a terrible word
everyone but frankly it's the
engineering way and in most things with
specification analysis of use require
all these things I think we we have to
recognize there's a
I was at a mother national research
council conference talking to the US
defense industry that is a you know
great proponent of traditional software
engineering methodologies because they
have multi billion dollar multi-year
programming efforts and for you know
real-time control systems for fighter
planes that are working with other
systems and it's it they don't
understand how Google can produce
something in you know three person years
and six six months of time that we can
put on the web that works rather well
they just don't understand it doesn't
doesn't make sense so people are looking
at fusing they're clearly good ideas
about get a team that doesn't know it
can't be done frankly tell them they can
do it don't bother them too much because
if you bother them they probably won't
work as hard let them go do it and then
keep fixing it versus let's get together
figure out how to do it right and and
I'm really torn among this quite
honestly I was involved with the andrew
file system project and had the chance
to distribute AFS to about a million
users in the 1980s and early 90s so we
had a million people on a global file
sharing system and my judgment the
project failed as much for its inclusion
of security technologies which were well
thought out carefully architected done
by computer scientists as as anything
else and the reason for that is that the
web came with no security and anyone
could go install it without having to
get security approval and our system
because it had security required
security approval and that meant that
you went through you know a strong an
Alison people started asking security
questions and you would rather them not
be asked you wanted just people to pool
data now the way the way I've had other
advantages as well and I don't deny them
but frankly the over-engineering if you
will with good goals and I'm partially
responsible for that may be mostly it's
a very interesting problem so I think
there's some fundamental questions in
the design of systems that we don't
understand
I i could go on on this for a long time
I'd be happy to talk to you because I
thought a lot about it and I'm I'm
really at a loss to know what to say it
you know coming into Google part of me
wants to say gee we should be a lot more
rigorous and we need more top-down
control and whatever and part of me
looks at the effect of that in so many
places and sees the results have been
unsatisfactory okay I probably have time
for one more question okay one more
question right in the middle let me get
working and encourage people to sit near
the speaker thank you I'm attickson are
inferred from Susan C Chilton Berlin
also about University Berlin I'm working
on disability and parallel computing and
listening to your talk you said about
scalability availability and such things
I was missing one buzzword that is
peer-to-peer computing it's google not
interested in peer-to-peer computing
technology at all and if so why you seem
to hop over peer-to-peer computing
starting with cluster computing would
within your data centers and now you're
at the new big buzz word cloud computing
that some that's the same word that's
the same basically exactly so you're
missing peer-to-peer so I I would like
to just so I'm not exactly sure I'm the
best person to talk about this one
either but to me peer-to-peer means two
things so what it means first is is what
experience to users get right can users
share things with each other do they
have at the usage level does it appear
like a community does it appear that any
user can do something with any other
user and the like all right and I think
Google is extremely interested in that
you know we operate some of the largest
social networking sites in the world in
Brazil and India where the absolute
leaders in that and and we we are
strongly believers if you know I mean
whether it's gmail or instant messaging
and a variety of things we're strongly
believer that our our geo location
service that occurs on cell phones
is benefiting from the knowledge of
where peer telephones are to tell us
where our phone is so we're very strong
believers in that so then the question
then becomes an engineering question of
the engineering question is where to put
the processing right does the processing
occur from my computer as a server
that's a repository for my neighbor's
data or not and I think that's an
engineering question as to when that
makes sense and when it doesn't make
sense and I'm I'm not sure we have I
would say we have no stand on that as a
company we have a stand on doing the
right science and engineering I will say
and I did say earlier that if you're
looking at data aggregation topics
having the data at low latency to the
processing tends to imply some degree of
virtual centralization so if if you are
interested in organizing the world's
data you have to have a lot of it near
the organization structures that are
processing things it's very difficult to
do MapReduce across I mean technically
it's feasible but it's hard to do
MapReduce across the internet so that
would be my answer so so I really think
Pierre computing peer-to-peer has to be
broken into two parts right the function
that we provide to users and anyone
that's not interested in peer-to-peer in
that level is foolish and then it's at
the implementation level and this is
look systems is distributed systems
these days that's what it is so we're
the right places to put function okay
thank you so much for your time and your
questions let me pass this back to our
fearless now what do you do you did dumb
what was the name of your topic
yesterday house keep house key let me
pass it to the director of housekeeping</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>