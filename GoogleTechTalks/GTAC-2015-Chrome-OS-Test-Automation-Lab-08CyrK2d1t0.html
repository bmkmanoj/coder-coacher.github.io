<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2015: Chrome OS Test Automation Lab | Coder Coacher - Coaching Coders</title><meta content="GTAC 2015: Chrome OS Test Automation Lab - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2015: Chrome OS Test Automation Lab</b></h2><h5 class="post__date">2015-11-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/08CyrK2d1t0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and to end our gee tac we have one last
talk on test automation for Chrome OS
and partners by simraan and Chris thank
you so yeah so my name is Chris Sosa and
this is Simran bossy we're both software
engineers on the chrome OS team today I
really give a talk on test automation
for Chrome OS and before we start we can
give it a sort of quick outline of our
agenda so we were to start to talk off
talking about sort of what chrome OS is
and sort of the history of Chromebooks
and chrome boxes then I'm going to
follow up with sort of an overview of
the continuous integration that sort of
required to support the active
development for Chromebooks next serum
is going to start gaming overview of
testing and go into life of a test and
finally we're going to finish off with
some of the requirements for our
partners who test Chromebooks and chrome
boxes both before and after they give it
to us as well as mob lab which is a
product eyes version of our test
automation services so before I start
going too far I want to sort of remind
everyone sort of what chrome OS is or
for those who don't know tiger for the
first time so Chrome OS is a linux-based
distribution that powers Chromebooks and
chrome boxes it was first created by the
chrome folks who sort of wanted to apply
the three tenants of the chrome browser
to operating system development those
three tenants are speed security and
simplicity so for an OS speed means
fastboot best performance security means
being able to apply you know zero day
patches you know within a day and
simplicity means you know basically
getting the OS out of the way like you
know you shouldn't be aware that there's
a bios running you shouldn't be aware
that Linux is running underneath and
most people don't aren't aware so quick
history and sort of
to understand the scale of the problem
we open source in 2009 we shipped our
first Chromebook the cr-48 in 2010 since
2010 we basically ship 2x more devices
per year so at this point we're actually
shipping over 50 distinct Chromebook and
chromebox variations across multiple
architectures like x86 and arm and
various reference boards in terms of the
develop the development community we
have over a thousand check-ins per week
not per day I made that mistake and
across hundreds of get projects and as
part of supporting the three tenets of
chrome one of the most important things
is sort of keeping all the browsers and
the operating system up to date so we
actually support then you release every
six weeks to all Chromebooks and chrome
boxes in the field in fact the cr-48 is
still shipping i guess chrome 47 at this
point so like a development model does
it take to support this you know being
able to ship everything you've ever
shipped on physical devices every six
weeks is a pretty difficult problem and
on top of that we actually have active
development and all parts of the stack
so we have our own linux distribution
which means we have a kernel team that
does active development on the colonel
so as some of you may know i got curl
kit change could very easily brick a
device and we've actually so far not
bricked any devices so that's good and
then in order to support this and then
sort of do this right we sort of taken
sort of this continuous integration
model that a lot of web app developers
have which is basically keeping trunk
and it always a very good state and
apply that to operating systems that
means we actually have a submit queue
that gates any changes that might break
or brick any Chromebook or chrome box in
active development which is I guess all
of them right now because we still
haven't hit the five-year cycle on the
cr-48 so so yeah so trunk is always in a
near shippable state our branches are
only for stabilization all feature
changes and all bug fixes must land on
trunk first
and before we talk about test automation
12 gave it give you a quick overview of
the build system because that sort of
gives you a little bit of context about
the test automation so we have a cinema
queue as I mentioned we actually do some
building and testing on all 50 variants
in the submit q we actually do physical
device testing as well as emulator
testing so we actually have to pick a
side right we have both physical device
testing and emulator based testing and
emulator based testing helps a lot with
sort of getting things fast and things
quick physical device testing is added
on the submit queue to sort of help and
it adds a lot of coverage we also have
release builders these sort of do for
Canaries a day and they do a longer set
of testing because the requirements in
terms of time aren't as intense like
submit Q gates developers from checking
things in so that's got to be done
pretty quick and so we sort of aim for a
ninety nine percent coverage on the
submit queue and if we leave the one
percent of slower test to our release
builds and we also have try bots which
are basically an infrastructure service
that allows you to sort of emulate any
of our bots that do bills or tests so
that developers can sort of like hey my
submit you failed I don't really quite
understand I don't have you know hey I
cr-48 on my desk how do i reproduce this
hey want to try bots and he'll run both
the build and the test in our physical
lab as a point of reference we use bill
bot which is an open-source waterfall a
contingent aggression service in fact
actually all of our infrastructure is
open source because all of chromosome
sourcing we sort of inherited that sort
of being part of chrome so trunk unlike
some other open source project is
actually open source so all of our
development is always in the public
except for some small repos some all set
of repose and yeah most of the team
interacts with our build system either
through our code review system like we
post breakages in the changes you upload
or on the bill bot web UI and this is
actually a quick view of what the build
wat waterfall looks like all the columns
are basically specific builds
bill bot wasn't really meant to scale to
have lots and lots of builders on the
same view so this actually Scrolls a
very long way to the rest but we do have
some quick overview on top to sort of
give you a high level view and in terms
of what a bill does here's a quick
diagram we seek we build and then we run
a bunch of different testing services in
parallel including physical device
testing which actually leads us into the
the actual meat of the thing where we
talk about test automation on physical
devices so before I hand it off to
Simran i want to show you sort of a few
pictures of our automated test lab so
our automated test lab currently
consists of about twenty four hundred
different Chromebooks and chrome boxes
right here you sort of see a lot of I
believe Alex devices which are device we
ship four years ago and one of the
interesting things to point out is that
this thing here looks like a nice
exciting mess that's actually a debug
board that we have installed on every
device so one of the problems you get
when you have thousands of devices under
tests is unless you want to hire a lot
of people to go there to physically
bring them back up when they break like
you need some sort of automated solution
to actually automatically repair them
this is only a big issue if you're doing
platform testing because as I said any
colonel change can sort of brick a
device and you know not every developer
on the on the team has 50 devices at
their desk that would be kind of crazy
so we need some way to sort of
automatically repair them so these debug
boards are actually connected to all of
our Chromebooks and chrome boxes through
a debug header and it's able to sort of
simulate the read the automatic repair
flow that if a consumer actually had a
bad machine because you've either a
small bug or something that would
activate this so the the bug board is
also used for other development features
so it's used for battery testing and
other things we actually sort of share
it with other development teams
especially on the lower end like
active development on the BIOS and then
and these two pictures that we show sort
of whatever X looks like before on the
left before we add devices and on the
right actually so Chromebooks and chrome
boxes actively depends on you know Wi-Fi
connectivity for for use so we need to
find a really good way of doing
functional and regression testing with
Wi-Fi and Bluetooth and so these are
actually RF isolation chambers and they
do all of our functional testing they're
a little bit expensive so we try to keep
and mock out as much of the the Wi-Fi
parts as possible but they're actually
capable with these we're actually able
to sort of automatically and
programmatically emulate the change of
distance if you're actually the move a
device further away from a router and we
actually have both routers and
Chromebooks and chrome boxes and these
things so with that I wanted to hand it
handed off the Simran talk about her
test stuff so testing and Chrome OS is
done with the audit by a fork of the
auto test testing framework auto test
was originally designed for linux kernel
boom work and we kind of forked it for
hardware testing now the reasons we
chose out of the test is because it came
with a bunch of things we knew were
again need off the bat the start where
that gave us host in job management we
have this lab of 2,500 devices and we
need a simple way to like manage each of
them look at their state see what
they're doing at the same time manage
each job that's running so auto test
gave us all this off the bat it gave us
a test scheduler to match to make sure
that test actually ran monitor status
and give us results it came with a web
frontend for all this as well so that
made it easier for us to get this up and
going and it came with a number of other
services that we ended up using all
right so let me talk a little bit about
the different kind of test coverage we
do now the most standard tests that we
run the most often is our build
validation tests we call it the BBT and
pretty much it does regression testing
now this is our this is really important
to us because our submit Kia
canary builds everything runs the bb2 so
any time a developer wants to submit a
change to Chrome OS it has to pass all
our basic set of regression testing
before their change will commit to the
tree this is how we keep Chrome OS as
green as possible then we do actual
build a full builds everyday of all the
changes that landed and that also runs
the BBT if the tree goes red we stop
submitting changes and it lets us fix
everything up for developers next we
have Chrome OS release tests so whenever
we want to do release um we have people
on a team they choose a release and then
we run a series of tests against the
specific build the release testing is
how we has to be done before we release
anything and a good example of this is
our auto update testing we need to make
sure that any update that we push out
can also update bet on to a new version
should something go wrong without that
we will break devices and that would be
terrible I'm actually a powered test so
we can actually remotely turn off the
power AC outlets to all the different
Chromebooks and chrome boxes and that
allows us to turn off the power and run
it stress Wi-Fi testing and all sorts of
testing to see the life of the battery
how long did devices last and this
because this is a pretty big important
part of selling laptops next we do on
hardware component testing so because
chrome OS we manager software stack and
Google's very closely tied to our
partners so any components a partner
wants to put in the new Chromebook there
has to be on our approved vendor list so
a good example this would be internal
SSDs will actually do component testing
and try burnet SSD and see how long it
lives and make sure it's going to be
good for a Chromebook and lastly we have
fully automatic firmware tests so inside
each Chromebook is the chrome embedded
controller and the firmware test ensures
that it can do all the stages of
recovery and all the basic BIOS level
stuff that we expect a Chromebook to do
so I'm going to go over the different
servers we have in the lab and pretty
much a life of the test so when a user
wants to create tests essentially either
through our web front-end or or through
our suite scheduler
our goal of proxy tests can be created
so individual developer can request the
test to be kicked off our suite
scheduler runs our very slow test
regularly like a nightly test or a
weekly test and schedules are ensures
that it kicked off and our builders
which Chris went over before once they
have placed a build into Google storage
they'll talk to the proxy to kick off a
job now pretty much our RPC proxy just
takes this request and translates it
into a database entry it says Alan or
run the BBT for on this build for this
device which could be like a samsung
chromebox i3 for example and so once
this entries in the database our
infrastructure knows that it needs to
get gone run this test this is where our
host scheduler comes in so we had these
2500 devices they're all in different
states at any time the key to be ready
that can be running a test they could be
verifying for a new test or a bad state
would be repair failed where our
automatic repair processes didn't work
and this device should not be used for
testing so the host scheduler looks the
database and sees what tests need a run
and it will say that the BBT I suggested
earlier one is Samsung chromebox I three
and so it will look for a samsung
chromebook sy3 that is in the ready
state and assign it to this job at this
point the scheduler is will now see that
this test is ready a run it has a host
it'll actually go through the process of
scheduling this come kicking off this
job and monitoring it now the scheduler
is probably our most important part of
infrastructure and it launches a test it
aborts jobs that might be hung because
they all have a timeout you the job gets
stuck for 24 hours that means it's
wasting resources and device so it needs
to board jobs it also mine just all the
different other servers are actually
executing tests so earlier when I was
talking about auto test we actually
support two different types of testing
one type is called server-side tests and
these are test to actually run the
server and manipulate a device the most
basic way to most basic tests that would
be a reboot test it would the test
actually runs on our drone servers and
it would tell a device reboot and it
ensures that the device comes back up we
would do this like 10 reboots and make
sure that the device comes up every time
now the other type of test that we roll
we run is a client-side test
this is a test that actually execute on
the device but the drone is still
responsible for kicking off that process
amount entering it ensuring it doesn't
get stuck so the drones are actually the
server start kicking off monitoring all
our tests now like Chris is going saying
earlier all our builds are done on our
builders but we need to store them
somewhere so when a build is completed
is put in its place into Google storage
so that way our lab has access to it as
well as our developers Google storage is
just a big back-end that you can put a
bunch of files if you're not familiar
with it now because of all the traffic
and all the tests are running if we have
20 different Chromebooks try and
download the same image off of Google
storage will kill our labs network
bandwidth so for that we develop these
new servers called dev servers they're
essentially a cash up to Google storage
and we'll pull the image into the lab
topology and store it there for 24 hours
the other thing the dev servers do is
they actually emulate our normal update
Omaha servers so that way when the
Chromebooks are flashing and installing
a new image it's as if they're actually
going through the normal update process
your Chromebook would normally do in the
field so if for my previous example we
build their kicks off a test it will
actually the device will now download
that build from the dev server which if
it's not there we'll get it from google
storage and an update before running the
test after after the tests have R and we
actually upload all the test result
isles back to google storage this way
it's accessible to us and all the
developers who need a steel logs should
something fail we actually save almost
all our test results for the last six
months so if something goes wrong we
have something to compare against lastly
we we need to keep scaling our lab keeps
growing at by the exponentially with the
number of devices so for this we have a
concept of charge which allows us to
continually just add shards and let a
scale well hitting our limits so I just
went over that the topology of our lab
and we have all these different servers
and they all work together and if I was
to write a test I could write a test to
interact with the dev server the drone
the scheduler the database to get
information and it gets really difficult
for our external partners to replicate
this should we
find a failure and they need to stay do
create to help fix the issue so we came
up with the idea of mob lab instead of
having five servers it's a single server
that includes all those services and
replicates our lab pretty much the
reason we needed my lab is because of
the time it take your doing hardware to
bring up in the time it takes to to go
back and forth between us and our
partners in Asia could take a long time
for example a proto board is built they
send us the board takes seven days to
ship has to get through customs then we
find an issue and then we have to tell
them and then they do another run and
this just adds up so it lets them do the
testing and replicate our lab on their
end and then they can arm our testing is
now scaled out to our partners as well
and it allows us to ship devices faster
which is good for Google and good for
hardware partners so what is mob lab
exactly so essentially what we did is we
took the basic chromebox image and
installed all the different services and
services we required to run our allowed
infrastructure and from there we added
all the logic to initialize and
configure everything correctly simplify
to make it as simple as possible so this
includes the patchy web server with the
web interface the same database
structure that we use Python the dev
server code that so they can download
images from google storage that's
actually really important because when
we post images now for they can actually
download them and test with the same
exact images that we produce and then
includes all the other services that
I've mentioned before now the great
thing about it is it's actively
developed by us and whenever we do it
updates the test framework we can auto
update and push this out to our partners
and it's also cross platform so these
are a couple basic examples of what are
different partners might want to do OEM
and odm are the people who are making
the new laptops and they want to start
running the BBT on a brand new board is
great would be a great way for them to
verify how the hardware's doing they do
stress testing they might want to do the
power load test before they choose a
battery and they also want to make sure
that the farmer is correct and that's so
Steve ender like Intel I want to try
different kernels or do regression
testing against new kernel changes or
generally they make a reference board
that they actually don't ship a
Chromebook
other partners like Dell or HP will
build the Chromebook around hardware
component vendors they want to sell
their there are different components to
OMS and they can't unless we approve it
so by giving a model app to say like
sandisk they can do SSD validation send
us the test results because they go back
to Google storage and we can see them
and we can say whether this new part is
valid to be using Chromebooks and lastly
BIOS then there's want to make sure that
their BIOS works with our firmware so
the benefits of mob lab for our partners
is it's really easy a set up pretty much
data take a chromebox put install the
image and everything should set up
properly it's a common test framework
the great thing about this is should we
find a failure we can just tell them
what tests to run and they can reproduce
it at their site before it if we try to
do with our workstation versus their
workstation different setups different
operating systems they might not be
reproducible the faster debug cycles now
that we can easily do these reproduction
is a great benefit to everybody involved
well these partners also get all the
tools benefits that we got out of auto
tests because they can manage all the
different devices they have as well as
easily kick off the tests and like we
said it's auto updated by us and the
really great thing is it's open source
if they have ideas or changes they want
to do they can create a CL and change it
and upload it for us to review and it'll
become part of the mob web platform this
is a example of a lab setup that a
partner might do so the chromebox in the
middle is the actual model of device and
we only have a few requirements to get
it going one is internet access because
a lot of these factories are based in
China that might apply mean VPN access
so that way they can access google
services the reason they need to access
our services is one for google storage
that's where our builders will give them
the images they can test and two they
need access to the au service or should
there be an update they can actually
download the update and get the new
infrastructure that we've been building
next on the side you can see they we
have a test subnet and pretty much we
just add tell them had another ethernet
interface and in a door switch and you
can hook up all your test devices there
and our system knows to test those
devices on that network and then from
their own corporate network they can use
their own laptop and kick off the test
now Chris was showing you guys early in
the photo that serve aboard we actually
give these to our partners so that way
they can run our full suite of tests and
that also is supported with the model of
setup so if should their devices also
need to be repaired they can
automatically happen so beyond just
chrome OS model has been applied to a
number of other platforms on hub
actually did all their testing by using
ma blood devices they even created a
quick lab at a couple mob labs and
they're able to get going brillo which
is going to be Google's Internet of
Things platform is going to be supported
by mob lab and android support is coming
up as well some additional features that
that mob lab gives you custom OS image
support so this allows our partners to
actually do their own custom images say
they want change the kernel version they
can actually create a whole their own
custom image and with the new kernel and
then they can actually run run all our
tests against it custom test support
they can write their own tests and
before they even submit the test into
our tree they can test they can run the
test and make sure they work and
validate it private test for positive
support so you can actually keep your
test outside of our open outside of our
sources and still run them this is great
because holub is open source or model
ebbs open source but on hub was not so
there's tests or closed source we
actually have virtual machine support so
to look make it easier for people to get
my lab setup and we actually have a a
tool called mob monitor would simplify
set up and lets people know when things
go wrong ah anyway as a summer than I've
said Chrome OS is sort of based on
chromium OS this is a fully open source
project do you have any more questions
there's your Disqus lists feel free to
send email all of our documentation is
online and our fork of auto tests is
actually also publicly available so feel
free to check it out any questions
thanks guys so what kind what type of
bugs do the real device has fine that
emulator tests don't Wi-Fi bluetooth
those are things that are hard to test
them a lot of colonel bugs actually it's
a lot of colonel Boggs um there's a lot
of stuff with when you have the the
emulator like the touchpad is emulated
so any kind of touchpad regressions you
have you won't have it it's part of a
you could theoretically like fix this
problem by re-implementing all these
cert the low-level device driver stuff
to also work in the emulator but
basically we usually don't because it
requires twice the amount development
work so anything basically low level is
not cop of the emulators greater than
100 get repos question how are those
synchronized do they depend on each
other ahead our branch is required
perhaps for different hardware chromium
versions so our community creates a
snapshot of the repo manifest so we use
repo which is basically a way of working
with a bunch of other get projects to
sort of collectively have one giant
source tree Android uses the same thing
if you create a snapshot of that it
might flags all the hashes down and so
you basically have a fixed version of
trunk so that's what dr. McKee uses and
for any releases we always generate a we
always generate a snapshot that we
actually distribute to all of our
builders building the same cane canary
at the same time so that that's how we
get around that how many bugs appear
only in physical devices versus passing
and emulators a lot of them
I mean so the thing is emulators if you
think about it we have 50 variations of
Chromebooks and chrome boxes emulators
cut down that amount of variation you'll
see and test quite a bit they're really
good like if you have like a regression
in the browser say like Oh emulators
will catch that almost one hundred
percent at the time if you have anything
that's like a low level service talking
to any kind of other level service and
later is not going to catch it and so
the thing is emulators like usually
prevent those catches ever from reaching
the hardware test because we kind of
have a tiered system testing so like
it's kind of hard to say because I have
to look at only emulator changes versus
only physical device changes but I mean
they're both very valuable is the most i
can say without spending a long time
looking at all the logs awesome test lab
but 2400 machines Wow any thoughts or
plans to streamline the number of
machines for tests it's just gonna keep
growing so the opposite yeah I think we
have a set number that we require for
every new device yeah we have a set
number and a lot of it sort of up to the
software well I guess we're all we are
the same team but a lot of its up to
submit basically how we choose to
develop right because we have a unique
image per device the software is unique
per device because we're trying to keep
the image as small as possible to make
sort of keep the speed tenant and chrome
it's really hard like if you were to of
course have a lot more generalized
drivers that applied equally you might
be able to get more coverage without
having all the devices and we're
actually thinking about potentially
reducing the number of devices we need
for follower devices so usually with
kind of device development you have a
reference board that has most of the
drivers spect out but then individual
partners might say change the they might
have the exact same thing from another
partner but since it's an i5 in 793 in
those cases we can use a lot fewer
devices in terms of like the fact we
really don't want to brick anyone in the
field we do want a small amount of
coverage at least but we can definitely
get away with fewer
have you considered something else to
manage the test lab instead of auto test
for example beaker project org used by
red hat in fedora we've looked at other
frameworks but we're kind of selling
grain taught a test that you kind of
step with it yeah we're pretty open
minded but a lot of our especially since
we're both terrific tues integration
team a lot of it a lot of our work has
been scaling out auto tests and a lot of
the services we built our in the fork of
auto test we use and so like we for
example simran talked about sharding
which is basically where the big
problems with auto test is that it
schedules everything on one thread and
like when you have 2400 devices running
you know hundreds of thousands of tests
you know one thing I can only do so much
and so we've actually distributed and
shorted out the work of like matching
host two tests which we probably are
looking at to upstream but we haven't
yet so we're definitely open to it and
auto test is a great framework it's not
perfect so we're always open to look at
other things how do you do battery tests
so we have these are big power outlets
to actually are running Linux and each
our lab topology is set up so each
device is plugged into the correct
outlet so a server-side test is again
like I mentioned before can request a
turn this device on this rack this rack
this row off and then the power will
actually be disconnected and then the
end of the test we do cleanup let me
assure that the power is restored but
pretty much that's how we can kill the
kill the AC remotely and do the battery
testing
how complex do the power tests for
battery test cat for example is the
battery duration tested while watching
videos playing html5 or JavaScript in
tons of games and you ever open bugs
against chromium for just decreasing
battery life I'm not too sure the
specifics of the power test to be honest
yeah so our software model is to have we
provide the infrastructure individual
developers on the sub teams do all the
the actual testing so the power team
would be able to answer that question a
lot better well we are now out of time
so thank you very much guys thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>