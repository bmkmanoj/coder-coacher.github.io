<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Genome Assemby, Chinese Postman, and Virtual Clusters | Coder Coacher - Coaching Coders</title><meta content="Genome Assemby, Chinese Postman, and Virtual Clusters - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Genome Assemby, Chinese Postman, and Virtual Clusters</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-m7PFnSvmJM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yes about my new work in genome
assemblies and Chinese postman and
virtual clusters which is a hodgepodge
of several two completely unrelated
things but I decided that given that the
crowd here will could be from ever
absolutely every walk of life not
necessarily interested in biometrics per
se I can do something a little bit
strange and surprise you so let's skip
the slide so first I want to start with
a one slide introduction to biology just
in case it's been a while since your
high school biology class or when you
took high school biology they didn't
know about DNA yet so this is a coming
from US Department of Energy so it must
be right but the basic idea is that your
your body is made up of cells so they're
winter sir thank you
thank you so your body is made up of
cells and these are the basic building
blocks and inside your set each of your
cells there is this thing called the
chromosome there are many of them
chromosomes and chromosomes are DNA
that's the basic building that's a basic
code for all life or at least all life
that we know off and DNA is this nice
double stranded helix which has pairs of
letters which bond to each other and
these base pairs there are four of them
AC G and T and C always bonds to G and a
always bounced to G and from this DNA
you make proteins and proteins are the
stuff which actually do things they help
yourselves do what your cells do they
help you digest they help you use your
muscles they help you
you have your communication with neurons
and so on so in this talk it's on this
biological front we will talk about
whole genome shotgun assembly and whole
genome shotgun sequencing and that's the
idea of how you figure out what the DNA
looks like so your genome it's this
really really long molecule it actually
has three billion nucleotides or bases
and you want to figure out what it is
but we don't have technology which will
actually take the DNA and tell you here
are the letters in it the technology
that we do have it's it can sample
really short pieces from the DNA and
give you the sequence so these sequences
are called reads so given a three
billion long genome we can get lots and
lots of 500 long pieces and you can see
a half of the pieces are red and half
are blue and this actually implies that
they're coming from different sides of
the DNA remember DNA is a
double-stranded helix so there is one
side the red and the other the blue and
they're actually oriented opposite to
each other once coming from this end
one's coming from that end and you can
get all these pieces and now the job is
an assembly program of an assembler is
build what the genome could have looked
like so this requires you to figure out
which pieces of the DNA go together
and that's basically a sequence
similarity sequence alignment and that's
a pretty easy computational job and just
what you do is you throw a lots of
hardware at it and there it all happens
and then once you have that you need to
lay them out and build a consensus
sequence so get that what letter should
be at every single position in the
original genome and there could be gaps
like there could be some areas where we
didn't have any reads so in that case we
won't have any sequence from there and
then biologists go in and one they have
they have technology to basically attack
a particular gap to get just the
sequence from there so the problems are
unknown orientation when you get a read
you don't know which side that's coming
from so people say DNA is a string well
no it's not quite a string it's a
molecule and you don't know which of the
two strings of that DNA you're reading
there are sequencing errors so when you
get a piece of DNA there could be some
mistakes could be read a letter wrong
there could be incomplete coverage which
is this problem and there are also this
thing's called repeats and those are
what makes the assembly problem hard so
repeats are areas of DNA which appear
over and over and over and over again
many many times in the genome and nobody
is really sure what they do or why
they're in the genome there are some
theories but nothing concrete the only
thing we know is that they make assembly
difficult so in this talk we will sort
of take a very theoretical view of
sequence assembly and the theoretical
view starts with it definition so what's
our input is input a set of strings over
h EG NT output it's a common superstring
of all of these strings so this is going
to be a string which includes all of
their other shorter strings okay so just
a simple example so let's say we were
given these three strings this is a
valid super-strength
it's has THC T in it it has a CG TAC in
it
and it's got GATC in it okay
so it turns out there are lots of super
strengths and which one do we want well
initially people thought that they would
want the shortest common superstring so
this is the shortest genome which would
explain all of the strings that we have
gotten well there are two problems with
it the first one is that it's and be
hard which is sort of not necessarily
any reason to quit but it's sort of
makes computer ethically people uneasy
but it can be solved using a Traveling
Salesman problem solver or as I recently
learned the new it's now called
traveling salesperson problem so here is
the it can be done using something
called the overlap graph and this is
something I'll keep coming back to the
first half of the talk graph theoretic
models for sequence assembly so and then
overlap graph so here let's go back to
our example we have HCG THC and so on
the nodes of our graphs will be these
reads so here they are the edges are the
overlaps and all of the edge nodes
overlap with all of the reads over with
overlap with all of the other reads but
the weights or the distances are the
lengths of the prefix is how much do you
have to go before you get an overlap so
for example if you go from AC g TAC two
TAC 80 there are three letters at the
beginning AC g so this is the weight the
distance on this edge and THC 82 cata C
you have to go two letters and so on so
it turns out that the travelling
salesman tour is exactly the shortest
common superstring but I should have
come in circular superstring but then
you can do the usual trick of triangle
pairs and get the non circular version
and usually we'll I'll talk about sort
of circular paths so which will make
just it makes the algorithms easier
there is no conceptual difference so
this is the shortest
traveling salesman tour and it okay
actually also corresponds to the
shortest possible sort of common
substring yeah
because so yeah that's a good question
so here AC GTAC the way you can have a
cg THC followed by cata C is to have the
C letter in common
TAC a T does not overlap at all I don't
think that one so there are five letters
which you have to go through before you
can have that string right so it's
basically there is no overlap which is
in play I mean think of it think of
there being a special extra letter here
which is at the beginning and end of
every string so it's like a star here
and the star there there'll be five
letters which you go through before you
hit the star which causes the overlap so
just yeah no overlap businesses marry
the empty string is still a valid
overlap from the theoretical perspective
so all right so this is a you know the
shortest common superstring you can
solve it using traveling salesman salt
tsp solvers and there's lots of them and
you can actually be pretty successful at
it however let's sort of take one step
back and think do we really want the
shortest common superstring or something
else well let's go back I said DNA is
full of repeats these are identical and
nearly identical copies of segments of
DNA that appeared many times in the
genome well how many well for example
the L ll repeat it is 300 bases long and
it is present a million times or so in
the human genome so that's quite a bit
well what would a shortest common
superstring solution do to something
like this well it actually we puts it
only once in the solution because these
are identical copies best it knows they
don't really don't really need them to
high in the explanation so they're only
present once in the answer in the
shortest common super-strength
and there's been a lot of work and over
the past ten years or so on modeling the
repeats explicitly in the framework and
the graph theoretic framework and sort
of the two approaches which I'll talk
about are de bruin graphs and string
graphs this is work by Pevsner and his
group and this is work by jean myers and
the hope to some extent of all of these
approaches has always been well maybe we
can not only have a more accurate
solution but can we also make it
tractable polynomial time and so this
has been sort of what they've been
pushing that our approach is hopefully
will make the problem since you're no
longer looking for just something
shortest it will become in some way
tractable so let's first talk about de
Bruyne graphs and this is a approach
which was developed by pavel person
starting in 1989 not de bruyne graphs
themselves but we burn graphs are older
but for sequence assembly so the nodes
will be something which we call a K
minus 1 Murs and so a k-mer is a K long
piece of DNA K log K long string so the
nodes are K minus 1 Merce and I guess
that you'd ask what are k-mers then the
edges are the k-mers and this will make
our life slightly simpler and just as a
definition that the set of all k-mers in
the genome is called the k spectrum so
just as an example this is a case
spectrum these are a set of cameras
which theoretically are present in some
genome and this is the de bruin graph
these are all of the K minus one mer so
these are three Murs these are tumors
which are present in there you get this
kind of graph the edges correspond to a
three so you should have at the TTC
somewhere so tt shows it has an arrow to
t see the letter T is shared so totally
together they spell TTC and so on so
finding the shortest ring with a given K
spectrum is actually equivalent to
Chinese postman this is pevsner's result
so the Chinese postman tour of a graph
which I'll get back to slightly later on
in the talk is a tour which visits every
edge at least once so it's like a Larian
tour but you're allowed to repeat edges
and so this so pevsner's showed that
this problem can be solved for strings
with a given K spectrum and then he sort
of take--took his approach and started
expanding it into de bruyne graphs with
walks so what is this so here now let's
say instead of having a uniform sampling
we have just all three Merce we have
some three Murs and some longer strings
you can do the exact same trick you can
have your notes as came out at minus one
Murs and edges of k-mers so you get the
exact same graph but now every single
read or everything longer than three
letters becomes a walk on this graph and
just today is a syntactic point a walk
is different from a path in that it's
allowed to repeat notes so the reads are
the walks so for example the see a titi
path goes like this see a titi the GC AG
path goes like this and the ATTC a goes
like this and the problem in the de
bruyne graph approach is to find the
shortest super walk and that the super
walk that includes all of the input
walks on the de bruin graph and Pevsner
sort of he was optimistic when he
published his 2001 paper that this
problem could be done in polynomial time
he says that there is still a gap that
he was not able to solve but it actually
showed that polynomial time if every
ages is used exactly once but not if it
could use edges multiple times
and sort of the he was really optimistic
that this could be a polynomial time
algorithm well it turns out it's not so
de bruin super walks on de Bruyne graphs
are np-hard for pretty much every single
setting you can come up with and it's a
really simple reduction actually from
shortlist comment superstring which we
started with so given a set of strings
over ACGT or any other alphabet what we
do is we add que special symbols so K is
the size of the camer and we use
diamonds between all of the letters and
before and after the string so AC AC
becomes diamond diamond a diamond
diamond C so on C diamond diamond so
this is a K times longer string and
since K is a constant this is still
polynomial time and all good and we make
a de bruyne graph with these so now we
actually what we end up getting is
cycles which correspond to all of the
individual letters of the of the
alphabet and a read is now a set of
cycles just this cycle than this so for
example AC AC will look like this it's a
cycle a followed by the cycle c followed
by the cycle a followed by the cycle c
and it turns out that any super strength
of length L in the original becomes a
super walk of length L times K plus 1 in
this graph and this is pretty easy to
verify so for any super walk is
obviously some kind of walk in this
graph of exactly K times long k plus 1
times longer because we inserted K extra
nodes on every single cycle and the
other way is also pretty easy to verify
there every single no matter how you
visit them you just get some kind of
super walk as long as you go through
everything so this result you know kind
of we were disappointed we were hoping
it would be polynomial time actually and
but you know what we did is we said ok
well so the bruin graphs didn't work out
let's look at string graphs which is
the second formulation for compressing
repeats and the motivation for string
graphs when gene Myers built them in
sort of 2005 were there problems with a
de Bruyne approach so the division into
Kaymer's arbitrary it's it's also very
sensitive to sequencing errors so when
you have a one letter change just by
mistake the sequencing machinery went
went went to you know we wrong somewhere
and ii told you that there is a c
somewhere but while there should be a t
well that'll correspond to two sort of
different paths on the de bruin graph
they will separate for some time then
they will rejoin and you can think of
that searching for these things on the
graph is going to be difficult and that
third problem is this is not memory
efficient you need one note per Kaymer
but what you would like is you want one
note per read per actual sequence no
division of the k-mers flexibility in
the presence of sequencing errors while
the repeats are still collapsed so the
whole thing of de bruyne graphs if you
have some string present multiple times
it's the same path of k-mers gene wanted
to have the same thing for string graphs
so this is how you build a string graph
first you find the overlaps between the
reads so this is read one this is read 2
and this is how they somehow overlap and
you allow for mismatches in there and
for insertions deletions things like
that you model that as an edge same as
in the old overlap graph approach
however when you have lots of these now
so these are lots of reads and we'll
worry about directionality later first
but you get this kind of graph and these
red edges while they're present they're
actually inferable from the black edges
so any paths which use the right edge
you can just go through here so what you
do is you remove this transitively infer
and verbal overlaps and get a graph
which looks like this so it's nice and
linear and finally you collapse chains
so this becomes all a single edge and if
your chain had any internal vertices
it's a required edge you have to visit
it because
there is because otherwise you basically
have not explained some read in your
assembly and if I didn't have any
internal vertices it's an optional edge
which means that you don't have to visit
it it's just there for your convenience
if you wish so the goal of the g-
formulation was to find the shortest
path using all of the required edges and
any optional ones that you want but not
necessarily all of them well it turns
out that this is also in P Hart again
very disappointing but this is actually
even the simpler reduction where if all
edges are required
actually this is poly-time so there was
some hope initially if all edges are
required this actually Chinese postman
problem but with optional edges you have
a very simple reduction from Hamiltonian
path take a graph make required edges at
every node make all of the other edges
optional and if you have a path of
length 2 n a cover of length 2 n here
that's exactly a Hamiltonian path here
yeah very simple reduction so I guess
the conclusion of this proportion is
we've demonstrated that both I mean it's
both of these there are really no other
methods for graph theoretic models for
sequence assembly are also np-hard but
once we did sort of you know we were
really disappointed we actually in my
group would like to build things and not
to show that they're difficult so the
question was can we combine them to do
something easy and it turns out well
yeah kind of so let's go back to this
Chinese postman problem the Chinese
postman problem is to find a walk on the
graph which uses every edge at least
once and possibly uses some edges
multiple times and the shorter such walk
so if you haven't if the graph is
illyrian right if there isn't a layering
tour in the graph this is a poly this is
you know it is a solution the layering
tour is a solution uses every single
edge and it's minimal well then there is
the process of Euler ization what if
it's
not illyrian then you can make it or
Larian you can do it with minimum cost
flow you find the nodes which are
unbalanced so remember Illyrian
tellurian tor
it exists if all your nodes are balanced
same in degree as out degree so here I
have two unbalanced nodes I what I do is
I find the minimum cost flow from here
to there and duplicate those edges
making the graph now balanced and what
the result is is now inner Larian graph
and it's a pretty simple proof to show
that this is a smallest number of edges
that can be added to the graph to make a
tellurian and to have a Chinese postman
tour however one problem was that with
pevsner's result is that DNA is not a
strength remember we've just been saying
oh it's just a string overlaps no it's a
molecule so when you have this string
ATT GCC AAC you have this path but
there's also that the same strength the
reverse complement of the string so ATT
is a key and so on and thread in this
direction so instead of this set of
k-mers you get this so for each one of
them you also get its reverse complement
and instead of this nice little graph in
which there is only one path you get
something which looks like this and the
goal is not a Chinese postman tour but a
separation into two Chinese postman
tours which are reverse complements of
each other and Pevsner in 1989 basically
said just throw it in and we'll use some
heuristics to sort it all out and yeah I
have spoken to him and he said well he
doesn't think that this problem is
polynomial time well it turns out it is
however we had to bring in something
from the work of gene Myers which was by
directed string graphs so remember DNA
is double-stranded and the strands
selection was unknown so what gene did
or actually what somebody else did
nanjing
is to model overlaps between reeds using
something called by directed edges so in
a by directed edge you have a
directionality at each of the door of
the ends of the edge so if you have to
reach overlapping like this while it
looks like a regular edge but if you
have to read which overlap sort of tail
to tail there edge also points out at
both directions and one to read overlap
at the insides they both the two edges
point in and so this leads to by
directed graphs sort of the overlap
graph becomes by directed and their only
requirement that we have on the walk is
that it match directions at the note so
let's take a look at this node X when
you walk through it you can come in on
an in arrow then you have to leave on an
out arrow so you go from here out like
this you can also actually come in on
this arrow on the B arrow and then you
can leave on an eight arrow you can go
backwards as long as the only rule is
you have to match directions and so this
graph although it does have a Chinese
postman tour and it actually looks
something like this you can start at Z
go to X from X you actually have only
one choice you have to go to B because
you have to match the arrows you get to
Y now you have to spin and you have to
go oh that's actually yes that's fine
you have to spin around now you have to
go backwards through B now you can go to
X 3 X 2 a 2 W back around 2 X but here
you can't just pop out on to G you have
to spin around one more time and then
come out so this by directed graph you
can visit all of the edges within
without going back can't you go to Z no
because you see that the directions of
the arrows are unmatched yeah so you
have to if you come in on an end you
have to leave on an out you come in on
an out you have to leave on an in but it
can't mix them
so what catch a chill glue in 91 and
Meyers took of this up in 95 and 2005
notice that this exactly corresponds to
overlaps between DNA strings and this
corresponds to sort of using a molecule
on the one strand if you come in on an
in and leave on an out and if you do it
the other way then it corresponds to the
other strand of the same molecule so
this work so this sort of what we did is
we just generalized this work to a by
directed the brewing graph so each node
now corresponds to a k molecule so it
says CA on one strand and TG on the
other edge orientation correspond to
strands if you come in and leave on come
in on an in and leave on an out that's
the plus strand that's EA and if you
come in on an out and leave on the in
that's a minus strand TG and a path can
use a node in both orientations so for
example this is sort of made up for
example but this corresponds to CA 80 so
C 80 + 2 T and G GC and so on you can
see keep on spinning in here for as long
as you want so and this will use the
nodes and both orientations so however
what up what does the complexity of the
Chinese postman problem in by directed
graphs so we took a started looking
through literature and we found the
Chinese postman problem undirected
graphs is polynomial time and is
actually equivalent to regular matching
in the graph in the directed graph also
polynomial time and it's equivalent to
network flow mixed graphs so those are
graphs we have both directed edges and
undirected edges it actually becomes
empty hard for by directed there's no
literature but it's kind of a cool to
buy directed flow the same ways direct
is equivalent to regular Network flow
and now at this point we use the
resource
of the heat which was not available to
catch a chair go back in 91 when he
developed by directed graphs and we used
Google so the computational technique
via Google revealed that by directed
graphs were known earlier than Chiquita
thiago who they found discovered them in
1991 they were actually known back in
1967 in the classic work by Jack Edmonds
and they were further extended by gabbo
and 83 so the flow in the buy directed
graph is actually equivalent to
something called B matchings and those
are matchings where you have a number B
attached to every vertex and you allow
it to be matched up to B times and you
can use edges multiple times in the
matching and so by directed flows are
the same equivalent to B matching the
same way as Network flows is equivalent
to matching in the bite in the bipartite
graph so in 1967 Edmonds showed the
polynomial time algorithm and gabbles
1993 results he gave a a squared log
squared V time which in our case becomes
just V squared because our graph is
sparse every node has at most four edges
incident on it or the size of the
alphabet edges incident on it so this we
can now go from this graph and the this
we can solve the Chinese postman tour
and this automatically gives us a
solution to pevsner's problem because
there are two tours of this graph you
can go through like this or you can go
through like this just the same path but
backwards and they exactly spell the
reverse complements of each other and if
you just take the mirror image you get
the polynomial time algorithm for
separation into the two strands so just
sort of to give you is if you're some
open problems remain so one problem
which is actually equivalent to an open
problem which has been open for twenty
years
is there a Chinese super walk sir no is
this one is there a Chinese tour of a
particular length so that is a
is difficult because you can think of
the numbers as written in unary because
every edge has length exactly 1 if all
of the if edges had distances and they
were written in binary it would be
np-complete another open problem is
there a Chinese super work that uses
every edge a given number of times so we
said earlier that if every edge is used
once the problem is polynomial time well
what if God came down and told us you
have to use this edge 25 times on this
edge 17 times is there then a Chinese
postman tor so that's a open problem and
one problem which remains open
is there a polynomial time model for
genome assembly and that's sort of still
quite open because so usually people say
genome assembly is np-complete well no
what they mean is not genome assemblies
and to complete but the X model of
genome assembly is np-complete genome
assembly is not a theoretical problem so
this is what we're actually most
interested in and we're trying to figure
out that we can find something which is
a mix of the two so I'm now going to
completely completely completely switch
gears and talk about things which have
absolutely nothing to do with biology
and now we actually get to building
things so this is a project on virtual
machines to enable bioinformatics
computation or at least that's what I
tell the people in the medical school
who I work with who are like why are you
working on this but it's actually you
can use it for any kind of
parallelizable computation and so just
I'm assuming most people here actually
know a lot about virtual machines just
but just as a very brief overview a
virtual machine you can think of it as a
computer running inside another computer
it has it looks it's as far as the
operating system inside knows it is the
only operating system around it does
everything as though it's the boss but
in reality there's something which is
running outside of it which is the
hypervisor and keeps track of all of
these virtual machines it can be
suspended live to another computer
restarted there this is called migration
so
here you can think of you have them
something which is running you think I'd
like to think of it in terms of my
laptop I can if I'm doing something on
my laptop and I need sort of a fast
connection to the internet and at home
my connection is slow I can close my
laptop carry it with me to the lab plug
it into the network open it up and it'll
be in the exact same state in which I
left it so it can be so this is called
migration when you do it with just a
virtual machine now the nice thing is we
can run several virtual machines on a
single physical machine and they will
all be oblivious about the existence of
each other unless we sort of have them
talk to each other in some way and they
have already been used for quite a few
things so adding security migration of
process is creating a ubiquitous
environment so you know you can think of
you can have your VM on a USB key you
show up to a machine you open it stick
your USB key in and it just boots up in
whatever state you lift the year you
left it you need given that he's the
size of us because you'd need a very
small machine but this can be done so
our project which started out a snowbird
by some colleagues of mine and we now
call it snow flock is the idea that a
machine should really be computing where
it makes the most sense to do
computation so if you're sitting if
you're doing some you know high-end
graphics such as playing Doom you
probably don't want to be playing on the
remote machine and they're getting your
doom connection through X if you're
computing over a large data set you
probably don't want it to be local
because that data set may not fit in
your hard disk or maybe you have to
download that data set and actually one
of their main points is that machines
are smaller than data sets if you think
about sort of the typical windows or
anything else install that'll be usually
much smaller than the size of all of the
data that you're computing over in a
typical scientific application and
what's not a nice thing they can provide
for efficient shared usage of large
computing data resources so I have a
cluster and I want to allow another
biological researcher to do some
computation I can just give them an
account
but then if the user screws up if they
have for example a bad password somebody
hacks their account once they're inside
they can actually it's much easier for
them to hack the whole system and so on
so if you have a virtual machine if they
get hacked I'm not going to get hacked
so altogether it gives you a powerful
but yet secure computing environment you
can do anything because you have an
operating system but you I cannot but
you cannot get hacked as easily so here
is sort of an overview of this of the
project we have remote users and we have
our cluster a remote user has a machine
which they're running and they want to
migrate the machine to our cluster once
it's at our cluster we will allow them
to fork copies of their machines so they
had one copy now they have multiple all
of the two users both migrate their
machines over some of the cluster nodes
will have machines from both users other
customers will have machines from only
one user and they can all communicate
they basically get a virtual network
using all these nodes but they cannot
see each other the blue note the blue
user is oblivious to the existence of
the red user and so on so how do we
actually accomplish it so what is the
life cycle the machine is initialized
somewhere remotely it will migrate to a
computer data resources and then we'll
fork clones to allow for parallel
computations so this will give you many
machines collect results and migrate
back and the way this is actually
accomplished is using pretty much
existing technology so here's a user is
sitting here's his master node which
he's interested in it's connected to
something called one disk which is wide
area network disk and which is actually
connected to the physical disk image and
then there's snow flock it's our tool
which is running inside the dom0 this is
the hypervisor
the supervisor of the machine which is
running and this is the user space so
here are all of the sort of all of the
machines will run and this is our
cluster it also is running snow flock
so when they want to do some serious
computation what they do is they request
of snow flock area that they migrate
over to us that may sends a request
through the internet across to the
cluster and a virtual private network is
established between the user and our our
cluster so now all of the connections
will happen through that the master node
is then migrated and it requests again
the requests the migration the actual
migration call the machine has migrated
across the VPN and this is included so
Zen is a popular hypervisor open source
and yeah it's already includes all the
facilities for migration across a local
network and basically a VPN gives us the
ability to do it using all existing
tools and once the machine is migrated
snow flock will send information about
how this machine should be configured
where its disk is and so on and the
actual disk the way it's connected it's
going to be this one disk here which is
connected to the one disk here so we
will not actually move the whole disk
across this is could be gigabytes across
a possibly slow connection we will
actually do the disk fetches on request
so the nice thing about this is all
network connections stay alive if the
user has an SSH connection open to this
machine that will stay alive once the
machine is migrated it will it will not
die once the machine once the machine is
over on our side it can ask for clones
once it takes the request to Snow flock
the machine is saved and sent across to
the to the to another node and copies
are started the copies will point back
to the Swan disk located on the dom 0 on
the user side and that those will point
back to the wan disk and the way i want
this because actually works it's a very
simple copy on write and copy on read
system if you're within a physical
machine you're doing copy on write only
so when you make a right you will write
a new copy when you make a read you will
request a copy of somewhere else and
then you'll just get the value if it's
between two physical machines will
actually save a copy on every read as
well so very simple ticket so this is
little works on the level of disk blocks
and it turns out to be very efficient
finally once the node has done its
computation it will need to clean up and
the way that works is again you send a
cleanup request that gets forwarded the
slave nodes are just killed off there's
nothing which needs to be done for them
they disappear then the master will
migrate back to the client the disk with
any changes which they have been done to
the disk will be merged back and the
network will disappear one thing that
they're you know still remains is how do
we handle this situation of multiple
users so the two users are both on our
physical costume we need them to be able
to talk between machines on their
network but not see the other physical
with the other virtual machines which
are around and then we actually use
something a very elegant solution at the
level of at the Ethernet level rather
than the IP level so what we do is we
put a little box at the virtual NIC
so any connection any packets which are
going into the client virtual machines
have to go through that box and we
provide that and what that does is it
looked at every single Ethernet packet
which is coming in and rewrites it or it
decides whether it should be accepted or
not so if you have a packet which is
coming in it looks at the source and if
that's a node which is on the same
virtual cluster then you allow it
through and you actually rewrite the
destination to the MAC address of the
client virtual machine so the address
which all of the other machines used to
refer to it to the machine is this one
but
the machine itself thinks it has this
MAC address so you just change it so
that the machine will accept the packet
if however the source is not something
which we know so that beef then we just
throw the packet and the same thing
happens on ascending you check the
destination and filter the packets
appropriately so this allows you to
completely you know cleanly handle the
networking problem at the level at which
the machines which are running don't
even know that anything like this exists
so I guess what's the overheads is this
going to be a heavyweight solution which
will be impossible to run anywhere well
first of all a virtual machine overhead
so we took a popular bioinformatics
package blast and ran it on the virtual
machine versus a real machine just this
is sort of simple validation that we can
still get work done and it turns out
there is a 4.8% overhead which is
insignificant from our perspective okay
what about the time it takes to clone a
machine you have a machine running now
you want to have a copy of it running
somewhere else so within 13 seconds of
the issue of a command or a clone
instruction the master is running again
so any network connections to the master
everything else is going to stay alive
13 seconds is an insufficient time out
for for the network connection and
everything else to die and the clone on
a different machine is running within 25
seconds so just as a comparison copying
a file a 1 gigabyte file it the same
across between these two machines takes
23 seconds so you know we're pretty much
maxing out the network and the disk fact
fetching well it turns out that on
boot-up server when you start a virtual
machine using one disk it requires it
reads an x another 12 K of disk and
post-blast it's 15 and the written stuff
is also insignificant so the networking
overhead there's actually no slowdown
because the CPU is mine and which does
the rewriting is much faster than the
network
the CPU overhead when you're
transmitting it goes from 30% CPU usage
to 36% and when receiving from 50% from
47% to 49 and a half percent so again
slight overhead in terms of CPU and
almost no overhead in terms of the
actual time it takes to send the file or
receive a file so we're sort of the snow
fuck work is very much still in
development we're finishing the
implementation of a prototype and we're
going to release it open source and all
the good stuff we're evaluating disc
multiplexing so for now every single
client which comes up it has to request
the disc but it would be much more
efficient to just multiplex the disc out
to all the clients and use the actual
switches to get all the improvements
instead of having their independent
fetches we're considering API extensions
so you know just as we have conforth
virtual machines now we want to consider
do we want to have a joint call as well
and what exactly would that mean in the
VM scenario we're looking a little bit
at scheduling a lot of work has been
done on this and other policy related
issues but we're probably just going to
get something off the market off of the
shelf for this and finally want to
create a biofloc installation and
service so basically biologists will be
able to do remote computations on their
data resource which is provided for them
rather than having to download all the
data keep local copies and so on okay
well with that I want to thank all of my
colleagues so the assembly work I talked
about was done by mainly by Paul
Medvedev who's a grad student at
University of Toronto and also
Konstantinos guru and also Jim Myers at
janila farms worked with us on the
virtual clusters it's a collaboration
between my group and al dalaras group
with joe whitney andres Havilah and
steve rambo considered contributing a
lot of work and Ryan Lilly another
colleague in this year's department
another PI and this stuff I actually
didn't talk about so I'm not going to
thank those people I'll thank those
people but not now and the funding was
provided by insert which is a Canadian
and US F and C fi which has no
equivalents in the u.s. lingo so and
thank you all for listening
we should actually for each part of you
talk for the first invention that major
problem for assembly is that you have
repetitions now I wasn't following
exactly the details of the modification
to present it later but it seems to be
that doubtful that any any of their
hosts anything can handle repetitions
unless you insert some extra data about
counting how many you have is that
correct
not quite here let me show you yeah so
the question is about repetitions in the
genome and how you can figure out that
there are repetitions without actually
looking at the data so here is that once
I go back far enough is used to show on
this slide
so take a look at this graph so let's
say this edge was required because there
was some internal verdicts and this edge
was also required this was just from the
structure of the graph he would now be
able to figure out that all of these
nodes have to be used twice and then
split at some point over there so with
no additional data actually you can
figure out that this chain is used twice
in the genome yeah so twice okay three
times okay so you know it's once you get
to a million times
you're basically topless I will agree
with you that's going to be very very
difficult you will get some over
compression but the problem with the
shortest common superstring approach is
even things which are present twice in
the genome are would be compressed the
other thing which helps us from a
practical standpoint is that things
which are present twice could build very
long things which are present a million
times typically are very short and
hopefully we have a full read which
spans the whole thing so that we have
some unique stuff before and some unique
stuff after which will help us figure
out how many ways there are through it
so you can use the unique parts in order
to help you figure out the parts which
are which are common which are multiple
copies
you use usually when when you simulate
one machine with another if you're using
a lock instead of the same construction
while in your case you say it's only a
few percent so what's the reason well so
I am actually so I'm not the biggest
expert on how and the underlying virtual
machines work but basically it's worth
the virtua the way a virtual machine is
different from a from just having a
machine run inside an application is
that all of the instructions run
maximally close to the hardware so when
the virtual machine execute the
instruction it has to be in the same
architecture that the hardening
underlying hardware understands and the
instruction is directly sent to the
hardware you don't need to translate the
instruction like it's not like a Intel
chip and a PowerPC chip that the the
hardware is the same the instruction can
just be directly taken from the virtual
machine and put in the hardware so the
overhead as a result is very very small
it's full control of its own
instructions it the hypervisor basically
I think you can more think of it as a
parallelization like you can have
multiple threads running within the same
operating system or multiple processes
it's similar that summer scent you can
think of it as just a virtual machine is
just the process on the hypervisor
what is junk DNA III don't think I used
that term but junk DNA people refer to
junk DNA as pieces of DNA which II don't
understand
it's a simplest answer if you don't
understand it it's junk and then it
there's papers published like finding
jewels and junk DNA which are finding
things which actually do stuff among the
things which you didn't do think did
anything junk DNA a part of the genome
JG cannot assemble the parts of the
genome which are just not junk if you're
either getting the whole genome or you
know you're not and like for example
these repeats the alo repeats I
mentioned a million copies people think
they're junk but that's mainly because
we don't understand what it is they're
doing and we've studied them for however
many 10 years and we still don't know
what they do so maybe they're junk but
who knows
so the question is whether the length of
the read helps and it certainly it
length of the read if you had the the
length of the read be the size of the
genome it would be a trivial problem so
it's a it's actually a very interesting
problem because what this shows is that
so what this result showed was that if
your reads were all length three we
could have an algorithm but the
questions will give you the correct
solution and from an algorithmic
perspective shorter reads make things
easier but from a practical perspective
you will get the same over collapse of
areas which you don't understand so you
need your read basically to be longer
than the length of your repeats and if
they'll if the length of your read is
bigger than the length of the repeats
it's a simple solution a simple problem
the problem is that it's a trade-off so
you can get really short reads really
cheaply and lots of them long reads are
expensive to get and you get fewer
that's it all right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>