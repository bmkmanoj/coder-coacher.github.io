<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A General Approach to Discovering, Registering, and Extracting Features from Raster Maps | Coder Coacher - Coaching Coders</title><meta content="A General Approach to Discovering, Registering, and Extracting Features from Raster Maps - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A General Approach to Discovering, Registering, and Extracting Features from Raster Maps</b></h2><h5 class="post__date">2010-09-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7qXLEopuKGk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Craig Knobloch is the director of
information sorry director of
information integration at USC their
information Sciences Institute where he
leads a team of 20 researchers staffers
and students and doing various
interesting things he's here today to
talk about his work on detecting and
extracting structured data from raster
maps so please put your hands together
and welcome them great thank you Michael
okay so I'm going to talk about work
will be doing now for a number of years
title my talks a general approach to
discovering registering and extracting
features from raster Maps as you can
tell from the title there's a lot of
different stuff to cover so what I want
to do is give you sort of an overview of
the different pieces of technology would
have developed over the years and try
and give you a sense for the kinds of
problems that were word we've solved and
are currently working on I need to
acknowledge my collaborators so this is
really don't work between us see and geo
symbol technologies which is a spin-off
company from USC that's been
commercializing some pieces of
technology and there's a number of other
researchers and people that are
completed their PhDs that have worked on
this so Jason Chen yaoi Chang I'm on
goal Matthew Michaelson and sarah shah
hobby have all contributed to various
pieces of this technology okay so as you
probably all know raster maps are very
rich source of geospatial data they're
often easily accessible they often
contain many different types of
information on the maps themselves lots
of different layers lots of different
interesting kinds of maps and they often
contain information that you cannot find
anywhere else and so you know the
challenges are how to actually find and
exploit that information so a couple
examples on the on the slide here so on
the Left we have a travel map of Tehran
which is quite detailed you know has all
the names of the streets you can't
really see it in this picture it has you
know locations of gas stations all this
kind of interesting stuff that a
traveler might want to know and on the
right we have a USGS topographic map of
st. Louis Missouri and I like this map
just because it has a lot of detail and
also has a lot of historical information
the USGS has these topple maps going
back into the 1850s and they contain a
lot of interesting sort of historical
information about where the roads were
with
buildings were over different periods of
time okay but some of the challenges and
actually extracting data from maps are
that well they have a lot of information
they often have this problem that
there's a lot of overlapping features on
the maps making it often hard to get the
information out of the map there's often
very limited access to the metadata so
we may know the general area of the map
is up but we may not know things like
the scale of the map the geo-coordinates
other sort of key pieces information
that you'd like if you're going to
combine this data with other sources of
data and often they're only available in
raster format so most most maps at least
current maps are typically created from
vector data and then turned into raster
data but often what you have available
it is just the rest or the raster did
itself and in older maps are typically
were created by hand and then you know
converted into raster at some point so
there was never a vector format for
those maps so the challenges are how do
we actually find these maps that cover a
given area and a given topic how do we
register them meaning how do we actually
figure out exactly what the coverage of
the map is and then how do we actually
extract the different layers and then
recognize the features in those layers
in the raster map and so I'm going to
talk about all of those things today
okay so here's the outline of my talk
I'll give you some a brief description
some of the work we've been doing on
sort of map discovery how we can go out
and find maps for given regions then
I'll describe two different techniques
we're using for doing the automatic
extraction of the different features
these are the different layers in a map
like the road layer or the text layer so
i'll talk about automatic techniques and
then i'll talk about some more recent
work we've done on detecting the layers
or extracting the layers from very noisy
maps then i'll talk about the automatic
registration of these different kinds of
maps you know how do we actually figure
out you know the relationship of the map
to satellite imagery and then some
recent work we've been doing on feature
recognition which is actually pulling
out the content from these different
layers and I'll conclude with some
related work and discussion okay so map
discovery so what we want to do is
basically collect candidate maps from
the web and we've sencha ly been doing
this with two types of maps first we
started with looking for standalone maps
using things like image search engines
you know
images where you could go and you could
type in name of a city and maps you get
a whole bunch of things that might be
maps and then what we discovered that
well some of those are interesting maps
most of those are relatively low
resolution maps and so I started looking
around and discovered that many of the
really interesting naps that you can
find on the web or embedded in PDF
documents partly because PDF has some
nice facilities for actually storing
maps but also maps to tend to be
embedded in larger documents so so so
then we did some work on actually
extracting the the images directly from
PDF documents and then the challenge is
you know if you have these images so if
you use an image search engine or a PDA
or you find a PDF document you pull out
all the images then the challenge is how
do you actually figure out which things
are actually maps so we developed some
techniques where we identified a set of
features that can be used to sort of
characterize maps and then we use a
technique called content-based image
retrieval or cbir to try to figure out
which things or maps and which things
were not maps in terms of the images so
here's the basic approach so I'm along
the top here you see a set of images
these some of these things are maps some
of these are not maps and so the basic
approach is to take each of these images
extract the set of features from the
images find similar images and what we
did here was we had we built two
repositories one was a map repository
which essentially is a large collection
of things that we were known to be maps
and then we had a non image repository
here shown on the right side of the
screen which are the things that we know
that are not maps these are things like
pictures and figures and things that are
not maps and the idea is to essentially
find similar images and then to
essentially classify this final image
based on what its most similar to so if
we found that it's mostly similar to
other maps then we'd say ok this is
likely to be a map and if it's mostly
similar to other non maps and say ok
this is probably not a map so you can
see at the bottom here we've you know
taken the images from the top and
classify them in what we hope out is
output from the system is then the
classified things that are actually maps
and we played around with a number of
different features but the feature we we
found that worked the best were to use a
set of things called water filling
features and the idea is this is really
a
looking at a certain kind of structure
in the image so turns out that maps and
if you if you look from a distance you
know most of us can look at an image and
from a distance we can recognize whether
it's a map or not and that's typically
strong sort of line features so has very
strong edges so what we do is we
essentially start with a map like the
one shown on the left here which is a
map of different I think political
districts and we create a canny edge map
from this which is really just the the
map of all the edges so we really make
this makes it color invariant since maps
have a whole variety of colors we didn't
want to build a map recognition tool
based on the colors so we're really just
looking at the line features and then if
you see the little area that's circled
here we pull out some set of edges here
and then we compute the water filling
features on these edges so this is just
you can see what's actually going on it
blows up the image and this shows us one
part of the image here and the water
filling features consists of three
things there the what's called the fort
count the filling time in the water
amount and essentially what these are
doing is capturing the properties of the
lines right and is really capturing how
long the lines are how much the lines
branch and the total amount of total
number of pixels that are basically
contained in all the lines here and so
for each of the different lines that are
contained in this in this edge map we
compute these things and to make the the
properties sort of size invariant with
respect to the size of the image we then
create this normalized histogram of
these different features so we end up
with is a feature vector that consists
of these three features for this sort of
normal and histogram of the of the
different sizes of these features and so
we can essentially feed this into this
this technique I mentioned there's
content-based image retrieval where the
idea is we take our map repository and
our non mappers very short at the top we
run it through the CBR method which
essentially says all right we're going
to take the image where we're going to
do the feature extraction on the image
and then find those images that are in
one of these two repositories that are
most similar
and so it's going to generate the and
this and the slide here shows the five
most similar ones and then it
essentially is a voting system right so
if you say well the top three are
basically maps and then the next two or
non maps then this is more likely to be
a map than an on map and so it
essentially does you know a k-nearest
neighbor classification where it's
essentially looking at the the voting
scheme here and we actually do we
actually this just shows the number of
votes but we actually weighed it based
on the similarity so we do have a
feature strength in terms of how similar
each of these is in terms of those 24
features and we decide what your maps so
that gives us pretty good results we did
the rear an this on a test of 8000
images with four thousand images two
thousand maps to those non maps and a
separate test set so we trained it on
the repository and then the test set is
similar size and the kind of results
were getting here are precision which is
pretty good seventy-seven percent recall
71 percent which gives us no role f
major of seventy-four percent so it's
not perfect but it allows us to quickly
classify those things or more likely
maps so then we can go into the later
stages of processing so we'll see as we
go on in my talk that you know really
this the purpose of this is to quickly
identify which things are likely to be
maps and then in the later stages if
something's not a map then it's going to
fail the later stages in the processing
and we get filtered out question back
here well okay so the recall we're more
likely to throw things away because we
have 71 percent recall so it's lower
recall them precision so you would like
to I mean you could adjust those though
I mean you could you know if you wanted
to tweak the numbers but we found is
there's a lot of redundancy out there so
you know there's lots of map so if
you're looking for a maps of a given
region so maybe you missed some but
there's so many maps of there that you
may actually find other ones to cover
the same area in the same themes okay so
now I'll go on to the next topic so I've
talked about how we might go out and
find maps automatically but maybe you
already have some maps as well so let me
talk about some of the methods we've
developed for doing
automatic extraction of the different
layers or features from the map so if we
look at an input map on the left so the
the basic problem here is that you have
a map and you want to essentially pull
out well initially want to pull out the
road layers and the text layers okay
those are the what we focused on whether
the same techniques would apply to other
kinds of layers and so we want to do
first is remove the background
information so if the input map showing
on the rest on the left here and what we
have on the right here is a grayscale
histogram of the actual pixels in the
map and as you can see some of the
pixels are much more common types are
much more common than others and what we
want to do is figure out which ones are
the background pixels so you can see we
draw this line here from the 0 0 point
on the axis up to the the highest point
on the histogram on the right and then
we drop a perpendicular down and if you
drop a perpendicular down you find those
points that are essentially those lines
those perpendiculars have essentially
the longest okay and those are the
things are going to actually segment the
histogram into separate pieces and the
one on the right here is most likely be
the background color because the
background color sort of tends to be the
most common pixel color on a map and so
we can centrally divide this up into
different groups look for the dominant
number of pixels and then essentially
remove that from the actual map that
you're seeing so you can see on the map
itself we can go from one that has this
sort of shading in the background to one
where we can pull it out and what we're
left with is essentially the the road in
the text layers and this works for a
wide variety of computer-generated maps
once we do this now we're left with
something that looks like this where we
have both the text and the road
information on the map so the next step
is to actually come up with some way of
actually separating the information into
both the road layer and the text layer
separately so to do that we essentially
look for these small connected objects
or care which tend to be the characters
and you know this is from the obvious
property which is you know Road lines
tend to be long and connected and
characters are going to be relatively
short and so we're going to look for all
the characters and essentially group
these in
these connected objects which are
essentially the strings or the text
strings on on the map they may also be
the symbols on the map once we pull
those out we can remove these connected
objects and we're left with it with the
road layer although you notice this
little problem with our road layer which
is that in many cases the characters
overlap on top of the road layer and so
when by removing the text we end up
breaking up the road layer here so you
see there's some places where it's now
disconnected and we're gonna have to fix
that but this gives us the initial sort
of data to work with so we have the road
layer now on the left we have the text
layer on the right which are all those
things we removed and the next step is
to actually recover the missing
characters on the road layer so to do
that the first thing we want to do is
actually identify some of the properties
of the roads itself so many of the
interesting naps actually tend to be
double line road maps and so we
developed this technique called parallel
pattern tracing where the the task is to
actually figure out if it is a double
line road map and what's the pixel width
on that double line road right so we
know that that actually helps in further
processing and if it's a single line
road map we want to know that as well
because we do different processing for
that and so what we do here is we
essentially look for we essentially
assume a certain pixel width and then
test to see if the map is what the
properties the map bar so for example we
assume that the road is a three pixel
width wide road then we can look and see
if this this pixel so here it shows this
yellow pixel on the map and we can look
3 pixels away and we can look to see
well how many of those pixels are
actually filled in right and if it turns
out that if this is in fact a three
pixel width wide road then we're going
to find that when we look at this pixel
width compared to other ones that we're
going to get a large number of pixels
exactly that distance away that that's
going to dominate this this this
distribution of pixels so in this case
you can see the the road opposite the
road side opposite the yellow one is
three pixels away and you're also going
to find some other character some other
pixels three characters way to each side
now you know roads can be at angles and
so on and you won't always see that but
overall this is going to be a proper
you're going to find out
on the map and so what's going to happen
then is we're going to essentially
iterate through we're going to say well
okay let's consider whether or not this
is a one pixel width wide road map to
pixels three pixels you know up to
something like 10 pixels and we'll look
at a graph of all the pixels and you'll
see a spike at the place where it's
actually a double line road of that
particular Road with so once we apply
this technique what it's going to give
us then is the road width and if if in
fact it is a double line road map and if
it's not then there's not going to be
any peak in the graphs so that then is
going to get for this map shown on the
left here once we know the road width
then that allows us to extract at other
layers so we can actually move for
example these topographic lines on this
road because you know all the ones that
are not three pixel width wide roads are
not xroads but we also you'll see later
we'll use the fact that this is a road
width of a particular size in further
processing okay so here the next step is
to actually reconnect the broken road
lines so what we really want to do is
end up with the topography of the roads
that's accurate so those roads that are
connected since Road tend to be
connected you don't end up with a bunch
of separate Road segments right so we're
trying to basically go back and
reconnect the ones that were essentially
broken when we remove the text layers so
to do this we go through a series of
morphological operations that it
basically allow us to reconstruct this
road layer so the first step is called
dilation and the key here is now that we
know the the road width where you know
how many steps of dilation we can we can
and should do on this particular map
since it's three pixels wide we know
that you're not likely to put another
road three pixels or less next to those
roads because then it would be very
confusing to actually look at them out
so we can do the dilation we know how
much how many steps in dilation to do
then we go through a step called erosion
which then shrinks the road back but
hopefully leaves those roads that were
connected that should be connected
connected and then finally we go through
a final step called thinning where the
road width then goes back to being a
single line road so the final set of
roads we have are all one pixel width
and width so and this is very useful for
the further processing okay so we've
gotten back
single line roads so now we've
essentially extracted the road layers
and the text layers and this is great
this works on a lot of
computer-generated maps so you can run
this on google maps you know yahoo maps
any of these online maps any map that
was typically generated in by a computer
and has certain properties so for
example has detailed roads the map was
drawn to scale we can automate the
process these maps but the challenge is
that there are many maps that don't that
aren't as clean as these right they're
not general by computer so for example
here are two different maps that you
might want to process the one on the
left is in fact a scan map so this is
the one of the maps from USGS and these
maps were originally drawn by hand and
then scanned in and scammed a long time
ago using a relatively poor quality
scanner and then the map on the right
was one that was we purchase online it
was shipped to us and then we scanned it
in and you can see if you look carefully
like the background colors here have
different shades where the road where
the map was actually folded okay so that
the coloring is not consistent across
this map but even if you look at the map
on the left you know the number of pixel
colors that make up the roads even
though it looks black there's I think
eight or ten different pixel colors that
actually make up those roads so these
maps are very hard to process in a
completely automated way so in you know
here's one of the difficulties the fact
that they contain many many colors you
know just because for two reasons one is
because the scanning technology tends to
produce lots of colors to sort of
capture all the variations in terms of
the different pixels so this map here on
the Left had 285,000 and some odd colors
in it and if you look at the grayscale
histogram here you can see there's a
whole distribution wide distribution of
colors to represent you know by the I
just looks like a few colors right it
really looks like you know fewer than a
half a dozen colors on that map so what
we want to do is come up with a way to
deal with these kind of maps so first we
go through a process to do some color
segmentation we reduce the number of
different colors we have on the map so
the first step is to use this
mean shift algorithm where we can
essentially look at the color distance
between the pixels in the RGB space and
this allows us to essentially take
pixels that are very close in this color
space and merge them into a single color
so that gives us a good reduction of a
factor of two reduction from 285,000
255,000 it's still too many colors but
this helps us in the second step and the
second step we do a k-means algorithm
where we're going to limit the number of
colors to some number K and we
determined that number experimentally
and we go from you know 150 five
thousand to ten colors so if we we give
the algorithm the value for K and run it
and it generates a map and basically you
can tell whether or not that was a good
value for K if you could still
distinguish the roads from the other
features all right so we end up with a
grayscale histogram you can see on the
right that has you know 10 10 lines in
the histogram okay so what's required
from the user in this case is now just
to identify the roads themselves to
provide examples of the roads so our
goal here is to be able to process a
wide variety of maps with really minimal
user effort since there's a lot of tools
out there where users can do a lot of
work to extract information our goal is
to make this as you know as simple as
possible and so our user Laban is
essentially requires the user to just
provide us an example of each of the
different Road colors so if you look at
this map here you can see on this
particular version which has the reduced
colors there really is just two colors
for the roads there's the white roads
and the yellow roads here and so what
the user would do would simply identify
two examples where they simply point to
the center point of those two roads I
mean anywhere on the map some center of
the line so here there's one wrote one
label in on the white roads one label in
the yellow roads and then what we do
with that it was you basically take
these examples and we decompose them
into the number exempt number of colors
so let's assume that I gave it a for the
purpose of this slide a k value of six
so that I couldn't put more than six
squares on this slide what we do is we
now take this the
the label on the left and decompose it
into each of the each of the six colors
so each each of these squares has only
one of the six colors from from the
image and what we want to do now is
determine which one of these where r
which one's of these six colors
correspond to Road pixels right because
our task here is to figure out the
actual Road pixels on this map and we do
this by sensi applying a technique for
detecting what are called the hue lines
and these this is a sense a technique
for drawing a line or set of lines
between the that runs the center point
of the pixels on a given image so if you
look at the the six images on the top
correspond to the six pixel colors that
we pulled out and then the six pixels
the six images on the right one of them
corresponds to each one of the ones on
the left and on the top rather and this
shows you the hue lines and the hue
lines okay are in two colors on this on
the bottom the ones on in the red are
the ones that are within some distance
of the very center of the image and this
is important because remember we ask the
user to label the center of the road
lines so if there's a lot of few lines a
lot of red lines rather then that means
that most of the pixels are are running
through the center of the image which
means that they're likely to be the
actual Road pixels the blue ones are the
ones that are farther from the center so
this is really just shown here to
illustrate this point there the red and
the blue colors and you can see the
colors that correspond to box is 0-1 two
are clearly have more blue lines the red
lines three it's kind of a toss-up and
four and five clearly have more red
lines than blue lines and so those are
the ones we're going to say okay these
are the ones were confident actually
correspond to Road pixel colors okay so
we can essentially the term in the road
colors on those and essentially combine
these so we say okay we're going to
generate this road template by taking
these colors that correspond to these
two types of templates and that's going
to generate the the colors that we're
going to actually identify that are
likely to be roads so we can essentially
take this color template apply it to the
map
and then generate a map that looks like
something on the right here so you can
see we went from this map on the left
which originally contained lots of
different colors in it to one on the
right which contains mostly the road
pixels and there's a few areas here that
are still filled in and we have some
ways to remove those but I'm not going
to talk about that today but essentially
are applying some additional operations
on that to get rid of these large solid
areas and to reconnect from these lines
okay so that gives us a technique then
to essentially take maps that may be
very poor quality in terms of the scan
quality and also due to compression have
lots of different pixel colors and to
extract out an accurate road layer so
I'm sorry this is the the final map so
once we go through the morphological
operations we end up with a fairly good
quality roadmap here from this original
restroom at ok that brings us to the
next step which is to actually do this
automatic registration of the maps so
what we've done so far is I've described
you know techniques for essentially
pulling out the road layers and text
layers automatically the next step is to
figure out exactly how this map relates
to other geospatial layers right because
we really would like to understand the
precise coordinates of the map and then
to be able to apply transformations on
the map to essentially be able to
overlay the map on top of satellite
imagery or other geospatial layers that
you could visually see the information
on the map overlaid on other data sets
okay so the basic approach is shown here
in this picture the and and the key idea
here is to essentially exploit the
layout of the intersections found on a
map and compare it to the intersections
on an image or a vector data set in the
intuition here is simply that you know
if you have a large enough area the
layout of the road intersections is
going to be unique ok and you're looking
at the actual trying to find the similar
layout on the imagerunner vector data
set so then you can essentially do the
mapping between the map that you have in
this other data set so what we have
shown in this image here on the bottom
we have a map a raster map with some
unknown set of coordinates right we
don't know the coordinates of this and
we're going to detect the intersections
on this
and I'll talk a little bit more about
how we do that in a minute on the top we
have a road network okay and this is
like a vector road network and this is
relatively straightforward we can just
detect all the intersections by just
searching in this vector road map to
generate all this and these corresponds
to these red dots here the intersections
then we need to do our point pattern
matching I'll describe briefly how we do
that and then the final mat the final
result would be the actual alignment
between this map piece that you're
seeing here and this vector layer here
and we can come up with the exact
mapping not just to the corner points
but we can actually map each individual
Road intersection to the corresponding
Road intersection on the other data set
and that's actually quite useful because
then we can do the actual process called
rubber sheeting to align that map with
the image okay so let me first talk
about the problem of detecting the road
intersections so I've already talked
about pulling out the road layer so the
next step then is to actually detect the
actual intersections themselves and to
do this we apply a technique called
corner detection where we essentially
look for every place that there's some
transition or change in the direction of
the pixels so you can see this happens
both at the intersections but also
happens in the middle of a road perhaps
where because of pixilation the road
jumps over 1 pixel there it looks like
it's sort of but there's a simple
technique we can pull out all these
corners and then we want to do is figure
out which of these corners are likely to
correspond to actual intersections and
for the purposes of what we're doing
here we're going to assume the
intersections actually require at least
three roads that come together so if you
have fewer than three roads we're going
to discard it but if we have more than
three then we're going to say ok that's
a road intersection so that's how we
generate the set of road intersections
but we're not quite done because what we
really want to do is generate a road
intersection template right which is in
this is not just the location of the
intersections but what the intersection
actually looks like and the problem is
that in that processing for pulling out
that road network one of the things that
happens is we may actually end up
distorting the actual Road lines so you
can see that here in the top image where
this is the actual road
line that got extracted from the map and
you can see what happens at the
intersection it gets distorted because
of the morphological operations that we
applied which do this filling in pixels
and then removing pixels to try and
reconnect the roads and if we just
extract the template directly from this
then the template we would produce would
look like this one in the center here so
you can see this template does show
three roads comes together but doesn't
show the actual angle the roads are
actually come together and that's a bit
of a problem what we really want is the
template on the bottom here which shows
an accurate road intersection which
shows how many roads come together the
location or center point of the
intersection notice this early the
template here in the middle is not
centered and the exact angle that these
roads are communiquer okay so how do we
fix this problem so we essentially start
with the approximate location of the
intersections which was you know in the
original algorithm I described for
pulling out the intersection location
right we have these thin lines right
that we pulled out of this which are
distorted and then we also have the
intersection positions which we also
pulled out when we detected the location
of the intersections and what we're
gonna do is we're going to combine these
two we're going to first say all right
based on the we know the approximate
width of the road lines and so we can
create this blob that basically covers
the entire intersection so we can take
those intersection points and create a
blob and size of the blob is determined
by the the distance between the road
lines right if it was a three pixel
width wide road we know how big to
create these blobs and we're going to
overlay these blobs on top of the actual
intersection points and then what we do
with that is is essentially extrapolate
from the lines themselves back into the
intersection so if we say okay here's
the general direction of the road lines
that over the distance that we're
looking here we can actually extrapolate
these Road lines back to the center
point and we can essentially correct for
this distortion so we end up instead of
the destroyer T and intersections here
on the top we can end up with
intersections that actually very nicely
capture the location and the geometry of
the actual intersection points and this
is actually really important for several
different things
we're going to use in the future do in
the next steps here the first one is the
point pattern matching so the next step
in this now we found the intersection
points is to actually figure out the
relationship between these intersections
and this other vector data set and in
this process we use not just the
location of the intersections but the
actual template of the intersections to
do the matching so as I said before we
use essentially the district the
distribution of these intersections to
determine the relationship between the
map and the image and so what we're
doing is essentially finding a mapping
between these points so on the left here
you see we've extracted some set of
intersection points there's 80 points
here on this map and on the right we
have the intersection points that have
been identified on top of this image and
we're looking for the mapping between
these two ok so we're essentially trying
to find this transformation between
these two and the advantage of actually
having accurate templates like I just
described is in that search process we
can actually search for those templates
that actually match right we can search
for ones that actually have the same
number of roads that come together same
angles and same and relative locations
are saying so we do the search to find
this transformation and come up with
this mapping between the map points and
the points on the end on the imagery
given this transformation then we can
apply this technique called conflation
or rubber sheeting we're essentially
look at the mapping between all of the
intersections on the map and all of the
intersections on the image that come up
with the actual transformations that
we're going to apply and this is
important because if we want to just
take the corner points of the map and
superimpose it on top of the image you
may not get a very good alignment simply
because the we don't know certain things
about how the map was created in terms
of the actual projection that was used
in other details of the actual
construction of the map but by doing
this we can react essentially apply a
set of local transformations that give
you a very good alignment between the
map in the image so that the labels that
are shown on the map will actually be
shown in the correct place on top of the
image so we do the rubber sheeting and
you end up with you know a result like
this where you can see the labels
correspond to
directly to where the roads are the
details from the map person posts on top
of the image here's an example of
imagery from Baghdad so the upper left
hand corner is a an image from google
maps on the right we have a map the
corresponds to the same area and then
we've automatically processed this map
and so you can end on the bottom left
hand corner we've superimposed this map
and made it semi-transparent so now you
can see the labels from the map are
super-close directly on top of the image
in the correct place and on the right
we've actually pulled out the text layer
here and superimposed it and so now the
labels are simply superimposed directly
on top of the information that's in the
original image so essentially by going
through these the steps have described
so far we pull out the different layers
and then automatically register them
with respect to the imagery now we can
do one of our first goals which is
simply to allow you to essentially label
use the map to essentially label the
image all right we'd like to do more
than that though so you know that gives
us you know visually a useful piece of
information but we really like to do is
go back and construct the original data
sets here so we want to construct
something that corresponds to the feet
the actual data sets that you could use
to create a map I'm particular i talked
about extracting the road layers and the
text layers and so what i want to
describe now is how we can actually
build up the actual data sets that
correspond to the vector layer and in
the text layer okay so the first the
first one of these is the road layer so
really we would like to end up with is
not just a raster layer that shows the
roads but to actually build the road
vectors and I mentioned earlier that the
fact that we have very accurate
intersection information really helps us
in terms of doing this vectorization
process because the way the the most
accurate way to do the vectorization is
instead of just vector I just taking the
map and trying to vectorize it and
there's commercial tools to do this what
we do instead is we actually say alright
we're going to start with those Road
intersection templates because they
correspond to the actual center point to
the intersections and then they contain
the directions of the roads and the
number of roads and we're going to do
the vectorization from starting from
those points
and so you can see here on this it's
going to gives you a sense is you start
in the middle and you can basically
going to essentially do the extraction
of the vectors based on those Road
templates and we get a very nice result
doing that a much better result than you
would get if you just tried to take the
whole extracted road networks tables
turn it into a vector layer so this is
an example result that essentially shows
the road vectors superimposed on top of
the original map so the road vectors
that were built here are shown in red
and then it's just super imposed on top
of the map so you can see how the
vectors we created correspond to the
original roads and you can see the
result here is actually quite good
you'll see some weird things that happen
on the edge and that's simply you get
some weird strange results as you get
close to the edge of the map so you know
that gets fixed when you stitch these
the tiles together you end up with nice
vectors along the edges as well if we
look at results I don't really have time
to go into details here but just give
you a sense so we tested this on 16 maps
from 11 different sources and we
compared it to a commercial tool called
r2v which is probably one of the you
know better commercial products for
doing this which is an automated raster
to vector conversion software and in
terms of completeness correctness and
quality which are really measures of the
correct lease extracted road data
relative to the false positives and true
positives here you can see that across
the board our system which we call stray
bow did better than our 2v and the
numbers that really matter here have to
do with the overall sort of completeness
Corrections and quality but also the
redundancy so it turned out that what
was happening here is that our tivity
would get high completeness by having a
tremendous amount of redundancy in the
data and redundancy is a measure of how
many times they were extracting more
than 1 pixel for the same road pixel so
you can see the numbers they're very
large they'd end up with lots of little
extraneous lines now we could have
gotten better results with our TV if
we'd spent the time to really tune it
with a bunch of manually specified sort
of pre-processing and post processing
functions but as you recall one of our
goals here is really to be able to do
map extraction here with very minimal
sort of
user input so we didn't want to do a
bunch of training on this okay so that's
the results in terms of extracting you
can see the results are actually quite
good in terms of the quality of the
actual data that were able to extract
the road gave the were able to extract
the second piece is to actually do the
text recognition so we want to be able
to take the labels that we find on the
map and do the recognition so we
actually know what the the characters
and words that are actually on the map
and there's really a series of three
steps we're going to do for this the
first is to automatically low-tech
locate the text string it sounds easy
because people are very good at this but
we have to actually find the text
strings and the actual orientation of
those strings on the map so that's so we
find the strings we're going to detect
the orientation and then what we do is
we actually rotate those strings so then
we can run off the shelf optical
character recognition software on it we
thought rather than reinventing our own
OCR software there's lots of good
commercial tools out there but the
problem of the commercial tools as they
all assume that you have the text string
located horizontally going across the
page and that's not the case with maps
so that's the final step okay so let me
show you give you a sense for the
different steps here so here on the Left
we start with the text layer that was
extracted notice this is just the text
layer we were able to pull this out
separated from the road there we go
through a dilation step okay and then we
look at all the connected characters
here and you can see this does a pretty
good job of just detecting the location
of the text strings except that some of
these strings you can see here we you
this large box of strings that are all
connected together because on some maps
they end up you know strings that go in
different directions the end up putting
very close to each other and so you end
up with these big blobs of text so we
have to have some way of actually
teasing apart these different text
strings here so we go through another
step here where we essentially look at
the size of these you know the larger
blocks here and we do some additional
processing to essentially look at the
angle of the characters with respect to
each other right what's the general
direction of the characters and doing
that we can then pull them apart so here
we have Olympian in Washington
hadley way which are all sort of
superimposed on top of each other and we
don't know exactly how to pull them
apart but what we do is we leave that to
the OCR software but rather just sort of
say well we think there's at least two
well at least three different strings
here one of course to one corresponds to
Washington with some you know extra
pixels you can see the end and the y
come very close to Washington and
likewise an Olympian we end up with this
w here and so we don't try to separate
out these pixels we just generate two
different strings and say okay we're
going to head generate one for
Washington and one for Olympian with
some extra stuff in there same thing
with the way here in Hadley way we end
up with this T from Washington sort of
superimposed here but once we do that
then we end up with this nice green
layer down here we see we now we've
actually broken up the text strings into
all of the separate components right so
we actually have all the individual text
strings identified and though well their
general orientation but but you can see
the boxes are still large here right so
if you look at the box around Olympian
you can see that we don't really know
the exact orientation of Olympian yet so
the next step is to actually figure out
the orientation the precise orientation
of this text string so if you take what
we do is we take the string Olympian and
we actually generate a set of
orientations for it and then run through
a technique called run length smoothing
which essentially generates it what's
called is closing operator we're going
to fill in some pixels on these on these
strings and then go through an erosion
step and the interesting thing is that
once you get the correct orientation
then the result of this erosion step is
you're going to be left with the most
number of pixels in it so we can
essentially use this to Jen determine
the exact orientation of the string once
we do that we take that are in the
correct orientation then we can run it
through a commercial OCR system which
will then do the recognition and string
like this it has no problem recognizing
this as Olympian it'll generate you know
the text string and because we've done
the registration of the map with imagery
or the vector data we also know the
precise lat long coordinates of the
actual string so we can actually you
know get not get just the texturing but
also its location so in terms of results
so
here are results here are some earlier
results we have more recent stuff they
I'm not going to present today but the
early results show on two different maps
on the Left we have a rand mcnally map
labeled RM in the in the table and on
the right we have this tourist map
international tourist map labeled itm in
the table and you can see the results
are actually quite good you know
character level precision which is going
to be the measure of you know how much
noise you introduced is over ninety-five
percent of both maps and then the
character level recall showing the
second column here is ninety-three
percent for the rand mcnally have
ninety-five percent for the
international tours now which is really
quite good for doing automatic
recognition because you can look and see
there's a you know potential for a
tremendous amount of noise on these dams
word level in precision recall is lower
and that's simply because you know for
any one mistake for a character right
means that you're going to get the word
wrong and so you expect the precision
numbers to be a bit lower for these so
here we ended up with precision in the
7076 281 percent for these two maps and
for recall word level recall
seventy-nine percent to eighty-five
percent but I view these as preliminary
results because we have some ideas for
techniques that we can employ on top of
this where I think we can get much
higher numbers in terms of to get word
level and precision recall into the
ninety percent level okay so that mean
it brings me to sort of related work in
conclusion there's lots and lots of work
really work on map processing and people
been doing that processing for the last
hundred twenty or thirty years some of
the older work on that processing
focused on you know stuff that was done
in the 70s and early 80's focused on
problems of just how to store the maps
because back then they were so large in
terms of size and how to actually see
the maps and then a lot of manual
techniques more recently people have
developed techniques for various
components so we built on a lot of other
people's work and the work we've done
but I think the the single largest thing
that distinguishes our work from
previous work is that most people in the
past focused on a single type of map
right usually they start with the
problem that okay I've got the USGS topo
maps and the problem is how do I
actually curry
the layers from this particular type of
map and they tended to focus on one type
of map and they optimize their
techniques for that type of map what
we've tried to do is to essentially say
all right we want to be able to handle
any kind of map well we assume we make
some assumptions we assume the maps
drawn to scale that it has a road
network on it and that we know the
orientation of the map but otherwise we
assume we want to be able to handle any
map that sort of falls within those
those requirements and to minimize the
amount of user effort required to
actually do that so a lot of the
techniques I'm not going to go to the
innovative techniques that focused on
specific types of maps and you know or
specific pieces of the map processing
and there's then I mean this is just a
brief survey of some of the work there's
a lot of work out their own map
processing okay so to conclude you know
what I presented today is you know a
general approach is essentially
discovering you know going out in
finding Maps automatically registering
the maps we would determine the actual
geo coordinates and the details of every
intersection point how it corresponds to
some other layer and then extracting the
features from these maps the new
contributions in this work include
disability to automatically identify a
map from other things that are not maps
the techniques to extract Road layers
and text layers from poor quality maps
that I described our approach algorithms
are automatically determining the geo
coordinates of the map and then our work
on feature recognition where we build
these accurate intersection templates
and in turn use that to build the road
vector data from the maps and to extract
the text labels from the maps there's
lots of applications of this kind of
work one obvious thing is simply
annotating imagery right you get a lot
if you're just looking at an image of an
area you may not really know what you're
looking at but if you can bring maps and
automatically and overlay them on top of
image then you can use that to automate
give you context and understand the
actual imagery we can use it for
creating and updating naps one
interesting thing I was surprised by is
we would take commercial maps and do
this automatic registration and overlay
them on the imagery and you would
discover there are a lot of mistakes and
commercial maps and be surprised how
many mistakes
actually in the maps and they're very
easy to see when you did overlay them
but also building naps for areas we
don't have good maps for and the last
one is constructing Gaza tears so one of
the big challenges that people are
always looking for very detailed sort of
features geocoded features that they can
use for linking other kinds of
information and stuff and so one thing
you can use maps for is actually
building these Gaza tears automatically
from all the different map sources that
are out there just last slide here so if
you're interested in learning more about
this I mean almost everything I talked
about you know everything I talked about
today is actually described in you know
some of our publications so the first
publication here on the top is a recent
paper we presented at the document
recognition conference that describes
her the overall approach and techniques
and stuff and then we have detail
publications on all the individual
pieces that I described today and these
are all in my webpage if you just google
my name you'll find my web page and you
can go in search for for all the papers
on this topic okay I think we have a few
questions thank you yes
excellent question okay so the question
was how much information do we need to
know about the map in order to do the
registration currently we assume the
either we know the same of the city or
the bounding box than that falls in but
that's a problem that I want to get back
to because I think there's ways that we
could actually completely automate that
I'm one of my goals is to be able to
just defeated a map and say okay tell me
exactly what this is a map of and so I
have some thoughts about how to solve
that problem but we haven't fully solved
that yet but today it's just a general
area of the map question over here yeah
excellent question all right so the
question was what other features have we
worked on extracting there are many
different interesting features I mean
you mentioned parks and buildings we've
focused almost exclusively on road in
text features but in general based on
the work we've done in the maps we've
seen I think that the work we've done in
extracting the road layers would extend
very easily so pretty much any feature
layer and we just haven't worked on it
partly because you know we wanted to do
roads because we can actually then use
the roads for doing the registration and
we wanted to do text because then we
could lend label the roads but I think
be very interesting to then go on and do
political boundaries parks all the water
features and so on they're often shown
in different layers and different colors
and so that's why I believe that the
techniques for doing Road features would
extend very nicely to the other features
um let's see we do okay so the question
was the fine which is that the the
erosion and dilation operation you know
do some distortion of the actual
information of the actual Road pixels
and so the question is you know good did
we have we considered actually using the
original pixel locations to help us
recover information that might
correspond to things I call this X and
stuff the answer is yes I mean one of
the things that how is happening here is
that you're right when we're doing the
processing on the on the road features
there is some distortion that happens
but a lot of what we're trying to do
here is to actually recover enough
information from the map to actually
first do the registration and location
of the intersections on the map and once
we have that then we essentially can go
back to the original road pixels and do
the extraction the road pixels right now
we're doing the extraction from the
essentially the pixels that after we've
actually reconnected the road networks
and you know that's probably just
because it's easier to do it it's easier
to do that vamping on that but it would
be worthwhile to go back and look at you
know some of the more subtle things that
happen because you're right when it gets
to certain kinds of features like the
cul-de-sacs you mentioned or the other
the other place we see problems are on
things like exit ramps and entrance
ramps or free raise because they have
sort of unusual angles and stuff that
tend to get distorted by those features
a lot so would be worthwhile to go back
and look at the original pixel locations
to try to recover that information we
don't do that in the current system but
I think it's something we've looked at
we've talked about and just haven't
integrated it yet Michael we did we did
actually and it turned out that was
actually quite a natural thing to do on
the USGS topographic top of topographic
maps because the top o lines are
typically shown in a different color and
so just like we can do the
Road layer we can do the same thing with
the top o line to pull this out yes
that's a great question um you know it's
something that I've just started to
think about it would and have been
working with some other folks put
together proposal because one of the
opportunities here is now that we can do
this processing on sort of wide variety
of maps is to look at the apps over time
look at historical data and my intuition
is that we don't require a very high
threshold to actually be able to link a
set of a map to the location in terms of
the number of matching intersections
because it really has a lot to do with
the layout of the intersections and my
intuition is that roads tend to be
relatively monotonic in the sense that
people put in roads and then they build
more roads we build roads and you know
they do move them around from time to
time but not a lot and so I think that
or if you look at historical maps that
we probably could do a very good job of
being able to link them over time we
haven't done it yet so it's really just
a hypothesis but I'm hoping to actually
get some funny to work on it hey
especially oh yes yes I've read them and
I don't think we violated me to uh Road
Tracy no imagery you mean as opposed to
doing it from maps at all yes
yeah so in fact right the other obvious
approach to doing the the question that
Sebastian asked was you know have we
ever consider looking at aerial imagery
and just doing the extraction of the
road lines just directly from the aerial
imagery and you know that's the other
obvious competing technique here to get
the road locations and people have been
working on you know extracting roads
from imagery for for many many years and
in general it's a hard problem and it's
hard for a couple reasons it's hard
because first roads are often obscured
by other features so one big problem is
that you end up with trees often
blocking the road so you can actually
see the location the roads sometimes
they get around that by you know in cold
climates they collect the imagery you
know in the winter when the leaves are
off the trees but that doesn't always
work with evergreens the other problem
is that in you know cities with large
buildings and stuff than the buildings
often can obscure the roads and so so it
can be quite challenged in that get the
data off the roads off the off the
aerial imagery and the other problem is
that simply Road colors so here we
actually did a different project where
we looked at automatically aligning road
networks with imagery and so we had to
do some extraction of the road pixels
from the imagery and one of the big
problems is simply that the road colors
are not consistent not like on a map so
often you'll find you'll people's
driveways the rooftops and stuff can
actually have the same pixel colors as
the roads themselves so there's a bunch
of challenges in terms of getting the
road data directly from the imagery I
think one of the interesting things that
we have explored a little bit is
combining the two right that you know if
you combine the fact that maps give you
the general location for the roads and
the imagery gives you the detailed
information about the roads that we did
a small pilot project with another group
look at if we could actually combine the
two and improve the improve the actual
extraction of the road lines from the
image by using the information from the
map but I think there's a lot of
information that are contained in maps
that you can't easily get directly from
the imagery
yeah so the question was to what extent
our techniques will actually apply to
historical maps so one of the
interesting things is you know one of
the assumptions that we make is the maps
tracks you drawn to scale and you know
if you look back in terms of mapping
mapping technology in terms of being
able to draw accurate maps I think
they've developed quite good techniques
in the late you know mid to late
eighteen hundreds and so you know based
on what we've seen we believe that you
know as long as the maps were actually
done to scale or more or less to scale
there's some cartographic license that
happens in maps but if there's a general
scale to the map then we believe that we
can actually go back and do many of
these historical maps we've looked just
recently we've looked at a number of
maps from places like China that go back
into the 1900s in late 1800s and you
know the pixel colors for roads tend to
be quite consistent the the fonts even
actually essentially even the fonts ok
are were done by hand but the way they
did them on many of the store call maps
before they did computer typesetting was
they would build a stencil for the
actual characters and then they would
use that stencil to actually draw all
the characters on the maps so the
character the character shapes are
actually quite consistent in terms of
recognizing the characters so so I would
say in general we can do historical maps
that were done to scale and use some
standard templates in terms of the
actual lettering or characters on the
mess
because the question is what extent the
techniques are going to be applicable to
sort of the available data given that
you have issues of copyright and the
fact that some maps could just be
generated from the vector data vector
data may be may be available to actually
create them it's a really good question
and I think it depends very much in the
application so you know I think even
today there's many interesting sort of
research problems that we could actually
solve by just being able to pull out the
maps that you wouldn't necessarily ting
you know IP issues and as I was
discussing Michael the IP issues vary a
lot from one country to the next and so
you know some places you can actually
extract things like the the text
information without necessarily but
incorporates another places that might
be an issue and then you know it depends
very much on the actual application that
you want to use it for so we're talking
to various social science this and such
they're really interested in being able
to look at road networks and how they
developed over time and then other
people we've been talking to our very
interested in you know being able to
build very detailed Gaza tears for other
kinds of applications and you know both
of these things are things that I think
are very compelling uses of the
technology that wouldn't violate any of
the IP issues those questions okay well
thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>