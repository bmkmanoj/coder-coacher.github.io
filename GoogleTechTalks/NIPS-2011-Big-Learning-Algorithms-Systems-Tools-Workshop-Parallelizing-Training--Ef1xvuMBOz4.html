<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: Parallelizing Training ... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: Parallelizing Training ... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop: Parallelizing Training ...</b></h2><h5 class="post__date">2012-02-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ef1xvuMBOz4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay can everyone hear me okay at the
back oh yes great and hey nice hey
thanks for the introduction mission good
afternoon everyone as Misha served my
name is Derek Murray from MSR Silicon
Valley and today I'm going to talk about
how we use various Big Data techniques
to parallel eyes training for one part
of connects body tracking pipeline now I
was I was fortunate enough to get to
work in a small parts of this I was an
intern MSR two summers ago accordingly
this means most of the work was done by
other people and amongst them Jamie
Shelton was responsible for developing
the learning algorithm that we used and
I'll touch on some details of that
briefly mihai video in Silicon Valley
did most of the work in porting the
algorithm to run on a cluster using dry
add link and Mark finocchio was
instrumental in getting this technology
transferred into the products really
hurt any yes the product in question is
is this kinect for xbox 360 which if you
haven't heard of it is a you kind of
input device for the xbox 360 games
console stuffed full of sensors
including a microphone for voice
recognition a regular camera for face
recognition and a depth sensor that
captures the scene in three dimensions
and this talk were most interested in
the depth sensor because it's this
component that's able to capture you
know your sweet dance moves or whatever
and turn them into signals that control
what's happening on the screen so where
does machine learning come into this
well the problem the resetting I
dissolve if I was taking a depth image
recorded by the Kinect and labeling the
parts of that image that correspond to
different parts of the body this
brightly colored output is then used to
build a skeletal model of the player
which games and other applications can
use to perform gesture recognition
so how does exports classify these
images in real time well to be real time
it needs to do this very quickly and for
this it uses a decision tree or to be
more precise er a randomized decision
forest that runs on the xboxes GPU and
training this decision forest is where
we need big data analysis we use a
cluster machine running the Dryad
execution engine and provide it with a
large corpus of depth images of various
poses paired together with the
respective ground truth body parts
classifications for those for those
poses so let's take them over now and
revisit the standard algorithm for
training a decision tree so for some
node in the tree you have a collection
of examples each of which has a class so
here the classes are blue and orange and
there are six examples of each so to
refine the current node in the tree the
algorithm which is this clip in sure do
you think I should hold out or something
maybe like to the practical level proper
sorry witness all right wonderful okay
yes so yes we've had a number of
features on each of the examples each of
which splits say examples into two
groups or more but we only consider two
in this work and heuristic alee the best
feature to choose is the one that
maximizes normalized information gain so
the examples are then divided according
to their value for the best feature and
the algorithm is recursively applied to
the groups so to make this a bit more
concrete the Kinect classifier uses 31
classes corresponding to different parts
of the body and 2000 features which
correspond to differences in the depth
signal at different positions in the
image so with numbers like those there
are many opportunities for paralyzing
now room for example and the simplest
thing to do since we're building a
decision forest
BTW parallel is building the different
trees in the forest however because in
our application there are relatively few
trees and each tree takes a long time to
train we didn't bother exploring this
option instead we paralyze the
independent work done in processing the
individual tree nodes and i forgot to
say but the trees we're thinking of have
about our complete binary trees of depth
19 or 20 so yep on the order of a
million nodes in them so there's plenty
of parallel work to do also on the
different training examples which are
pixels in the context of a training
image and also on the features so now as
I've described it the algorithm has a
rather divide and conquer kind of flavor
since for a given node all the work
that's done processing its children is
independent however the number of nodes
is so large remember Arab around a
million nodes that would be too costly
to schedule a new batch job for each
node and this would potentially require
a lot of data to be shuffled around to
make the subgroups for each child node
instead what we do is we flatten this
recursion into iteration and perform the
work for one level in the tree in each
job in a single job brother so let's now
take a look at how a single layer of the
tree is processed so we start with peers
of training images match together and
distributed across the cluster these
form the input to the first step which
has which performs one task per batch
and we also pass in the existing tree
that we've computed so far as the second
input so what does this task do well the
first thing is to transform the set of
images into the much larger set of
examples so these are individual pixels
I think which is about two thousand
pixels uniformly at random from the
training images to use as training
examples for each example then it uses
the existing tree to identify the Nord
with which that example is associated
and you might think that we would keep
this around from the previous round but
it's much cheaper to recompute it than
to persist it to disk between rounds and
this also gives us
tolerance having associated an example
with the tree node the algorithm then
evaluates each feature against the
examples each of the two thousand
features against each example yielding a
direction left or right depending on the
value for that feature and indicating
which of the two child nodes of the
current node would receive this example
if we split on that feature and having
done that we emit a tuple containing the
for the current example in feature the
lord ID the feature ID the class from
the ground truth image and the direction
in which the split would happen and
finally we grip these by the key by node
feature class and direction to build a
sparse partial histogram of of the
examples so next what we want to do is
compute the complete histogram for each
tree node so the partial histograms we
repartition them by node ID and some
together the counts for each key so now
we've moved from parallelizing on the
training images to parallelizing on the
nodes and the decision tree so this
aggregates enough data together for each
node to compute the best feature the
feature there's the best normalized
information gained and so the algorithm
is able to yield a new tree node
splitting on that feature
and now we have a set of partial tree
frontiers from these orange tasa fitted
up new partial set of partial tree
frontiers containing the new nodes
computed at this round so the last step
in the level of the tree is to marriage
the frontiers together with the existing
tree to produce the new tree for the
next round and having done this we can
pass the new tree back into the same
algorithm and repeat until we reach the
desired depth so a clustered version of
this was based on an existing
small-scale version they used a single
multi-core machine to build the tree and
I think it could train a tree to depth
18 on ten thousand images in about a day
our version could train three trees to
death twenty one hundred thousand on
sorry on a million images in the same
time period so this was certainly worth
doing we used dried link which is a
cluster programming model that was
developed two ns are the uses higher
order link operators to define parallel
operations on collections and translates
these into dryer programs that execute
on a distributed cluster so these link
operators are might be familiar if you
used to database programming things like
select where group by and so on but
there are additionally they are strongly
typed and the allow programs to call
directly into c-sharp code which in
which the the learning task was
implemented so tightly had several
advantages for this implementation in
particular because the histograms had to
be heavily optimized through just memory
consumption they were implemented as
custom types and dried links integration
of the.net type system made it no
problem to implement operators in these
types in addition dried link generates
automatically serializers and
deserializer is for these types which
can be tedious and error-prone if you
have to do yourself and the underlying
dryad system provided fault automatic
fault tolerance within a job so it was
able to deal with transient crashes and
network outages which were fairly common
given that we were using commodity
machines for for testing this
ah focus on wrong place there we go so
these are just some numbers
corresponding to one of the trading
rooms from which one died present a
couple of graphs so we had 1 million
images in the training set two thousand
example pixels from each we were
competing 2000 fixtures features which
were continuous features with 50
candidate thresholds for each feature
and just to give some idea of how long
the training tapes 10 test cluster
training of three this is a different
test bus from the time that I'd reported
earlier but it takes about a tree to
depth 19 takes about one day we use more
machines for the other tests the red
bars show the number of dr vertices
executed in each rounds as a massive
number of processes going on here and
the blue line shows the amount of time
spent in each stage so for the early
stages it was taking about 30 minutes
for to process a level in the tree and
this increased to two and a half hours
as we got to level 19 the large jump of
the number of processes at depth 10 and
16 indicate where we had to adapt our
paralyzation strategy so the accumulated
histograms that we're aggregating
together we're becoming far too large to
store memory so what we did was to
additionally parallel eyes on the
feature evaluation so we do this in
batches and add another marriage stage
to find the best picture per node for
each across all of the batches this
graph I don't know how well you can see
it it shows the execution profile for a
single level in the tree so along the
x-axis we have time and on the y-axis
there is one data point for each of the
different machines in one of her
clusters the colors correspond to
different phases of the computation and
hopefully you can see a wee bit better
if i zoom in so if i zoom in this one
little detail of the graph the green red
and blue phases of the of this graph
correspond to building the partial
histograms for different subsets of the
features so this isn't a later around or
the histogram really large and these
praises these faces don't proceed in
lockstep there
I have work done in across the training
set is different and is quite skewed but
on average the cluster has kept
sufficiently occupied that the skew
cancels out and as you can see if we go
back to the overall view these all the
machines finish within a few seconds of
one another so as an application this
really stretched the capabilities of
dried link which wasn't really designed
to handle this kind of algorithm so for
one thing we had to work around the
performance penalty that link itself
imposes in order to be maximally generic
in to be able to work on any kind of
collection each link operator performs
at least two virtual function calls per
element so this when you have a huge
number of elements in the future
evaluation the primitive computational
step is very very cheap this overhead
began to dominate so we had to manually
in line various operations meaning we
can write quite as pure link program as
we would hope to this actually sparked
some separate work on the stand waft
automatic optimizer for link and we
presented details of this at PLD I are
living the year another challenge was
that many big data systems are optimized
to handle large numbers of small data
items and drivelling is no exception in
this regard this meant that we were
often confounded by buffering strategies
for example when you emit records from a
dr link operator they are the
implementation buffers them up because
usually when you have a few small few
bytes per record it's wasteful to go to
disk every every time you write that but
when you're dealing with multiple
hundreds of megabytes worth of histogram
in a single record you don't really want
to be buffering at all because you end
up buffering so much the Euro know of
memory for this we had to come up with
an adaptive buffering scheme and we had
a similar problem doing work sharing
between the chorus in a single machine
so yeah we had been using the parallel
link which is a sort of automatic
multi-core parallel version of link that
paralyzes own in-memory collections and
we had to change the partitioning scheme
that it uses so that it didn't build up
cues of too much too much data a third
problem was that our challenge was that
because these jobs were much longer
running
our average job we stuck to see more and
more unusual faults so this not just of
worker machines are the network but also
centralized components might have some
periods of in unavailability causing the
whole job to crash so to deal with this
we added some check pointing to the
driver program that was submitting each
of these jobs and this allowed us to
restart from wherever a computation left
off it also allows us to change the
implementation in the middle of a
training run which in the early days
when it was taken much longer was really
useful in this case we'd be taking we'd
be starting over from where it crash
because it ran out of memory because we
implemented it properly but that got
better so I'm real out of time so to
conclude and this talk I've told you
briefly about distributed parallel
implementation of decision tree training
this capable of training 320 level trees
on a million images in about a day our
implementation all the data types of
uses are generic and it could easily be
adapted to other training exercises but
the main idea to take away is that to
make this work in a big data setting you
flatten the recursive structure of
training into an iterative computation
and decompose it into multiple jobs run
on the cluster finally if you're
interested in more details about the
training pipeline including how the
ground truth is obtained from motion
capture data and how the classified
images are converted into skeletons I
encourage you to read this paper from
cvpr 2011 but at this point I'd like to
thank you all for listening and take any
questions you might have
we did we did yeah that was so that
became really important once you got to
think depth 16 in the tree you also
needed to put into the partition by
feature no notice so the main data set
is just the images we kept the same data
set and that didn't change these were
only ever read from disk endeavour never
written anywhere else oh right so we
were is more of a hybrid of the two
approaches so images would live on I've
we replicated for fall Tom's I think he
lived on about three machines I'm
coincidentally when we partition
features it was into three sets so that
meant that we could in theory run those
completely independently although we
tried to keep the cluster oversubscribed
so that the performance was except on
the efficiency of the training was high
the accuracy change I don't know the
numbers off the top Myer there in the
CVP our paper it improved secondly with
more images and and using the multiple
trees three I think was the sweet spot
to avoid overfitting you stole some
improvement up to five we didn't they
were diminishing returns Oh
alright well it was beneficial from our
software engineering point of view it
made it release you take this existing
solution actually was based on while the
reserves NFL just a single process
version then it tried to make a version
for mpi net which was not working out
very well particularly because we're
using these same unreliable machines and
there was no Devon nurse or no automatic
checkpointing support or fall times but
the amount of change in the actual
machine learning court was very small to
move it to a to move it to the dried
link implementation so we had Jamie
who's a machine learning expert nehi
who's a drive link expert who knows a
bit about machine learning and the
together were funded quite easy in a
week or so to get something working to
make it perform was more of a challenge
I was why I ended up doing most of
finding the strange performance
regressions and trying to trying to
hammer them down but one thing we found
is that it was getting so much faster
and we were just from the MPI version
was taking a week to do what we could do
in a day so they would ask for more and
more let's train another level of the
tree does just double the amount of data
that you're passing around or quadruple
or you know and it was mostly doing that
that we discovered the real challenges
wait</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>