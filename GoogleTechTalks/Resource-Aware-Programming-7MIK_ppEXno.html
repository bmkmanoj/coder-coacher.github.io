<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Resource Aware Programming | Coder Coacher - Coaching Coders</title><meta content="Resource Aware Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Resource Aware Programming</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7MIK_ppEXno" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello welcome to the tech talk resource
aware programming it's my pleasure to
introduce Wylie taha who I met at Rice
University why was giving a talk and now
he gets to do the same except at Google
which i think is pretty cool place to
give talks anyway I know and further ado
here's what we cool thank you very much
Chris it's a pleasure to be here today
and the goal is to tell you all about
the interesting research in programming
languages that we're doing at Rice and
I'll avoid getting into technical
details and theorems and formal isms and
so on and focus on using various
examples and languages that we've built
and intuitions and then motivation from
the kinds of problems that we'd like to
see our language is being used to solve
so to get started I'd like to say that
one of the key things to building better
programming languages is to design
abstractions that would help us build
the programs that we want to write
abstractions like arrays functions
objects modules and so on all these are
examples of things that we've seen
before in different application domains
like high performance computing or
databases for example where they've
proven successful all right and there
are a lot of standard examples of these
abstractions that we know pretty well
how do they help in a lot of cases they
do a very simple thing which is to make
our program shorter and more manageable
often they also make it easier to reuse
so that when we've solved something a
particular problem before it's easy to
reuse the solution to solve a new
problem that we've seen and if they're
designed carefully then they can also
help us verify and reason about the
correctness of our programs okay and in
particular reasoning is something that
we're very interested in and when we're
able to do that what we get at the end
of the day is a guarantee about our
program often through the the language
that we've created or the type system
predict you'll get a guarantee about our
program and the guarantee says a
specific bad thing won't happen at
runtime okay so you've built this
program and it looks like it's supposed
to be doing a certain thing but we're
also interested in knowing that there
other bad things that it's not going to
do okay of course ultimately if we take
verification all the way then we go the
next step and we be sure that it's doing
what we wanted it to do okay but a very
practical thing is to have at least
guarantees about certain bad things not
happening and here we're interested in
things classic things like buffer
overruns or runtime errors and so on
okay and there's very intricate
interplay between the design of
abstractions and what we can do in terms
of reasoning about our programs
afterwards alright so this the last
slide is supposed to be motivation for
you know the design abstractions that we
get in high-level programming languages
high level programming languages to me
are things like Oh camel ml and Haskell
and and all these you know very high
programming high level programming
languages that we know about now if we
go to the real world and look at the
kinds of programs that people are
writing today then we'll find that well
what do they look like they look like
the controllers that run inside our car
all kinds of medical applications and
then health services applications
robotics applications they run important
they have very important control
software that determines what function
the rest of this metal does and the same
thing for defense applications so what
languages do people use to write these
pieces of software there are things like
C and C++ for the most part and if we're
very interested in in performance of
their big computational components of
the system then we might find that the
written in Fortran these are actually
even though 40 or 30 years ago these
were high level languages today they're
not what we would consider high level
languages based on the the new
innovations that we've seen over the
last 20 or 30 years so why is it the
case that for a lot of the applications
and the software that is being written
today we don't see the high level
languages being used so my thesis here
is that basically at the same time that
we use these more advanced abstractions
we're also giving up
control over fairly important low-level
details and a lot of cases especially
for embedded and real-time systems a lot
of times the benefits that we get there
are a lot of benefits that we get from
the high-level abstractions but the
programmer that's responsible for
building the system at the end of the
day can't really give up the control
over the low-level resources because
that programmer system designer is the
person that's responsible for achieving
these real-time guarantees or the
various performance characteristics as
the system must have okay so there are a
lot of examples of abstractions that we
could use to illustrate this point the
simplest one is maybe automatic memory
management okay automatic memory
management allows us to think of dynamic
data structures at a higher level than
the model where we allocate data
explicitly and then deallocated at the
end of the day and we get this huge
advantage with dynamic memory management
of safety because we have only allocate
operations and no explicit deallocate
operations that we don't have to worry
about dangling pointers which are a big
safety problem and languages that don't
have dynamic memory management so get a
very nice abstraction from dynamic
memory management at the same time this
means that we relinquish control over
when things get allocated and also when
things get deallocated in addition
because the system has to do more work
for us and we don't necessarily know
when this work will be done we may be
doing a critical computation that needs
to be done quickly for this particular
application and that the garbage
collector must run and suddenly we have
no idea how long it's going to take for
this computation to finish okay so this
is just one example of many instances
where we care not only about the
functionality or input-output behavior
of a program in terms of the standard
input/output behavior but we care also
about the resources that are being
consumed the basic resources being time
and space needed for the computation but
we can imagine all kinds of other
notions of resources that depend on the
particular kind of problem that you're
solving using the the software artifact
that that we're trying to build okay so
the question that we are interested in
what are the abstractions that can be
used to allow people to build the
programs that they want to build and at
the same time get guarantees about
resources of this form
so the goal of the research of our
research is basically to have be able to
produce languages that are as expressive
as possible to the programmer so that we
could still structure our problems as
clearly as possible and reuse the
solutions that we have before the same
time in a just side by side to this
expert civet e we want to have
guarantees that are strong as possible
about the programs that we write okay
and essentially not let the mechanisms
for getting guarantees and better
properties over programs get in the way
of being able to write programs in a way
that is as natural as possible right the
way we're going to do this they're
essentially three components to to to
our approach the first is called
multistage programming and essentially
this is a way to separate the design
that's captured by a program from the
actual implementation that comes out of
the design at the end of the day and one
way to think of this is that our
programs are really our designs are
going to generate the programs that we
want to run at the end of the day okay
another aspect especially important for
real-time and embedded systems is to
incorporate a treatment of reactivity or
a way that allows us a mechanism that
allows us to write programs naturally
where these programs would be
interacting with a stream of inputs
coming from the outside and producing a
stream of outputs back to the
environment and finally using advanced
type system techniques and particular
linear types and index types to be able
to express much finer properties than
the typical type system or traditional
type system would let us do it okay so
the plan for the rest of the talk we're
going to start with a sort of a
caricature of traditional computing
called batch computing where all the
inputs are available in one shot for a
computation for the program that we want
to build and the output comes only after
we have all the inputs that are needed
right so we're going to go extend this
model in one dimension and here what we
have is some of the input arriving early
and we actually use that as soon as it
arrives to do some computation and
produce a new specialized computation
the specialized computation can then
receive the rest of the input and
produce the output more efficiently okay
and we can even later we'll see how this
separation is also useful for getting
stronger guarantees about the final
phase of the computation so the other
almost orthogonal dimension is
reactivity and we'll talk briefly about
what this means and what programs
written for this model of computation
would look like and the work that was
done to make sure that we have stronger
guarantees about a reactive programming
model and in some sense we're going to
be combining these two approaches at the
end of the day this essentially the the
ultimate goal of the research that we're
doing so in this in this view we
basically are able to write our programs
as designs that could use arbitrary
resources to synthesize the final
product that we want to produce maybe
it'll run on a small platform maybe
it'll be a real-time program that has to
run as part of a bigger controller in a
car for example and we still want to be
able to get very strong guarantees
before we produce this program for any
particular instance another way of
seeing this is that we want for our
design we want to have a type system
that will tell us that for any input
what will produce in the second stage of
computation will also be guaranteed to
be resource bounded before we know what
the emphasis are so will first begin by
looking at a multi-stage computation
what we do here what we'll do here is we
look at a simple program written in a
functional language that performs a
simple computation of the taking an
integer and and raising a real-valued
number to that exponent so we'll take a
natural number n and a float and we'll
compute X to the N the way we do this in
no camel is fairly straightforward the
code is is as simple let means we have a
declaration wrecked says it's a
recursive declaration this is the name
of the function we're defining and the
two parameters with their type and we're
annotating the function also here with
the type of the return parameter
just as a side comment we don't have to
write these types because okay mo can
infer these types for us automatically
but we've included them here for clarity
all you're going to do is we're going to
say if n is equal to zero then we're
going to return the answer 1 otherwise
if n is even then we'll do this trick
where we call the exponentiation on the
end parameter divided by 2 and then
square the result right and similarly if
n is odd then we'll just take X and
multiply it by the exponent by recursive
call to X where n is reduced by 1 so
this piece of code is really simple it's
doing a very trivial fairly trivial
computation but it illustrates an
interesting example of a problem where
nobody would really write this kind of
program if they needed to compute
exponentiation ok it has too much
overhead it's a generic program it's
easy to understand but as a piece of
code normally we wouldn't write programs
like this ok why would we not do that
well for things like X to the power of 3
cubed there are much easier ways to do
them much cheaper ways to do them than
to call this function right ok this is a
problem with abstraction how can we
simply allow the programmer to write
something like this and not pay the
overhead for this generality every time
they want to compute X to the power of
three so the basic idea of staging is
going to be to let us have a way to use
this input n if it's available early and
produce a specialized program so
essentially the picture that we want to
have is something like this where the
one computation that we had initially is
split into two parts one we want to know
gets done early and be guaranteed that
it gets done early ok this is going to
be the p1 part and the p2 part is going
to be what's left to to be to do in the
second stage we're able to do this in a
multi-stage language with some simple
annotations there are the things the
changes are the things in yellow but
first let's look at the types the basic
idea here for statically checking
multistage computation is not only do we
say that X is a delayed value so we're
going to treat X symbolically but
also say that X is a delayed value
that's going to represent real value in
the next stage okay so this is the extra
information that we have here and we
know that not only are we going to
produce a symbolic representation of our
computation at the end but this symbolic
computation corresponds to a value of
type real at the end of the day all
right and this makes sure that we're
able to guarantee that whatever
generator we right here will always
produce a well type program and we never
have to worry about free variables or
you know inconsistent computations in
the generated program all right and the
rest of the program we're almost sort of
like guided by the return type we know
that this is a delayed real so all we
have to do to get a delayed real out of
a real is to put it in quotations and
this is what we do here this line
doesn't need to change also actually the
if statement doesn't need any changes
because n is still an integer and we
could do the test n equals zero
immediately in the first stage but this
gets delayed for the second stage the
real reason why we have to keep some
things in the set to the second stage is
what happens here and in particular if
you look at this line we're going to be
doing a multiplication or we used to do
a multiplication here and what's
happening is that this X that we want to
use in multiplication is now known to be
delayed meaning it's going to be coming
in a later stage okay so because this
multiplication is delayed to express
this in our program we coat the whole
expression this means the multiplication
is not done until the next stage to
incorporate the X that is coming in as a
parameter we put this little escape in
front of it say this is a piece of code
that needs to be spliced into this piece
of code that we're creating here the
other really important thing is that we
can also escape the quotations around
this whole expression and say well you
know what the call to exponentiate can
be done right now this doesn't mean that
we're going to get a real-valued results
from the call to come to X because now
this is the stage 2 X we're changing our
whole program what it means is that all
the testing like the conditional and
this other conditional and all the
additional computation besides the
multiplication is going to be done in
the first stage so in fact this escape
here means we can make do
call immediately we can also do the
subtraction from subtraction from n
immediately and we pass it ex still as
the reference to the same delayed
computation for the future stage yes
question that's a very good question so
the question is if we have another
problem this is a particular sort of
variant of the power function where
we're getting this input early in this
input late the question is what if we
have this early and maybe we think we
could do some work based on this and
this is the one that's late or we have
some information mix of the information
so what we would do in the simple case
is we would actually write another
version with different annotations here
on the types and different annotations
in the code and we would be able to use
each of the two variants for different
cases in general there's another trick
very nice trick that we could do which
is called abstract interpretation and
that would allow us to use richer
representations for these two things and
decide do all this work ahead of time
mechanically I'll come back to this a
little bit in the more sort of the next
example actually okay so hopefully the
explanation of this was clear to
everybody if there any questions please
go ahead and ask me now this is done
similarly and squaring also has a
similar situation to multiplication
where we don't know what the value here
and as a real value is going to be so we
delay the square in operation in the
same way okay now how do we use this
right this just highlights what we were
saying once we've staged added the
staging annotations and we have a stage
power function then to use it we could
construct a little piece of code that
says we're declaring a function f of X
and in the body we're going to escape to
do to make a call to this computation
we'll call X where the argument of five
exponent 25 and notice we're passing in
this symbolic value that's bound right
here okay one of the features of
multistage languages is that there is
never any possibility of confusion
where this is coming from so unlike a
lot of sort of like early languages
where this is just a symbol in a
multi-stage language this is actually a
statically static index into this
reference here so there's no possibility
whatsoever for confusion about where
this X is coming from there's no dynamic
accidental dynamic variable capture and
so on so we evaluate this term and this
is exactly what we get back okay and
this is completely mechanical because
the staging annotations are very much
like commands in our program that tell
us exactly what we need to do there's no
magic symbolic computation or or
simplification it's all determined by
the programmer all right obviously this
is much more what we would like what we
would have written by hand if we didn't
have staging constructs in our language
in the sense that you know we're doing
straight line computation for this
particular problem this is not quite
having the times one here is not
something that we would do but there are
a lot of systematic ways to make sure
that our generators don't produce this
kind of thing in the first place and of
course you know this is a much more
efficient and later will say you know
much more resource bounded than the
first computation just typical examples
of the kind of performance effect of
staging in the exponentiation function
that we're looking at if we compare the
unstaged version with the second stage
the result of running the the generation
and compare this computation to this one
speed ups vary from let's say you know
five sometimes a little bit for other
examples lower than five they can range
from 4 times 2 40 times depending on for
interpreter examples if we take an
interpreter and stage it and whether we
do some additional optimizations so one
thing that you know we always we often
really get asked is how how much of a
speed-up can you get from staging or
from partial evaluation which is
essentially the same idea done
automatically it can really be arbitrary
all right there's no limit to how much
gain you can get partly because partial
evaluation means you're taking some of
the inputs and doing the computation or
and doing some of the computations
if you happen to take all of the input
well that's still part of the input and
you could do all of the computation and
you would be basically done in the first
stage right what's more important really
to understand about staging is that it
allows us to write programs that we
normally you wouldn't have been able to
write before because the cost of
abstractions would have been too high
okay so like the power function the code
for the power function we wouldn't have
been able to write this or a lot of
other programs that are similarly very
general and we would have had to write
basically settle for writing special
cases by hand because we can't generate
we don't have a clear mechanism for
generating these things automatically
okay so this is a larger briefly
describe a larger example where we take
the fast Fourier transform which is
something that a lot of times is needed
in software and very often actually
implemented in hardware because it's
used in a lot of signal processing
applications the idea of you know of
this example is to see how close can we
get to being able to write programs that
look like the mathematical very high
level descriptions of this computation
and still be able to get implementations
that are fairly efficient in in terms of
the low level representation of the
computation so this is a mathematical
definition of the fast Fourier transform
how can we go from something like that
looks very similar to this to an actual
implementation all right what we did is
we brought ok mo code that looks very
similar to what we have here and of
course because okay mo happens to be a
functional language is very easy to
express these things all these things is
just parameters and because this is a
recursive definition also it's very easy
to express it just as concisely as we
have here then we've staged it and we
decided to see how well can we do if we
know the first parameter of the FFT
which is the size of the problem all
right so there are a lot of interesting
things that come up in a bigger example
so like somebody asked you know what
happens if we only know part of the
information or if we have different
kinds of information that we know about
different parts of our parameters with
the F of T example all kinds of
interesting issues came up
and the good news is that actually these
are basically the main issues that ever
come up when you're staging programs and
managing them is basically something
that if you if you know how to do it for
small examples then basically that
provides us with a systematic way for
doing it for bigger examples one of the
first things that comes up with stage
computation or any kind of program
generation technology in fact is it's
very easy to have repeated computations
and particular whenever we put
quotations around a certain value
instead of giving back returning a
result which is like 17 or 14 a very
simple value it's very easy to write
programs that produce very large values
during the computation that can slow the
generation process significantly it can
also produce very inefficient programs
that repeat the computation several
times so there's a trick that I was
introduced to deal with this called
stage memorization and the challenging
part of doing this in the generative
framework is we don't want to generate
code and then look at it later because
if we generate code that gets duplicated
if we try to first generate code with a
lot of duplication and then do common
sub-expression elimination well we've
already done something that costs that
we're only generate very generated
something that's exponentially large and
then anything we do to solve that
problem is going to be waste of time so
the trick is to make sure that it gets
done before anything gets generated
another thing is it's also common to see
in generate automatically generated code
simple computations trivial computations
which just copy one value from one place
to the other okay essentially the same
mechanism that's used in stage
memorization can be done can be used to
deal with this problem and it turns out
to be the first instance of this idea of
abstract interpretation that we could
use to represent the parameters the
dynamic values that we're producing in a
way that tells us some useful
information about this dynamic value
ahead of time similarly the same can be
done for this and you can see that if we
deal with this problem this also takes
care of the output of the power example
or we had x times x times one at the end
ok so all these problems are dealt with
essentially in the same way and finally
one really interesting thing that
happened
we have used for a long time this ideal
of taking something out of math book and
implementing it directly and being able
to run it efficiently and it was kind of
surprising that if we took the
definition of fft as it is from a
textbook and we're you know somewhat
naive about how exponentiation of
complex numbers is done then we find
that we get some pretty bad roundoff
errors as a result and this was
something that we also notice quickly
and had to deal with it turned out that
in some ways it's related to this but
maybe not exactly the same thing the
good news about this particular approach
to doing things is ultimately we found
that to get really good graphs for the
computations so independently of the
specific order in which things get done
to get the smallest number of
multiplications and additions in the
generated computation we really only
need a very small number of
simplification operations in combination
with this abstract interpretation idea
and they're fairly simple properties so
you know the properties of zero and one
for addition and multiplication and for
negative numbers and some very simple
properties of geometric functions okay
the first set of rules here is enough to
deal with all the unnecessary
computation except the unnecessary
copying of course and the second one is
what was needed to deal with the
accuracy problem okay so we were able to
when we implement this we're able to
produce the code for various sizes and
compare the direct implementation
directly stage implementation with the
ones that were slightly more intelligent
using abstract interpretation and so on
and we compare them to the
implementations in the fftw system and
another standard way of doing FFT you
which is split radix and interestingly
it turned out that the two
implementations that we had that were
only different in one parameter matched
very closely what fftw on split radix
does the the key insight the very high
level inside about fft that came out of
the
is in fact that there's a very small
difference very tiny way to characterize
exactly the difference between the FFT
WA and the split radix way of doing the
fast Fourier transform and it's
essentially just in the way that we
define complex multiplication ok so
because we were able to implement this
generator for f of T circuits in such a
high level way we were able to make this
observation fairly fairly quickly if
there are two ways of defining complex
multiplication one is basically where we
use for multiplication and the other is
where we use three and if you switch
from one implementation to the other you
move from fftw to split red X and vice
versa ok so what's the moral of this
part of the story I think to me it's
saying that if we have better tools for
writing generators that produce lower
level implementations and we can focus
we can keep our designs for these
generators small we're able to see more
about the problem that are solving right
and we get very high level insights into
the kind of computation that we're doing
all right so now to the reactive
dimension of you know going from batch
computation to something much more
sophisticated here's what an FRP
functional reactive programming program
this is an extensional functional
programming to deal with reactivity
here's what a simple frp program looks
like they're going to be two concepts of
interest one is continuous behaviors
these are values that are outside the
computer in the real world and that are
changing over time and here's one way to
define them inside my program so we're
going to say the value chase mouse is
equal to move by some offset the picture
of Becky where offset is initially
integral of this value of velocity and
velocity itself is equal to the mouse
coordinate the location of this mouse my
minus the offset that we've defined here
ok this is the syntax by the way this is
an actual Haskell program SQL is another
functional programming
language and the behavior that we're
going to get from this complete
specification is when we move the mouse
value of offset changes and we get the
picture to move the picture gets to
follow the movement of the mouse so this
is the idea is continuous behavior we
can also incorporate discrete behavior
in reaction to discrete behavior in a
similar way we define the value grow
flower to be stretched by some size the
picture of the flower where size is
initially one and then it's going to be
the integral of this B sine another
value called B sine what's B sine well
initially be sine is going to be zero
it's going to stay 0 until we get an
event happening on the outside if this
event is the left button press the value
changes from 0 to minus 1 so this means
of course that the integral is going to
be starting to go down over time and the
B sine is going to be minus 1 until the
left button is released in which case we
go back to be signed that means that we
go back to the initial state in which we
were in another thing that could happen
is if the right button is pressed
instead of minus 1 will have the value
one and then we'll do the same centrally
the analogous thing for the other side
right so again this gives us a complete
running program and the way it's going
to work is whenever we get let button
pressed size going to go down and the
right button is pressed size can
increase okay so this is these two
slides illustrate the basic ideas and
functional reactive programming
continuous behavior and discrete events
and the FRP frame work has been used to
program all kinds of applications
including graphics animations and
programming robotics systems and you
know a whole bunch of different really
neat applications now frp allows us to
express reactive computations pretty
nicely but it's done in the middle of a
functional complete functional
programming language which means among
things among other things for example it
has garbage collection no garbage
collection is really wonderful when
we're not doing real-time
programming but when we're doing
real-time programming this means that in
any time during the computation we might
have to wait until the computer the
computation is finished with garbage
collection so what we did with EF RP
there with frp is we extended it
actually we cut it down to a much
smaller core which allows us to express
the same kinds of computations that we
were ascribing in the previous two
slides but without having the rest of
this big functional programming around
the function programming language around
so we don't have access to all the other
cool things that we can do in high
school but we're able to write the
reactive program is much more directly
and this way we were able to get much
stronger guarantees about the
computation that we were able to get
with Haskell so it was used to program
you know little Robocop robot for
example and you know this is this guy
has a little radio receiver and two
small wheels and each one of them is
connected to a motor and it comes with
and it uses a micro pic microcontroller
that uses a certain subset of c-4 to be
programmed and you know to to to look at
a simplified part of what it is involved
in programming this little robot we have
the wheel here and the motor and it's
our job to send the right signals to the
motor right amount of power to get a
particular desired speed alright so the
way we'll do that is we will get tix
from some kind of infrared counter on
the wheels and based on that and another
slow clock from the outside we're going
to determine what the actual speed is or
an estimate of the actual speed from the
radio we're going to get signals to
increase the speed or decrease the speed
and based on that we're going to
determine what the current desired speed
is look at the difference between them
and using an external another external
counter we're going to determine how
much power to send to this motor so this
is the EF RP code for doing this will
define the desired speed to eat for each
one of these boxes actually we're going
to have an equation in the frp language
desire speed we're going to say is
initially 0 and on an increment speed
signal the desired speed becomes desire
speed plus 1 if we get a decrement speed
signal
we decrement it and similarly we define
the actual speed the speed estimate
which is going to be based on counting
the number of tix we get from the
infrared sensor until we get a slow
clock signal and so on okay so this is
the EF RP code for this controller the
implementation takes the frp code
translates it into this event handler
style c code the main thing the two main
things that i want to say about this
code is on this side any program that we
write we're guaranteed that it's going
to be terminating and it's going to be
using a finite amount of space and of
course we can't to general say this
about c code that we write by hand it's
very easy to write a one-line program
that goes into an infinite loop for
example the other thing is from the
point of view of designing these kinds
of programs a lot of times we're
interested in what happens to a
particular piece of the state such as
speed how is this particular piece of
the state determined and in this
representation we get everything that
relates to this value in one place in
the sea part this gets scattered in
different parts of the computation that
have to do with how to react to
different events okay now having said
that this localized is certain
information that we might be interested
in when we're looking at the real time
behavior and we want to compute the the
bounds on how much time is computed to
react to a particular event of course
this also has useful information because
it lists all the work that we have to do
to respond to a particular event most
recently we've been taking the work on
here far p and extending it to be able
to write device drivers and one of the
main things that we did there is to
extend efr p first we made ef4 p by
cutting down frp itself and the main
thing that we've been doing recently is
extending frp with fairly extending it
carefully with features that would allow
us to not change the input output
semantics and our ability to reason
about efr p but to change the kinds of
resource guarantees the real time
guarantees that we get so with the
priority scheme for example that's
transparent
and that works transactionally we would
still be able to read our programs in
the same way that we did before even
though what may happen in practice is
some event might occur we might start
handling it and then another one with a
higher priority might interrupt it we
would throw away the work we were doing
at attend to the second one and then get
back and deal with the first one later
okay so that's the kind of thing that
we've been doing mostly to deal with the
device driver example okay so finally
when we combine these two things what
what benefits do we get and what is the
technology that's available to be able
to do this kind of thing so to give you
a sort of like an intuition for what we
want to do here's a very yet another
example a very high level computation
high level description of a computation
sorting and here we've defined it with
two recursive function what is insert
and the other is sort and this is sort
of a classic insert sort function
written in a functional language we
defined sort as saying let's look at the
list L if they'll is if the list is
empty the sword list is just the empty
list otherwise all we're going to do is
we're going to take the first element in
the list and insert it in the right
place in the sorted version of the rest
of the list okay and insertion itself is
going to say let's take an element
analyst and how do we insert how to
return something that has the a in the
right place and the L we look at the l
if the list is empty then it's obvious
we just returned a list of size one that
carries this element otherwise what
we're going to do is we're going to look
at the list and see if the head of the
list is less than is greater than the
element if our element that we want to
insert in the right order is smaller
than the head of the list then we're
simply going to put the the new element
at the beginning and then basically
return the rest unchanged otherwise what
we have to do is we have to put the head
of the list at the beginning and insert
a in the right place in the rest of the
list the very high level description for
how the sword works unfortunate thing
about it is you know we probably never
want to implement inserts work this way
because it's not resource bounded in
fact takes much more
then we would normally need for sorting
a list so a really cool thing that was
done a few years ago by Martin Hoffman
company is to produce a functional
language high level language from our
point of view that has a lot of the nice
abstractions and what it does it has
these linear types the linear types
allow us to guarantee that essentially
with very low small change on the
previous program we can annotate it with
typing information that says you know
you don't actually have to do any
malik's to do insert sort okay you can
do insert sort without any allocation of
additional memory how does this work
well maybe we'll get an idea if we look
at how the type system works the
essential idea is that in addition to
any kind of dynamic constructor we're
going to say that the type system needs
to know where some have some abstract
understanding of where this structure is
stored okay so this is going to be
almost like a cave a capability that
comes when we deconstruct or analyze a
list so if we find out that the list is
a cons cell then we also get a
capability for being able to use this
console later when we call insert we
have to pass a capability that would
allow us to essentially find a place to
put a into a list when we're returning
the result and what we'll do if the list
is empty then we'll do this cons at the
same place that we got from this
parameter that in the first case we got
full of course from this call so
essentially as we deconstruct the old
list we get information about where to
construct the new list right and a
similar thing happens when we're pattern
matching on the rest of the list here
when we're finding out that this L is a
cons we get this capability that we get
to use in at this point to create this
console and for this console we could
use this one of course we could have
interchanged this D and E but the type
system makes sure that we can't use any
of them more than once that's why it's
called Linear's because any of these
capabilities can only be used exactly so
we could exchange these two things
and we have a choice in where we do the
cons but we can only do a cons if we
have a capability to do a cons and a
capability can only be used once
similarly we use the D and E here in
this other branch and in this case we
use it directly for a cons but in this
case we use it to be able to call insert
which we know is going to mail lock a
cons cell one last thing to say about
this of course is i said 'i can only be
used once you know it's introduced here
and is used here if we have an if branch
we should take into account that only
one of the if branches is used so we're
able to actually use it in one of once
in each of the two branches so you don't
need to know exactly the identity of the
cell right but you need to know that
there is some cell that has disappeared
that you could use at the level of the
type system at the level of the
implementation you actually do need to
know something about where it's going to
go I made this how do you know that you
don't have some other variable somewhere
else oh the functions are maybe another
friend which is also referred to the
safe house I'll with you Josh ah
excellent question this goes back to yes
absolutely thank you the question is how
do I know that there is no other thread
or other reference to this thing that
somebody else could be using at the same
time right so we said that the core idea
here in this language is linearity and
linearity is what's going to allow us to
type check this program and make sure
that it can be implemented with any
additional mailbox how do we know that
nobody else has a handle on this this is
an excellent question goes back to my
very first slide the abstractions that
are used in the language interact very
directly with what we can do to make
guarantees about the programs written in
the language if we have multi threading
and if we have other ways to store
references to this console and the
capability then we wouldn't be able to
get this Garrity okay it wouldn't
necessarily work in the dire quay so
this doesn't necessarily in these
languages
just means that the direct way to
incorporating multithreading would
indeed violate the property that we're
trying to establish with the type system
here so I haven't thought about how to
deal with that particular interaction
but it'd be a very good one too if you
want to very good one to consider you
must have something the summer the fact
that must be an annotation with
exclusive access to the thing we're not
that's right that's right and in fact
you the kinds of type systems in some
ways that one uses to guarantee
properties about multi-threaded programs
statically are similar to the kind of
type systems that are used here and also
index types which I'll talk about next
or another way that the people have
tried to deal with the threading
systematically so one does have to look
at what are all the what's all the
machinery that's needed to incorporate
all these properties and guarantees in
the same language yes another question
oh yeah aliasing what's this right if
you're if you're if you have any way to
copy the e you would run into problems
and any way to copy a structure that
contains the e you would also have
problems that's right so the types is to
make sure that not only is the e linear
but all these data structures are also
linear okay so that that's the slightly
easier one to deal with and in fact
they're also variants after Hoffman's
language which has been around for a
while there's another sort of step
forward from linear types which is
called alias types all right and it
deals with various other kinds of data
structures and computation kinds of
complications that you want to have
around a little bit more naturally maybe
than what the vanilla linear types do
okay and in fact you know to deal with
the problem that we addressed here you
have to deal with the specific problem
that you mentioned about the linearity
of Elm okay so here's an example of a
guarantee that we can get with
a carefully designed abstraction more
expressive type system like linear types
but one of the things that we lose with
the original proposal here of linear
types is the ability to pass around
functions so we forget sometimes that
you know functional languages are great
because higher functions are very
convenient what are higher or function
is useful for well especially when we're
sorting we generally want to make our
implementation of sorting parameterised
by things like this we don't want to pin
down the comparison operation right and
parameterizing by something like this is
essentially either is done either by a
call back or by passing in a function
argument all right when to get the
guarantees here we've lost the ability
to pass these things as values what do
we do the key idea that's done here is
to develop an extension that
incorporates both staging and linear
types then we can make a very clear
distinction about when this part of the
computation gets done if we think of the
idea of picking the particular sort
function as an earlier stage okay then
we can use these brackets to brackets
around the beginning of our
implementation of insert and sort and
say that we're picking the particular
implementation of the comparison in an
earlier stage and we plug it here as
part of this template the template can
be an actual template where we produce
completely separate code for different
implementations or it could be a virtual
template that implements everything in
the same place all right but by doing
this extension where we make the staging
distinction explicit we're able to
recover back the exclusivity of the
higher-order functions so that we don't
have to write source code for exactly
the same thing several times we're still
able to do in the parametric way and
also keep the guarantees about being
able to do these modifications in place
for the for the computation of the
insert sword okay and most of the work
actually that has to do with being able
to get this extension of the linear type
system has to do with making sure how
can we write a language where we're able
to copy things that are safe to copy and
copy things that and make sure that
things that can't be copied are not
copied okay so this was linear types the
other thing that I'd like to sort of
like briefly mentioned today that's
another really important component of
resources where programming is index
types okay here's the intuition for what
index types are about this is a type
declaration in o camel that doesn't use
index types so we'll go over this first
quickly to make sure that the same text
is is is clear we're declaring a type
for list parameterised by type parameter
a and the list can be either nil or a
cons which carries a value of type a so
if a is int then we would have an inch
right there if a is a string would have
it a string right there and the other
part the tail of the list is itself a
list and it can also has to be
parameterized by the same a so this is a
polymorphic simple polymorphic list and
the append function described here
simply says we're going to take two
parameters one is called X's and whether
the other is called why's the s's are
typical for referring to lists and
functional languages both have tied a
list and the return result is of type a
list as well the way we do append is if
the second argument sorry if the first
argument is empty then we just return
the second argument that's the easy case
otherwise what we do is we break down
the first argument into the head and the
tail and we put back the head on the
result of appending the tail of the
first one with the second one is this
clear to everybody okay so fairly
standard definition just making sure
that the the syntax is clear what we're
able to do with index types is not only
to have a data structure that says this
is an alpha list and this list can only
carry things of type alpha meaning if we
pick alpha to be int there were all
they're always going to be ants it's a
homogeneous data structure and so on
what we're able to do with index types
is to say much more precise information
about the data type the data structure
in fact we can pin the data structure to
its exact value using this mechanism if
we want but that's not always necessary
so what we'll do in this example is
say we're interested in lists
polymorphic retyped lists and we're
interested in knowing ahead of time what
their size is this is exactly the same
problem that will have with arrays if we
wanted to ensure that array bounds
checking is done statically for example
so what we do here is we add an extra
parameter called in this case n it's not
your everyday type but it's an index
type and what that means is we can
actually write functions that work on
these types so it's going to be of type
the type is called nant or the kind I'm
sorry the kind of the type is called net
so the type of the night that the type
of the type is a natural number now we
say that nil which we knew before as an
alpha list is an alpha list of size 0 so
this parameter here is restricted to be
of size 0 of the value is nil and then
in the next case what we want to say
really is a cons value if it's carrying
a list of size M then the whole thing is
of size M plus 1 or successor of em in
this case okay and we're able to do this
by declaring this let this local M which
is a polymorphic parameter that's going
to range over the value that's carried
by the console and the console itself is
everybody clear or any questions about
this one so far with this additional
structure in the types what we do is
we're able to go to append and
essentially say that it has the
following type if the list if the first
argument is of size M the second
argument is of size M then the result is
going to be of size M plus n and this is
going to be all static we checked to do
that we're going to take two parameters
the first one is the size of the list as
arguments to append the first list the
second one is the size of the second
list and in you know slightly more
elaborately type decorated match
statement that describes refers to what
the size of X is a type of X is not the
type of the return value is going to be
we're able to say the code here stays
the same here when we do the analysis on
the console we want somebody to tell us
what the value of this M is for the
particular argument we take this value
and then we're going to construct a new
console where we say the size of the new
console is going to be m2
n where n is this parameter and what we
carry is exactly the same as before but
we also pass in to append the size of
the the rest of the list okay and this
is all statically checked and now we
know that whenever we use this append
function we're guaranteed that the the
sizes of the parameters are going to be
known statically and it's going to be
safe to assume that these are the sizes
okay what is cool about index types done
this way this is actually the last slide
was something that we just presented a
paper about in a nice last week at Pepin
2007 all the checking of the types is
done statically nothing is left until
run time in the in the static type so
they behave exactly the same as before
basically any program that you know is
safe and that you could prove to me that
is safe you could type check no I
haven't okay so the key thing is that
any program that you know is safe and
you could prove to me is safe you could
type check okay so the key is actually
in having the proof so if you have the
proof you should plug it in to the type
system and the type system can
incorporate this proof directly proof of
us appear in your programming language
if you have the proof you can do it if
you don't have the proof you can't do it
I'm sorry all right yes yes so it's not
necessarily going to be easy that
anything you have a warm fuzzy feeling
about that is it's that it's true that
you're going to be able to explain it to
the type checker but for you know the
more sophisticated library building
programmer that knows that certain
properties hold about these libraries
and they can actually demonstrate it
then they're able to express these
properties now okay so not everybody can
type check all the programs that they
would like to type check but a
sufficiently skilled programmer is going
to be able now has a way to communicate
this information to the type checker
right yes
excellent question the underlying the
question is what is the underlying logic
for this framework the name of the
language that we just released his
concoction and the middle part is coq
this is in reference to the proof
checker from France so it's higher order
logic the calculus of inductive
constructions and you know they have
things like you know formalisms of the
real analysis results there's an ape
megabyte proof library that you know
where the machine checked the key
results like the fundamental theorem of
calculus and stuff like that written in
 and very very expressive proof
language and what we'll do for you is
you write the proof it'll check it it's
not a you know you could use it kind of
as if you're improving framework but
it's primarily a proof checking your
framework and this is in the last
example this is actually what's used to
write all these types whenever you see a
tick paren take / n take paren all these
things are actually terms in the proof
language and all the checking on these
things is done by the proof checker okay
yes another question coercion czar
tricky so this is another talk about
gradual typing for higher order types
and the question let me repeat it sorry
I'd the question is if I wanted to write
my regular sort which doesn't have the
information about the sizes of the type
and I wanted to use it in conjunction
with this append what do i do can I
simply do a cast the the short answer is
basically this is a combination what
you're looking for is a combination of
gradual typing and the more expressive
types that you get from index typing
still ongoing work it's not possible to
get soundness it's not possible to do it
without actually checking the size of
the list okay so I think for this
particular example the least amount of
work that you could do is dynamically
look at the list see how many elements
you are and then construct a list a size
that says okay there exists a size for
which this is a size list and here's the
size
that's basically the least amount of
information that can be done in terms of
applications basically we can guarantee
any property that we know how to verify
ourselves statically and will be checked
by the machine and a particular of
particular interest there's dsl
implementations and to be able to check
dsl's statically check the type systems
and the parsing statically for dsl's so
in summary you know the key ideas behind
our work on resource or programming or
to capture the design intent very
clearly in the code that people write
for embedded in real time systems at the
same time to have solid guarantees about
low-level properties in general
resources that are used in the
computation and to make sure at the time
at the same time we have the expressive
ax t and we have the low level control
but safety is not violated right so
these things are integrated together
soundly the key ideas that are used to
realize this or multistage programming
index types and reactivity these are the
things that we talked about give
examples of in the talk and ultimately
this should make programmers more
productive and make their life easier
make it easier to produce better more
reliable programs and thank you very
much and I'll leave these things up as
pointers to further material if you're
interested thank you so we're a little
bit past time I don't know if we have
any more time for questions I think
we're I think we're done now so it
doesn't look like anyone's clamoring to
get into the room and so I don't think
we're going to be rushing off so if you
have questions to ask you can come up
and do that but otherwise we're all
finished the doc thinks pretty good yes
so where does this not work
so right now that's a very good question
the question is where does this not work
right now we're just finished we just
finished the release of concoction which
has the support for the index types we
haven't written a lot of programs in
concoction yet there are a lot of
programs that we would really like to
write in concoction in fact we've
created this language because we had a
lot of programs that we needed it for
but right now we're at this point we've
just finished the implementation it's
released it's available online the
manual is extremely short it's four
pages because all you need to know is o
camel and for you know three three other
constructs to to start programming in
but we what I'd like to do next or we
would like to do an access to get much
more experience with programming and in
this language with index types and in
fact while there are a lot of related
systems that are out there there's a lot
of interest in index types in the
programming languages research community
there aren't a lot of distinct program
examples that we know of there are a few
things few small ones that are used to
compare languages but I don't think that
there is a large body of programs in
index in languages that have index types
yet so we're very excited about actually
trying it out and see if it can do all
the things that we would like to do the
other thing sort of that I think is very
interesting is what was pointed to
earlier with the question about what if
I have an old kind of legacy function
like sort of the old type and I want to
integrate it in this framework and
recently we've put forth the proposal on
gradual typing and the idea is that this
would provide the machinery needed to
have parts that part of the program that
have all types that don't tell us very
much or even know types like scheme or
dynamically typed languages like Python
for example we're using Python now as an
example for what we would like to do and
be able to integrate that with
extensions of the language that have
types and the do have guarantees about
the type parts so that's kind of another
area where we'd like to go
other abstractions and AP ice look at
the age of eight races between
components look like at this system for
in a real worlds kinds of things that
yes you have a favorite list starting
it's a little number of work is fairly
easy to describe completely what it does
but when you get to larger things with
window existence or real world
applications it's big the description of
the interface would be so much
information about what's going on please
oh yeah oh yeah yeah yeah so the
question is how do real-world components
you know fit into this model of the
world one of the things that could
happen is if you described with index
types you can say factorial has type it
takes an X and returns factorial of X so
you're no longer say it takes an int and
returns an int but it takes a particular
X give me whatever X you want and I'll
produce a number which is specifically
factorial of X which is fact now is
defined on the time you can specify your
full input-output behavior in the type
okay and for some things that could be a
good thing you could use this this means
that you could use it for some kind of
verification if you want i'm personally
not particularly interested in going
that far with index types much more
interesting things like the append for
example but you're you're not
necessarily even if you do that i mean
first of all it's a choice it's up to
you whether you want to use the index
types they are not on larger components
if you do that you'd only be able to
capture the input-output behavior and
not necessarily the side effects and the
implementation details okay so you and
then if you just use the types as they
are no camel now there is still a lot
that you can hide in fact there's still
a lot that you can't capture explicitly
on the type so ultimately I think this
is again a situation where you know to
to to start exploring this world experts
are exploring what can be done usefully
with index types there and what may be
disadvantage of index types we have
to start we have to try these things and
see what happens and a good way very
good tool for being able to explore that
in addition to showing Christmas party
pictures is to have a mechanism for
gradual typing that would let us let us
have components from all types and new
types live together happily right now
you can have both of them in the same
language but you can't use the both of
them very easily together as a reference
to a paper on stage programming that has
20 different ways of staging one
function I suspect it was an interpreter
that paper not the factorial function or
is it a specific paper that you have in
mind or this is pathetic okay okay so i
think i know the paper that you're
describing so in that paper there's
there are about 10 different versions of
an interpreter done for a progressively
more expressive language so there's not
exactly the same language and the idea
of doing it in 10 different ways is
really to explain to people reading the
paper how to write interpreters for more
sophisticated languages so that's kind
of the reason why there are 20 different
versions there and ultimately when one
is writing an interpreter for
sophisticated language you have to do a
lot of experiments it's not a fairly
it's not just something that you sit
down and do but I think what you're
really asking about is if I have a lot
of variability in this times at which
different inputs arrive like for example
in the power example one input might be
arriving early and the other late but
then you might have a situation where
they're different right and you're
concerned about how do we do things when
when when when that happens the general
way of doing things that seems to work
is this abstract interpretation trick
where you basically have a slightly more
interesting data structure for both of
the inputs and then you say okay here's
what I do when the first one is
available early and here's what I do on
the fruit and the second one is
available you know early and so on so
there are ways to manage them I don't
think that right now I could say I could
claim that there is a perfect solution
for this problem this is an issue that
has been around for a long time in fact
it was fairly well known in the partial
evaluation
literature which kind of produced
multistage programming multistage
programming solve certain problems that
arise in partial evaluation and in
particular being able to control exactly
what the partial evaluation is doing but
but this issue is still kind of an open
issue and now especially with the index
types we were able to do much more
informative experiments than we were
able to do before because unfortunately
we also ran into this problem of you
know types can get in the way when the
type system is too simple then the types
can actually prevent you from writing
programs that you really like to be able
to express and especially for this
application area of statically checked
domain-specific languages which is
almost any language that you're
interested in it was the exception of
you know some dynamically typed
languages almost any language has some
typing structure if you want to
interpret that and write a stage
interpreter to implement it then you
have to deal with this limitation on
typing and index types really help us
with this okay remember actually in the
very much earlier on the speed up from
interpreters were somewhere between four
times and forty four times the
difference between them is whether
you're able to use index types or not so
index types in that case give you a
factor of ten speed up we're staging
just gives you a factor of four ok so
the being able to write index programs
now is very important to make the next
step
yep FFT
so
right so that's the question is in the
FFT example we had these rewrites I
didn't really say very much about how
they're integrated into the
implementation but being able to use
these rights is essential for producing
the code that we get at the end and the
question is well in general how many
rewrites do we need to have in general
you would need a lot of rewrites to
solve all problems you know nicely the
the reason why these rewrites and the
fact that they're small is very useful
for this particular example is a lot of
times to be able to write good
generators for certain applications we
need to be able to incorporate
domain-specific optimizations or problem
specific optimizations so the idea of
that example is when you're writing a
generator it makes a lot of sense to be
able to somehow be able to incorporate
these optimizations that are specific to
the problem with this abstract
interpretation technique I didn't talk
about how you do the details here but
with the abstract interpretation
technique you actually have a fairly
systematic way of taking the data
structures that you're working with and
incorporating these rewrites on these
data structures so that they're
performed during the generation process
the issue of how you direct them and how
you make sure that they're actually
usable effectively as opposed to
diverging and going into an infinite
loop themselves is is addressed in that
context basically it's the
responsibility of the person developing
the stage at implementation to sort out
how to direct these rules and how to
produce an implementation based on these
rules so there's no really there's no
black box that where you put in the
rewrites or the the qualities and you
get the rewrites out that's outside of
the basic programming framework
absolutely absolutely absolutely so it's
the programmer the designer the person
designing the whoever is designing the
implementation of fft needs to know
enough about what are the essential
optimizations that are needed here and
they're given a particular method for
turning this into fairly easy to read
code that
that does what you want but there's no
right now there's no toolbox for writing
the equations and deriving the rewrites
from okay actually pushing back here so
we haven't actually ourselves done these
kinds of you know very specific
experiments on specific programs running
on specific platforms but there are
other results in the literature where
people have done that using essentially
the same mechanisms that we now have in
the framework so with index types
there's very nice paper from few years
ago by Karl Cary and Stephanie virus on
using index types to talk about I think
both I think time the number of time
steps and I think they're also concrete
studies on size as well and the
motivation at the beginning was to say
you know what are the mechanisms that we
need to have in our language that would
let us talk about all these resources
and the quantification that we get in
with the index types now is the
essential thing that that wasn't there
before how do you prove anything that's
trivial about progress if you look for a
point it's not associated is not
distributed we haven't we haven't done
any experiments in that direction yet
but there are some very interesting
libraries that formalize so the question
is again sorry how do we how do we prove
anything about floating points in this
framework and the there are some very
nice theories that formalize fixed-point
arithmetic in now we haven't used
them yet because we've just finished the
integration of the mechanism into
the types but we certainly would like to
be able you know we expect to be doing
work with these and in the near future
so hopefully in a month or two I'll be
able to say more about that
any other questions all right thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>