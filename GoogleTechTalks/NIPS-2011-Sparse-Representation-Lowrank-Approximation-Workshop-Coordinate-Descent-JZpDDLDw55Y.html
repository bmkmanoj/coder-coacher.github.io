<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Coordinate Descent... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Coordinate Descent... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Sparse Representation &amp; Low-rank Approximation Workshop: Coordinate Descent...</b></h2><h5 class="post__date">2012-02-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JZpDDLDw55Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you so the represent some recent
work on coordinate design for learning
with spots three tricks congratulations
this is joint work with LGD young and
Giovanni so we're looking at large-scale
supervised learning problem so we have a
set of label training data and we try to
solve jointly k tasks or k problems by
looking for our double matrix
rectangular matrix so that minimizes
penalized empirical risk minimization
objective so on the one hand we have
knowledge of the vector which is the
requisition currency and then
difficulties so typical examples of this
multi office regression output space is
just part of a multi-class
classification just occurred in the
focus here for the sake of gravity so we
do we get such situations where we have
large number of features so these very
much large number of classes and
obviously a large number of examples so
our common rigorous asian community that
the loss to scale to large supervised
many problems if the trace norm trigger
ization person so it's just an l1 more
on the singular value spectrum of the
rectangular matrix ability then we have
context of some additional problem so we
could think that it's a easy problem to
solve even though it's a large-scale
problem the issue is that even though we
take a smooth
lost conscience
on the right-hand side we still have
very much the rigorous Asian dirty term
on the left side so we would like to
solve this kind of problems
so what is the state of the other coach
the state of the other branch languages
this decomposition and as so called
composite minimization editors so the
most popular one is the so called
proximal regions irregular so these are
attractive arguments when the so called
próximo operator is cheap to compute
such as the proximal brain f-14d and one
in the vector base for the other one is
the special victor vector entries it's
highly inaccurate and got to
intervention for accuracy galaxies major
weakness of this kind of evidence system
when the boxing operator is expensive to
compute and they're also quite sensitive
to conditioning of the design matrix
which happens quite often in larger
applications when we have a large number
of features that most often correlated
so the situation with the Tres norm is
the proximal brain in this case
corresponds to performing the full
single Herbalife's when you become
position on the double matrix at each
iteration and this is extremely
expensive in terms of range that also in
memory so that we see kingdom for we're
seeking a method that doesn't involve
such a highly expensive intuitions so
what we propose is 1487 approach so in
the vector case for just a regular in
one home the quality Saracens provide
efficiently scalable avenues for
large-scale algorithms their competitors
my vision is over the government similar
theoretical guarantees and that quite
promise to in conditions design matrices
yes
the issue is that it sends you how to
devise such methods for first
non-british advantages because we don't
know which kind of audience we're going
to choose to perform quality sense so
here we use lifting into some infinite
dimensional space to perform the
continent descent so instead of looking
or using the singular value
decomposition of doing which is
obviously even accessible the solution
we just use the composition of the value
onto Ragman surfaces which completely
determine and then the trace lock can
just be written as the minimum and one
of the weights of the decomposition of W
onto those reference or spaces now
fitting that into the original objective
we get visited objective which looks
very much like usual and one realized
learning problems where we have in place
of the similar the trace now we just
have to sum of the weights of this
decomposition on to the autocomplete
feature we can also show that if the
loss function is complex and smooth then
the two problems equipment in the sense
that even though the listed objective is
complex measurements of the original
problem they share the same minimum now
the continent is antagonist so he works
as follows we have this decomposition
onto the over completely theory and at
every iteration we speak the coordinates
that yields the steepest descent okay
and then
if we don't have a sufficiently distant
schedule then we perform a substation
limitation so let's take a closer look
at each kind of iteration so picking the
the continent which is the steepest
descent corresponds to performing them
computing the top singular vectors of
the radius of the last function and this
is linear in time in the dimensional
company the second step which is the
subspace of ization can just be
performed by using Newton's method
because so far we keep either increasing
the support of speed up and this is also
we can perform a second order in
addition and when the support of if that
becomes large and perform most gettable
for success by Africa so just a snapshot
on the our experiments so we performed a
comprehensive benchmark comparing the
proximal gradients and our approach this
is just a picture on favour with the
silver moon case so we are in the logit
extremely logical situation and the
features are highly correlated our
approach is quite completed compare the
proximal payment approach meaning that
in terms of CPU time gives a higher
accuracy than the proximal gradient so
the take-home methods message of this
work is that so it's a well-known result
that the trace north is just an l1 of
some high dimensional space yes we can
use that and leverage that to perform to
him to design an efficient and fabulous
fortress not rigorous than the problems
that scale to large data sets she's come
to our poster</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>