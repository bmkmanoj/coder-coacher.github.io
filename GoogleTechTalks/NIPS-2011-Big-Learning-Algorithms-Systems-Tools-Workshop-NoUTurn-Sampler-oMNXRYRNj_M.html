<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop:  No-U-Turn Sampler... | Coder Coacher - Coaching Coders</title><meta content="NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop:  No-U-Turn Sampler... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NIPS 2011 Big Learning - Algorithms, Systems, &amp; Tools Workshop:  No-U-Turn Sampler...</b></h2><h5 class="post__date">2012-02-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oMNXRYRNj_M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hope you guys are next bigger now is
Matt Hoffman and he's doing it
so I'm gonna talk to you about the no
u-turn sampler or nuts and Utes
so at a very high level what what we're
the problem we're trying to address is
this problem of sampling from on
normalized distributions where this
comes up that we care it comes up in a
few places but the place that we care
about is the situation where we want to
do Bayesian inference so we've got a
Bayesian posterior that's proportional
to the probability of our light of our
data given some parameters times the
prior probability of our parameters but
we don't know how to normalize that so
we have to use Markov chain Monte Carlo
if we want to sample from that posterior
distribution so what what nuts is is an
extension of this Hamiltonian Monte
Carlo or HMC algorithm also known as
hybrid Monte Carlo which is an efficient
MCMC algorithm that gets a lot less
efficient if you get your problem
specific hand tuning wrong so the point
of nuts is the primary point of knots is
to be an adaptive extension of HMC that
retains and in some cases actually
improves on HMCS efficiency well getting
rid of this need to hand tune your
problem specific parameters which is
both annoying and actually expensive so
just a very quick review of HMC so the
basic idea is that we can actually
sample from these distributions by
setting up an appropriate fictitious
physical system and simulating the
dynamics of that physical system so if
we gender so we're going to construct a
Hamiltonian which is a potential energy
function and kinetic energy function the
potential energy function is going to be
our minus log our negative log posterior
and we'll introduce a momentum vector R
that is endowed with Gaussian
distribution which corresponds to a
quadratic kinetic energy function and in
the way that H MC works is we begin by
really sampling R from its distribution
which is just a multivariate nor
so that basically is just a give
sampling step then we evolved the state
theta NR by simulating some number L of
a discretized discretized steps that
approximate the continuous dynamics of
this physical system that we've set up
and and then we accept or reject the
evolved versions of our state theta R
based on the accuracy of the simulation
so if you want to think about this as a
metropolis algorithm which is the right
way to think about it basically what
we're doing is generating metropolis
proposal by simulating these Hamiltonian
dynamics and the trick is that we're
able to actually move quite far from
where we started while retaining a high
acceptance probability because negative
log problem the negative log joint
probability in this model is equivalent
to the energy of the system energy is
conserved in physical systems so the log
probability of the proposals can be
close to a lot of probability that we
started with which means a metropolis
acceptance probability close to 1 so
here's an example taken of an h MC
iteration taken from Radford Neil's
excellent tutorial on the subject which
I recommend to anybody who's interested
in this so we start with the position
that's here - one and a half - one and a
half I think and the iteration begins by
randomly basically you can imagine right
so we're trying to sample from a two
dimensional multivariate normal with
reasonably strong correlations you can
imagine in a physical system that's like
this sort of quadratic shaped Basin that
sort of long and skinny and if we have a
ball that's just kind of standing
sitting here to begin with
we flick it in a random direction which
in this case is like minus 1 1 and then
involve the dynamics over time what you
what happens is you sort of trace out
this oscillating path eventually it
turns around and comes back towards
where it started we run it so we in this
example we're running for 25 steps and
we get here ultimately and so that's a
reasonable distance from where we
started which is a good thing and here
this is the Hamiltonian which is the
the energy of the system which is the
negative log joint probability of the
position and momentum right so basically
this minus this exponentiated is going
to be our acceptance probabilities
that's e to the minus 0.4 which is which
is not astronomically small so there's a
very good chance we'll accept this
proposal
so that's that's HMC in a nutshell just
to sort of further motivate HMC and you
know trying anecdotally convince you
that this is actually much more
efficient a much more efficient way to
sample often than more popular methods
such as random walk metropolis rwm or
give sampling here we're trying to
sample from a 250 dimensional normal
which you know if you're if you had a
250 dimensional posterior with strong
correlations maybe it might look
something like this so there are very
strong correlations between every
variable and so being here on the right
are some independent samples drawn from
that distribution here are some samples
draw generated by nuts which is like I
said an extension of this Hamiltonian
sampling idea and it's you know you can
see it's done a reasonable job of
sampling from the target distribution
here are some samples drawn using Gibbs
sampling run for about the same length
of time a little longer
actually as nuts and you can see that it
hasn't really done a great job of
exploring the distribution I wouldn't
say that with confidence there's even
one effectively independent sample in
there and metropolis is just kind of
hopeless for this high dimensional
distribution not even that high
dimensional distribution with strong
correlations so that's that's sort of
the motivations we want to be able to
get we this kind of sampling efficiency
that we get with HMC so just summarize
sort of pros and cons of HMC it's able
to suppress this random walk behavior
that you see with random walk metropolis
and Gibbs sampling which basically are
able to take only small steps at a time
they're only able to generate small
proposals that will be accepted with
high probability which means that they
explore this space via a random walk
which means that they require order
d-squared steps if they want to get a
distance D from where they started which
is really bad right like that kind of
scaling is just not very acceptable and
also HMC has nice much nicer theoretical
scaling with dimensionality than
metropolis does or Gibbs gives a little
harder to analyze because there are some
pathological cases where it's perfect
but but in the usual case it's it's far
from perfect downsides to HM see it
requires gradients which means that it's
not really something you can use on
discrete variables you can use it in
conjunction with Gibbs sampling for your
discrete variables but it doesn't solve
that problem and the thing that we're
going to be addressing is this issue
that it has these parameters associated
with the simulation so there's a step
size epsilon you want that to be small
so that you get high acceptance
probabilities and a reasonably accurate
simulation but you also want it to be
large that you don't have to take a
million steps to travel a small distance
so you have to get that right um and and
then there's this simulation link l
which again you want to be you don't
want to be too small because if it's too
small then you're only going to move a
small distance each iteration and annual
reverter and walk behavior which as we
discussed is bad but if it's too long
you actually get another really bad
thing happening so there's the obvious
bad thing which is that so each one of
these simulation steps requires that you
compute a gradient which is you know not
cheap and so you don't want to do more
of them than you need to but in fact
it's even worse than that right so in
this example I would argue that actually
we're taking too many steps right so we
move move move so the point of HMC is
that we're able to travel a far distance
from where we started and you know
except with high probability so here
we're moving moving moving moving making
progress making progress making progress
until we get to this area that's circled
in red and then we start to turn around
and move back towards where we started
and so at that point what we're doing is
we are paying a computational price to
make negative progress right so that's
not good so the core idea behind nuts is
we want to be able to choose the
simulation lengths automatically right
because it's a pain to run a bunch of
preliminary runs to figure out what it
should be and that sort of thing
and so what we'd like to do are sort of
guiding principles that once we start to
make a u-turn right once we turn around
and start moving backwards it's time to
stop the simulation putting that a
little bit more formally um we want to
stop the Hamiltonian simulation when
running it for an infinitesimal a length
of fictitious time would actually
decrease the distance to where we
started right and if you do some very
simple calculus that basically winds up
being equivalent to this condition here
that when the dot product between the
momentum variable and the vector from
where we started to where we are goes
negative then it's time to stop the
simulation that corresponds to basically
the vector from where we started to
where we are and the momentum vector
right if it's more than 90 degrees keep
going if it's even a little bit less
than 90 degrees it's time to stop so at
a high level each iteration of knots
precedes by as an HM C we begin by
resampling this momentum vector then we
sample a slice variable if you're
familiar with slice sampling great if
you're not don't worry too much about
this it's it's not critical we could do
nuts without this it just makes the
algorithm a little bit simpler and
that's pretty much all I'm gonna say
about it so then we get to the meat of
the algorithm where we trace out the
Hamiltonian dynamics of theta and are
both forwards and backwards in time by a
series of doublings so basically we take
one step and then two steps then four
steps and we have to do either we have
to choose to go forwards and backwards
randomly to satisfy detail balance which
is necessary to ensure that we're
actually sampling from the right thing
and then and then we stop doubling when
a particular kind of sub trajectory
makes a u-turn and at that point we
sample carefully from among the points
that that we visited so far so I'm going
to go through an example run iteration
of nuts in two slides but first I want
to build up this idea of the
correspondence between this doubling
teacher and in building up a binary tree
implicitly so this is an exam this is
sort of a cartoon of how that doubling
procedure works so we start out at that
black point there with initial momentum
pointing in that direction so we this is
for doubling so we each each doubling we
flip a coin to decide whether to go
forward to backwards so we go forward
one and then we flip another coin go
backwards to flip another coin go
backwards for look another coin go
forwards eight um and you know this
might keep going for for longer and so
right this criterion that I just defined
here right that is only defined that's
defined across four pairs of states
right so any that basically for any two
of these states we can ask has this
trajectory made a u-turn yet are we
going backwards
um and so unfortunately we can't just
ask is the back of the trajectory and
the front of the trajectory making a
u-turn because that would violate detail
balance which is a tough but there
master I guess and we also really don't
want to have to consider all possible
sub trajectories because there's just
way too many of them so instead what we
do is we look at the trajectory is
defined by balanced binary sub trees of
these of the entire tree corresponding
if the trajectory traced out so far
right so like the trajectory from here
to here right from there to there we
might ask from here to here you're here
but not from like here to there right
because that's not an entire balanced
binary sub tree so that's the and so
then we only have to do work
proportional to the number of states
that we visited and that's totally
dominated in any reasonably large
problem by the cost of gradient
computation even reasonably moderate
sized problem okay so an actual
iteration of notes we start here this is
a contour of our target distribution
we trace out the dynamics both backwards
and forwards in time and so basically we
keep going until that basically the
reason that this trajectory stopped is
because there's eight states at the back
of the trajectory or the front of the
trajectory up there and if you look at
the vector from the first of those
states the last of those states it makes
an angle of just slightly less than
ninety degrees with the momentum vector
at the end of the trajectory so that
tells us that it's time to stop doubling
we actually have to so then we have to
be careful about which of these states
we actually choose is our next state so
we actually can't choose any of the
states that aren't in the same half tree
as the state that we started in so
that's just because basically if we did
choose one of those states we might if
we started from here say then we could
we could regenerate this half of the
trajectory but then we would decide to
stop and it would be no way of getting
back to where we started so that's not a
valid proposal so I know that's going
kind of fast but in the interests of
time I'll keep moving so we also we also
need a way of tuning this step size
which we do using a slight elaboration
of Nesterov dual averaging algorithm you
could also use Robins Munroe for this
and people have this seems to work a
little bit better and so basically the
idea is that we want epsilon to be you
know big enough but not too big we're
measuring that in terms of the average
HMC acceptance probability which we set
a target Delta and you know basically
that that's so it's still a parameter
that you have to set but it's much less
sensitive to it basically if you said
Delta equal to like 0.6 0.65 you'll do
fine generally where as epsilon varies
by orders of magnitude across problems
and we can use this for both HM see and
that's and we will in the experiments so
our goal is to figure out whether or not
as to compare the efficiency at
generating effectively in the
samples of nuts and HMC right so the
question is how quickly can we generate
samples that are not dependent on the
previous states in the Markov chain um
so we tested nuts and 8mc on for target
distributions one is this 250
dimensional multivariate normal with
strong correlation so that's a synthetic
example then the other three are actual
Bayesian posteriors one is a bayesian
logistic regression with 25 coefficients
one's a hierarchical Bayesian logistic
regression with two-way interactions so
that's substantially more parameters 302
dimensions there and a stochastic
volatility model with three thousand and
one three thousand time points three
thousand and one parameters that need to
be estimated and so we did a grid search
on all of the various tuning parameters
so that's Delta for both agency HMC and
nuts and the simulation length for HM C
and ran a bunch of iteration ran a bunch
of experiments and and they're all
displayed in the following plots so I'll
just break there's a lot of data on
these slides so I'll just break it down
so the y-axis is number of effectively
independent samples per gradient
evaluation so that's basically a measure
of sampling efficiency number effect
basically how many effective samples
we've generated compared to like an iid
sampler divided by the amount of work
that we've done higher is better and the
x-axis is the accuracy target Delta and
don't worry too much about that just
sort of if you focus your attention on
the middle and just notice that we're
not that sensitive to Delta then that's
that's all you need to pay attention to
there and so for this example the 250
dimensional normal notes actually
outperforms HMC no matter what
trajectory length unique you use and and
indeed as as is well known HM sees
performance strongly depends on the
trajectory length that you choose so
each one of these subplots aside from
the one at the far left is HMC with a
different trajectory target with a
different trajectory length and so
around
here in this area you're doing well on
reasonably well although not as well as
nuts but if you get if you go too far
your performance suffers if you go not
far enough
your performance suffers we see a
somewhat similar picture for the
logistic regression model here we're
getting basically the same performance
as HMC with the best parameters but
substantially better than HMC with
poorly chosen trajectory lengths um
hierarchical logistic regression similar
story to logistic regression we're doing
maybe a little worse than optimal HMC
but not much uh-huh um yeah there does
seem to be and that's pretty well maybe
a little more for the 250 dimensional
normal that's partly an artifact of of
the kind of randomness in the selection
of the of epsilon of the step size which
it not seems to be seems to play a
little better with that and have a lower
variance estimate of the step size then
hm-hm C does um oh that's a good
observation
finally the stochastic volatility model
here again we're doing substantially
better than HM C does for any trajectory
length and and again nice so and again
the HM C's performance is strongly
dependent on trajectory length so just
to wrap up I'm out of time but nuts is
an extension of HM see that gives you
the performance of HMC without the need
to tune these tune these parameters
which makes it both more user-friendly
and also applicable also easier to use
in a generic inference package like Stan
which is something we're working on at
Columbia which is a generic inference
package sort of in the model of bugs or
Jags but with less of a tendency to
choke on small to moderate sized
problems and I also have MATLAB code
implementing nuts if you want to
take a look at that on my website and
and that's it thanks a lot I'll also be
at the poster outside
about the ladies microseconds
excellent
yes sir I should have been there about</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>