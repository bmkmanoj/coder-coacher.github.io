<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Model-Based Testing: Black or White? | Coder Coacher - Coaching Coders</title><meta content="Model-Based Testing: Black or White? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Model-Based Testing: Black or White?</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9BqYkzP6LYk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it is my pleasure to present the speaker
today dr. mark mark I think is visiting
us from University of Waikato in New
Zealand then is going to be talking
about model-based testing in particular
tools approach a practical approach
which is something that I think is
really timely because we are looking at
it extensively for multiple projects I
know we have two of the offices online
so Kirkland and Boulder hi to you guys
and what I'm going to ask everybody to
do is hold the questions till the end
unless there is a clarifying issue
because there is a lot of material and
then at the end we will just open it up
for questions and we'll also take
questions from the remote offices as
well so please feel free to jump in once
we open it up so with that doctor thank
you very much so I just thought I'd
start with a brief geography lesson to
say where I come from and mention that
this is not just all work that I've done
by myself I've had a very close
collaboration over the last six or seven
years with Professor Bruno desire and
the group in France that have now formed
a company so some of the things I'm
talking about have been done within so
I'm gonna surprise I'm gonna looked at
this how far California is from New
Zealand it was hard to fit them both on
the map together it's 12 hours flight so
I'm from the North Island of New Zealand
and Hamilton there that's a google shot
of hamilton and this is the University
and I'm in a computer science department
there so the structure of the talk
there's four main parts things that I
want to talk about plus conclusions I'm
going to start talking me about an
overview of model-based testing and I
think a lot of you already have heard
quite a lot about model-based testing so
I'll go fairly fast through that and
just to give a brief introduction then I
want to talk about black box versus
white box not black box testing because
we're always doing black box testing
testing plan requirements but black box
models white box models which i think is
just an interesting distinction
and the main power of the talk is to
give two examples one using a black box
model using a tool open-source tool that
I've developed in the last year with the
models written in Java doing unit
testing and another one a white box
model using a commercial tool doing
system testing and this one's offline
that ones online so I've kind of tried
to make things as different as possible
between the two examples so you can see
a bit of a spectrum of the model-based
testing approaches and tools that are
possible okay so what is model-based
testing well the definition I like
perhaps because I I thought of it I
would say the automation of test design
so we hear a lot about automation of
test testing that usually means the
automation of test execution okay I want
to push that further I want to try and
automate the design of the tests so I'm
assuming that the execution probably is
automated but I want to go further and
see if we can actually execute and
automate the design and so we do that by
generating tests automatically has some
tool from a model of the system under
test there are different definitions of
model-based testing this is quite a
strong definition that I'm taking here
where the model is actually a model of
the system that we're testing and so
let's contrast this with traditional
approach to testing we'd start with the
requirements and someone manually would
read those understand those requirements
and develop a whole bunch of test cases
okay
in contrast in model-based testing we
are trying to just develop a model from
the requirements a model of part of the
behavior of the system not the complete
behavior we it's very important when
you're doing model-based testing to try
and miss out some of the details to try
and abstract and come up with a simple
model or several simple models
that touch on different aspects so
there's quite a skill in doing this and
coming up with the right level of mob
model it's not just something that every
programmer can do it requires the
ability to do abstraction but once we've
got that model then we can have some
tool which will automate this part here
and so the hope is that overall we do
less work because the work of writing
the model is hopefully less than the
work of writing all the test cases I'll
talk more about that later on just to
put this in perspective you may have
seen this diagram before it's sort of a
three-dimensional taxonomy of the space
of testing so we've got code based
testing here where we're driving our
test design from the code itself what
we're doing in model-based testing is
blackbox testing developing our tests
from the requirements and it's mostly
aimed at testing the functionality a
little bit testing the robustness there
hasn't been a lot of work done on
performance testing for example using
using models as there are some on that
but it's not quite mainstream yet but on
the other scale model based testing can
be used for unit testing we'll see an
example of that sort shortly or anything
up to system testing and we'll see an
example of that as well so I thought I'd
introduce it by example this is an
example that comes from France it's a
system over there called Key donk and
that literally means who's there
and this is a service of France
télécom where you bring up a number
you type in a phone number and it'll
tell you who owns that phone number
their name and address is there a
service like that in the u.s google ok
in some countries is not allowed but
it's interesting in France it's actually
a public service of France France
Telecom so it's kind of the inverse
mapping of the white pages so here's a
typical use case we dial the the number
and we hear a message saying something
like welcome this is all in French of
course I've translated it for you
press star button so that it knows
you've got a touch phone and if it hears
the star button we press the star button
and then we hear another thing saying
please enter a ten digit number followed
by the hash key pound key and then we
enter a number and if it's a number
that's in the white pages then we'll
hear the person's name and we go into
another options of hearing their address
spelling their name finding out their
credit card number you know all those
all those kinds of things I exaggerate a
little so we might listen to his address
and then and then hang up so there'd be
a typical use case if we wanted to write
a model of this we could come up with a
fairly simple finite state machine model
and here's a really simple one so you're
probably you're all familiar with finite
state machines I guess so if we just go
through the use case here we'll see that
starting in the offline if we dial the
number then we expect to hear the
welcome message and that takes us into a
state which is waiting for a star to be
pressed if we press the star button then
we're here the please enter a number
message and we'll be in this state where
we can do in two different kinds of
numbers if we happen to enter the number
that is in the database then we'll hear
the person's name and be able to then go
into state we we can get the spelling of
his name the address etc hang-up at any
time wrong numbers all kinds of things
so it's a really simple model that is
actually quite a lot simpler than than
the real system because the real system
has timeouts on each of these states it
has three ten-second timeouts I think so
eventually after that three timeouts
it'll go and hang up but as a first
approximation that's a nice simple model
so how could we generate tests from that
was fairly obvious we could just take a
walk through the system and the first
thing we might like to do is it just
take a random walk so I'm going to talk
about a few different test generation
algorithms
walk we'll just say let's at each node
that we get to each state let's choose a
random path out of it so we start off
there's only one to choose from and then
we randomly choose the star one randomly
choose a number that doesn't happen to
be in the database so we get a sorry I
don't know that number message choose
the number that is in there and then
hang up and we're aiming to produce a
length a test of length 10 so we're
still carrying on dialing up again
happening to take the same route this
time we get to type in the Fire Brigades
number and ah randomly you don't always
get very good coverage with random right
because it happened to take sort of the
same choice twice there twice here
perhaps it would have been smarter to
explore some of the other routes so
random is pretty dumb but it's extremely
simple to implement it's like two or
three lines of code to to go through and
generate a random algorithm and it has
some nice properties that eventually a
random generation will cover every path
every subsequence so it's getting more
and more sophisticated coverage if you
like the longer you let it run so you
can just let it run for several hours if
you want so that's a really dumb
algorithm but surprisingly useful in
practice is a more sophisticated one
Chinese postman is the problem of you
have to walk down every road to deliver
all the letters and so here we want to
make sure that every transition has been
visited and we'd like to do that in the
minimum amount of time so that's what
the Chinese postman algorithm does and
if we do the Chinese postman on this
it'll come up with one tool which is
minimal length tries to avoid doing
anything twice
it actually has to traverse this lines
three times because there are three ways
of getting back to that state but apart
from that it does a pretty good job of
avoiding duplication so that's a nice
algorithm to do we could say well we
want to go a bit more than that we want
to test for this particular State
we want to test the interactions between
the ways you can get into the states and
the ways you can get out of it so that
would be all transition pairs so for
each input we try and have some tests
that try all the different outgoing
transitions and st. the same for the
other input would try the three
transitions so for each state you're
kind of getting an N squared number of
tests but it so it's roughly N squared
in complexity but still it starts to to
test the interactions between operations
and this is one that I quite like this
is one that I first hear described by
Harry Robinson who when use at Microsoft
or maybe it may be Google and let's say
we've got a use case and this is about
the dark black line here and we know
that that's going to be something that
people will often do and so we want to
test some minor variations on that so
first of all we'll obviously test the
use case itself but then we take all of
the sort of minimum cost permutations or
or mutations of that path and so for
example instead of taking the the
recommended line there we might take the
alternative one instead of taking this
one here first we go around back that
loop and so on so we can choose all the
alternative paths and get some kind of
user directed testing because this one
here unlike the first three algorithms
they're all completely automatic sort of
blind algorithms just push a button
they'll go and do it this one here is
actually being driven by a use case so a
test engineer has an opportunity to say
hey this is a really important thing
test this thoroughly so it gives you a
bit of user input on what you want
tested so those are some examples of how
we might generate some tests then of
course we want to actually execute these
tests there's two ways of doing this
offline or online and I guess the
distinction is pretty obvious and
offline we can generate the test and
store
in a file as just a sequence of commands
or as code and so we can then take that
file and execute it on a different
machine execute it later put it into our
test management suite and run regression
test every night so that the generation
and execution are separate whereas an
online testing the tests are actually
executed as they're being generated so
if you think about the graph example we
take one transition of the graph we send
that off to the system under test wait
for the response to come back check if
it's correct and then generate the next
step so it's very tightly coupled and
obviously that's good or necessary
really if you're testing a
non-deterministic system under test
because when you send a stimulus you're
not sure exactly which response is going
to come back with or may generate
spontaneous responses and so that case
probably your generation algorithm wants
to be able to react to those two that
non determinism and change the path that
it's taking it's also good for things
like online testing overnight testing
you can just say we'll keep on testing
until I come in in the morning and so it
can be generating them dynamically as
you going so those are the two basic
distinctions the way we can execute
again we'll see one example the first
example I'm going to do is going to be
online and the second one will be
offline so what are the benefits of
model-based testing well the obvious one
you think hold is this is going to save
me time because hopefully the time taken
to write the model if it's a nice
abstract model fairly small simpler than
the system you're actually testing
hopefully that'll be less than the time
taken to design test by hand and of
course if we have a automated generation
then the generator test should be
executable and when we execute them they
should have an Oracle in them which
actually tells us whether the test
passes or fails so we kind of get a let
for free
the only painful
is designing the model it's a theory and
practice we've done some industry case
studies my colleagues in France
particularly have done quite a few a lot
of work with industry and in some cases
they found is sort of 30% saving in time
so the time of doing the manual test is
30% longer than the time of writing the
model and other cases that I've seen
it's actually roughly the same so it's
not always clear whether you're going to
get a win in terms of cost savings and
time so there can be a benefit sometimes
other times not the other benefit you
get is systematic testing if we are sort
of using a systematic algorithm to cover
our model then we can be sure of
covering every action every transition
etc so maybe if you li designing tests
you'd forget some of the cases so that
can be good and by changing the test
generation parameters we can control how
many tests we get but this next one is a
surprising perhaps benefit people don't
think of when they first start doing
model-based testing is that just the act
of formalizing the requirements and
changing them into model raises
questions like okay we're in the state
here what does happen when you press the
start key in the state the requirements
don't say anything about it and so we
have to go back to the the users or
designers and clarify that and those
kind of things happen virtually every
time you write a model and that is
actually I read a really interesting
report from Microsoft talking about this
when they started using model-based
testing a few years ago one of the
things they noticed was that testers
were preventing a lot of errors because
they as they were modeling they were
fight detecting these ambiguities and
the requirements feeding them back into
the design process and that was probably
preventing errors from ever happening
okay but the interesting thing the
sociological thing was the testers
didn't get in your reward for that in
fact there was no way of measuring it
they can measure the errors that have
been created and then found there is no
way of measuring errors that have been
prevented and so there was no sort of
reward mechanism for it which is an
interesting observation so that can be a
surprising benefit this is my favorite
one and one I think is most significant
that if we have evolving requirements
which almost always we do with
model-based testing you can just change
the model update it a little bit and
then push the regenerate and re execute
the tests button ok and hopefully that's
automatic and so it's probably a lot
less work changing the model than it is
to go and maintain a large set of
manually design tests and with some
tools when you change the model you can
actually regenerate the tests and run
just the ones that have changed so you
don't need to run your whole test suite
again so that can save your execution
time as well and we can sometimes also
get the traceability automated so if we
annotate our model with requirements IDs
we say you know requirement CD 3.5 is
related to this part of the model here
then the tools can actually track there
and can tell us exactly which tests are
testing that requirement so because it's
because the tests are generated
automatically you can kind of keep track
of that traceability so those are some
of the benefits the main negative is the
modeling the time taken to do the
modeling the expertise required
sometimes it can it's like a programming
job but it's a bit different to that
because you also have to be raising the
abstraction level ok so let's talk about
black box and white box models so
imagine now that someone has taken this
big requirements document they've
understood it abstracted they've written
a model and now they're giving me us the
model to generate some tests from so
just put yourself in the place of a test
generation algorithm and we want to see
what's the diff
between being given a black box model
and a white box model well obviously a
black box model is black right it's an
obvious difference but a black box model
we can't see inside it all we can see is
that there are these three actions we
can perform we can reset it and we get
this view of telling us what state it's
in that's all it's going to tell us
about the internals and so if we want to
start exploring or generating tests from
here all we know initially is that we're
in state zero and so let's try pressing
the the a button and the state change to
three so that means if we take this
transition here this part is going to be
state 3 now let's try pressing the B
button hmm stay at 19 so that means this
one is state 19 and every press C we get
state 20 this is starting to look like a
long job we don't know how big this
model is it could be huge
let's try pressing C again state 0 ah
right we've gone back to the initial
state so this transition here actually
links up back to our initial state so
we're gradually exploring the model we
could be actually you know generating
tests as we're doing this if we're just
following a random path and as we do
we're finding out more about the
internals of the model the behavior of
the model but we can't see it up front
so I suppose I could have done this
yesterday because it's my first weekend
on state in San Francisco and I wanted
to explore the city of it so this would
be a bit a little bit like me going
outside of my hotel catching the first
bus or train that comes along staying on
for 10 minutes or until I see another
connection with another bus getting off
the choosing that bus just randomly
swapping busses every 10 minutes or five
minutes I guess I'd see a lot of San
Francisco but it wouldn't be very
directed you know and I've probably
wouldn't get to the places that I
actually did get to as you can imagine
my strategy was a little smarter less
random than that my strategy was to
actually look at the map and figure out
oh yes I'd like to go there and there
and there
an actual fact doesn't help me much
because I walked out of the hotel and
started walking east and realized after
a few kilometers that was actually going
West because the Sun was in the wrong
side of the sky
coming from the southern hemisphere you
see but I've initially got that sorted
out so here's a white box model and the
obvious difference is it tells us we can
just see the model here we can see oh
this is quite a small model that's quite
simple and we've got the same control
same buttons but we can actually see
exactly where we are we can plan in
advance ok let's take an a transition
there oh yes better take a B let's go
see oh let's take a B transition
hmm we're in a terminal state so we need
to do a reset so we can kind of see all
that if we want to plan ahead plan a
plan a path to make sure we go and cover
a loop or Chinese postman all
transitions we can easily do that so
which would you prefer
well obviously white box right there's
more information you've got about to do
better with more information but I guess
my point is there are some trade-offs
and the reality is that final state
machines just aren't good enough final
state machines are too simple if you
start modeling a real system you rapidly
find out that your systems got a few
hundred states or a few thousand states
maybe maybe billions and you just can't
draw that and too many transitions so
they become too large so in practice
when we're doing modeling we need more
expressive notations and one common
widely use notation is extended finite
state machines where we add state
variables to our model to store some
data the data that's kind of a little
bit independent of which state we're in
it's it's useful for several states and
then our transitions become
significantly more complex they can
perhaps take parameters they can have
guards to say whether this transition is
allowed or not so sometimes when you
reach a state the transition is enabled
other times it isn't and when you do
take the transition
then it can execute an action which can
update the state variables so we now got
sort of a programming language more than
just a state machine so for example if I
was taking the bus I might say oh well
how farm are taking the bus it's kind of
parameter and I'm only going to take
this bus if it's going more than five
kilometers miles sorry and if it does
it's going to cost me three dollars
something add three dollars to my cost
so then we can start having a more
complex model more dynamic behavior so
the question is what what language are
these guards and actions written and and
this is where we get to the one of the
key slides of this talk which is the
difference between black models and
white models and one of the things I
think is important is that if you're
writing a white model where everything's
could have open you want to build it and
you're going to have a tool this can
generate tests from it the tool has to
understand the semantics of the model so
it has to understand not just the idea
of states and transitions but it also
has to understand the actual language
that's used for the guards and the
actions so that kind of means you need a
declarative language with simple
semantics clean semantics to describe
your actions for example we could use
ocl or something like that
to describe the behavior of the actions
which means that it makes it easy for a
tool to analyze if I take this
transition I know what's going to happen
whereas in a black box model the tool
can't see that all it can do is decide
whether to execute it or not and so
we've got freedom to choose any language
we want we can so long as the language
is executable that's all that matters it
doesn't have to be the semantics doesn't
matter so long as it's executable so
that means we can write our actions and
a familiar notation any programming
language you like regardless how
horrible it's not pointers recursion
loops point pointers I mentioned that
already and object-oriented dynamic
dispatch that's a real pain to reason
about all those kind of things would
make it really hard for a tool to figure
out exactly what's going to happen when
we execute this program but it still is
executable so the obvious trade-off is
that with a white box model we can see
the model in advance we can do some
planning say oh yes I want to follow
that path there and sort of we know that
guards are going to be we can choose
some data which will make the guards
truth whereas with a black box one we
can't do that we just have to discover
the model by exploration and so for test
generation with black box you're a bit
limited you can do some simple things
like random walks use cases and things
like that but fairly simple algorithms
because you don't know the whole model
in advance as you get to discover more
of the model you can do more
sophisticated things whereas in white
box you can do all those simple things
but you can also have some extremely
sophisticated symbolic reasoning saying
I want to reach that state over there
find me a path that will satisfy all the
constraints and and get to that stage so
it's a lot more demanding on the tools
but more powerful so that's one of the
key points of the talk now I want to go
through two examples the first one is
using black box models using model
j-unit which is a tool that I've written
in Java so the goal of this tool is to
be the simplest model-based testing tool
you could possibly have for a programmer
because I'm a programmer and my students
are programmers so if you were if you're
not a programmer and you wanted sort of
a drag-and-drop you know draw the graph
on the screen kind of tool probably
you'd end up with a different kind of
tool but for me I want to write the
models in Java for example and so this
is the kind of tool that I ended up with
so we can write our models using the
full power of Java we can use
inheritance to factor out common parts
of the model we can use loops we can use
extra methods we can use object
orientation dynamic dispatch all these
kind of things
that we do for good software engineering
we can do them on our models so our
models can be really expressive it's
still quite concise it model genders
kind of aimed at unit testing could be
used for system testing as well but I've
made sure that it's well integrated with
j-unit so that it works well there and
it just provides a few simple test
generation algorithms a purely random
walk a greedy walk which tries to prefer
fresh paths over exists it used ones all
round trips and a few other things like
that so it's quite a simple tool so
let's have a look imagine now that we
want to test one of the standard Java
data structures set of set of elements
and the first thing we have to do is
realize that this has got an infinite
number of states and we could test all
day we need to make some serious
abstractions to reduce the size of the
system as I've decided major abstraction
let's just test maximum of two elements
choose two two elements and that'll be
enough to test I'll set a very
simplifying assumption there we end up
with quite a small model like this they
say okay we start off on the empty state
if we add string one we'll have a set
containing just that we add string two
we'll have the full set with two both
elements in it if we delete es one will
be just have this one left leaders to
back to empty and so on so that's very
straightforward to understand in fact if
you think about a little you realize
there's a few transitions missing and we
should add these ones if it's full and
we keep on doing adds it doesn't change
that's that sort of part of the setlist
of it and so same if it's empty and we
do deletes and so on so there's
extremely simple model for States for
actions sixteen transitions you could
you could draw that out you know with a
graph drawing tool but I want to do it
in Java so how would we do that model in
Java well
here's the code and Java the red parts
are the parts that are a crop required
by model J unit so every model must
implement this interface which has these
two methods here and the action
annotation tells it what are the actions
that are callable the from each state so
these are these define the transitions
so a programmer who's thinking about
this model will realize well I don't
really need to model sort of the
complete contents of the set a better
way of doing it is to just keep track of
where the string one is in there or not
with a string two is in there or not so
two boolean z' is a nice way of modeling
this it keeps things simple and so that
is protected state because this is a
black box model we can't see the
internals of the state we don't know the
internal semantics of what these methods
do we just execute them to provide the
the the observation the little LED panel
that shows the internal state a little
bit we can define it to be whatever we
want so we can have a different view of
the state then is actually our internal
protected variables but in this case
here I'm just out decided to output the
two variables as true or false so this
is kind of a faithful representation of
the internal state you can have
representations and throw lots of
information away and give you a small
number of states and you need a reset
operation she sits in both defaults and
a few actions and for example if we add
a string Ed string one just mean setting
that boolean flag to true if we delete
string one it means setting it to false
so it's extremely simple model so that's
about ten or eleven lines of code those
ten or eleven lines of code define the
four states the four actions and by
executing them the sixteen transitions
so this model is kind of smaller to
describe then
all the things by hand when you get to
large models you can have a relatively
small java class that actually creates
large large models well that's not
really the goal the goal is to keep your
models it's fairly small as possible
so we've now written our model this red
part here what else do we have to do
well the red parts of the parts that the
user has to do and the blue parts are
provided by the model J unit so we've
written the model that's implemented
that interface model J unit also
provides a wrapper that sort of goes
around this users model and it uses a
reflection to find all the actions it
allows you to execute actions and resets
it keeps track of a set of listeners and
tells them everything's going on so the
several listeners that can keep track of
the coverage of your testing and most
importantly it has this hierarchy of
classes to do test generation so an
abstract one to generate tests and in
several implementations with different
algorithms so the last thing we have to
do as a user is write a few lines of
code which will choose a test generation
algorithm and pass our model to it and
make it work
generate some tests so here's that code
choose a test generation algorithm we're
going to use created a greedy tester and
pass it our model and then how many
tests well let's go for 150 so those two
lines of code will use that model and
generate our test sequence all through
one or two we didn't want to write those
two lines of code we could use a go a
and just go and click a few options and
I'll generate that code for us or
generate the test for us either
either way the idea of that is just to
reduce the overhead of learning model
j-unit so you have to still write the
model in Java but then you can just use
it and experiment with different test
generation and things so if we do that
we'll get a whole sequence of 150
transitions here that just printed out
as triples so each set starts off from
the empty state add string to randomly
gets into the state false true and then
from there Ed string one so now it's
full delete string one goes back to that
state - lets drink - so you can empty
again to meet string two again and stays
empty and so on carries on and models a
unit will also tell us that okay after a
transition you've actually covered 50%
of your model 50% of the transitions
after 30 something transitions you've
got 75% and you'll get 100% transition
coverage after 116 which obviously isn't
very optimal let's just do the greedy
algorithm still isn't an optimal way of
covering things as fast as possible
there's better ways of doing it so that
has created a model and allowed us to
generate tests from it we could use
those for offline testing we could just
take that output script and write some
separate program which goes through and
executes set but we can also do online
testing so let's do that to do online
testing we're just one way of doing it
is to add some glue code some connection
code connects our model to an
implementation I'm just going to test
hash set there but I don't expect you
can find any errors in that but were but
let's just use that as an example and so
every time we do an action in the model
like adding a string we're sitting one
of the model variables to true we'll
also do a corresponding action on the
system under test okay adding a
particular string string one there
adding the empty string there and so on
the same for delete so you can imagine
the idea of model-based testing is that
the model is evolving and changing State
and in parallel the system under test is
changing state a more complicated state
and we're kind of we need to check that
the turret in sync so something missing
from this this would execute okay and it
would kind of test the set but we're not
getting much feedback there's not much
Oracle here Oracle as in the wise woman
who sits on top
Hillen tells you whether you're doing
the right or wrong thing we need an
Oracle to tell us whether these whether
the tests are passing whether the hash
set is doing the correct thing so let's
add an Oracle as well and the way you
should do that is just for each method
to call a checking routine after it's
changed the abstract the model state and
the system under test and now this
routine here will check that the to
agree and here's the code some example
code for that to check the to agree well
we could calculate the size of our model
set which would be 0 1 or 2 and check
that that's the same as the size method
of the system under test we can check
that the contains thing works correctly
and agrees with our flags we could go a
bit further and check the is empty
method check that equals method and so
on you can do it add as much sort of
consistency checking as you want
depending on what you want to test so
there's the adapter code or glue code
that links our model to the system right
imagine now that hash there had a bug
and say if you try and remove an empty
string something goes wrong then this is
what would happen when we run it we'd
actually run it we'd see a few
transitions working correctly and we get
an error report like this failure and
action deleting string 2 from the state
false true in this case may be a null
pointer exceptions just like this didn't
really happen right I don't want to be
sued by Sun here this is just an
imaginary example and some sort of stack
trace so you can track it down to find
out what caused the error so in reality
I've run this on hash set and it doesn't
have any didn't detect the new bugs but
it still needs me wondering how good is
this test yet that I've generated and so
I thought I'd answer that a different
way introduce another tool this is a
tool that has kind of come out of the
university that I'm at but it's also
from a commercial company and the split
off from our university called real to
and they've released that is this is
open source just a few weeks ago and it
does tries to measure the the goodness
the of your J unit test rate and it does
that by taking the actual class that
you're testing and mutating it and does
a whole lot of different mutations and
for each mutation it runs your j unit
tests and sees if they detect the
mutated mutation and if they do that's
good that part of the code is tested
really well if it doesn't then maybe
your j unit tests aren't good enough so
we can measure the percentage of
mutations covered if zero percent of the
mutations are detected by your unit test
you probably haven't got any unit tests
so that's a bad sign if you get 50
percent of the mutations covered
probably your unit tests are pretty
inadequate because 50 percent of the
changes to the code aren't being
detected so there could be a lot of bugs
in there that the unit tests won't pick
up if you're getting sort of 80 to 95
percent then you've got really good unit
tests and 100% is ideal in theory but
sometimes difficult to achieve because
of the way the codes structured so this
just gives a useful measure of how
thorough your unit tests are
now this is not measuring code coverage
all this is measuring the percentage of
mutations that are covered so 100% means
that every single mutation of yours or
your class is being detected by the
tests it's probably correlated with code
coverage but it's not it's not the same
thing it's probably more demanding than
code coverage in many cases so our in
our in jumble on on the test that we've
generated so I actually wrote my own
little toy implementation of set of
strings it's sort of a hundred lines of
code I suppose just using an array and
ran run jumble with - our flag which
does a bit more mutations than normal
and I had the the gray code and you know
check the is empty and equals methods
and I also added some code to check the
result of the add and remove methods and
so it's jumble finds 25 mutations in my
code and comes back and each dot there's
a mutation that passed as in the unit
tests detected it and the other ones
here the to failure messages are
mutations that weren't detected and so I
come back with a score of 92% which is
pretty good these two turn out to be
this is the the iterator through the set
which is just I returned the iterator
through the underlying array ArrayList
and my tests didn't actually call the
iterator at all so it's kind of pointing
pointing out to me that hey you forgot
to test the iterator and this one down
here is some complicated FTL's case
inside the loop of the equals method I'm
not sure why that's not being covered by
these tests I'd have to investigate that
further so it gives me a bit of feedback
yes the generator test that
hundred-and-fifty sequence is pretty
good it's covering the code covering the
implementation quite nicely but there's
a bit of room for improvement so let's
look at a white box example so the
example notation I'm going to use here
is UML and
we'll use a class diagram to give the
overall structure of our system under
test and an object diagram for an
initial state scenario to do the testing
from some state machines to specify the
behavior of some of the classes and some
ocl for the methods and the other
classes and the example tool will be a
commercial tool that's been in
development for about 10 years but in
commercial production since 2003 and the
latest version uses a quite a
sophisticated automatic reasoning engine
from prove accom which is kind of like a
a really powerful automatic theorem
prover to actually analyze the model and
generate tests so how does model-based
testing work with this tool well you
model in UML we use bawlin together to
do that and then export the test from
that and go into the lyricist designer
where you can select your test
generation and generate some tests and
then actually generate test there you
export them to some executable language
maybe j-unit script code or maybe quick
test professional something like that or
various other other testing languages
and then of course you execute those so
let's go briefly through that I'm going
to use a library system as an example
we'll sort of web based interface so
each subscriber logs on to terminal does
some loans and things like that and will
generate je unit tests and these can
either execute by correcting connecting
directly to the library API or via
Internet Explorer using a wattage
library so which clicks on links inside
Internet Explorer so here's our model
the class diagram is a simplified class
diagram of the real system because we
can throw away a lot of detail but it
still has things like books copies
subscribers this is the main system
we're going to test
and the idea of a session so each each
browser starts up an individual session
and a session has a whole lot of actions
it can do we need to specify what each
of these actions does and so does the
main system which is the server and as
well as that classroom will now
instantiate that class diagram to an
object diagram to give us some test data
so here we'll say we've got one client
so I say one server two clients
two sessions in other words two books
it's not a very big library two copies
one copy copy object doesn't actually
belong to a book yet and two subscribers
one of who kind of is subscribed and the
other one is disconnected not connected
yet so that gives us some data to
generate test with for the server it's
kind of it's in different state so it's
convenient to use a state machine to
model the server and the library server
can the library can be either open or
closed
you can switch between those at the
beginning and the end of each day and
you can also take it offline to do some
admin work like changing the date and
things like that it's a very simple
state machine these transitions here
this is an event open or say open and
then as well as an action here there can
be a guard in this case here day start
activity we need to define that rather
than defining it directly in the diagram
we just do it on separate page and so
for example the day start activity is
just incrementing today's date other
ones have got enough thing else in them
and so on so that's actually ocl which
is probably new to many of you but it's
not not too different to a programming
language just a bit more declarative and
we need to define the methods and the
other class too and this actually uses
quite a lot of ocl and here's just part
of the code for the lending a book
operation and it's doing things like if
the person borrowing has a book
whose return date is before today then
there it's overdue
so the message should come back that
this is an over subscriber with a late
book and so on there's a whole lot of
cases there and that's written an ACL as
well so that model is quite
sophisticated we export that from bawlin
together and load it into the test
designing tool then we get the test
designer has a goal of trying to test
every transition of a state machine
every branch of an ocl if-then-else
so it ends up breaking up our whole
model into a whole lot of sort of test
goals test targets and it comes up with
80 or 90 different parts of the model
that thinks should be tested and here's
one of them which comes from the lend
book operation and it's som this is ocl
again it's pretty complicated to read
but there's some various things in here
when you get to read it you can see that
okay for this test to bow to generate
this test we have to satisfy these
conditions so we have to be at the right
node the right station our state machine
and we have to have all the right data
set up so the system has to be ready and
has to be valid subscriber whole lot of
error conditions have to be okay the
subscriber can't be finished in his
subscription before the book will be due
back and this last one here says that
subscriber mustn't have an overdue book
so there's a whole lot of conditions in
if we get there we expect to get this
message saying that they've got an
overdue book so it shouldn't be allowed
to to lie in the book so generating a
test for that is actually quite
challenging because the test generations
got to find a path through the state
machine to get to some state where it's
possible to do this test and set up all
the data to make sure we've got to
subscribe a subscribed and the right
kind of book and that they've got
another book out on loan which is it
which is overdue all that kind of thing
there's nothing explicitly telling it
how to do that we're just relying on the
symbolic execution engine to fine
a path that satisfies all these
conditions okay so this is one of the
most important it's got to have an
overdue book this person and so the test
generator hextech you search for some
sequence of operations that satisfies
all of these constraints and they're in
some suitable data that will satisfy the
conditions so if we run the test
generation in a minute or two it
satisfies about eighty or ninety percent
of the test targets and in this case
here it generates this sequence of
operations to satisfy this this case of
lending a book you see it's got about
nine or ten things that has to do before
it can actually call the lend book
operation so it's generated quite a long
sequence the setup sequence so then we
can export that sequence of there
into Java in fact as I mentioned before
when we generate the test is actually
telling us that we had 82 targets it's
managed to generate test for 73 of them
there are nine that are undetermined and
we could perhaps investigate those and
find out whether the machine just isn't
powerful enough to solve to find that
path or whether there's a mistake in the
model so it gives you some feedback on
the model and also the requirement
coverage as well so we export those all
those tests into j-unit and we might get
some code like this which is a unit for
code and so just the set up is a
sequence of operations to set up all
this data and then we finally do our
test which is to lend lend a book and we
expect to get an exception throwing just
a late subscriber we could actually
execute that but to execute that we've
got to have a system under test which is
maybe running in a web browser or more
of an API and so we need a little bit of
adapter code glue code just like in the
model j-unit case which is going to
define each of these operations and
translate it into the low
level operations of the API so that
again some some code to write there
manually but you're not writing the test
you're just writing a bit of glue code
for each method so that in conclusion
the you've seen an example of black box
models and testing from those in white
box models my conclusion is that the
black box models are simple to write
because you're just doing it in a
familiar language like Java and you've
got sort of complete flexibility how you
define the actions they're good for
simple heuristic test generation you can
get lots of tests out of them but
there's a lot of redundancy in those
tests and not a very sort of optimal
test rate and you get very weak
guarantees we can run this execution for
an hour and it might come back and say
okay well I couldn't reach state32 even
after trying you know generating a
thousand tests I've got no idea why
because it's not doing a deep analysis
of the graph to find out why that thing
isn't reachable whereas white box models
you can do quite smart test generation
you usually come out with a small number
of tests very carefully designed you can
kind of get guarantees like each test as
the minimum length possible to test this
condition we can do look ahead and you
come back with and results like state32
has been proven to be unreachable so
that almost certainly indicates an error
in your model so there's two sample
points on the spectrum of model-based
testing showing different styles of
models this one here was offline testing
generating the tests as java and
executing later this one was doing
online testing and those are just two
points there are a whole lot of other
approaches brief commercial investment
here covered in the book that Bruno and
I have written and I've only described
two notations here but is actually like
you know dozens of notations that have
been used for model-based testing and
lots of tools commercial tools as well
as quite
she open-source phones as well so
there's more discussion of those there
so that's the end I haven't talked about
industrial applications I could do that
but I don't think I didn't think I'd
have time and I was right so Christians
hi so when you're talking about
generating the 150 tests you put them
into one big sequence have you or do you
know if anybody's looked at the
difference between say fifteen sequences
that are ten long versus one sequence
that's 150 long and how that can impact
either coverage or defect detection yes
capabilities yes that's a good question
so I didn't mention it but I'll just
cover using the default setting of that
tool which is to have a 5% probability
of doing a reset so that is why those
occasional resets it just means on
average your test sequence is going to
be 20 long but you could sit there to be
any percentage you want to influence the
length of the tests but the question I
have seen I can't remember who it was
but I have seen one paper that did some
research on long complicated tests Bruce
had lots of lots of short ones and I
think the conclusion was that the long
tests are often expose more interesting
errors or unexpected errors because of
extra interactions but of course the
disadvantage is they're a pain to debug
if you get a failure after a thousand
operations it's actually quite difficult
to to know what the cause was as opposed
it was just 3 it's easier to track down
and another idea from Harry Robinson
which I like but haven't been permitted
yet is as v-line algorithm take a long
sequences failed and then randomly cut
parts out of it and see if it keeps on
failing and trying to reduce it down and
down and down like sort of genetic
mutation until you get the smallest
sequence that just shows the same a
failure that where you can try and help
that debugging problem yeah so there is
a paper I can't remember it off off they
hit my head at the moment any other
questions
so it seems like one of the the
vulnerabilities of model based is the
state explosion so I'm wondering what
you think about how these things would
scale in a in situations like at Google
where we have a lot of self-healing
systems that use tons and tons of
heuristics it's difficult sometimes to
understand what the state is even when
you built it yourself
how would your solutions or your
thinking
relate to those kind of problems
you're right stat explosion can be a
real issue one advantage of the the
black box approach is kind of in a way
if the even if the state is infinite it
doesn't matter
using random generation you can still
generate a few tests but you're probably
not getting very good coverage if you do
that you're better to try and use
abstraction really strongly and come up
with a fairly small model so probably
the obvious answer to state explosion is
try and use abstraction to to narrow
down the properties that you're testing
to be something that's fairly small but
that's not always always easy to do or
practical so I haven't got a magic wand
that will I can wave and make all of the
state abstract state explosions go away
even though I am 4m from New Zealand but
any other questions
kirkland or Boulder do you have any
questions you know you can pipe in any
time it doesn't seem like it so in the
case thank you very much for coming to
Google and talking to us about
model-based testing and hope we can
discuss some of the issues Softline
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>