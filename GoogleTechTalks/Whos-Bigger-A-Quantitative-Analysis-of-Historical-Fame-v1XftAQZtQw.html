<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Who's Bigger? A Quantitative Analysis of Historical Fame | Coder Coacher - Coaching Coders</title><meta content="Who's Bigger? A Quantitative Analysis of Historical Fame - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Who's Bigger? A Quantitative Analysis of Historical Fame</b></h2><h5 class="post__date">2012-06-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v1XftAQZtQw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's my pleasure to introduce to you dr.
Stephen skena who is a distinguished
professor of computer science at Stony
Brook University New York he is here to
talk about who is bigger a quantitative
analysis of historical frame as you can
see he has published over 130 papers in
computational geometry computational
biology graph theory and data mining is
also the author of four books including
the algorithm design manual which is
quite popular within Google and
elsewhere largely is also the co-founder
and chief scientist at general sentiment
of media measuring company without
further ado I'll get professor on the
podium I'd like to thank y'all Tim okay
thank you okay so um let me just say I'm
very happy to be at Google I have
several connections here uh one thing is
a bunch of my students have been here
over the years I think we've got like
eight or nine full-time permanent alumni
of our news and blog analysis project
here and it's a rite of passage for all
my PhD students to spend summers here so
we've got Rama here and yang ping Chen
in a you know Washington the other
connection i guess i have here is that
um my understanding is that uh you know
my algorithms book is a popular thing
for people trying to get jobs at google
you know so when you and since many of
you I guess have jobs at google perhaps
you've seen it but when Stevie I a
recommended my book at Google my sales
went up a lot so I've always had a warm
spot to google for that reason um but
okay let me talk about what I want to
talk about here which is um we have a
method or system that we don't want to
talk about for trying to construct a
relative rankings of historic figures um
it's a common thing in um you know for
there to be books and newspaper articles
ranking the top 100 athletes in history
or presidents and history or politicians
or scientists or Italians or any other
group that you can imagine
and so there's a you know it's a common
thing that want to try to rank
historical figures based on significance
now what we mean by historical
significance is subjective and
culturally biased and all that but um
but being able to rank people is
interesting from a point of view
prioritization I want to show you is it
interesting for a point of view
education I'll show you there's some
interesting analyses you can do if you
can rank people by significance so I'm
basically what this talk is going to be
bad as about a project we have to rank
all the people in Wikipedia by
significance okay and let's try it just
to see what we're doing so who's bigger
okay historically historically more
significant George Washington or Abraham
Lincoln who here says George Washington
couple who says Abraham Lincoln a couple
more that's not surprised that the split
because we have a blinkin is five and
sixth among the most important
historical figures the least important
president we have is Chester Alan Arthur
who many of you may never have heard of
he came in at 190 a--the um during the
60s John Lennon said that the Beatles
were bigger than Jesus okay is this true
or false who's bigger Jesus or John
Lennon who here says Jesus who it says
John Lennon okay and again we are right
here okay we have Jesus is the most
important single most important
historically significant figure um the
beat all the Beatles you know are you
know still quite impressive um but uh
but less than that and they do if you
rank them by significance fall in the
canonical order of john paul george
ringo if any of you have beatles fans
who's bigger Elvis Presley or Ludwig von
Beethoven we're interested here in
historical significance who here says
Elvis fuse here's Beethoven okay turns
out Beethoven is ranked historically
more significant although Elvis is
actually quite high on the order with
Thai kofsky and substantially ahead of
Franz Liszt by our measurement okay
who's bigger I'm Eli Whitney or Justin
Bieber now who knows who knows who's Eli
Whitney
we know who you inventor of the cotton
gin a pioneering thing for the
Industrial Revolution so who's bigger
Eli Whitney or Justin Bieber um okay who
says Eli Whitney who here says justin
bieber and as a mixer and part of it a
question of what do we mean by
significance if we rank them according
to our historical significance that
measure Eli Whitney scores substantially
more important more more significant
than justin bieber justin bieber falls
in the same equivalence classes Frankie
Avalon of a teenage idol you know
popular at that time but by contemporary
Fame which is another sort of byproduct
of our analysis certainly more people
have probably heard of Justin Bieber
walking around the streets then then
then Eli Whitney so we can kind of get
that kind of a measure so who's bigger
Mark Zuckerberg or Jesse Eisenberg okay
who says uckin bird who sings Eisenberg
ok that one's that much is clear okay so
we have Mark Zuckerberg ranked around
7,500 um in historical significance
who's bigger Larry or Sergei okay so um
who here says Sergei who here says Larry
okay so what do we decide so we actually
have them in terms of historical
significance we have Larry somewhat
ranked somewhat higher than Sergei again
lower is better in these kind of
rankings but by Fame by in terms of the
main on the street recognition we
actually have sergey brin a little bit
higher than then Larry Page and again
you can see them in perspective both of
them ranked higher than Eric Schmidt
okay in terms of our historical
significance measures um here are the
top 20 people of all time and so if you
look at these figures you'll see these
are really sort of heavyweights of
history that we sort of were able to
pull out as being the most significant
people in history by our measures here
so why are we doing this one reason
we're doing this is um you know they're
there is an increasing interest in you
know trying to apply big data kind of
techniques to studying things in the
social sciences you know we have you
know my
real interest that this sort of falls
out of his sort of news and blog
analysis and we have collaborations with
sociologists to try to interpret you
know what can you learn about the
frequency and sentiment of individual
people when you're analyzing them in a
news corpus over time you know for large
amounts of things so amazing we looked
up to do this kind of analytics to help
understand social forces and part of
this has been out of this is one of the
things that's inspired the the work I'm
talking about today but I do believe
there are sort of more computer science
II kind of applications to this that
might be interesting um you know Twitter
users are familiar with Klout scores how
important is this tweeter you know if
they do this thing you can think that
what we are doing is trying to build a
Klout score for people outside of
Twitter you know who is more clout than
the other you can imagine using
significance measures to try to
disambiguate you know between you know
entities names you know often collide
between multiple people and there might
be multiple senses of whether an entity
is important and so trying to identify
the real when you see a Larry Page
reference do you mean the real Larry
Page you do you mean an obscure British
entertainer that kind of thing if you
know who's more significant you can help
make those kind of decisions you can
measure documents for how esoteric the
content is you know there's readability
measures that measure sort of things
like grammar but there's also sightings
of subject readability which have
probably functions somewhat of how
obscure what they're dealing with and
we'll talk about some application to you
what we're going to use it to try to
identify biases in documents and people
and things like that because we can
service some kind of a reference
standard for significance so okay so now
let me tell you about our methodology
again you guys are used to ranking
documents on the internet by importance
that's sort of what Google does for a
living um ranking people is done you
know reasonably often when you hire
somebody you have a hiring pool and you
rank them from best to worst that's
basically what you do college admissions
things rank people so there are lots of
times when people you know well of
situations in the world where people are
ranked based on quality or significance
and the standard approaches wouldn't
scale to the kind of
do people can do expert polls you know
is George Washington more important than
Chester Arthur you know you can have the
public vote but of course the public
doesn't know about a lot of different
things so you know the limits to what
crowd sourcing could be trying to have
the crowd crowd source the difference
between various Elizabethan poets would
be a hard thing to do or you can start
to build models and this is kind of the
way that we would be doing it so our
goal here is going to start from a
historical universe of Wikipedia
Wikipedia has a population roughly equal
to San Francisco there's about 800,000
people with Wikipedia pages um and you
know why our measures we can rank eat
all of them from most to least
significant our least significant person
was a Serbian canoer okay who would want
a bronze medal in some non Olympic event
he's one of the two guys on the right
nobody knows who okay but that's that's
him and so what we're going to do is
derive our significance measures from
various Wikipedia quantities the first
let's say a sort of factor that we're
going to use is weak is page rank which
I imagine some of you people have heard
of here um you know um and obviously
page rank is you know a google thing and
it's used to ranking used to rank
sources are you know by-by in some sense
by importance on the internet we can do
the same thing with Wikipedia you know
Wikipedia pages are uh you know aren't
vertices of a graph and there's links
between one wiki page and another run if
you're a person who has links to your
Wikipedia page for many other important
people you're probably important and so
by using Wikipedia we can compute the
centrality of people and when we do that
yes
okay so that's that okay you'll see that
in a minute okay so at the moment I'm
not ignoring topic pages okay and so
this is um first of all using the in all
the pages in Wikipedia and when you do
it we understand how effective the
factor is we've identified you know a
thousand prominent people okay well
known people and look to see who does
best or worst in this cohort among that
measure so by page rank and Wikipedia
you get some very good you know some
some obviously some heavy hitters is
among the people of highest-paid rank
the people of lowest pagerank tend to be
very young celebrities okay um you know
who I suspect you guys know better than
I do um but um you see some kind of
anomalies why is Linnaeus who here knows
who Carl Linnaeus is yeah okay so he was
the original biological taxonomist and
he's one length from every species page
so you know really implicitly if you're
allowing subject pages that's really
what you're asking you're allowing
dinosaurs to vote you're allowing all
kinds of other species to vote and you
know if you now restrict paid the graph
to only people pages you get a somewhat
different a factor okay and again here
we see you know now we see you know
standard heavy weights here
interestingly people who start becoming
relatively low ranked by people page
rank or people like Richard Stallman and
Jimmy Wales you know who are you know
the new people and the Wikipedia people
and the reason is because they're so you
know they're more associated with big
organ you know prominent organizations
and products than they are with other
people and so both of these page ranks
mean something we're going to use both
of them in our final computation another
factor that we might use to build a fame
model would be Wikipedia hits okay we
would expect that if you are an
important person more people will want
to read your Wikipedia page then then
other people would and Wikipedia hits
are kind of orthogonal to page rank
Wikipedia hits measures the interest of
readers whereas page rank would measure
the interest of writers
yeah well we're gonna well we'll get
right now we're just looking at what are
our raw inputs okay and we'll talk about
how we mean so the inter they're going
to be inputs to both instantly but
they're all going to be inputs to both
okay but how we're going to you'll see
where that the fame comes up from
significance yet know so you can get the
hits data from Wikipedia foundation so
uh so this is available to download and
we have gotten and so this is actually
an interesting it's an interesting data
source to have okay um and when you do
it who are the top people again if you
look at the prominent people by
Wikipedia hits most of them again our
modern celebrities and things like that
somewhat upsettingly and surprising the
only non contemporary fitler person who
sits in there turns out to be Hitler um
you know when you look at the important
but low number of hits people you tend
to see things like Canadian Prime
Minister's and Australian Prime
Minister's and things like that okay as
being you know sort of stalwart figures
but not ones that that people are
actively reading about so much so we can
use hits we could also use the article
length of a Wikipedia document as a
feature in principle we would expect
that a more important person would have
a longer Wikipedia article and you know
in in you know standard traditional
printed with encyclopedias it was clear
that length of a document was a scarce
resource that shouldn't be true in the
Wikipedia era but there are still you
know forces in Wikipedia that that you
know there is definitely a community
that wants to enforce notions of brevity
and conciseness and appropriateness so
I'm you know there are over a hundred
thousand people who've had their pages
removed from deal what to go Wikipedia
usually they wrote them themselves and
stuff like that but so the community is
definitely trying to delete things that
are redundant and excessive for a
personality and so length is somewhat of
an interesting measure so who do we see
is the most law of the people with the
longest and shortest wikipedia articles
in general the longest articles belong
to very well
no controversial relatively
controversial figures are people with
constituencies you know l ron hubbard
you know Scientology has a constituency
um unfortunately Hitler has a
constituency um uh you know so che
guevara has a constituency um if you
look at the people with low shortell
relatively short article lengths you end
up getting certain content select
contemporary people who probably haven't
done that much to merit their fame and
certain you know ancient figures like
Euclid in your repartee of whom very
little is known yeah what this is we are
interested in the text here we are
counting the text we are do have deleted
the info I believe in this measure we've
deleted the info boxes we've deleted the
index if the bibliographic sections of
it this is I think supposed to
correspond just to text you know we've
uh you know we've you know we've looked
at all of them but this is I think the
factor that we're most interested it's
finding most meaningful any questions
okay another measure would be Wikipedia
page edit okay that uh you know
anybody's allowed to edit Wikipedia you
would expect that if you're a well-known
significant person more people will know
about you more people have something to
contribute about you more people will
care and therefore you'll probably get
more edits again who do we see as being
high edit people we see people again
with you know with with constituencies
controversial figures religious figures
tend to generate a large number of edits
probably their flame wars back and forth
between constituencies whereas the low
edit people or people you know who for
the most part have been dead for a
thousand years aren't generating very
much new new material so what did we do
with all of this stuff okay we would um
we combine them using a technique called
statistical factor analysis the idea is
somehow that we've gotta get a bunch of
different measurements a bunch of
different observations and we'd like to
identify a small number of statistical
you know of sort of underlying factors
that are generating the variance here so
again my analogy
if you had a bunch of measurements for a
tux you know you can measure your length
your shoe size all these kind of things
the main two factors that govern and
probably predict a lot of your other
measurements on a tux are basically
something about how wide you are and how
tall you are and you know again spearman
you know originally used this Darrell
factor analysis so that he could you
know prove that there was one underlying
notion of intelligence um measured on a
bunch of you know as a result of all
these different intelligence tests so
when we do a factor analysis we discover
that there are you know two primary
factors that pop out of this thing okay
that expels explain roughly equal
amounts of the variance okay and when we
look at it these factors tend to have a
natural interpretation one of these
factors loads very mostly on the page
rank variable and that's going to
correspond to something that we kind of
think of as gravitas serious
accomplishment where's the other factors
it loads largely on things like page
hits and revisions and this seems to
correspond more to a notion of you know
gross public fame celebrity things like
that so we can they call that celebrity
and our notion of Fame and significance
is going to be as some of these are
these these factors so the ratio of what
your reputation is of Fame versus
gravitas dozen tables distinguish
between different kinds of people the
people on the Left have them you know
greatest amount of this gravitas factor
and if you look at that they all tend to
be serious solid figures in history the
people with the greatest percentage of
their renown coming from fame from from
from you know celebrity is this you know
our our wrestlers and things like that
if you look at it again that the size of
the bar Britney Spears is the only one
in this bunch that has even a slight
amount of gravitas to her and you know
we don't think of her as a high gravitas
figure here so this is kind of to meet
kind of interesting we have a tool to
distinguish between you know account you
know in some sense what we think of as
accomplishment and in some sense what we
seem to think of a celebrity um and in
fact our notion of Fame the question of
what is do we mean by Fame our basic
notion of Fame is just adding up these
celebrity and gravitas factors that's
basically what we mean by Fame so when I
talked about the fame of figures that's
what we wanted to do but if we measure
Fame like this we find that we
overemphasize people of this time okay
by this measure of Fame Britney Spears
is more famous than Aristotle which
certainly does not correspond to a
notion of significance that we would
like to think of historic way you know
by our notion 28 of the most significant
most famous individuals of all time
would still be alive and that that we
think is overestimating it so we wanted
to try to build a model that would
factor in reputation decay in our
general sense is Britney Spears a
hundred years from now will probably not
be as known as Aristotle the kind of
have an image that her level of Fame is
going to decay and so we might try to
factor in an idea of a half-life we
might imagine that somebody's Fame drops
by half every 50 years and it isn't
quite at that kind of a model because if
so someone like Jesus would have dropped
by you know a factor of a million or so
and become invisible if they really had
a half-life and so we tried to look at
various data sets that try to come up
with an accurate model of how is it that
reputations decay and we decided that
there were two different processes at
work first there is a notion of a lapse
from living memory and second there's
some kind of a contemporary bias because
of Wikipedia advent of Wikipedia so how
could we measure how reputations decay
over time and here you guys came to our
aid is a google engrams data set that's
very interesting where you know I you
know you guys have scanned all the books
that have ever been imprinted or some
non-trivial subset of them you know
twelve percent or something like that
and have produced a data set of for each
popular Engram from length one to five
how many times has it occurred in books
published each year you know from going
back to three hundred years to date
and based on this we can get a Fame
model to see you know if you were famous
at a particular time people wrote books
mentioning your name and so we could
start to get plots like this this would
show us what was the relative fame among
these revolution women in the
Revolutionary War as a function of time
and you start to see interesting things
who here knows who Betsy Ross was who
was Betsy Ross yeah what'd she do invent
is sewed the flag now she did not appear
in the historical record at all until
eighteen seventy why do we know she
sewed the plague but one point her
grandson wrote an article said yeah my
grandfather she sewed the flag and
everybody got very excited and started
talking about Betsy Ross okay so you can
measure something like that again she
doesn't emerge in our data set until a
particular year using the Ingram's we
can figure out when where people talked
about okay and then we can sort of model
we know for every famous person when we
were they alive when were they born when
did they die how much were they talked
about in books as a function of time we
can start to align this thing to try to
figure out when do people typically as a
cohort achieve their peak Fame and how
fast is that decay okay and based on
this we can build a model that basically
gave us uh you know we found that famous
people you know decay are slowly
relative to less famous people okay we
found that the peak of people's fame is
typically when they reach about 60 or 75
somewhere in that range at least as
measured by books and that it the kaizen
levels out so we know a hundred years
175 years in the future this stops being
decay okay and this is why we still know
about Aristotle and Jesus at that point
their fame is basically locked in the
historical record and there isn't a
further decay so we can factor in that
decay rate there is another factor that
that that also seems to occur which is
um that it is now a lot easier to get
into Wikipedia if you're alive today
then if you were alive um 50 years ago
and the way we could tell this is by
plotting the
deaf ear of people okay the frequency of
people in Wikipedia by their death year
that's sort of our plot over there and
if you compare that to world population
which is the bars here or the number of
people in the pipe five by then ok so
the bars represent the number of people
who died in Wikipedia each year the
black line represents that the world
population okay and if you look at this
it amazing Wikipedia for a 200 over 250
years amazingly well fits the
distribution the number of people in
Wikipedia is well predicted by the world
population okay with three little bumps
first bump is World War one the second
bump is World War two more people died
in these wars of historical note then
then normally so we have more Wikipedia
people then and then since Wikipedia
came in a lot more people are
represented in Wikipedia than there
should be okay and so um so based on
this we can identify that there's a
cohort of people here who have a lot
more celebrity than they should have
okay gravitas has remained consistent
celebrity hasn't we have found a way to
correct for this thing by subtracting a
fixed amount of celebrity from people
based on their their peak activity year
and using these to decay measures we now
get a notion of what we mean by
significant
ok so the Ngram stuff would is um we are
using basically as a just a measure of
um you know just for decay here ok
although um although I was it something
we're quite interested in ok again
gowtham here ok my students spend a lot
of time yeah experimenting with the end
grams and building an interface on it
and stuff like this so we're very
interested in the Ngram stuff but you
know the integral of limitations one one
limitation is it of course the data
Republic data stops in 2008 so you don't
get more recent events there um it also
is relatively hard to match names in uh
you know in the end grams okay because
certain people you know certain the
question of what is Babe Ruth called is
Babe Ruth babe ruth or is Babe Ruth
George Herman Ruth okay and people are
often referred to under different names
the answer is it's interesting names for
everything we've done here this is the
only play it's me there's the only
thought that we have used the N grams
for for here ok although in supporting
analysis we do we make a lot of use of
the N grams so engrams are good we think
it's very good but for what I'm talking
about here it's basically only for decay
purposes ok any questions
yeah so okay so the answer is you know
might again you know might might
celebrity change over time you know the
whole notion of celebrity seems to be a
somewhat recent thing in world history
you know that you know you didn't have
broadcast media until you know 19 20 or
something like this and so you know as
we've looked at this thing this was sort
of the way that we felt was the most
appropriate way to deal with it you know
you want to use the historical evidence
like the Engram so you're doing
something in a principled way you know
there's a certain sense we add the
britney spears should decay and fall off
the earth quicker than other people but
what the real justification one has for
this is unclear to me it is not clear to
me that media celebrities will fall off
the earth you know in a world where you
know reruns are playing forever on
television it may be that Gilligan's
Island the people in Gilligan's Island
will outlive the pre or Jesus or
something i would say that but uh but it
so anyway so we don't really take
special care to correct for that except
for this sort of fixed correction to
what we think of as Wikipedia effect so
how good is our model you know so we hem
up with a model and again our model is a
first principle thing it's not a
learning thing particularly but we'd
like to assess how well do we do
identifying historical significance and
so to do this we looked at a bunch
collected as many published rankings as
we could where people tried to rank
historical figures by significance some
of these are based on you know author's
writing books there aren't amazing some
of them are based on crowdsourcing
things like the IMDb star meter okay and
some of them are you know based based on
other pole poles things like this is
some expert balls a variety of different
sources and so the question is how well
did our um yeah
right well we do have loved them but we
do have for example in this so certainly
we don't do anything explicitly to know
about baseball in our model that much is
clear but we do have things like the
baseball star rankings from from a
website so our gold standard here was
basing we're trying to come up with as
many different published rankings as we
could that was sort of our our gold you
know not nothing nothing nothing that I
think you would agree was meaningful was
excluded okay you know occasionally we
would download something that looked
like a list and then you'd see it was a
random looking set of people and didn't
correspond well with anything ok so I
think this is a fairly honest and
representative who's an honest and
representative attempt to come up with
as many rankings as possible that is
that is the goal here okay and you know
and so we were going to use these as a
gold standard to try to assess them so
what happens if we do that I get a no so
what do we end up getting so the
interesting arm variables here are what
is the rank correlation the Spearman
rank correlation of our rankings with
the you know with Egypt with it with
these lists and what we're able to do is
our here we're comparing us again what
are we doing your normal
in all the categories our decayed model
achieves a better uh correlation with
the published rankings then um then you
know then uh any of the other models
that we had um now the numbers here may
still not look very high to you you may
want you know numbers to be very high
but one thing to notice is that these
ranking lists had a lot of disagreement
among themselves you might imagine the
list of the greatest Italians in the
world might put Frank Sinatra ahead of
Mussolini where somebody else might put
Mussolini ahead of Frank Sinatra is a
certain amount of inconsistency among
these things and basically the inter
list correlation among all of these
lists if you just took the people that
were on more than one list then you look
at these correlations the inter list
correlation of this was at 1.49 our
correlation with the list was higher
than that ok so in some sense our
rankings are in some sense central to
relative to all the rankings that we
publish and so I feel reasonably
justified in saying that our rankings
are I think more meaningful of what the
set of ensemble of them are trying to
capture than that themselves so with
presidents I mean if we take a look at
this will look for the president's lists
here correlation of you
then um then uh then then you know than
any of the individual measures did okay
yeah still substantially okay so in this
case you're right we are doing worse on
the president then we did on the uh you
know on the human rankings the president
rankings that we had we had reset five
sets of President rankings the agreement
among these was in fact higher than that
then the agreement uh not okay so that's
certainly true right
okay our goal is a simple model that we
have here that we can use across
multiple things to make you know some
kind of a sense about it okay and you
know as opposed to trying to optimize
any particular sport of endeavor you're
right in saying we did worse among the
president's then the presidential
historians but if you think about it
again if the presidential historian
polls are all very much an agreement
that means is basically one list okay
and it's basically us against that one
list okay and so the r you know so you
know any deviation we're going to be
wrong on okay so uh but anyway
nonetheless this is what we're doing
okay so what do i want to finish up
talking about it took up some time but
i'm gonna finish up talking right now
what can we do with it okay so in
principle here i've talked about it we
have a measure we like reasonably well
2-ranked people by a store has
historical significance how can we use
it for things and what we learn from
this so one thing we can do it is to
look at historical um friends in the
world that you know that it when you
when you mention them become obvious but
you have a hard time quantifying it so
what is that the trend that decline is
the decline of the great scientist okay
um everyone in this room knows people
who won the Nobel Prize in nineteen to
1900 in you know from 1900 to 1920 you
guys all know Einstein and Heisenberg
and all of these kinds of people um if I
asked you to name a Nobel Prize winner
from the last 20 years in the sciences
okay I don't think many of you here I
would be very surprised if any of you
could name more than two or three of
them okay there is a sense we have that
somehow as public figures scientists are
a less significant bunch less
recognizable bunch as historical names
and figures than they were before so how
can we quantify it so here we have a
graph where the x axis is the what you
call the are the year okay that they won
their prize the y axis is the you know
the measure of significance is you know
uh not the ranking but just measure of
significance and we show what is the
significance of these p
okay who won each class of Nobel Prize
and the physicists are more important
more prominent more significant than the
chemists in them and the medicine prize
winners okay historically and again I
think that would be borne out if you
looked at the roster of people who you
know about um in recent years since the
Nobel Prize in Economics came out that's
actually those people have a higher
profile then the um you know what you go
then this thin with physics then the
scientific winners okay um you see an
effect where the quality of all of these
prize winners goes down fairly quickly
after you an initialize the prize part
of that is a backlog because these
fields have you know backlogs of great
people who they can award the prize to
at the beginning that they have to use
up before they give it to newer
scientist but but even so you see a
decline here that you don't see among
the Peace Prize winners or their
literature prize winners these people
have retained the same level of stature
that they have historically had okay and
so there is something a different
scientists are not becoming public
figures the way that uh that that they
used to and the way that people in other
disciplines are that's one thing 15 then
look at the history of the papacy I
don't want to go into that here's
another Google Ngram spot at you guys to
guys like your hand grip but um a second
application we looked at was sort of the
question of who belongs in a history
textbook um you know you know history
that you know people who people hear
about historically are people in
textbooks okay you would expect that um
that you know who is in a textbook are
they the people who should be in
textbooks um my daughter is in fifth
grows in fifth grade when we started
doing this study um her history textbook
had 250 names referenced okay Nick in a
you know in a glossary of who you should
know about who you have to study for and
a typical assignment would be compared
the person to the what their description
one I was astonished at among the 250
people were figures like this who I'd
never heard of is there anyone in this
room who has heard of any of these five
people okay and yet they are deemed as
people that my fifth grade fifth grader
in some sense should study Oh
should know who they are these were the
people if you look on the left of the
most important significant people in her
textbook the people on the right were
the least significant people in her
textbook as you can see there is a wild
difference between I don't think again
there's a big difference in two people
on the left and the people on the right
so you can start to ask what is the
quality of the people in her textbook
and you start seeing a phenomenon like
this you know roughly half the figures
appear in the top twenty two thousand
most significant people in the world
history but you end up getting a tale of
35 people who are you know quite
insignificant quite a video syncretic
choices that really shouldn't be in a
fifth grade textbook okay and this kind
of provides a tool to try to analyze
these things you know we tried to figure
out why were these in there where they
state standards run them up and that
didn't ya US history class what
okay so what you ok so if what you're
saying is that you have to teach us
history and there's a thousand great us
figures you know I you know to 100 great
historical figures in the US and then
there's a hundred others you should
learn about who are wildly less
significant that's true but what we
would expect is that in a US history
book these there are plenty of
historical figures of interest you know
in this in this room I between where i
would say they are aware we would
welcome it conditioned on united states
what i will tell you is the straightness
of this line up here I don't really
believe that's the phenomenon you okay
again when we look at it it turns out
that there is a certain amount of
political correctness here that they had
a lot of them innocent figures that were
insignificant historically by our
measure a la raza de different minority
groups and things like that but we were
able to the remote offices please mute
their mics
um but we were able to identify for each
group people who were excluded who would
have been more worthy to include so if
we want to write a history textbook run
your people through our uh you know what
to it through our measure and you know
and again in each one of the groups that
were we thought they had a lot of bad
rep you know on representatives who
probably shouldn't be there in fact they
were other people who were more worthy
of inclusion solely would've done um in
fact this gets into what i think is an
interesting question it's a question of
how good or human selection processes
okay you know in principle when you're
writing a textbook or doing something
like this you're choosing who do you
want to put in canonize in your book or
something like this how good are people
at making these kind of decisions you
know you guys have to make hiring
decision to have a pool of applicants to
google okay and you want to select the
best ones how good a job do you do with
it I know this is something you guys
study a lot but it's I claim that the
stuff with that thinking in terms of
organizations that have tried to
canonize historical figures how well do
they do at doing identifying the right
ones provides a sort of a laboratory to
studied it so let me let me go through
this kind of idea quickly there is in
New York a Hall of Fame for great
Americans which starting in nineteen
hundred every five years tried to say
who were the greatest Americans to honor
and they would have a lectern and the
people on the Left were among the
hundred people they ended up selecting
as the greatest Americans of all time
and those are all great Americans the
people on the right were also selected
as among the hundred greatest Americans
of all time and I will believe that
probably no one in this room knows and
knows more than one of these people on
the list okay and Hall of Fame
selections are interesting it's not like
a dress problem where you don't know if
this person is going to do in the future
every person you're selecting in here
was dead 25 years before you picked them
they weren't going to go and do great
things afterwards okay somehow when
faced with the choice is up who can i
pick is the greatest Americans they came
up with the people on the
right and you know by studying these
things you can see that often they had
much better people to choose from okay
by our contemporary historical
significance okay decorated with this is
shown it and again we get a similar
phenomena that for two-thirds of their
choices they pick the best people or
very high quality people and but there
is a very long tail a third of the
people they're picking arson you know
there are thousands of people hundreds
to thousands of people below them that
that would have been better choices that
they chose to not to pick we see a
similar phenomenon when you look at
sports hall of fame's which try to
select things you have a people on the
left or very well-known baseball players
people on the writer people that most
baseball players and fans would never
apart of and a similar phenomena there
is a straight line here you know a
certain arm fraction ill seventy percent
sixty percent are clearly quality and
then the quality tapers off we think
this is sort of a more general phenomena
here that uh that that whenever you have
an expert panel try to fix things okay
that somehow there's some some noise in
measurement and the result the noise and
measurement doesn't really affect me who
are really the great at the tail you
have to be really blind and not think
George Washington is a great American
but when you start getting to the tail
you know a certain amount of noise that
you have ends up wildly affecting the
position of candidates and my sense is
the same thing happens there's only the
same processes here's happen with job
hiring and college admissions so if I
look around the room those of you who
are Google employees the same phenomena
holds one third of you don't belong here
there should be someone who be in the
poll who was much better than you okay
who could have been chosen but they
didn't okay if you extrapolate from
these kinds of things um you can look at
the question of how our women
represented in Wikipedia or should there
be more women historically in the
historical record or are they over are
the underrepresented are they over
represented how might we get a handle on
it um on one level you could do is first
order statistics say well you know fifty
percent of people are women fifteen
percent of the people in Wikipedia women
women
underrepresented but there might be an
argument that well perhaps they didn't
do the accomplishments that would would
have brought them note okay and that may
be the right fraction of women in
Wikipedia is right how might we get some
kind of a handle on on this kind of an
issue so my theory is the following um
we can look at this through the idea of
a significant trend we agree that
Wikipedia members are outliers in the
population you know the number of people
who are just outside of Wikipedia
quality is much larger than the people
that are in it so you certainly could
put more people in Wikipedia if you
wanted to UM the real question is are
many significant between Wikipedia more
significant than women if the men and
Wikipedia or more significant than the
women then that would be an argument
that you know in general the pool of
women isn't as strong okay on the other
of the women are more significant that
would mean that if you wanted to have
same standards of significance you could
admit more women to Wikipedia while
maintaining standards and if we
partition people into cohorts based on
their birthday year we find that
historically women have required far
more historical significance than men to
get into Wikipedia okay so if you plot
the x-axis is birth year the y axis is
significance the dashed line is women's
female significance the the dark line is
male significance for much of recorded
history women have required much more in
the way of significance the average
woman in this Wikipedia of a time is
much more significant than the average
man in Wikipedia and it if you do the
analogous computations equivalent like
they have to be four percent for I two
points smarter okay to be a woman in
Wikipedia than a man historically any
questions about that
final thing again um you know uh there's
a question of you know if you wanted to
become historically significant and you
had money how would you do it you know
uh Medici Lorenzo de Medici is famous as
a philanthropist much more than as a
ruler of Florence what would you do if
you want it to become you know convert
your money to faint how should you do it
one way to do it is to endow a prize
okay that uh certain people we know in
the world history or famous your Nobel
is famous for the Nobel Prize you know
the Fields Medal you know what yes
so you're saying that Nobel is basking
in the glory of is that a credit one of
your majors was dislike people to people
right right right right right does
Alfred Nobel pick up pagerank from the
page my guess is my sensors he certainly
does he certainly picks up glory from
the Nobel Prize winners it probably says
there's undoubtedly a link from somebody
Nobel Prize winner to the Nobel Prize
page and from the Nobel Prize page
there's probably a link there's a link
to Nobel so I have no doubt that he
picks up reflected glory from the people
who win his prize okay and so that a lot
of this recognizes what he's doing the
other possibility is to start at
university that if you have enough money
to endow a university and get a
university named after you that's a
great way to get a good historical fame
right and so I figure my university
Stony Brook would probably have its
names rights bought for about 1 billion
dollars so you're in a position to do
that okay so what are we doing again
what is our work now again we're
interested in trying to do this kind of
analysis in a cross-cultural way
Wikipedia is in you know 40 odd
languages or even more to what extent
can we remove some of the cultural
biases we have by doing our analysis in
other languages in other wikipedias and
this is something that we're starting
the work at we're interested in applying
this you know working with sociologists
to apply this in a variety of different
ways to study gender bias and cumulative
advantage we're interested in again more
stuff with the Google n-grams we analyze
the engrams a lot we're interested in
doing things like assembly and and
sentiment analysis on these end grams
okay and this is something we're
interested in we'd like to extend this
idea of ranking people in places and
things beyond Wikipedia but to all the
people on the web okay you know again
I'm not in Wikipedia at this moment I
don't have any significance according to
our measure could we figure out what my
significance is by doing some kind of a
web parole and web analysis there and
that's something we're interested in and
finally we're interested in taking this
analysis and writing a book on it and so
we've been trying to look at to what can
we learn about world history through
these kinds of analysis
and that's my other project and that's
basically all I wanted to say oh so we
have some resources if you want we have
a web page who is bigger com if you want
to play with some of our rankings the
decayed significance isn't on here yet
but I encourage you to go take a look
and play with it we also have an app if
you enjoyed playing the who's bigger
game at the beginning you can go to look
up our app and play with this thing and
finally I'd like to thank the people I
work with work me on this again the
people who matter most here would be
Charles Ward he's my postdoc and he's
going to be coming to work here in a few
months and I'm Gautham here is the one
that were did our work with our end
grams okay and help prepare the end
grams data which you can see from the
who's bigger site as well and that's
where I think I'd like to leave it yes
yeah right
okay so so the question okay so you're
saying that happen we're based on
Wikipedia how good or bad is Wikipedia
is I guess implicitly what you're
questioning and and to me as i've done
this i have become more and more
impressed with how good wikipedia is you
know there are certain things that
wikipedia would get right that it
doesn't seem obvious that it would get
right like for example the matching
between the frequency of people that
it's talked about in world population
going back hundreds of years okay that's
a sign that somehow you know it is that
that's something it shouldn't happen you
know if wikipedia is really being
produced you know uh in an event you
know in a random way yeah yeah
the record yeah the people there are
people that are represented historical
record you know Cece percent of them are
the right people and then another third
of the part are significant okay so so
let's say so one thing you might be
saying is maybe it's the tail of the
distribution okay so what do I say here
we have 800,000 people in Wikipedia you
haven't seen a significant rank flashed
up higher than 400,000 which means that
there is you know among any person we
had third thought of or heard of or
anything like that these people are all
falling on the second half of the
distribution to me that tells me that
that I think we eat media has the
significant people we have not found
anyone in the course of our studies that
lets say we felt was missing from
Wikipedia okay that's I guess sort of my
answer to what you're saying I don't
know if that's quite what you want it so
I don't think that people here are being
missed um you might say that the
measures that are being you know the
aesthetic here is not the right
aesthetic that what Wikipedia values may
not be sort of what is historically
significant but the people that come up
at the top of the lists are the people
that I think should come up at the top
of the list they correlate well to what
you see in these published rankings and
so my sense is that there's some meaning
you yeah
is it just great dead white males so I
mean they're you know let's think how to
say this thing um so when we looked at
for example arm you know in the history
books really the fifth grade history
book you know that um nine of the top
100 figures by historical significance
in uh what you call it um my daughter's
textbook were black okay so it's not all
white males at tops you know there is a
sizable cohort of figures who you know
are not white who do fall into the you
know reach prominence in Wikipedia by
our measure now obviously there are
cultural biases here you know certainly
when terms of international figures you
would not expect them to be as well
represented in um you know in an English
Wikipedia than others here
so it so it is certainly true that um
that the different parts of the world
would have different penetration that
would be true um this one reason why
we'd like to try the nose looking at
wikipedias from different languages as
presumably you know if you look at an
African language I suspect that the
Wikipedia you know access there is more
probably from from those countries than
elsewhere so there are probably but
there are our biases there but obviously
the you know most of what we're
interested in is the Anglo you know
angle speaking world and I think these
are pretty well represented here
anything else yeah
so we have we have look thanks to google
and they're scanning things we have
looked at the indices of historical text
books from going back nineteen hundred
or so the whole notion of a history
textbook is not a relatively recent
invention okay it goes back to know
nineteen hundred or so and you know we
did we didn't conclude anything
particularly interesting when we looked
at this so the answer is have we thought
about you know how much of this is
revered you know and our older history
books possibly an interesting way to
look at it the answer is yes we haven't
made it found anything particularly
revealing there no nothing worth
mentioning that's my fear okay okay
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>