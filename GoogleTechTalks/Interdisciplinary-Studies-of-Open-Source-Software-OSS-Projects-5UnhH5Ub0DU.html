<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Interdisciplinary Studies of Open Source Software (OSS) Projects | Coder Coacher - Coaching Coders</title><meta content="Interdisciplinary Studies of Open Source Software (OSS) Projects - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Interdisciplinary Studies of Open Source Software (OSS) Projects</b></h2><h5 class="post__date">2008-02-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5UnhH5Ub0DU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">our speaker today is praying the bumble
prims a professor of computer science at
UC Davis he got his PhD from Rutgers in
1994 worked at bell labs for 18 years
and has been with UC Davis for 10 last
10 years thank you for inviting me to
speak here bored at work so this is a
project we have going on at UC Davis on
open source software development of open
source software studying various aspects
of it it's funded by the National
Science Foundation the science of design
grant there's one of the fun things
about this project is that it's a very
multidisciplinary project there's people
from computer science inaudibly my
colleague Vladimir Phil cough who's a by
implementation whole lot of students
this particular work I'm going to be
talked about mostly is the work of two
students Zacks all who's here and Chris
Berg was a who's not here so it's mostly
their work the team also includes people
from the school of business because one
of the things we're interested in is to
understand how social organizational
structure and open source projects play
out and how that interacts with with the
software design structure so a couple of
people from the school of business we
also have a couple of physicists a swim
and raw and bloody and rice at this
house who are interested in the physics
of large networks okay so um so just to
quickly summarize the kind of problems
were interested in large software system
fair projects are always of great
interest to software engineers in sa of
teams of large teams of people building
these really complicated artifacts and
shown here is some kind of complicated
graph with many different types of nodes
and dependency edges and you know these
border users and the users are generally
not happy because there are lots of bugs
and you know and and it's everybody
hates and there's lots of problems that
come along with large software systems
instantly when I gave this talk first in
Switzerland my audience told me that I
got the ethnicities of the developers
and the
users reversed so but but so there's
lots of problem so you know one one
aspect of the problem is the size and
the complexity of software systems and
the need for constant change another
problem is is what what we call
discovery which is that the systems are
so complex and so many dependencies
involved in there that it's hard for
people to even learn about how it how
it's built in and it and to work with it
you know people immediately make
mistakes introduce lots of bugs and the
users get unhappy so in a software
engineers have been wanting to study
this for a long time but it's been
difficult mainly because we near the
University in academic environment it's
hard to get data to study what are the
factors that actually drive this and and
and create the real problems so maybe
you could try to improve upon them so
open source projects are like a you know
special in this sense they have all the
problems that you see in traditional
traditional closed source projects you
know so you have for example a lot of
communication and coordination going on
an open source projects which is which
is affected by the distributed aspect of
it and a lot of this lot of this data is
actually available you can see how
people talk to each other how they work
with each other and so on in this sense
the the interesting thing is that the
design of the system itself can help our
hinder with the way people and teams
work with each other so if you have a
system that's well organized maybe that
you can you're better able to divide it
among teams and have the team's work
with each other better and have less
need for coordination activities so
design can be either a hindrance or a
help so there's this thing called
Conway's law due to to tool in conway
which says that essentially that
artifact structure and organization
structure can emit at each other over
time so this is actually the core of our
project or scientific project which is
to study the relationship between design
and social structure another thing
that's interesting is that in every
software project one of the key aspects
is bringing new people in and bring them
the speed so invariably this takes a lot
of time and new people you know
invariably like slow everybody else down
so this this is a kind of also dealt
with in Brooks's law this were some of
you might have heard this book called
the mythical man month and Brooks law
basically says that adding new people to
a software project that's already late
makes it even later right so I knew
people as a crucial issue and something
that's really worthy of study and this
is one of the things first things we did
was to study how new people joined open
source projects and for open source
projects there's another aspect to it
which is that if you don't attract new
people eventually going to die and also
they also for many developers being
accepted as a committed into an open
source project is a real kind of badge
of honor right so a lot of people want
to become say an Apache developer or get
come with privileges into certain
aspects of Linux and if so understanding
this process how this works is really
really kind of interesting in the
apartment so this is something else that
one can study in open source project the
other thing that's interesting is the
effect of tenure so this is well known
in traditional organizations and has
been studied by organizational behaviour
is that people who stick around in one
job for a long time within an
organization invariably not only become
less productive themselves they also get
in other people's way and hinder other
people from becoming productive because
you're sort of like interested in
getting some kind of recognition for
what they've already done so they you
know they might resist change in
renovation so this is something else
that one can study in open source
projects and they actually have a
proposal out to the NSF to study the
effect of tenure and open source
projects okay so the thing about open
source projects is that there's a lot of
the data is available they know so they
are complicated they're just as
complicated as closed source projects
but all the activities that people have
performed this is already archived and
you can go off and mine it and study it
there's lots there's lots of large
distributed teams but the cool thing is
that community norms and open-source
projects require that all the all the
communication takes place on these
archive media like email list right so
it's all archived and can go off and
study how people
these mailing lists and that allows you
a kind of you know historical gives you
kind of historical record that's just
simply not available in a traditional
environment where somebody can just go a
next door and talk to their colleague
but in open source all this is his
comprehensive and it's archived lots of
buds bugzilla has lots of information
and that also is quite useful to figure
out the aspects of history that make
might indicate the presence of bugs or
predict the presence of bugs or predict
which bugs take a long time to fix and
so on so all this can also be studied so
open source essentially I mean that you
know the way I like to describe it is
that open sources put software
engineering whereby informatics was like
10-15 years ago right so all of a sudden
we have this you know like by
informatics really came to life when
people internet with gene sequencers and
F lomatic ships you know and give which
gave you a lot of this data so now
software engineering is now in the same
board we have like tons of data and it's
sort of embarrassing to me as a software
engineer that we're just starting to
learn how to deal with this massive
volume of data how to analyze it how to
analyze large dimensional sparse
time-series matrices and learn something
useful from it we're just sort of
starting to learn how to do it so we do
a bunch of different things but I'll
basically talk about probably mostly
about one thing but I might get to the
second topic as well one of the things
are interested in is developing software
engineering tools to help programmers
deal with the problems of large software
systems like complexity and scale the
nice thing is once we tell up the tools
we can use open source software itself
as a way of evaluating the performance
of the tool we show you an example of a
tool be built and how we evaluated it so
this the Toro taco board is a
recommender system called Fran the
second thing that's interesting is to
study how social activity technical
activity and and design structure all
interact with each other using open
source mailing list archives and CVS
archives as the means of studying what
people do and how they talk about it so
we've done a bunch of studies along
these lines the thing I'll talk about if
I have time to get to that is is
immigration how people go from being
mailing as participants to actually
becoming committers in an open source
project and what factors drive this one
of the interesting things we looked at
recently in this
study of mailing list activity is we
looked at how often function names file
names method names exception names are
mentioned in the email and how often
they've mentioned in commits so in other
words half and their function names and
so on I used in code that gets added and
how often it's actually mentioned the
email discussions so you know we were
careful not to filter our patches and
things like that from the mailing list
we really only looked at when they
actually talked about and this is many
peculiar things we found I mean it's
very new work so I don't have any slides
and I but we found that cumulatively the
relative frequency of mentions and
emails and the mentions and source code
is incredibly strongly correlated but
periodically in terms of monthly that's
not we don't really quite understand why
but we have some you know this is kinda
interesting phenomena that one observes
and you know that we want to study okay
alright the part 1 the first thing I
wanna talk about is is Fran alright so
Fran is a recommender system explain
what that is and why we need something
like that alright so let's suppose that
we have a new developer Daria who's
writing multi-threaded cord for apache
and and she is interested in using multi
whoops sorry
she's interested in allocating a shared
memory pool to shared between threads so
she allocates this memory pool and and
then when she's done with the weather
thread she fucks her throat and she she
she runs some cord in the thread and
when she finishes the thread she calls
this method APR it Fred exit to exhibit
late now this APR under bad if any
people looked at Apache cord is the
Apache portability runtime it's a
collection of about 300 odd functions in
about 30 modules that implement various
portability functions and makes it easy
to port Apache from one operating system
to another so APR has several different
sub modules and this one is the thread
module then she calls the APR thread
exit function to exit from the thread so
fine now when she does this she gets a
crash right and and you know such
clashes are you know arising here
because of a PR thread exit behind the
scenes d allocates memory pool so that's
why that's why this is some crash
because the memory pool Guardi allocated
got used in some other thread for some
other purpose data gets corrupted and
she gets a crash okay so such crashes
are now going to be like fairly random
they're going to occur at random
intervals because they depend on the
thread thread overlapping the thread
interleaving in order for in order to
trigger a particular defect right so
these are like really hard to reproduce
in debug okay now if Daria had a
recommender system right what she would
do is she would say I'm going to call
this function and ask for
recommendations all right now this could
be built into a development environment
or it could be a tool that you know she
uses offline but in any case you know it
might might for example one possible
embodiment is as soon as she types in a
PR trail exit into a record I'll pops up
a list of relevant functions let's see
my other functions that she might be
interested in so if you give a PR thread
exit to Fran as a query it returns these
functions ok these are relevant
functions very close to you relevant to
APR 3rd exit that are returned by this
recommender system friend ok so once
once once Daria sees these functions she
can then be prompted to go off and look
at these other function
then she'll quickly realize that a side
effect of a PR thread exit is that it
will call flushing of any pool that was
allocated so so by knowing this they're
not dahlia dahlia can essentially avoid
this kind of avoid this kind of coating
which might much my leader do introduce
a bug that's very very hard to debug
okay so that's the goal of friend given
a function find related function it's
very very simple goal okay and so this
is an active area of research right now
there's a there's those recently the
second workshop on recommender systems I
just have to did a couple of weeks ago
and there's a almost in every 6 e or f
SE starfish in conferences there are
some papers and recommender systems you
know Netflix prizes given a big boost to
the whole area of recommender systems so
this is this is this is essentially the
same same kind of problem finding
relevant functions okay all right so
assuming the problem is clear I'll press
on okay so return given a function
return a set of functions
okay okay and so that's the that's the
problem and now there's lots of
different ways the recommender systems
can work one of the ways the recommender
systems can work is to use version
d'accord so they can look at like 100
versions of the code and say whenever
somebody added a function call to this
function they also added a function call
to the other function that's one way in
which recommender systems have been
built to work so we're started giving us
a harder problem we're saying we use
only 1x one version of the core don't
use multiple versions so so what does
friend Fran do so friend essentially
kind of works by by sort of imitating
the behavior of a programmer right so a
programmer when they're looking at a
function and trying to find 11 code they
might look at the body of the function
that implements the function that
interested in using so they might look
at the body and say what are the
functions does this one call or then I'd
look and see what are the functions
called the function i'm interested in
using and what functions do those
functions call so sort of a neighborhood
given a function there are other
functions that call this function and
the ones that are called by the ones
that call this and likewise you take the
ones this one calls other ones that call
this so there's a whole neighborhood of
functions right so essentially
programmers would explore this
neighborhood looking for related
functions so in a sense Fran is doing
the same sort of thing right so there's
some kind of random walk of that
neighborhood and returns the functions
of the highest probability of being
visited ok and it works actually really
well it's a very very simple algorithm
but it seems to work extremely well and
we'll show you how we evaluated it okay
so step 1 select a neighborhood of the
query function so this is how we select
the neighborhood so so assume that this
is the query function we assume a single
query function that that you're
interested in right these are the
functions called by this query function
and these are the other functions that
call the functions called by the query
function so these are called spouses so
for example if this is some APR thread
exit what are other functions that call
a PR thread exit and those are all those
are called the spouses likewise you also
look at the pen and seal the functions
that call the query function you look at
other functions called by the parent
function so this is your complete
neighborhood ok so this is the
neighborhood be used
okay now what we do is interact the
functions in the neighborhood sometimes
these neighborhoods can get quite big we
sort of you know we sort of in some
somewhere like in the 300 range we sort
of cut it off but taking it very big
right so we sort of prune the
neighborhood beyond a certain size and
then we rank them okay and usually we
return the top five or top 10 or top 15
functions based on the ranking okay so
how does the ranking work so Fran uses
two concepts called source nests and
target nests so sources are functions in
the neighborhood that call a lot of
functions in the neighborhood so what
we're trying to do is define functions
in the neighborhood that are more
specific and most like the function
we're looking at ok so we say ok then I
functions that are in the neighborhood
functions are not in the neighborhood
right so we'll take the functions and
see what are the functions called by a
lot of functions in the neighborhood
right these functions are source like
and likewise is a notion of target may
switch it functions in the neighborhood
that are called by a lot of the
functions in the neighborhood so this
notion of soreness and target miss and
sort of the mutually recursive
definition ok so and what we what we
claim is at target pneus which had
functions that are called by a lot of
functions in the neighborhood it
determines how relevant a function is so
what we can essentially do then is
define source and target miss vectors so
these are vectors are the same dimension
as the neighborhood so every every point
every every function on the neighborhood
is a source miss score in a target and
score ok and so we have these sources
and target miss vectors S&amp;amp;T ok when we
start with an initial source score
vector s0 ok and we have the
connectivity matrix for the neighborhood
a ok so so the transpose of the
connectivity matrix is a transpose ok so
now what you do is you take the source
nuh score ok and from the source the
applied that transports of the of the
connectivity matrix this tells you
essentially if you apply this it
essentially tells you how likely I have
to get to a particular target based on
the source ok so this gives you the
target nuh scores based on the
connectivity of the call graph on the
source nuh scores so if you call from
more sources then that particular
entry in the target inspector will be
higher because you learn more ways of
getting to the target is vector from
from the from from this from this matrix
so that the matrix is more nonzero
entries in the columns then the
corresponding target my score for that
entry will be higher right so
essentially reinforces target miss based
on source and then you have a the next
step which is the dual of it so likewise
you take the target in the scores and
you multiply it by the connectivity
matrix and likewise if something is
called from many sources then that
source will have higher target higher
source nuh score right so then you can
simplify it and get this kind of
iteration ok so once you've got this
then you get the convergence property
from from from Kleinberg so essentially
SNT I a Markov chains and probabilities
built from a a transpose a and a
transpose and so the lovely decline
burger is that TI converges to the
principal eigenvector of a transpose a
ok an escomm vs to the principal
eigenvector of a transpose ok and the
paper is in Siam soda 1980 so this was
essentially actually one of the ideas of
how to do page ranks which came but
before for the famous pagerank paper so
this another one of the earlier
formulations of using links to calculate
rank so here in Sioux blinks of course
using the call graph similar idea okay
so you can struct the neighborhood of
the call graph for the neighbor graph of
the query function you construct the
edge incidence matrix a transpose in a
and you find the principal eigenvector
the largest value is the eigenvector
given the most gives you the most
relevant function ok so give it a query
function you construct the neighborhood
of the query function you construct
these matrices any compute the largest i
compute the principal eigenvector of a
transpose a and that gives you the
scores ok at 11 scores ok so the
question is you know so there's been a
bunch of other ways to go recommender
systems before this this this work was
done so the question is whether this
actually does better than then existing
existing existing work ok
alright so that the two previous
approaches that that happen that used
that used call graphs to compute
relevant scores one is based on data
mining association remaining essentially
another was a system called Swain okay
so data mining so data mining
essentially is a frequent itemset mining
so that says that if if two functions
are called together more often then the
two functions are more related right so
if two functions F and G are frequently
called together then F and G are very
closely related each other and so that's
it's basically that idea so what you do
essentially is given a query function
find all the functions from which it is
called so what are all the functions
that call the query function and find
other functions their Co called in those
functions along with F right and then
you return them using the most
frequently co called first right so the
F and G are called with each other 10 x
and f an HR only co called 9 x then f g
will be higher rank to that age right so
there's a bunch of papers that use this
approach one was in Dixie 2000 the other
was in the software repository mining
workshop a couple of years ago and so
this is one thing that we compared our
work with the other the other algorithm
that does this sort of thing is called
suede so suede essentially uses any kind
of relationship and any kind of entity
to find relevant functions and it uses
two properties called specificity and
reinforcement which is actually very
closely related targets and sources as
you'll see in a second so essentially
suede works with a set of query
functions a set of functions used as a
query in a relationship so suede says
that given a query functions that relate
to few other functions besides the
functions of the query are specific
right and functions relate to more
functions in this queries that are more
reinforced right so if you have a set of
four functions you look at those
functions that related to as many of the
four as possible and then related to
very few others besides the four that
you've used in the query set right so
there's a function that is called by the
four functions in the query
set and not really called from anywhere
else that's very specific because it's
only called from punctures in the query
set and it's highly reinforced because
it's called from all the functions in
the query set so they look for both
these properties specifically in
reinforcements okay and it returns the
one that are more specific and most
reinforced ok so it's since the waste
way it works is similar to considering a
smaller neighborhood where then then
then what then what Fran does and it
doesn't do any kind of any kind of
iteration so the ranking in suede is not
as good as a ranking that we do a pencil
is a smaller neighborhood and it doesn't
rank them as well as we do ok so we did
a comparison of these these two things
with our approach now one of the sort of
key controversies in recommender systems
is how do you evaluate them right so
given a recommender system that finds
related functions how do you evaluate
them so so let me I can sort of like
quickly review some of the different
things that people have done with the
recommender systems so for example one
thing is recommend somebody who'll fix
this bug right so given a bug recommend
somebody who'll fix this bug and the
ways people have done it is by
essentially am using historical data
right so what they do is they'll train
the system based on the history of bug
fixes in bugzilla and told you know say
2005 and then they'll take a clean new
bug that the next book that comes along
saying 2006 and say I'll take the same
algorithm and recommend who's going to
fix this bug and look in the history of
this bug later on and see whether the
people who actually would recommend it
as fixers for this bug we're the ones
that actually did fix the bug so the use
is the way of evaluating it this can be
done kind of you know more or less
quantitative automated fashion and you
can have rigorous statistical
evaluations in this way and another kind
of evaluation another kind of thing is
like um you know what we're doing for
instance is i'm working on a function
which other function is most relevant to
it or which document is the most
relevant to it okay in such situations
there is a complication which is that
what is relevant depends on the task
that the human is doing right so really
the only way to ultimately evaluate with
the recommender system is doing the
right thing is to take a human and ask
them do this task now here's my
recommendation for this task do you like
this answer or not the humans is yes and
it's relevant if they say no it's not
okay so for this kind of particular
recommended task in some sense to
evaluate systems and to compare them you
really have to have a human study
subhuman subjects study we didn't want
to do that so we chose kind of a we
defined a particular kind of task for a
recommender system which we could
evaluate the quantitative em we did that
right so I'll tell me the task that we
chose to evaluate it on and evaluated so
we essentially wanted to judge which of
the three algorithms was better right so
imagine doing this is a human study
right you have to essentially have
several different you have to
combinatorial study various several
different control groups which are
matched with each other in skills &amp;amp;
expertise and you're like sort of give
them similar tasks and and have them
compare the value of the recommender
systems it's very hard to do comparative
studies with with human subjects so
that's one thing you want to do whether
the algorithm is better and one of these
algorithms actually better than random
guessing right so we want to do that to
the other thing we'd like to do is
although in our results on this I think
our tentative we'd like to know is it
possible to predict one one particular
algorithm is going to do better than the
other and a particular task and if you
could tell when one algorithm is going
to do better then you can take the
different algorithms and decide which
one to use and use that one for
different settings right so if you know
that under these conditions this
recommender system is going to do a
better job then you first look at the
problem that for which you want a
recommendation and say okay you know for
recommending horror movies you know this
algorithm is better something to use
this one right so you could do that but
but you know so we did that in this case
and we got some interesting results but
you know probably want to take it with
it with a pinch of salt okay so all
these things are kind of really hard to
do with human subjects studies it just
gets very expensive and complicated and
there's lots of threats to the validity
of any experiment that you do because
the variability in human subjects so it
is very expensive and difficult we
didn't do that
so what we did was we did we defined a
particular notion of relevance right
particular notion of relevance which she
could automatically have you know kind
of an Oracle for and we evaluated the
recommended tools based on this Oracle
so we use the Apache portability layer
for finding relevant functions so we
needed a set of answers that will tell
you given a query what's the right
answer right so we this what we did ok
so the Apache portability later has 330
functions the functions are grouped into
32 modules the problem we set was okay
we're going to take each module and use
each function in the module as a query
given the function of the module the
recommender system should return other
functions in the same audio so that's a
task we sell ok now is this a relevant
task for the recommender system in the
case of a vicino because the document
already tells you what the functions in
the modules are right but remember we're
not using the documentation we're just
using the car graph right so essentially
what we're doing is we're using the call
graph to reconstruct the modules right
in some sense you know this old problem
that a lot of people are dealing with a
long time ago of taking C programs and
converting them into alternative
programs they would like try to find
objects and C programs is like a
classical challenge in reverse
engineering is to find objects and in
functional programs so kind of we're
doing that right so we're essentially
saying can we just use the call graph a
single snapshot at the call graph to
find modules okay without using any
other information ok so this is the task
we set for ourselves ok so it's a
realistic task we have an automated
Oracle that tells you what the right
answers and and not the wrong answers
are and we have a non-trivial sample
size you know this 330 questions we can
run so we can get some good statistical
data on whether we're doing better than
than other other other tools ok the
problem is said it's very very specific
task right it doesn't it doesn't really
address the vast range of things a
programmer might want to do for which
they might want to have some
recommendations so it doesn't really
address a large a large set that is a
very very specific problem and you know
maybe it's a bit over demanding so we
were criticized for this because
essentially there are problems hitting
allows you to give one single query
function and find related functions and
some of the other tools that were
comparing against don't really work all
that well with one single query function
you know basically the response to that
is we expect that our performance will
improve if you have more than one query
function right so you have to do that
experiment but right so that's another
possible criticism of the way we do the
evaluation ok so the evaluation question
stated here is null hypothesis is that
is that that you know that that the
tools don't do it given a tool it
doesn't know any better than random
guessing that is you know you take the
set of functions they picked them at
random and the tool does know any better
than that right the second hypothesis is
that the answers we give in terms of
precision and recall you know are no
better than in the other tools right so
essentially these are the hypothesis you
want to reject that is that our toll
actually is doing better than random
guessing and art will actually best
perform better than the existing tools
and in fact we do yes we do reject them
a precision recall so recall is you know
supposing you have a set of possible
answers some of them are correct but
some of the some of the functions that
actually rather than how many of the
correct ones you get and position is how
many the ones you get are actually
correct so they're sort of duels of each
other and the f1 score is a harmonic
mean a precision recall it is you take
the product and divided by the sum twice
the product / the Sun
okay so um so the first null hypothesis
is that the top k ranked for query
function is no better than random
guessing okay and so now when you say
random guessing you have to have some
kind of combinatorial model of water
random guesses right so it's a very very
simple model right so the idea is you
basically have you know you have you
have your whole set of answers and some
of them are right right and you want to
see how many of them you would get if
you were guessing at random so the way
we think about it is let's suppose you
have a box with you know a thousand
marbles and let's say some portion of
them 50 of them are black right the rest
of them are white right in the black
ones are the right answers right and you
go in there any pic 10 of them five of
them 10 of them 15 of them right so if
you choose five ounces of random what is
the likelihood that you'll get all five
black balls right if you pick you know
if you pick from an urn that is a
thousand white balls in 50 black balls
we pick five at random what is it chance
to get all the right ones pretty low
right so if you consistently keep trying
and you consistently keep getting all
black ones then you're doing much better
than that i'm guessing right likewise
with 10 and 15 right so this is a pretty
simple combinatorial model you know it's
just it's called the hypergeometric
distribution it's just basically one see
something / see something time see
something if you work it out it's really
very simple so that's basically the
random model what you want to get so if
you're really doing random guessing then
you pick a certain 15 let's say you take
15 balls out of this the distribution of
these of the black balls order the 15
will follow a certain kind of symmetric
distribution and you know basically if
you if you have your proportion of black
balls is k % or certain RK person that
sits x percent then if you pick 15 then
the mean and the more they're going to
be around 15 times X right you're going
to get that many that many black balls
roughly if you pick a random right
because you picking them you know
without knowing what's what's in there
and if you get all black balls it's
going to be chances are you're doing
something very good right so that's
basically the random model so
essentially for each value of K that is
picking five answers 10 answers between
answers Iran all 330 queries
right and what you do is the number of
times a tool gives you an answer that is
less than less than one chance in 20
ever cutting at random right so if you
get all all answers are right it's very
very low on so if you get three or four
right answers you know it's probably
pretty hot unlikely but may not be that
unlikely so what we're doing is we're
only considering answers that would be
likely to be able been obtained less
than five percent of the time by ramen
chances so we're rejecting anything
below the point 05 level above the point
05 level okay and we correct from
multiple hypothesis testing so
essentially what that means is if you
buy 330 lottery tickets you're a pretty
good chance of winning at least one
right so there's there's a just purely
out of random chance you might get at
least some right so if you're doing 330
experiments repeatedly with the same
data some of them might turn out to be
right just by random right so you want
to correct for that what that means is
that you say since I'm doing so many
tests the p-value I get should actually
be higher because of a greater chance of
getting a right answer by purely random
chance right so you are just the
p-values upwards because you're doing so
many tests so that reduces the number of
cases where you're giving yourself
credit for finding an answer that is
better than random guessing okay so this
is the answers this is the results we
get so what this tells you is the number
of times each algorithm gave you an
answer or the number of right answers
was less than five percent likely to
have been a pain by chance by pure
chance so in this many cases with top
five answers Fran gave 406 answers where
the number of right answers was unlikely
to have occurred by pure random chance
more than five percent of the time right
so so this tells you that Fran was able
to give you right answers these many
times frag give you that answers these
many times and suede give the right
answers these many times so clearly you
know we're doing better than random
guessing a large portion of the time
right and there and we're doing better
than the than the other algorithms okay
so this essentially is answering the
first question are we doing better than
men
and it appears that friend is most of
the time doing better than men i'm
guessing okay now the next question is
this friend do better than the other
algorithms all right so the way we
compared that is by using f1 scores so
f1 scored essentially essentially does
the cock the harmonic mean of precision
and recall and it and basically it gives
you a penalty for doing bad on either
right see if you're bad on recall or bad
and position it penalizes you downwards
to it's always worse than your precision
score audio recalled score now why is
that well the reason is right you can
always get your position up really high
by dropping your recall and vice versa
right right because you can just so go
off and get more answers right then you
recall will go up with your position
will drop right are you get hardly any
answers the position might go
opportunity call will go down right so
what you really want to do is to not
give too much credit for either want to
penalize them for doing badly on either
right so this is that this is computed
in a way to penalize the algorithms for
for considering both there are some
criticisms of this approach but this is
a reasonable way to compare different
different algorithms okay so what does
graph is the the red the red process of
Fran and the yellows sorry the blue
squares are swayed and the graph is
divided with three parts ok so by
essentially this is a win for us the
cases where Fran does better than suede
this is a loose for us the case where
suede this better than friends so we
don't do as well as suede does and these
are the cases where we're tied ok so as
you can see in most of the cases
friendly its way ok the answer that you
know that don't get to put off by this
it's just kind of like arranged dances
or anything on order to give you this
kind of shape there just just to make it
easier to read the graph so you can see
that your most of time Fran beats Wade
ok and sometimes sometimes slate beats
friend but in the cases where we beat
where we beat suede you'll see that
suede actually gives you a zero value
for the f1 score many times
it's almost like it's all bottoms out
essentially whereas the cases where they
beat us we're sort of not quite zero
we're not fairly close to them right and
then in some cases where they both kind
of don't do very well all right so now
the this is kind of eyeballing it you
can do a statistical test so what'd you
do essentially is a statistical test
that says that the valleys of f1 scores
obtained from Fran are statistically
significantly higher than the valleys of
fun scores are playing from suede and
this is a simple kind of t-test and you
know it's actually a matched t-test
because it's in the same queries you can
compare the two I don't know that's what
we did we do the match t-test order the
simple t-test we did the nonparametric
version of the t-test right so so yeah
so essentially you know we can reject
the null hypothesis that were not better
than suede so in fact we are better than
suede okay so this is comparing Fran
with the data mining approach and the
story is similar although we don't do as
much you know in the case where we do
better than better than fryer is not as
as as big a region we do beat fryer and
more times than fried beet sauce but
we're not as as much better than far as
we are then then suede and we matched in
some of the cases again here also we can
reject a null hypothesis that Fran is
not better than suede so friend is
better than suede even in this case it's
similar question ok so we can now this
this does raise an interesting question
since fryer does better than us in so
many cases can we figure out exactly
when fryer that's better right if
there's a simple way of describing when
fryer that's better then we can use
fryer in those cases when it's going to
beat us and then we have a combination
algorithm that actually beats both that
is better than both so we did that so
this graph essentially plots the
advantage of of our approach over fryer
when does our approach do better than
fire and what we discovered was the
initial the initial kind of neighborhood
size in the initial neighborhood is
large then fryer that's better then
asian level is smaller than we do better
and friend us better all right so this
isn't she tells you that if you
construct the neighborhood and he the
large neighborhood at the beginning then
we're not going to do as well as fire so
this case is sort of a simple way of
selecting which algorithm you do is use
you construct the neighborhood the
neighborhood is large you pick fryer the
neighborhood is small a big fan so sort
of tells you a simple way to choose
between the two approaches so and so
that's what we did and and then we have
a combined performance figure of the
different algorithms the car be
algorithm algorithm and top is combat
combining Fran and friars using this
idea of you know picking one when we
know it's going to do better right so
that gives you better performance in any
of the above any of the others now this
is this should be taken to the pinch of
salt because this might be over fitting
right so we have a particular is a valid
in a particular application which is
Apache for a particular problem which is
recommending blended functions in the
same module so it's not clear that this
is going to generalize but we did find
that at least in this case we could
combine the different functions and get
better performance so we have 10 more
minutes ok I think I won't have time to
go through the second part of the talk
but i'll try to go through it kind of
fast so so so this kind of fun project
because essentially you know do some
very very old ideas from your algebra to
do this and we did quantitative
evaluation of this approach whoops ok
all right immigration now let me just
see what I want to say about this um so
I might have to stop kind of halfway
through the stock but i'll just talk a
little bit about it so essentially
immigration open source project that
basically the act of immigration is do
you go from being a mere emailing as
participant to being having commit
privileges so essentially what we're
doing it is to studying what factors
influence when somebody makes a
transition from being an email
participant to being a committed so so
it has a lot of uses you know it can
help OSS project leaders attract new
immigrants identify those
people are more likely to be productive
committees and then bring them in it can
also have people who want to become say
for example in apache developer or
Mozilla developer help them give them
ideas and what kinds of behaviors what
kinds of actions will help them gain
admission into being committed heard it
meant also be useful to companies that
are interested in supporting open source
projects so you know if you're here open
source project supporter you might want
to know which projects are vibrant which
projects should be you know you should
you should you should try to support and
how to get your people to influence the
direction of the open source project by
becoming committers and so on so this
could be quite interesting for a lot of
people for a lot of different reasons so
the way this is studied I might have to
stop with a quick comment on this and
I'm happy to tell you more and I there's
a paper on the city in just a minute
this is done using a statistical
modeling approach called hazard rate
analysis so what hazard analysis does is
it essentially studies the rates of
transition as a function of different
predictors so a classic use of this is
cancer survival right so your people
have cancer anyone know when they're
going to die right and what you do is
you sort of fit in different predictors
into the model like you know like where
their smoker or not whether male or
female the heart disease another kind of
classic use of this is a recidivism
right so you release you know you
release a young white female from prison
and you want to know how likely is it
that she's going to end up back in there
in six months or a year or so whatever
so various factors like age and previous
history of drug use and so many factors
that predict when the person is going to
end up back in prison so it considers
the rate of transition from being in our
case from being an email poster to the
UN Committee so i think i'll leave you
with basically this graph which is kind
of typical of all the open source
projects we studied the x-axis is not
calendar time it's time since your first
email right so number of years since
your first email all right so this
particular graph is for postgres but all
of them look look fairly similar the
y-axis is the rate of conversion rate is
very very small right so usually only
about 1% of 2% of developers in a given
period will convert from being an email
participant to to being a delivered
right so all the hazard
models essentially work on a population
that's at risk and the subpopulation
that makes a transition right so given
given for example present recidivism the
proper nation at risk is the number of
people that have been released from
prison right and the x-axis is going to
be the number of years since they were
released from prison and the y-axis is
the proportion of the population at risk
that actually exhibits the recidivism
behavior right so what we're seeing here
essentially and I'll essentially have to
stop with this is a non-monotonic rate
of immigration right so the rate of the
mechanician initially is quite low right
number of people are converted from
being email participants to being
developers is quite low it goes up
rapidly reaches a peak and then declines
alright so the paper essentially you
know one of them to get into the paper
essentially talks about the factors that
influence the rate of immigration so we
studied essentially three factors you
studied demonstrated technical
competence which we model by submission
of patches right we consider social
status which we model by constructing a
social network and looking at social
network measures right and and so you
know and of course cat and the time
since immigration so we looked at these
factors to see which predicts so the way
we explained that you know so the
question is why is it non-monotonic like
why does why does it actually show this
now I'm electronic aspect and what we
found essentially is that people's level
of interest as exhibited by their by
their by their by them by their level of
contribution of patches which is the
most important thing right this means
you're really engaged in the system and
learning enough technical stuff to
action to contribute patches the radio
which contributes patches drops off
dramatically quickly right within about
one or two years if you haven't yet
become a developer we just stop
contributing patches the same thing
happens of emails right so if you're an
email participant within about the first
two or three years after if you don't
convert to becoming a developer they
love that interest drops very fast right
so there's a decline with tenure there's
a decline in interest and engagement in
tenure and we believe this is actually
true probably even of commercial
projects right so in a commercial
environment you're getting paid for your
job after one or two years on the job
you can get bored and lose interest and
we don't have any hard data to support
this in software engineering projects
but there's a lot of data to support
this and
kinds of companies so there's a
declining level of interest so that's
one tend the other trend is increasing
social status right so social status as
an enormous impact social status we
measured using social network measures
in the email social network has a huge
impact and whether or not you can
convert into becoming a developer in
fact the dependence on social network
status is exponential right so if your
social network status increases by 1
unit your we measured it essentially by
degree in the social network the number
of people you have connections with so
if your degree increases by 1 unit your
chances of becoming becoming a dollop
that increases exponentially based on
that so that increases exponentially but
social status builds up linearly with
time right so essentially have two
competing trends one trend is increasing
social status with them with time the
other trend is decreasing interest in
commitment of time so those two combined
together gives you this non-monotonic
property what the rates increases and
then decreases so there's a paper on
this and if you should start there
there's a early version that's published
there's a fuller version with all the
other all the detailed analysis and that
i can make available if anybody's
interested so i think i'll stop with
that thank you very much any questions
yes
you mean using the comments on the
methods as if something that feeds into
the recommender system okay so there are
there are tools that do that i mean so
there's a there's a tool called
strathcona where they used LS a latent
semantic analysis / comments to look for
similar functions we chose not to do
that it's an alternative approach right
what we didn't do that I mean and then
and there's a there's one arguable
reason against it which is the call
graph is always there comments may not
be there version is to might be
truncated but the call graph of the
current version system is always there
and it never lies it's always what it is
right so you can always you know if you
can get good recommendations based on
the call graph you're always better off
that's right that's right so you know it
so be nice if you have some way of
combining the evidence from from LSA or
something like that over text to do this
yes yeah it's 32 right
okay so the so the way there's a there's
two papers on that that you can find out
our website but essentially we take the
emails emails a broadcast medium for
open source projects so if i send a mail
and you reply to it there's an
indication of an information flow from
me to you so essentially you're voting
for my email and saying my email is a
good email so my outdegree increases
when you reply to it and that's an
indication of social status yeah this
other measures you can take that's a
local measure that only depends on who I
talk to there are more complex measures
which will take to account the
importance of the people I talk to so
you know if I get an email reply from
either guido van rossum actually that's
not very good in Python because he
applies to every email so but you know
if you know if I can reply from Ryan
bloom and I'm an Apache that's an
indication that it's more of an
indication that I'm important then I get
reply from a random person so there's
other measures of in social networks
sort of more eigen vector based yeah
yeah so there are there are several
measures of status for this particular
immigration study we used we used in
degree one has to be careful not to use
too many measures because then you're
confounding it with too many hypotheses
at the same time so we we just use the
degree as an indication of status so we
by the way in this project we studied we
studied Apache post curse Python and
Perl so and all of them show very
similar properties
the other questions
the frequency
ah ok so submission of patch patches has
a very strong impact in several projects
so in every project except postgres
submission of a pact really increases
your chances of becoming and getting
committed privileges in Postgres it
doesn't and it was it was a kind of a
puzzle why it's not that by in Postgres
it turns out postgres is very reluctant
to admit new developers and they
actually found an email on the mailing
list that said if you send in so many
patches that were tired of putting it
patches and then we'll make you a better
there's a one can you come into
religious don't know why that is but
it's it's in every project as it's it's
own own kind of culture you know so I
mean so you know essentially there's
like three kinds of open source projects
there's there's a right so there's
basically three kinds there's the
Foundation which has a written down
Constitution there's a community-based
which is like postgres which doesn't
really have a written constitution but
decisions are made kind of by committee
and the last one is a monarchy Python is
an example of a monarchy so at one
person controls everything so we said
you know we have examples of each kind
in the inner in our sample set which is
the four or five projects and they're
all so short a similar behavior you know
except for this one thing I mentioned
with patch submissions in Postgres
light and clips
where
people probably have other means of
communicating each other sites on the
list yes babe that's a problem that is a
problem that's a problem yeah so um you
know so that's hundred actually under
discussion right now because one of my
students is thinking about doing an
internship at Microsoft and they're sort
of interested in this but their social
networks are more ad hoc people just
blue face mail you know whatever and you
can't you can't really you can't really
tell what's going on so many of these
projects are community norms that
indicate that all substantive
discussions related development must
take place on the mailing list right now
there's another whole thing which we
haven't yet touched which is IRC
archives right so we haven't gone that
yet and something something else we need
to look at
questions
you
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>