<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Virtual LA: The Next Generation | Coder Coacher - Coaching Coders</title><meta content="Virtual LA: The Next Generation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Virtual LA: The Next Generation</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g5j18-_ThGo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is Bill Jepsen our distinguished
visitor who is from the graduate school
of architecture urban planning at the
University of California at Los Angeles
and Bill's famous for a number of things
most one of which at least the reason
he's here today is having built accurate
my newly accurate models of huge urban
cityscapes in 3d and he and I met a long
time ago in a funny way we he up there
have been these riots in Los Angeles
some time back and you're trying to
communicate to the to the world how to
move forward from that know how to
rebuild from the areas that were riot
ravaged I don't have the idea of
modeling not only that kind of landscape
as it was but then also possible ways of
rebuilding it putting all this stuff in
a van driving it down to these urban
areas but he will tour through and vote
like I like it to be like that or like
this where they can see in 3d and it get
comments back like though we need more
lights there because that's where the
drug dealers hang out and illuminate
that keep him out of it so it was a
great idea was called rebelling I called
bill and I said can I see his work is so
great I said I've got some government
people coming tomorrow can I do a good
mo he said that's sure no problem lyssa
didn't he watched the news the next day
and notice of me and President Clinton
Vice President Gore and I'm flying
through this rebuild Elliott they talk
about Bill and so he said your valence
the next time you asked me if you can go
do it I know you're serious so I call
him about above the go check hey you
know we're getting seriously Google
Earth about doing 3d buildings and the
next day we announce that we've bought
Sketchup so that was my part two for
them so he's here to talk today about
how they build buildings and how they
might work with us in the future to be
kind of bring some expertise and
building huge urban cities names they
need
why I'm blending a virtual oh I released
the downtown portion thereof and it's
going to take about eight more minutes
to do so once it's up we're going to
apply throughout investigate some things
but let me tell you a little bit just to
waste of time since we have it about
help us all got started it's actually
goes back the gestation for this
actually goes back to the Apollo program
and in the late 60s and early 70s NASA
was looking for some spin-off kind of
applications that justified all the
money that they spent on the Apollo
program and I'm one of our faculty were
one of the faculty at UCLA at that time
Peter cameras are got a NASA spin-off
grant to use the moon landing simulator
the Apollo moon landing simulator where
you know that I don't know if was Neil
Armstrong or who's the other guy Aldrin
Buzz Aldrin I don't know who is the one
who flew the moon lunar lander down and
landed it but it's was a CRT that they
practice landing on the moon and there
was two of them in the world at that
point in time there was one in Houston
de made it and went back in G's
headquarters in New York and so Peter
got a grant to do a little 200 years
limited 240 polygons 240 polygons city
that they could drive through so he
designed the city they flew in the
Houston the Nash to the engineers there
for months later they flew him back and
the NASA engineers had created the 240
polygon city and they drove him around
for 15 minutes made a 60 millimeter of
idiot or not video a actual film send it
to him into the project so in 1974 when
UCLA hired me they showed me that that
film and they said this is what we want
to do
now remember that in 1974 the technology
that we were using was i call it the
green etch-a-sketch it was tektronix
storage tube where you could draw lines
on a little 15-inch screen and in order
to raise anything how do you erase
everything so it's just like a net to
sketch so that we were a long ways from
what we can do today but we actually
managed to replicate the lunar lander
simulator and beyond just a bit beyond
it so having given you more history that
I'm sure you want or wanted to hear I'll
tell you a little bit about what we are
doing which is that where our typical
application is we look at new
development in a dense urban context we
work on almost all of the high-profile
projects within the city of Los Angeles
we have a model that encompasses now
about 25 square miles in the city which
we interactively navigate through we try
to be as accurate as we can we like to
say that we're accurate down to the
level of the signs in the windows and
the graffiti on the walls where you see
trees those are the accurate tree types
if it's a eucalyptus we have put in
eucalyptus models we make multiple
presentations to communities and people
within the city we've had theaters that
have been rented out by the city or
actually put on loan or get 750 people
come in and we look at these new
projects and they are actually evaluated
using our technology and in fact we go
through multiple iterations on new
projects because people of all walks of
life can understand exactly what it is
that they're seeing so we have about 25
square miles now Los Angeles is rather
large as some of you probably know the
city of Los Angeles is 500 square miles
the city proper los angeles county is
4,000 square miles
so we have a bit still to go before you
can populate the entire Earth dense
urban environment but it's it's moving
along not all the 25 square miles is
contiguous has basically spread out from
Santa Monica to downtown LA from the San
Fernando Valley down to LAX so we have a
fairly large area that we cover we can't
load it all up it just swamps a graphics
card particularly with the imagery and
textures of he is if we had better
technology maybe we could so there's a
there's a variety of things that we've
looked at over the years in terms of
applications so before we like I said we
probably have about five more minutes
before the same is ready to go these are
the questions that i can answer yeah
whenever we have a project in an area we
go and update that area we don't try to
keep it up to date in terms of the areas
that have already been built if there's
a reason to update it we do the cost of
updating an area and you know anywhere
from ten to twenty percent of what the
original cost is our building it the
reason is that the streets don't really
change their position unless there's a
big earthquake or something the
buildings are typically about the same
you know ground level imagery changes
but you know paging the imagery in and
out is not that difficult and so you
know we're really only going to apply
our efforts where there's a particular
problem that needs to be solved or a
reason needs to be updated now the woods
and will say the interesting part about
the update is that everything we do we
timestamp and so as Michael indicated
we've been doing this since around 92
well using this version I've been doing
this in 74 but the current gestation is
goes back to 92 in terms of the database
so we actually are creating
three of the city of Los Angeles that 92
doesn't have much in it but as we move
forward and things get replaced they
don't get her in a way to get kept so
you know someday I'm told that's not all
but then I'm older well created a
history of Los Angeles and it all gets
captain we actually at one point
developed the time slider so that we
could push the time scale back the
problem is that since we're already over
using texture memory if we love the old
stuff the net force was out new stuff
and that's not a good trade-off for us
so we typically don't load the history
and he send out there is one other area
that we work in which is what we call
historic reconstruction so we've done
Herod's Second Temple in Jerusalem the
forum of trajan in ancient Rome and
we're currently working on the Chicago
columbian exposition of 1890 some other
whoops it's not one
so everything that we do is fully
interactive we even though the database
is quite large we try to keep the frame
rate up to something that allows you to
interactively navigate this is running
this on a little shovel computer which
is not mine so it's not as good as what
we would normally be able to experience
but I can take it on a plane much more
easily than the dell computers that we
use and so you can see the little
crosshair I'm controlling where we go
and what we look at with the crosshair
and anytime we can stop look around
we're looking at a version that we put
together to show the homeland security
people so as you see these lolli top
pops going around those are actually
representing different Metrorail type
vehicles these cars fire engines etc
we've had a grant where we've actually
tracked in real time various vehicles
driving around Los Angeles so everything
we do is based on you know i'm going to
say global coordinates you can think of
a gps or actually state plane coordinate
with the local offset but we've done
taking the system put it in a car
married into the in-car navigation
system that Toyota uses output the GPS
coordinates and had on the dashboard an
LCD panel showing the same view on the
LCD panel from the virtual model that
you saw at the windshield as you're
driving around typically the kind of
thing that we get involved with is
looking at new development so here's a
project that we did a few months ago
well I over the last couple of years
actually it's a development across the
street from staples which is where the
Lakers play this is the initial proposal
back out to get a little bit of a view
of it so staples was actually and
there's there's a little bit of Z
fighting happening here the nvidia cards
don't have quite the same resolution on
the z-buffer that the old SG is that we
used to run on half so you get a little
bit of Z fighting if you see the
flashing so this project was proposed
City Council and Los Angeles had a
problem with it they had a problem with
the original staples proposal as well
they were sent to the interest
entertainment group we need to do one
thing here
this needs to be 5.7 ok so anyway AG
came to us we put in their conceptual
model they use this to get all their
entitlements this was showing the City
Council is showing the interested
community groups that process actually
went quite well far better actually they
on what their staples proposal did so
based on this which was conceptual in
nature they went back they hired a bunch
of architects and so there's five
different buildings and they have five
different architectural firms that they
hired they all delivered their plans or
final plans to us
and this is what's being built so they
came back to us we put this in they used
as we made up a bunch of DVDs and image
or videos and they use this at the
ground-breaking ended it out I was on
the news that night but it's the kind of
thing we do the new development looking
at it in urban context people who don't
necessarily even speak English which is
important in Los Angeles can look at
this and understand it we can drive
around inspect it from every angle and
even more importantly we evaluate it
from a pedestrian or a car I height so
it's the way people are used to looking
at this kind of thing and they
understand it so that's very goggle
however in doing all these projects
what's happened is we've developed this
very large database like I said 25
square miles probably 8 to 10 20 miles
just in the downtown region it's very
accurate it's built using a whole
variety of loops going through the
ground
we built it using a variety of data
sources and I'd say we probably use 30
different data may be more data sources
from the city on a regular basis and in
fact I've had to go through all kinds of
Homeland Security background checks etc
in order to get the okay to get some of
this information we're kind of a
low-budget operation this is the team
vehicle here
that's Dave Dave is one of the modelers
we're about to we work on most of the
high-profile projects within the city of
Los Angeles for example we're just
starting on exposition Park which is
where the Coliseum is or use that for
the la's in FL did there's also a very
large for URI development brendale
videos from the odd that you just got
the call on that will start working so
you know effectively we tend to be
involved in many of the high-profile
particularly the contingents projects in
and around the city of Los Angeles so
not only do we have much of the cities
that exist but we have much of the new
these proposed construction as it will
exist so we're typically ahead of the
curve and when that happens of course
that's when we go back in the update
those areas so boy over here
now our metric or I threshold is that we
need to develop these models to the
point where people who live in this
community can look at this and say yeah
that's where I live that's what it looks
like so you know if we cut corners if we
don't have accurate data then we lose
our credibility because the people who
are looking at this and using it to
judge some very contentious projects are
going to effectively go no this is not
this is not what it looks like and
therefore will call into question what
it didn't look at we're saying is going
to be there
and one of this thing here
disney concert hall anyone has any
questions go ahead and ask them used to
fielding questions as we go through this
yes I mean you're gay now
well you're right question yeah the
question is how to the data capture that
basically we use only one real tool
which is well to tools one is a digital
cameras in the other is photoshop now we
go ahead and we lay out the environment
that we're going to be working in
accurately using whatever data we can
get so for example we'll get from la do
t drawings of you know what the
streetscape is like you know how wide
the streets are where they are etc it
turns out though that the most accurate
for example the most accurate Z data
comes from the sewage department so
we'll go to the sales department will
pull plans is one thing about the sewage
department they know how high things are
because tours were kind if they go
downhill but they go up y'all they're
really not ten here so we'll get freeway
data from Caltrans will get various
other pieces of information and we'll
compile it into what I'm going to call
the street layouts will get plans for
the buildings from CRA Community
Redevelopment Agency or from other
agencies the planning department etc and
will compile all this information in
order to turn it into effectively layout
but at the end of the day we're going to
go down there and digitally photograph
everything and then use that information
to build the models so we're going to
have to
perspective correct all the imagery that
we take there's a lot of occlusion that
happens at the street level and so
consequently you're going to spend a lot
of time figuring out what it is that
needs to be in the model you're always
operating on a budget a polygon budget
and the temperature budget and so you
don't want to apply you know
high-resolution imagery to the top of a
building if you don't need it but you
may want to spend a lot of time getting
the signs in the windows or their
graffiti on the walls down at the lower
level so in some ways building this is
as much an exercise and art as it is one
in science we have methodologies that we
do out we have rules rules of thumb
we've developed you know we go through
this and we effectively as time goes on
redo the rules because the hardware gets
more capable our ability to show imagery
gets better so you know some point parts
of this model actually we're done in 92
and have not been redone since then but
at the end of the day we use lots of
different data sources however the total
we use are basically photoshop and
multigem multi Jensen bother me is here
on Photoshop is what we use to clean up
the imagery and that's just about it
um we think we can automate that what we
call the low level of detail you know
there's I'm going to say that there's
about a stack of 25 layers of detail in
this model from the you know satellite
view down to the ground level of you and
because of the street level occlusion
and because most of what we do is going
to be left out from the street level
we're going to have to have you know
puts on the ground going through looking
at this or you know in terms of the
interiors that we do you're going to
have to do a lot of it by hand by
actually getting the plans and
elevations from buildings and making
sure things are accurate but the top
maybe the top eight levels of detail the
lowest levels of detail could probably
be automated or maybe town or depending
on how good the tools are maybe even 15
so the issue is at one of whether or not
i think that we could use remote sensing
type applications i know we can the
issue is how good is that data and you
know how far down that stack of 25
levels can that day to get us before we
have to go in and start looking at
individual trees oh yeah you know that's
a eucalyptus or an oak tree or southern
oak or maybe it's something else a ficus
and so there's a whole set of issues
that we've all around where you draw the
line and in particular like I said
there's always going to be street-level
occlusion that you're going to have to
deal with now we're looking at using
this model as sort of a 3d metaphor or
3d index into a world of other
information so that people could
effectively go up and say okay you know
here's can't exactly we did this is
older one the swatch factory you click
on that particular we have a point click
interface so we can embed URLs in any
polygon
graphic image that we could do a point
and click on the Squatch battery and
pull up the swatch factory interactively
pull it up the swatch factories website
if we had embedded that URL we're
talking to a whole variety of different
first responders and others about having
building owners putting their floor
plans and elevations online that the
fire department of the police department
could access through this kind of
point-and-click interface so to the
extent that we can use the automated
tools to you know build out the first in
layers of this that would be great that
would be a big win for us restore
probably
right there the question is that you
know when do we determine when to use
the actual imagery versus remote sensing
type imagery ok well the patterns like
the trees you know trees are typical
that the streets for example textures
those are all coming from a standard
library so things that you know it
doesn't have to be that exact tree just
has to be a eucalyptus of about that
size and they're the age we're going to
use pre-existing imagery or we may have
to create some but will then put it into
our library and use it however that's
pretty much as far as it go so for
example we're looking at the interior of
the Bradbury Building here these are the
actual brick patterns you're the
Bradbury so we're not kind of just
because somebody's using red brick we're
not going to take a standard red brick
pattern and use that we're going to
actually take the imagery from that
building and use it because if you don't
then first off it's not going to be
accurate enough and secondly
everything's going to look the same it's
not going to have the image quality that
we're looking for so you know again as I
was saying before there's an artistic
piece of this or anesthetic piece of
this which says you know when do you use
standard stock imagery you know well
it's okay for plants because very few
people are going to inspect a plant
really closely and say that's not the
exact right tree it is the right species
it is it right size but that's not the
tree that's there but on the other hand
for a lot of this we're going to take
the imagery and develop the building
from that so we're going to actually use
the imagery to build the building so we
might as well use the imagery the
texture map the building it's all one
process other questions yes lovely the
size of the
geometry intention
the database I'm going to say is
probably on the order of 85 to 90
percent texture versus geometry in terms
of the size that we have a binary
database format that was loosely defined
on something that actually Michael
developed after i bitched at him for a
long time called performer binary so we
developed our own that's based on
performer binary using the binary
interface sighs this is about eight
hundred megabytes what we're looking at
we're not even looking at we haven't
gotten close to actually looking at all
of this the raw files for this are
probably on the order of a couple of
terabytes for the downtown model so you
know we're very efficient in terms of
the binary and the raw databases are
much larger other questions yes
you know um they contacted me a couple
of times and I think they'd rather
develop their own intellectual property
and our database is very large and you
know they they basically go through
these exercises that are different from
what we do they don't have to be
accurate that's not really important
playability is important to them and so
consequently we haven't actually made
that connection we've talked to them
I've given them samples of our database
but things haven't progressed beyond
that yes
me
or
you have any kind
dislike
yeah the question is whether we have
automated systems for determining when
we have more than one data source that
are in conflict which one to use the i
would call our approach to that sort of
seat of the pants in the sense that we
typically know of our all of our data
sources which are the most accurate but
we'll also go out and verify that with
digital imagery so we would kind of take
in use what we think is the most most
likely to be accurate information and
use that this is visual simulation and
the the height of a skyscrapers off by a
few feet no one's ever going to notice
the difference now we measure the
setbacks of buildings from the street
for example so there are certain pieces
of this that we know are accurate
because we feel verified those and so we
do take some steps to try to verify the
accuracy of the information but you know
typically we have multiple sources and
so you know we can do cross checks
across those sources yes
yeah we have the problem is that in a
real-time application you have 30
milliseconds to render a frame the more
complex the computational load the less
the size of the database is going to be
so you know we've looked at that for
example on the disney concert hall we
didn't really get a good metal sheen and
so we should have probably done
something there but we did because the
scope of the project actually was fairly
limited on terms of that what we're
looking at here is were in the escape
tunnels of the LA subway how many of you
knew there was a subway in Los Angeles
yeah that's pretty amazing most people
in Los Angeles don't know there's
actually a subway and certainly very few
have ever ridden it we did this for the
police department they were concerned
about familiarizing their officers with
the answer me areas that are not the
public areas and consequently developed
a below-ground model of the subway so
that they could fly around and literally
stick their head underground and
understand how these answering
non-public areas are actually configured
relative to the public areas and they
were concerned with the whole variety of
things if there was a terrorist event
but also they were concerned with if
someone this is the Jewelry District
robbed the jewelry store ran in there
with a gun and their officers weren't
familiar with it they didn't want their
officers going in and chasing down or
where the emergency exit tunnels so
there's a whole set of those kind of
that we can help answer other questions
are using anyway now we really don't we
appreciate things but that's about it we
often get asked whether or not we can do
shadow casting and that the typical
responses we can but it's more costly
and then typically people go away with
it faced with a cost oh yes we met map
everything
so we look at a few other applications
that we've laid it on top of this the
interesting thing here is that once you
have a fully three-dimensional an
accurate three-dimensional real-time
model of the city there are lots of
different applications you can begin to
layer on some of them are kind of fun
others are pretty I don't know how to
explain them so one of the things we
looked at again we plan on using this or
we want to use this is a
three-dimensional metaphor in decks into
a whole world of data now if I add this
machine hooked up to the internet which
we didn't have time to do we can fly
down here and there is there is a camera
on the 10 freeway and we can literally
click on this camera and pop up a web
browser and look at the video imaging
streaming from that particular camera on
the 10 freeway in real time so we use
this again as a way of locating things
there aren't too many cameras around on
their left cases in Los Angeles
unfortunately we can get access to very
few of them because that led OT is
afraid of getting sued if someone
captures imagery of an auto accident
they might end up getting soon so they
won't release that kind of information
or they won't put it online there's a
whole variety of different actions that
one could conceptually do like tracking
vehicles in real time the emergency
response vehicles we also did a study
for the company that makes in-car
navigation systems for Toyota hence the
description i was given earlier of
having an LCD panel in the dashboard
that created the same view you had as
you're driving around but when things
were able to do those systems know where
you are
gps
and if you punch it a destination
they'll create a shortest either
shortest travel time half or a shortest
distance path i'm not sure which from
where you are to the destination that to
be a sport well we're able to output
that those coordinates are that travel
path into our system we develop this
concept of the red carpet and overlaid
it on top of the model and now as you're
going around instead of getting these
kind of strange commands from a woman's
voice saying you know TURN RIGHT 500
feet and seeing a line drawing very
actually looking out on LCD p LCD panel
on the dashboard this view is we drive
along with a red carpet overlay so now
we're able to navigate in the same way
you would if you are familiar with the
route and familiar with the neighborhood
by using the buildings around it as a
visual cue and we found that you could
pick up the appropriate pants and way to
go is quickly by glancing at this as you
could by seeing within your rear-view
mirror and understanding that so it
turned out that this was pretty cool and
in fact I've been trying to get nvidia
interested in to upgrading the graphics
cards for in-car navigation systems in
order to use the real-time TV model
effectiveness for the in-car navigation
systems
questions
yes only hope the DRS Marlowe steak
like one block
the question is how much time does it
take to model one block my rule of thumb
is 60 hours 60 modeling hours per city
blocks so you know if you're looking at
a google earth type application there's
a few man-hours going to be there before
the whole earth is in but we you know
we're acted down at a very fine
granularity you know a lot of the remote
sensing kinds of this can be done to get
you partway there before you need to
really start spending that kind of time
so you know there's there's going to be
sort of a gamut from 60 hours per city
block down to or up to you know being
able to do fairly large piece of the
city now the one thing I will say though
is that when we played out the city all
of our modelers know how to find
everything in the model in a matter of
seconds and we're always changing this
models of the dynamic model as new
things come online we're taking old
things out and I'll throw them away we
save and we time stamp them but we're
always updating changing modifying etc
so this model is very facile and with
the rut sensing data which again is a
cloud of points in a lot of cases that's
not foul so we permit not facile and you
can't really change it and so you know
there's a sort of a difference in
usability between a remote sensing
created database and one that's been
created by hand specifically towards
updating changing etc yes
the the roots of the buildings are from
a set of ariel's that I purchased a
number of years ago there were half
meter resolution if we can get better
aerial imagery is that the question you
were asking is where did we get it so we
just use the aerials to map the roofs of
the buildings yes you've got Polytechnic
thinking a lot real-looking
and partners that
Jason
well the reason that they if they look
cartoonish it's because we have to
sample them down pretty much I mean
we're yeah and that that tends to have
that kind of impact you know we're not
we're not specifically trying to achieve
that that's actually an undesirable
artifact Alonso look real but a lot of
hope we were looking at has been done in
the 90s timeframe and we didn't have the
texture capabilities that we have now so
you know we were sampling things down
there's literally 16 pixels by 16 pixel
size in order to get as much as we can
as we move forward and grain buffers get
larger than our ability to use the
imagery approves when we were able to
start compressing textures we got a big
boost their so but a lot of this model
predates that
going again yeah I think they mostly use
street level right now this is a loaner
computer and I put up what we call I put
it in what we call drive mode we tend to
punch through the ground level because
it's not reacting fast enough that's a
parameter but I can't set it because of
the machine that I'm operating on but
mostly people want to drive at the
street level they do not want to fly and
look at the helicopter viewpoint so you
know that's the kind of thing that we
notice now that they like the fact that
by and large the mouse interface that we
use is familiar and most people rather
than some other kind of an interface and
so most of the people people come into
my lab and fly around for about 10
minutes become very facile at using the
interface so that's been good as well
alright so let's go down here this is
another new development that we're
currently working on as the new
headquarters for the LAPD this is what's
currently there and notice how slowly
we're sinking down to I hi that's that's
a problem with the way that this machine
is set up so let me go ahead and switch
ok
so this is a new development that's been
proposed
that's what we're currently working on
so you know this still mean like a
little cartoonish
but it's getting better
are there questions asked question
Michael mythology George are the skill
level required of the bomber
the question regards the skill level of
Mars there there's two pieces that go
into that puzzle one is that some people
never make it and you probably
experience that yourself in hiring
people particularly on the aesthetic
side there's an aesthetic that needs to
be applied when you do these things and
some people just don't get it when
people come in for those who do get it
so there's a there's a threshold which
is some people never make it and then
those who do it usually takes them i'm
going to say six months to become
reasonably productive in my lab and then
another six months before they're pretty
good so there's a learning curve of
about a year before they've really
ramped up now look at these I teach
classes and so you know I pretty much
got the methodologies down and we have a
lot of materials that say you know
here's how you do it here are some rules
of thumb etc etc but even given that
we're some people who are just like
inherently incapable of making good
choices is that is that from a set of
people Trombley graduate school of
architecture or met people off the
street
those are from people drawn from the
Graduate School of Architecture now let
me just say this I spent a lot of time
disabusing people from the School of
Architecture from things that have been
thought of how to do it and they're
they're basically trained to add more
detail to spend a lot of time you know
modeling every mole ian and sill and so
you have to break them up that habit
because the imagery is actually far more
realistic sorry then what you you know
if you use the imagery it's going to
actually look better and it's going to
be easier on the compute cycles and so
you have to break them of their bad
habits you want to lay things out
logically rather than spatially is you
have to break them of that habit so you
know there's a whole set of learning or
unlearning that they have to go through
before they can actually fit in and so
being from the School of Architecture
it's a good thing aesthetically and a
bad thing training wise because they
come in with the wrong concepts and they
have to be broken or retrain shall we
say
other questions now this is downtown and
there's other areas we could visit we
could go to UCLA or LAX if anyone's
interested or we're almost at the end of
the hour so why don't you guys guide me
what you wanted to do the wrong question
look at least when you have to review
yeah i mean the binary has to be rebuilt
you can think of this as compiling a
program it takes me about two and a half
hours right now to recompile the
downtown which is our largest database
the wrinkle compote compilation process
is basically loading all the raw flight
files and image files and processing
them into a binary but you know I come
in every morning and you know I'll
reload things and if we have an area
that's going to be seeing a lot of
changes over a short period of time a
punch a hole there and create a second
binary it's just that little piece so
that we can reload that piece without
reloading the whole thing and so you
know effectively you can concatenate
binaries and so you don't have to spend
two and a half hours reloading a binary
and we also have an ability to import
raw files into this and as long as you
don't do that too much you can just go
up from the minute you do an import and
bring you in a dxf for a flight file or
some other kind of thing as long as it's
in the right coordinates it'll just be
imported right into that particular
location and then you can fly around and
look at it but that will host
performance you know if you do too much
of it because we use the scene graph to
communicate to the application how to
render things and that's how we keep our
frame rate up if we don't use that then
literally I've done this experiment if
we flatten the model we're going to get
instead of 30 frames a second we're
going to get a frame every two hours
which we don't find to be acceptable for
our kind of applications so every
well no that would be effectively the
question is whether I can work with
every separate piece of database as a
separate binary and the answer would be
no that would be effectively flattening
the model and consequently we would not
be able to get good performance so you
know if everything is standalone little
piece then the higher level levels of
detail you remember earlier I talked
about 25 levels of detail from top to
bottom well there are no levels of
detail if you have all the separate
binaries and consequently you're going
to just have this huge pile of raw
polygon texture polygons that this thing
is going to have to render it's not
going to understand which version to
render of the things that are far away
and consequently they're going to be
really heavy yes I had a question about
how many we did that little detail is
that mostly far the next gen ultimate
atomically is
I would say it's even more for the
geometry then for the textures but we do
have protections as well so we'll have
maybe three or four versions of an
individual building when it's untextured
you know for polygon or five polygons
you know pore size in the roof down to a
very highly articulated you know
multi-thousand polygon version so the
polygon count will go from zero which is
you're so far away from this building
that you can't possibly see it to you
know thousands and thousands the texture
count will go from one or two very small
textures to you know a couple of dozen
or maybe as many as 100 but higher much
higher resolution textures so we're
going to have both textures and polygons
in the LOD range the question becomes
one you know how much of the frame
buffer they take up and how much of a
rendering road did they take up and you
know depending on the building how big
it is how important it is those are
going to arrange it they're gonna going
to be quite a range in terms of the
quantity they're able to join videos
anymore
yeah you tend to start I mean that's a
natural process you tend to start with
the massing level model and then
articulate that so if you just say
things out at the appropriate time then
there's almost no additional overhead if
you start with a very highly articulated
model and then you try to generalize
back that's actually more difficult and
consequently it does take more time but
if you go through the normal modeling
process that levels of detail just fall
out of that almost for free other
questions okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>