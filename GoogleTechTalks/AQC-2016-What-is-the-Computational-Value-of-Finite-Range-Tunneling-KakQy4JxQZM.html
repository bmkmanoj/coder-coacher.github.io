<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AQC 2016 - What is the Computational Value of Finite Range Tunneling? | Coder Coacher - Coaching Coders</title><meta content="AQC 2016 - What is the Computational Value of Finite Range Tunneling? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AQC 2016 - What is the Computational Value of Finite Range Tunneling?</b></h2><h5 class="post__date">2016-10-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KakQy4JxQZM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">very spicy again chef from glue all
right thank you very much my name is
Vasily enchev and I'm going to talk
about the computational value of finite
range tunneling this is work done at
Google together with all of these other
folks okay so this is the outline of my
talk so first I'll go over some
background on adiabatic quantum
computation and quantum annealing then
I'll talk about our idea behind the
finite range tunneling and how to use it
to achieve a computational speed up next
I'll define our basic building block
that we use for our results we call
these the weak strong cluster pair and
out of the weak strong cluster pair we
build larger problems called weak strong
cluster networks I'll go over these two
and then I'll cover our bench
benchmarking results where we show the
speed-up of the latest d-wave machine
versus simulated annealing and quantum
Monte Carlo and then I'll close with
conclusions okay
so first let's start with defining what
is behind quantum annealing so we are
doing a quantum evolution here of a
quantum system from some time T 0 to
some time T capital T we're assuming
here an ideal closed system and later I
will talk about a more realistic model
the adiabatic theorem from quantum
physics says that if we have an
evolution time that is large enough when
we start in the ground state of our
time-dependent Hamiltonian at time T 0
we are going to end up in the ground
state of our Hamiltonian at time capital
T so this large enough is defined in
terms of the minimum gap in the
spectrum again spectrum of the
time-dependent Hamiltonian the minimum
gap is the closest that the ground state
energy gets to the first excited state
energy during the evolution and the
evolution time needs to be approximately
proportional to the inverse square of
that minimum gap okay so how do we solve
optimization problems using these
physics well we can start with an
initial Hamiltonian that hasn't known
and easily prepare above ground state
and then we can encode the solution to
our optimization problem in the ground
state of a define of Hamiltonian which
we call H P here so then all we have to
do is initialize our system in the
ground state of the beginning
Hamiltonian do the evolution for some
time slowly enough and then we would be
guaranteed to find the ground state of
our problem Hamiltonian and hence the
solution to our optimization problem so
this is all idealistic in terms of
running at zero temperature and having a
closed system but in reality physical
devices actually operate at finite
temperature so this this thing is not as
simple as described in the previous
slides what we get with temperature is
what has been called quantum annealing
which is a quantum enhanced optimization
heuristic that exploits tunneling but
also because of the presence of
temperature there can be thermal
transitions that can happen as well so
the advantage of quantum annealing
versus the gate model quantum
computation is that it seems that we can
have practical Hardware implementations
now whereas gate model quantum computers
will take more time to build and to
implement the technology so it's also
known that quantum annealing is better
than similarity kneeling for problems
with our narrow barriers and this figure
here is tries to illustrate that so when
we have a difficult optimization problem
with lots of local minima and large
barriers
thermo annealing would have a hard time
using thermal fluctuations to jump over
a tall barrier whereas quantum tunneling
would be able to better deal with that
barrier as as long as the barrier is not
too thick you know so for tall and thin
barriers quantum annealing is better
than simulated annealing and that's what
we're trying to leverage here
so d-wave has been working on
implementing this quantum annealing
algorithm in hardware in particular the
problem Hamiltonian of the wave is the
Ising model which looks like this
so the difference yeah so it's not
actually this General Eisenhower onion
because the in the d-wave machines for
engineering reasons not all couplers are
available and also there's a limitation
on the precision of the couplers and
local fields that you see here in these
terms the fine when we find the ground
state of this Ising Hamiltonian what
we're doing is solving this optimization
problem so this is from the perspective
of optimization so this is what we would
be doing if we were to find the ground
state and then in the d-wave machine
this is the whole time dependent
Hamiltonian the beginning Hamiltonian
consists of transverse field applied
individually to them or all together to
the stings to the qubit under the word
machine and this is the the annealing
schedule so initially the transverse
field is high and then it gets decreased
whereas the problem Hamiltonian is
switched off and then gradually it gets
turned on so this is the evolution from
beginning to end this is the hardware
graph of the current divided machine
that we have available for our use at
NASA Ames the dots here represent the
qubits on the dual machine and the lines
represent the couplers between them and
in addition there are local fields also
that can be applied individually to each
qubit so
this machine has a thousand one hundred
and fifty two cubits but only one
thousand and ninety seven of them are
operational because the yield of the
manufacturing process is not perfect I
have a short video here to illustrate
the operation of d-wave so first we have
the transverse field applied uniformly
to all the qubits on the chip and then
the transverse field is gradually turned
off and the couplers and local fields
are turned on after which the qubits
orient themselves in the Z direction to
assume their positions that should
correspond to them granted all the final
Hamiltonian and these up-and-down
orientations correspond to logical zero
and one which can then be read off and
represent the result of the computation
alright so next I'm going to cover what
we understand here by finite range
thermally assisted tunneling so let's
say we have some optimization problem
like this for simplicity we've
constructed something in two dimensions
which looks like this one projected to
one dimension here so tunneling can help
us overcome as I said barriers with a
dot are tall and thin so for example
going from A to B here can be done by
tunneling also with the help of
temperature by first picking up energy
from the bath and kind of raising up a
little bit maybe halfway it should up
the barrier and then using quantum
tunneling to get true on the other side
and then finally dissipating energy back
into the bath and relaxing into the next
local minimum then then maybe we can do
the same to go from B to C and so on but
in this particular example we've drawn
the barrier between C and D to be pretty
thick just to illustrate that quantum
tunneling would probably have difficulty
going from C to D because of the
thickness of the barrier so the
probability of
tunneling through this barrier would be
small so this means I mean this is a
general feature of hard optimization
problems and means that quantum
tunneling may not always be able to help
especially when we're limited to finite
range tunneling so if only a few of the
qubits can tunnel together then at some
point their number might may not be
sufficient to really get through a tick
barrier so indeed in that situation
we're interested in studying how quantum
tunneling can beat approximation
algorithms and some of this work has
already been started by other teams you
know and we think that is a very
interesting question to explore in the
future so the basic building block that
I mentioned in the introduction for the
results that are short later is called
weak strong cluster pair and the goal of
this basic building block is to use it
to demonstrate how a finite range
tunneling can provide a considerable
computational advantage
so this problem consists of just two
Chimera unit cells the Hamiltonian of
this problem is this consists of three
terms two of which are describing what
happens within each of the clusters so
we have some couplers and local fields
in each of the clusters and then this
component describes the inter cluster
couplings that we'll have between the
clusters in particular all of the
couplings are set to one ferrimagnetic
the local fields of the left clusters
are set to some small positive value and
for that reason we call this cluster the
weak cluster the local fields of the
right cluster are set to minus 1 and
because of that large larger magnitude
of the local field we call this the
strong cluster in the ground state of
this problem all of the spins should be
pointing down you can verify that I
guess is an exercise but early in the
evolution the weak
cluster spins are misled by their fields
because their their fields are positive
you know so they're kind of pushing
those pins to be pointing up which is
the wrong direction for the ground state
later in the revolution however the
inter cluster couplings these guys they
start to override flock of fields but by
that time it's already too late because
the weak spins have started as I said
orienting themselves up instead of down
so at this point in order to still find
the ground state the we cluster spins
need to tunnel they need to turn
themselves around altogether and that
corresponds to a tall barrier it's
possible to also do with thermal
activation but it's less likely and you
know there's a calculation for this that
we have in a previous paper by borshu at
all in Nature communications that shows
that yeah with a certain noise model
with experimentally measured parameters
on the d-wave 2x that the tunneling
transition would be more likely than
thermal activation for this week's from
plus repair so I'll go a little further
giving an intuition about how this
problem works so this is a plot of the
mean field potential of the weak strong
cluster pair with the axis being as this
one axis is the evolution parameter from
beginning to end this axis gives the
tilt angle of spins in the weak clusters
so minus PI over 2 means that we cluster
spins around oriented down and PI over 2
means that they're oriented up which is
a force minimum ok so as we start from
here and follow the red line the red
line gives us the part of instantaneous
local minimum of this problem and this
is generally how the evolution would
proceed
but at some point approximately at x
equals point 1 8 will have a bifurcation
point and by that we mean that in the
potential we have a second local minimum
starting to form ok and then it turns
out that actually the global minimum
forms on the other side which is this
along along the blue line but the system
has already started following the red
line here and by the time it's apparent
that the global minimum is somewhere
else
this system is already behind this
barrier that has already formed along
the Green Line here so in order to still
reach the global minimum the system has
to tunnel under the barrier along the
Green Line or have a thermal activation
over it jump over it thermally and again
as I said before it's more likely that
the quantum tunnelling will be
successful rather than the thermal
activation and we have verified this
experimentally so we tried increasing
the temperature gradually of the d-wave
machine and running these weeks on
Cluster pairs to verify that a method
that works with thermal fluctuations
like SVM C actually has its probability
increased with temperature because that
makes it easier to jump over that
barrier thermally but a quantum device
like the wave it's probability of
success goes down with increasing
temperature with because the tunneling
probability gets decreased that way and
this is also in accordance with in
agreement with two simulations of to
quantum simulations called niba and
Redfield that don't have any feeling
parameters but are using parameters
again experimentally measured noise
parameters from the division so this is
strong evidence that this is really
what's happening in the d-wave machine
and that tunneling is playing a function
or rather for solving successfully the
week's non-clustered per problem all
right so out of the Wickstrom cluster
we build larger problems which we call
the weak strong cluster networks this is
a crafted problem and we specifically
designed it to like this to have tow and
narrow energy barriers so that we can
amplify this effect that we saw in the
weak strong cluster pair problem
basically the way we construct it is we
take a number of weeks from cluster
pairs that we can find on the d-wave
graph and we connect the strong clusters
of them in a class a glossy fashion
which means that we set the couplers
between them either oh two plus one or
minus one at random so here these black
unit cells are the strong clusters of a
number of weeks from cluster pairs and
their weak clusters are just hanging off
on the side like you can see here and we
connect the strong clusters together by
randomly choosing for each pair randomly
choosing whether to set their couplers
to ohm minus 1 Rho plus 1 and because
that's similar to maybe a spin glass
problem at zero temperature if you
collapse the unit cells to you know
single spins we call this a kind of a
spin glass kind of a way of connecting
the strong clusters so this is the small
version of the problem with a hundred
and eighty spins on the d-wave graph we
have constructed larger versions like
this this is still larger yet larger and
then this version covers almost all of
the graph of the current divide machine
so at largest at large sizes like this
we're suspecting that the glassy
backbone of the problem is dominating
the computational hardness this is also
explored by a recent paper by hamid cuts
crabber scheme which you can find here
on the archive so it's probably the case
that finite range tunneling would be
insufficient for reaching the ground
state when the spin glass when the
glassy backbone is dominating the
computation of hardness and again here I
want to mention studying approximability
in this case
so even though at some point we might
not be able to reach the ground state
we're still interested in maybe finding
good approximate solutions that can
compete with classical approximation
algorithms so that's an open question
for now although yeah we've started
studying it and other people have
started studying this ok so now we come
to to the results of this study I'll
first talk about how we what we measure
and how we measure it and then I'll show
the main results so our metric here is
the tour annealing time for finding the
ground state with 99% success
probability for the d-wave machine we
fix the annealing time to 20
microseconds
that's the lowest possible and we fix it
to the lowest possible because it's
actually not optimal I mean if we can
run the Deever machine faster we would
be achieving better results and then we
measure the total annealing time to
reach the 99% target probability which
is according to this expression so this
is a 20 microsecond per run annealing
time this is the per run success
probability of the wave and this the log
expression gives the number of
repetitions that need to be done in
order to achieve the target 99% success
probability okay for similarity kneeling
we have some parameters to vary we try
to find the optimal per run annealing
time which is given by optimal number of
sweeps times the problem size times a
constant of 0.2 nanoseconds that we
assumed for the best possible classical
hardware that can be done so we optimize
the number of sweeps per run and for
example we find an optimal number of
sweeps or something like 50,000 for the
median instance of the larger size of
the week's non-clustered networks we
also vary the initial and final
temperature of similarity kneeling in
order to find the optimal annealing
schedule and again the tour of annealing
time is given by a similar expression
where we have the optimal
porunn annealing time and the optimal
parent success probability so we report
the single core annealing time of
simulated annealing and we know that
simulated annealing repetitions can be
trivially parallelized
for qnc okay so qmc is a simulation
method that samples or tries to sample
from the Boltzmann distribution of a
classical Hamiltonian which approximates
the transverse field Ising model so it's
used we use it as a solver whose
performance is expected to correlate
with the performance of an idea of
physical quantum annealer but qmc has a
large constant three factor when we run
it on classical machinery so it's still
not a replacement for a physical quantum
annealer so in qnc we also have
parameters to vary and to optimize we
optimize the optimal power on an ill in
time according to this expression here
and as well as the number of sweeps per
run we fix the inverse temperature to be
equivalent to four point ten millikelvin
to still keep it realistic to physical
device for physical devices and we find
that running it with open by the
boundary conditions is better than
periodic boundary conditions so there
are more details related to these
parameters in this archive paper for
anybody who's interested so one thing
that we found in our experiments on the
Wickstrom cluster networks was that qmc
was generally doing more suite sporran
in its optimal regime and achieved
larger power and success probability non
similarity kneeling so if we take this
as a conformation that actually quantum
tunneling is essential for this problem
because similarly the kneeling cannot do
quantum tunneling it it can't do much
better than just kind of random sampling
you know so that's what it mostly does
whereas qmc is simulating the tunneling
or attempts to simulate the tunneling
that a quantum device would do and
that's why it's achieving it's able to
achieve a higher success probability in
its optimal regime yeah so that's an
interesting to observe
okay so this is the expression for the
total kneeling time of qmc and again we
report single core annealing times
frequency as well and we know that the
key MC repetitions can be parallelized
also these are the main results that we
find I guess Hartnett already introduced
you to this figure in his introduction
so here we find that single core similar
to kneeling in Hue NC times are 10 to
the 8 times larger than the d-wave 2x
times on instances of the weak strong
cluster networks of sizes up to 945
variables we also find it interesting
that the error bars of d-wave and UMC
are larger than the error bars of
similarity kneeling so interpret this as
revealing the sensitivity of the
individual instances to the glossy back
bones of the weak strong cluster
networks the reason why the similarity
kneeling error bars are much smaller is
that similar to kneeling is already
severely stumped by the weak strong
cluster pairs themselves okay whereas
the quantum methods they can
successfully solve the weak strong
cluster pairs individually and they only
get stumped by the glassy backbone that
becomes more dominant as the problem
size increases and this also occurs more
often with increasing problem sizes okay
so in conclusion we found that finite
range tunneling can provide considerable
computational advantage so we saw an
impressive eight orders of magnitude
speed-up over similarity kneeling and
quantum Monte Carlo of course besides
these classical algorithms there are
other classical algorithms that can
perform much faster on not just the weak
strong cluster networks problem but on
pretty much all chimera problems and in
particular for the weak strong cluster
networks problems this is kind of
trivial for classical algorithms because
we can see the clusters by eye right but
the point here is that these classical
algorithms like the HFS and cluster
finding algorithms they will no longer
be able to work successfully as we
increase the connectivity of our
Hardware graphs and for sufficiently
dense graphs pretty much any classical
algorithm would have a very hard time
competing here we also found out the
glassy backbone of the weak strong
cluster networks dominates at large
sizes and we note that finite range
tunneling can be insufficient for
reaching the ground state in these cases
and in other cases too as I talked in
the beginning when we have thick
barriers financial engines on the line
will be insufficient
but then studying approximability may be
very fruitful to do all right that's all
I have thank you very much ok please
which one the previous slide the picture
the graph
yes so you mentioned that the advantage
of quantum delay versus quantum want to
call it just prefactor but if you look
at higher harder problems like 85 or 75%
percent is quantum technology fails so
it's not just three factor is more than
three factor for harder problems right
I'm missing something or you're saying
that qmc fails more than do i files for
harder problem so here are the factors
oh it's hard to see here because we
don't have data really for the higher
quantiles of qmc for the larger sizes it
might be the case we just it this was so
so computationally intensive that we had
to stop our runs at some point and we
don't really have the data there but
there's a whole bit that it's more than
three vectors there's something yeah
maybe yeah thanks sure hello I was
wondering if you can go back to the
slide where you have
redfield niba and the d-wave with error
bars this one yes so I wonder if you you
if you've tried to use a more accurate
quantum mechanical simulation because
both Redfield and the non non
interacting blip blip approximation
those are both very risky methods to use
when modeling open quantum systems they
both fail in a wide range of regimes
okay um yeah I wasn't the one actually
that run these simulations so I don't
know if there's somebody here yeah yeah
sorry okay
I quit method we know of if you think
there is a more awkward method I would
like to know what yeah on this
particular regime and it actually took a
long time to develop that with Mohammed
embodiment amounts of people we believe
this for this problem where you know you
can look at the details on the paper you
know know this but actually this paper
we think is pretty accurate but if you
think you come you know proposal team
Iraq where that will be interesting to
know we're not aware of anything more
important yeah okay maybe we can talk
later yeah thank you okay we still have
several minutes for questions yeah
can you tell us a bit more about what
the glassy background means in the large
instances of weak strong clusters yeah
this is just the arrangement of the
strong clusters here as I said we're
connecting them in what we call glassy
fashion and all that means is that we
just randomly pick the sign of their
couplers whether that's minus one or
plus one you know so you can kind of
view it as a spin gloss at zero
temperature you know if you collapse
each unit cell to a big spin and connect
these spins like that with random
couplings you know that's the only
reason why we call this the glassy
backbone of the problem
for the simulated annealing results
could you explain the annealing schedule
that was used and perhaps what other
annealing schedules might have been
considered what other parameters might
have been considered the annealing
schedule for simulated annealing yeah
which annealing schedule did you use yes
for similar tunneling we used I think it
was a linear schedule that decreases the
temperature in linear steps basically
right yeah did you consider any others
any other schedules I think yeah I think
we've tried like an exponential schedule
also yeah but but it doesn't seem to
make much difference there's both change
it freeze rather quickly so there might
be other schedules that might do better
okay yeah I I think we have a reasonably
high confidence that we've you know
tried all the good schedules but yeah
maybe there is something more to be
don't here yeah okay thanks thank you so
myself asked a question
you've said that for larger systems
quantum Monte Carlo didn't reach
conclusions with high accuracy and I
heard the rumor that you spent a very
large computational effort to simulate
the system for some reason even quantum
annealing yep time you spend a good
chunk of the Google computational power
is it true that's right that's right yes
so the other reason why we don't have
any more data points here for the larger
sizes of qmc at the larger quantiles is
that yeah it was we already spent quite
a bit of computational time on getting
the other data points and this would
have taken a lot longer so yeah so it
was quite I mean you can imagine that
Google has a lot of computing power and
we did employ a large significant
portion of it for just computing this
single plot figure here yeah so energy
wise the wave is more efficient in the
sense sure yeah by far yeah
yeah okay that's the aspect maybe
important
practically here any other questions or
comments
okay not let's thank the speaker once
again thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>