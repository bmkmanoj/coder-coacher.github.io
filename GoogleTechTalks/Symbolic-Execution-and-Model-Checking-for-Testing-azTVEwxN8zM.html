<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symbolic Execution and Model Checking for Testing | Coder Coacher - Coaching Coders</title><meta content="Symbolic Execution and Model Checking for Testing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symbolic Execution and Model Checking for Testing</b></h2><h5 class="post__date">2007-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/azTVEwxN8zM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to introduce Karina prefer Ono
who's an ex colleague of mine from NASA
Ames really who worked on test case
generation so I invited her to come over
and that's what they've been doing most
recent okay thank you
so this is actually joint work with will
and Visser who used to be at NASA Ames
but now he's at seven networks and
actually he also gave a talk here so
maybe you'll recognize some of the
slides and ideas okay so the I will talk
about combining symbolic execution and
model checking for testing and this is
as I said the work with willem Visser
but actually a lot of summer students
also contributed to this work so I
listed them here and also some other
people from NASA Ames David Bushnell
Peter mallet and Youngblood so the goal
of this work is to detect errors in
complex software and by complex
I mean software that has data structures
raised concurrency and so on so I listed
here several of the solutions to this
problem of error detection and this is a
very simplified view actually the the
borders between these different areas
are blurred now so one is software model
checking maybe with abstraction for
example predicate abstraction is a
popular research direction so this is
automatic its exhaustive but of course
it suffers from scalability issues for
example explicit state model checking
and I will give a bit of background
about this so to see what I mean by this
cannot handle large complex input
domains
and because of the abstraction the
reported errors may be spurious another
technique is static analysis again this
is automatic it's scalable is exhaustive
but the reported errors may be spurious
so you might get a lot of warnings that
don't correspond to real errors and of
course yet another technique is simply
testing so the advantages that reported
errors are real but of course testing is
not exhaustive so it may miss important
critical errors but this is the a well
accepted technique and this is for
example the technique accepted at NASA
and basically we learn to sell our more
advanced technique as testing techniques
because this is what people would accept
so our approach is to combine the
strengths of exhaustive techniques such
as model checking and also symbolic
execution and I will tell you what I
mean by that for to enable testing and
basically we combine them for test case
generation so this is a very very
high-level introduction to model
checking so and comparison with the more
traditional simulation or testing so the
idea is that one models individual state
machines for subsystems and features as
may be finite state machines and then
simulation and testing checks only some
of the behaviors of the system so of
course it may miss errors that were not
analyzed while model checking goes
automatically through all the possible
behaviors of the system so it can handle
millions of combinations in an automatic
way and usually model checking also gets
a specification for example written in
some temporal logic or some automata
formalism that describes
expected behavior of the system and the
output is either that the property holds
or that there is an error and moreover
model checking also gives you an error
trace that allows you to basically it
helps you to debug your system to find
the cause of the error so in particular
for our work we use a model checker
which is called Java Pathfinder and this
has been developed at NASA Ames since
1999 and actually John was part of the
team that developed it and it went
through several phases so this is an
extra sea state model checker for Java
bytecode and it is built on top of a
custom a java virtual machine so it is
in something like an advanced virtual
machine on which we can control the
scheduling we can control the state
information and we can perform
abstractions and so on
and the focus of this model checker is
on finding bugs and they are concurrency
related such as dead logs data races Mis
signals and so on
also Java Runtime related so it had for
example jpf looks for unhandled
exceptions and so on and it can also
check for application specific
assertions like Java assertions and also
it can check for safety properties
implemented with some listener mechanism
and so on so jpf uses a variety of
scalability enhancing mechanisms and I
listed some of them there and then I put
a bit of publicity for it so it received
some awards and but the important point
is that it is now open sourced and so
basically people can use it freely and
also contribute to its development so
now what do I mean by symbolic execution
so so first of all I say that we have
extended jpf with a symbolic execution
and this is our enabling technology for
test case generation and I'll talk more
about it and we have several papers that
are publicly available that describe
this extension and basically for test
case generation we combine symbolic
execution with model checking and
constraint solver solving and this
extension applies both to executable
models and to code and it handles
dynamic data structures as inputs also
arrays loops recursion multi-threading
and so on and it's generating an
optimized test suite that satisfies
garbage criteria is specified by the
user and it also reports coverage and
during test generation because actually
we use jpf as the underlying engine it
also checks for errors so this is a very
high level what symbolic execution does
so basically the systematic passed
exploration and during past exploration
we generate and solve marry constraints
and these constraints are gathered
basically from the conditions in the
code that is analyzed so this is a
little fragment of code very simplified
from some codes at NASA actually that we
analyzed so basically there is a
condition that checks if the pressure is
less than some minimum value or greater
than some maximum value then basically
do something abort the mission for
exactly because you are not in the
parameters otherwise continue or
something like that
so how would one test such a simple
program of course in a classical setting
you just provide some input for example
this value for pressure and maybe the
minimum and maximum values are defined
in the code and then you
the code and this will exercise only one
branch of the if statement well in
contrast with symbolic execution we do a
non-standard
execution that uses symbolic values
rather than concrete values so for
example for pressure it will use some
symbolic values and maybe also for
minimum and maximum and during symbolic
execution it also maintains the past
condition that is initially true and it
will be updated with the conditions that
are analyzed in the code so then for one
part that corresponds to the first
condition in live branch the past
condition will be updated with this
condition then the analysis engine
basically the model checker will
backtrack and explore another path
corresponding to this condition and then
again it will backtrack and it will
explore yet another paths and then what
we do we get these past conditions we
solve them and we get the test input so
now we will obtain basically three sets
of test inputs that will cover all the
paths through the code this is at a very
high level what is going on here and I
listed here are some applications of our
techniques so actually this summer we
have been working on testing some NASA
control software and basically this was
a not piece of software which was not
very large maybe six hundred lines of
code but it had very complicated
conditions for example the path
conditions that were gathered by our
analysis were up to sixty constraints or
something like that so manual testing is
time consuming for them it took one week
and they could not obtain full coverage
we also perform some guided random
testing and again we could not obtain
full coverage but with our techniques we
were we generated about 200 tests to
obtain full coverage and I'll talk a bit
more about
this example in the end at the end of
the talk and this the total execution
time was less than one meaning and
actually they used our test suite to in
regression testing to test an update to
their code and they found some major bug
in the design of the code so our test
should lead to some serious redesign of
their software so I listed here another
application so so the first one in some
sense these are some white box testing
we generate code from the we generate
test from the analysis of the code but
we can also use our techniques in a
blackbox fashion for example we apply
these techniques for testing a rover
executive developed at NASA Ames so this
is a piece of software that receives
plants which encode commands for a robot
and then it sends them to the hardware
too and also it monitors the execution
of these plants and the environment and
it can abort the plan and so on and
basically for this application we
encoded the grammar for the language of
this for the planning language and we
also put some symbolic constraints on
this grammar and we were generating
plants test plans for with this
technique to test the actual software so
this is a black box application and
again this all of these applications are
documented in papers that we wrote and
we also have some testing for generation
techniques for java classes again in a
black box and white box fashion and I'll
talk a bit more about this at the end of
the talk so this was a basically a
high-level overview of our tools and our
applications and now I will try to go a
bit in more detail
in describing more details about our
techniques so I will start with symbolic
execution which we did not invent it was
King we invented it in the 1970s so
basically it enables analysis of our
programs with unspecified inputs and as
I already said it executes a program on
symbolic rather than concrete input so
hence symbolic states represent sets of
concrete state and for each pass the
analysis maintains the pass condition
that basically encodes the condition on
the inputs for the execution for you to
follow that particular path and also
usually one during this analysis needs
to check for the past condition
satisfiability and if it becomes
infeasible it means that the current
pass is no longer feasible so the
analysis should backtrack and I did not
put it here but but in essence symbolic
execution computes the pre and post
condition of a piece of code so one
could also use this for some other
analysis we had the discussion at lunch
about that so a symbolic state now has
symbolic values and expressions for
variables also a past condition and the
traditional program counter and also
some thread scheduling information in
case of multi-threaded programs so this
is a bit of a small example that again I
want to contrast standard concrete
execution to symbolic execution so on
the left hand side we have some code
that takes two inputs x and y and they
are swapped if X is greater than Y so
this is the code that swaps x and y and
the here we check on assertion and the
idea is that this assertion should be
unreachable because we did this swapping
when X was greater than Y so if this was
successful this statement should be
false
so again with a concrete execution we
would start with some concrete values
for example one and zero and we would
get a concrete execution trace now in
contrast with symbolic execution the
result is no longer a trace but rather a
tree so this is basically the result of
symbolically executing this piece of
code so initially the past condition is
true and big legs and big y are the
symbolic values for the inputs then at
the first if statement the analysis
considers both branches and on one
branch the past condition is updated
with this condition and on the other one
with the negation of it corresponding to
getting into this part of code and again
here the past condition is updated and
notice that for the case corresponding
to the assertion being reachable the
past condition becomes infeasible so we
use off-the-shelf decision procedures to
check that so basically we will get that
this assertion is unreachable so now
traditionally symbolic execution was
defined for programs that get a takes K
yeah sir yeah
theoretically this one
however you
kamakrazee walking ex and
yeah this is a simplified view in
reality in your analysis you can start
with a part condition not true
but rather for example for in order to
model overflow you would put some ranges
so then you start with a non
precondition or if you want so you need
to encode this extra logic to purchases
so this was just an idea and there is a
lot of work to encode that chance but
it's possible so it's theoretically and
a lot of people are doing this so this
is a well-known technique so now what as
I said the symbolic execution is a
worked traditionally for scalar data and
it usually has a problem with
concurrency and what we have done among
other people was to generalize it to
handle now besides the inputs or reals
besides the integers or years as inputs
also data structures for example how
would we handle if how would they
analyze the method if the input is a
list or a tree or a graph also how would
we handle a race and so on so our
framework handles all these features
here and basically it handles
concurrency and arbitrary control flow
for free because jpf already handles
that so in particular for dynamically
allocated data structures and arrays we
use a technique that we call lazy
initialization but this is the thing to
basically lazy evaluation so we start
the execution with uninitialized data
and we lazily initialize the heap with
as needed by our analysis and I will
give some examples and again I put here
some papers that document this work and
as I said Java Pathfinder is used to
generate and explore the symbolic
execution tree and we also handle
aliasing in the input data explicitly so
basically we enumerate all the
possibilities in the input and I will
show an example and we use off-the-shelf
decision procedures to check for past
conditions and as I said the model
checker basically backtracks if the past
condition becomes infeasible and as you
mentioned of course there is a lot of
approximation happening and a lot of
imprecision getting from the past
conditions and you can take different
decisions if you don't know enough
information you may choose to continue
to explore the past or maybe you may
backtrack in case of testing for example
where you want to be guaranteed that all
the inputs exercise the code and we can
talk more about that offline there are a
lot of design decisions but about what
to do and I'll also talk a bit about
more advanced techniques that basically
perform sub sub sub sumption checking
and abstraction for the symbolic state
so now I let's look at another example
that now has as input a list so class
node implements a singly linked list LM
is the element in a node of the list the
next points to the next element in the
list and swap node basically swaps the
first two elements in the list if the
first element is greater than the second
one this is the idea and now let's
assume we want to analyze swap nodes so
the implicit parameter to this method is
the one pointed to by this so this is
what we do here and these are the
results of our analysis so basically we
will output seven configurations and
each configuration corresponds to one
pass through the code and because
actually we don't have a loop here
because I'll talk a bit about that so we
have a complete analysis here so for
each input list we also perform the
put least as I said symbolic execution
basically computes a summary of a method
in terms of the input and the expected
output a symbolic summary of a method
and these summaries could be used for
many other applications not just for
test case generation and we've done some
work on that and other people also did
so here question mark means that the
element stored in this heap node is
unconstrained so it doesn't matter for
this execution and also this yellow blob
means that again the next field of the
second element is unconstrained so the
analysis did not reach that point it
could be null it could be a new node
another node it doesn't matter for this
analysis and now the I also want to tell
you that
for example we also checked properties
during this generation so I assume we
did not have this check that next is not
null and then our analysis of course
will discover this null pointer
exception so now I will illustrate I
will just give a bit more intuition
about this lazy initialization so let's
assume we want to execute this next
equals T dot next and this is the
current heap configuration so we have a
list with two elements T points to the
second element and the next field of e1
is unconstraint undefined so what our
analysis will do it will first try to
initialize this blob to all the possible
values according to all the aliasing
possibilities in the input and then it
will apply the standard Java execution
so this is the idea here so for example
here we will have four possible
configurations one corresponding to null
another one to a new node with
unconstrained elements and then also for
two configurations corresponding to some
circularity
the input list and then as I said it
will it will apply the normal Java
semantics so now because next is
initialized it can do next equals T dot
next because T dot next is defined and
again I'm doing a bit of hand waving
here because for test input generation
we also need to maintain some mappings
because you have destructive updates so
you need to reconstruct the input lists
in order to present them to the user to
reproduce this information but we can
discuss a bit more about this offline
and another feature of our analyses that
we can handle preconditions so instead
of starting the analysis with the true
precondition meaning the inputs around
constraints one can for example specify
as a precondition that the input list is
a cyclic and then these two
configurations would not be possible so
our analysis will check that and it will
not consider the past following these
configurations again this is a bit more
complicated because so when you have
this we call them complex preconditions
that go iteratively through a data
structure things are not that simple so
we do some approximation and in some
cases our and Isis will continue from
here so we can talk a bit more about
this again offline so this is the result
of applying basically neck's equals T
dot next so now we talked a bit about
the implementation so our initial
implementation was first done by
instrumentation basically by a source to
source transformation and the idea was
that we replace the concrete types with
symbolic types and concrete operations
with symbolic operations for example
instead of integers we would have class
that handle symbolic integers and then
we would replace plus minus all the
operations with method calls
implement these operations and again for
field operations we would replace
certain getting next for example with
this lazy initialization algorithm and
then this the advantage of this is the
the generality in principle one can
apply then any model checker to perform
this analysis or it or one could simply
run Java and get basically symbolic
execution along one run so we also I'll
talk a bit about the decision procedures
that we used so we started with the
Omega library for integer linear
constraints and then we have one of our
students
that's what Anand developed commonly an
interface a general interface to several
decision procedures and we have
interface with some other decision
procedures and our idea is to basically
plug in whatever different decision
procedures and solvers to our and Isis
or the user could customize them
depending on the application domain now
I'll talk a bit about state matching so
actually performing symbolic execution
on looping programs may result in an
infinite execution tree so what one can
do is especially since our goal here is
testing is to perform search with
limited depth or to put a limit on the
number of constraints along one path or
maybe to imply link limit for example
the hip nodes in the inputs or things
like that but we have also investigated
a bit more advanced techniques that
basically perform subsumption checking
so the idea is now as I said a symbolic
state now represents a set of possibly
infinite set of concrete States so then
you need to check some logical
implication between these symbolic
States in order to perform this analysis
and the idea is that once you did
so during model checking you would store
these symbolic states and then when you
generate a new symbolic state and you
see that it was subsumed by an already
stored symbolic state the modern checker
can safely backtrack because it means
that the previous run already covered
for the successors of these runs so this
is how one would use state matching or
symbolic subsumption in this case during
model checking and yes so I'm not sure
if I should go into a lot of detail here
but basically what we do we normalize
the heap so basically the state of a
java program contains the all the heap
information we normalize it with a desk
for search traversal and then we obtain
some unique labeling for some matched
nodes and reach a logical implication
between numeric constraints and I can
give an example just to give an idea but
again we we will need to talk in more
detail about this so let's assume that
this is the start state and then the
model checker may be went on a different
path and generated a new state and as I
said the goal is to see if this new
state is somehow covered by the old
state because then it means that it can
safely be discarded in our search and
what we do here is as I said we first do
these dispersers traversal and we try to
match the nodes in these two graphs and
this yellow blob basically as I said it
means that the heap is unconstrained at
that point so of course it can be
initialized to this sub graph so this is
let's say the intuition why these two
structures match and also we do some
normalization of the data stored into
the heap to also check logical
implication into the data that is stored
into the hip so now the problem is that
even with
substantial checking this is not enough
to ensure termination because we might
still have an infinite number of
symbolic states so one needs to also do
some form of abstraction to further
limit the search space and we have
implemented some automated support in
Java Pathfinder for this basically the
idea is to store now abstract versions
of the explored symbolic state so
basically they are like compact
encodings of the symbolic States that
maybe lose some information but
hopefully they are enough to maybe
obtain good coverage of the code and
then we use subsumption check into the
determine if an abstract state is
revisited and again based on this we
decided the search should continue our
backtrack so this analysis is no longer
complete it explores another
approximation of the real program
behavior so now we are more into in the
testing domain we might miss some errors
but so the the state space that is
explored in senses depends on the
quality of the abstractions that we use
but as I said these these stills possess
errors to the properties that we are
interested in and it's useful for
testing and we have automated support
for two abstractions one is for singly
linked list and another one for arrays
and they are called shape abstractions
they are actually inspired by the
working shape analysis there is a tool
DVLA for example at Wisconsin that
performs shape analysis so the idea is
to to preserve some information about
the heap the shape of the heap and maybe
throw away some other information that
may be some the values of local
variables or to summarize some this is
the high-level idea I'll give an example
so in these particular abstractions for
list
the idea is to summarize contiguous list
elements that are not pointed to by
program variables into so-called summary
notes notes and also the data the
numeric values that are stored in these
nodes are also summarized basically now
a summary node will encode the union of
the values of the notes that were
summarized and then we apply some
sumption checking to these abstracted
heap structures that have this
summarized nodes and we also defined an
abstraction for a race that uses this
singly linked list and actually people
in the shape analysis area so this is an
active area of research and there are a
lot of abstractions defined for more
general graphs that have some
constraints and our idea is to borrow
those abstractions into our analysis
what they do usually is an over
approximating analysis so they try to
cover all the possible paths and maybe
too many because of this but we use them
in this non-standard way so this is just
an example of the usefulness of this
abstraction so let's assume we had on
the left hand side a symbolic state so
again it has it it is represented by
some heap configuration with some
unconstraint data and also some
constraints on the values stored in the
list and then let's say that the model
checker explored generated another
configuration maybe on another past and
actually our initial subsumption jetting
algorithm will find that these two
structures cannot be matched basically
because here we have one node between so
we distinguish between the first node
pointed to by this and the third now not
pointed to by a local variable and for
example while here we have two nodes
that are in between this
but with shape abstractions we can
actually say okay we don't care how many
nodes are between this and the 1.2 by n
so we put them together here and
suddenly our sub sumption checking
algorithm will match them so at this
point we the model checker will be
instructed to backtrack not to consider
the successors of these days well this
is very technical but let's see some
results for these techniques so I'll
talk a bit about some applications of
this JP FSC jpf symbolic execution
extension so we have some experiments
reported in some Easter papers that
basically apply these techniques in a
blackbox fashion so the idea is to
encode the so-called classic variant as
a Java predicate and then to apply our
techniques from that java predicate and
the result will be to generate different
different structures that satisfy the
class invariant also we apply them in a
white box fashion so now we run symbolic
execution directly on the java methods
and use the class invariant as
preconditions and we compare these
methods in this paper and we also
performed work on test sequence
generation and I'll talk a bit more
about this later now as I said actually
symbolic execution is a general
technique that can be used also
improving program correctness and we
have played a bit with generation of
looping variants for it and actually
again at lunchtime we were discussing
about so this technique so in some sense
the symbolic execution gives you for
free specifications to check so you can
apply it and you would get the
preconditions and postconditions and
just
then just stick them in the methods that
you want to check out the surgeons and
now you have a contract for your class
and this could help later with testing
or regression testing and things like
that so this could be another
interesting application and also we
applied them to our detection in
concurrent software and also in testing
for generation for some flight control
software that I talked to the beginning
so this is a bit of information about
the sequence generation for Java
containers so we analyzed for containers
meaning namely binary tree fin Bonacci
heap binomial heap and three map and now
all of these our results are available
with the jpf distribution and actually
now a lot of people use these examples
too as a benchmark for their testing
techniques so what we aimed here was to
explore method called sequences with the
help of Java Pathfinder and to match
States between calls to avoid generation
of redundant state tests okay sorry to
mistakes and also we are experimented
with performing after matching on the
shape of the containers so here we did a
simpler abstraction than the one that I
described where basically we just
compared the shapes of these containers
between method calls and we threw away
the numeric data encoded into these
containers so basically the output of a
technique is the sequence of this form
so first you would create the binary
tree and then you would add two values
and maybe remove one so this is a test
case now for us and we just checked for
the default properties that JPS checks
like no runtime exceptions thrown
so we perform the comparison between
explicit state model checking also with
some symmetry reduction meaning with
some reductions that are encoded in jpf
to take advantage of the symmetry in the
heap of the program that is analyzed we
also applied symbolic execution with
subsumption checking and also symbolic
and concrete execution with abstract
matching and we also compared everything
with random testing and for coverage we
compare these techniques in terms of
statement coverage so basically we
measured how many statements are covered
in the code but also we considered a
more sophisticated coverage namely
predicate coverage which was introduced
by Tom ball from Microsoft so the idea
there is to get some predicates from the
conditions in the code and there and try
to cover all the possible combinations
of those predicates so this instance is
mimics a bit it's harder to achieve it
tries to to stress the techniques to
cover more of the state space of the
programs being analyzed so our results
were the symbolic execution work better
than explicit model checking and
actually that model taking the shape
abstraction gave the best results so in
we infer that at least four containers
just maintaining the shape of them is
good enough to obtain very good coverage
and this is not surprising because
obviously the shape of a binary tree
would give a good indication of the data
that is stored in the binary and also it
was interesting that actually random
testing gave pretty good results but it
requires longer sequences to achieve
good coverage and now there is actually
a debate if longer sequences are better
than shorter
Quincy's and yeah we need to investigate
more which one is good for testing so
I'll go back a bit to that example that
I talked at the beginning that was for
test input generation for NASA software
so this was an example which I said
although it was not very large it had
very complicated conditions so random
testing performed very poorly there
since um since it was the ideal
application for symbolic execution that
tries to go systematically through all
the conditions and so basically this we
checked this abort logic that has a lot
of conditions that encode the so called
flight rules and if these flight rules
are violated the logic is supposed to
issue an abort and basically we
generated as I said two hundy test case
is what was interesting is that they
were we were also able to customize the
coverage that they want so for example
they were our collaborators the
developers of this code were interested
in covering all flight rules and the
board combinations and the point is that
one can customize what kind of coverage
wants to do with and pretty easily with
a listener mechanism in jpf and another
point that I wanted to make is that we
want to work on integrating this
symbolic execution based test generation
which is in essence a unit level testing
technique with end to end simulation and
so the problem with applying this
technique is at the unit level is that
often the input data is constrained by
some information from the environment
from the rest of the system for example
for this code from last room for the
abort logic we generated the test case
where the inertial velocity was
240,000 fish per second and the attitude
was zero and our developer collaborator
joked and he said it must have been a
really bad day because it's impossible
to have this so physically it's
impossible and actually in the hope that
we just analyzed of a small very small
portion of the whole system that encodes
physical models that would have this
constraints so what we want to do is
actually to perform some end-to-end
system level simulations and to learn
these constraints and then to put them
as preconditions into our analysis and
we are working we have a collaboration
than we are working on that and actually
we have some initial results so
basically we were able to eliminate test
cases that were impossible to these
physical laws with this analysis okay so
I've just list here quickly some related
approaches the one is a core a tool
developed at MIT and actually safra's
cruciate was a summer from there was a
summer student and we started with him
this project in 2003 but Karate is
applied as a for blackbox test
generation so basically what we did in
some sense is a generalization of that
tool then there is another popular trend
which performs so-called con colic
execution so the idea is that you run a
program on some concrete input and
during that concrete execution you dolls
also gather the symbolic constraints so
basically you do a symbolic execution
analysis along one pass and then you
take the constraint you negate one
conjunct in the constraints solve them
and then you get inputs that will steer
the execution towards another part that
will exercise different parts of the
code and so on and this was started by
patrice got frog who is now to Microsoft
and also koushik sent who is at Berkeley
now and there are several different
approaches that
to do that several different tools for C
and Java that perform that we also had
another approach that is similar to what
I presented here that basically performs
concrete model checking with a different
form of symbolic analysis which is
called predicate abstraction and
refinement but I will not go into
details with that there is another tool
which is called seamstress
that again performs some symbolic
execution with subsumption checking
between method calls then Dawson angular
at Stanford also basically works on this
kind of con colleague execution and I
listed more approaches here
so now as current and future work we
have this summer we have worked on a new
symbolic execution framework which no
longer uses code instrumentation so
basically it was moved inside jpf and it
works by a non-standard interpretation
of byte code so we have an extension
that performs the for each byte code
performs the symbolic analysis that we
discussed and actually the symbolic
information is propagated via attributes
associated with program variables the
operands on the stack and so on and this
is quite nice because actually with
those attributes you can encode other
analysis now you can propagate whatever
information you want and actually this
is also used for checking for example
the runtime errors and things like that
and now we use another decision
procedure that I found on SourceForge
and did it's called Chacko and the
advantage of it is that is pure Java so
it's a good it's good for development
because now many people work on this
framework so it's easy to it works on
any platform so this is what we use and
later we want to integrate the other
decision procedures for it end
chocka actually handles both linear and
nonlinear constraints and also integer
and real constraints but of course it
might timeout it has the inherent
limitations decidability limited and
everything is available from Java
Pathfinder and now basically it's a
push-button technology and as I said one
can use these techniques a symbolic
execution not only for testing but also
for other analysis so this is another
characteristic of our this new framework
is that for example symbolic execution
can be started from any point in the
program so basically you could simply
execute your program and have all the
concrete information at some point
decide to do it symbolically and this
has the advantage that you may still use
some concrete values from the context
because you may pick which values to
become symbolic so let's say for a
method you would decide to use symbolic
parameters but all the global
information will be concrete so this
would give precise information about the
context and as I said we are working on
integration with system level simulation
where we want to basically perform Monte
Carlo simulations to obtain ranges and
actually constraints for the input also
we have Peter one of my colleagues at
Ames has a recent extension jpf
extension that models UML state charts
and of course our techniques supply for
free there and we are also working now
on using symbolic execution to help
regression testing so the idea would be
that you tested your code and now some
parts were changed so we want to
identify which code was changed and then
generate tests only that exercises that
change and of course one could apply
symbolic education product and to do
more applications okay so thank you this
was mine
we have hope I did not confuse these
people oh so when you Perdue when you do
the test sequence generation I was I
didn't completely
staples yeah I'm all very touching yeah
so basically there we did something very
simple
we created a driver for Democrat finder
that basically non-deterministically for
example in this case we'll call add and
remove and then after each method call
we would try to match the state of the
container so we would have an
abstraction that basically we would not
do state matching inside the method but
just outside so after an ad you would
have a new state for the three that will
have one element after another ad will
have three with two elements but after I
remove you'll have you go back to one
element which you already explored on a
previous path so this is this was the
idea yeah it yeah and then with the
state matching as I said in some sense
the values that are added were not that
important so it was enough just to match
on the shape of the tree extraction on
the shapes
showed immediate notes at one point
that the choir know so here actually we
do not even summarize we just threw away
the numbers and that's it and it was
good enough so very rough abstraction
actually performed the best out of all
the techniques so some of them were very
complicated for example three map well
yeah I I don't have the results I didn't
have time to put them and now I forget
forgot exactly just that it was a
challenging to obtain good coverage for
these containers yeah yeah and they call
a lot of these were the public method
but they call a lot of bother
yeah so this is the idea to try to cover
add and remove ugh it's a pretty simple
problem happy but it's difficult to in
practice so
the runtime characteristics of the tool
how scalable is so how yeah good
question we are first putting it into
place but as I said it's basically it's
a unit it's a unit level analysis tool
this is what I believe and I think with
these features that basically you can
run your tooling we can also turn on and
off the state matching so you can maybe
just launch the tool and go deep into
the state space and then do this
detailed analysis we think we might get
interesting results but of course
scalability is a problem so that's why
we also want to combine it with this
Monte Carlo simulations to have precise
unit level analysis this is what I would
like how I would see it useful so
the 600 line called exemplary center
small but what's the largest codebase
and the second question is did you use
the troll to analyze the implementation
this is a classical question but we
didn't because as I said this is good
for unit testing I think so if you have
complicated code but the unit level so
it's not if you have millions of lines
of code then you should choose to to
focus on something that bothers you or
not applied to the whole so in some
sense I could claim okay we can launch
Peter applied jpf - I forgot with your
big applications that had the millions
of lines of code but then what I could
do with this and as it would be to focus
it on some portion inside it that maybe
is problematic for example for this
small portion that is again part of a
big simulation environment for them we
were able to generate very interesting
test cases that led to some redesign
even of other parts of the code but yeah
and yeah it didn't apply to jpf I think
Willem actually applied some static
analysis to G here but this is a
different level it is a very detailed so
it wouldn't scale to millions of lines
of code although again we want to so
first of all we want to put this in
place we are working on integrating
chauka for reals it calls it but you can
set the precision and you have to play
with a lot of parameters also with the
timeout sometimes the decision procedure
doesn't come back and we would like to
allow the user to customize that and
then one can for example there are
approaches that try to scale this with
some compositional analysis so you would
apply let's say symbolic execution to a
method or a procedure computer summary
meaning the inputs and the outputs the
input-output mapping and then when you
analyze the program that calls that
procedure you just plug in the summary
or things like that
so one could do that but we didn't
so there is still a lot of work but what
works now is at the unit level actually
it works well so this is thinking about
scalability we did a test generation
you're matching the state of the
basically the example container that
you're trying to test so you have this
query and you're trying to you know add
things to it generate all these
different
and in your matching on your state
matching is on the shape of the tree
that comes back after each operation so
it's that your entire state space and
that your story is very sensitive for
example for sequences oh I forgot now I
don't have the slides but four six
sequence is longer than seventeen or
something with that were needed to
achieve some deep coverage all the tools
would chuckle and chuckle this is the
good joke and random testing could not
cover so you need to go this extra step
- if you really want that coverage okay
if you don't care it's fine and very
comprehensive the constraint solver I
known another constant just the sheer
complexity if you have for example three
map and you have a history of seventeen
methods that was completely it is
already very complicated for college yes
to run out the moon and actually all the
techniques so now a lot of people it's
an active area of research and they use
this as a benchmark - and you see it's
very difficult to obtain good coverage
maybe it doesn't matter yeah you don't
see this fear yeah I I don't have the
river yeah I think I forgot now but it
depends always if you do the abstraction
maybe we went to 20s so for some I don't
have the data now and I forgot now a bit
but for some coverage this predicate
coverage that we define you needed
longer sequences that for that you could
obtain only with this abstract matching
so this was the best in deeds that you
could do but yeah
but yeah it of course it's also an
implementation issue the the truth is
that for example no other people built
after us so we still use a
general-purpose model checker and for us
it's a good research tool but other
people build dedicated tools for example
just to generate test sequences and they
are of course better in terms of they
are no they run faster they just don't
maintain all the information like JPL
does but just let's say maintain some
good encoding of the abstract state
between method calls for example seem
strong does something like that the to
log Tao so if you would have a dedicated
tool then it would be it could be
improved obviously but for us this is a
vehicle to experiment with different
techniques so okay
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>