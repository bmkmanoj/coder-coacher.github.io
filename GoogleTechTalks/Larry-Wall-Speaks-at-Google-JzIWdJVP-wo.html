<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Larry Wall Speaks at Google | Coder Coacher - Coaching Coders</title><meta content="Larry Wall Speaks at Google - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Larry Wall Speaks at Google</b></h2><h5 class="post__date">2008-08-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JzIWdJVP-wo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I often get get this sort of question
over the years I've gotten it many many
times usually from people interviewing
me for a magazine if you had to do it
all over what would you do differently
and there's really only two good answers
to that one of them of course is nothing
and that was the purl answer for many
years and the other good answer is
everything and that's more or less the
Pearl six answer when we decided do
pearl six we decided on the one hand to
clean up a lot of the cruft no we
decided to clean up follow the craft for
our definition and so in particular you
know when Pearl started out it was you
didn't have a following of course so I
had to borrow a lot of UNIX culture into
Pearl and a lot of that culture was
already crufty namely regular expression
syntax and we only made it worse so that
was part of our mandate to clean that up
but on a deeper level we we didn't just
want to fix the syntax we wanted to fix
all these there's the fundamental flaws
in that in the think O's and the design
O's so one of the major bad decisions
that I made early on was to treat
regular expressions as a kind of string
instead in Perl 6 we tried to treat them
as a kind of language more specifically
a sub language and I'll get into what I
mean by that
here's a statement that you could make
in either Perl 5 or Perl 6 but they mean
somewhat different things declare a
matched variable and initialize it in
Perl 5 it treats this as a string and
interpolates that variable and then it
reparse --is it as a regular expression
that's bad in Perl 6 it's just a
language and
we'll see how that works as we go along
but it only does one pass of parsing and
it treats it as a sub language so when
is the language not a language well
actually when it's many languages and so
what we've discovered was with the Perl
6 effort is that Perl 6 isn't a single
language you know Perl 5 is one language
that's how we thought of it we're
thinking that Perl 6 is many languages
or if you're British Perl 6 are many
languages but in Perl culture we don't
tell you how to think and people think
in different languages well actually we
want you to think that we do tell you
how to think we just don't tell you what
to think well we do that too oh well and
what you should think is there's more
than one way to do it which is one of
the Perl slogans and that's my nickname
Tim toady is a pun on that but one of
the things that has always been the case
with Perl is that you're allowed to talk
at different levels of linguistic
sophistication we don't expect a
fifty-year-old to speak with the same
diction as a five-year-old or vice-versa
so you're allowed to do baby talk and
you're allowed in fact to do cargo cult
programming at the beginning you don't
necessarily have to understand it you
just sort of put the things there and
bow down to them and they do the right
thing and later as you're going along
when you have to change it and it
doesn't work you have to learn why it
didn't work and then you start learning
the the underlying um semantics
but I would like to say or at least
assert today that the computing culture
as a whole as has gotten stuck in a
level of cargo cult thinking with regard
to parsing instead of that I would like
to think in terms of derived languages
where we don't copy and paste our
compilers oh I want a new compiler I
let's I want it to be kind of like that
one so I'll copy the Yak grammar over
and then I'll start tweaking it instead
we should do something a little more
modern modern you know polymorphism
isn't that modern but it's modern er
than cut and paste so when you see a we
want to parse something like this
instead of instead of a standard parser
where you have a yak grammar that's kind
of fixed and and just there's there's a
special rule for for this and on you go
you know there you see some
commonalities here this this is a
different language than that than the
outside of it so when you're when you're
parsing at this point you want to be
parsing against a different set of rules
than when you're out here on the other
hand when you're parsing a variable
you'd like them to be the using the same
rules you don't want to duplicate rules
likewise well likewise if you're if
you're going on to to use double coated
strings that do interpolation here's a
language where dollars means something
special and backslashes means something
sub special if you change it to two
single quotes it's a different language
and that's the way we are choosing to
think of it here so I bypass this little
thing here which how we're doing this
regular expressions are in fact derived
from the Perl grammar here let me
actually show you the prick let me move
this a little closer to the other space
here 12 okay
here's the the standard pearl grammar
don't worry about the comments and read
if you can't see them now this is
actually written in Perl 6 and it's
probably nothing like any Perl 6 you've
you've ever seen before or nothing like
any Perl 5 you've seen before if you've
seen pearl 6 and it'd probably be
something like it but it has grammars
that are essentially just classes so if
I go down here and find the rate write a
regular expression grammar it is derived
from the Perl grammar and it overrides
some of the methods and off you go
here's another example let's go back to
when you're parsing quotes here such as
those single and double quotes you just
saw here's the double quotes find a find
a double quote call this special rule
that is parameterised as parameterised
on the language that you want to parse
inside take start with the base Q
language tweak that to have double quote
semantics tweak that to have a
terminator of a double and a double
quote and parse that and then look for a
terminating double quote the actual
nibbler regular expression using the
term loosely is right here and so this
is going to loop over all the characters
first it's going to if it finds a a
whatever the stopper is which in this
case double quote and then it quits if
you're doing nested bracketing sort of
quoting it's got to find a starter and
keep the nesting straight and calls
itself recursively if it finds an escape
which is like the dollar signs the back
slashes it handles those two but again
it's polymorphic over whichever language
you're dealing with and finally at the
bottom just grab another character and
and add it to the text so that that's
one aspect of it another words that I'd
like to describe is called transitive
alternation here's another rule which if
I uh
yeah
I actually show it here
it looks like that in long-form it's got
a label on the front of a statement and
since various modifiers but in essence
this is doing this it says a statement
is composed of a statement control or an
expression or just a bear let me call it
well but that can be expanded out an
expression starts off with a term and we
actually have a an operator precedence
parser sandwiched in the middle of a
recursive descent parser and that is
that is what the the operator precedence
parser is going to look for first so
that's what that really means in terms
of what we're looking for at that moment
the exact language that we're matching
well but that expands out the if you're
looking for a term you're looking for
some sort of prefix or a noun and that
expands out to various kinds of nouns
and prefix operators and on you go the
point of this is that that purl fives
alternation the vertical bar is not the
same as purl sixes in purl 5 you know in
the purl compatible regular expressions
that everybody is borrowed it means
check the left thing and if that doesn't
match check the right thing it's like a
short-circuit operator instead in purl 6
we go back to sort of the the original
definitions of irregular expressions for
DFAS and single vertical bar is is
parallel matching of all the
alternatives simultaneously and then we
then we use the double vertical bar much
more consistently for the serial
matching but the question is who wins
when there's a conflict in these
alternatives is the first the oldest
newest is it a core rule that should
match or easier to find the problem with
the core is Perl 6 is got this little
problem if you're going to define it
that way is in that it has no core Perl
6 has no keywords to the first
approximation and it has no built-in
operators
instead everything is is built up out of
out of these rules you can think of the
entire Perl 6 language as just the
result of matching a fairly fancy
regular expression against the string so
this is the way you define sub rules and
so the built in operators like + + + + I
just come in that way should
user-defined operators take precedence
over built-in ones well maybe if I
define my own prefix symbol like + - I
can do that ok let's try it here you
know there there there is no there's no
+ - in the standard grammar here but if
I have a grammar that is derived from
the one you just saw and I define a
token + - I can actually use that
and up here we see that we get good as
actually get a symbol plus - that's a
prefix operator so that actually you
know works rather nicely but and that
obviously it takes precedence over it
over the plus operator so it doesn't
parse that as plus and then a minus and
then that on the other hand is suppose I
define an infix cm operator you know
maybe it maybe it compares to Roman
numerals to see if they're 900 apart or
something like that
all taking your afternoon nap huh
caffeine works wonders well should
easily defined take precedence well
probably not because if there's a pee
after it you probably want to do the
comparison operator instead I wanted to
do what I mean which usually means that
I want longest talking magic and we talk
about this so much is just short
shortened to LTM but you know longest
talking matching is is great but what
about how does how does that play out
with all this polymorphism because
polymorphism means very light binding so
what it comes out to is that we need a
just-in-time lexer for every language
now we're considering the inside of
quotes and regular expressions to be a
different language so it has to create
those languages let's see I already
showed you the plus/minus pearl sort of
mini language and where'd it go here but
when I ran that it actually Malec sirs
here you it's hard to see but there
there's a standard pearl lexer and
there's a plus - pearl Lexor they're
just kept out as a handy cash it could
be all in memory so if I go down to Lex
and plus - pearl and look here let's see
yeah just in time Luxor okay so there is
let's see it's a prefix operator so
let's look at see what
under the prefix operators that
generated this this Luxor here and we
see right up to the front here is our
plus/minus operator that we defined in
our derived grammar plus all that all of
the operators that came in from the
standard grammar this part of it can be
matched by a DFA engine with the longest
token semantics and once we do that it
immediately knows as soon as it matches
that what the next few steps are in the
recursive descent parser so it doesn't
have to decide anything it just cascades
down rapidly and I wish I had more time
to show that to you but then I couldn't
tell you about the other cool stuff so
you know there's an old saying only Perl
can parse Perl and it sort of extends to
Perl 6 as well it's not it's only
slightly true because we're actually
bootstrapping it in other languages but
we can at least modify it too it's
easier to parse Perl 6 in Perl 6 the
fact is all of these regular expressions
if you scratch them they're just methods
it relies on multiple dispatch semantics
and this concept of short and long names
where if I say match a prefix that's the
short name of a rule but it's really
standing in for a bunch of long names
where it's prefixed this prefix that
prefix the other thing this auto lexing
with the transitive alternation all
these every time you come to a new
alternative it hoists all these things
up and builds a new lecture if it needs
to for that and all the alternatives are
considered equal all the way down
there's no first class second second
class operators no built-ins vs.
user-defined
it's all on equal on an equal footing so
when you when you see this this sort of
an alternate alternation it all just
works out and it keeps hoisting it
upwards so
so well the well we saw the Akiko in the
wrong direction it's because I had it
the other side before I can fix that
excuse me
okay
if we go to the standard pearl looks
here here and look a statement did I use
the statement
I did not so let's uh saw you improve
its generating it on the fly here I will
I will parse a one of the tests out of
the test suite it's about eight thousand
bytes that parsed in about four seconds
so it's doing about with no special
optimizations about doing doing about
two thousand characters a second at the
moment so now if I go back to Lex
or I'll let's see what we have okay now
we have statement one which is the first
alternative inside statements and we can
see all the statement controls at the
front they're just like the rule has if
we go on down we see the terms that
start off an expression nouns keep on
going down more nouns more nouns prefix
operators and this is hosted up that
lexer into the ends of the higher-level
lexer
we're doing that time okay time flies
now of course I'm going the other
direction don't have time to talk about
back off on longest tokens it's just a
form of backtracking
but the Thais are reserved by the order
they came they were declared the longest
tokens are by and large they're derived
automatically from the grammar that you
write it knows which things which
matters have side effects and which ones
don't and the ones that have side
effects terminate your longest token
matter but you can explicitly use this
this symbol which is both a backtracking
control and essentially means this is
the end of the token if you don't match
after this it's an error and these are
all sorts of other things that Perl 6
provides which I don't have time to talk
about that but they're the sort of the
the boring things that that are very
useful in writing a grammar I'd like to
talk more about the handy stuff about
putting the regular back into regular
expressions and about how we've powered
them up while we regularize them and
yeah we we expect people to steal these
regular expressions like they did Perl
5s regular expressions that's great I
talked about the difference between
those gotten to handy new back back back
mattress for horizontal and vertical
work whitespace how often do you want to
just say well I want them I want to
match whitespace but I don't want to go
to a new line if it don't match the new
light things like that in Perl 5 we
discovered the extent and extended
syntax which was white space between
tokens was wonderful for readability and
so wonderful it's it's now sort of
mandatory so you don't have to specify
it there's no more / s modifier because
you just you just ambigú 8 right there
in the regular expressions if you want
to match not a newline
you know backslash lower case n is match
a newline so
by the rule that we uppercase the
matches that are negated that's not a
new line and dot always matches every
character similarly we don't have modes
on the on the multi-line matching you
use a different token for matching the
beginning of the string versus matching
the beginning of a line within the
string and it's very readable because
right there you don't have to look to
the end of the regular expression for it
we've regularized all the brackets
friends are always for capturing that's
that's the same we stole in the square
brackets for non capturing bracketing we
stolen the curlies for embedded code
closures we call them because they
aren't I've stolen the the angle
brackets for all the other where most
the other meta notations in particular
character classes are demoted to being
inside of angle brackets because usually
in the age of Unicode if you're using a
character class that's wrong anyway
so we'll give it a slightly longer
Huffman coding and since we stole the
Curly's for the general quantification
then we have our new notation that's
much more readable I think and a cool
quantifier you can quantify not just
based on it on a range of numbers but
you can quantify saying as long as there
is a comma between these things match as
many digits as you can that's you're
probably bt+
to match a sequence of digits
word boundary operators that are
directional using fancy French quotes
you can you can now use all of the the
the all of the non alphanumeric
characters are now considered
potentially meta characters so you don't
have to keep a list in your head of is
this thing a meta character or not since
we are not doing interpolation like
strings we can we can match whatever is
in a variable literally which is the
right default unlike in Perl 5 in
particular back references match
literally so we don't have to
distinguish between back references
inside a regular expression versus
outside they'll now all use the same
notation lots of other just very handy
things that I don't have time to talk
about today okay but I really like
talking about some of them you know the
cool things the you know all these
languages that lets you add new
operators they sort of tend to make you
specify what the precedence level of
those operators is and for some reason
those precedents levels are almost
always numbers and to me that that's a
kind of magical constant that you
shouldn't be talking about so if you go
back and look at the standard grammar
here where we define our operator
precedence table somewhere here did I go
by it
I almost have gone past it it's so short
these days yeah there it is okay you
notice our precedence levels are
actually specified with strings here and
they just happen to end with equals
because that makes it very easy to add a
character replace the equals with a
different character less than or greater
than and add more characters on the end
and so you can go on forever inserting
new new precedence levels and you don't
actually specify these you just say I
want the same thing the same precedence
as a multiplication or I want it tighter
than exponentiation or looser than you
know an and operator or something so
that's that's one cool thing another
cool thing that we're doing in the in
the standard grammar here is recognizing
when people accidentally there's going
to be very easy for people especially
coming from 4:05 culture to use the Perl
type idiom when it has changed to
something more irrational so oops we we
checked check the various you know most
of the special variables are gone for
instance but if you say you know if you
use this variable dollar at and it
recognized it will say you dollar at
variable use of dollar at variable as an
eval error is obsolete please use dollar
bang instead
and there's lots of those inventors
there that's really excuse me it's a
pretty cool they also see some nice use
of the switch statements in here
which are not spelled switch and case
because that's talking about the
constructs rather than just using
natural functional words from English
one of my Elizabeth whist ik prejudices
another cool thing is meta operators
assignment operators and the gated
operators none of them are built in
they're all derived from existing infix
operators as appropriate so and if you
add a user operator in the appropriate
class you get this automatically get the
assignment operators or the negated
operators they go with that have
built-in reduction operator take any and
fix operator including user-defined ones
and put them inside at the beginning of
a list and it will apply that operator
between each of the elements of the list
hyper operators we have done a lot of
thinking about various notations to
support various kinds of parallel
programming and for you know vector
processing and parallel lockstep kind of
processing hyper operators take any any
existing scalar operator and say apply
it equally to both sides and it can do
that and there's various ways of
expanding out one side or the other if
if one of them is lacking in dimensions
these are all just met operators another
cool thing is the use of what we call
rolls some of you perhaps have heard of
small talk traits we've incorporated
that idea into purl with some with some
extensions and christened them rolls so
we also use that concept within the
grammar where's a good example okay yeah
for example when we when we derived our
quoting languages different quoting
languages have different sets of back
slashes for instance and here are here
are the the backslash sequences for for
double quotes
and there you can even define roles that
will take them back out again simply by
defining a role a rule with them that
gets mixed in to your grammar that just
has a failure and that hides the the
original thing so you can you can just
pull in these things as you will as your
as you're defining new languages with
different various sets of features
here's here's your basic cue role which
defines the essence of single quote and
none of this is none of this is
hardwired into your compiler anymore
okay ratchet and six space usually this
shows up as as the difference between
most okay if you if you write a normal
regular expression we see this as a
regular expression here then then it has
semantics more or less that you expect
this does the star here does
backtracking it's greedy it's gonna
match as many posts as as it can and
tried further and if they can't then it
backs off if you instead are looking for
a token then it turns on what we call
ratchet mode I don't see a good example
off hand here but in that case well
here's one okay we're looking for a some
number of traits to parse and in this
case it parses them all but if this
fails it's not going to backtrack and
try shorter ones that's what we call
ratchet sometimes it's called possessive
quantifiers and that's that's the
default within tokens rules are what's a
good example here the rules are just
like tokens except that anywhere there's
white space in here it also allows white
space within what is matching so it's
good for matching things at a higher
abstraction level so up here you're
getting more into sort of the the Yak
frame of mind and assuming that a lexer
has already dealt with the white space
are we doing on time here
okay I'll go about five more minutes
here and then we can have questions but
the the really cool thing that's going
on here is that for so long there has
been a this deep divide between the the
people who wanted to do DFA matching in
this pure computer science sense and the
sort of a lot of the practical people
who would like the NSA matching because
it gives them a great deal of power and
flexibility but you have to worry about
the order of things happen because it's
really a programming language not a it's
really a more more procedural than it is
declarative but all we have here is the
opportunity to mesh these in an almost
transparent way with the longest token
match or automatically pulling out
everything that is makes sense to match
with a DFA engine and it can run very
fast and then as it gets to a certain
point it switches over to the to the NFA
semantics which can have very parallel
powerful actions and very powerful
assertion semantics and most time you
don't have to worry about it it just
happens I think that's that integration
will turn out to be a quite a powerful
idea and we're still exploring the
ramifications on it we now just parse
the whole we swept in the whole program
we've got lots of memory these days and
almost never does the program exceed
your your amount of memory so we don't
you know pull it in a line at a time and
then count the line and somewhere down
in some rule or other we have to
increment the line counter and if it
gets off it's off you know we just we
know where our position is in the buffer
and if we get an error or something we
just count the number of new lines
before it and we know our line number
we don't even we don't even really parse
ternary operators here the the rule for
parsing the the ternary operator just
treats some treats that as a real fat in
fix operator that happens to have an
expression embedded in the middle and
it's a this this is calling into the the
rule that is the that happens to be the
operator precedence parser and as as
with any rule since they're all just
methods underneath any way they can be
parameterised and we've parameterised it
with the the the maximum precedence
level that's allowed in there and if it
doesn't get that then we know very
fairly accurately which mistake they
made you know they put an assignment
inside when it where it doesn't make
sense something like that and a lot of
this is it is designed to give a very
useful compiler to the end user to give
them a message where they don't have to
scratch their head for for five minutes
to try to figure out what went wrong
another
another notion we have here that has not
been thoroughly explored yet but is the
idea of suppose points as you're going
through and doing a parse oftentimes
you'll come to a spot where you say well
the right way to parse it is this but it
looks like they might have made a
mistake here I don't know if they did or
not they might mean this so we will
suppose that that they knew what they
were doing but we'll remember this and
if some somewhere later on we get a
panic and and start and and we got a
parse error it's going to come back to
here to this suppose point and it's
going to say well what if they had
written it the other way so we do a
hypothetical parse at this point going
forward again and if it gets further
than we did before we can be almost
certain that that is the mistake they
made
now we don't go as far as a lot of the
compilers in the 1960s and try to fix it
for them that would be bad but we can
give them a very very good error message
and skip that we're we're all over
Unicode so we prejudice things in in
terms of assuming that we don't just
chop our backslash X's after two
characters that's sort of a 8-bit
assumption we're biased towards
characters so it'll chew up as many x
digits as you can little little tweaks
like that but my overall thesis is is
essentially no computer language has
ever taken extensibility seriously they
tend to fort fall into the the fallacy
of any color as long as this black and
you know as language did language
designers as a class of people tend to
think that they know how it ought to be
and try to impose the one true syntax on
on their users whether that's lots of
lots of silly parentheses or mandatory
whitespace or various other ways that
language designers go wrong and I think
I'm pretty much out of time here yeah
it's time for questions
pardon me like that's the usual question
and the usual answer is Christmas
we just don't say which one the flip
side of that is after pearl fix comes
out every day will seem like Christmas
but you know seriously we've made an
awful lot of progress you can see that
I'm actually running a parser here is
still pretty buggy but I'm actually what
I've got here I mean there's other
people who have written other parsers
that are sort of hardwired for standard
Perl 6 I'm trying to do the parsers
right according to this polymorphism and
longest token matching so that's that's
my field of expertise and so I'm working
on compiling this using this and it
actually will compile several hundred
bytes into this before it blows up now
and the way I'm doing it actually is
I've got a cheering gum and baling wire
program called gimme five which takes
the standard it's really you don't want
to do language translation like this but
for for a one-shot translate this chunk
of this specific chunk of Perl 6 to this
specific chunk of Perl 5 it does that
the only thing it does a real parse on
is the is the rules and the tokens and
then so this standard grammar is you
know one hundred hundred thousand is
it's a less than four thousand lines and
that's got a lot of comments in it and
the this that if you want a idea of the
sort of power we're adding with the
notations translating that to Perl 5
ends up with forty five thousand lines
of code which ends up looking like
like this
so a little teeny rule like this so
regular expression food ends up turning
into interesting
an interesting bit of code there and
there's other ways to write that but it
was just a convenient way to do the
backtracking and it and it's very
inefficiently written right now right
now the the notations is assuming all
over the place that you're doing
backtracking even though most of these
things are tokens and are guaranteed not
to backtrack they're they're quantifiers
and that could be optimized very easily
and but for bootstrapping purposes 2,000
bytes seconds probably enough so we're
making progress and to get way back to
the original question I talk like a
politician you know you give me one
question oh I'd give you a different
answer
that's or the question I want to ask
answer but it'll get done when it gets
done but in my my look out is just to
make sure things continue to converge
and as long as they're converging is is
not like a business project where you
know you have a burn rate and if you
don't get it by done by date X you're
just dead meat it's an open source
project it's all volunteer labor it
happens when it happens but as long as
it's converging it will happen
eventually and then hopefully we'll be
happy
you have it
his characteristics
correction there
well right now it'll be a lot slower
because we haven't got any of the
engines to to you know run the full
semantics yet and we're sort of you know
prototyping it here and bootstrapping
it is certainly the case that we we bear
potential performance in mind down the
road and that's part of the reason you
know we want to do the longest tolkien
matcher thing in a DFA because we know
that's very fast and that will control
the the parts of the a recursive descent
parser that would be very slow which is
you know probe this probe that probe the
other thing keep keep track tracking
we're just doing away with that every
time we recognize a token so we expect
it to be very fast now that being said
you know computers are getting faster
and that's an old argument but a lot of
the theory for parsing was done sort of
back in the Dark Ages when people were
trying to shoehorn parsers into small
memories and slow CPUs and they tended
to warp the language in favor of the
computer rather than the user so just as
a for instance a yak grammar something
goes wrong it can't tell you much more
than syntax error you know near here
with a recursive descent parser you can
give much better feedback because you
know what you're looking for and if we
can make a recursive descent parser with
that as largely recursive descent least
for the tokens and high-level stuff and
sandwich operator precedence and where
it makes sense then we can give really
good error messages and get most of the
performance - and we think that's a good
a good disruptive technology kind of
trade-off
we're already a second really free
language
why the
you know drawback to settlement when a
language is so free that over the years
as you write this thing you did you get
a really wide set of being set to know I
understand what's going on
when Pearl six comes out we have you
know a way of you know having probably
Mormonism for everything that
so what are some of the ways that we can
kind of
you know stop it from being like wild
yeah that's that's a fair question and I
think that by and large it comes down to
a cultural question now at that point
and we've already seen what was Pearl
five that the culture tends to enforce
use of of the strict pragma and the the
warnings Pregnant's so much so we're
doing that we made that default in Pearl
sakes
and they'll come up with other things
like that another take on it is on the
one hand we we try to provide maximum
flexibility but on the other hand we
also try to provide you with a better
idea of what you should do by default we
discovered this with Pearl five object
system which is exceedingly orthogonal
and in fact two orthogonal in the sense
that it gives you no obvious way to do
it
so the Pearl six object system is you
mean you can do whatever you want with
it underneath just as with Pearl five
but on the top of it here it's it's got
you know there's a standard way of
declaring attributes a standard way of
declaring methods and so on and so forth
and if there are are fairly decent ways
built in to do most of what you want
already then the temptation to roll your
own becomes less so that is sort of you
know one of those oddly ironic things
that that a language that is providing
more flexibility would also try to
prevent you from using that by giving
you a way to do it already but
by putting those sort making those sort
of good default decisions in the base
language it takes a lot of pressure off
of the mean to roll your own and and I
think overall for most tasks actually
reduces the learning problem but other
things we're doing is is actually
rethinking also the the way the
documentation interacts with with the
syntax so that we can intermix almost in
a literate programming style the the
documentation such that it's active
accessible so that if you if you derive
a grammar you know everything is
first-class objects in there you can go
in there and ask the object what do you
know about yourself you know in ways
that other languages have explored even
more than Perl has you know we steal
good ideas wherever we can find them so
you know there's no simple answer to
that problem but yeah we have thought
about it
so talk to mostly about the personal
talk about running of it like mm-hmm
yeah I can talk about it most most of
these bullet items that are you know
what one one liner you know each talking
themselves and people talk about their
various VMs and such and parrot is is
one of the VMS it's perhaps going to be
the name vm but Perl 6 was a language is
VM agnostic probably the the parrot VM
has the longest running effort but their
mandate is not just to make a VM for for
a Perl 6 but a VM for that will be good
for most any dynamic language and I
actually have had very little to do with
the parrot VM at the beginning of the
Perl 6 effort the community sort of said
to me well you know we how we know how
you implement we've seen your Perl 5
code and it's pretty darn ugly so you
know but we'll do the implementation you
think about the language some you know
actually that's very beginning was just
the community was going to do everything
you know I was just gonna sit back and
watch but after a few months of trying
to do community wide language design and
you know we asked for RFC's and I
expected about 20 suggestions got 361
and they were just all over the map and
a mutually contradictory had each of
them had tunnel vision they were gonna
leave Perl 5 the way it was and fix this
one thing so of course if we just
implemented malls as suggested it'll be
in a complete hodgepodge so we had to
sit back and and the community came back
to me sort of hat in hand and said we
need a language designers so I've mostly
been concentrating on the language
design it's only just recently that I
I've gotten back into implementing just
this part of it so I've kind of stayed
away from the implementation end of it
it's Memorex Audrey Tang who was working
so rapidly on on pugs and and
demonstrated how to how to get people to
really get going on IRC and just sort of
do 24/7 programming and pugs is the
result of that and it's to this day as a
semantic prototype of Perl 6 is the most
advanced and it's starting to show
Audrey came down with severe hepatitis
and to the extent that it was basically
life-threatening and her doctors I mean
she has some other things
attention-deficit kind of problems and
was you know on stimulants and she had
to stop taking those stimulants so she
still works in the background but she
wants to keep a low key and and you know
we all unfortunately as we get get older
run into times when we have to learn to
pace ourselves and you know she hit a
brick wall that was solid and most of us
I've had a few of those myself but it's
never never entirely happy making but
and she's she's doing doing okay
I will be looking at ability with
prototype modules for a second
okay now we got several stories on the
on that one of them one of them is is
simply that we will would be doing
certain amount of pro/5 emulation worst
case running a Perl 5 interpreter in the
same process best case on that is shared
run loops so you don't run into the
problems of stack full run loops and the
other the other leg of that is that we
already have in prototype Perl 5 - Perl
6 translator it was done a couple years
ago for google Summer of Code and it's
probably had a little seam a little
design rot since then but in principle
most most Perl 5 code can be translated
Beryl 6 that doesn't help with the the
XS modules that interface directly to C
or C++ code but that would be something
that you would probably use emulation
for and you know the translator is also
going to be good for for educational
purposes even if it doesn't get you
actually get used for migration I found
this to be the case with the octal
translator and said to Perl when I first
came out with purl 1
I didn't I I delayed the release a month
or so while I wrote those translators
because I thought it would be better
accepted and you know people did use
them a little bit for actual migration
but by and large they would just type in
something they were familiar with and
see how it came out it's probably
what'll happen with this translator -
but it gives people warm fuzzies to have
it there but usually what we find is
people get excited enough about the new
new features and syntax that they they
really want to rewrite it and
and take it as an excuse to refactor
everything you know and when this much
code turns into this much code that's
more readable that they'd like that if
you run a translator it comes out
usually a little bigger and usually a
little less readable
whatever you liked in this life
that's good question I was I was
actually the mentor for this translator
what I discovered was I am NOT a good
metric so I am not mentoring this year
but that's that's my problem not not
summer of codes problem I I am somewhere
on the autistic spectrum I think and I
don't do certain social interactions
like initiation that is crucial to being
a good manager the only reason I and
manage to run the this open source
project is that I I have learned to
delegate even the delegation to other
people</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>