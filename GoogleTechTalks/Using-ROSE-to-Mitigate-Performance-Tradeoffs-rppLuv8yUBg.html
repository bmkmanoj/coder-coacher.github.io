<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using ROSE to Mitigate Performance Trade-offs | Coder Coacher - Coaching Coders</title><meta content="Using ROSE to Mitigate Performance Trade-offs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using ROSE to Mitigate Performance Trade-offs</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rppLuv8yUBg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay let's go ahead and get started our
speaker is Dan Quinlan from Lawrence
Livermore National Labs who has been
working for quite a while on a an
infrastructure for translating see
source source and and as a result has a
system that he can use for for lots of
different things in the middle you know
code analysis optimization people have
done instrumentation things with it all
sorts of stuff so with that introduction
I'll send you off to him he's going to
talk a bit about the system he has a
postdoc here with him his going to talk
a little bit about some software
engineering things that he's been doing
with it and we hope to have a bunch of
time for questions thank you very much
so Rose has been a project that we've
been doing for quite some time and it's
was originally focused on the
optimization of user-defined
abstractions the motivation for this was
that we had at the lab developed
numerous high-level object or
abstractions and libraries of
abstractions and frameworks to support
development of scientific applications
for computational fluid dynamics but
there were issues associated with the
performance of this and at addy we
laboratory where they're very obsessed
with performance you have to get all
these details squared away and so we
started rose as an attempt to address
the optima formance optimization of
user-defined abstractions in doing so of
course you have to develop the whole
compiler infrastructure for supporting
this but we were obsessed with the idea
of presenting the of one having an
audience which was library writers not
compiler people so that's a little
different than some projects and two we
were interested in representing the full
detail of the C++ language now we sort
of get see free we've also been pushed
in a variety of for a variety of reasons
from our funding agency to also support
Fortran but the point is that we can
represent the full representation of C++
every little detail essentially that is
in the source we can represent that and
of course make it available for
automated tools to be built Rose is not
a magic bullet that you run over your
code to do one thing in particular it's
a tool for building tools which are
source to source translators which of
course do whatever it is you say it
should do when it goes over the code
I'll explain a little bit about just how
roses is organized Thomas at the very
end I'll basically try and give a short
talk and then allow Thomas to talk for
10 minutes on some of the work and how
he's using rose for for reverse
engineering of codes and hopefully we'll
have lots of time for questions so the
let me also say that I have a example
tutorial if anybody's interested in just
thumbing through it i'll be happy to
actually just let that be passed around
on the audience so you can look at that
if you like please make sure I get it
back when you're all done but the table
of contents gives you a rough idea of
the 60 or so different examples in there
of little tiny translators that
literally go do different sorts of
things some of them are are intended to
be instructional to help users learn how
to use rose some of them are there so
that when i get the certain questions
asked for the 15 50th time i can say
it's in the tutorial and others are
there as simply examples of things that
we've done with different different
companies and different research groups
that were things which they needed to be
done and which i asked if i could put in
the tutorial so the motivation for this
work is that department of energy
develops huge amounts of software not
just in c and c++ but also in fortran
hence the necessity of a stressing
fortran the fortran work is currently a
collaboration with rice university and
it's not available yet in the in the
Rose distribution we have about
two-thirds of it in place and another
third of it has to be delivered but
we've been addressing the analysis and
optimization of C and C++ applications
specifically scientific applications and
so some of the UNAM
the optimization that we've done has
been those things that are important for
scientific applications lots of loop
optimizations for example but a lot of
custom tools could be built using this
we're not exactly in the business of
building custom tools were more focused
on optimization but rose is a general
infrastructure supporting a lot of
different sorts of tools it's a source
to source approach which means that
which means that a translator built
using Rose takes in source code and it
outputs an executable now its source to
source internally but internally we're
going to hand it off to the vendors
compiler and the vendors compiler is
going to compile that generated source
code that we generate and generate an
executable as a result in a large make
file system for a large project million
lines thousands of files you can simply
change the name of the compiler to the
name of the translator that you've
written and analyze your source code
it's meant to be very simple and it
works in this context and it's necessary
that it be designed in this way because
we simply have large million line
applications with thousands of files at
the lab which we have to be able to work
with and actually we want to not change
their make file system one bit because
it makes the source code look simple
make file systems are the most
complicated things I've ever seen but
the point is that there are a number of
different stages intermediate we use the
EDG c++ front-end internally we have a
research license with them that allows
us to distribute a binary for research
use only and we have access to all the
source and we routinely share the source
with those who have a you have an EDG
research license but we can also just
give away the binary the next stage is
that we translate it internally to an
internal representation which is more
friendly to being modified and and
examined using automatic tools and we
also have mechanisms recognizing
high-level abstractions automating that
one you you insert this you insert this
part that is to say we have a lot of
different analysis and built in
internally we have a lot of
transformations but if you have
something
you want to do some specific types of
analysis are some specific sort of
transformation you contribute this part
there's no free lunch after you've done
that part we and then we then pass it
through to generate source code we then
pass that optimize source code onto the
vendors compiler I'll show you I'll show
you perhaps an example or there's
examples in the tutorial that basically
showed that code we generate is
generated with all the source code all
the comments all of the preprocessor
control structure it's you know it looks
relatively pretty I think but the point
is we save all the information about the
source code yes yes and even some of the
ones that they ask for there's a lot
though honestly if I were to use the
latest version of EDG perhaps they would
have fixed some of these and I wouldn't
have to do some of the work that I had
to do but yes we're using 3.3 read
journal and see what's up
and I can upgrade report but we're using
so Rose is a tool for generating tools
that would operate on source code we
take in the source code we generate an
AST we then manipulate that AST to form
a different AST or modify it in some way
the properties of this AST is that its
object oriented and it's easily modified
and then we generate source code it's
very simple yes we're praying front end
yes we don't use the Fortran we don't
use that Fortran front end that doesn't
exist of course this would Fort grant
front end do you use the oven 64 front
end we have a as part of a contract with
rice who has a lot of experience with a
open 64 front open 64 compiler we have a
contract in place that has allowed us to
generate allowed them to generate
world which is nearly verification of
all existing 42 sage 3 which is our
intermediate representation and that
translator is in place and that gives us
roughly a fortran 77 level of capability
is my understanding i have yet to get
the front end i have the the ir node
modifications in place and I have the
back end code generation in place right
now so this has been work that we've
been doing with them for quite some time
and I want to make sure that they get
you know credit for that but as a result
of that we expect that eventually we
will be able to step up to the fortran
90 capabilities of that compiler however
to the extent to which that compiler
doesn't address maybe 14 95 or Fortran
2003 we're pursuing other opportunities
to perhaps see if there's other front
ends that might be more appropriate but
that's not very important to us we're
trying to first get a four base level of
Fortran 77 level capability much as
earlier on we first got a level of C
capability before moving on to C++ which
wasn't supposed to be that hard but
really was yes are you only looking at
one source file on time
we can do with groups of source files
you can either specify all the source
files on the command line but that comes
pretty damned impractical when you get
to a thousand separated over you know
104 directories we also have a
persistent mechanism for storing
analysis information any analysis
information that you want any
information you want into a SQLite
database that could be retrieved
afterwards that's a mechanism by which
we build call graphs over thousands over
you know big number of files if the
SQLite database is used in the
configuration and there's also a whole
program analysis work that we're doing
which I'll explain in a moment which is
designed at being able to read in or
process all the files separately and
then collect them together such that we
can hold a million lines five million
lines of code in memory at one time and
so the next reasonable question there is
how much memory does it take to hold a
million lines of code well about 400
megabytes right now so that's a fairly
reasonable basically memory sizes have
gotten so large that I think it's
entirely reasonable though the
complexity of the analysis is not
reasonable the storage of the of an
entire application and memory is quite
reasonable using the mechanisms that we
have or not as large as canoe for
example so there's a variety different
program analysis and optimization
capabilities that are available built
into rows right now there's call graph
analysis there's resolution of function
pointers to restricted subsets of
functions resolution of virtual
functions and of course the combination
of the two pointers to virtual functions
which is really obnoxious in order to
support that we have to read all the
files we have to build the call graph
hierarchy and then we have to do the
analysis on all of the accumulated
information sqlite is used as a
mechanism for storing this information
an alternative which we expect to be
able to use in the future is to simply
do it in memory simply because we'll
have the entire application in memory as
an alternative but we've had to use and
maintain these mechanisms for processing
things one file at a time simply because
that's where we've stood in being able
to process large codes
so far we have dependence analysis it's
procedural it's not interprocedural
there's control flow analysis these are
examples by the way that are in the
tutorial you know I figured what chapter
control flow is but there's a little
example of how to in the tutorial of how
to build a control flow graph and it
shows you the functions you have to call
in order to have that be done for you
and then there's an example of a
arbitrary source code which I've simply
chosen mostly at random and what we do
in the tutorial and there's a tutorial
directory of examples also what we've
done in the tutorials will really take
that source code presented in this
tutorial take that input code presented
the tutorial compile the example code
run the input code on the example code
take the output put that in this
tutorial so the tutorial represents the
current state of exactly what's working
or in some cases not working so there's
none of that in the tutorial right now
at any one time we have slicing that's
very important for certain sorts of
analysis there's partial redundancy
elimination some of these things are
contributions from people who have
worked with us partial redundancy
elimination for example is a
contribution from Jeremiah Wilcock
connection to the open analysis
framework is open analysis framework is
a framework being developed by some
friends of ours at Kyle Michelle Stroud
at Colorado State it's intended to be an
IR independent analysis framework and so
we've been using that as well and argon
has been using Rose with that as well
I'll show at the end a list of about two
dozen or so different groups that have
been using Rose worldwide and some of
these contributions have been as a
result of collaborations with them we're
very big on collaborating with people
that's one of the ways in which we test
our own work and also get contributions
from others there's a number of
different optimizations in place the
optimization work is a result of Qing
Yi's work who was a postdoc with us for
almost three years from rice and she put
her thesis work in two rows as a result
we have rather sophisticated levels of
loop
ization fission fission fusion blocking
unrolling ray copy etc there's also in
lining and outlining capabilities
there's research work that we're doing
on annotation based optimizations the
point here being that user-defined
abstractions have certain properties it
might be that you've designed a
particular class which has no aliasing
associated with it it's a part of the
semantics of that class that it has no
aliasing you have no way of
communicating that to the compiler and
because the implementation has a pointer
inside of it the compiler is going to
turn around and not do a lot of things
because it doesn't noticed but you know
that it could be aliased so you could
annotate information could annotate
abstractions in order to communicate
this sort of information and as a result
enable certain sorts of optimizations
this is some of our research work but
it's very much in line with research
work that we're doing on customized
optimizations so there's been a number
of accomplishments for us robustness has
been a very important issue we are the
only compiler group at a deal we lab I
that I'm aware of the Dewey does fund
other academic compiler research as a
result of being a compiler group at a
lab we have to compile lab applications
which means that they sort of they test
whether or not we're worth anything at
all by throwing us a million lines of
C++ so I'm pointing at a couple
different applications there and these
are applications at the lab that we can
we can compile and applications that
we're currently developing specialized
analysis and halved written in the past
some specialized analysis in order to do
sorts of optimizations and I'll be
discussing that just a little bit
separately from from that work that
we're doing internally our goal is to
notice it rose for examples on the list
there's about three or four bugs that
are keeping us from compiling Rose with
Rose itself so sort of let you know
where we stand Rose itself about a
million lines code we're trying to step
up to about 10 different million line
applications before we release Rose this
summer this is going fairly well
I get a lot of help from other people in
helping find find problems but in
general I'm the bottleneck to getting
them fixed because i have to debug them
there's collaborations that we have with
IBM that we're very proud of this is IBM
Haifa in Israel they're developing tools
using rose for use internally at
different sites at IBM yes are capable
of running on multiple machines right
this rose understand the interpretation
what app you're referring to parallel
applications okay so that's a very
interesting question the reason why it's
interesting is because yes all of the
applications of the lab scientific
applications are parallel applications
and they don't just run on a couple
different machines they run on on
machines with thousands tens of
thousands 64,000 128,000 processors
these are very large machines but they
are codes that are essentially serial
codes with embedded communication that
makes them parallel with rows we can go
and see where the embedded communication
is but there's nothing parallel about
rose and the ability of rose to
recognize the use of a parallel abstract
on abstraction from a parallel language
library like MPI or something like that
parallel message passing library excuse
me is simply the same mechanisms that we
have for recognizing all abstractions
and so yes we can go find where MPI is
being called in a large application and
that might be very interesting but
there's nothing about the aneta
compilation of a parallel code that
really makes it look any different than
a serial code so in a sense it's a
serial issue the compilation is a serial
issue now we could turn the analysis
with it if it's sufficiently expensive
into a parallel issue but that might be
fun but that's a completely different
subject so there's a lot of different
custom analysis that we're doing
analysis to find properties in the class
so for example there was one application
that loved static initialization they
thought it was very good they used it
everywhere then they changed compilers
and realized that maybe it wasn't so
good after all because it's order of
static initialization is compiler
dependent they saw they promptly removed
it and that went great until they had a
bug and then they discovered oh the
whole bug that particular bug was a
result of static initialization
but they thought they had removed it all
it turns out rather difficult and rather
subtle to detect all the places where
you've built a static something or other
in a class it's going to cause a problem
for static initialization so after
several months of they thought they'd
found last one last time and yet they
had another bug and they trace it down
to this particular problem I was asked
if I would go find the latest one so
they didn't I asked him to not tell me
where it was and I would go run right a
special tool that would go over their
entire code and find it I found nine of
them that were false positives as a
result of an internal bug and Rose I
fixed the bug so this is the value of us
working with these groups I fixed the
bug and we found one of the one of the
nine was in fact the one that they had
just fixed and we verified that there
weren't any more so that's good the
point is that you may be in a similar
situation where for a completely
different reason there's something in
your code that used to used to like a
lot and you discovered it you don't
really like it very much anymore and you
might want to find where it is and it
might be completely legal C++ but you
still want to find it and kill it so
that's an example of how that's done
there's a there's work that we've done
on loop classification loops in
scientific codes come in many different
varieties and there's all sorts of
opportunities to optimize certain types
of loops and so we've done work on loop
classification for a particular
application blab we've also been doing
work for more complicated these each of
these become a little bit more
complicated and more involved we've also
more recently done work looking through
a large mayen line application looking
for where it is two functions could be
inlined and where it is there's a loop
that could be fused as a result of that
in light and lining is something for
which you're never going to get the
compliant the vendor compiler to do it
because typically alias analysis
prevents it and we have more
sophisticated mechanisms for doing that
and so as a result we could do fusion if
we could see things together the trick
is how many opportunities are there in a
million lines
diffusion of two particular loops and
and fuse the diffusion of loops that are
across different functionalities so this
is a specialized sort of analysis
written just for optimization of
scientific codes yeah well there's other
things too
male I believe our worldwide license to
using YouTube but it
get them back
yeah sure
can you get
you might have to pay
actually it's the third example in the
arts the third example in tutorial at
the end of
examples of how to do cook courage
there's a coup coverage Katherine I
asked them when I wrote it whether or
not I could include it in the tutorial
they said yeah sure no problem and so
you know I work for them to write it and
and as a result there's a code coverage
example there that's most of the work
required to do code coverage now they've
added more work and there's a tool which
they run with that to interpret the
results and that's the part that they
make actually available for free on the
web but which may be for research only
or something I don't know I don't know
what the rules are regarding it or it
may be that it doesn't work on some
particularly large problem or something
like that but these are tools which
they're using at different worldwide
sites for detecting bugs in threaded
applications and the code coverage is
just one small part of the problem so
actually this is part of research work
that we're doing with them on detection
of folks automatic detection of bugs
they've been doing work on the threat
automatic detection of bugs and threaded
applications for some time and they've
had great success with this the basic
technique is you instrument the code
you perturb the thread curb the order of
the threads when they execute and you do
a code coverage to make sure you covered
everything and you detect things like
there's a shared variable here but
you've only ever shown us an example of
the
by one friend so as a result
shared or maybe better test others in
order to print out the problems that
might think that might be a parent if in
fact it was shared across multiple
friends so the point is they detect many
many subtle bugs and threaded
applications but they had previously
done this with Java and had no access to
see your support plus in order to do
this as what's already left
or how
the
but the journeys
when asked arrives
catching separate
um
so there are all sorts of here
procedural analysis that were involved
in regarding loop loop optimizations I
won't cover that too much I talked about
briefly there's work on empirical
optimization empirical optimization is
the technique whereby on a particular
machine I don't know what is the
combination of optimizations that will
make the most amount of difference but
it's probably different for each machine
and here I'm showing a loop fusion
here's the unfused loops here's the
fused loops and what we're looking at is
a particular hyperbolic piecewise
parabolic method implementation with 50
different loops and we're going to
generate all the different possibilities
of pairs of loop fusion actually not
perishable infusion local loop fusion
but we're not doing any reordering
because that would make it very
expensive as it is there's 128 different
possibilities there's a lot more if you
allow reordering the point is that we
can write each different version of the
code run it and see what the performance
is the performance in this case is is
measured in two different ways which I'm
not going to go into but this is work
that we've been doing with people with
kim kennedy at Rice and one of his
students and Chingy who was a postdoc
with us who's now at University of Texas
San Antonio
this is a simple example of loop
optimization people write code like this
for clarity but you might want it to run
like this in order you might want to
have regenerated this code for actual
running it because this code will be
factored two times faster than that code
the compilers will not typically be able
to fuse those sort of loops but we can
do a lot of the sort of stuff this is an
example of a 2d case simply showing that
it gets more complicated people tend to
write code so that they can be
maintained so this limits the sorts of
optimizations that they'll introduce by
hand and yet we can turn around and
generate equivalent much more
complicated code which you wouldn't want
to maintain but can be automatically
generated for you and is much faster in
this case we're showing different sorts
of relaxations which are typically
actually expressed as separate loops
when they're written by hand but which
can be fused as a result of loop fusion
and skewing and as a result of that you
can get factor to improvement
performance but you'd never want to
maintain this stuff because it's very
difficult it's an example of where it is
code should be written by hand but by
code written by hand should be written
to be maintained and code generated
internally can be written for
performance yes
is that for
it makes no difference I'm talking about
serial performance here parallel
performance would be equivalent but i'm
not talking about parallel execute you
know we can talk about parallel
execution all you want but this is a
serial stuff and it applies to parallel
as well yes it applies Intel processors
are just as much and the reason why it
was because your cinch I mean ask me
afterwards and we can we can we can
really cover why that makes a difference
and why it's it's really quite processor
independent issue simply because you're
increasing locality of the computation
and that locality that increase in the
locality of the computation is good for
all modern processors that use a cache
so it's just good for Intel as it is for
other processors this is work that we're
doing on automatically recognizing
high-level abstractions here's a little
tiny example code it's written using a
couple different abstractions a range
object and a double array object these
represent array objects
multi-dimensional array objects as C++
and here's a little tiny expression
involving that those abstractions so
here what we have is the AST and what we
have are the the different markings for
the different pieces of the code so for
example the blue represents the array
abstraction and the green represents the
range object so what we see is that
there's range object range object array
object and then there's the big
expression involving them and at the
Tate at the leaves of the the expression
tree representing the expression there
we have the individual index objects and
in white what we have are the Plus Ones
representing the C++ which didn't
correspond to any one of these library
abstractions the point is that we can
automatically read an application read
the libraries from which it was used and
mark the AST to have all this
information so that when you want to go
do optimizations and you just want to
find all of the up and you have a
particular optimization you just want to
do one for example the use of a ray up
tractions you can easily find them that
part can be automated one of the things
we've also done is we've hooked up
performance information so that you can
get performance information in the AST
also so it tells you something about
whether or not it's even relevant to do
certain sorts of optimizations there or
not this is the slide that I was
referring to a moment ago when I was
talking about reading in the application
separately here we have three different
a STS for a little trivial program keep
in mind Rose works on million line
applications but they don't fit on the
slides so I represented really trivial
things on the slides but here we have
three different applications three
different files and what we can do is we
can turn around and merge those together
so the analysis to the analysis of each
one nothing has necessarily changed but
we've essentially represented them more
compactly the principal issue here is
that a million line application at the
lab is typically a thousand files each
file containing about a thousand lines
of code with 75,000 lines of header and
I don't have room for that 75,000 header
to be replicated a thousand times so
this makes it very space efficient and
this is a necessary technique for
representing huge applications in memory
at one time now once we have in memory
we can do all the same analysis that we
could do I was or that we would write
for an individual file we can simply do
it on the whole AST this is a this is a
somewhat trivial example of a call graph
it's not a very big one but obviously
it's a little bit bigger than you know
three or four points each one of these
black dots is a function each one of the
blue lines is in fact a line between the
functions which is a function
representing a function call this is
actually represented using a tool that
Thomas will talk about a little bit but
the point is that this is a call graph
showing what functions calling what and
in fact actually because of the scale of
it it doesn't tell you anything really
but it does tell you that there's a
little group of functions over there on
the corner which aren't called by
anybody and maybe they don't even need
to be there but this is some of the work
that we're doing to step up the current
work in the call graph analysis this is
another sort of tool and capability that
we've built into rows specifically the
ability to combine a maple with rose to
do symbolic manipulation in this
particular case what we're doing is
we're counting up we're we're basically
annotating the AST with modeling
attributes these modeling attributes are
saying that there's a memory access here
and we're basically counting up the
memory accesses so we count up the
memory access as we get an equation for
this memory axis and in terms of B and
then of course we end up assuming in
terms of bound and of course then we get
another one in terms of bound so we have
generated an equation which represents
the complexity of the computation in
terms of the you know an equation which
you can compute and in this particular
case this function is calling fubar so
main here is a summary of the complexity
of the main taking you to account the
complexity of fubar being called in an
order N squared operation and fubar has
its own complexity and so on so on
anyway you can automatically do this ad
nauseam and end up with information
about the complexity of the code here
what we're doing is we're representing a
graph of the complexity this is a graph
of the complexity of main and I believe
this is a graph of the complexity
because main actually depends upon only
those two two variables whereas the
complexity of that function depends upon
a couple more variables and so it ends
up being a more complicated
representation but it's what you'd
expect you notes quadratic
here's a very nice example as a result
of collaboration with people at UC Davis
this is the attribute is the annotation
of types with unit information the sort
of stuff NASA really wish they had done
10 years ago the point is that alpha for
example is specified to not have any
units some of these variables are
specified dab units so for example this
density is kilograms per meter square
per meter cubed thickness is in meters
energy is in meters squared kilograms
per second squared and the point is that
by annotating the variables in a few
places what can be done is through type
inference one can interpret what the
types are of these things and in the
process determine that there's a bug
here specifically right here because one
knows that the exponential the value
which is exponentiated is unitless
there's a theorem of this and also of
course it doesn't make any sense since
for it to have units but in order for
that to be units we have to get meters
to cancel with what x0 is and x0 is
computed using this which is evaluating
that and this is using information about
atomic weight atomic number etc the
whole point is that this should have
been a reciprocal but what was able to
be determined was that there was a bug
now the exact fix of the bug who knows
but the point is this should have been a
reciprocal and if it was a reciprocal
than it would have been fine this sort
of analysis at static analysis in order
to find bugs is very interesting to us
which is why it is we've been working
with these people this is a this is ling
Schiele's work who's a who's a graduate
student at UC davis and professor
dong-su is his advisor and this is a
result of collaboration with them this
is a capability that we're trying to
stand up in rows in order to
look at scientific applications very
large one of course the most common
question I get you haven't got yet
actually is what is my output look like
when i run it through rose the most
common thing that happens that people
are used to at the lab is that if you if
they hand their code to a tool the
output of that tool will have seriously
deranged their code and this upsets them
a great deal here i'm showing you an
input code and here's the equivalent
output code there's very subtle
differences between the two other codes
would give you a little bit more
difference the tutorial shows you some
other examples of what the input looks
like what the output looks like but
basically I'm saying that we preserve
the comments we preserve the
preprocessor control structure there's
an awful lot of stuff that's preserved
we save all the information about where
every every construct began both in file
name line number and column number so it
could be reconstructed even better but
the point is and and there's mechanism
there's a particular example where it
shows you how to how to have it be how
to change the in Taylor the construction
but the point is we go to great trouble
to output the code in a reasonable way
so these are the sorts of interactions
that we have with different groups
specifically there's internal labra
interactions that we have there's work
with other laboratories are gone is
Argonne National Laboratory outside of
Chicago oak ridge or NL is Oak Ridge
National Laboratory in Tennessee there's
do e projects department of energy
projects that we're a part of and then
there's a lot of different
collaborations that we have with outside
groups and in fact actually this is not
really a complete list but it's what
fits on the slide and the sort of stuff
that we're proud of doing and we're very
happy to be working with some of these
people and it's a lot of fun for us
which is sort of why it is i'm here
because might be fun to work with you
guys too okay so now I want Thomas to
talk
excellent yes
don't
okay so let me start with telling you
why I'm here I got hired two months ago
into the Lawrence National Livermore
labs and my research interests are
reverse engineering in program is
civilization so question is what did I
get hired into a compiler group so the
answer is of course that the the dan and
the group they're interested in
analyzing software so they are
interested in reverse engineering and
especially using rose so let's introduce
you to a framework that I brought from
Sweden where graded before which is the
visualizer which allows you actually to
look at source code so what you do is
you have your software system you have
your platine and you put different chips
on that framework so for example a chip
for retrieval so we put your rows on to
this something for analysis and
something to for visualization and
finally you get some images in order to
understand your software system so for
those of you who don't know what reverse
engineering is I would like to explain
it to you let's say you have a software
system that if used for many years and
somehow the system gets a little bit
strange so for example you discover a
bog and that buck when you fix it it
leads that to the fact that there's many
more bugs in your system so something
happened over the years maybe have
employed some students for a short time
or I don't know whatever happens in
industry so what you want to do is you
want to reengineer your system in order
to do that you need to understand your
system so you put different levels of
visualizations of your system so you try
to see at the source code of different
components and at the entire
architecture to get an image of your
software system you to have to perform
reverse engineering
so why would your reverse engineer
system well maybe you have noticed that
most of the time when you actually try
to do changes or enhancements of your
software system most of the time is
spent on understanding the system so for
example for a correction task you will
spend sixty-two percent of your time
just to try to understand your own
system that means your own system or the
company system if there's many more
developers on that in general for
maintenance tasks you spend 40 to 90
percent on understanding system how much
as maintenance compared to the entire
software lifecycle so if the maintenance
takes forty to eighty percent fifty to
eighty percent sorry so in the worst
case how much time do you spend to
understand your software system in the
worst case you spend seventy two percent
of the software lifecycle to understand
your software system so if you have a
software system the last for about ten
years you spent seven years to
understand your suffering system isn't
that a waste of time and money so what
we would like to do is we would like to
use some kind of tools that help you to
understand your system so what what do
you take you take whatever is available
of your software system the source code
the developers of they're still in the
company and documents do you trust
everyone do you trust the documents well
in Germany they usually charge some
German so i can say that and germany we
trust our documents because they will
designed so but in general you take your
source code and you try to produce
different images and try to get the idea
what happened to the software system in
order to do that you use a tool this
tool starts by parsing the entire
software system so bypassing the
software system you get a model then you
try to perform some analysis and finally
try to visualize to get an understanding
now I would like I tell you there's only
this one tool available this there's
many tools available so especially the
what kind of visualization do you want
to have everyone needs a different kind
of visualization maybe you like your
mail diagrams so you would put your
rational rose or something similar into
this place well its of course hard if
you have rational rose here and you have
a front end like like rose c++ front end
and you combine them it might take you a
few months and then you figure out oh
well I actually need a different kind of
visualization so then you start screwing
on that system and it takes your time so
what you would to do rather is to to
compose those kinds of reverse
engineering tools so you take just the
components that you're interested in for
visualization retrieval and analysis and
you just create your own individual
program is standing tool within hours or
days so that's actually what the
visualizer is and you see here an
example of an instantiation of different
kind of chips that are put on the
platine for retrieval analysis and
visualization now what can you do is
that an example would be to show a
static picture of your software system
so this image is the whistle analyzer
itself it shows you different components
of the system so this is the
visualization part there's some game
engine there is the core and there's a
Java front end for example and what you
see is the different classes a call
graph between the classes you have the
size of the classes as the size of the
spheres here and what you can see that
the system is very nice decoupled so you
get an idea about the quality of the
system I would to give you a comparison
to a former version like I have to tell
you the software system was not always
as nice as here in this version so in
2002 the visualizer itself was very
complex so we had a one huge big system
and the red color actually indicates the
amount of documentation so it was very
bad documented then we
add some students working on their
master teasers and finally after some in
some work that I've done we got also
this picture that you just seen in 3d
where we have decoupled system it's much
easier and faster to make changes and
understand your system what else can you
visualize for example you would like to
have Ende about the quality of your
software system so with the visualizer
you could easily arrange different
quality aspects of your system and to
the axis so let's arrange the complexity
of your software system and in the
x-direction the lines of code and why
and you immediately figure out which
ones are the outliers of your system and
not only that you also figure out who
did this huge classes in the complex
classes you might want to talk to the
person why did you do that the way in
the set direction we have aligned the
lack of documentation in the system so
the parts of the code in the front here
they are very bad documented what I've
done in a course is also ask the
students to try two different metaphors
and he will see see a city metaphor so
what do you we see is different classes
or presented its buildings text just
showing the same as the height the
amount of lines of code and then you
have the quality presented as a texture
and fire texture showing you bad quality
of the software system and the more it's
burning the worse it is and if your
entire city is burning you probably
should do something about your program
okay so the purpose of reverse
engineering of course to understand your
software system much faster and better
save time and money what would you like
to see you would like to see the code
structure ideas about the quality of
your program if i want to find code
duplicates you want to see if there's
any malfunctions have this much
functions being introduced by purpose or
not and maybe the managers would like to
see the work distribution of progress
that you can also measure of a certain
time so what I presented you right now
is the visualizer
and the visualizer is going to be or is
already working together with rose and
the future work that I'm working on is
to find interesting patterns in million
lines of code of C++ but I don't have
any results so far but if any one of you
is interested in that work please come
and talk to me yes so company called
clock works and they have a tool called
code servers
it sounds very similar it's been out for
a few years can you comment on what the
differences are
I know it would code crawler from
Switzerland and I know a German German
company which is having a similar tool
but compared to the framework the
framework allows you but basically to
put different tools together very
quickly we're really not trying to
bruising products
and so we're not really trying to eat
with products sure so if something's are
has been done before and it's been
commercialized and all that way I don't
know the problem is that if you have a
commercial to like I know one German
tool and they sell a license for $57 or
something and the problem is if you come
up in a year with a new kind of
visualization or new kind of programming
language and so on you will have to
spend a lot of time into getting this
tool to get the new features while if
someone creates a new present a
visualization that is interesting you
can put it in within hours into this
framework so there's a difference
rose is open source all we do is open
source and roses released vendor BSD
license it's not released on the web yet
we've given it out to about two dozen
different groups that we collaborate
with internationally but it'll be
released this summer I'm be happy to
give you you know access to the full
documentation there's about 15 megabytes
of of documentation and a package which
I could easily give out it's been
reviewed and released internally at the
lab they actually made me a reviewer
because they didn't want to really read
it but it's a huge amount of
documentation and it represents all of
our documentation for rose what you're
seeing in the tutorial is one of three
pieces of the documentation there's also
a manual and then there's also all of
the HTML web pages which document how
the classes are used for the
intermediate representation
50 to 250 thousand dollars probably they
charge me less than a charge you but
basically for research use there's
there's no problem we can get out of
binary so we routinely deal with the IBM
guys with their way by giving them a
binary and we'll make rose available
with binaries but there's there's
nothing that we really modify of EDG so
it's not really a big deal for us to
move up to your versions vtg etc but
we're of course very thankful that they
have this sort of research license
program which allows us access to it
yeah for research only we may at some
point decide to actually buy a license I
don't know but we'll see then then we
would remove all restrictions except
that we couldn't distribute their source
code but we'll see thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>