<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Statistical Aspects of Data Mining (Stats 202) Day 4 | Coder Coacher - Coaching Coders</title><meta content="Statistical Aspects of Data Mining (Stats 202) Day 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Statistical Aspects of Data Mining (Stats 202) Day 4</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qBcI9WakS2o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome to lecture four of data
mining at Google today I want to finish
up a little bit of chapter 2 that in cut
2 last time and then I want to get into
chapter 3 which is sort of one of my
favorite chapters because we get into
visualization of data so we start making
pots and things like that an R is very
good for making plots that doesn't
pertain to you okay so this homework
assignment it's going it's due for the
students that are taking it at Stanford
on Tuesday so remind me after that I can
email around the solutions or I'll
probably have them up on the webpage so
if you want to try doing some of those
exercises then you can check your
answers with that chapter 2 we were into
last time and we talked about data in
chapter 2 basically we tend to perceive
data in this matrix form where the rows
are what your books calls objects I call
observations and the columns are
different attributes or what I would
call variables and the last thing we
were talking about was suppose you get a
data set that's big in the sense that it
has a lot of rows or a lot of objects or
a lot of observations and maybe you're
trying to compute something like you
just want to know the the mean or
average taxable income right you just
want to know what the average is in your
data set well it may be sort of
inefficient to sort of do the mean of
the entire data set if you could just
take a random sample that may be
sufficient so last time we were talking
about sampling which is using only a
random subset of the data statisticians
often do something because they can't
get all the data they want they can't
get all the data from a large population
for example they want to know the
percent of all people that will vote for
a candidate well they can't ask everyone
in the US who's going to vote for a
candidate but they can take a sample
data miners like to do sampling because
often they have all the data or as much
data as they really want but it's sort
of just too slow or too cumbersome or
unnecessary to work with a whole data
set so we often just take a sample if
that's going to give us an answer that's
close enough to what we're after and I
think I mentioned you this this time
that I got this some quote from the book
but it's very circular right it says
basically a sample will work almost as
well as the entire data if the sample is
representative what does it mean to be
representative well that means it has
the same characteristics oh it's quite
circular but the point is it really
depends on what you're after if you're
after just the average well then the
sample might be good enough if you're
after sort of the largest case well your
sample is Prabha the largest value so
the sample is not going to work good
enough so whether or not the sample
works
really depends on what you're after but
for many things if you're just after
like the mean or the median or the first
quartile or something like that you know
doing it on a very small sample might
give you the same level accuracy as you
would get on the whole data set to the
point where you actually care about it
so often something can be very effective
simple random sample is the most basic
type basically you think of it as
drawing numbers out of a hat or drawing
names out of a hat where each name reach
number corresponds to a row in your data
set so you just think put all the rows
of your data set into a hat and draw
them out it can be with replacement
without replacement we someone asked
about the distinction between that last
time usually it's not a big deal as long
as the sample size is small relative to
the whole data set generally you like to
do things without replacement but as we
discussed sometimes it doesn't really
make sense so you do things with
replacement and then there's more
complex schemes and I think last time I
showed you an excel how to draw a simple
random sample basically all you need is
a pseudo-random number generator and
you're in business and there's one of
those in Excel which is the rand
function you can use that by default
draws numbers uniformly between 0 and 1
and then you could sort on that and that
would give you a random sample without
replacement and if you wanted to do it
with replacement you can imagine how you
would do that and here I have some
screenshots I think of what we went
through last time basically this last
column here was a random number I
generated using the rand and then I
simply sorted on that and then you can
pull off the top rows now in our there's
this function called sample which works
pretty well one of the advantage to
using this function sample is anytime in
R you can use some of their built-in
functions and avoid doing a loop it'll
make things much faster because loops
and are really slow so this sample
function is nice it prevents you from
having to sort of do a loop and calling
the random number generator time and so
the arguments it takes you see here X
which is what you want to sample the
size then the default is to use without
replacement so sometimes you have to
override that too to true if you want to
do it with replacement and I think last
time we left off here I was drawing a
sample of 10 observations from our stats
202 log data set so let's see how do we
do that well I put the code up here and
I'll sort of tell you what this does
basically I'm creating a new object
called Sam
and that's going to be a sample so
sequence of 1 1922 I'm gonna get a
sample of 10 integers from the sequence
of integers 1 to 1922 and I'm gonna do
it with replacement because I asked you
to do it with replacement so that's sort
of the first step and I think we
probably did that so if I just say take
this command now notice I called it Sam
and that sample because if I called it
sample of course I would be overwriting
the sample function and it wouldn't work
and our does let you overwrite things
like that and you can get yourself into
trouble so now Sam is basically 10
integers between 1 and 1922 sampled
randomly with replacement ok now how am
I going to use that well I'm going to
use that to index into my data set in
particular I'm going to take out these
rows and that's going to be my random
sample now I need to read in the data so
let me find it I think I should have a
local copy of it sitting around here
somewhere this is what stats 2 a 2 log
let me just put it here
I remember where it is let's see
grab the path and I'll set the desktop
to be my working directory so throughout
the day anything I say or anything I
load will be set working directory
desktop what Oh I spelled working
directory wrong WD working directory and
I usually include a command like this in
the beginning of my script however if I
move my script to a different folder
than I often have to update that ok and
I'm gonna do read let's see let's call
this data read CSV let's see it's called
stats 202 log text and it's crucial to
say that the separator is a space and
the header is not there
oops that's it equals ok and there's a
cute little feature here if you want to
sort of see it in a spreadsheet there's
something called data editor under the
Edit menu and I can type in to see what
this looks like
oops what just happened there
oh I called it dat well it's gonna be
called let me call it data don't confuse
me data okay so say edit data editor
data there we go so you see here this is
sort of a preview of what the data looks
like and you know it sort of chops
things off depending on the size of the
screen and things like that and the
other command that sort of is nice
sometimes a head of data I think just
gives you the first five rows by default
so anyway I've read in the data I have
my Sam object which is the numbers of
the rows that I'm going to take in my
sample and then I simply say here so the
question said okay I should say here the
question said draw a sample from the
first quantitative attribute now if you
remember that data set it turns out the
seventh column is the first one that our
thinks is quantitative it's not really
quantitative because you know so data
dollar sign v7 will give you the seventh
column oops
v7 will give you the seventh column
because the names of the the columns are
like V 1 V 2 V 10 etc so dollar sign V 7
will give me the column that's called V
7 that's equivalent to saying data
nothing comma 7 the seventh column and
you see R thinks this is numeric right
it's not a factor it thinks it's numeric
200 404 I mean we know that this is not
numeric we know that these are codes and
should be treated as categorical but our
things it's numeric and I want to play
with us a numeric example so let me just
pretend this thing is numeric okay even
though it's not really I guess I'm
illustrating you know one of the things
I tell you not to do don't treat
something as numeric too but it's not
but just for a numeric example I'm going
to use this one so what am I going to do
I'm going to take the rows that are
numbered Sam so I'm going to say data
dollar sign V 7 which is that whole
thing of 1922 and just the rows that
correspond to the numbers Sam and that's
going to be my random sample so what did
I call that on the slide I think I
called it my sample so say my sample
store as this thing data a dollar sign B
7 which is the seventh column and just
those rows what
oh that's gonna be a disaster
yeah okay there we go
my sample there we go
so it's just those rows okay so I think
that catches us up to where we were here
on the slide so I have an object called
my sample that is a sample of ten
objects from that data set now the
question is is 10 good enough right and
of course it depends well what are you
trying to do well suppose I was trying
to figure out the mean of the seventh
column how well can I figure out the
mean of the seventh column with just ten
numbers and that's sort of what this
slide is asking it says if I do the
sampling the previous exercise
repeatedly roughly how far is the mean
of the sample from the mean of the whole
column on average so we can sort of see
for one instantiation here see if I can
blow this up a little bit make it a
little bit bigger for you guys let's see
gooey preferences let's do a font of
size 14 that should help a little bit I
go down here there you go okay
so if I take the mean of my sample can't
type today okay it's 260 1.2 so let me
so this is sort of the mean of my sample
so it's called a sample mean and this
time came out to be what 260 one point
two and then we could compare that to
the true mean now in general if you
didn't really want to mess with the
whole data set you wouldn't really know
the true mean but here it's only 1922 so
let's just look at the mean of data
dollar sign the seven and so the real
mean is two hundred ninety nine point
three let's just call it like you know
roughly three hundred right okay so our
Delta or we call it like our absolute
Delta sort of the price we paid for
taking just ten observations as opposed
to all 1922 we're off off by roughly
forty okay so that's sort of the price
we paid and you can see if you do this
thing repeatedly if I take another
sample let me go back and just do this a
couple more times take another sample
and get that guy and then again take my
sample to be that figure out the mean of
my sample this time I got three hundred
forty two point eight but it depends on
what ten observations you get so then I
got three hundred forty two point eight
the true mean you know is still roughly
three hundred that doesn't change so now
I'm off by I guess I'm off by about
forty in the other direction sort of
cute and let me do it one more time just
so you sort of again take a sample and
figure out the mean of it and this time
I got 302 so I'm really close this time
right so the true mean is approximately
three hundred so this time my delta is
about two so off by forty off by forty
off by two okay so the question is you
know on average how far are we gonna be
off if I keep doing this over and over
again you know what's like the average
value of these deltas and what you can
see up here is I wrote a little loop to
do that for you and this is sort of the
first loop we've put up in our so I'll
sort of mentioned what's going on here
first thing because I don't want to call
mean every time in the loop I just take
a constant and store that is the mean so
real mean store as the mean of the
seventh column so this real mean object
is basically going to be you know about
three hundred whatever that two hundred
ninety nine point whatever was now I
like to initialize variables in our
which you don't really need to do but I
get in the habit of this so I'm gonna
store the differences in this Specter
and I'm gonna go through this loop ten
thousand times so I just create a vector
of all zeros and a vector of like ten
thousand that's all zeros and I'm going
to put the differences in there so like
you know these could be the first three
forty forty two I'm gonna do it ten
thousand times and here I start writing
the loop and so this is sort of how a
loop looks in our for K in one colon ten
thousand right so K is going to start at
1 and go up to ten thousand each time
I'm going to draw a sample so this
command is the exact same thing I did
before sample of size 10 with
replacement that I'm going to say my
sample I overwrite my sample with data
dollar sign d7 whatever the rows are
from this sample and then store
difference the key element of store
difference I'm going to put as the
absolute value of the difference between
the mean of my sample and the real mean
and then I'm going to compute the mean
of those which this time I did it it
came out to be about twenty five point
seven or what I said here about twenty
six here you see you know I got 40 42
the claim is that this thing averages
you know roughly 26 and you know just
for sake of doing it in real time you
can see what would happen if I would do
it here so let's see the real mean
that's going to be this two hundred
ninety nine point whatever number right
real
oops real mean and then the store
difference I just initialized that's
just a vector of all zeros yeah let's do
that
why not 100,000 times okay one more zero
right okay and then I have to change
this one to a hundred thousand the loop
cenar are really slow oops
shoot okay hundred thousand okay
what's the what stand for where do you
see our AP Oh rep okay a rep it just
seems like repeats that thing that many
times so if you did question mark rep
you would see the first argument is what
you want to repeat and the other thing
is how many times you want to repeat it
so that's just going to be a vector of 0
repeated a hundred thousand times let's
see it's just my way of initializing it
and initializing it at zero I don't know
maybe that's a bad habit but I sort of
haven't I got into at some point okay so
I'm still going to take samples of size
10 and then let's see each time we're
going to make my sample to be those 10
guys and then I'm going to compute the
difference to be the absolute value of
difference between the sample mean and
the real mean and then close that so it
was a hundred thousand times
you keep wait wait wait wait the loops
in our our you know slow right oh wow
that's life and then let's see the mean
probably pretty close to 25 point
something 25 point five so we call it
about 26 so we're off by an average
about 26 so 26 is sort of the price we
pay for having to for taking just 10
observations as opposed to taking the
whole 1922 and so you say well if 20
six is too big of a price to pay if you
don't want to be off by 26 on average
what do you do well then you take more
than ten the interesting question is to
see how sort of our error scales as we
increase that but before I get onto that
anyone have any questions about sort of
this our commands on the slide here okay
so it's your first example of writing a
loop in our don't get into too much of a
habit of writing loops NAR because you
see that they are pretty slow but you
know for simple simulations you can just
say well I don't want to think about it
I'll just write a loop and see how it
goes okay so then the question is you
know if I'm off by 26 on average by
taking a sample of size 10 what if I
take a sample of size 100 right then I
should be closer and here you see I
wrote the same thing except I changed
the sample size to a hundred and now I'm
only off by like eight on average right
so I went from having an error we call
this sampling error of about 26 to a
sampling error about eight meaning the
price I'm paying for taking a hundred as
opposed to all 1922 is I'm off by about
eight and so the question of how big the
sample is depends sort of on well how
close do you really need to be now the
interesting thing is that you'll see
that it actually scales as a function of
the sample size more so than a function
of the whole population size so you know
you say ten or a hundred or ten thousand
you you know and you're gonna get closer
and closer and closer no matter how
large the data it is which is sort of
interesting but the point here is that
by going from 10 to 100 now we're only
off by 8 if you want to be closer than
that you could go by a thousand but the
thing to talk about now see where is
this eraser is that I want to just
mention the relationship between the
sampling error which here we saw went
from 26 to 8 as I increase the sample
size from 10 to 100 and that actually
illustrates sort of the point I'm going
to make if we have a sample size of 10
so let me call this sample size sample
size of 10 we saw that our average Delta
which is what I'm calling my sampling
error was about 26 roughly and when I
used the sample size of 100 my average
Delta was about like 8 point
okay so the question is you know this
thing is decreasing as this thing
increases but the question is at what
rate anyone know what rate square root
right turns out to be the square root
and that's sort of what I said you're in
the next slide it's the square root
sampling what'd I say the square root
sampling relationship when you take
samples the difference between the
sample values and the values in the
entire data set scale is the square root
of the sample size for many statistics
such as the mean it's not true for
everything but it's true for the mean
true for the median true for any
percentiles true for a lot of things
wouldn't be true for the max for example
okay for example in the previous
exercise we decreased our sampling error
by a factor of the square root of 10
right
by increasing the sample size from 10 to
100 since 100 over 10 is 10 right so I
went from 10 to 100 which means I
increased my sample size by a factor of
10 which means I should have decreased
this by a factor of the square root of
10 which is about 3.1 right oops oh yeah
here square root of 10 is about 3.1 so
roughly 3.1 and likewise the ratio of 26
to 8.1 is about should be 3.1 right
twenty six to eight point one oops
twenty six to eight point one about 3.2
so you know actually this one is also
three points so perfect right perfect if
you only keep one decimal so that's the
square root relationship the interesting
thing to note is that it's only the
sizes of the samples that matter and not
the size of the whole data set because
this relationship basically is assuming
an infinitely large population so of
course this relationship sort of doesn't
work as well as you start to have a
sample size that's closer to the whole
population size but usually the sample
is small relative to the entire size of
the data set so this relationship tends
to work pretty well and so you can
imagine that your sampling error
generally scales as the square root of
your sample size why is this true well
it's a pretty trivial statistical
exercise to see that the variance
scales linearly when things are
independent and then the standard
deviation being the square root of that
scales as the square root of the sample
size question so the the thing you need
is that the sampling is independent and
that the observations are independent
that's what you need that's what you
need yeah you need it to be you needed
things to be independent so that's why
you can add the variance that's right
you can add variances if things are
independent and so you add the variances
of n thing it goes like linearly and
then eat the samples divided by n so
that's divided by N squared so then you
get the one on n in the square root one
on it okay so this is sort of a basic
result from statistics right because
statistics does a lot with sampling not
because they get huge data sets but
because they get small data sets and
they want to know sort of what their
sampling error is okay any questions on
this square root relationship question
in the back yeah probably that's better
right so if you know that the sampling
error goes down as the sample size goes
up so really an inverse-square
relationship right right and in
particular the sample mean if you're
curious actually scales as the standard
deviation divided by the square root of
n but other statistics will scale with
other constants but the square root of n
sy is going to be in there for most of
these things other questions about the
square root sampling relationship or the
inverse relationship okay so that's
actually all I wanted to say about
Chapter two
oh no not all I want to say that chapter
two one thing about sampling is that
it's not the answer to everything if you
have these independent observations
right if you can imagine your data
looking like independent rows and it
doesn't really matter which rows you get
because all you're gonna do is something
like the mean or something like that
then sampling sure that's easy but when
you don't have this independent
structure like so for example here's
words of a song write words of a song
are not independent if I just take a
random sample of words from the song I
have no idea what the song is about
um other applications right if I take
independent samples from my weblog well
that's not really the right thing to do
because I get you know this person doing
this thing then this person doing this
thing but I don't really know what any
one person did so instead of taking
independent samples from my weblog maybe
I want to sample IP addresses you know
or even better if I knew
the users were I could sample users or
maybe I want to sample days right out of
365 days I want to take 10 days internet
searches right you don't just want to
sample from your from your log certain
certain actions right you want to sample
click from this person to click from
this person you'd rather sample the
entire session from a small number of
people right or at least the entire
query session from a small number of
people so you really need to think about
not breaking relationships and in this
sort of toy example of a song instead of
just sort of sampling words you might
want to sample complete lines right so
not ten percent of the words but ten
percent the lines or maybe you want a
sample you know if you have a whole
bunch of songs not ten percent the words
but ten percent the song so you need to
sort of keep units intact when there's
dependencies within the units now the
tricky thing is with a large data set
that you haven't explored that yet you
might not really know what these
dependencies are that you need to keep
intact so sampling is sort of a first
thing to do is not always the best thing
to do because you don't sort of know
what your sampling unit should be in the
previous example with the web logs and
I'm just after the mean I just take some
rows great because there's no dependency
among the rows it doesn't really matter
but in an example like this with the
song maybe I should take entire verses
or at least entire lines but if I just
take words you know ten percent the
worst does not give me ten percent the
information in the song right in fact I
have no idea what this song is about
yeah you're right right but you know
someone on the right someone will know
so anyway that's that's the final word
on sampling okay any questions about
that so the point is sampling is not
that obvious you can't just say oh I
have a lot of data let me take a sample
because unless you really know the
relationships in the data you can't
really just say I'm not going to lose
anything by taking a sample because you
might break some of them okay now that's
really all I wanted to say about chapter
two chapter three is sort of a very
interesting chapter one of my favorites
it's talk well probably my favorite
chapter that we'll do because we get to
make graphs and things like that
it's called exploring data and they
divide the chapter so three point two
deals with you can so you can either
explore data numerically using like
summary statistics you know like the
mean the standard deviations or the
percentiles or you can do it visually
using tables and graphs and they start
off with the summary stats in 3.2
but then they do the visualization in
three-point-three I'm gonna begin with
the visualization and I'm gonna argue to
you that that's actually sort of in the
right order to go in because you've
probably seen people before that they
get some data the first thing they do is
compute the mean well if all the data is
between you know like zero and a hundred
and one number is like a million then
computing the mean probably isn't the
right thing to do until you throw out
that huge outlier so you would catch
that with visualization but you might
not catch it with summary statistics so
usually the advice is to start with
visualization and that's what we're
going to do also know that as we go
through this chapter and talk about
visualization many of the techniques you
would use to explore data visually you
would also use to present data now the
types of you know graphs that you're
going to use for presenting might be
different from the ones you want to look
at just when you're exploring but a lot
of the techniques are similar and things
that are meaningful to you as you're
exploring the data are also likely to be
meaningful to other people as you're
presenting the data to them so page 105
they start talking about visualization
they say visualization is display of
information in graphical or tabular
format successful digital is a
successful visualization requires the
data be converted into a visual format
so the characteristics of the data and
the relationships among the data items
or attributes can be analyzed to report
it goal of visualization is
interpretation of the visualized
information by a person and the
formation of a mental model of the
information so usually if you think
about in terms of presenting people may
not remember the numbers you gave them
or the table you gave them but they'll
often remember the picture that you gave
them right and they say you know the
picture is the thing that makes the
impression on people and they'll say oh
that's that report with that picture and
we make fun of people you know they
didn't actually read the report they
just looked at the pictures but the
pictures should sort of be the most
meaningful thing and the thing where you
can sort of say the most and so that's
why we'll spend some time talking about
different pictures that you make for
data in this this subchapter okay so
this is sort of a really toya example
but I like the fact that it's a toy
example because if you can't see what's
going on with 40 numbers you know
imagine that you have 40 million numbers
you really can't see what's going on and
so here I just have 40 numbers I taught
a class once with a two hundred point
exam and these were the forty scores and
so the question is you know like okay
you know you're you're the you're the
professor you get back is the exam score
how'd the class do right what do these
numbers tell you well if you just look
at numbers you say well it just looks
like 40 numbers I mean you can start to
look and you can see well least no one
got a two-digit number because I would
notice that right away you know so these
starts when we got over 100 but it's
really hard to see sort of any anything
interesting in this data now there's
only one one attribute right it's their
exam score so I'm not looking for
relationships so with only one variable
what I would be curious about is what is
the distribution of this data and the
way to look at the distribution of this
data is what your book talks about a
histogram so you've probably seen this
before so one thing you might get out of
this if you are familiar with these is
how to make one an R so where does the
histogram basically it's a plot okay and
it displays the distribution of the data
by basically dividing the possible
values into bins and showing the number
that fall into each bin right so with
those exam scores you might go 100 to
105 say how many people were there 105
to 110 so how many people are there you
can also make them relative frequency by
simply dividing the counts by the total
which would be useful if you were
comparing different size groups the
table that goes with it's called a
frequency distribution and an R there's
a function H is T that's useful and let
me demonstrate that to you now the nice
thing about the histogram is it does
scale well right because it doesn't
matter you know here I have 40 numbers
but it doesn't matter if I have you know
40 thousand numbers because I get to
choose how many bins I'm gonna make and
the counts you know can get big and I
can just rescale my y-axis so the
histogram is fine for large data sets
you know might take you a while to
compute but it's a good way to summarize
it let's look at this hissing in R so I
said make a frequency histogram in R for
the exam scores using Whitsitt bins of
width 10 beginning at 1:20 ending at 200
so we go 120 130 130 140 etc like that
so here's what you do so first of all
this is just reading in the exam scores
right there's no hetero hetero equal
false then I called the hist function
now some functions in R for plotting
will sort of automatically plot for you
whereas other functions need to be
called within the plot function itself
so this is one if you just call hist it
automatically makes a plot for you I'm
gonna plot the first history the first
column of the exam scores there's only
one columns
that's going to be that then I specify
the brakes and here I'm gonna use that s
DQ the sequence function 120 comma 200
by 10 so that's gonna be a vector that
goes 120 130 140 etc color Co L is color
you have to quote the color otherwise
we'll look for an object named red X
label Y label these are whenever you're
plotting in R you usually get to specify
these or override the defaults that's
the x-axis label that's a y-axis label
then the main is simply a title on the
top of the plot and there's usually a
default value so if you don't want to
title up there you could just put quotes
with nothing in there so I'm claiming
this it's gonna make a histogram for you
let me sort of demonstrate that to you
so exam scores here let's see so you can
see we have exam scores now there's all
40 of them and what else am I gonna do
call the histogram function and there
you go there's your histogram so you can
also see so the labels are the labels I
put on there if you wanted to do you
know you suppose you said okay I want to
do a hundred to 200 right you don't want
to start at 120 well you could do that
too right you would have just set this
to be 100 suppose you don't like red
suppose you want to be pink X label I'm
gonna leave the same then main maybe you
don't want any title at all you could
change that and Windows Device there you
go
there's a different one starting at now
100 as opposed to 120 and now pink okay
so it sort of gives you flexibility to
do things like that the other thing is
if you don't want the plot you just want
sort of the accounting done for you I'm
gonna show you in a second how you can
get the histogram function to actually
give you values as opposed to making
plots but by default is just going to
spit out a plot at you and that's called
a histogram now what can I see in this
data well I can see things that I didn't
see before I start to see that like you
know there's a lot of people here a lot
of people here but it's curious that
there's not that many people there right
you might sort of expect sort of a you
know modal thing but it almost looks
like it could be bimodal now with a
sample of size 40 I don't know if this
thing is really going to pursue
but as an instructor you might worry
right if you're grading people and a
whole bunch of people are here and a
whole bunch of people are here but
there's no one really in the middle you
know you're trying to tailor your
lecture to sort of hit the people in the
middle and what happens is you're not
hitting anyone right half the people are
saying this is too easy half the people
are saying this is too hard no one's
happy and you're not just gonna see that
by looking at a list of numbers but when
you start to look at the distribution
you see it right you certainly wouldn't
see by looking at the mean because you
probably see oh the mean is right there
and you think things are perfect right
the mean is like a sea or wherever I
want it to be but it looks like it might
be a little bit my modal which would be
of concern okay so I think that takes
care of the histogram of any questions
about making a histogram in our the plot
window if you want to sort of save your
plot you have a few options so one thing
is there's commands like PostScript and
PNG which sort of if I you know you look
at PNG basically you call the PNG
function then whatever plots you produce
after that will be written out to
whatever file name you specify
PostScript is analogous if you're just
sort of playing with it in a Windows
environment here and you make a QQ plot
and you say weird my cute plot go you
say you make a Q plot and you just want
to immediately save it right you don't
want to have to go back and and do
anything then it actually lets you sort
of click and save it right so you can
click on this thing into a file save as
and it lets you export as PNG PDF JPEG
anything you want there PostScript the
PostScript I think has encapsulated
PostScript which is usually what you
want so anyway the plotting in R is
really nice it gives you a lot of
flexibility later on in this chapter
I'll show you how to sort of change a
lot of the other parameters in the
plotting but there is my histogram for
my exam scores for that toy data set ok
any questions about that histogram in R
okay so that's one basic plot you can
make now sometimes you don't want to
make a histogram with these bars right
if you look at some of the plots that
that people make having the bars is a
little bit childish and you're sort of
wasting a lot of ink that it doesn't
really need to be there so what people
sometimes do is they just sort of take
the midpoints of the histogram and they
connect those by lines and that's
generally called a polygon
I'm sorry frequency polygon or could be
relative frequency polygon if you divide
by the total to make them decimals they
don't talk about this in the book but I
mean from a histogram it's easy to
generalize by convention we usually like
I said use the midpoints of the
histogram bins and then they include two
extra bins at either end just so you get
it going back down to zero so it looks
complete and I'll I'll demonstrate that
for you now there's no function in our
that I know of to make a polygon but
that's okay because you can trick the
histogram function into making a polygon
for you and so here I said basically
make the polygon an R for the exam
scores same bin widths starting at 120
and at 200 so this is how I do it and
let me explain to you what's going on
here I first treat an object that's
called my histogram and I call it the
same as I did before exam scores column
one breaks 120 to 200 by 10 but then I
say plot equal false and some function
like histogram that by default produces
a plot when you say plot equal false
it's not going to produce a plot anymore
it's going to create you know this
object well let me let me just sort of
show you what's in the object cuz a
whole bunch of different information is
in the object that would be used to plot
it if you were plotting it so when I do
this okay I get an object that's called
my hist and what does it have in it well
it has a bunch of things it has
attribute that has the midpoints has the
density which would be if you scaled it
to an area Juan has the intensities
which looks like the same thing as the
density has the counts okay so that
would be useful and I think it has one
other thing that you can't see here
which is the the bins
so it has the midpoints to 125 135 it
also has the 120 130 so for example if I
say counts let me grab the counts out
there counts store is my histogram
dollar side and counts it's going to
give me the counts that were up here
right it's going to give me a vector of
those numbers so now the counts I've
stolen from the histogram function I've
stolen the counts and I can also steal
the breaks that's what it calls the 120
130 etc breaks so I've stolen the breaks
from it so basically the histogram is
nothing more than a plot of these
numbers and these numbers
you know this on X and this on Y and so
is the polygon right so once I've stolen
those out I can use our to basically
make a plot of these numbers as a
function of these numbers make points
connect them by lines and so in R
there's this really great function
called plot and this can sort of
basically make it you know plots as you
would want to specify them right you
specify what you want to plot on the
x-axis what you want to plot on the
y-axis now in this case I did 115 comma
breaks plus 5 right so the first breaks
was 120 130 etc so this would be 115 125
135 145 so that's what I wanted to do
when I said I want to use the midpoints
I don't want to use the 120 and 130 I
want to do that and then of course I put
a 0 at either end so 115 gets a 0 and
205 gets a 0 and you'll see this when I
make the picture PCH
I'll talk more about this next time but
whenever you're plotting in sort of
these stats software packages using the
defaults is not always a good idea for a
couple reasons one is they don't often
look good and two people sort of know
that you use the defaults and they may
be you know associate you as someone who
doesn't know what you're doing so you
know I mean it's like the same thing in
Excel when you see the gray background
you all you think is they don't know how
to change that because clearly it
doesn't look good so the default in R is
to make the points with little circles
so I tend to like PCH equal 19 which
makes the points of solid dots which a
looks better and B tells people I you
know I know what I'm doing the X label
and the y label I specify those before
and then the main is the frequency so
let me just sort of show you that and
again let me stress that the syntax for
plot is the vector of X values comma the
vector of Y values and of course those
have to be the same length or it will
complain right so what do you want a pot
on the X what you want to pot on the Y
and then by default it's gonna make a
scatter plot so let me sort of do that
part for you here and windows there we
go
right so the 1 15 1 you know 115 125 135
etc was specified there and then the Y
values were the frequencies with the
extra 2 points at 0 and so then the only
thing else I have to do to make the poly
is to connect these points because
whenever you're making a graph like this
that you're trying to read you know it's
hard to see if you haven't really
connected the points in order so there's
another great function in are called
lines and the lines function takes
pretty much the same arguments this plot
with you can't specify these many things
again because the line function actually
is just going to add to the plot and so
I give it the same X values as I did
plot and I give it the same Y values as
I gave plot and it basically goes back
into plot and connects the plot points
with lines so plot and lines together
you know plots going to give me a plot
with points on it within lines if I give
it the same X and same Y we'll connect
those points with lines and so let me
show you that here and again it's not
going to overwrite the plot it's just
going to sort of sit on top of the plot
and there you see and ours kind of like
the last thing you add is the thing
that's on top now nothing that's being
covered up here that's the general
behavior so there you see the polygon
this is the same information that the
histogram has but I haven't had to sort
of waste ink with the different bars and
the advantage to this is that I could
put a second one on the same plot and
nothing would cover each of anything up
because you can imagine you can put you
could not put two histograms on the same
plot right you can't put two bars the
bars would cover each other up and let
me just sort of show you that in fact
this is the same as the histogram by
doing the following
P a are actually maybe I'll write that
down now is sort of the answer to all
your plotting questions and we'll talk
more about that next time but it sort of
lets you control everything and in this
case well I'll just show you PA are
right you you can just read this and
after you read it you'll that you'll
you'll make the following generalization
I can do anything I want when I'm
plotting in R and there's probably some
three-letter you know three-letter
string that specifies it right so lab
lasts you know all these little things
do a lot and you can just keep reading
in particular this time I am after the
function called
MF row oops MF row which specifies how
many rows and how many columns I want so
I want to try and put two things on the
same plot so I'm gonna do actually let
me do two rows and one column
okay so ups so net whoa
so I think any equals not apprentices
there we go so now everything I've
caught after this is going to sort of
you know two things per plot right so if
I go back well let me let me plot this
one that I just plotted the polygon
paste this and then paste this I'll talk
more about the power function next time
because it does give you a lot of
flexibility and if you look at the plot
now it's the same plot before but it's
sort of squeezed it on to half of the
page right so same polygon as before so
it's squeezing on to half the page now
that I do that I think I maybe actually
liked it better the other way I leave it
okay and then if you go back in compare
to the histogram you made before you can
see how the polygon relates it's the
same picture oops what happened I closed
it okay well now's my chance to fix it
okay so let me do one comma two okay and
then a histogram so histogram okay
there's this room that don't close it
and make the polygon
there's the polygon here okay where are
the lines add the lines okay so now as
the picture I was after there you go you
get to compare the two side-by-side so
you see that it's really the same
information that I simply put a point
here a point here a point here alright
point here point here point here then
they just have these two extra guys
right so that when you come here you
don't want to leave them hanging in the
air you just sort of go down here so
this point is at 195 right 190 200 195
then this would be 200 210 so the last
point just for equal spacing goes at 205
so that's kind of polygon displays the
same information as a histogram but I
haven't sort of wasted ink I still see
that my class scores are sort of bimodal
with a lot of people here a lot of
people here but not many people in the
middle and the nice thing is if I gave a
second exam I could make the polygon on
the same plot and I could compare them
whereas
would be impossible to make two
histograms on the same plot because the
bars recover each other up okay so
that's the polygon and I think that's
all I wanted to say about that any
questions about the polygon in our
question I think it's not so bad it's
just you probably wouldn't want to put
2/10 there like I think you like to keep
the equal spacing but it's really you
know if it ended at zero you wouldn't
want to put like a negative ten I think
it's okay you know because you like to
keep the equal spacing but like probably
not want to label it because it looks
stupid yeah yeah that's a good point
so if it really stops at 200 his point
is questions why does the graph go
beyond 200 okay any other questions
about the polygons of the histogram in R
okay so both of these show the the
distribution of scores and so within any
bin I can see sort of what's the count
or what's the percent sometimes though
what's even more useful and I'll
probably try and give you some examples
of when it's more useful is to look at
the oh so there's my answer on the slide
is to look at the cumulative
distribution right so not what percent
got in this bin but what's the total
percent less than each value and of
course we call that the cumulative
distribution function right cumulative
means you know accumulates right the
percent less than each value and so in
statistics you'll hear sometimes people
talk about the CDF which is the
cumulative distribution function right
it starts at zero ends at one or a
hundred percent and this is for any
point is basically the probability of
being less than that value so what we
have when we have data is we have the
empirical cumulative distribution
function right so for any point I know
the fraction of points that are less
than that value right so what percent of
exam scores are less than 100 what
percent are less than 120 what percent
of less than 200 right for any value
this function returns the percent that
are less than that value and sometimes
people call the plot of this thing the
part of the empirical cumulative
distribution function sometimes they
call it an ogive which I don't know it
doesn't get used that much but just so
you know it's not in the book I mention
it anyway someone wrote right R is open
source so someone wrote a nice function
called ECD F in R that does a pretty
good job as far as I can tell
plotting the empirical cumulative
distribution function and of course you
can think about how do you make that
thing right you simply say okay this
would be like the exam score and then
this would be you know the the
cumulative percent and it would start
off you know it you know 100 over the
lowest score is at zero and it would
work its way up to a hundred percent
right here and it would simply go up by
one over n every time someone's scored
or if two people got that score would go
up by two over n right so some sort of
plot like this and then how would you
use it well I'll show you I mean you can
say okay here's 50 percent so what's the
median right there okay what percent got
less than this value well that percent
did and so sort of show you how this
thing works so this thing says make a
plot of the empirical Okuma distribution
function for the exam scores using the e
CDF function in R so how do you do that
well I told you that the R is kind of
funny right that this function e CDF
does not it's much different from
histogram right it doesn't by default
produce a plot it actually is written so
that you're supposed to call plot and
then inside plot put this thing and
that's not consistent at all with the
behavior for histogram right histogram
when I called histogram I got a plot and
if I wanted sort of values out I had to
sort of say plot equals false with this
function by default I get values and if
I want to plot it I have to put it
inside plot which is sort of curious so
you know if you sit at home and you keep
typing e CDF and you never see a picture
it's because I have to say plot of that
ok
so e CDF of the exam scores column 1
which there's only one column but if I
don't say column 1 it gives me an error
verticals equals true why because
verticals defaults to false which means
that it only has horizontal lines never
has vertical lines and looks really ugly
do dot P okay do I want it to plot the
points that's what that means no I don't
right that's as far as I can tell it
because by default it puts these little
points on there as circles and believe
me it looks better without it maybe I'll
do one by the default and you can see
the default looks pretty ugly the main I
just put a title on the top X label y
label you know you can always specify
those the nice thing though when you
make a plot you know this is sort of one
of these elementary things but label the
axes so
the person doesn't have to read anything
to know what the pot is saying right so
if you've labeled the x-axis exam score
and the y-axis cumulative percent then
everyone's going to know what that pot
is plotting if you say if you don't put
labels there then you know someone's
gonna pass around your pot and no one's
gonna know what it means so I always
like to put labels on the plot that are
sort of enough for someone to know what
the heck it's saying okay so this is
going to work to make empirical
cumulative distribution function and so
I say here and there we go
okay and you can see what's going on
here right so you know no one got below
here and then someone got a score there
right so it goes up I went over at and
then someone got a score here so it goes
up by you know another one over N etc
and like it looks like two people scored
here so it goes up by two over and etc
etc etc and in the end of the day you
know the highest score was somewhere
here and so then it goes you know 100%
how is this useful well I want to know
what percent got less than 160 so I go
here and it looks like about thirty
percent I want to know what the median
is so I look at 50% polit over here
median looks like it's 170 you know I
want to know what the 90th percentile is
follow 90 over here it's like there okay
so it's very nice like that and you
imagine as you get more and more data
it's only gonna smooth out more and more
so that is your product and critical
chemo distribution function while I'm
mentioning it I'll just say to you that
if you don't whoops if you don't change
the defaults you can see that it's sort
of as ugly so if I just say this right
I'll get a plot but it won't look that
nice I think let's see where's my plot
there you go by default it doesn't have
the vertical lines in there and it has
sort of like these circles so I don't I
just sort of thought this thing was ugly
so that's why I showed you how to change
those defaults you also see that it just
labels this as X you know and then this
this is sort of meaningful if you're
well I don't maybe not of X is usually
the CDF and stats but and then you know
this is completely unreadable so that's
why I like to change those I'll show you
to like you know that again it is open
source so if you look
some function like this you can see here
like the documentation isn't that good
but the nice thing is he provided a
whole bunch of examples so you can
always just sort of paste these in and
see what they do and change the values
and see what's going on you know so it's
examples instead of documentation or you
just email the poor guy and you tell
them you know I have no idea what your
code is doing you know and so anyway
that it is open source so it's good to
sort of and a lot of times authors when
they write books too will actually write
their own libraries these authors did
not because it's not really in our book
but a lot of times they will write their
own libraries and you can sort of play
along with the book and there are at the
same time so there's the one I put up on
on there the the last thing well I think
I just I'll just save this right but the
next thing we're gonna talk about is you
know if you have another set of data
right so here at the end of the semester
I give a second exam and I want to
compare these scores to the other scores
how can I do this well with the CDF the
e CDF function in particular human
distribution function no problem putting
those on the same plot same thing with
the the relative frequency polygon right
you can put those on the same plot it
doesn't matter that there's fewer scores
here it looks like three people dropped
out of the class
it doesn't matter right one has a
denominator of 40 that it has a
denominator of 37 as long as you're
working with percents as opposed to
counts it won't be any problems so next
time I'll go through and show you how to
put sort of you know two polygons on the
same plot two empirical accumulate
distribution points on the same plot and
we'll talk about sort of general other
types of plot so you can make an R and
I'll make a plot of the web logs and you
can see some spikes that are curious so
the next lecture we'll do a lot more
with potting and I think that's all I
wanted to say today any questions before
we take off question in the back yeah
you can um basically well to tell easy
DF to give a percent you probably have
to go back I'll put the take the output
from that function divide it and then
plot it again unless he has put
something in there to do it but he may
not have so you don't want it to go from
zero to one you want to go from zero to
100 right if you didn't put an option
there for you to do that what you do
instead of plotting it you create
an object you know or you get the output
from it you take that output divide it
by a hundred or multiplied by 100 and
then put it back in there so yeah other
questions before we take off okay I'll
see you guys to z' day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>