<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Augmenting Social Cognition: From Social Foraging to... | Coder Coacher - Coaching Coders</title><meta content="Augmenting Social Cognition: From Social Foraging to... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Augmenting Social Cognition: From Social Foraging to...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kAPwDda9p3k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I realized that this is a kind of an
interesting position for me to be in to
talk about sort of something that's new
to people who might know already sound
this stuff so feel free to interrupt
them and ask questions during during the
presentation so I want to tell you a
little bit about something that we've
been calling augmented social cognition
at park for a little while and this is
joining work with two of my entrance
Anika couture who's at UCLA Todd make of
its at UC Boulder and Brian Pendleton
who is a programmer in our lab and
balance who who is a recent hire in our
group so first I wanted to sort of give
you a little bit of a retrospective on
the kind of work that I've been doing
since I actually started out in the area
of graphics and information
visualization many many years ago and
for which I'm probably the most
well-known for some work that we call
sort of visual sense making that is
making sense of information through
visualization and I just show you very
quickly some pictures of the kinds of
things that we've actually done so for
example in 98 @ published in the chi
proceedings some visualizations of whole
websites and your traffic patterns so
you could actually see where the
interest or attention people are paying
in these websites then that actually led
to some work in which was actually the
topic of my PhD thesis which is the
visualization spreadsheet and that is
about representing whole data sets like
for example the traffic pattern of an
entire website and put them into a
spreadsheet and represented graphically
and you can actually do subtractions and
additions between the traffic and
actually do computation around the
traffic patterns that exist on the
website then I was hired to park about
10 years ago and ever since then I've
been working on the contact color
information sent which is a series of
underlying technology that is used to do
things like for example simulate the you
stage of a website and naturally
identify usability problems and that was
actually embodied in a almost product a
product that never made it to the market
called bloodhound you know simulating
how people actually sniff through the
website and follow the information cues
to the information they're interested in
and then I also worked on the system
Colombo Jack which is a user logon
alistair log analysis tool that in
addition to the actually doing the
analysis he also did this extra
clustering step that actually figured
out what users must be paying attention
to so he actually can tell you things
like for example thirty percent of your
users are actually interested in
downloading drivers and twenty percent
of your users are going to the support
site then from there I actually worked
on a bunch of search and foraging tools
things like for example published in the
ACM tokai a journal was this idea called
central that I worked on with a student
of mine named Chris Ulster who's now
assistant professor at CMU and the idea
was to use this information set modeling
method to actually highlight URLs or
links that the system is predicting that
a user is likely to want to follow and
their turns out that you can speed
people up by about fifty percent when
you do this kind of predictive
algorithms
that's right it's actually based on the
profile of the user in the linkage and
textual analysis of the website and then
I worked on something called send index
which is about how do you take something
like the back of the book index or some
sort of hierarchical ontology what
happened that's not cool yeah stupid um
apologize for that so which is about
using ontology information to see if you
can actually enhance the way people can
browse through a book and then from
there I also worked on something called
send highlight which is about using
these kinds of computations to figure
out if you can actually predict where
people want to pay attention to in
pieces of text and actually highlight
key words or phrases in which people
might want to pay attention to so you
can pre highlight imagine getting a text
book that's already pre highlighted with
all the interesting bits that that you
might want to pay attention to and
that's what sent highlighting did and so
is it the same for everyone no you it's
again you based upon a combination of
user profiles that you've given to the
system as well as a set of search
keywords so it's a combination of those
statutory highlights the places that you
might want to pay attention to and then
of course there's evaluation behind all
this this search tool and foraging tools
that I worked on one of them was
actually using eye trackers to figure
out if people were indeed paying
attention to these highlighted areas and
on top of all this yeah that's like
we evaluated both before and after as
well as alternative methods of
highlighting where you only highlight a
key words as opposed to sentences and
things like that and so this is actually
to be published this summer and the eye
tracking analysis of this kind of stuff
obvious is extremely challenging but we
have a whole laboratory setup for for
this kind of analysis and then finally
I've actually also worked on some
personalized search which I do not have
time to to talk about and it's not yet
been published to anyways so all this is
to say I've spent six minutes to tell
you a little bit of our history which
I'm not expecting you to know all the
detail of the things I talked about but
is to say that this is basically the
environment in which i've been working
in for a long time which is part of it
obviously this is my actual office at
park and as you can see i have six
screens and i have a funky keyboard and
what this is all about is saying that
I've been focused for the last several
years ten years or so all on this sort
of personal computing you end at this
top kind of environment right and one of
the things that we do at park is to say
well we should take this to the max that
is now how many of you have been happy
with working in front of the airline
tray table right I mean that's the size
of this this laptop right so we said you
know screw that right that's actually
replicate what it would really be like
working in front of a desk that's six
feet wine that's why many of us at Park
actually have six you know high
resolution screens in front of us and
you know notice things to see what
that's like so the history of my
research has been in this area of sort
of disk top computing how the intense
people's productivity and etc but then
after all these years I kind of had this
realization and I really think it's
somewhat of a stupid realization and
this constant surprise to many of you
that humans are in these social animals
and we want to connect with other people
one reasons why I'm
here and you're willing to listen to me
on streaming grateful is because you
want to find out you know why I'm like
and what my research is about and that's
a social at actually right and so you
know from a superficial level and can
just say humans are social but I
actually recently had a had a very
personal experience with this but for
one thing it's not just me kind of
slowly I've discovered this but the
web's kind of start slowly discovered it
and some people have started calling
this thing web two point or the social
web or whatnot and I had a personal
experience recently where this really
hit home why this has really changed and
the way people think about the web I
just got married in October and two
weeks before I got married my future
father-in-law now my fault my
father-in-law was diagnosed with
pancreatic cancer and it was one of
those things that really changes your
entire perspective on priority in life
and everything and the fruit the first
just the day before I was due to give
this this exact same talk at a place
called HTC IC consortium I got an email
through my through my system and from
this guy named Brad and he he sent me
this email says hey ed I'm a fellow
delicious user and noticed that you
bookmark a lot of pancreatic cancer
stuff I'm at home with my dad who was
diagnosed a little over a year ago and
now as a tail end of things I've learned
a lot through his treatment about what's
out there I don't know there's something
you or your family has but just wanted
to drop you an email and be well and I
was sitting literally in the middle of
this workshop and tears just started
running down my face because this was
such an emotional experience for me that
someone else who was having this exact
same problem actually send me email took
time out of his busy schedule dealing
with his father's illness to send me
email and connect with me in this very
personal way and this he's late we
started a conversation through his blog
as well through email and it turns out
that he has a really interesting blog on
on the web chronicling his experience of
this disease his father's disease and
I'm sad to actually say that Brad's dad
passed away about seven days after he
sent this email and and so this whole
experience really reinforced for me what
web two point or the social web has
really been able to connect people but
through blogs through various different
kinds of communication and so what is
really what two point of about it's
really somehow something about the many
semi-new mechanisms and services that
seems to be out there and from a
research point of view what I really
want to talk about here is that these
web two point mechanisms can be study
and characterized and so let me try a
little bit on on on this okay so on the
one end of this collaboration spectrum
you have something that's more
lightweight so lightweight social
processes are things like for example
counting votes so it's a way to sort of
identify the fattest pneus of
information it's a way to maybe increase
the signal to noise ratio of the
information that you personally receive
so example of something like this is
like digg com or the most bookmark item
I'm delicious or as the if you have read
the book wisdom the crowd Jack sorrel
whiskey and probably going to pronounce
that name incorrectly but the classic
example of this actually was estimating
the weight of an ox in the room of
people it turns out that the room of
people who if you take the average of
the guests was better than an expert's
guess and that was something that was a
little bit surprising and when you think
about it really the truth value of a
stock like in the stock market is also
kind of a wisdom to crawl kind of effect
going on it's really a electronic market
and I'm toad actually within Google
there's actually this electronic market
for ideas right there's another
instantiation of this and then to some
extent really page rank or have an
authority algorithm in general is also
the kind of this lightweight social
process where blinking one page to
another page is really a vote and
therefore it's kind of just a vote
counting mechanism for figuring out
what's important what's not
important in the middle of the spectrum
you have systems that actually evolve
information structures that can be used
to actually organize that information so
for example delicious with its social
tagging flickr with the tags and the
photographs and they actually have
algorithms that find the most
interesting photographs in that tagging
relationship that's established by the
users you to France to actually create
friendship relationships and social
networking things right at the high end
of the collaboration spectrum you have
things like wiki's so Wikipedia
certainly is the most well-known example
here what's going on there is that you
have groups that you utilize systems to
make sense in sheer complex topics and
materials and not only that they
actually have users actually have
discussions with each other some very
heavy weight kind of collaboration and
they actually also use sort of sound the
lighter weight mechanisms like for
example the social status or karma
points to actually entice people to
participate as well as as a way to sort
of counting votes in and sort of have
some information fatima student
identification along with it as well one
of the interesting things here is that
there's a system cos pedia how many of
you have actually watched the show Cal
lost you probably are all too busy to
actually watch this but well at least
saying that it's too complicated you've
probably know something about this show
so lost is this show that I've actually
never watched but it's apparently the
show about mysteries on TV and there's a
group of people who have banded together
and used Wikimedia as a way to figure
out all the puzzles in this show and
some of the puzzles are so complex such
that expand multiple continents so for
example there was one case where a
particular item was hidden in the Sydney
store window and the queue was given off
in the in the show itself and within 24
hours people through collaboration
mechanisms on the net actually found the
item in that storefront in Sydney
through a bunch of
little cues that needed to be solved and
so this is the kind of collaboration
that people are actually carrying out
using using these kinds of technology so
if you think about these different kinds
of social processes going from very
lightweight to heavyweight processes you
have page rank and dig on the one hand
flickr IBN dog ear which is a social
tagging system for the enterprise or and
then you have sloshed on wikipedia which
are a very heavy weight collaboration on
the other end okay so it turns out that
this little axis in which you can lie
this lightweight collaboration to very
heavy wake up collaboration also
correspond to many different other kinds
of properties things like for example as
you go tour heavier weight collaboration
you need more interactivity between the
user you have more computer support
there's more social network connectivity
that gets created there's more explicit
collab cooperation but it turns out that
there are also more potential for
conflicts and it's and the more you go
toward Wikipedia you're really making
sense of something as opposed to just
searching or browsing so all these
things kind of are rolled into this one
axis and it turns out that in order to
really understand what's going on here
you need to bring in research from many
different fields so for example on the
voting system side you have the
understanding of the microeconomics the
behavior economics of foraging and
search work that has been done by people
like bernardo Huberman lata Edenic etc
and then you have the wisdom of the
crowd kinds of theories and things that
are being built there and then you have
actually things from the School of
Information Sciences like things
concepts like for example information
Cascades which is about the idea of that
a piece of information act gets
transmitted from person to person
sometimes without without deliberation
right so so a misinformation can travel
precisely because of the information
cascade because not each step is
actually
as an example right so in the middle of
the spectrum you have a lot of analysis
that's needed for social networks so for
example Ronald birds working University
of Chicago on this idea called structure
holes is about the broken firm ation
what he found was that actually people
who tend to brocach between different
groups that is this you have a group of
people who are interested in psychology
another group of people who are
interested in computer science the
people who broke her ideas between these
two groups those people actually turns
out to be also the higher performing
members of the organization and he
actually showed that your salary that he
studied a big organization and he's
actually show that being in a brokerage
position actually corresponds to the
amount of salary that these managers
received yes oh that's a very good
question I don't know I haven't read all
Ronald Bert's work in this area and so
certainly there's he showed that there's
a correlation and he argued that is a
causal effect but I think you should
probably read his own work to make your
own determination my personal belief
that it is a causal effect but maybe it
hasn't really been shown in academic Lee
or scholarly yet and then you also have
in the middle of this a lot of kind of
data mining mechanisms that requires
things like for example information
theory from Claude Shannon or latent
semantic indexing kinds of work that you
actually need to in order to figure out
what kinds of information structures you
can actually extract out of these kinds
of either social networks or content
with the linkages information that's
that's there and then at the far end of
this spectrum you have things that are
more toward the sociology or more toward
the information science analyses things
like for example the understanding of
conflict coordination between people
invisible colleges of people who
actually
form for example Pamela Sam Strom's work
has shown that you if you look at
linkage analysis of the content are
produced by people you can actually see
these little groups of people that
didn't really talk to each other but
they actually are collaborating through
knowledge artifacts and then Peter
parolee has done some work in
understanding interference effects from
one one person giving hints to another
person and when is it beneficial when
it's not beneficial and then Gary Olsen
and Judy Olson at University of
Michigan's done some work in
collaboratory 'he's which is
laboratories that are span across
geographical areas and then they need to
collaborate and in order and be
productive why are features of these
collaboratory 'he's that make them
successful or not successful and then
jack arrows work in collaborative
problem-solving also needs to be fed in
to actually understand this space and
then there is sort of these kind of
slightly fuzzier things that I'm not so
sure how we really fits in so things
like for example you know why do flame
words happen you know it clearly
emotions play a role but what's the
understanding of the emotion that that
we can use actually to model these
processes and therefore you know maybe
filter out flame wars or something like
that so understanding of these kinds of
things require inputs from all these
different fields so that's all by way of
introduction to this idea of what i mean
by augmented social cognition so if you
look up the definition of cognition in
the dictionary it is the ability to
remember think and reason the Faculty of
knowing so social cognition therefore at
least my usage of the term social
cognition is the ability of a group of
people to remember thinking reason the
construction of some sort of not only
structure by a group okay so this is not
quite the same as in the branch of
psychology that actually call something
social cognition where there they really
mean cognitive processes that is
cognitive processes of the individual
that's involved in social interaction so
that's part of this but not the whole
thing okay so anyways social
mission is really just the ability of a
group of people to remember thinking
reason and then finally that leads to
what i mean by augmented social
cognition which is some sort of
enhancement or support by the systems
the ability of a group to remember
thinking reason okay so that's what i
mean by augmented social cognition the
system supported construction of
knowledge structures by a group okay so
today extend you know if i don't want to
be pompous and say that this is a new
field or anything like that but to
extend that you believe that there is a
new phenomenon going on on the web about
the way in which a group of people get
together to think and remember and
reason then there's a need to actually
go and understand and study how this
process actually works and at this point
i kind of want to quote John to key in
saying that well what's the first step
in solving any interesting problem is to
get some paper and pencil and you stop
plotting the damn thing okay and so this
is not a direct quote but John two key
was a consultant in part for many years
and and this is always the first advice
he gives to people when they have
questions about you know how do I go and
solve a problem so let's get some paper
and pencil well in this day and age we
don't really use paper and pencil we use
a computer to count so let's use a
computer to count okay so the first step
in trying to understand this area is
what a bunch of characterization studies
using augmented social cognition and so
we're going to start doing that by
looking at Wikipedia and delicious and
I'm just going to I'm going to breathe
through basically three conference of
paper submissions that we submitted this
past summer and so that you get a flavor
of the kind of characterization study
that we've been doing so the first one
is studying the increasing coordination
costing wikipedia this is joint work
with nikki couture pawan Sue and Brian
Pendleton so we want to understand the
coordination cost and how it is
affecting the long-term viability of a
collaboration in formation of
environment like Wikipedia the data that
we have is essentially the entire thump
of Wikipedia as of july second 2006 it
contained 56 million revisions 4.7
million wiki pages to
point four million actual article pages
and about eight hundred gigabytes worth
of information certainly smaller than
the kind of data set that Google is
already being dealing with but you know
not a non-trivial data set certainly and
we believe this is the first plot of
something like this for Wikipedia so the
first thing is that we define something
called direct work the wreck work is any
work or edits to the article pages that
actually results in moving the article
forward in some way and that's what we
mean by direct work and you can see that
starting from 2001 where it's you know
essentially 95% is gradually decreased
to something around sixty-five percent
or seventy percent and so there's direct
work that is edits going directly into
the article pages indeed is decreasing
okay so very good question i'm gonna get
to that so in terms of indirect work
there's actually a wider idea of
indirect work so for example increasing
amount of traffic on wikipedia is people
talking to people well that's not
exactly a surprise so users actually
discuss with each other about things
like what should go into your article
sometimes they just have discussions on
things various different things and it
turns out that if you categorize those
starting in mid-2001 there's a little
bit of people talking to people and then
getting to about july two thousand six
of about as high as twelve percent or so
and right now probably between eight and
ten percent something like that
yeah so the that's that's basically back
here when they really incorporated
discussion pages so these are users
talking to each other and then you're
really asking about also article
discussions as well and I'll show that
in just a little bit and then as you
previously alluded there is also a lot
of procedural discussion that happens on
Wikipedia about things like rules and
policies about how this thing should be
run and it turns out that there indeed
has been a corresponding increase in the
amount of discussion about what the
procedure should be going from zero
percent to in mid-2001 to about twelve
percent currently and then reverts which
we asked about also as being increasing
from 0 % to about six or seven percent
in the last couple of years and so if
you take all those graphs and put it
into what we call a stat graph you get
an overall sense of all the movements of
the kinds of edits that are going into
where they are going so for example a
bar 0 because it's in order to actually
show you what's really the trend that's
going here but it's very clear that you
see this trend that the work going into
article is as decreasing the
corresponding it is being an increasing
user talk in maintenance and in a lot of
these other sort of procedural and
indirect work what's an edit
right well time or the amount of edit
that you're actually doing it for
example oh yeah so I'm gonna get to that
in a little bit in the next half of the
talk so I'll get get to that a little
bit so in addition to understanding of
the coordination conflict at the global
level we're also interested in conflict
at the article level as well so we we
want to understand how you could
actually model conflate at the article
level and building that characterization
can lead you to for example identify
high conflict article and therefore
maybe have intervention before it gets
out of hand or you could have a little
social dashboard of showing people where
the conflicts are so that they can
actually put in their two cents
depending on the point is the
identification of article that that
article level it can be very very useful
the trick we played here is to use this
it turns out that in Wikipedia there's
this thing also called they also allow
tagging and sound detective special
meaning so for example a tag called
controversial actually tags an article
as being controversial or not at that
moment in time and what we what we
decided to do was to use this
controversial tag in a somewhat novel
way if article 1 an article to both have
10 revisions but article 1 had eight
revisions in those 10 that had been
marked controversial that is the
controversial tag was applied to it
while that revision was being made then
we say that it has a controversial
revisions whereas article 2 only has two
and then therefore we would say article
1 is much more controversial in an
article 2 ok so that's kind of the rough
measure that we decided to use so
assuming that you kind of believe that
there's a little bit of a ground truth
were measuring how much conflict there
is and the article level can we actually
identify what pages are actually in high
conflict and why so what we decided to
do was compute a bunch of very easy to
compute metrics and see if you can
predict what articles are in conflict
and so Sandy's metrics are really easy
to
invision like for example number of
revisions to the article to the
Associated talk page of the article to
the page length maybe the longer pages
are more controversial number unique
editor that has contributed their voice
to the article maybe that has something
to do with the amount of conflict there
is a big discussion had been around an
ominous edits right do I anonymous edits
actually increase its conflict or not
that's another thing we looked at so
what we did was essentially use a
support vector machine on all these
different metrics and to try and predict
what what how many controversial
revisions that articles have and this is
this is we did a FIFO cross-validation
this is just one of those plots that we
did you can see that it's fairly
correlated it anyone want to venture a
guess on what that upper upper right
hand corner doc is wow I've given this
talk three times now I can't believe
people are let's just pick it right out
indeed that is George Bush I I actually
thought it was going to be something
like intelligent design because you know
just couple month before we collected
this data that the intelligent design
was all the rage in the in the in the
press right so I thought for sure it was
either going to be abortion religion or
or or intelligent design but it turned
out to be George Bush but I guess in a
way George Bush kind of embodies all
three of those issues correct so perhaps
that's why he's you know he is the most
controversial president that we do have
so anyways if you look at the
determinants of conflict from that model
that we constructed there are some
interesting aspects of this model that
we found surprising so some aspects are
not surprising like for example the
number of revision increases its
conflict well that's kind of again no
causal effect I'm trying to draw here
i'm just saying correlations right so
what's surprising is like things like
for example the number unique editors
in the pock page actually decreases
conflict that's kind of strange right
another thing that's really strange that
we found was again unique editors to an
article also decreases conflict an
ominous edits to the talk page increased
conflict that is more people who are
kind of starting flame wars this is at
least our hypothesis of people more
people that are going to start flame
wars without identifying themselves
seems to increase the conflict there is
on that particular topic but the
surprising part is that the
corresponding anomalous it is to the
articles actually decrease conflict
seems to suggest that the number of
unique voices that are added to the
article seems to decrease conflict and
so there are sort of explanations that
you can use to figure out what these
determinants of conflicts are but
certainly you know without your thinking
through a really identifying what why
these correlation exists is not clear to
us you know why we found these kinds of
determinants of conflict so this is kind
of surprising part
Owen ominous edits are our edits that
people have not marked their name
revisions just SAR are all of them what
are your anomalous around so I'm one of
the things I'm here about is that you
know we have found things like that but
we don't really know the answer why
these determines worked out the way they
do this is just one of the things about
machine learning you just get spit out
of these things and then you have to try
and find answers for them another thing
that we did was okay you might say while
you apply this model to all the articles
that have been tagged what about all the
articles that Benedict tagged that's
controversial maybe they're
controversial articles that are out
there that hasn't been identified as
such and they really should be so what
we did was we picked untag articles that
have more than 100 edits and then ran
through our the model that we just
created through SVM and then sampled a
range of these predicted conflict scores
and then we send them out as surveys to
Wikipedian administrators to validate to
see whether our predictions are anywhere
close to what Wikipedians would have
predicted on the amount of controversy
that's on these on these articles and
turns out that by by spearman's rank
correlation we do get fairly good
correlated predicted score so this is
sort of a little step in validation that
this model seems to actually embody what
people really mean by conflict at the
article level okay so a quick summary of
this section is that Wikipedia is it
appears to be this new learning culture
on the web where people really talk to
each other and they have these these
interaction patterns that seem to evolve
these knowledge structures and that
these patterns can either encourage
conversation or they can encourage
direct contribution and so like for
example the thing that we talked about
the anomalous edits Wikipedia at the
very beginning had this this design
choice whether to allow anonymous edits
in fact the German Wikipedia is right
now discussing maybe they have already
determined i forgot but they were
discussing whether to allow anonymous
it's you know and this is a design point
that has actually drastic it appears to
us from the research that we have here
that actually seems to have drastic
effect on what might actually happen the
kind of interaction that might you might
have in these in these systems in these
wiki systems so our work here is really
to try and find these conflicting
pattern and understand them and maybe
start understanding how to design for
these kinds of systems in the future
okay so I want to go to a second a bit
of this which is entitled power the few
verses wisdom the crowd and this is
joint work with Nick kicked or balance
to Brian Pendleton top make of its ok so
there's been this interesting
controversy about the power where does
it really lie in Wikipedia Jimmy Wales
into in december two thousand four he's
been actually been going around to these
high power conferences like Joel and Ted
and things like that talking about his
view on how Wikipedia really evolved and
one of the things that he said that some
truck somewhat controversial is is that
it appears to him at least at that time
to a two and a half percent of the user
are making half the edits in Wikipedia
and so he said well I should really just
design the mechanism for that two and a
half percent of the user of my
population that's supposed to designing
for the other you know 97.5 percent of
the user well that's a pretty drastic
statement to make you're you're saying
you're going nor 97.5 percent of your
power user population then Aaron
Schwartz at the end of last summer who's
a fairly well-known blogger wrote
something that got splashed dotted he
actually went and studied a few
wikipedia articles and then analyze the
content all the edits that happening
between and he posited that actually the
novice users appears to be actually
creating much of the text on Wikipedia
so all of a sudden there was this
controversy about well is it really the
novice users are creating much of the
text or is it really the elite users who
you should really be designing for okay
who really writes Wikipedia
delete users on the one hand powered a
few or is it wisdom the crowd really a
bunch of novice users who are you know
joining in and actually creating this
content and who should we designed this
tool for so you might say things like
for example for that for the elite users
you might give them really powerful
tools for editing or kicking people off
or stopping flame wars or whatever you
know if you know that the power really
exists within a very small group of
people you give them very powerful tools
but if you knew that most of the novice
users were actually writing the content
and then while forcing them to use la
tech to create equations is kind of a
difficult thing for them to learn for
example so you might want it design
tools that are a little easier for them
to create content right so that's what I
mean by you you might change the
direction of the design of the system
depending on which who really writes
wikipedia that makes sense ok so so
here's the first graph that we kind of
looked at and says well it turns out
that the they're kind of potentially
both right at the end of two thousand
four indeed alt it all the
administrators in in the system appears
to be making nearly half half of all the
editing Wikipedia but that has not been
true since then it the administrators
are making something like maybe less
than ten percent of the edits at this
point in in july two thousand six so
there appears to be this rise and fall
of the elite users in the system so
administrators by the way is a status
that you can achieve in wikipedia if you
can editing for a while yes because
profile to use a change the number of
that's a very good yeah i'm gonna take
to the bottom of that yeah is in you
those are both very very good questions
and with unfortunately we haven't gotten
to the bottom of those but we do have
answer to some of that I do believe the
fundamental mechanism that's happening
here is probably something about
knowledge specialization you know two
and a half percent people can only know
about so much before they run out of
things like knowing about you know food
yeah for example or what's that specific
mystery that happen in in lost episode
number 24 you know seen one right only a
few people in the world really knows
that kind of information so I think it
has something to do is knowledge
specialization but one of the things
that we wanted to do it was this
research was trying to figure out what's
the what's at the bottom of this okay so
yeah the number of edits rather than the
percentage advantage because form of
Education normalized by you mean by
you've got percent of edits what about
o'er odd number yeah we do have those
graphs as well some of those I i I've
cut out this talk in order to make it
fit in 10 minutes of this part of it but
I can certainly show you those graphs or
give you the paper to preprint you're
looking definitely a power um
exponential for each one of these so I'm
I actually I have one of those graphs in
here that's something like this this is
more or less what you're asking for it
right so the that there's a lot of lines
on this graph you only need to pay take
more or less pay attention to two of
them the red one which is the novice
user that have only made a hundred edits
or less and you can see that it kind of
has this this curve kind of like goes
like that and then the blue one which is
a user to have made ten thousand edits
or more and it kind of also goes like
that but much less so
including everything and i'll get to
i'll get to your question about the
amount of edit a little bit because
we're yeah yeah that that's kind of a
tough question so I'll try and get to a
little bit of that so it turns out as a
percentage of total edits what are you
do it by this administrative measure
where you say whether someone is an
administrator or not or you do the
data-driven approach of the analysis
where you do this social stratification
based upon the number of edit they've
made from less than 100 to 10,000 or
more you also see the same effect so
it's not a status label that's being
attached to it really truly this affects
us in the data right so so novice users
from these graphs appears to be sharing
a larger and larger role the question is
why is this really happening one of the
things that we hypothesized was maybe
spam bot fighting has gotten better and
so administrators or these really high
power users are not spending as much
time on dealing with the spams and
therefore their corresponding
contribution this kind of relates to the
question that you're asking if they're
just spending time fixing spelling
errors or something like that maybe as
the quality gets better and the number
of spans gets lower therefore they're
not spending as much edits on those
things and therefore the contribution
kind of drops well that turns out not to
be the case you can actually measure by
activity on Wikipedia fairly easily and
it turns out that no the bots hasn't
really gotten any better they're just
been doing the same amount of work every
that sense so the guests of of your
guests earlier about maybe it's just
some sort of knowledge specialization
thing that's happening appears to us to
be the correct answer one of the things
that it's an evidence for this we don't
have a direct evidence for it yet is
population growth is very different in
Wikipedia so again you only need to pay
to pay attention really to two of these
lines red one which is novice users and
deep blue one which is the
ten thousand edits or more well we are
calling the elite users you can see that
by the way the y-axis is exponential
right so this what you're really looking
at is the slope of these lines and you
can see that the slow for the high power
users versus the novice users are
different another way to look at this is
by the total population shift that's
happening in Wikipedia in other words
each one of these one slice a moment in
time here is a pie chart that tells you
the population in Wikipedia and you can
see again there's this oh that's just
pure population elite users are
comprising a much smaller part of the
total social pie then the novice users
and that seems to be driving this effect
and and so we're kind of calling this
effect the rise of the bourgeoisie
because this appears to be that at the
beginning what you need is a small group
of people who are really dedicated and
really spending a lot of time with the
system and then afterwards you kind of
need this rise of the bourgeoisie to
sort of take over and really push the
rest of the content forward but that
still really doesn't quiet answers the
question of who really write the actual
content which is what Bill was just
pointing to so you know maybe the edits
are not a very good measure because they
could just be fixing little spelling
errors or they could be creating a lot
of content order you're actually
removing content perhaps even aaron
schwartz this is the novice users that
are actually writing the content Jimmy
well sis is naturally the elite user so
who is right so what we did was we took
30 machines and and computed the
differences between all 58 million
revisions that are on Wikipedia using
the distributed computing architecture
call Hadoop which is I guess in some
ways similar to the MapReduce system you
guys have here and then we looked at
what was going on here so as a
proportion of the words that are
actually changed by administrators again
we saw the same thing that proportion
actually heads this rise and fall in the
system but what's more
perplexing is actually this graph and I
this is the graph of showing the
different classes of users in Wikipedia
and their ratio of words added to the
words that are removed / revision okay
in case you can't quite do the math in
your head I I did this little trick here
this line above one anything about one
that means that class of user have added
more words than they have removed words
anything that's below that line means
those groups or user have removed more
words and then they have added words ok
so the novice users are removing or more
worth than there actually adding words
and everyone else appears to be adding
words so but yet the novice users are
also the group of people who are doing
the most amount of edits by a large
proportion earlier records in here
novice blanks of page and somebody
restores it because that restoration is
adding words yes we do all we do the raw
diff between the revisions yes so what's
really going on here well unfortunately
I don't really have an answer for you
this is still a little bit of a mystery
to us as well this is where the summer
ended and the interns left and then we
haven't had time to go back and really
answer this question yet but this is a
very interesting phenomenon appears to
be happening so the summary for this
little section here is that it appears
that you could have some basic
understanding of the patterns for how to
boost wrap a learning culture like a
Wikipedia right it appears to us from
this analysis that you need a set of
very dedicated yuly users at least it
seems to me in the beginning and then at
some point you have this rise of the
bourgeoisie that needs to happen in
order to to carry this this system
forward now you might you might say well
you only study Wikipedia so you know how
can you say that this this is going to
be true generally for all social systems
and out there well the part I didn't
tell you about is that we also study
delicious and in delicious is exactly
the same phenomena appears to be
happening so there appears to be the
same thing going on in delicious we're a
very small group of user was really
dedicated in using the system for a long
time and then later on there was this
mass of people that was joining it that
really carried the system forward but
this more or less still has some open
questions about the pattern of
contribution versus group or users that
are on there and we don't have all the
answers here this is just a
characterization study right we're not
really trying to say too much
the point in general emphasizing their
contributors in a certain way that's a
very interesting point that you yeah
that's a very interesting point that
build you just brought up because people
are kind of creating the system blindly
and just trying to see what would happen
without really measuring what was really
going on and like you said in dig they
appears to be de-emphasizing these elite
users at this point because so much of
the bourgeoisie are now joining in as
part of the parade so now our sudden it
seems like the algorithm that you had
used to bootstrap the system in the
beginning it's not the same algorithm
that you need in order to keep it going
later on and so it has a real design
implication in terms of the kind of
algorithm that you might design for this
kind of vote counting system or
Wikipedia systems or you know all these
kinds of collaborative systems as well
yeah so how am i doing on time oh well
you're scheduled to end up 12 okay well
I'm going to try and breeze through this
part of it faster on analysis of tagging
system and this is joint work with the
topic of its and I really want to show
you this because I think this smile so
apply to some work that you guys might
be interested in doing so the problem
that we were interesting looking at in
this below part here is how do we
evaluate a tagging system and what I
really mean by that is given a tagging
vocabulary how effective it is actually
in describing instead of URL that's was
this thing that we were interesting
looking at the approach that we took to
attack this problem is again the two key
method that's take let's crawl the whole
damn thing we crawl the entire delicious
bookmark said and the way we did that
was we had 30 machines and we wrote a
little screen scraper and that we had it
you know going all at the same time
making a request everywhere from five to
ten seconds
random and crawled it for like a month
and a half or something like that and
then we started using some information
theory to look at this problem how many
of you have taken information theory
class in college so some set of you I
didn't so I had to give myself up on
this really quickly over the summer I
took a little bit of this in statistics
talks obviously but I didn't really
truly deeply understand it but I want to
explain to you very quickly what entropy
means entropy is the measure of the
uncertainty just remember that entropy
is a measure of an uncertainty it
measures the uncertainty about a
particular event associated with the
probability distribution that's what
entropy means so the easy way to that
sometimes people have explained this is
through a saw experiment if you're
drawing color balls out of the box if no
see if you have a bunch of different
colors in there and there's no single
color that predominates the distribution
then the next ball that you draw out you
never know what color you might be it's
completely random you have no idea
that's when entropy is maximum you have
maximum uncertainty okay does that make
sense so if the top the box only
contains black balls every time you
reach in and grab out is a another black
ball then you know almost for certain
that the next time you're gonna grab
you're going to get a black ball and
that's when entropy is the lowest and
that's when its minimum okay it has very
low uncertainty about the next color
ball that you're going to get that's the
way to think about what entropy really
measures so it turns out that entropy
can increase only in two situations one
is the total number of events increases
the other possibility is that the
probability distribution becomes more
uniform okay so it just this is just
only equation I shown with this talk I
could show more but this is only one
show so here is a the entropy of tags
showing the saturation in tag usage so
what's happening this is a January first
two thousand four that's when delicious
really started more or less beginning of
time so to speak and you can see that
the entropy that is the uncertainty
that you're going to see the next tag
increases increases and then finally
just kind of plateaus okay so what that
seems to suggest is that the encoding
the encoding of the tag was getting more
and more uncertain more and more
uncertain as at some point the encoding
of those tags for the sources that are
Ian that are in delicious just kind of
stay at the same level people have kind
of discover all the tags that they
probably need to describe the
information sources out there and it
seems to suggest that the way people
think about tagging is is stabilizing in
terms of the tag usage there's this
saturation effect that's happening
another way that you can actually look
at this data is through conditional
entropy which is measuring how much
entropy or uncertainty is still in a
random variable has remaining if you
have learned completely the value of a
second variable so how does that apply
in this case is that is that you can
actually see the amount of uncertainty
that are still in the document if you
knew all the information there is to
know about the tags that are already in
the system right so what this really
says is if you know all the tags that
are already in the system how much
uncertainty are do you still have in the
system about the document that you're
going to see that make sense okay so
that's increasing the amount of
uncertainty about the document that
you're going to see in the system is
increasing despite the fact that you
already know what the tag is already in
the system so what that seems to suggest
is that if you're simply using tags to
browse through this space of linkages
between tags and documents is getting
harder and harder to you for you to
swing through this space because all the
all the uncertainty that's in the system
is actually still increasing even though
the the tags are stabilizing that make
sense okay another way to explain this
you might you might think about is that
how are people sort of coping with this
and there's a court but there is a
there's a connection to search down talk
about in a second but the average number
of tags / bookmark has gone from 1.8
since January first of two thousand four
to 2.8 more recently right so what that
is saying is that people are coping with
the fact that words are losing their
ability to specify documents by adding
more tags so that they can be more
specific about what's actually in the
document so that makes sense and it's
the same thing that's has been happening
to the user behavior in in search people
have gone from originally 1.8 average in
about two thousand one or so into 2004
2.8 query words per search to about what
3.4 and probably a little bit more now
right and the reason is it's an
evolutionary response to the fact that
the documents is giving a bigger and
bigger in order to really specify the
information that you need you need more
and more words to actually specify that
particular piece of information that you
need so that's kind of the point of what
I'm trying to say about this analysis so
it could this also be the more users or
entering the same bookmarks and then are
trying to personally tag them
yes
you're asking right release the user
base haha people are hitting on the same
bookmarks in the system and so those
people are adding more and more time for
personalized times more and more
personalized background yeah tags that
come from their own right right their
personal experience or whatever right so
they might mean ontology thereon yeah
for example someone might start tagging
the thing to read to 168 you know what
whatever that means right that's an
interesting point one of the things that
we didn't do is really try and
understand what's the relationship
between the group usage of social
tagging versus personal usage is a
person tagging that's kind of an open
question that needs to be examined for a
research point of view I don't really
have good answers for you unfortunately
or not yeah what is it not permitted it
would be interesting and that is the
level of information you get per cat
that abduction and certainly so it's
possible if the average number of
attacks remain the same but the tags
become better in terms of there are more
informative fishing this space of
documents yeah so you're in a way that
you're asking about a measure called
mutual information exactly yeah and we
actually did measure that and it turns
out that if you look I don't have this
slide in this in this slice it but it
actually increases at the beginning and
it's been dropping ever since so that's
the average over all tags or average
over all the data data that we have all
tags all documents so this means that
people add more tags but the tags that
they had are not that good so that's
clock whistling very Dutch had but then
they ran out of that's right and and the
way that they're responding to that is
by adding more number of tags / bookmark
to increase what they really mean by
that content does that make sense you
got it exactly
so so the summary for that little
section there is really that entropy can
be appears to be a way to think about as
a measure for the social tagging system
it appears to be a good way to to
measure it and that as a map it seems
like social tagging are losing their
ability to guide user efficiently and
the way that users are responding to it
is by increasing the number of tags they
have / / bookmark and that has again
design implications for the kind of
social tagging system we might want to
build in the future so this is kind of a
framework for thinking about analyzing
it so I have one more slide so in
conclusion I took exactly one minute one
hour according to my to my clock here
what I'm truck what I try to do in this
talk is to define an outline this this
area of research that we are calling
augmented social cognition what we're
trying to do is to understand the
emerging behavior in social software and
how to understand how to enable these
kinds of social foraging searching and
since making that people are doing
around the system trying to understand
the conflict the coordination cost of
various kinds of design choices that you
might make in these systems and we're
arguing that the first step to try and
understand this area is to get a big
paper and pencil and try and start
characterizing these behavioral data and
we've shown three example of that
conflict coordination wikipedia power
shifts in wikipedia and the tag
usefulness of delicious and it appears
that there are metrics that you can use
to try and attach these problem an
understanding of those areas likely
going to need a multidisciplinary
approach and so this is kind of a little
bit of a call to arms of all the
researchers to you know who are
interested in this area perhaps to go
and understand this area a little bit
better so again I'm always amazed that
people are willing to pay attention to
me talking so thank you very much for
giving me an hour of your time thank you
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>