<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Brains, Meaning and Corpus Statistics | Coder Coacher - Coaching Coders</title><meta content="Brains, Meaning and Corpus Statistics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Brains, Meaning and Corpus Statistics</b></h2><h5 class="post__date">2009-03-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QbTf2nE3Lbw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a great to have Tom Mitchell here
for those who of you who don't know tom
is been at CMU for many years is the
head of the machine learning department
one of the few schools in the world has
a vision my department just great idea
and he's worked on a wide variety
machine learning and text mining
problems I've fought for while I worked
with him on some text mining work at the
now the front start-up and he sinned in
last you know seven years so it's been
looking at the brain imaging and what
machine learning can do to make us
understand what those images tell us
about the function of the brain in
particular they were the how language is
using the brain and that's what he's
going to talk about thanks for name
though good to be here good to see
familiar faces and unfamiliar um I tend
to wander when I talked so if you can't
hear me in the back when I'm wandering
over there somewhere flag me or
something and I'll try to come back so
as Fernando said I've been interested in
well actually I've been interested in a
long time for in how brains work who
isn't and when I was a grad student I
even as she was an undergrad to be more
accurate I thought maybe I should major
in psychology so I could study how the
brain works but I thought about it a
little bit and looked into it a little
bit and decided it was hopeless because
they didn't even have an oscilloscope
they could get out though only this was
pre brain imaging and so really the only
way to study the brain was to give an
input and look at the output and then
just kind of try to reverse-engineer
from there it seemed futile so instead i
worked in AI for many years and then
when i ran into marcel just the guy who
became my primary collaborator about 10
years ago um he showed me this cool fMRI
stuff he was doing so I got more
interested in it and we've spent the
seven or eight years working together
trying to use brain imaging with machine
learning methods to study different
questions but the primary question is
this how does the brain represent ideas
so we don't reflect on this all the time
but of course when you think of your mom
versus your computer what it means to
think about those two different things
is that when you think about their your
mom there's one set of neurons firing in
your head and when you think about your
computer it's some other pattern of
neural firing in your head and that's
what it means to be thinking about mom
or computer and so we're interested in
whether we can understand things about
that okay so that's the goal this is
work done with a bunch of people that I
got there on the top is Marcel just he's
my primary collaborator there are a lot
of very interesting people involved in
this some of you may remember Dean
Pomerleau this guy over here he did some
of the interesting early work on neural
networks for automatic driving he's
become hooked on this stuff these days
too and we're collaborating very closely
so okay given the fact that we have
brain imaging devices we're interested
in as I said how's it's bringing
represent ideas to be a little bit more
precise when we at least when we began
the very first question we had was given
techniques like functional magnetic
resonance imaging can we even see the
difference in neural activity when
people think about two different things
there's no guarantee that the answer
would be yes because even though fMRI is
wonderful it doesn't let you see down to
the level of individual neurons than
what's going on instead a single pixel
we call them voxels because they're in
three dimensions a single voxel in fMRI
image is about contains about ten to the
fifth neurons so you're not seeing
anything like individuals it's more like
looking at a city 10 to the 5th neurons
so the answer to that by the way is yes
or I would have picked a different topic
to talk about today but then more
interestingly is the neural activity
that represents these concepts localized
or distributed do you really have a
grandmother cell what about your brain
in mind do we represent things in the
same way so there's all kinds of
questions you can ask like this but in
addition to just kind of enumerated
things that's interesting to ask are
there some underlying principles in the
way that the brain organizes neural
activity to represent different things
you know if you look at the 50,000 words
in English and the 50,000 neural
patterns when you think about each of
those words is it just a kind of hash
code of the you know are the neural
activities just completely independent
for each of those words or is there some
systematicity and we're interested in
those kind of questions um okay maybe
many of you maybe have already seen
functional MRI but if not I encourage
you to participate in an experiment you
can volunteer it's a very pleasant
experience you just lie still in a
machine don't move your head and think
and then we get from that a picture of
in three dimensions of a strong
correlate of neural activity with a
resolution of about a millimeter spatial
resolution of about a millimeter and the
temporal resolution is not very good
because thinking happens at a rather
fast pace for example if you read a
paragraph you read about three words per
second we get only one image per second
so if you're reading we're not going to
even get down to the level of seeing
individual words worse than that fMRI is
actually measuring fluctuations in
oxygenated hemoglobin in your blood and
the time constant on those fluctuations
is several seconds so fMRI is very nice
spatial resolution
unfortunately poor temporal resolution
so that's the tool that we started with
more recently we've been looking at
other brain imaging methods I'll talk
about that a little bit but primarily
here I'm going to be talking about fMRI
so given that we decided well the way to
study how brain represents ideas is to
put people in the scanner and show them
stuff like this so in a typical
experiment will show people some item
and with the instructions to the people
or think about this item think about its
properties if we show you the same item
several times please try to think about
the same properties don't feel obligated
to think about it differently each time
you see it that won't help us and other
than that we let people make up the
properties that they think are relevant
so sometimes we show pictures sometimes
we show words sometimes you show both
and we space those apart those stimuli
about 10 seconds and as you remember
that kind of will cover this temporal
blur of fMRI blood oxygen fluctuations
that are being measured okay all right
so now given that first thing I should
show you is what does one of these fMRI
images look like so here's the image or
part of the three-dimensional image
looks like for images but I'm really
showing you for two dimensional slices
of a single three-dimensional image when
this person looked at that stimulus
that's up in the right corner so a
bottle so this is the person's
representation or part of their neural
activity when they think about bottle
and the top of the picture is the back
of the head the bottom of the picture is
the front of the head and as the
thermometer on the right says the red
blotches are high neural activity
blotches so you can see that when this
person thinks about bottle there is
catchy there are patches of neural
activity remember the voxel oh I should
tell you the voxels in this study are
three millimeters wide
so these blotches are on the order of a
centimeter or so wide maybe a little
bigger and they're kind of scattered
right so now the next thing I first
thing you should ask and you see this is
well does it look any different than if
they think about their grandmother so I
don't have the one for grandmother but
let me show you the mean image over 60
different stimuli that looks like this
so it's unfortunately very similar to
bottle but there are some differences so
if you subtract out this mean from
bottle you get this other difference
image and so here's the summary of the
activity that is differentially
associated with bottle compared to your
average noun concrete noun that we
taught them and so primarily we when we
do our analyses we run it on this
difference image because that's where
on this is thanks for asking that I
should have mentioned this we presented
only this one stimulus for bottle but we
presented at six different times and
what you're looking at is the mean over
those six times and in also when we
presented we capture an image once per
second and we consider only the images
that occur four seconds after stimulus
five six and seven because that's where
the fMRI blood oxygen fluctuation peaks
so this is the repetition this is the
mean of repetitions of bottom yep
yes so this is for one subject one
participant in the study I'll show you
some from other people later okay so
then the first question the first
obvious question is is there information
in fMRI to distinguish these different
items we convert that all these
questions into machine learning
questions because that's those are the
kinds of questions we know how to answer
and so the way we convert that into this
into the machine learning question is
can we train a classifier where the
input will be an fMRI image and then the
classification task is to say which
stimulus or semantic category of
stimulus was this person thinking about
when they when we captured this neural
activity and so we've trained a whole
bunch of different kinds of classifiers
I'm not going to go into the details
they're not as interesting as the
neuroscience results I think but we've
tried a lot of different kinds of
classifiers that you would want to use
if you were trying to classify very
high-dimensional data 20,000 voxels in a
single image using pretty sparse labeled
data we only have on the order of dozens
of training examples and 20,000 features
so you'd want to use things like
regularized logistic regression or
support vector machines to deal with the
high dimensional sparse training data we
also do some pre-processing for example
sometimes people even though they try to
be cooperative move their head a little
bit so we do some pre-processing to
remove the head motion artifacts we we
do a lot of feature selection because of
the high dimensional data so you know
what kind of cross validate that says
the program uses the training data to
choose sometimes subsets of features so
let's see the other thing I should
mention because it's going to be
important later is another kind of
pre-processing that we do on is to try
to encounter the Phantom all of our
brains have their
physical size and shape and so at some
point where we want to compare
Fernando's brain to de Kang's brain avi
I won't say which one is larger but
they're obviously not exactly the same
size and shape and so we use
off-the-shelf software to morph brains
into a canonical coordinate frame and
that morphing software is imperfect my
estimate is that it gives you a
registration error on the order of a
centimeter and you're dealing with
voxels that are three millimeters wide
so it kind of Miss aligns the fossils so
that they only are reliably aligned to
within a couple of a few fossils away
okay so when you train these classifiers
it works here's a in this case we were
training a classifier on what turns out
to be one of the easier tasks
distinguishing whether a person is
reading a word about tools like hammer
and screwdriver or a word about
buildings like googolplex or apartment
and I guess googolplex wouldn't be a
building building 42 or apartment and
what you see here each black bar is the
classification accuracy for a different
participant in the study and in this
case we're training the classifier
separately for each person and so since
half of the stimuli we're tools and half
where buildings chance level would be
point 5 you can see we do better so yes
the answer to question number one is yes
you can train classifiers to distinguish
at least categories of semantic content
and words yep question
how big is the sample set was the
question um we showed each person uh Wow
in this study I believe the answer is
that we had ten buildings and ten tools
and that we presented each 16 times if
not it's that plus or minus one or two
yes question sorry say that louder oh
right i had on that previous slide
something about significance level
that's just the 95 so if you work at
chance you if this classifier was
operating a chance the expected accuracy
would be 0 point five but if given the
size of our test set if you wanted to be
ninety-five percent confident that the
observed accuracy was not a chance level
then there's a band of accuracy around
point five that you want to get away
from and the significance level that I'm
showing there is a ninety-five percent
confidence band around chance point five
you could do it with a permutation tests
in this case you can do it in closed
form is just a standard binomial
distribution okay so I just want to take
a step back and point out that this is
one of the world's fun problems to work
on if you're a machine learning person
you can think of this as a case study of
several interesting aspects of machine
learning we already mentioned sparse
class classifying and training on sparse
data it's also an interesting domain
although i'm not going to focus on it in
this talk of analyzing complex time
series data and so for example Rebecca
Hutchinson is finishing up her PhD
thesis at the moment on a probabilistic
model for time series data that kind of
like a base a dynamic Bayes net assumes
there's some latent set of stuff going
on that's hidden that's generating this
observed time series and it's also a
very interesting case study domain if
you're interested in training many
classifiers that cover many different
instances so for example a different
classifier for each brain I suppose a
Google you have similar problems trying
to train a different class of art for
each user but and if you believe that
the classifiers are not the parameters
of those classifier for different people
are not all completely independent then
they're interesting machine learning
questions about for example can you use
hierarchical Bayes methods to set priors
on the parameters of the classifier to
then use on subsequent brains that
you're trained on so the only way I
could work up the gumption to not go
into machine learning details was to
include these three slides so I at least
got to point out what a cool machine
learning problem it is ok so now on with
the main story line which is the
neuroscience results ok so since the
answer to question one was yes we can
train classifiers that at least can
distinguish some semantic categories
with reasonable reliability based on
fMRI the next question is
but what are those classifiers actually
picking up on so suppose that I give you
the words hammer and Department a tool
in a building the fact that I can get a
classifier to distinguish whether you're
processing the h.a mm er stimulus or the
AP whatever stimulus doesn't mean that
my classifier is getting at the part of
your brain that's thinking about the
meaning it might just be picking up on
the neural activity that's detecting the
H in hammer and there is no H in
apartment and I could get the same kind
of accuracies that I just showed you if
it was doing that because obviously your
brain when you're looking at this a che
mm er it's recognizing the H or you
wouldn't be able to see that it's hammer
and then you're thinking about hammer so
what we're picking up in fMRI is some
combination of all the things your brain
is doing and so the fact that we can
train a classifier that distinguishes
whether you're looking at the word
hammer the word apartment doesn't
guarantee that that classifier is
actually capturing the neural coding of
semantics it might just be low-level
perceptual features so question number
two is how can we tell which of those is
happening and again we turned it into a
machine learning question can we one way
to answer that is can we train a
classifier on fMRI activity when you
look at words and then use that
classifier to decode fMRI activity when
you're now looking at pictures and if we
could do that then it couldn't if you
can do that successfully it can't
possibly be an H detector because there
is no H in the picture of a hammer so we
tried that and yes you can do that and
it works actually quite well so for
example here's um
the left a chart that shows the accuracy
if we train on words stimuli and tests
on words stimuli and on the right is if
we train on words stimuli but tests
instead on fMRI data collected when
people are looking at pictures and you
can see the accuracies are comparable in
the two cases and so that means the
answer to our question is yes so this is
pretty cool what it means is that really
this classifier is picking up on the
neural activity that's capturing
semantics is not just some low-level
percept question
so instead of stimuli very different
Simone is optimal
so I still in a garage or pictures to my
life I'm sorry you're mentioning
different stimuli pictures different
different rough difference monument
cross the line Oh different synonyms so
instead of yeah right um I'm pretty sure
its concept based based on this kind of
thing and you do see it you know if I
present the word glass and the word
bottle we get remarkably similar neural
activity so sorry I should repeat these
questions question was about synonyms
what happens if people look at synonyms
and the answer is we haven't done that
explicitly but we've presented
similar-looking words and earths are
similar meaning words and found similar
neural activity so okay so then another
question you could ask is about
similarity across people when you think
of bottle is it the same as that person
we are looking at up there on the screen
and again we can convert this into a
simple machine learning question can we
train a classifier on the people on the
right side of the room and then use it
to decode with the people on the left
side or thinking and again the answer is
yes you can so here the black bars show
as before the classification accuracy if
we train on one person and test on that
same person other data from that same
person but the white bars show what if
we train not on any data from that
person but instead use the data from all
the other people and then test on the
this person and you see the white bars
are actually not that different on
average from the black bars so that's
very strong evidence that the neural
representations that our different heads
are remarkably similar otherwise it just
couldn't you just couldn't trade on
these people and get it to decode those
and this is a very stable result we had
some
people from 60 minutes came to interview
us about this stuff and during the
interview we put their associate
producer in the scanner and we showed
her some words and we picked words that
we knew were more mostest criminal but
still we gave her 10 different words and
then we gave our program 10 pair wise
choices is she reading hammer or house
is she reading tomato or toe and it was
correct 10 times out of 10 despite the
fact that and never had seen her brain
didn't train on her brain it was just
trained on other people that we had
collected data from so this really does
work it really is a stable result and
it's in some sense the biggest surprise
that we had on these these were
primarily we use CMU students and so
there and they're not all native English
speakers we did we've done some work
with bilingual Portuguese English
speakers and we found for those people
we could we didn't look at the
cross-cultural question but we looked at
doesn't matter if we present the word in
English or Portuguese and we could train
when represented English words and then
classify correctly when we present the
word in Portuguese so but we haven't
looked at the cross cultural questions
which I think are very interesting we
just haven't gotten their question
there is a mix of left and right but we
tend to use right-handed subjects I
think they're a very small number of
left-handed subjects in you very small
so the results that I'm showing are
dominated by right-handed subjects
question is have we done any tests on
people with cognitive impairments none
that we have results to report on we're
actually doing tests now on autistic
people and it seems that there are
neural representations of these semantic
categories are very similar although
there are also some apparent differences
in the neural activity that don't happen
to be the coating of semantic categories
so we'd like we like to learn more about
them okay so there's some sort of where
we got to and by the way this this last
question and the rest of this talk is
based on data were collected around the
60 words so I just want to show you the
60 words so you can kind of get a feel
for the diversity and the similarity of
the words so notice these are all
concrete nouns of some kind concrete now
means an object you can touch and they
fall into different categories they're
fairly diverse yes there's nothing
special about these since then we've got
another set of much more abstract words
that we've been working with but I just
want to give you a grounded sense of
what these words were okay so at this
point uh we were feeling pretty good
because we had found out some things
that we didn't know we were going to
find including the thing that neural
representations are quite similar across
people but in some sense it's kind of if
you think about what you would really
like to understand about how the brain
represents ideas what we really have so
far here is kind of a list or a catalog
so for these 60 different words I can
show you the catalog of
three-dimensional neural patterns of
activity for each of those 60 words and
I can tell you that they're kind of
similar across people I could even show
you some of the places where they vary
across people but basically we have a
catalog it's kind of like in the early
days when the astronomers who is a guy
Kepler Copernicus maybe the people they
were just cataloging the motions of the
heavens but they didn't have anything
like a theory that would predict where
the heavens are going to be tomorrow and
so we started thinking about the
question what would it even mean to have
more of a theory of how these
representations work so generally when
you think of a theory you think of
something that makes predictions and one
kind of prediction that seemed sort of
the the first one the work on is well we
could say we had some kind of a theory
if we had a computer model where we give
it a new word for which we hadn't yet
collected fMRI data and it could predict
the neural representation for that
network now if we had such a thing that
would require that we somehow figure out
systematicity in these different
patterns not just the list of 60
patterns for 60 words but some kind of
systematicity so we thought about this
for actually years we're kind of bogged
down in this the way you get bogged down
in this is you notice well if I give you
a brand new word about what you don't
know anything like Apple then how are
you going to have a computer model that
predicts fMRI activation if it if you
don't have a way to represent the
meaning of the Apple to begin with so
the way we got unbought was we noticed
that we could use statistical properties
of the word in very large text corpora
corpora and
around this time Google released the
trillion token corpus I think primarily
for use by the machine translation
community from rite of up to five grams
in their accounts so we thought why
don't we try to build a model where we
represent the the the meaning of the
word in terms of statistical features of
that word in a large corpus and that way
we can build a computational model that
tries to predict neural activity in two
steps first given a new word like Apple
it will look up in the text or in the
database summarizing the text properties
statistical features of that and then
based on those statistical features that
will try to predict the activity at each
of the 20,000 places in the brain so
that's what we did and so the first
question is what statistical features
and the answer we came up with it was
pretty simple as we like to start simple
so we made up 25 verbs to be honest I
made I made these up I made up about 15
sets of words and poked around a little
and converged on these but it wasn't a
huge exploration it wasn't like we tried
thousands and thousands of things and
the reason I made up these words if
there's a hypothesis floating around in
the neuroscience community for which we
had seen evidence already that neural
representations of meaning of things are
grounded largely largely grounded in
sensorimotor regions of the brain and we
had seen for example that when we show
people those words about tools that very
reliably there's activity and premotor
cortex when you read the word
screwdriver or the word hammer and
premotor cortex is the part of your
brain that's active when you're planning
to do this or this
so there's an example of what I mean by
the conjecture that neural
representations are largely grounded in
motor cortex also sensory cortex so
you'll notice these verbs have a lot to
do with sensing and motoring see here
listen taste touch and they could Viv's
were the ones my seventh-grade teacher
told me where the senses the five-cent
and then a few more abstract words that
largely have to do with your spatial
relation or the way that you interact
with an item so I'm not claiming these
are the rosetta stone but these are the
25 verbs we used okay and then the
features we defined simply as
co-occurrence frequency so given an
input word like Apple the first step in
the process is to look up in the Google
trillion token corpus data how often
Apple co-occurs with each of these 25
verbs so when you do that you get
statistics like this which so here are
the the word frequencies normalized to
become a vector of unit length the word
frequencies for celery well the verb eat
Co occurs most often with celery and
ride does not occur very often with
celery another hand airplane has a
different profile of verb frequencies so
indeed these verbs do a pretty good job
of capturing the meanings of these
concrete nouns so that's step one in the
model step two of the model then is to
train up the model so that once it's
done it predicts the neural activity at
any voxel in the brain V as the linear
sum of coefficients contributed by each
of the verbs weighted by
how often that verb co-occurs with the
noun in question so it's essentially the
prediction at bothell V is just the
frequency of co-occurrence of the input
word with the I Ferb x sub coefficient
for that verb in that voxel observation
said I saw v could be verb or voxel
villa's voxel there is verb so it's just
a weighted linear some of those images
and those images are all the learned
coefficients during training so we have
60 words of data as you saw we did a
bunch of experiments where we trained on
58 of those words and then we kept two
of the words separate not to be seen by
the learner and we train a model like
this and the model has about half a
million parameters because for each of
the 25 herbs there are 20,000 voxels
whose coefficients need to be learned
and it's basically a big multiple
regression problem so that's the form of
the model and now we can apply it on the
two words that we left out and didn't
train on so when we leave out celery and
airplane you see on the top the
predicted images and you see on the
bottom what the program didn't get to
see which is the observed images for
celery and airplane and you can see
they're not perfect but you can also see
that they capture some aspects of the
neural activity
so that's the that's what the model does
and now we can start asking questions
about about the model and its property
so you can look at those images is a
little hard to tell if you like the
model or not based on these images you
can see it's doing something good but
it's be nice to be more quantitative so
first thing we did was a cross
validation test where we repeatedly
trained on 58 of the 60 words then we
give it the two it hasn't seen we give
the two images it hasn't seen and it has
to tell us whether which one is celery
in which one is airplane so if it's
guessing the chance level it would get
half of those correct by chance and when
we gave this problem to the system it
got seventy-nine percent of them correct
and again we're training models on
individual subjects individual people we
had nine people in this study so if you
average the accuracy all over all nine
trained models this weekend so what this
means is in three quarters more than
three-quarters of the cases if you give
this model two words it has never seen
and to fMRI images for those two words
in three-quarters of the cases it can
tell which one goes with which so
there's real information content in the
prediction this does include words in
the same category now we I don't have
the numbers here but we also looked at
the accuracy if you leave out an entire
category and then just give pairs of
words in that category and it's only
barely statistically better than chance
if you do that if you pick pairs of
words in the same category but you train
on the other there were five words per
category but you retain the other three
it's not this level of accuracy but it's
in sort of the mid-60s then which is
still at least statistically significant
yep
of questions what was the accuracy for
multilingual non-american I don't know
offhand but when I mentioned the
Portuguese English training testing that
it was roughly as accurate as if they
weren't bilingual in that case okay so
that's one way we can look at the model
I think a more illuminating way is to go
back to the learned semantic features so
remember those images of coefficients
20,000 trained coefficients for each of
the verbs and those by the way were
solved back solved by the training right
we never showed verbs as stimuli to
people we only showed nouns and from the
noun images the model solved for those
it hallucinate it essentially the 25
verb coefficient images that are showing
but we could go back and look at those
and see what they look like so we did
that and here for one participant where
the learned coefficients for let's start
with the verb eat so you see that blotch
of activity for the learned coefficients
for eat that's in a region called right
parza / culeros that some people in the
some people call gustatory cortex
because this is the part of your brain
that's activated when you taste things
so we never told that to the program
we're never even told the program
anything about physical adjacency of
voxels but out of the data there emerges
this by best fitting the noun data there
emerges this idea that nouns that
frequently a co-occur with eat will be
represented using activity in gustatory
cortex and similarly for nouns that
co-occur with push they'll be activated
by activity in the postcentral gyrus
which is
essentially we're premotor cortex is and
now as the co-occur with run will be
activated in this third area which other
people had previously asserted was
associated with biological motion with
perceiving biological motion so these
were I think in some ways we were very
surprised to see this we didn't
anticipate this sort of thing but it
just kind of emerges from the training
of the model there's a question over
here Tom probing patients to make sure
that when they make incisions they don't
display parts of the brain that are
important that there's a lot of
commonalities across subject will you
pick these words eat push run did you
have those areas ideas apply no no
Ashley after the results came back I
spent a lot of time this is embarrassing
on Wikipedia typing in parts of perky
aleris and finding out what people had
known about it so I mean I knew that
post central gyrus was associated with
motor cortex but I didn't know there I
didn't know where gustatory cortex was I
didn't know this thing about body motion
so but what was your inspiration Oh for
those words I was thinking sensorimotor
and I and I also looked at the nouns and
I said well we got five foods in here
each is a sensory thing I was going to
put I think maybe we have taste and eat
but i was thinking sense that i was
thinking sensorimotor so that's why I
put them in and push you know motor and
run motor I was trying to distinguish
arm arm motor from Lake motors i put in
push and touch push in touch and run
now we'll see these these images are
images of the 20,000 coefficients
learned by the model for the verb eat at
least for one participant and since we
did this for nine participants another
thing I could show you is the mean of
the nine independently trained models
for eat so we looked at that too and
there is what it looked like so if we
look at the average not just the one for
participant p1 but the average you see
very similar regularities across every
well across the mean of the nine people
so here's even more evidence about the
striking similarity and neural
representations across our brains not
only you know can we train a classifier
on tools versus buildings but when we
train the model independently on nine
people the activity it associates with E
is very similar across the night okay so
another kind of more fun way to look at
what the model does good thing that so
one evening when we're feeling kind of
silly we thought well we've got this
model why don't we build a brain map
every vaasal in your brain we could
label by the word in English that most
that is predicted to most activate this
spot in your brain and so you can
imagine this then you navigate around
the brain and see where grandmother is
if if grandmother is indeed in there at
all so we did that but we didn't do it
for all twenty thousand bottles we took
72 anatomically defined regions in the
brain and just ask which nouns are
predicted to most activate different
areas so for right upper culeros you'll
remember that's actually gustatory
cortex the word in English out of the
10,000 most frequent the noun that's
most predicted by our model is to
activate this is wheat
and these other words on the other hand
this region has a very different profile
of words and my favorite left anterior
cingulate but then if you start poking
around in the literature you see that
people had previously published this
thing about gustatory cortex about
biological motion and left anterior
cingulate people kind of believe is
associated with processing emotional
stimuli so here's another you know
independent corroboration with or
converging evidence from with other
people suggestions about the behavior of
the model aligning with it here another
some others that are kind of
entertaining that I don't understand why
cities especially spanish-speaking
cities would be I guess there are all
kinds large cities are predicted by our
model to activate left superior extra
striate I have no idea whether that's
correct or false this one is interesting
and again their previous evidence or
previous suggestion that this is a reach
and associated with sexual arousal all
right so um
let me skip over a couple slides because
I have one or two things I'd really like
to get to and let me just say you can do
an even better job of understanding
what's going on if instead of
considering the data from a single
person when you're making these
predictions you continue to train the
independent models for each person but
when you test the model you get even
higher accuracies obviously if you test
by giving the two held outwards to all
nine models to predict the nine celery
and airplane images and then there'll be
more signal in the nine independent
predictions than there wasn't one and so
when it goes when you if you ask it to
compare the predicted versus observed
data from multiple participants you get
higher accuracies than I was reporting
for single participants this is just
important because in the next stage of
the research we got interested in well
what really is the correct semantic set
of features those 25 verbs were so kind
of successful but why don't we explore
alternative semantic basis for neural
representations and so we switched to
using this kind of scheme for evaluating
the models because we wanted to not be
confused by noise in the fMRI data so
it's a little bit of a technical detail
okay and now the question is you know
those 25 verbs are really a key part of
the model what we're saying what this
model is implicitly hypothesizing is
that neural representations for every
concrete noun you could ever think of
can be factored into 25 components who's
that can be reassembled by adding them
together in a weighted linear fashion to
predict the neural activity for any word
you think about that's what this model
is essentially hypothesizing but we just
made up those 25 words so what about
alternatives so first thing we did was
we did generate other lists of 25 words
taken from the 10,000 most frequent
words in English and they don't do so
well so the red block over there is our
25 verbs and this histogram shows the
accuracies of other sets of 25 randomly
selected words out of frequent words
okay so there's something going on here
with our verbs but then you start
talking with people you know people say
well why do you use 25 verbs why don't
you just use say the 50,000 most
frequent words in English a fifty
thousand dimensional semantic basis so
we tried that the left column of numbers
they are called mean accuracy is the old
way the original way of evaluating
things the right column is when we
concatenate the data from all nine
subjects but basically it turns out our
25 words continue to work about as well
as other things we tried Tom landauer is
a guy who is known in computational
linguistics for being an advocate and an
inventor or something called latent
semantic analysis which is running PCA
on word co-occurrence matrices and so he
was convinced that would be much more
successful so we tried it there's a very
interesting paper that came out in ICML
last year some people did some multi
task training on a large text corpus we
tried their features so um we're getting
similar answers here but yeah
arbitrary words you tried to
specifically choosing verbs
in the histogram that I showed you we
were choosing random words not random
verbs we haven't tried choosing random
verbs but the the list of 486 verbs here
is a pretty good list and actually I'm
not going to mention this elsewhere but
I wanted to tell you since then we've
collected 40 very abstract words data on
abstract words like justice love anxiety
democracy and we found that when we
train the model using those words our
original 25 verbs did not work so well
but if we use this list of 486 verbs
than it does work well and so that I
think the 25 verbs work particularly
well because we were working with
concrete nouns and when you start
talking about having people think about
words like anxiety it's not as grounded
in sensorimotor regions
it's 486 verbs that I found when I
started poking around the web for lists
of verbs a little embarrassment since
then one of my colleagues who's more
principled has given me a list of verbs
that are from a standard
psycholinguistics database that are
considered the primary verbs but when
you use those you get very similar
results to the 486 yes yeah if you drop
verbs from the original 25 it does go
down so actually when I said that I
tried about a dozen things before
converging on that I tried smaller sets
i tried larger sets yeah I don't think
there's a verb that's key it really is a
kind of combination thing but um so I
just want to tell you that we also you
know we're machine learning people why
are we not getting a program to learn
the answer to our question as we did for
our other questions so we got interested
in the question of just training a
system to figure out what is the optimal
semantic basis and so there are several
ways you can do this but fundamentally
you want to set up the problem the way
shown here on the bottom of the slide we
have corpus statistics that could be say
the 50,000 co-occurrence frequencies of
the 50,000 most frequent words in
English with a word on the right we have
the fMRI data that's 20,000 voxel
readings and now what we want to do is
something like find in a common
abstraction lower dimensional probably
that for which we can get a linear
projection of the corpus statistics into
that abstract space and then a linear
projection back out of that into fMRI
space which is what our model was doing
in the first place it's just that we
didn't discover the semantic features we
just plugged in 25
verb co-occurrences as the semantic
features so there a couple ways you can
do this but and if you're familiar with
PCA it's sort of like running PCA where
you have simultaneously two different
data sets that are paired the way that
we found was most successful was to use
something called canonical correlation
analysis which learns to linear mappings
from the corpus statistics and from the
fMRI up to this abstract space and in
canonical correlation analysis you learn
the mapping that maximizes the
correlation between the coordinates that
you get if you may have the corpus
statistics data and the fMRI data
maximize the correlation between those
coordinates so we did that and we got
the best results we've gotten so far so
if you do canonical correlation analysis
and just keep the 10 most dominant
features then by the measure that we
actually trust more which is the
concatenated data we get slightly higher
accuracy and since doing this we've
collected an additional fMRI data set
shown on the right in this chart where
we use the same 60 stimuli but we left
out the pictures we just showed words
only and we got 11 new people and
collected data from them and so if you
compare our original 25 verbs with the
10 features that are derived from CCA
you can see that on across these 20
subjects in both datasets it looks like
these 10 features do fairly well
so that's I want to wind down because I
know it's going to be lunchtime and I
know better than that so what does this
mean i think if you take away anything
from this talk i would like you to take
two ideas away the first is something we
didn't know before but neural coatings
of ideas at least for concrete nouns are
remarkably similar in our different
heads they're not identical we are
different but the amazing thing is that
they're similar enough that these
modeling procedures can extrapolate from
one person to another the second thing
is really the second thing is that you
can predict the neural activity in your
brain when you think about a word based
on how that word is used on the web
that's exactly what this model is doing
the input to this model is how is this
word used on the web and the output of
the model is the predicted neural
activity and it works so there's
something fundamental about semantics
that's captured in corpus statistics
computational linguists is of course
thought this for a long time but here's
a kind of different twist on that story
and some additional converging evidence
for the computational linguists that to
corroborate their idea that that this
really does capture semantics so I think
going forward there are a whole bunch of
fun things I'd be happy to talk with you
later about we're looking at new imaging
modalities we're collecting data from
Meg right now which gives us one
millisecond time resolution this week
while I was out of town a neurosurgeon
I helped me and our group collect some
data by putting an electric grid on the
surface of somebody's brain who needed
this for clinical reasons anyway and
that person agreed to collaborate with
us and read the same 60 words and think
about them so we have different kinds of
data that we're looking at that I think
will give us a new dimension of data to
play with where we'll have millisecond
time resolution instead of the five
second time resolution that we have for
fmri once you get down to millisecond
you can actually see the unfolding of
the awareness of meaning in the brain
takes you a couple hundred milliseconds
to look at a word and realize what it
means so we can look at that every
millisecond while you're doing that we
might be able to get some insights into
how these representations are actually
constructed whereas right now we're just
saying sort of what they are and what's
the systematicity but be interesting to
have a more causal picture event too so
thank you it's great to</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>