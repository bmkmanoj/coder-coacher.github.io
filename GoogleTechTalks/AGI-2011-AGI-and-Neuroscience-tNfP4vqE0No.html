<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>AGI 2011: AGI and Neuroscience | Coder Coacher - Coaching Coders</title><meta content="AGI 2011: AGI and Neuroscience - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>AGI 2011: AGI and Neuroscience</b></h2><h5 class="post__date">2011-09-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tNfP4vqE0No" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so last year at AGI I gave a lecture
about reinforcement learning in the
brain and I gave a talk also about
large-scale recording in the brain or
from the brain this time we've got an
entire neuro tract in AGI and so I'm
gonna use my time on the soapbox to try
to introduce explain and advocate why
that might be useful for AGI human
intelligence is intrinsically something
that's meaningful to us whereas other
types of intelligence intelligence that
may seem a bit more strange or different
well it can be useful for a lot of tasks
but it's just not the sort of thing that
we're viscerally connected with in the
same sense that we see typical strong AI
show up in sci-fi movies so a project
like OpenCog for example just to use as
an example uses many methods so it's
open to a lot of different methods but
overall it really relies on cognitive
science to establish what what sort of
parts it requires of what we think of as
a brain or intelligence and maybe
neuroscience can help to elucidate some
more of those parts now you might be
wondering what is a typical experiment
of cutting edge a cutting edge type of
project in neuroscience today there are
lots of interesting projects going on
and just to highlight one that's very
popular right now I'm going to point out
the hope the sorry the Blue Brain
Project in the Blue Brain Project so
this is Henry Markram this group in
Switzerland what they do is they try to
model at great detail the cortical
columns in a rat and what he's done in
his previous work is that he did a lot
of studies on the connectivity between
neurons so a long long range
connectivity short range connectivity
and they used that to come up with the
statistics that are relevant for these
for these cortical columns and they also
use an electrical model to represent
what the neurons do and the equations
called the hodgkin-huxley equations to
express what these neurons should be
doing whenever they are firing whenever
they're active but the question is can
investigations like this actually help
us to advance our understanding of
general intelligence so how does that
affect AGI ai is been guided largely at
least so far by cognitive science and
insights gained from psychophysical
experiments this means that you end up
with cognitive architectures and
modularity functional specialization
that are expressed in model site such as
Akhtar and soar and many visual visual
system models reinforcement learning etc
and Xavier made some really good points
about this during the lino tutorial
actually he pointed out that cognitive
models are complex and sophisticated and
I guess if you're talking about
something like general artificial
general intelligence you really
shouldn't expect something simple and
unsophisticated but anyway what you're
left with is a huge plethora of
cognitive models each one of them
derived by focusing on specific tasks
psychophysical experiments are good at a
few things they're very good at figuring
out parameters limits error modes things
that help us to determine what sort of
functions may actually be going on in
the mind and which ones are probably not
happening but they also only illuminate
those features that you can test at that
moment so they're only measuring things
that are being expressed so critical
aspects of collaboration between
implemented functions that maybe there
could be missed if you attempt to
reverse engineer a cpu would you
restrict yourself to observing a couple
of programs say five programs would you
for example do so even if those five
were picked specifically because they
happen to be easy to characterize
because none of those five used anything
more than say three of the same
operations this is something that
Dharmendra mantra Dharmendra Mata made
very clear at one of his recent talks in
fact he pointed out that most models of
the brain only use a very small portion
of the knowledge that we have about the
brain and that's without even saying
that even those models even those
collections everything that we know
about it is probably incomplete he also
took a deeper look at a presentation
that came along on Tuesday at another
conference where he mapped out many more
brain regions based on something called
the Coco Mac database that's a database
of macaque monkey brain regions and
information about them and he stripped
them down by degree until he ended up
with what he called the core of the
brain the place where the clustering is
particularly dense and where the
connections from all the other parts of
the brain seem to terminate even then if
you simulate that core it results in
data that's
difficult to interpret and his solution
for that or his temporary solution
anyway was to glue together 16 monitors
which gives him 64 million pixels that's
about one pixel per neuron in the cat
brain and whether that's going to help
to understand what's going on in there
that's still an open question but if you
don't look inside the box it's easy to
be overconfident about what we actually
know about the brain about the mind and
about intelligence without naming names
another good friend of mine recently
presented his approach to AGI at a
conference and he began by noting that
the local structure in the auditory
cortex and the visual cortex and many
other areas look very similar so the
brain seemed to have only one
fundamental algorithm but there's no
free lunch meaning ok how can this work
on all the problems in life that can
only work if those problems have the
basic same underlying structure
consequently he assumed it's safe to
devise a GI based on what algorithm
needless to say he got into a lot of
trouble with the neuroscientist in the
audience mostly because there are many
parts of the brain that operate quite
differently than the neocortex does but
also what is an algorithm in where do
you find it is it in the opcodes that
are in your computer or is it really in
the way that you use those to write C
functions for a specific purpose so it's
really in the specific circuitry that's
formed by the common elements not by the
Elam's themselves even if those are for
example entire mini columns in the
neocortex this is what makes AGI
difficult no matter what your framework
is having operators is not the same as
having a complex program I'll call this
the Numenta or HTM problem of AGI we may
not know 90% of how the brain works and
I can equally claim that we don't know
90% of the content that makes an AGI
forming representations as hard as Josh
Hall said wouldn't it be interesting you
know some of those 90% happen to be the
same so how does one select between
available models how does one validate
or test one's assumptions a good
scientific principle is to seek more
ground truth Nobles which we can ground
our theories and models in models are
the domain of theorists and the ground
truth and measurements are the domain of
experimentalists one way to get around
the problem of inspecting a black
box by looking at its input and output
is to open it up and investigate what's
inside for a long time though
neuroscience just didn't have the tools
to do that there was no way to reconcile
the very small with a very large so in
that sense Ben is right when he says
that we really don't know much about how
the mind is implemented in the brain but
the thing is we're actually at the cusp
of developments that are about to change
all of that and we saw some of the this
morning with ed Boyden stalk so in this
era where connectome research is
accelerating and new projects are
appearing on a weekly basis neuro
informatics is going to begin to learn
about mechanisms at the scale and
complexity that's relevant to the human
brain and to jagi as well neuro
informatics is beginning to combine
functional models of components with
structural information from the
connectome and what you're seeing here
is probably one of the best examples of
this Brigman and winfrey DANC recently
published this and it's a really an
achievement that shows outstandingly
that you can derive high res arriving
information about function from high
resolution large scale analysis of brain
circuitry what they did here is that
they recorded from the ganglion cells in
the retina this is what you can see in
the in the top picture the upper right
little thing with their colorful circles
and they they discovered what the
receptor sorry the receptive field
directions were in those ganglion cells
but they also measured and recorded data
from a reconstruction a 3d
reconstruction at high resolution of the
morphology of the system so where it was
sliced really thin and it was put under
an electron microscope and they were
able to use that to derive from the
connectivity that they found in this
reconstruction what the receptive fields
must be so they found in fact that those
receptive fields were the same that
they'd recorded before indeed from
looking at them at the very detailed
structure they were able to derive
function similar projects in zebrafish
are now underway as well and at both
Stanford and Harvard it's so the
question is is it important to be able
to deduce functions from implement that
are implemented in brain circuitry and I
would say if you're wanting to use it to
advance AI then yes if you want to use
it to improve DCI brain computer
interfaces then yes if you want to use
it to fix or improve brain function then
yes if you only want to copy
then I guess no except that probably
understanding more about it will still
help you to identify and correct copy
errors learning from the brains
implementation is akin to the way a
programmer can look at someone else's
source code and learn from it that's why
in a sense that's a major strength of
the open-source movement and that's
something you can gain by looking inside
the box
the brains implementation isn't
necessarily oh this is not even quite on
the mark there isn't necessarily the
best one for a specific task but at
least all of the functions are there and
they all work well together and AG I can
learn something about adaptive robust
self consistent integration and
coordination in a complex system
that's why I'll call this the second big
problem the Nova mentor open card
problem so how for example do you self
organize associations at different
levels of abstraction or how do you use
the co.design of hardware
implementations with their target
functions for an efficient autonomous
system maybe something that could run at
ten watts for example there's more but
we don't have much time so ask about it
and then we'll talk about it later
now it's not paging forward the way I
want to obviously I've done something
wrong
probably have to get out of that box yes
there we go
human intelligence is an extreme
complete inextricably linked to the
question of AGI some of it is about
making things that are as versatile as
we are for example a human can learn how
to read can learn how to do mathematics
and then can go out and read textbooks
read articles and can become a
computational neuroscientist or go work
in macroeconomics or something like that
but it could also be that we want to
deal with some of the aspects of human
intelligence or behavior that were not
satisfied with for example we're really
not very good at math we're not good at
deductive reasoning we're not really
good at estimating at all or
multitasking and I guess if we go beyond
these fundamentals it's just that we
often struggle with the conflicting
demands of our intrinsic drives and of
our intellectual pursuits
so whether AGI begins de novo without
relationship to human intelligence or if
it's built to resemble human cognition
it's really a tool that we create to do
something with specific goal in mind
using cool tools is nice but watching
from the sidelines as another
intelligence creates future cultures and
achieves astonishing things is
definitely suboptimal our dreams and
legends and stories are about heroes
to embody superhuman capabilities who
can fly so right now I can experience
intimately what it's like to carry out
vastly parallel neuromorphic computation
that's what's going on inside my head
but I'd also like to be able to
experience what it's like to calculate
like a calculator and I'd like to
experience thoughts that include quantum
computation I think that if these sorts
of things were options there were very
few of us who would reject the
possibility to at least explore that
that's where I think the drive
motivating work in AGI is shared with
the search to enhance the human
experience that includes fundamental
experiences like how we become fixed in
our ways as we age as particular paths
are being pruned and other ones are
being strengthened and it's hard to get
around that after a while so it's easy
to say that dealing with the brain is
hard that adding memory is easier in a
computer or that access to the details
is easier but stating that something is
easier isn't a good reason to reject
something that could be hard after all
there are probably also tons of things
that you could do that are a lot easier
than making a GI artificial general
intelligence can also be about enhancing
the generality of existing intelligence
sometimes that improve involves
improving existing AI maybe something
that comes from narrow AI and so for
example when it involves improving
natural human intelligence a GI neural
engineering and brain machine interface
has become overlapping domains there is
more but we don't have that much time so
I'm not going to continue on this topic
for much longer you can ask me about it
and we'll talk later beyond learning a
few things from neuroscience we can make
a case for detailed reverse engineering
there are a bunch of terms in use but
just to keep it concrete I'll talk about
a procedure conservative approach where
you try to copy all the neuroanatomy and
the neurophysiology and that's what we
call whole brain emulation it's
conceivable that we can determine the
transfer functions that's what the T
they're supposed to represent of all the
important elements and that we can also
and it's actually increasingly likely
that we will know the structural
connectivity between those elements
that's knowledge that you can gain
without actually understanding how a
mind works
it makes reverse engineering and
emulation an approach that could get
around stubborn or intractable
conceptual hurdles and in emulation
there's a closer connection with
physical ground truths that can increase
the confidence about stepwise
developments and its eventual
culmination in a working whole at the
moment developments benefitting whole
brain emulation and connectome research
are advancing at a rapid clip computing
hardware is rapidly becoming more
parallel which benefits naturally
paralyzed processes like the brain
neuroinformatics is taking steps to
address representations at large scale
for example in the blue brain but also
in other attempts such as at the eye ncf
recording from the brain is beginning to
address large-scale and high resolution
via very large recording arrays channel
insertion and similar biological
approaches the number of projects
addressing problems of whole brain
emulation are increasing at an
increasing rate and I just have a few
examples up here in one corner you see
an excerpt from an image taken with the
Adlam next to that is the knife edge
scanning microscope we've got work to
upload basically a C elegans there's
zebrafish project there is at Boyden
down in the other corner Brainbow a
number of other projects going on
so connectome research is really
becoming a major mainstream scientific
pursuit now to my last topic what really
determines the progress that we make
it's really all about the money funding
for AGI there's the academic route of
course seeking grants in that area
the usefulness of partnership with
neuroscience should be obvious because
it's clear that more grants are going to
be devoted to human intervention things
where they where humans feel that they
are being helped personally such as in
the NIH where you try to solve diseases
and problems like Alzheimer's and stuff
like that then there's the private
sector entrepreneurial efforts arguably
that's where the true prospects of any
new technology line it's only when
manageable chunks of development each
with their own profit incentives become
apparent that the technology truly takes
off we've already seen the effective
market pull on narrow fields of AI on a
concrete example is for example at the
company I work for
Halcyon where we have a specific
interest in more general AI namely
increasingly sophisticated AI scientists
or experimental
broader than most areas of AI it's still
a very well described task it's a good
case for gradual entrepreneurial
improvements you can incorporate
increasingly difficult parts of the task
and at each stage there are savings for
those who implement it and so there's a
market there's more about this as well
but we only have a couple minutes so ask
about it we'll talk later
we need entrepreneurial role models we
need people with talent vision and a
multidisciplinary ability to conceive
and guide ventures as another field
success requires both technical skill
and artistic ability communicating
across disciplinary boundaries and I
know this is the wrong picture because
it should have been an Android since
we're here and not something from Apple
so hopefully it's becoming obvious that
those neural researchers and AG I should
interact benefit from each other and
deal with many of the same problems in
humans BCI and AGI open sourcing the
brain learning directly from it and
re-implementing its parts is a potent
means to exchange knowledge between
neuroscience and AGI we can use that
approach to explore undiscovered
functions essential to the mind the
requisite size and complexity of
intelligent processing hardware burdens
the need for massive parallelism as a
neuromorphic computing the need for
embodiment or total immersion in
realistic problem space reverse
engineering by connectomics has a need
for new tools and new tools like
telescopes bring about scientific
revolutions there's a lot more but we
can talk about that later as well so one
way to do AGI is to do de novo
intelligence another is to enhance
existing intelligence to make it more
general and there are gradual ways to do
that and those ways are lucrative it's
not a coincidence that many of the
researchers working in AGI are also
interested in neuroscience and
vice-versa
thank you
okay we have a panel at the end so right
now we'll just go straight on to the
next talk since I took quite a while
okay hi can everybody hear me yeah well
that's everybody at the back is well
good I have to start with two
disclaimers the first one is that I'm
gonna be very brief here and if the
arguments seem a little superficial read
the paper I'll they'll be a little bit
more deeper if you still don't agree
then talk to me and we can talk about it
the second thing is that I'm not an AGI
researcher as such I'm a computational
model I in cognitive science with a
heavy interest in neuroscience and the
first time I even heard of AGI was when
the call for papers for Neuroscience
session came in my into my inbox so I
study California that sounds good I'll
go to California and then the second
question that came to my mind is like
why would you even want neuroscience in
AGI because it wasn't immediately clear
to me and I define intelligence for
myself really as a measure of the
cognitive abilities of an agent so I'm
more floating the entire problem of
defining what intelligence is into the
problem of defining how to measure the
cognitive abilities of an agent and
consequence of that is that human-like
intelligence isn't necessarily
human-like cognition and what you're
after in AGI is human-like intelligence
rather than human-like cognition so I'm
guessing really that the interest in
neuroscience comes from the fact that it
studies the mechanisms that underlie
human and animal cognition and therefore
since that is like the only example of
an intelligent system that we have
knowing how that works
might our boss billing building
intelligent systems neuroscience player
the second thing that came to my mind is
like haven't we been there done that's
like they're people who build models of
just computational circuits that they
find in the brain without really knowing
what they are doing we had the entire
connectionism thing we have record you
on that were exact estate Knapp works
liquid state machines etc so I don't
want to talk about all of these I mean
these are all neuroscience inspired
approaches but I think some of these
all the reservoir computing this subtle
which neuroscience and then very quickly
you're into mathematics physics
dynamical systems where you can do
really amazing things but you not
necessarily have to check back with the
brain at any point after that you can
build really clever systems that are
that go beyond what the brain does it go
into a completely different thing so I'm
more interested in what's inside what
other type of insights can be gained
from neuroscience and then there is the
pessimist in me that says that the
understanding of neuroscience is very
far from complete understanding of human
cognition also very far from complete so
to turn to the mechanisms that you don't
understand underlying a system that you
don't understand in order to build a
similar system with similar properties
good luck but okay I'm not that
pessimistic so not let's quickly turn to
another thing it's embodiments which I
think people have heard of now but if
not okay it's very difficult to
summarize on one slide usually people
have conferences to talk about
embodiment but the body shapes the minds
that's didn't the fundamental message
here how far is a matter of debate if we
look at the concept of symbol grounding
there are people who believe that the
way the mind represents and processes
symbols involves the essence promoter
level
intrinsically it's impossible to process
symbols without doing that whereas other
people will argue that yeah okay maybe
you need the sensorimotor level to
ground the meaning of the symbols but
you can actually process these and do
your intelligent stuff at an a modal
level abstractly what neuroscience
evidence we have a country between to
support either position and I don't
really want to go into that in too much
detail now but I see three important
implications of embodiment which then
have three important consequences the
first one is that the cognitive
cognitive abilities of a machine they
might well depend on the machine itself
the second one is that if you want
human-like cognition you might need a
human-like body and the third one which
is probably the most important one in
this context is that if you're going to
study mechanisms in a human body that
are used to give rise to human
mission it might not necessarily be
relevant for machines that have a
fundamentally non human embodiment okay
there are consequences the first
consequence is that if you want to
design an intelligent machine you
probably have to design both the machine
and the algorithms and not just a ladder
and the feel of cognitive for robotics
for instance is getting into these
getting into that a lot the picture you
see here is an AI cup because
everybody's talking about the now I sort
of put up a different picture and you
don't necessarily have to have a human
embodiment but the capabilities of your
intelligent agent are going to depend on
what its particular shape inside the
world is going to be a second
consequence it's possible they're really
possible that you cannot do human
cognition if you do not have a human
body
there are many embody many studies that
show how the human body affects the
human mind at all levels I'm citing the
snag effect there it's probably not the
best example but I tell what it
basically says is that the way you
represent numbers depends on yeah it
depends on your body if I ask you to
turn your head left and right left and
right and to randomly produce numbers
you're going to produce smaller numbers
on average if your head is turned and
left then if your head is turned to the
right you have this spatial
representation of small numbers to the
left large numbers to the right okay the
more important consequence again is that
well maybe there is no point in doing
your respond or a science inspired hgi I
don't really think that but if you
really want to be extreme about the
consequences of embodiment maybe you
want to get to that point but I think
it's more useful to see it as that when
you look at neuroscience
you can't just blindly copy what you see
you have to ask yourself some questions
more importantly what is it that I'm
actually seeing and how does it relate
to the embodiment that I'm also
observing so some of the mechanisms that
you might be seeing can just be a
constraint of the body just because of
the fact that you're in a human body
means a biological chemical system means
that you have to do things in a certain
way that are not constraint they're not
really
giving you any advantages just that you
don't have any other options then there
might be mechanisms that actually
exploit the embodiment so they take your
body and then they do something funky
with it I think these are the most
interesting ones for AGI we'll get to
that in a second and the third one is
that there might be mechanisms which are
completely independent of them of the
embodiment I have some examples where
the body constraints well I picked
spikes for that no it's probably not
everybody's going to agree with that but
I like the example because what we have
is various small animals like C elegans
was also mentioned in the previous talk
they don't use spikes they have
electrotonic potential so slow graded
signaling things and they're faster they
carry more information they're really
better than spikes spike signaling in
almost every way except they're really
bad at long-distance signaling so it's
fine if your little animal that's a
millimeter long with all the neurons in
like a tenth of a millimeter but if you
have a human brain can't do that so the
distance required for signaling in the
brain might well be the constraint that
made us use spikes rather than other
things but independent examples I can't
really think of one I think a lot of
people would say that generally the
computational mechanisms that the brain
implements might be one whether that is
really body independent or still
constrained by the body or that I don't
know I don't want to get into that
discussion the body facilitates I see
mainly language and the mirror neuron
system language because the body helps
you ground the concepts that you have if
nothing else and mirror neuron system
because I recently wrote a paper and I
kind of want to plug it a bit now what I
want to say about mirror neurons is that
there are neurons that fire both when
you observe actions and when you execute
the same action and one study in
particular by fougasse see they did
electrophysiological recordings in the
monkey brain and intraparietal low-pass
sync and what they showed you is that
there are mirror neurons are organized
into pool of neurons that each encode
the specific motion primitives so some
neurons will be encoding a reach all the
neurons will be encoding a grah
and a circle of neurons will be encoding
bringing whatever you grasps now to the
mouse if it's food and to eat and what
they also showed is that some neurons
fire only if the most primitive is
observed in a specific context of a
specific code so only if you're going to
eat the object or rather than placing
the object somewhere and all the neurons
fire independently of that and I really
have no time to go into that in a lot of
details but there is a paper currently
under review where try to show that how
many neurons will fire only when you see
a specific goal and how many neurons
will be firing independently of the goal
just generally is a consequence of the
input into the mirror neurons system
depending on how the brave body provides
these inputs and depending on how you
then encode it you can have any sort of
organization that you want within the
mirror system I'm trying to music that
to say a little bit that the mirror
system actually exploits the body in
that sense the body provides information
in a certain way and the mirror neuron
can use system can use that that way the
information is provided in order to
create an organization that can then be
used in higher level cognitive systems
tasks take-home message then really is
that if you're going to do a
neuroscience impro approach to the
design of an intelligent system you
should not forget that the data you're
getting from taking it is the data from
a human body from a system that has
developed over years to create human
cognition in a human body and yeah you
can do a lot of interesting things with
it I saying it but when you're building
a machine you have to be aware that it's
not exactly and the same thing so when
you take examples of where the bra where
the body actually facilitates what you
can do with your neuroscience you
probably can't translate that one to one
to a machine but what you can possibly
do is come up with a similar system so
that your intelligent machine in a
different embodiment
still make the maximal use of its
embodiment that's it yeah okay well for
about 30 years I was involved in the
design of extremely complex real-time
electronic control systems and for the
last 25 years partly overlapping with
I've investigated how to apply the
techniques we use to maintain
understanding of very complex electronic
systems to understanding how higher
cognition works in terms of physiology
and one spin-off is a conclusion that
the architecture of the brain has some
important lessons for artificial general
intelligence if you're going to design
any complex electronic system two
architectures are of great importance
one is the functional architecture that
divides up the features of the system
into groups of closely rated features
and specifies how those features are
going to interact the second is a
physical architecture and this divides
up the physical resources of the system
into components that perform different
information processes in this case
electronic systems data read and write
an execution of instructions and any
feature uses most or all of the
components of the physical architecture
and almost all electronic systems have
the familiar memory processor
architecture and it's interesting that
this physical architecture is so
ubiquitous now this is the physical
resource architecture of the brain and
interesting that structures
corresponding with the cortex
hippocampus thalamus basal ganglia
sub-elements cetera are ubiquitous in
the mammal brain and also can be found
in Berber Eanes and to a degree even in
reptile brains so the relevant question
is what the information process are
being performed by these different
structures and this is a view of those
information processes and they're not
the same as the processes going on in a
computer on the Left there's a group of
structures including the cortex that
define and detect conditions within the
information available to the brain which
means sensory inputs but also
information about the state of the brain
itself including the court
receptive fields can be defined as
groups of related conditions and the
receptive field is detected if a
significant proportion of the conditions
are present and receptive field
detections are communicated to the
structure on the right and in the basal
ganglia each detection is interpreted as
a set of recommendations in favor of
many different behaviors each with an
individual weight and the basal ganglia
determines the total recommendation
weights of all the behaviors and
implements the strongest consequence
feedback or rewards changes the weights
of recently accepted behaviors and
weight changes are behaviors they need
special management because they have
very potent effects on system behavior
as you can see from human addiction now
as I said anyone receptive field
detection in the cortex has many
different behavioral meanings but
receptive fields have to be learned and
then he changes risk damaging the
integrity of all the previously acquired
meanings so there's a special subsystem
the hippocampus that manages the changes
it detects special receptive fields that
recommend when and where other cortical
receptive fields will change and then a
few words about the Sabella must give or
the others the moment sometimes a
sequence of actions is frequently used a
playing the piano or speaking there are
different sequences of muscle movements
that are frequently used in the same
order it would be possible to go through
receptive field detection and
recommendation weight comparison at each
point in the sequence for each action
but it will be slow so it's more
efficient to store frequent sequences in
the C bellum and an in initial receptive
field detection triggers a sequence that
usually goes through to a conclusion so
the cortex is a thin sheet of neurons
with a pronounced column structure
perpendicular to the sheet there are
several million columns and each column
detects a different receptive field and
a representation of some receptive
fields detected in cortical area te as
shown on the right this area is
important for distinguishing between
different categories of visual objects
but note the receptive fields don't
correspond with object categories one
receptive field recommends identifying a
number of different categories and the
basal ganglia
implements of behavior appropriate for
the strongest recommended cavity like
saying the name of the category the
cortex is divided up into probably
several hundred areas and some are
numbered in the diagram each area has a
different detailed column structure
different sources of inputs and
different output targets so each area
detects a different kind of receptive
field each kind of receptive field is
useful for recommending a number of
different types of behavior for example
the diagram shows the cortical areas
that are active during two tasks
remembering a past event and imagining a
future event and each task has two
phases one is conceiving an event from
some verbal cues and the second is
elaborating the details now you might
think that remembering and imagining are
different kinds of tasks but they use a
lot of the same resources exactly the
same green areas are used for conceiving
an event exactly the same red areas for
elaborating an event the difference is
that there are some extra blue areas
that support conceiving a future event
so a major design decision if you like
inverted commas is specifying the number
of areas and the types of receptive
field that would be most useful for the
kind of behaviors the brain has to carry
out and a more detailed level neurons do
the condition detection branches of the
dendritic tree define different
conditions and there's a complex
integration process by calcium action
potentials illustrated in the top right
to determine if enough conditions are
present to trigger our neuron receptive
field detection column receptive fields
sometimes have to change and there is
two principles to minimize the risks to
the existing behavioral meanings don't
change unless it's absolutely necessary
and change as little as possible and in
any situation there needs to be at least
a minimum number of recommendations to
make sure there's a high integrity
selection so if less than a minimum
number of receptive field detections are
going on some receptive fields have to
be expanded slightly so they're going to
be detected as well now to get the
minimum change think about the column
structure for a moment the top layer
neurons detect relatively simple
conditions the middle layer more complex
the bottom layer even more complex and
these are the outputs the column
receptor
field detentions if there's lots of
middle layer activity and no bottom
layer that indicates that only a slight
expansion would actually get detention
sothe expansions are needed you need to
find the columns with the strongest
internal activity and that's what the
hippocampal system does the middle layer
activity of columns all across the
cortex is collected it's organized into
groups of columns that have often
expanded their receptive fields at the
same time in the past and then into
groups of groups and finally these super
groups are communicated to hippocampus
proper and then in the hippocampus
proper there's a competition process
that determines which are the most
appropriate columns for expansion and
there's output some ca1 that drive the
receptive field expansions now I've
talked about the information processes
but how can these processes be used to
support complex intelligence now
intelligence can access information from
past experiences not just the current
sensory inputs which means some indirect
activation of receptor fields but how do
you pick which fields to to activate in
the diagram just one cortical areas
illustrated a number of times at the top
all the columns that are ever activated
in response to seeing different birds
are colored red any actual bird
experience in the next 4a illustrations
are will activate a different subset of
columns
although the predominant recommendation
strengths will be in favor saying maybe
that's a bird an unfamiliar object I
like at the bottom will activate less
than the minimum number of columns so
there's got to be some receptive field
expansion illustrated by the shading now
different birds activate different sets
of columns but some columns turn up
relatively often in different but not
always in response to different Birds
I've indicated in some shading now
suppose each time you see a bird you
hear the word bird there's some auditory
columns that are going to be activated
as well and some of those auditory
columns will often be active at the same
time as the frequent visual columns
now if the auditory columns can
recommend indirect activation of the
visual columns on the basis of frequent
simultaneous past activity then hearing
the word will activate a set of columns
as if you're looking at a kind of
average bird in other
it's a semantic memory now think about
recalling an event at the time of the
event let's suppose columns in different
areas all sorts of areas will be
activated if the event is novel there'll
be quite a bit of receptive field
expansion I suppose a bit later you have
some verbal cue words and those cue
words will result in activation of some
visual columns indirectly as discussed
earlier but now let's suppose that
columns also have recommendation strings
to activate other columns on the basis
of simultaneous past receptive field
expansion what's going to happen if you
put that kind of recommendation into
operation is that it's going to lead to
an active column indirectly activated
population that will approximate to the
column population that was active during
the original experience in other words
you'll have an episodic memory of that
earlier experience I want to touch
briefly on some of the other structures
so the on on the right and let me
comment briefly on the basal ganglia
behavior selection has to meet two
general constraints usually select a
behavior and never select two
incompatible behaviors and the
arrangement of nuclei in the basal
ganglia meet the constraints the
striatum determines the total strengths
reach behavior a direct path encourages
behavior an indirect path discourages
other behaviors and a modulation path
meet make sure that no more than one
behavior is selected in any particular
time and then behaviors are implemented
via the thalamus by triggering the
release of cortical informations of the
appropriate place now reward behaviors
are selected by the basal ganglia as
well but they have to be implemented
back into the basal ganglia because
their weight changes so there's got to
be very careful management of strategic
tactical general movement and detailed
movement behaviors and in humans reward
behaviors can go badly wrong where in
the case of addictions now I think I'll
skip over the thalamus for the sake of
time I basically the thalamus is is
picking the information that will be
passed from one cortical area to another
on the basis of cortical information
qui cortical recommendations and see a
little bit then about the C bellum
which is some so basically the the see
bellum is has two parallel paths that
the regular path through the basal
ganglia and thalamus is the one that
selects behavior and then the Sabella
versa but that Sabella the Sabella
cortex in Sabella nuclei and get all
sorts of cortical information and they
can drive sequences of behaviors and
again for details see they see the paper
so there are some theoretical arguments
but as a system needs to learn more and
more features with limited physical
resources it'll tend to be constrained
into the brain architecture I've been
describing and I've cut the currently be
careful with functional architectures
that don't pay attention to the
underlying information processes almost
any functional architecture could work
but as the ratio of the features that
have to be learned to the available
resources increases systems that don't
use this kind of architectural runners
and problems and the problems basically
I either new learning will tend to
destroy old learning or the resource
requirements will or tend to be
excessive and the archit this
architecture in the brain has a
demonstrated capability to be scaled up
to handle very large numbers of learned
features thank you
okay good afternoon everybody my name is
Chris Keller
Janelle Zeri and Brian curser our
students have been working with me on
the project that I'm about to tell you
about so the toddler talk is what makes
a brain smart so let's first start with
questions about what the roles of
neuroscience in research of neuroscience
might be in research on artificial
general intelligence so one of the roles
that we can think about our cognitive
architectures and I think we've heard a
lot about that over the past couple of
days so you can imagine basically taking
large-scale wiring diagrams in our
models and trying to map them on to
large scale systems level brain
descriptions right um certainly this is
something that's been going on for a
long time and needs to continue to go on
I would just like to sort of caution
that one of the issues here is that we
are largely driven by the architectures
and mapping them on to the brain
structures rather than the other way
around so I'm not it's not clear to me
at least at this point in the sort of
state of research that we're drawing a
lot from neuroscience at this level I
think more it's going in the other
direction but we can talk about that
more during the panel a second level
that we can talk about the role of
neuroscience in AGI is that we can sort
of bring it down to sort of
microcircuitry levels so we can talk
about laminar structure columnar
structure we can talk about neuronal
structure right and certainly there's a
you know enormous amount of research
going on at this level as well that
again certainly is going to be very
valuable I think as we move forward with
AGI research one cautionary note here
that we've already heard I think ed
Boyden mentioned um is that you know
we're at such a level of detail here
that it's somehow it's going to be
potentially difficult to determine what
are the principles that matter for AGI
when we get down to this level and one
of the principles that are more sort of
implementational that have more to do
with the biology rather than the sort of
intelligence part of this level of
analysis so the one that we're gonna I'm
going to talk a little bit about today
is this sort of third level that we can
imagine which is sort of a neuronal
principle kind of level and again I
think we heard something about this from
ed Boyden today this is the idea that
we're going to try to draw abstractions
from you know general abstractions from
there
science at whatever we might take our
best guess as the basics or a unit and
see what we can do with those
abstractions right and so and as it had
told us today the the neuron seems like
sort of a good place to start and in
particular when we're dealing with
sufficiently complex nervous systems
we've got the spike okay we've got also
at a very general level you know all of
these nervous systems have recurrent
activity at various scales right we've
got recurrent activity locally we've got
it sort of mid-range we've got
long-range recurrent activity so that
seems to be a fundamental principle and
then we've got at it
we've got plasticity right we've got
synaptic plasticity of various kinds so
what you see here is basically SCDP
spike timing-dependent plasticity
something that's very popular and
gaining a lot of attention these days
we've got hebbian plasticity all sorts
of mechanisms but if we put these three
together this seems like a good place to
sort of draw try to draw principles
write draw information from neuroscience
and that might tell us something about
intelligence so if you basically just
take those principles I just mentioned
it seems somewhat trivial right so it's
kind of what's the big deal we all we
all sort of knew that um reservoir
computing is somebody just mentioned
like with state machines Echo state
networks I think has taught us a pretty
interesting lesson about just these very
very simple principles and the sort of
I'm going to sort of play this out over
the next five six minutes so the
principles the lessons that I think we
can draw from those principles are that
if you just look at recurrent spike
dynamics okay we know they're okay so
they're all fundamentals to cortical
circuits but what's interesting is that
it appears that memory and computation
are very generic and very inherent to
pretty much any kind of recurrent spike
dynamic Spike dynamics provided that you
have this sort of right level of
recurrence and I'll get into that so the
bottom line the take-home message here
is that maybe general intelligence maybe
a GI has a we can learn a lesson from
this right that basically recurrent
spike dynamics have inherent to them
whether almost whether you like it or
not memory and computation so maybe you
know maybe we should we should base some
of our theories on that so in case
you're not familiar with reservoir
computing here's a basic diagram from
birching or nationally
the idea is that you have a recurrent
network that has ongoing activity inputs
come into that Network and they perturb
that activity they change the nature of
that activity right now the importance
of sort of the the key break I would say
from previous work to sort of this style
of modeling is that that recurrent
activity is not learned it's generic
okay its general purpose it just has
general memory and computational
capacity to it and I'll get more into
that in a minute
and the idea of a liquid state machine
or a reservoir computing device is that
you're going to learn a very simple
function like a linear classification
for example to read off of that
recurrent activity so the recurrence is
hard right it's nonlinear it's very
difficult to control but the idea is
don't bother just let it be what it is
and then learn an easier function to
read off of that nonlinear dynamic okay
so so the tie we'll talk what makes it
brain smart if you come at the that
question from this approach of these
neuronal principles and reservoir
computing well now we can reframe the
question right and we maybe make some
attraction here we can say what makes a
good reservoir right now I'm not saying
that the all parts of the brain are all
working like a liquid say machine that's
sort of silly it's a principle right
it's a principle that that there's
something important to this idea of
memory and computation being inherent to
recurrent dynamics if it's true then we
got to know what makes good dynamics in
this regard now what I want to sort of
basically try to drive home today is
that a dynamic balancing of excitation
and inhibition is going to turn out to
seem to be an important answer to that
question not the only answer right but
an important answer the question and
again I'm gonna go back to Ed Boyd's
talk so he showed you homeostasis right
and how the brain basically if you if
you knock out certain parts you knock
out some excitatory parts the inhibitory
parts come in and try to sort of level
the playing field so to speak so this is
the kind of this is exactly the kind of
thing that I'm talking about here so now
what I want to tell you is just give you
a sense of some of the work that we're
doing along these lines and the kind of
mechanism that we're using in these
models to get this to get this dynamic
balance
excitation and inhibition okay so we're
gonna use a principle called critical
branching it's a kind of homeostasis a
rather special kind of homeostasis then
it won't have too much time to go into
here but the basic idea is if you think
about spiking in a recurrent Network as
a branching process where each spike
branches into some number of future
spikes over time then you can describe
something called a branching ratio which
is says you know given a certain number
of spikes at time T how many spikes
do you have going forward at time T plus
tau or something like that um in that
framework in that formalism there's a
very simple idea here which is that you
generally need your network to have a
critical branching ratio somewhere near
one why is that it's fairly
straightforward if it's less than one
spikes died out over time you're
guaranteed great this is on average
right locally it can be more or less
than one on average if it's less than
one you're guaranteed that your network
is going to die out over time it may
take a long time to do that but it will
die out if your branchman ratio is
greater than one you're guaranteed that
your network will blow up over time
again on average expected etc right so
if you think about this then there's
just a simple idea that almost like has
to be true it has to be the case that
networks framed this way have to be
somewhere near a branching ratio of 1
which is called critical branching so I
don't have time to go into the details
of course you can look at the papers a
little bit more there's more papers on
the website bla bla bla but what we've
done is come up with a really simple
really simple way to get networks to
very generically without with with
somebody mentioned you either get very
quickly into complicated math this is
not complicated math ok this is sort of
biologically I would say plausible kind
of mechanism that will take a network of
any kind of structure and get it to be
somewhere near critical branching the
basic idea okay without going into the
details of what you're seeing on there
the basic idea is something like this
the synapse the synaptic connectivity
see in the brain according to this
theory defines the space of possible
networks that the the system the tissue
the network the the brain can play with
him
okay and what the model does is say I'm
going to take those synapses and I'm
going to enable them or disable them in
a dynamic simple sort of rule-based way
such that I will explore that space of
connectivity within the large potential
space and I'll create basically an
effective connectivity that only
includes the enabled synapses and those
will go to critical branching okay again
I'm skipping a lot but that's the basic
idea okay why you know there's many ways
to do this if you're if you're any
neuroscientist in the audience you know
about synaptic scaling and homeostatic
regulation all sorts of mechanisms this
is kind of a new one
in that at least in the neuroscience
community not new in the physics
community why would we go with this
right why why why am I telling about
this one um again don't have time to
tell you about it today but what you
know this is the story's a little
backwards here but what really got us
into this way of thinking about spiking
networks is that we see these power laws
these scaling laws okay these and here's
three examples again don't have time to
go into it we see these scaling laws all
over the brain and all over behavior I'm
actually a behavioral scientist I
started with behavior and worked my way
down to the spikes here to sort of
figure out that the results that we were
seeing in intelligent behaviors showing
these kinds of variations that didn't
make any sense to us um it turns out
that critical branching allows you to
understand these behaviors understand
these phenomena understand these power
laws okay um now more to the point of
you know AGI is that what we what we and
this is basically really just kind of
based off the birch sugar naturally your
paper that I mentioned earlier when I
sort of introduced reservoir computing
when you have a network that is critical
branching when it sort of has this kind
of balance it also maximizes its memory
and computational capacity when you sort
of analyze it as a reservoir computing
device so again of time but the basic
idea is you know remember I said how you
sort of send inputs to the network and
they perturb the dynamic and you can
test whether that dynamic has a memory
by let's say for example you send bit
like patterns into the network and then
you try to perform a nonlinear function
those on those temporal bit patterns so
for example XOR and you can do perform
an XOR function over time such that you
know n bits back or you know n and n
minus 1 perform the XOR function given
the current pattern and that will tell
you something about the memory of the
dynamic what this graph is showing is
that that way of thinking about memory
and computation is maximized at least in
this case when your critical branching
and falls off to sub and super critical
ok just to show you if I have enough
time that this can actually I'm not
going to spend too much time on this
let's see if it was working just to show
you that this actually kind of does
something semi interesting um what we
did was we took one of these networks we
hooked it up to a webcam and we
basically then used a second kind of
very simple heavy an algorithm that
would learn to basically classify based
on these spike patterns that you see
classify objects that we put in front of
it ok
and in this case we have a lock and keys
and I'm not sure if we're gonna get to
it but what's gonna happen here over
time is that you know sort of right
before your eyes this is sort of in real
time what you see is that based on those
spiking input patterns on the right
you saw spikes start to sort of come
online that was basically the algorithm
sort of finding a network in that space
that would more or less be critical
branching and then what you see with the
red and the blue there is that this sort
of second step of the process and says
ok once you've got yourself to a good
reservoir to a good dynamic now let's
see if you can start to tell the
difference between a lock and a key this
pre Oaks are open-ended you know is
somewhat contrived kind of situation and
you can kind of see those red and the
blue bars on the my right I guess um is
that basically it does pretty quickly
starts to learn the difference between
locks and keys in general without having
to worry about translation invariance
and all those kinds of things and I
think at one point this is Brian did
this work I think at one point he
switches the lock and switches the keys
and it kind of generalizes without a
problem it's a toy problem ok this is
only it all it knows is locks and keys
but it just shows it's sort of an
existence perfect
can do something interesting with this
kind of model myself okay so conclusions
so neuronal principles I think are
useful useful level I mean all these
levels are probably useful to try to
connect neuroscience with AGI but I
would like to argue that this is a
particularly useful level trigger
branching is an adaptive principle that
leads to self tuning spiking neural
networks and as a general purpose
computing reservoir it may be useful for
AGI Thanks okay I'm not going to attempt
to defend a claim quite as general as
the one on the title I'm afraid because
I've only got ten minutes and instead
I'm going to I'm going to argue for for
this this particular claim which is that
general intelligence and consciousness
share a common foundation at least in
the biological case and at the end I'll
try and hint it how I can be fed up into
the much larger claim that syn that
that's in the title and the essence of
the argument is that modular small world
networks with a certain structure
support they wrote they provide a common
foundation for first of all for
providing a large repertoire of meta
stable coalition's in the brain which in
turn provides support for flexible
cognition and at the same time the same
kinds of network structures provide
support for a global Llorona workspace
which according to certain theories
according to global workspace theory is
the foundation for for consciousness so
I'll start off by giving a quick
introduction to global workspace theory
so global workspace theory is one of the
leading contenders for for a for a
scientific theory of consciousness and
it's based on a particular type of
architecture and the particular type of
architecture involves having a large
collection of parallel specialists
processes
and global workspace and the idea is
that these this collection of parallel
specialists processes cooperate and
compete for access to the global
workspace and then the coalition of
processes that wins this competition
then gets to broadcast out or influence
the whole cohort of of parallel
processes and then this this this sort
of alternation between competition and
broadcast then carries on in that that
kind of way and then within the context
of that kind of architecture then global
workspace theory makes a couple of
empirical claims and that's the really
important bit but the the essence of the
of the architecture really is that it
harnesses the power of massively
parallel computation and the global work
space itself exhibits a serial
procession of states but each state to
state transition is the result of
massively many individual computations
but this the specific claims of global
workspace theory are threefold really
first of all that the human brain in
some sense instantiates this kind of
global works based architecture and then
then these two important claims the
information processing that occurs is
that is localized and occurs just within
the parallel specialists is non
conscious and only information that is
broadcast is consciously processed so
that's the essence of the global works
based theory and there's a good deal of
empirical evidence has accrued over the
years for this theory which dates back
to 1988 when Burnet bars first published
his book but now there's there's there's
growing empirical theory and of course I
can put in lots of slides about the
empirical evidence for the theory but of
course there isn't time to do that so
but we can talk about it a little later
but the critical thing I do want to talk
about is what is this this so the vital
part of this is to show how the human
brain might instantiate this
kind of architecture so the question
there is what really could potentially
correspond to a global a global neuronal
workspace and according to the to the
ideas that are being pursued by quite a
number of people including for example
Stannis Lester hen and his colleagues
and myself the the the global neuronal
workspace is essentially an in
communications a communications
infrastructure that's located in in the
white matter and the white matter the
neural white matter is the collection of
long-range fibers that joins together
the the different regions of the of the
gray matter and we can study it's it's a
very hot topic in neuroscience to study
the connectivity of the brain through
studying the white matter and here we
see a diffusion tensor results of some
diffusion tensor imaging or on the white
matter and you can see how it's possible
using DTI to extract out all of these
white matter tracts and having extracted
those kinds of tracks using using DTI
techniques you can then you can turn
this kind of data you can turn it into
this kind of data which is essentially a
network comprising nodes and edges and
you can then apply the mathematics of
graph theory to understand the resulting
network and it turns out that when you
look at for example the human brain that
certain particular network motifs or
network characteristics appear so what
we find is that we find that the network
that you get has small world properties
it's modular and it has hub nodes and
and a particular connective core of hub
nodes which you see in the middle and
this was alluded to I think in also in
Randall's dot right at the beginning
this kind of work that has also been
done with the with a macaque so this is
what you see this kind of this kind of
set of features so it's a modular small
hierarchically modular actually
hierarchically modular small world
network with a collection of hub nodes
of
Ector hubs that are the nose that join
together the different modules and you
have a core of these hub nodes which
which joins everything together so so
this is a more abstract representation
of the same thing so this is what we
have a modular small network with these
connector hubs and you can isolate from
this you can isolate this this
connective core which you see on the
right here and according to the kind of
theory which which I advocate you can
you can identify this connective core
with the global neuronal workspace or at
least this connective core of the human
brain is a good very good candidate for
the locus of a global neuronal workspace
and okay so here's a couple of important
sort of messages from that so the idea
is that information and influence funnel
in - and fan out from this connective
core and the connective core acts as a
limited bandwidth processing bottleneck
which allows for serial mental
operations so you get this serial from
parallel but more importantly for the
context of the present talk it also
promotes cognitive integration so that
so that the animal can marshal a
coherent response to the ongoing
situation from the totality of the
resources of its brain thanks to this
combination of broadcast out of
information and funneling in of
information into this connective core
okay so that's so remember that I'm
trying to defend these two sort of Forks
of this of this claim so so I've given
you very very quick argument that this
kind of network supports consciousness
of course this is a massive claim and
how can I possibly five minutes for that
one but okay there's a whole you know an
awful lot of other material on this okay
now the second thing I want to talk
about now it's flexible cognition so
that's the lower part of this - this is
sort of the the lower tine this fork
that I want to defend and ok so so
for a cognitively well-endowed animal
confronts a space of of affordances in
its environment that's combinatorially
structured and open-ended and the animal
can explore you cognitively well-endowed
animal can explore this space of
affordances either online or offline by
offline I mean through through
imagination if you like or through
mental rehearsal but to create the
critical thing is that in order to open
up new vistas of affordance in this
open-ended space then then the animal
requires a degree of cognitive
integration which will enable it to
combine previously on related regions of
expertise so essentially the the
essential insight there is that you want
arbitrary combinations of brain
processes to be able to come together to
deal with what's potentially in a new
situation so it might be that you need
to to form some completely novel
collection of sensory and motor and
memory processes taken from different
areas of expertise if you want to deal
with a situation that you've never seen
before so the real question is how is
that achievable within the brain how
does the brain do that so yes so if so
if the constitution of a process
coalition a coalition of brain processes
if it's always just if you always just
get tried and tested coalitions then the
animal is only going to be capable of
stereotypical responses and if it sticks
to stereotypical responses then it's
going to be blind to portions of that
reform space it's not going to be
cognitively well endowed it's not going
to be able to explore this open-ended
combinatorially structured space of
affordances so so that so the real
question is how is combinatorial
open-ended coalition formation achieved
in the in the biological brain and my
argument is of course that the same kind
of foundation the same kind of founded
connective foundation is what underlies
that so it's gonna just check my time II
know I've run out of time according to
this Oh God
right two or three more minutes okay so
according to Pascal fries and his
communication through coherence
hypothesis then what glues together
different brain processes that might be
distributed around the brain is
synchronous oscillation so so a
collection of brain processes or
collection of populations of neurons
that are awesome at oscillating in
synchrony even though they're
distributed around the brain are able to
communicate and interact with each other
there are kind of computer models that
I've been working with have shown that
modular small world networks the same
kind of networks that we see in the in
the brain can support a large repertoire
of metastable coalition's of interacting
synchronous populations of oscillators
so it's essentially showing that the the
this kind of property and this this
little graph that you see here actually
shows eight populations of oscillators
and it shows how they come in and out of
synchrony with each other and you can
see there's a large repertoire of
coalition so when so so when the high
numbers mean large synchrony so when you
get several lines at the top then that
means you've got those those populations
of oscillators are all working as a
coalition basically so you've got lots
of different coalition's of coming and
going in this metastable way and it's
been recently shown by cabral and deco
and others that resting state fMRI data
exhibits exactly these dynamical
properties and and it's also the case
that the default mode network which is
of course one of the most prominent
network that you see in resting state
fMRI data coincides with the connective
core of the human brain that i pointed
out earlier on so all of this is very is
very suggestive okay so that's been a
quick whirlwind tour of those two those
two sort of tines of the fork that the
same kind of connective infrastructure
supports a global neuronal workspace
which according to global workspace
theories what you need to be able to
draw a conscious unconscious distinction
in the processing in the human brain and
also supports the formation of
open-ended arbitrary coalition's of
brain processes
which is what you need for flexible
cognition so so that's that's the
original claim and just just sort of ten
seconds on how would we bolster this
well to them to the stronger claimants
in the title that's obviously would that
requires you know at least another ten
minutes but so so that would makes is a
matter of making some of these arrows
point the other way but I think I guess
that in a nutshell I believe that the
very same constraints apply even when
you vary the substrate although of
course you're varying the substrate
means that you're that that your
connective infrastructure that you're
talking about there is going to be
between massively parallel processes of
a different sort they're not going to be
necessarily spiking neurons they could
be other things but I think the same
basic constraints applying so what
really was a whirlwind - if you want to
read more about it it's I've summarized
what's in chapters four and five of my
current book so thank you and of course
we use the same approach where those
asking questions they come up to the
front here and we can use some of these
microphones here or at least one of them
my question was for Murray I was just
wondering is there any evidence that the
small world with the hub pattern you
have small worlds connected by a hub is
there any evidence that that is
recursive so that in what you presented
the small world might itself have
collection of small worlds that are that
have its own individual hub local hub I
guess yeah sure in fact the concept of a
hub node can be subdivided into
so-called provincial hubs and and
connector hubs and so I was
concentrating on the connector hubs but
you can look at modules and subdivide
them hierarchically again you find that
within the human brain connectome for
example the the high level
modules get subdivided into lower
smaller modules which have their own
connector hubs between them which if
you're looking at the top level you
think of as provincial hubs so it does
have that kind of kind of recursive
structure well this is a comment which
arose on from the presentation on
embodiment for which thank you but it's
to anybody interested to respond it
seems to me there's an aspect of
embodiment that tends to go unremarked
unnoticed which is shared between many
organisms with very different bodies
elephants gorillas birds humans chickens
namely were embedded in a 3d space with
time and there are other things in the
same environment
some of them inert like fences and doors
and nuts and branches and leaves and
others active like predators prey and
whatever and I suspect that there's a
huge amount that biological evolution
had to do to enable all of those species
to cope with the problems of being in
such an environment and that is it may
well be that there are common solutions
so if in an elephant has to push down a
tree obviously it's got a trunk instead
of hands and legs but nevertheless in
one push a tree down has got to bring
two surfaces into contact with force
applied in the direction and so on and
things of that sort if you want to grasp
something and you've got either jaws or
fingers or whatever and it seems that
there's an awful lot of that kind of
stuff that does not depend in the
details of the morphology of the
individual but it can do in very
specific cases but if you can abstract
away from that you can do a lot more you
can understand what somebody else is
doing
you can see what your kids are about to
do that may not work and then you were
then didn't want to help them you can
see what a predator might be what you do
to your kids etc so I suspect that
there's a vast amount of competence in
humans and other animals that doesn't
depend on the specific details of the
body morphology although there's another
whole lot of stuff that does for
real-time interaction running jumping
and so on okay well I think you're
probably right in a sense there's
another aspect to this by the way and
instead of just focusing on okay why do
these animals all seem to have the same
types of brain regions and does this
have something to do with doing the same
tasks there's also this aspect of
actually regarding the environment
around you as a computational resource
so this is something I try to bring up
at at a previous talk which is that we
don't have to do all the work in our
heads if we're trying to chase a prey we
don't have to compute its entire
trajectory and figure out where we can
catch it because we constantly update
what we're doing we have recurrent
activity going on there we've got a
feedback from the environment to us so
the entire universe is helping us
compute all sorts of stuff and that's
true we're all living in the same
universe so if you've got an AGI that
you're training in an entirely different
universe let's say it's only dealing
with stock market data or it's it's only
dealing with the virtual world then you
have a different kind of feedback and so
you're going to perhaps end up with
different kinds of computational
structures so you may indeed have to
look at those kinds of embodiment
questions I guess
okay yeah a question for Murray the
global workspace what what if any is
their relationship to short-term memory
and if so the limitation or human
limitation of five to seven concepts
that we can can handle yeah I think
actually the the global global workspace
is certainly not the same thing as as
working memory there's somewhat
different different concepts so I don't
think they're necessarily has to be you
know a relationship there I mean here's
an example of something that
distinguishes the two things that that
we can hold things in working memory
without actually being being conscious
of them or being in working memory all
the time so I might for example I have
some idea of who's sitting to my left
here which is obviously held in working
memory is a very short-term thing
it's Andrew sitting on my left I don't
have to look back there but I haven't
been consciously rehearsing that fact
all of the time so so I see them as
different different things although it
may be that that you require there's
there's good evidence the consciousness
is required to access working memory so
I had probably had to be consciously
aware of Andrew at one point to know
that I left for that information to go
into working memory so there's a
relationship but I think they're
different things and actually I have
noticed that in literature you do quite
often find people who confuse or
conflate those concepts rather too much
perhaps because of that phrase workspace
and working memory are two similar but
but to my mind and to burn a bernie bars
Minds they're related bit different of
course while you're correct that working
memory and consciousness aren't the same
thing that doesn't necessarily mean that
for example some of the theories that
you just presented about what's behind
to the basically global workspace that
they are necessarily correct so so it
could be that let's say that there is an
oscillatory model for working memory
which requires these oscillations and
the binding between areas in oscillatory
activity that that is just purely a
phenomenon of working memory and that
this is not about consciousness it might
be I'm not saying that it is but I had
it I had to sort of related question to
you because you mentioned that the so
there was this important issue of
getting unity from this whole multiple
areas and everything and there was also
the matter of going from parallel to
serial and now we think of some animals
as being more conscious than other
animals do you see any relationship
between that and which animals may not
require serial processing as much or
unity as much yeah that's a great
question I I guess that I think that
there might be some sense in which the
the in which the degree of concentration
into some kind of central connective
core is going to be greater you know
more cognitively sophisticated animal
such as such as a human being so it's as
if there's there are even more resources
that can be funneled into a small small
kind of connective core in in the case
of say in the case of the human being
than in a rat say so does that sort of
answer the question and the same and of
course it's what passes through this
this this sort of bottleneck that is the
cereal the cereal stuff so you know in a
way maybe maybe in the more cognitively
sophisticated animal you might you might
Marshall even more resources to produce
what's what's going through that
bottleneck in cereal so so you get
cereal out of even more parallel as it
were I think this issue of animals that
have more consciousness capability I
think what another way of looking at it
is that if there are you have a some
experience then some columns and your
cortex are going to be active and that's
the information you've derived directly
from the current situation now the
intelligence means that you can get more
information than just from what you've
got right there and I think that works
at what you could do then is that how
picking the information you might say
well let's find some other columns that
have often been active at the same time
as the ones that are currently active or
let's find some columns have recently
been active at the same time as or
columns that changed in the past at the
same time and you can therefore you can
drive a kind of halo of extra
information that you can bring to bear
to determine the behavior sort of draw
on your all your past and I think one of
the differences between different
species may be the the size of the halo
that they can pull in and there was how
much information derived from the past
can be incorporated into your response
in the current situation I'm confused by
the critical branching concept I which
it seemed like it was saying that the
number of stimulations coming in at the
bottom is pretty much maintained through
the middle and up to the top I I would
have guessed that the number of
activations would die down so that you
you you work from a hundred down to ten
up to one so that you instead of having
all the information coming into your
visual field for instance and then
having a hundred million pixels that I
have to take care of I've only got one
or two concepts I and one of the
concepts there was that well if you have
the dial that goes all the down less
than one then it's it's obviously going
to end up going all the way down to zero
but that's only on a very simple
mathematical model if you have a model
that I it goes less but you incorporate
lateral inhibition then maybe I can go
less but at least one I and so could you
please speak to especially why would you
want to maintain the same number of
activations from layer to layer please
sure so the the original idea from John
Biggs and Demark lens was about
maximizing information transmission
across
the brain so let's start with that basic
idea that if you need to get a signal
from point A to point B and if those
points are sufficiently far from each
other if you are not in this state
you'll have one of two problems either
you won't get there or you'll be you'll
get interference from over activity and
very loosely and and and there's ways to
sort of play that out mathematically now
so you just mentioned this idea of like
there's another intuitive sense in which
you might imagine uh sort of a funneling
down of information from sensory input
to you know higher levels in the
hierarchy right um you know if you look
for example at Giulio Tononi 'he's work
on integration and segregation of these
sort of motifs or pathways in the brain
there's oh there is that kind of
funneling but there's also the reverse I
mean and if you look you know the brain
appears to be doing both of the
funneling and expanding and going back
and forth between the two so in that
light you might imagine that what
critical branching again on the grand
average says that those those sort of
complementary forces need to be balanced
out so is the expending only for the
activation or is expending for
perception as well well okay so in this
case we're now it is fairly abstract and
we're just talking about spikes period
end of story where the spikes are doing
are the currency with which perception
and you know everything's sort of
happening via these spikes yeah actually
the expanding and the sort of funneling
when you talk about it as fan out and
fan in it happens even in areas where
you're not talking directly about any
kind of sensory input or motor output
let's say in the hippocampal system for
example you have some regions there
where you get got a sort of a fan in so
you're really funneling things together
and then afterwards when you get to the
end of the system it fans out again and
in that case it's probably just because
you're trying to derive information from
many locations and start using them
together and then afterwards when you've
done whatever you're going to do in the
hippocampus and I'm not going to go into
theories about what it is that it does
though they're really interesting is
that at the end well you want to put it
somewhere you're going to go and it
that information and spread it out into
areas we're going to need it or make
connections with other areas where you
want to make a connection with what
you've just processed so there are many
reasons why you might want to do both
things in different areas of the brain
thank you hello
so my question to the speakers is
regarding the level of abstraction of
their models and why they think the
level of abstraction that they have
reached whether it be interested in
single neurons the hippocampus whole
body movements because they're
interested in the full dynamics of
embodiment and why it's the right one
and because I sort of see a I guess a
reflection of any other substrate
whether it be the logical people doing
AI in the past sort of thing and they
still take into account things like
whether or not it's an embodied AI
perspective or whether or not you know
they're looking at a specific domain in
that so I don't know I think I'm just
looking for a reaction from their
speakers on that point okay I think that
I can be a different example for the
moment or two examples if you want to
understand an electronic system you have
to think about it on the very high level
of this of the kind of features then you
have to think about it maybe on a more
detailed level which is the the kind of
major modules just to talk about the
hardware from oh just a major modules
you talk on another level about the the
printed circuit boards and then you talk
about another level on the integrated
circuits then you could and a
transistors and then eventually you're
going to into gates and so forth and I
think that the key thing is that you
have to have a hierarchy of descriptions
when you can so that you can precisely
map between levels and the higher levels
are a little bit approximate but what
you've got as you go down you get you
can get more and more precise and you
can't you and nobody is able to think
about every transistor in the system at
the same time and follow how a feature
is being performed and that's that that
problem is universal it's true in the
sciences you don't you don't understand
continental drift by following every
electron on the quantum mechanical level
you have hierarchies of description now
approach is very much to create an
ordered hierarchy and in fact I
obviously is not time to go into this
into a presentation but using the
information models that I was discussing
the the recommendation and the and the
condition definition you can actually
describe a high-level phenomenon like
episodic memory then you can drop down
to major anatomical structures of the
hippocampus and so forth then you can
drop down to more detail stretches like
cortical columns then you can drop down
to what pyramidal neurons are doing
within a column and then you can drop
down to the integration of the synaptic
signals within the hip within a
pyramidal neuron and then you can go
down to what the that the various
chemicals when you access genetic
information and that the signals that
are going to cause that and at each
level you can actually use the the same
paradigms the information processes to
describe a very slight piece at the high
level at the detail level but so you can
actually map all the way up and so now
as I said I can't I can't cover that in
a short tour but basically you could I
could look at my book all the other
papers and I believe I've created a
consistent hierarchy of descriptions all
the way from the psychological down to
the detail physiological so in your
example though just to get into there is
it the case that one of those particular
levels is more relevant to
implementation or is that you know you
must have a more somehow in a particular
physical embodiment
well in implementation I always talking
about the brain and in that case now in
terms of implementing a complex system
in reality you you probably do at most
individuals most engineers design a
system thinking about one particular
level because they can be fairly common
all the other levels are being thought
about by somebody else and they can have
a an approximate model for what's going
on at the other levels and it can break
if you try to design a system and try to
do at a high level and don't take
account of what transistors are actually
capable of then your design won't work
so you have a mental model of what's
going on down below but as you as you go
through your design maybe you'll try
that you build a bit more more
and then you suddenly discover on my
design doesn't work at that level and so
I've got to revise the higher level
design in order to get the other two in
order to be able to make it compatible
with the existing technology to in the
in the cliche term so I certainly
believe in multiple levels of
abstraction all the way up to the you
know very high level principles to
understand the nature of cognition which
is where we want to be and clear
mappings between them but on the other
hand I do hope that there is a level
below which I need not go but I don't
know yet what that level is I sir I hope
that is that we don't have to worry too
much about the electrochemistry of
synaptic transmission for example and
glial cells man if they if they are
important we you know we're really in
trouble but but you know yes so I hope
that there is a certain lower ceiling a
floor floor yeah you're not really sure
your question is really relevant to me
because I didn't present a model right I
just argued that when you look at the
mechanics of that you see in
neuroscience it's important to remember
that they exist was in a body and that
they might be influenced with the body
as to which level of abstraction to look
at philosophically I agree with what
Marie just said I hope that there is a
lower ceiling and I hope it's not too
far low
personally if it's a cortical column
I'll be happy but I don't know sorry
very I don't think it can be a cortical
column because the avian brain is not
organized into columns so so it can't be
you know we've got it's got to be the
case that the columns don't matter so
I'll give you just a quick pragmatic
answer to that question that's really
just historical for for me is we found
these scaling laws that I mentioned
briefly again don't have too much time
to go into but they were happening at
all sorts of levels everywhere from ion
channels up to group behavior and
everything in between so now the
question
that gives us a way to think about
pervasive scaling laws these scam law is
all over the place finally how did I get
two spikes the simple answer was I I
said okay we need a system that can get
us to criticality how what's the easiest
way to do that and it just turned out
that spikes were a lot easier to work
with it was a total pragmatic answer
spikes were just really easy to come up
with a mechanism that gave me
criticality no it's nothing more than
that really so I'm not like a spike guy
I'm actually a behavioural guy but it
just it led me to the spikes well just
to add my little bit even though I also
didn't present a specific model yeah I I
kind of I agree with Murray of course
and I agree with you as well in the
sense that if I ask neuroscientists what
do you think is the level that we have
to go to most of them will say something
like well it's probably spikes maybe a
little bit below that but we don't have
to go all the way down and that may be
true although it depends on what you're
trying to do and just to give my
perspective from what I'm known for
which is you know the the emulation part
whole brain emulation in this stuff so
what would you need to get to down to
that well I had an interesting
discussion with someone recently who
said that well you obviously can't
really do it because there is no way
that you can get a system to behave
exactly like any other system if you're
using different materials and that's
true because you know the material
itself like the atoms the electrons
whatever is there they're they're
performing the best that they can for
what they do because that's what they
are for you know this is the thing they
do best is their own behavior it's just
that it's it's a kind of a straw man
because you're not really interested in
all of that it's like if you have a PC
and you want to emulate it in a Mac
you're not really interested in how your
PC normally warms up the environment
because it's circuit board is laid out
in a certain way and all that kind of
stuff you're interested in does the
program run the same way on that
emulator as it does on your PC so there
is a lowest level there's a floor
somewhere we just have to figure out
what it is so we've seen that the brain
has topologically small world property
which if I understand it properly is
that the expected path link is is
logarithmic in the number of nodes that
you're looking at and at some level of
abstraction they look a lot like
hierarchies which are our favorite small
world networks as engineers
with these provincial hubs and connector
hubs and so forth but then when you try
to find the root of the hierarchy it
seems to get a little bit confusing and
so I'm wondering if you think there
might be some other class of small world
networks that's disjoint from the
subclass we call hierarchies that is
particularly important for intelligence
okay that's quite a that's quite a
difficult question I'm certainly the
class of small world networks where you
have high clustering coefficient and low
mean path lengths in a sparse network is
quite large and encompasses lots of
networks that are not modular I mean for
example the classic what Strogatz
construction is not a modular network
and I do tend to think that there's
something special about modular small
world networks especially hierarchically
modular small world networks apart from
the fact that empirically that's what we
find when we look at the brain but it
makes some kind of sense that the
modules match up to some kind of
functional specialization and so so that
makes a certain sort of sense I think
that my the you also don't have to have
hub nodes when in a in a modular network
so you can have a modular network with
hub hub nodes or without hub nodes and I
think that the existence of hub nodes is
quite important because that's that's
what gives you this core this connective
core in the middle which is what this is
where I claim everything funnels into
and fans out from so you might not have
those those hub nodes so I'm not quite
sure if that's that's not really an
answer to your question in the sense
that you were asking for something to
rhyme I'm just reiterating what I think
is important so I think that connection
of characteristics are the ones that
there are important I think the related
point here is that in an electronic
system we have modules and the driving
for it was the first definition of a
module you tend to have a lot more
information exchange within the module
than between modules and one of the main
reasons we do that is because if you
don't then if you change one module
you'll have side-effects spreading in an
exponential fashion all over the place
now
I think in fact there's a similar
pressure on the brain that if you have a
network in the brain or a module in the
brain some some cluster of resources
then the more that's connected to other
clusters if the brain has to learn
something the more you're liable to get
undesirable side-effects proper
propagating around so I think there's a
very strong selection pressure on the
brain in favor of trying to make
different pieces as isolated from each
other as possible in information terms
in terms of the brain is a pathway to
AGI at the Dartmouth brain engineering
lab they're taking clusters of neurons
and deriving calling them circuits and
driving algorithms that more or less
represent their function and Rick Ranger
dr. Granger's has made some sensory rich
robots with that he's developing
prosthetic limbs he's looking for ways
to take those algorithms create
synthetic things to treat brain diseases
can any of you comment on that and that
is that that as a as a road or as a
pathway to to AGI starting starting from
the brain thanks yeah I think that the
work that Rick Granger is doing is great
and I know that there's some very
similar and interesting work also out of
Steve Potter's lab and Kevin Warwick so
there are numerous people who are trying
to use somewhat similar approaches to
actually use biological neurons culture
neurons neurons that they put sometimes
within specific pathways if they want to
make sure they grow in a certain way
just use them in circuitry and there's
really nothing wrong with that but then
of course the question is why would you
use one particular Hardware over another
if you're trying to do AGI hardware will
you try to choose it for a specific
purpose let's say you want to achieve
low power or you want to achieve a high
level of parallelism or there's some
other particular reason why you're
picking that hardware and using it for
your solution and maybe if you're trying
to build another brain that's just like
our brain that maybe you want to use the
same components but if you're trying to
drive a robot or you're trying
to do something else that an AGI or an
AI would do I'd have to ask is using a
set of cultured cells really the right
way to go it depends I mean maybe it is
okay well okay so it's yeah okay well
okay well that's I mean that's the
approach that you take when you do
computational neuroscience and you're
building models based on that and then
you can drive anything with it yeah sure
I mean it's just a matter of how
abstract or how detail do you make them
so alright I'd still give the same
answer it's I mean you pick whatever
lowest level implementation you think is
the best for your purpose if if the
thing you're trying to do is to
replicate what the brain is doing as
exactly as possible say for example in a
case of brain emulation then I see why
you would do that but if you're trying
to drive a robot or you're trying to
make automated cars then maybe it's not
the right solution it really depends on
the task you're trying to do and and for
a GI artificial general intelligence
well I think that it's I'm trying to
advocate for the idea that it's really
useful to look into neuroscience to
learn about some principles that we can
use to do a GI but that doesn't
necessarily mean that I'm advocating
that we need to do things exactly as
they're done in the brain that you would
have to use the same the same exact
circuitry to achieve something that's
generally intelligent so my feeling is
that we can learn a lot from the
circuitry the way it's built in the
brain but that what the more you
understand the more we're able to
abstract from it the more we're able to
come up with components that are more
efficient for the purposes that we're
striving towards so perhaps at some
stages this is the best thing to do
first and then when you know better what
you want then you can go to something
that's a little more abstract where you
you know hone in on your goal a little
bit more
yeah I think that ah I have a slightly
different perspective that I think that
in fact the brain uses certain
information processes now computers use
information processors that are things
like data access and an instruction
execution and that sits underneath
virtually all of the information
processing technology we use and I
believe the brain doesn't use those in
the basic processes and I also believe
that those processes are the ones that
are appropriate for a very very complex
learning system you can get away with
all sorts of things if you're if you're
not reading with an extremely complex
system but as you get scale up in
complexity I think those are the right
information processes now on the other
hand you can implement those processes
on lots of different kinds of hardware
so it's not that you don't have to use
wetware if you like for your system but
I believe that you do have to find
efficient ways to influence implement
the kind of information processes of the
brain uses and then you can fit them
together in a in a functional
architecture so that you get you get
your intelligence so I just thought I
would ask how do you feel the atmosphere
in the field is towards building general
models versus researching more specific
things like maybe the behavior of a
particular type of cell or particular
neurotransmitter or maybe a specific
area of the brain well I try that one
that so I think that there is a huge
amount of effort in neuroscience on very
tiny amounts of tiny problems if you
like there's a lot of effort in trying
to find for example how genetic
information is transcribed and an in
support of the synaptic weight changes
for example and following thousands of
different chemical paths that are
involved in in in a way change and and
and studying all the properties of the
if you like it's a very intense and very
narrowly focused and I think that the
problem is that in the neurosciences
generally there's a lot of that kind of
effort and there's not a lot of
communication upwards you know the the
the cultural gap between even the people
who do I on channels and chemistry up to
the people who study certain anatomical
structures is very large and there's an
e a huge gap then from those people up
into the psychologist that's over and
you know you do lots of you do fMRI
imaging but on the other hand the
imaging I can't get down to looking at
individual neurons so I think that there
that there's this huge camps that have
very little to do with the other in the
neurosciences so part of that actually
there's a reason for that of course
there's a reason why a lot of people
spend their entire career looking at
just like one of those processing one of
these okay yeah yeah exactly its tenure
it's it's how do you manage to produce a
lot of papers very quickly and get
grants well one of the things that you
do is you concentrate on something
really small that you can keep on
producing data on and keep on saying
something that's just a tiny little bit
more or different than what you said
just before and you know that's that's
the way the system works so that's one
of the reasons why I was trying to point
out that what we also need is we need
you know people to take entrepreneurial
approaches for example or any anything
where it's absolutely necessary that you
become more interdisciplinary that you
at least look at different levels within
the system and that you go beyond that
so yeah part of its it's just the nature
of the system so just a short comment on
this I concur with what everybody's been
saying I think that the neuroscience
seriously lacks a very large theory of
brain function and and people are very
reluctant to work on that kind of thing
for just the kinds of reasons that
roundel just set out I think so maybe we
maybe Randall needs to go to the
neuroscience community and get them to
be interested in in the NGI problem the
natural general intelligence problem
that was a great remark now you just had
this opposition between brain and
computer the computer does it this way
the brain does it that way and to some
extent this might come down to the
question whether the brain is a computer
or the world as a computer so we really
need a body because the world is
something entirely different and so on
and as a computer I think we see a some
it has something that managers
regularity in information it's some very
very general notion according to the
church cheering thesis and traditional
AI has worked on the premise that
basically everything is the computer
like physics does even still to these
days it's a notion that is not
completely shared in all of philosophy
of mind but it's something that has been
a central tenet of artificial
intelligence and the mind as machine
kind of cognitive science and if you are
saying for instance that we really need
a body how do you mean that would you
accept a virtual body - like in a
computer game and if you would accept
that that we have a virtual body in a
computer game we could take this
computer game burn it onto a microchip
and implant it in the brain so it's
completely internal to the mind in some
way if you just have a prosthesis which
is part an integral part of the mind
it's something which a little bit a
little bit more organization to our
mental stage so we can meditate about
this game so to speak would you be
satisfied with that or would you argue
that no we need physical and embodiment
because physics gives you some touch of
mystical reality substance that somehow
enables us to be intelligent ok I'm not
I didn't really say that you absolutely
definitely need a physical body but what
I did say is that when you look at human
at the human mind and human cognition we
do have a physical body and we do exist
in a physical world not in a simulated
world and that does affect the way we
the incidental that I still have this
body
okay but in the general case I do think
that embodiment affects cognition right
your body determines sorry to you right
and certainly I guess you can make the
point that if you're building an
artificial general intelligence machine
yeah that might well be possible without
being in a physical world it's just that
we humans are in a physical world we
probably want to interact with these
artificially intelligent machines so I
don't know if you have an artificial
intelligent machine that exists
completely outside the physical world
I'm not sure we would even perceive it
as intelligent in a true sense or that
we could really interact with it in a
complete sense so I think it will need a
physical instance at least to be able to
interact with humans in a nice
intelligent social way you're not going
to agree with that are you I had a have
had interesting intelligent
conversations over the Internet yes
without being physically interacting
with people I do believe that this is
fundamentally possible you don't - sure
I am a human I am a primate basically
and my primate mind has been evolved to
control the movement of my body I
completely agree with that
but I'm not talking about this I'm
talking about artificial general
intelligence so I want I want to know an
argument a philosophical argument not a
practical evolutionary one because this
only applies to me I want to have one
which helps me to structure my work I
want to know if I need to build robots
or if I have can have a chance to build
something that works over the Internet
it would be great if if the speakers
there if you guys had microphones
because it's very hard for people here
to hear what you're saying you could
just come up to the line maybe I mean it
would help we have a couple of minutes
left so if you guys finish the
conversation and then we have one more
question then that's probably the end of
the panel okay so basically I I feel
like we converged on there's two
different ways to so do you need a body
for intelligence in his answer I think
is no because someone could set you up
in a little room with an energy box and
lots of energy and then you could
develop an AGI without a body and
survive as long until your energy ran
out and that's that's the AGI yes Andy
okay and so we go back to his question
in that case which is in this little
room is it possible to become
intelligent given that you have lots of
energy and no body so there's there's
two answers to that if you want to build
a real human then indeed it's it's very
useful to build an embodied system but
as long as you're just going for a
general intelligence that's not it it's
useful but it's not necessary I'll take
a different crack at that just because
it's something I've been wanting to sort
of mention in this group and now's a
good time to mention it so embodiment
environment grounds us right it's sort
of the ground truth what's it's what
basically allows us to coordinate and
communicate amongst each others so I'm
just something out there that I don't
think this communities may be
particularly interested in which is that
you know part of what makes us
intelligence is that we're social
creatures right it's not I I don't I you
know if you look at all of our sort of
accomplishments they're our greatest
accomplishments are
societies and cultures and so what makes
us smart is our ability to connect with
each other right and I think embodiment
is absolutely essential
now you can be embodied in different
ways it doesn't have to be this
particular body but you need a grounding
you need a common ground so that you can
have that kind of coordination that
makes individual brains smart it might
be what happens if you only have signals
going back and forth right well again
it's sort of like it's Mona Lisa
overdrive it's the meaning problems like
what does that signal refer to all right
this is a classic sort of philosophical
I'm I don't think I have the answer to
the problem but it's yeah I watch TV but
but how do I know that my signals
connect with your signals without that
embodiment in an environment without
that grounding you know I know how to
map them see I'm saying you'd have to
program it properly but uh and you'd
have to have it's got to watch lots of
YouTube probably you'll need a grounding
and I think that's what gives you that's
so necessary but not not necessary the
last question please I have an easier
question does this reservoir computing
idea naturally do Occam's razor and if
not can you make it do that so find the
simplest solution to some given function
is that richer simpler ideas I don't
know I I think that's a hard question I
would have to really get I'm just trying
to think how would I test that how would
I sort of make that concrete</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>