<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Radioactive astronauts: images worth a thousand experiments. | Coder Coacher - Coaching Coders</title><meta content="Radioactive astronauts: images worth a thousand experiments. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Radioactive astronauts: images worth a thousand experiments.</b></h2><h5 class="post__date">2008-05-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wGdjvGJQgDk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Thank You Noel for inviting me today
it's a pleasure to we had google and
actually see the campus first time for
me and today that the talk is going to
be about there's really two fold in the
talk i'm going to try to bring up the
technology and the type of thing we've
been involved with that links well with
palimpsest and actually Google's
technology and at the end i will try to
link it back to actually the type of
work we've been doing and show you where
those needs could play a row but they
don't play a role yet but and i will
show you a bit about how we do those
things so before i go into the biology
and about the the projects of the nasa
project i'm going to talk about the
technology a little bit and the first
question is in the early 80s people
started realizing for the longest time
people have said that the human eye is
the best the best pattern recognition no
tool that exists and it's true we are
extremely good at recognizing features
because we grow in an environment that
has features so we have grown to
recognize them a computer is very bad at
this it's getting better but they're not
as sophisticated as we are and they
aren't very good at quantifying things
in a very and in a very predictable
manner so you know if you go to the
doctor and let's say you you have to go
get above sea esta pathologist will get
something like this it's an image and
you see those nuclei here which is a you
know shown in blue orchids should be
blue but it's a it's a dark standing
here and the nuclei looking at this
pattern pathologist will decide what
type of disease you may have do you have
a normal t-shirt you have an abnormal
tissue and they're very good at this but
now the one thing they're not very good
at even though the expert in recognizing
pattern is to quantify and absorb a lot
of information at one time and that's
where computer becomes more powerful so
to illustrate this that was done in the
80s I'm just replicating what has been
done in the past early eighties someone
challenged a lot of people are saying
can you recognize the different patterns
so we regenerated those things here in
those images I created five different
circle with five different diameters so
it's five units and we mix them in a
random manner and the question is can
you with your eyes decide if those four
populations
are the same populations or in fact they
are maybe there are some of them the
same and some of them are different and
i would say putting that to anyone you
know when people have been tested on
this they it's really hard to tell
anything and in fact in these images
there is two groups so a and c are the
same population and they basically are
you know the majority of those circles
that you have the median sized circle
whereas the B&amp;amp;D actually have two
populations in there not something
really obvious by the eye but it's
really there and this is what we're
saying about quantifying biological
image I think this is the type of data
that starting any convincing barges that
they should go after quantitative to on
design involving a lot of money and the
and development trying to quantify those
images so our work we're not imaging
species will do love imaging but our
work will is to quantify data as much as
we can image-based and then integrate
them into some models to actually
predict behavior of human and how they
respond to radiation so fluorescence
microscopy is a growing trend in the US
and actually the world i should say if
you look on google and search
fluorescence microscopy on publication
peer-reviewed publication what you see
is a big jump in the 90s this is when
the first fluorescence microscope became
available or i should say affordable and
there's a big jerm where people start
getting on the on the boat and sign
producing a lot of those images and then
since then it's been going up non-stop
and and the technology is getting better
and faster we're getting we have now
broken the resolution of a microscope it
used to be point 15 mark micron now we
can go below that using 4pi technology
so there's a lot of technology that's
coming up around the corner we're
generating more than a higher resolution
there for a lot more we need a lot more
space and just to give you an idea of
the type of market with dealing with
just in the US and just looking at the
university if you consider this about
2,600 accredited university in the US
and most of them have at least one image
in core facility each imaging capacity
usually served 5,200 people you can
imagine immediately compute is about
half a million to 1 million people that
deal with this type of
every day and that's only in the Academy
it's on ani in the US so this is
something that's growing and it's just
going to get harder and basically what
we start seeing in our lab for instance
is a we getting a bottleneck in terms of
how we deal with the data we we're
trying to not process all the data
because we just have too much and we're
not giving we're not you know giving a
good time on the line and basically
we're not giving the when I extract
extracting what we can from those data
because we just saturated so the outline
of the talk is the imaging challenges
we've been facing over the past five
years at the NASA projects so NASA
edited five universities I should say
five national lab in the US and I'll be
now is one of them so that we were given
a lot of money to actually study defect
original human we do one component of
the project and this five other
universities in the US that does that
and under the nasa project i will talk
about the effect of cosmic creation
astronauts really imaging oriented type
of talk and on the imaging challenges
will go over how we sort and are we
browse through our data right now how we
do segmentation how we deal with
registration and how we deal with panel
recognition and again we're not imaging
species so if your imaging expert you
might think our approach is fairly knife
but we try to being a physicist we we're
really talking to many different group
at the same time and we try to integrate
we do quick imaging approach I give us
fairly quick answer so we can link them
back to the models and I have results
for the for the biology so it's kind of
a weird niche where we are so this is
type of data set we get usually you get
a gallery mode where we can see as much
as you can it's really hard to see the
data but basically all those blue things
are nuclei there are stand for DNA and
the different colors mark different
things such as DNA damage for instance
and on those gallery mode this is one
software called metamorph we can go and
click on anything and then immediately
the annotation of the image pops up so
we know what we're looking at then this
is one way we we have a quick view of
our data then what we have is we use
matlab actress so that we use many
different software in the
process is not something smooth at all
under matlab matlab is a great system to
actually do a lot of prototyping so we
put type all of our work on under mat
lab and what we've been developing is
tool to read different imaging format
because microscopy unfortunately has
different imaging format they all teeth
based but then each company because
we're dealing with five dimensional
images there's XYZ then you have
channels so the channel can be up to 32
channels at this point in microscopy so
you can acquire 32 different colors so
that becomes a dimension then you have
time so those five dimensional images
becomes pretty hard to handle and so
they have created those embedded TIFF
system and so they you know zeiss has
created this DVI and NSM metamorphose
created sdk nikon has created ICS and so
we have to each time we have to go and
and read their special tags and have
them under mat lab so we can parse
because the beauty of reading those
images and reading the information and
images we can start sorting and parsing
through things such as for radiation
biology what we're looking for is that
those we gave to the specimens we want
to know how much it got we want to know
when we stop the specimen was it fixed
so the time it takes after radiation is
an important factor so the longer you
wait the other type of endpoint you're
going to be interested in the type of
level you're looking at so are you
looking at DNA are you looking at DNA
damage some proteins the type of cells
are looking at so all this is usually a
noted in the image at the moment of
acquisition and can be taken out and
then we also also do one thing classic
thing is we always do automatic
segmentation of the nuclide this is the
one object that's always wanted in an
image we want to know where the nuclei
are individual cells so we can then ask
questions for each of those nuclei so
this is done on on a batch mode as well
so nuclear segmentation nuclear
segmentation if you're lucky you get an
image like that it's great nice uniform
amo genius background you all you have
to do is threshold it and you get the
contour it's not very it's hard to see
here now that's a bit harder multiple
nuclei they overlapping with each other
multiple intensity multiple pattern and
so when we tried segment ECB
it's a bit difficult and we don't have a
great working solution nuclear
segmentation is a field that's been done
for I think 30 years so there's many
algorithm and everybody claims they have
the best system so we know in the
business of the nuclear summit you all
we want is actually have something that
is fast enough and that gets us through
the data and so those are different zone
of problems ii overlapping high
intensity so one of the prime is the
background verb for instance variation
of background so in the semi major you
have a background that has a high
intensity versus a low-intensity if you
were to threshold this if you special
low you'll miss some or if you special
hi you well if you threshold how you
miss those guy but if you search on low
you can start picking up stuff here so
we also have within each nucleus
patterns that tend to be punctuated
sometimes and how you deal with this so
the approach is very simple first to go
fast again we subsampled image we always
do nuclear segmentation on a sub
standpoint much because we don't need
that much accuracy for identifying the
objects so it's one a little trick that
we use when we subsample the image we
can then pass it through a classic
filter like Gaussian and median filter
which can kind of like make the system
more modulus then we threshold get a
binary mask and then through iterative
process we can actually find the seeds
of the multiple objects in one mask and
I will tell you a minute how we do that
and finally we use watershed technique
to regrow from the seeds and we get our
full nuclear segmentation interpret it
back to the full size obviously so the
iterative process is very simple like I
said there's many more advanced
technique but that one is actually very
quick and what we do is we just do
multiple to erosion and on a binary mask
until we separate two objects so if you
do on multiple level you can separate
and it's you know I'm not trying to
claim we have the best system here you
can see how it actually didn't do such a
good job we separate that one very well
but we're missing some of those guys and
the reason is really for something like
that you really got to go with a knob
shape based type of algorithm you Thresh
holding and this is not going to cut it
but again this is a very extreme case
and we have ways when we do the prep to
minimize this type of events so we can
grow the cells and stop this
at a moment where they're not touching
each other when they don't grow on each
other so so the batch processing matlab
so what we do with matter then we can
identify the nuclei and we can also
identify spots for instance so in this
case this image you're looking at here
those cells were traversed by cosmic ray
so each track here is a cell is a DNA
track those a DNA damage those little
dots so what you're seeing here is human
cells breast cells thus this is what we
work on breast cells the great model for
radiation because they tend to have
cancer easily with radiation so this is
our mobile human breast cells and what
we see when we put them on are on a beam
you they create those tracks and those
are DNA damages so we generated first we
get those huge gallery and then we do
automatic parsing to know what is what
so that image for instance gotta iron
particle got was one great as to those
and that 30 minutes after radiation then
you can so if I go back and forth you
can then segment the nucleus and I an
axial so you can identify the tracks and
those are label images so you can
identify different spots in the track
and then we can go ahead and do that
over all our data and if we go back to
the prodigious show you the computer
knows that these were for instance is a
50 centigrade that 100 and that one 300
centigrade and then on the fly almost
with matlab we can create a text file
that will come and generate those those
graph and big surprise what you see is
what you expect which is like the higher
the doors the more DNA damage you see it
should follow a linear trend you double
the doors you double the damage you
double the number of damage that's what
you measure perfect the slope itself is
a very interesting factor and that's
what biologists are interested in why is
that slope different and this one
because this one was obtained with a
certain type of radiation the one with a
different type of relation a tradition I
have a different way of inducing breaks
so this is the type of endpoint that the
budget is very interested in having
they're not really so much into all what
we've done but they very interesting
this so how does that link to go I think
here at least as a you know personal
user of Google you know the one tool
that comes to your mind is picasa
because if you stopped because on your
computer what's amazing is it will go
through your computer short
not bears on scientific parsing but I
mean scientific data but still will
parse and classify your data and then
you can grow through it I think it's a
great tool that does not exist in
scientific community all the company's
eyes and Nikon they have not developed
system like that they're not very smart
in terms of browsing through the data
and then in terms of searching through
that it's even more messy if you use one
of those software nikon or zayats
because they don't really plan for this
so i think this is something i would
love to see in panama sites project is a
way to really do a lot of what we're
doing visualizing design in such manner
so against a plug for my own interest
here but linking it to google so in
terms of visualization let me show you
that so again visualization we have to
use a different tool so we juggle with
five or six different software and each
chapter actually is about 20-30 k so we
have only one software usually for the
lab and we have to share the machine
where the software is on because we just
can't afford that many machines with
those software but so metamorph what we
do is which is the nuclear segmentation
so we can do and what I love about
metamorph is the interactive link
between the data and the images so for
instance you can start getting your data
so this is the area of each nucleus in
the segmentation and they are visualized
here so you have a color system where
you can say well I want to look only at
the one about 100 they showing green the
100 are shown yellow I can get to the
last I want to only want to keep those
nuclei that are size between hundred and
250 and here it is and then after I can
get again out of that population I'm
interested to see which nuclei are
fairly Iran so then I go for the shape
factor so I go click here shape factor
and then i say i want to shape factor
that's above point 75 up to one and now
I get the more spherical nuclei this is
just an example of how you go through an
interactive but i think this feature is
really useful because it gives you a
handle in your data very quick and you
can this that interactive mode between
the data and ND images and you can
really tune it and that's where you use
the best of both world use the best of
the human because the human is so good
at asking question that extracting
pattern and the computer is extremely
good at giving it to the person so if
you have that nice
log in the machine on the human it it
becomes very powerful now one thing I
didn't tell you yet is those images
actually three-dimensional images so
there's multiple slices and so if we
zoom on one of those nucleus this is
what actually what it looks like so
again that nucleus got travers by
actually got two tracks well i would say
at least one track here so that was one
damaged we're looking at two different
DNA damage protein so rather than going
out to different ones that's why you
have a yellow color and then that's the
way we visualize 3d images we have the
little cursor that you can move back and
forth and here i basically section the
nucleus about that point so that's the
XY view that's the YZ and that's the XZ
and then I can so that's bit princess
different software again bit plan can do
very cool stuff like I can do a maximum
projection by simply moving those two
lines here if I explain them I can
actually now do a maximum projection on
my XY view so if you go back and forth
you can see how this guy now shows up
here so there was another track he
actually ok so it's a way to visualize
data it's pretty nice and and visit the
data so all the way to deal with those
derailleurs to actually do volume
rendering very murdering makes pretty
images but it's only useful if you can
really play with the system and zoom in
and out so you can do either surfacing
and actually extract those spots using
different color fears and you can make
movies out of that so so that's the same
thing now and so anyway so what's the
volume rendering of this and how you can
visualize some data so the last thing I
want to talk about tools is pattern
recognition and that's something we're
just trying to get into if you see here
those are three different nuclei and
religion tends to induce a change in the
nucleus nuclear structure we don't
really understand it yet well but you
can do it with different things like if
you put salt in the media instead so if
you put the sails on a different so
there's an osmotic reaction and you can
basically under high sole condition you
arctic condense the new cruise it will
lose its water and I will look like that
are under hypertonic solution which is
if you remove the salt in the media the
cells going to start swelling
and is going to look more like this and
that's no more looking nucleus and so we
wanted to see if we could just by simply
looking the signature of intensity see
you difference and actually will be
disappointed to see that only the hyper
tunic tend to stand out if once you have
normalized the intensity which you have
to do you know my eyes for the vines on
the end I mean you're going to see
actually two peaks for those guys for
the opportunity but the I pool and the
normal really you can't separate them
anymore so even though they are
different so clearly this a new project
we're not sure how far we're going to go
with that but obviously we're going to
have to do is that's what we've been
talking about is doing with PC analysis
and using multiple features and only
intensity but also size and shape of the
nucleus would be another feature that
could be used to separate them so anyway
so I wanted to cover all this non we're
going to move to NASA project so I
wanted to give you an overall view of
the of the technology first and so
hopefully this will work so NASA is
interested in the effect of cosmic rays
non-human and the reason is so
interested is that in animation you can
see those solar particle actually there
are protons and hitting the the magnetic
field of the earth and actually what's
interesting is yours actually tiny thing
here what happened is the hearth of that
incredible magnetic field is really weak
but it has a huge range and because of
that we don't see any of those park on
earth so the things you just show you we
don't have them on earth we and so we
have no data whatsoever on the effect of
those particles on human because we
never got hit by them we have a lot of
exposure to photons with you know the
atomic bomb was many photons and
neutrons put nothing on cosmic ray they
don't come here so because of that
beautiful magnetic protection so you can
imagine the mission we're working for
the Mars the mission to Mars and the
mission to Mars they're gonna have to
leave this nice protected area and even
the Astron right now working in orbits
they don't get damaged compared to what
they will get once they get out and go
to Mars they're going to receive a huge
amount of those rays and that proton is
a predominant particle in space but it's
not such it's not the most dangerous
when the most dangerous one is iron and
iron is produced by supernovae and the
supernova proof so much of that that you
see a lot of those particle
eating the the human when they go on the
mission to Mars so we were interested in
studying the effect of iron particles on
human and so we do to get where do you
get a cosmic tradition on earth well you
got to go to an accelerator and not mini
Exeter can produce the type of energy
use in space so we go to Brookhaven
National Lab in New York that's the
alternate synchrotron and basically nASA
has built an extraction beam line which
is shown here and then what we do is
we're going to in the beam so this is
the control system this is a whole key
system with I recognitions that when we
go in the beam we can't get shot I've
been better we go in the cave that's the
cave the beam comes from here those are
our detectors so we put a bunch of
different detectors to quantified in one
of our floor affluence of particle going
through the specimen the specimen is
storing an incubator so you can stay
nice and warm and then you get an image
like this so those sales human cells
again get traversed by tracks and the
first thing we did is we wanted to
actually notify the track so what we did
is initially we develop a technique
where you can roughly drawn an image
very quickly the nuclear you want to
study and say okay the tracks went
through here here and here and then we
find a search and the computer comes
back with a track addiction so the way
we've done that to give you an idea is
the following it's a very simple idea we
do some projection of the specimen so
index in this case the gray matter to
show you if you project it in an angle
that is not along the track you're going
to get a profile that looks like this
you get a few peaks corresponding to
some of those parts but overall you get
a you know kind of a so so proud a
profile now if you hear it right right
on the angle and so I forgot to mention
something our beam is always parallel so
when we expose the specimen all the
particles are going straight and they're
so heavy and so fast their beta is poor
97 which means they very close to the
speed of light and so they take about 12
centimeter to stop so they go through
our specimen without any interruption
they just and if you get travers by then
they were basically Pierce you right
through you won't even you don't you
don't sense anything they is so small
but they are parallels
one thing that's good about a specimen
is we know we're looking for parallel
lines so by doing that when you do some
projection when you hit the right spot
you're going to see the only a few pick
and they're going to be very high pick
and again if you use another angle even
in this case where you have those two
guys you're going to get a pig but the
pig will never compete with the right
track so by doing that all we do is we
do those different projections and keep
the projection that gave us the minimum
number of pigs and the highest peaks and
once you have that you can look at the
center and project them back on the
angles and you have the track so that's
how we generated those guys so using
those tracks we had a great so I'm a
physicist by training so I really wanted
to extract something more interesting in
the data so one question there's a lot
of controversy about those proteins
we're using to recognize those DNA
damage people say they are DNA mean I
managed and not DNA damage the more
complex so one thing we said is like wow
one thing we know for sure is that at
the moment of the damage we know exactly
by the physics what is what should
happen and what should happen is the
following if you get a track here you're
going to get a DNA profile that's the
blue color is the DNA so you see you
know this more DNA here there's less DNA
here and basically what you expect to
see is on average break should happen
where there's more DNA it's a trivial
statement if I take you to the extreme
no DNA no damage you can have a DNA
damage if there's no DNA so an act if
you do the physics it's very simple it's
proportional is directly proportional to
the amount of DNA so knowing that what
we said is that what you expect to see
on each track if I get a DNA profile I
can actually and I'm told here in this
DNA profile they were for damages I can
take them and randomly distribute them
on the track on the profile and if we do
that many times it's a multi-car
approach if you that many times you
throw them randomly following that
profile you should generate an average
DNA damage profile that matches what you
expect from the physics and we did that
using all that tools and we did that we
got those results the blue curve is the
is the distance distribution of those
four sides so if you look at a track
that's different for sy and we're
looking at the distance between each for
sy and within we're generating those
distribution and what we see is the blue
curve is what we measure and now what we
measure if we do the randomization
a Poisson distribution it's the person
is cut here because a microscope hasn't
we losing the resolution here so we
can't get the tell the person because we
don't have infinite resolution that's
fine we still get the personal shape but
we get more like a kind of a Gaussian
type of thing here and the big
difference is the predominant the most
favorable distance between two force I
theoretically should be you know points
point 3 micron and actually measuring 1
point 2 micron so what we're seeing is
that those DNA damage protein that were
using they're not the DNA damage are not
where they should be they have moved and
they're moving a very interesting way
this seems to have excluding each other
you don't see that many clothes by DNA
damage and this is getting worth 35
minutes post-irradiation so that was a
big red flag when I presented this first
in the community they were like no way
it's artifact in imaging and okay so we
had to convince them something was
really going on and so we really said
well we have increase deviation from
randomness and there's an exclusion of
clothes by force I so where are they so
I kept going on this one and NASA I gave
me a green light to keep going on this
one so I went on and I'd say okay can we
can we find out where they are and we
came up again with a again very simple
imaging tool what we did is I said in
the image i can see that the break seems
to be where there's less DNA which is
contrary to achieve this should be where
there's more than able in in fact in the
images visually i would see that so i
said ok we're going to measure it the
way we measure it is this is a cartoon
well this is a real nucleus image but
those little red dots I place them just
to illustrate the point and if you put
those dots in a high DNA density region
versus a load in an estrogen can I
measure it in a quantitative manner and
the way you do that is simply by looking
at the sum of those signal at those
location normalize by the mean of the of
the signal over the whole new cruise and
when you do that when in a bright region
you're above one when you'd imagine
you're under one now the other thing we
notice is that a lot of those breaks
were seem to place themselves between
the bright region and the Dean region
interesting so for that we took the
gradient of the DNA which gives you
those kind of looking new brand looking
like images
and actually what you see that the
interface here has a high gradient okay
it's classic the the gradient will
actually have we will be bright where
you have a change of intensity and if
you do the same type of computation now
you'll see a value above one when you
are on those edges so you think those
those two parameters are DNA and are a
gradient we went back to the images over
that huge data set here we're dealing
with things about 400 gigs of data right
there summarizing that one graph so the
five year is the number of experiment
want to brookhaven to repeat so those
are repeat well you see is within the
first 30 minutes after radiation you
have an algorithm that's above one and
an Arden has below one which tells you
that basically those bricks are
happening not what you expect because
what you expect is that graze on here so
they have the gray zone but on top of
that we we created a signature where
they are happening and basically if you
see that slice here and that track if I
do a topographic map for the data for
the nucleus you see those basically the
higher the more DNA and then those
valleys is where there's less DNA what
you see is love those breaks a key are
in the valleys where there's no DNA or
very old in it on top of that what's
interesting is those brakes are those at
the interface between the high scope of
those profile you know this is just
visual of those just to get an idea what
it means and so the concrete publish
that in plus which is a fairly good
journal and and what we concluded was
that basically DNA damage are processed
in some very specific region of the
nucleus and that's never been shown on
human and the imaging and the modeling
was the key to come up with that it's
still controversy people still believe
that there's gotta be an expression to
our data but now it's out there that we
have at least release only yeast has
been shown right now to be able to when
you have a damaged the yeast will
actually cluster the damage into one
place and repair and that's a big deal
for NASA because if there is really
damage is being collected in one place
for gamma exposure when you get those of
gamma for instance you get breaks a bit
everywhere they kind of parsed so they
will probably get repair an individual
repair center when you get a highly
t-track like that I mean a cosmic ray I
love the love
you like close by so they're going to
end up being close to each other and
actually be repaired together and guess
what happened then what happened is that
the DNA gets confused when you repair
DNA you start putting one chromosome
with another one's called translocation
and that's a precursor for cancer maybe
that's the expansion why iron is so
carcinogenic because we know on mice
studies that when you get exposed to
iron you get a 40 fold increase in
cancer that's just the type of radiation
so it is ongoing debate and we're still
working on this but one thing to solve
the debate was to actually go for
lifestyle magine so now we're moving to
four dimensional images we have ways now
using a green so people have extracted
from jellyfish the fluorescent protein
that is first hunting the jellyfish has
been extracted and now we can encode it
into a cell and we can make the cell
fluorescent so we did here we took the
protein of interest that was the DNA
damage protein and we refused it to the
first and the DNA damage protein and
women movies out of them so we we go
that's no Kevin again that's our
microscope does think you better will
keep the cells and we merge them here
let's type of slide we're using so the
specimen are in there and then I hope
this is going to work
let me see I really like to show you
that one but if their computers on one
let me see
that p unregister
I know why I did that but anyway that's
a nucleus after radiation and it's
moving so the first thing we have to do
is registered the image so the way we do
that well for time purposes unless you
interested I will pass on the the
registration is done actually through a
third party software that we got on
matlab so i don't have much to say
anyone this but once you have registered
the image is gonna ask me again for the
direction so bear with me that one is
def p register
so after registration that's what it
looks like and so what I do to give you
an idea of volume is we underbid plan we
can rotate as we play the movie so now
there's more movement ok so you rigidly
to 3d registration which is kind of a
heavy on the computer and so now cuz I
reg but
alright so now what you see is actually
DNA damage movement so this was kind of
the key for us we haven't published this
yet is coming out because we want to do
more experiment but basically what the
budget was saying that was impossible is
happening which is that they are really
moving we're not really sure exactly
where why and that's what's going on
right now in terms of the project but
what's really remarkable is that
everything started with fixed specimen
and using the heavy-duty imaging
processing and all these quantification
came up with this and then we went back
and we could justify enough to get more
money to do this study on the lifestyle
which so much more costly to these these
studies so I think again and here this
is a plug to go go again but youtube for
instance has the movie compression
serving online system which is I think
very useful for those four dimensional
images and I'm not show you I would deal
with the third dimension the Z but
usually a maximum projection is the way
you do it do max maximum projection you
get a 2d movie that weight so there's
ways or you do volume rendering so
that's what I was trying to show you the
type of what it looks like on this on
the commercial package we use right now
this is the type of images we get and I
think again this would be nice to
intervene palimpsest eventually if we
want to look at those data so to last
slide basically one thing I think also
that links nice to Google is and that's
really more in the future i think but
one thing we do on the microscopy is we
can acquire the low magnification a
specimen and then revisit the specimen
at a high mag and that's very useful to
get an idea what you're dealing with and
then pinpoint towards region of interest
so what we can do is we can actually
store those large low magnification
images on a server and actually we are
able to pull out from the freezer the
specimen put it back on the microscope
we can home the stage and can basically
with the coordinates i can go back to
the same specimen and if i'm given the
coordinates i can go and reimage this
exactly the same way so with that in
mind I think would be amazing to
actually have some type of low
magnification storage of specimen have
people barges go on their computer visit
the specimen and then ask okay I want to
go back and
pinpoint region of interest where you go
back now I do a high mag and if if I
show you that so again those are human
breast cells so the the project the
reason why lbnl has been selected by
nasa to those studies because lbnl is
expert in growing human breast cells and
not only we grow them on a dish we can
grow them in a gelatin-like and so what
happened is when we do that we can grow
the cells and they make those aggregates
and those aggregates are like mini
breast duct and actually if we give them
hormones they would secret milk human
milk so they are so as far as we're
concerned us the best in vitro system
for humans to the radiation because
we're looking at a functional organ a
mini organ in a gelatin that actually
works exactly like the breast just add a
smaller scale so this is the reason wine
as I was so into having albina working
on this because we've been using this
type of system now if you focus just on
the imaging part those big blobby are
like mini mini cells and inside the
blood days milk but we can do is people
are interesting those features here
those kind of like branching so that's a
low mag image 10 x I can go on the
computer and visit that image and this
is actually the montage if I pull out
the full resolution of that image on 10x
this is what I get but now what we did
I've in the coordinate I went back to
the specimen that was in the freezer
take it out of freezer and I say okay I
want a 40x image in this region this is
what you get so again really there's a
lot of things that still out there that
still not done and I think that the
central committee will benefit a lot by
some type of collaboration and I want
you to conclude on I think we need to
integrate better acquisition data
storage and that's the reason why we so
interesting Panem sets also the one
thing to remember is that the storage
solution should also eventually good
visual sorting and organizing
capabilities and I think this is what
Google is really expert in in all those
levels so visualize fact the images
might be the one thing that google is
not so expert in its kind of a special
feature basic tools registration
segmentation I am pretty sure you have
better tools and we have interactive
link i think i hope i convinced rates
vary
wait to go back and forth with your data
now one of the annoying feature is if I
there's multiple format they're not very
hard some of them are actually you would
need agreement we need a with special
agreement with the company to let us
access the data its non NDA we have to
sign those things so I'm not sure
exactly i would work but anyway multiple
microscope format is actually a problem
right now and obviously the one thing
that you really need is the metadata in
the so that you can parse and actually
generate on the flag graph like i show
you so kind of like data spaces you were
mentioning this is why it would fit
nicely and i think one place where
everything is done would be great and to
give you an idea what i show you today
was made with five different software
it's not as smooth as it look like and
it's actually one of our expertise is to
know what tools is out there and what we
can use and so of course expanding our
tool kit would be great the software i
very closely and and also when we go
from software software there's no api
whatsoever except for big plan where we
they created a plug from matlab which is
great so we can call the function and
actually have them talk to each other
except for that one software the rest is
you're on your own you go visual basic
or you go with some type of macro huge
it's more macro and no api so once you
leave the software is saved under their
format and then you go to rebate it into
another so you duplicate data left on
the right it gets really when you have
gigs of the rights it's really annoying
so again a place where everything is
would be the ideal situation and I'm
management the chair of the end score
project NASA specialist centre of
research dr. barliss off those are my
collaborator and NASA Francisco janetta
is actually the director of the of the
project is the one funding all the
different projects and is very
interested in our data because he's
doing a lot of risk modeling so is using
our data to do risk modeling and people
at lbnl and if you have questions or
want to talk more be glad to talk to you
yep
candles
radiation
situation to say
so I'm sorry the question is if the
imaging looks different how we deal with
it
we do we actually so we actually stole
all of them and we usually have a time
course that goes from zero minutes three
minutes to the first hour is fairly well
covered we have at five minutes 10
minutes 20 minutes 30 minutes Hannah 45
minutes one hour and then as we go
further in we start changing the scale
and we go up to 48 hours and then for
other SI then we have different
questions because the looking at DNA
damage they are they all gone by 48
hours they have been repaired to destroy
the cells have died there's a process
co-op of ptosis for the cell to actually
kill itself if it's healthy so but we
store everything so this is actually
what panting sets is going to be storing
is all those data so we could go back
and we the real primary now is we don't
have the manpower to restore those data
but we only can look at specific
endpoint and and and at a certain
limited and we have limitation what we
can look at so if you could come back
and say you know why we should look at
this then it's really hard for us to
restart everything you got to pull out
the nuclear segmentation again and and
because it's not a usually are
eventually our that our archives so you
got to pull them out of the archive and
few things like this that makes it did
not answer any question no yeah
what in terms of data right now so we
have generated about a terabyte so it's
and a lot of it is duplication from all
those processing so and I think I'm
palimpsest what we plan to put more is
like two or 300 gigs I think the
lifetime aging actually takes love
memory because now you look at it if you
do this tag over time it gets it gets
really bad quickly
you know the question no
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>