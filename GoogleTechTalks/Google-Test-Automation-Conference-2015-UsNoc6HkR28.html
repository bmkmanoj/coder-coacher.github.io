<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Google Test Automation Conference 2015 | Coder Coacher - Coaching Coders</title><meta content="Google Test Automation Conference 2015 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Google Test Automation Conference 2015</b></h2><h5 class="post__date">2015-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UsNoc6HkR28" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">&amp;gt;&amp;gt;Yvette Nameth:  GOOD   MORNING
, EVERYONE.

&amp;gt;&amp;gt;Yvette Nameth:  COME ON! 
GOOD MORNING, EVERYONE. 
&amp;gt;&amp;gt;&amp;gt; GOOD MORNING! 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU.    
GOOD.
WE FED YOU GOOD COFFEE  COFFEE. 
WELCOME TO GOOGLE, IN   
PARTICULAR,
 WELCOME TO GOOGLE   CAMBRIDGE. 
 MY
 NAME IS YVETTE   NAMETH, AND I 
AM
 ACTUALLY NOT   FROM GOOGLE 
CAMBRIDGE.
I AM   FROM OUR SEATTLE OFFICE. 
JUST A QUICK HI FROM ME,   
BECAUSE
 I WILL BE WITH YOU   FOR THE 
NEXT
 TWO DAYS,   HELPING FIGURE OUT 
WHAT'S
   GOING ON HERE. 
I'VE BEEN WITH GOOGLE FOR   
ABOUT NINE
 YEARS NOW,   SPANNING BOTH 
PRODUCTS
 AND   ADS AND MAPS. 
I'M A TEST ENGINEER AND A   
MANAGER
 IN THE SEATTLE OFFICE   FOR THE
 GOOGLE
 MAPS PRODUCTS   RIGHT NOW. 
AND I DON'T KNOW IF YOU CAN   
TELL,
 BUT I'M RAPIDLY LOSING   MY 
VOICE,
 SO I'M GOING TO TRY   AND KEEP 
THIS
 SWEET AND   INFORMATIONAL. 
AS SOME OF YOU IN THE   AUDIENCE
 MAY
 KNOW, THAT MIGHT   BE A LITTLE 
HARD
 FOR ME, BUT   I'LL DO MY BEST  
BEST.
SO, FIRST OF ALL, LET'S MAKE   
SURE
 YOU KNOW WHERE THINGS   ARE. 
ONE OF THE MOST IMPORTANT   
THINGS
 TO KNOW WHERE IT IS IS   THE 
AGENDA.
WHAT ARE WE   DOING OVER THE 
NEXT TWO
 DAYS,   WHEN ARE THINGS 
HAPPENING.
ALL OF THE INFORMATION, SUCH   
AS AGENDA,
 HOW TO SUBMIT   QUESTIONS, HOW 
TO
 VIEW THE   RECORDINGS AFTER 
GTAC IS
 OVER  OVER, ARE AVAILABLE ON   
DEVELOPERS.GOOGLE.COM/GTAC.

LINK
 FOR ALL QUESTIONS, WHICH  
WHICH, SPEAKING
 OF, IT ALSO   CONTAINS THE LINK
 TO
 THE LIVE   STREAM. 
WELCOME TO EVERYONE VIEWING   ON
 THE
 LIVE STREAM, WHICH IS   GOING 
ON RIGHT
 NOW.  IF   YOU'RE IN THE ROOM 
WITH
 ME   HERE, REMEMBER, YOU MIGHT 
  ACTUALLY
 BE ON CAMERA.  WE'VE   GOT SIGN
S ALL
 OVER THE PLACE   TELLING YOU 
THAT,
 BUT THIS IS   MY ONE LAST 
REMINDER.

ALL POSTERITY.
THEY'RE GOING   TO SEE ME FOR 
ALL POSTERITY.
  I'M SORRY. 
SO IT IS WHAT IT IS.  AND   THAT
 INFORMATION
 IS ON THE   WEB SITE. 
BUT THE OTHER INTERESTING   
PIECE OF
 INFORMATION FOR   THOSE OF YOU 
IN
 THE ROOM AND   THOSE OF YOU ON 
THE
 LIVE   STREAM, IS THAT OUR 
LINKS TO
   Q&amp;amp;A ARE ALSO AVAILABLE FROM  
 THAT
 SAME WEB SITE. 
SO, AGAIN, YOU GO TO   
DEVELOPERS.GOOGLE.COM/GTAC
   AND YOU CAN FIND ALL THE   
INFORMATION
 ON HOW -- OR THE   LINK FOR 
THIS,
 OUR WAY OF   ASKING QUESTIONS. 
 FOR
 EVERY   TALK, WHAT WILL HAPPEN,
 AT
   THE BEGINNING OF THE TALK, IT
   WILL
 SHOW UP ON THIS SITE,   THE 
SAME SITE
 FOR EVERY TALK.    THERE WILL 
BE THE
 DATE, TIME,   AND NAME OF TALK.
  AND
 YOU   ENTER YOUR QUESTION. 
AT THE END OF THE TALK,   
ASSUMING
 THERE'S TIME   REMAINING, WE 
WILL
 TAKE AS   MANY QUESTIONS AS WE 
CAN.
  AND IF SOMEBODY HAS ALREADY   
ASKED
 YOUR QUESTION, FEEL   FREE TO 
UPVOTE
 IT.  WE'LL BE   TAKING THE TOP 
&quot;N&quot;
 QUESTIONS   FOR EVERY TALK. 
ANOTHER LOGISTICAL PIECE OF   
INFORMATION,
 BECAUSE I GOT   THE EXCITING 
STUFF,
 THE   REALLY MEETING MEATY 
STUFF.
PLEASE   WEAR YOUR CONFERENCE 
BADGE
 AT   ALL TIMES.  THIS IS OUR 
WAY 
  OF LETTING PHYSICAL SECURITY  
 KNOW
 THAT YOU ARE LEGIT TO BE   
INSIDE
 THE BUILDING WITH US,   THAT 
YOU ARE
 A GOOGLE GUEST.    AND THIS 
SAME BADGE
 IS WHAT   WILL GET YOU BACK 
INTO THE
   BUILDING TOMORROW.  SO   
WITHOUT
 IT, I'M SORRY, YOU'LL   BE ONE 
OF
 THE LIVE STREAM   PARTICIPANTS 
FROM
 YOUR HOTEL   ROOM.  AND THAT 
WOULD
 BE   REALLY SAD. 
SO PLEASE WEAR IT.  YOU WILL   
NOTICE
 ONE PARTICULAR THING   ABOUT 
YOUR
 BADGES.  MOST OF   YOU HAVE, 
LIKE,
 WHITE STRING   LANYARDS.  THERE
 WILL
 BE A   FEW PEOPLE AROUND WHO 
HAVE
 A   BLACK LANYARD ON.  THE 
BLACK 
  LANYARD IS VERY, VERY SPECIAL 
 SPECIAL.
THESE ARE YOUR BUD  BUDDIES 
SHOULD
 ANYTHING NOT   BE AVAILABLE TO 
YOU
 ON THE   WEB SITE OR OBVIOUS 
FROM
 WHAT   I'M TELLING YOU TODAY'S.

THE
 ORGANIZATION   COMMITTEE PEOPLE
, AND
 THEY   WILL CONNECT YOU WITH   
WHATEVER
 ANSWERS YOU NEED   HERE. 
THERE'S ANOTHER SPECIAL-  
SPECIAL-COLORED
 LANYARD THAT   I'D LIKE TO CALL
 OUT,
 TOO,.    THAT IS THE BLUE 
LANYARD.
  AND THAT IS ALL THE SPEAKERS  
 OVER
 THE NEXT TWO DAYS. 
SO JUST THANK THEM FOR   
DONATING THEIR
 TIME TO SPEAK. 
OF COURSE, THERE'S THIS THING   
CALLED
 SOCIAL MEDIA.    REGARDLESS OF 
WHAT
 PLATFORM   YOU USE, WE'D LOVE 
IT IF
 WE   COULD COORDINATE A HASHTAG
, 
  BECAUSE WE'RE LIKE THAT. 
GTAC 2015, WHEN YOU'RE POST  
POSTING
 ON GOOGLE+, TWITTER,   FACEBOOK
, WHAT
 HAVE YOU,   INSTAGRAM, ANY OF 
THE
 ABOVE.    WE'D LOVE TO SEE YOUR
   PICTURES.
WE'D LOVE TO HEAR   WHAT THINGS 
ARE
 REALLY   STANDING OUT, WHAT NEW
   QUESTIONS
 YOU HAVE FOR   YOURSELF, WHAT 
MEMORABLE
   QUOTES YOU HEARD THE SPEAKERS
   SAY,
 ET CETERA, .  SO PLEASE   SHARE
 THOSE
 WITH US. 
WELL, YOU'RE AT GOOGLE, AND I   
THINK
 EVERYONE AT THIS POINT   KNOWS 
THAT
 GOOGLE HAS A LOT   OF FREE FOOD
 AROUND.
AND   WE'RE NOT GOING TO LEAVE 
YOU
   OUT OF THIS.  LUNCH IS   
PROVIDED
 ON SITE BY GOOGLE   FOR YOU 
EACH DAY.
YOU REALLY   DON'T HAVE TO GO 
FAR.
I   THINK ONE OF THE STATIONS   
WILL
 BE JUST AS CLOSE AS   BREAKFAST
 WAS
 TO THIS ROOM.    BUT LUNCH WILL
 ACTUALLY
 BE   AVAILABLE OUT IN THE 
COMMON 
  AREA JUST OUTSIDE OF THIS   
ROOM,
 AS WELL AS THERE'S A   COMMON 
AREA
 UPSTAIRS THAT   REQUIRES NO 
BADGE
 TO GET TO   OTHER THAN YOUR 
CONFERENCE
   BACK, WHERE THERE WILL   
BADGE, WHERE
 THERE WILL BE   TABLEED SEATING
 TO
 SIT DOWN.    IT WILL BE 
DIFFERENT
 EACH DAY  DAY, THERE ARE 
VEGETARIAN,
   OMNIVORE, CARNIVORE OPTIONS  
 AVAILABLE
 TO YOU EACH DAY. 
SO WELCOME TO GOOGLE, AND   
ENJOY THE
 FOOD! 
BUT WE'RE NOT DONE THERE. 
YOU KNOW, WE'VE GOT TOMORROW,   
AND
 WE'VE GOT TO RECHARGE.    SO 
TONIGHT,
 GOOGLE RECRUITING   HAS DECIDED
 TO
 HELP US OUT BY   SPONSORING A 
CASINO
 NIGHT.    NO REAL MONEY 
INVOLVED.
  FUNNY MONEY ONLY.  DINNER,   
DRINKS,
 GAMES, POKER,   ROULETTE.  
TECHS HOLD
 TEXAS HOLDEM.  COME,   HAVE FUN
.
  AND, AGAIN, IT   WILL BE IN 
OUR WONDERFUL
   SHARED SPACE HERE IN GOOGLE  
 CAMBRIDGE.
NOW, THERE ARE SOME CHANGES   
THAT
 HAVE HAPPENED OVER THE   YEARS 
WITH
 GTAC.  ONE OF THE   BIGGEST 
CHANGES
 THAT HAS   HAPPENED OVER THE 
YEARS
 IS   THAT WE'VE STARTED TO 
EXPAND.
  WE'VE EXPANDED THE TYPES OF   
TECHNOLOGIES
 THAT WE TALK   ABOUT HERE AT 
GTAC.
WE NOW   NOT ONLY TALK ABOUT 
SOFTWARE
   TESTING AND EXPLICITLY WEB   
TESTING.
WE TALK ABOUT APP   TESTING, 
PHONE
 TESTING,   TESTING MACHINES, 
TESTING
   WITH ROBOTS, ACCESSIBILITY   
TESTING,
 YOU NAME IT, WE TALK     ABOUT 
IT.

INCREASED
 OUR DIVERSITY, TOO,.    AND WE 
WANTED
 TO ACTUALLY   EXPLICITLY 
RECOGNIZE
 THAT   THIS YEAR.  AND ONE OF 
THE
   CHANGES THAT WE'VE MADE THIS 
  YEAR
 IS ACTUALLY CALLING OUT   
EXPLICITLY
 OUR DIVERSITY   POLICY ON THE 
WEB
 SITE AS   WELL AS OUR CODE OF 
CONDUCT,
   WHICH YOU'VE SEEN ON THE WEB 
  SITE
 POST, POSTED AROUND THIS   
CONFERENCE
 SPACE, AND HERE ON   THE SLIDE.

IN MIND
 THIS NOTION OF   INCLUSIVENESS 
WHEN
 HAVING   LIVELY DISCUSSIONS 
WITH YOUR
   FELLOW TESTER COMRADES HERE  
 AT
 GTAC. AND WHEN ASKING   
QUESTIONS.
AND IF YOU HAVE   ANY QUESTIONS,
 FEEL
 FREE TO,   YOU KNOW, BRING IT 
UP,
 TALK   ABOUT WHAT DOES THIS 
ACTUALLY
   MEAN, WHAT DOES THIS IMPLY?  
  THIS
 IS ANOTHER INTERESTING   
CONVERSATION
 WE CAN HAVE HERE   AT GTAC. 
WITH THAT BEING SAID, LET'S   
ACTUALLY
 TALK ABOUT YOU GUYS. 
THIS IS A WONDERFULLY DIVERSE   
GROUP
 OF PEOPLE IN FRONT OF   ME, AND
 THOSE
 OF YOU ON THE   LIVE STREAM WHO
 DIDN'T
   ACTUALLY GET TO COME JOIN US 
  TODAY.
  SO WE HAD 1362   APPLICATIONS 
TO
 ACTUALLY   ATTEND GTAC.  THAT'S
 AN
   INSANE NUMBER.  JUST LOOK   
AROUND,
 IF YOU'RE SITTING IN   THE ROOM
 WITH
 ME.  AND HOW   MANY PEOPLE DO 
YOU
 ACTUALLY   THINK ARE HERE.  
JUST A
 FEW   HUNDRED.  WE HAD   
APPROXIMATELY
 200   APPLICATIONS FOR SPEAKER 
  SUBMISSIONS,
 FROM WHICH WE   PICKED ONLY 24 
TALKS.
AND WE HAD OVER 250 GOOGLERS   
APPLY
 TO ATTEND, LET ALONE   THE 
OTHERS
 THAT JUST SHOWED   UP.  THERE 
ARE
 TONS OF YOU   HERE.  AND WE 
THANK
 YOU FOR   WANTING TO COME, FOR 
MAKING
   OUR JOB SO HARD WHEN WE WERE 
  DOING
 SPEAKER SELECTION THAT   WE 
ACTUALLY
 FOLLOWED OUR OWN   ADVICE.  WE 
REALLY
 WANTED TO   TAKE DIVERSITY INTO
 ACCOUNT
   THIS YEAR.  AND RATHER THAN  
 JUST
 LOOKING AT THE DIVERSITY   OF 
TALKS,
 WE TOOK INTO   ACCOUNT THE WAY 
GOOGLE
 HAS   BEEN PROMOTING THE NOTION
 OF
   UNCONSCIOUS BIAS AND   
RECOGNIZING
 WHEN UNCONSCIOUS   BIAS COMES 
INTO
 THE WORKPLACE  WORKPLACE. 
AND IN THIS VEIN, WE ACTUALLY   
REMOVED
 ALL PII, PERSONALLY   
IDENTIFIABLE
 INFORMATION,   DURING THE 
SPEAKER
 SELECTION   PROCESS SO THAT WE 
COULD
   REALLY FOCUS ON WHAT YOU'RE  
 TALKING
 ABOUT AND MAKE SURE   THAT WE 
GET
 A GOOD BREADTH OF   TECHNICAL 
TALKS
 COVERING ALL   SORTS OF THINGS.
ADDITIONALLY,
 WE ACTUALLY ADD   ADD ONE MORE 
THING
 THAT CAME   OUT FEEDBACK FROM 
LAST
 YEAR.    WE'RE GOOGLERS.  WE 
LIVE
 IN   THIS BEAUTIFUL GOOGLE 
BUBBLE
   WITH 
 MASSAGE TABLES AND FOOD   AND
 INFRASTRUCTURE THAT SOME   OF 
YOU
 WOULD DROOL OVER.  BUT   THAT'S
 NOT
 NECESSARILY   REPRESENTATIVE 
EITHER
 WHEN   WE'RE DOING SELECTIONS. 
 SO
   FOR THE FIRST TIME WE   
EXPERIMENTED
 WITH HAVING TO   SOMEBODY WHO 
IS NOT
 A GOOGLER   ON OUR SPEAKER 
COMMITTEE.
WE   WOULD LIKE TO THANK SALAL 
WHO
   IS NOT HERE WITH US WHO DID  
 DIAL
 IN AND GIVE US FEEDBACK   ON ON
 POINT
 OUT WHERE OUR UN  UNCONSCIOUS 
BIASES
 BECAUSE OF   OUR DAY-TO-DAY 
INFRASTRUCTURE
   CHALLENGES, WHERE THEY WERE  
 COMING
 OUT IT IN OUR SPEAKER   
SELECTION
 AND EVEN IN OUR   TECHNICAL 
SELECTION.
SO THAT   WAS KIND OF COOL.  WE 
ENDED
   UP COMING OUT OF FIVE   
ACADEMIC
 SPEAKER, EIGHT   GOOGLE SPEAKER
S AND
 THE REST   OF ARE EVERYONE ELSE
 SHOWING
   US AS BROAD OF A RANGE AS   
POSSIBLE.
I GAVE YOU A LITTLE SNIPPET   OF
 WHERE
 PEOPLE ARE FROM ON   THE SLIDE.
  HOWEVER,
 LET'S   MAKE SURE YOU ARE 
REALLY A
  AWAKE.  THAT WELCOME SOUNDED  
 PRETTY
 GOOD SO I'M HOPEFUL. 
SO, I'M GOING TO PLAY A   LITTLE
 GAME
 WITH YOU.  I   WOULD LIKE 
ANYONE WHO
   TRAVELED MORE THAN 20 HOURS  
 TO
 GET TO GTAC HERE IN   CAMBRIDGE
 TO
 PLEASE STAND UP.    STAND UP. 
THANK YOU.  I THINK THESE GUY  
GUYS
 ACTUALLY DESERVE A ROUND   OF 
APPLAUSE.

NO, STAY STANDING BECAUSE YOU   
ARE
 ELIGIBLE FOR THE NEXT TWO  TWO.
  NOW,
 COME ON, SOME OF   US TRAVELED 
MORE
 THAN TEN   YEARS.  STAND UP, 
PLEASE,.

YOU
 TRAVELED MORE THAN TEN.    STAY
 UP
 THERE. 
[ LAUGHTER ] 
OKAY.  YES.  WE'RE GETTING   
MORE.
DID YOU TRAVEL MORE   THAN FIVE 
HOURS?
THIS IS   WHERE I GET TO STAND 
UP.
DID YOU TRAVEL MORE THAN AN   
HOUR?
LET'S GET NEW YORK  CITY 
STANDING.

OKAY.  IF YOU HAVE ANY   
NEIGHBORS
 SITTING DOWN, SAY   HELLO TO 
THE LOCALS.
THEY   ARE YOUR TOUR GUYS TO THE
   NEXT
 FEW DAYS.  THEY ARE YOUR   
FRIEND.
THANK YOU, EVERYONE.    YOU CAN 
SIT
 DOWN. 
WITH THAT BEING SAID, I WANT   
TO TELL
 YOU A LITTLE BIT   ABOUT WHAT 
IT IS
 LIKE TO BE   LOCAL TO GOOGLE 
CAMBRIDGE.
  THIS OFFICE HAS OVER 900   
GOOGLERS
 ACROSS 12 FLOORS AND   300 
CONNECTED
 BUILDINGS.  IT   WASN'T ALWAYS 
THIS
 WAY.  WHEN   I FIRST VISITED 
GOOGLE
   CAMBRIDGE THERE WERE LESS   
THAN
 50 GOOGLERS ABOUT FIVE,   SIX 
YEARS
 AGO, MAYBE MORE.  I   DON'T 
REMEMBER.

LARGEST
 OFFICE EAST OF THE   
MISSISSIPPI.
THE OTHER ONE   BEING NEW YORK 
CITY.
IT STARTED OUT IN 2003 ACES A   
SMALL
 SALES OFFICE, AS MANY   OF OUR 
GEOGRAPHY
 OFFICES ENGINEERS OFFICES DID. 
  OF COURSE, ENGINEERS SAID   
THEY WANTED
 TO WORK THERE,   TOO,.  IT WAS 
GREAT
 LOCATION.    IT WAS ACTUALLY IN
 BOSTON
 AND   RELOCATED TO CAMBRIDGE IN
   2006
 AND THIS PARTICULAR SITE   EVEN
ED
 IN 2008. 
I LISTED A BUNCH OF THE   
PROJECTS
 THAT EXIST IN GOOGLE   
CAMBRIDGE BUT
 WITH A 900-  900-PERSON OFFICE 
WE
 HAVE A   REALLY GOOD CROSS-
SECTION
 OF   THE GOOGLE PRODUCT SPACE. 
   EVERYTHING
 FROM INTERNAL   TOOLS TO ADS 
LATENCY
 TO   CHROME, GOOGLE PLAY, ITA 
IS 
  ONE OF OUR PARTICULARLY   
UNIQUE PROJECTS
 HERE, ET   ET CETERA. 
AND YOU MAY NOTICE AND YOU'LL   
REALLY
 NOTICE IF YOU GO ON   ONE OF 
THE TOURS
 WHICH I WILL   TELL YOU ABOUT 
IN A
 SECOND   THAT THIS OFFICE HAS A
 THEME
   AND THE ENTIRE OFFICE IS   
THEMEED
 LIKE THE T.  SO EACH   BUILDING
 HAS
 ITS OWN COLOR.    I CAN'T 
REMEMBER
 WHAT COLOR   WE'RE IN RIGHT NOW
.
I THINK   WE'RE ACTUALLY IN THE 
CONNECT
  CONNECTOR SO WE'RE IN ONE OF  
 THE
 CONNECTOR COLORS. 
BUT EACH BUILDING HAS A COLOR   
AND
 THERE ARE, LIKE, SUBWAY-  
SUBWAY-LIKE
 MAPS FOR GETTING   AROUND THE 
BUILDINGS
 BECAUSE   THEY DON'T ACTUALLY 
CONNECT
   FROM FLOOR THREE.  YOU MAY   
END
 UP GOING FROM FLOOR THREE   TO 
FLOOR
 FOUR.  SO IT'S KIND   OF 
IMPORTANT
 TO LOOK YOUR SUB  SUBWEIGH MAP 
TO
 GET AROUND   GOOGLE CAMBRIDGE. 
AND IF YOU ACTUALLY WANT TO   
SAY THIS
 YOURSELF AND SEE THE   AMAZING 
OFFICE
 SPACE ALONG   WITH THE GREEN 
SPACE
 THAT YOU   MAY SEE OUTSIDE THE 
WINDOWS
   JUST OUTSIDE THIS COMMON AREA
  AREA,
 WE ARE OFFERING TOURS   BOTH 
TODAY
 AND TOMORROW AT   1:00 P.M. AND
 3:30 P.M.

OR
 LUNCH JUST OUTSIDE NEAR   WHERE
 YOU
 PICKED UP YOUR SWAG  SWAG.  AND
 FOR
 PEOPLE ON THE   LIVESTREAM, I'M
 SORRY,
 LOOK   AT PICTURES ONLINE, 
THEY'RE
   GREAT.  AND WE HOPE YOU CAN  
 JOIN
 US AT WHATEVER OUR NEXT   
LOCATION
 MAY BE. 
HOW AM I DOING ON TIME, MATT? 
I HAVE ONE OTHER THING.  I'M   
NOT
 SUPPOSED TO TALK A LOT   BUT I 
CAN'T
 HELP IT.  OH, THE   SLIDES 
DIDN'T
 RELOAD. 
I'M NOT SUPPOSED TO TALK A   LOT
 BUT
 I REALLY CAN'T HELP   IT.  I 
WASN'T
 EVEN SURE I   COULD TALK ABOUT 
THIS
 THIS   MORNING.  BUT AS OF 9:00
 A.M.
   EASTERN TIME TODAY A PRODUCT 
  I
 HAVE BEEN TESTING IN SECRET   
FOR
 THE PAST TWO YEARS   FINALLY 
LAUNCHED.
IT'S THE   FIRST TIME I ACTUALLY
 GOT
 TO   LAUNCH A PRODUCT THAT 
PEOPLE
   DIDN'T KNOW ABOUT. 
[ APPLAUSE ] 
YOU DON'T EVEN KNOW WHAT IT   IS
! 
SO AS I'M STANDING HERE   
SPEAKING
 WITH YOU, MY TEAM   SERVICE 
HAVING
 MIMOSAS   BECAUSE WE ACTUALLY 
JUST
   LAUNCHED OFFLINE GOOGLE MAPS 
  FOR
 MOBILE, MEANING NOW YOU   CAN 
DO SEARCHING --
 YES!  YOU   ARE MY HERO, AV. 
[ LAUGHTER ] 
YOU CAN NOW SEARCH FOR A   
RESTAURANT
 IN A LOCATION   WHERE YOU'VE 
DOWNLOADED
 YOUR   MAP REGARDLESS OF 
WHETHER YOU
   HAVE INTERNET CONNECTION.  AS
   LONG
 AS YOU HAVE G.P.S. WHICH   DOES
 NOT
 REQUIRE WiFi OR   DATA SIGNAL, 
YOU
 CAN NAVIGATE   TO YOUR ROUTE 
USING
 TURN-BY-  TURN-BY-TURN 
NAVIGATION
 INS.  SO   THIS WILL BE ROLLING
 OUT
 TO G  GMM ON YOUR PHONE -- GMM,
   GOOGLE
 MAPS FOR MOBILE --   SOMETIME 
SOON.
WE ARE DOING   A SLOW ROLLOUT 
BUT IT
 IS NOW   OUT THERE IN THE WILD.
  SO
   THAT'S REALLY AWESOME. 
BUT GUESS WHAT?  I SPENT THE   
PAST
 TWO WEEKS DEBUGGING A   TEST 
THAT
 WAS REALLY, REALLY   ANNOYING. 
 I
 HAD THIS TEST   WHERE ON HE 
EVERY
 EMULATOR I   RAN IT ON, ON 
EVERY PHONE
 I   RAN IT ON, WHEN I STEPPED  
 THROUGH
 IT, IT WOULD NOT RE  REPRODUCE 
THE
 BEHAVIOR.  IT WOULD NOT   ALLOW
 ME
 TO SELECT AN AREA TO   DOWNLOAD
. 
AND I WAS LIKE, WHAT IN THE   
WORLD
 IS GOING ON HERE?  I   CAN DO 
THIS
 ON MY EMULATORS,   REGARDLESS 
OF MY
 API LEVEL.    IT DOESN'T MATTER
 WHAT
   VERSION OF MAPS FOR MOBILE   
I'M
 ACTUALLY RUNNING.  THIS   IS 
LIKE
 CONSISTENT BACK A FEW   VERSION
S OF
 OUR DEV BUILD. 
WHAT'S GOING ON HERE?  IT   TURN
S OUT
 I UNCOVERED ONE OF   THOSE BUGS
 THAT
 OUR USERS   PROBABLY NEVER WILL
, THAT
   ONLY MY AUTOMATION COULD.    
ONCE
 UPON A TIME A DEVELOPER   
ASSUMEED
 THAT YOUR FINGER   WOULD BE ON 
THE
 SCREEN WHEN   YOU HIT THAT 
PARTICULAR
   SCREEN WHERE YOU SELECT AREAS
   TO
 INPUT, AND THAT'S WHAT   
TRIGGERS
 THE IS THIS AREA   VALID TO 
DOWNLOAD?

TRIGGER
 THIS, MEANING THERE   WAS NO 
INTERACTION
 WITH THE   DEVICES.  AND EVERY 
TIME
 MY   TEST WAS FAILING. 
I SPENT TWO WEEKS ON THIS.    
THAT'S
 EMBARRASSINGLY LONG. 
[ LAUGHTER ] 
LIKE, LET ME TELL YOU.    
ALTHOUGH
 KIND OF FUNNY, LET'S   BE 
HONEST,
 THE TEAM WOULD   WALK BY AND BE
 LIKE:
DID YOU   GET IT YET?  SERIOUSLY
?
ARE   YOU ASKING ME?  DO YOU 
REALLY
   WANT TO RUIN MY DAY? 
BUT, IN THE END I JUST WANT   TO
 REMIND
 EVERYONE WE'RE   GOING TO HEAR 
ABOUT
 A LOT OF   PEOPLE'S SUCCESSES 
WHETHER
   IT'S LAUNCHING OFFLINE GOOGLE
   MAPS
 OR WHETHER IT'S SPENDING   TWO 
WEEKS
 ON A RIDICULOUS   EDGE CASE BUG
 THAT'S
 A HUGE   CHALLENGE.  AND THESE 
COME
   HAND IN HAND.  WITH EVERY   
CHALLENGE
 HOPEFULLY A FEW OF   THOSE PUT 
TOGETHER
 WILL   RESULT IN A SUCCESS.  
AND 
  WITH EVERY SUCCESS, ASK THE   
PERSON
 WHAT CHALLENGES DID   YOU LEARN
 FROM
 ALONG THE WAY   THAT HELPED YOU
 GET
 HERE?  SO   THAT WE CAN LEARN 
FROM
 EACH   OTHER.  SO I'M JUST 
GOING TO
   ACTUALLY PUT OUT A CHALLENGE 
  TO
 YOU GUYS TO SAY:  WHAT   HELPED
 YOU
 GET HERE?  AND   
CONGRATULATIONS ON
 ALL YOUR   BIG SUCCESSES. 
AND WITH THAT, I'M GOING TO   
ACTUALLY
 HAND OVER THE MIC --   WELL, 
THE CLICKER
 CLICKER REALLY --   TO JUERGEN 
ALLGAYER
 OF You  YOUTUBE TO TALK ABOUT 
  TESTING ON THE TUBE. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Juergen Allgayer:  WHOEVER   
DESIGNED
 THIS NEEDS TO HAND   OUT -- BOY
, THERE'S
 AN ECHO,   TOO,.  NOT ONLY DO I
 NEED
   SUNGLASSES; I NEED TO GET   
USED
 TO MY NEW VOICE HERE. 
GOOD MORNING, EVERYONE.    
JUERGEN
 ALLGAYER.  THAT'S ME.    I RUN 
THE
 TEST GROUP IN You  YOUTUBE.  
AND
 OVER THE NEXT   NEXT -- WHAT'S 
LEFT?
-- 50   MINUTES, I'M GOING TO 
GIVE
   YOU AN OVERVIEW OF WHAT   
CHALLENGES
 WE'VE TACKLED OVER   THE LAST 
YEARS
 AND OUR   SUCCESS STORY, AT 
LEAST
 A FEW   OF THEM. 
I JOINED GOOGLE EIGHT YEARS   
AGO WITH
 A JOB TO BUILD UP   THE 
ENGINEERING
 PRODUCTIVITY   FUNCTION IN 
EUROPE.
PROBABLY   MOST OF YOU HAVE 
HEARD ABOUT
   ENGINEERING PRODUCTIVITY IN  
 GOOGLE.
IT'S AN UMBRELLA   FUNCTION FOR 
LOTS
 OF   DISCIPLINES ALL AROUND   
TESTING,
 AUTOMATION, IN   GENERAL, SPEED
ING
 THINGS UP,   FROM SPEED UP THE 
COMPILERS
   ALL THE WAY UP TO BUILDING   
TOOLS
 TO HELP FIND MAYBE   THOSE BUGS
 THAT
 TAKE TWO   WEEKS TO FIND MANUAL
LY.

OF BUILDING
 AN ORGANIZATION   REALLY ONLY 
FOCUSED
 ON THAT,   I WAS VERY INTRIGUED
, APPLIED
   FOR THE JOB, GOT THE JOB,   
MOVED
 TO ZURICH IN   SWITZERLAND.  
AND FOR
 THE   NEXT THREE YEARS, STARTED
 TO
   BUILD UP THIS GROUP. 
AND THEN I GOT A REPEAT OFFER   
TO
 DO THE SAME THING FOR You  You
TUBE
 ABOUT THREE, THREE   AND A HALF
 YEARS
 AGO.  AND,   AGAIN, IT WAS 
PRETTY
   INTERESTING TO SEE, OKAY, FOR
   COMING
 FROM THE WORLD OF   TRYING TO 
DO THIS
 OPERATION   ACROSS ALL OF THE 
DIFFERENT
   PRODUCT GROUPS WITHIN GOOGLE 
  THAT
 HAPPEN TO BE IN EUROPE,   IN 
ONE OF
 THE EUROPE OFFICES,   KIND OF 
PIVOT
 AROUND TO SAY,   OKAY, WHEREVER
 A
 YouTUBE   TEAM WORKS, WHICH IS 
ZURICH,
   HERE, SAN BRUNO IN CALIFORNIA
  CALIFORNIA,
 MOUNTAIN VIEW, OF   COURSE, THE
 HOME
 BASE, L.A.,   PARIS, WHEREVER  
 WE
 HAVE   PEOPLE IN YouTUBE, WE 
BUILD 
  BUILD -- I HELP BUILD UP THIS 
  ORGANIZATION
 THAT HOPEFULLY   HELPS US TO 
GET
 YouTUBE AND   THE OPERATIONS 
BEHIND
 IT   CLICKING ON ALL CYLINDERS.
SO WHAT I'M GOING TO DO IN   THE
 NEXT
 TIME HERE, IN THE   NEXT HOUR, 
IS
 TO LEAD YOU YOU   THROUGH A 
COUPLE
 OF THOSE   CHALLENGES THAT WE 
WERE
   FACING.  BUT LET ME FIRST   
GIVE
 YOU A WIT OF BIT OF AN   
INTRODUCTION
 INTO WHAT THIS   SYSTEM UNDER 
TEST
 THAT WE'RE   TALKING ABOUT 
ACTUALLY
 LOOKS   LIKE. 
YES, WE'RE GOING TO TALK   ABOUT
 YouTUBE
 AND PRETTY   MUCH ONLY ABOUT 
YouTUBE.
  SO I WILL NOT MENTION A LOT   
OF OTHER
 OF THE PRODUCT AREAS   AND 
TOOLS BUILT
 THERE.  I'LL   JUST GIVE YOU 
THE STORY
 OF   THE SMALLER SCOPE. 
AS IT'S NOT -- NOT REALLY   
SURPRISING,
 BEING A VIDEO   SERVICE, A LOT 
OF
 THE -- OF   THE STACK IS BUILT 
UP
 WITH   PROPER VIDEO SERVICES, 
HOW
 TO   UPLOAD, HOW TO TRANSFORM, 
HOW
   TO GET ALL THE DIFFERENT   
FORMATS
 IN, HOW TO STREAM OUT  OUT, HOW
 TO
 DISTRIBUTE OVER   THE DATA 
CENTERS,
 ET CETERA,   ET CETERA,. 
ON TOP OF THAT, WE HAVE A SET   
OF
 VERY UNIQUE FEATURES THAT   
DIFFERENTIATE
 YouTUBE FROM   THE OTHER 
SERVICES
 THAT ARE   OUT THERE. 
WHEN I JOINED, WE HAD OUR   MAIN
 SITE,
 YouTUBE.COM.    AND WE WERE 
JUST
 STARTING TO   BUILD THE MAIN 
YouTUBE
 APP   FOR ANDROID AND iPHONE.  
  BUT OVER TIME, IN THE LAST   
THREE
 YEARS, THIS HAS CHANGED   AS 
WELL.
THERE'S MANY MORE   APPS.  WE 
CALL
 THEY WILL   VERTICALS, WHICH WE
 WILL
 TALK   ABOUT A BIT MORE.  AND, 
OF
   COURSE, WE HAVE ALL THE   
PLATFORM
 METRICS. 
SO FOR THE MAIN SITE, ALL THE   
BROWSER
 COMBINATIONS YOU ARE   ALL 
FAMILIAR
 WITH.  AND THEN   WITH THE -- 
WITH
 THE APPS,   THEN WE GOT A LOT 
OF 
  INTERESTING PLATFORMS THAT   
ARE NOT
 IN THE TYPICAL MIX.    SO WE --
 YouTUBE
 RUNS ON TV  TVs, ON SET-TOP 
BOXES,
 ON   PLAY STATIONS; RIGHT?  SO,
   UNFORTUNATELY,
   IN SOME OF   THOSE, WE ARE 
NOT AS
 FAR   ALONG IN AUTOMATION TERMS
.
  AND I REALLY WOULD WANT TO   
REACH
 OUT TO YOU., ANYONE   FAMILIAR 
WITH
 THAT TYPE OF   PROBLEMS AND 
WORKING
 ON THAT,   PLEASE REACH OUT TO 
ME
     AFTER THIS.  I'M REALLY   
INTERESTED
 TO LEARN ABOUT HOW   TO 
AUTOMATE ON
 A TV, FOR   EXAMPLE.

DETAILS,
 AS I SAID, VIDEO   SERVICE, SO 
WE
 ARE CONCERNED   WITH GETTING 
YOUR
 VIDEOS UP,   BE THAT FROM THE 
DESKTOP
 OR   FROM MOBILE.  WE STARTED  
 STREAMING
 LIVE WHEN -- FROM   GAME 
STATIONS,
 WHERE THE   GAMERS CAN STREAM 
UP LIVE.
  WE HAVE LIVE STREAMING, YOU   
MIGHT
 REMEMBER THE BIG   OLYMPICS 
STREAMING
 THROUGH   YouTUBE A FEW YEARS 
AGO.
SO WE GET THE STUFF IN, LOTS   
AND
 LOTS OF PIXELS AND BYTES.    WE
 START
 PROCESSING.  THE   PROCESSING 
TYPICALLY
 HAPPENS   WITHIN THREE MINUTES.
  AND
 IN   THAT TIME, WE GET THE 
FORMATS
   CONVERTED.  WE ARE STILL IN  
 THE
 MODE OF PRECONVERTING, SO   WE 
CONVERT
 AN UPLOAD SO THAT   WHEN YOU 
REQUEST
 A VIDEO, YOU   ACTUALLY -- WE 
ARE
 ACTUALLY   READY TO SERVE OUT 
THE
 FORMAT   THAT YOU NEED. 
WE STORE IT, OBVIOUSLY, AND   
DISTRIBUTE
 IT THROUGH THE   CENTERS.  
LATER ON,
 THE   STREAMING COMPONENT HELPS
 TO
   GET ALL OF THESE PREVIOUSLY  
 GENERATED
 FORMATS OUT IN THE   VARIOUS 
PLATFORMS
 AND DEVICE   FORMATS. 
YOU PROBABLY HEARD ABOUT OUR   
ADAPTIVE
 STREAMING, WHERE   DEPENDING ON
 THE
 NETWORK   SPEED AND THE QUALITY
 OF
 THE   NETWORK YOU'RE ON, YOU 
MIGHT
   CHANGE THE RESOLUTION AND THE
   QUALITY
 OF THE STREAM THAT   COMES IN 
SO THAT
 YOU ON THE   DEVICE GET THE 
BEST POSSIBLE
   EXPERIENCE WITHOUT SEEING THE
   SPINNER
 TOO MUCH, HOPEFULLY,. 
SO AROUND ALL THIS, ON TOP OF   
THAT,
 WE HAVE SOME VERY   SPECIAL 
THINGS
 THAT NOT   EVERYONE KNOWS ABOUT
 OR
   RECOGNIZES RIGHT AWAY WHEN   
YOU
 HEAR &quot;YouTUBE.&quot; 
THE BIGGEST UNIQUE   
DIFFERENTIATOR
 BETWEEN You  YOUTUBE AS A VIDEO
 PLATFORM   AND MOST OF THE 
OTHERS
 IS   THAT WE HAVE THIS FEATURE 
  CALLED
 CONTENTID, A WAY TO   ALLOW 
CREATORS
 TO PROTECT   THEIR CONTENT ON 
YouTUBE
 BY   USING OR UTILIZING THE   
INFORMATION
 ABOUT THE   COPYRIGHTS THEY 
ALREADY
 HAVE;   RIGHT?  SO YOU UPLOAD 
YOUR
   VIDEO.  YOU DO SOMETHING WE  
 CALL
 CLAIM.  SO YOU CALL OUT   THAT 
THIS
 IS YOURS AND YOU   DON'T WANT 
TO SHARE
 THIS WITH   ANYONE.  AND THAT 
ANY
 USAGE   RIGHTS YOU SHOULD BE IN
   CONTROL
 OF,  , ET CETERA, ET   ET 
CETERA,.
INTERESTING PART OF THIS IS   
THAT
 THESE COPYRIGHT RIGHTS   ARE 
HANDED
 OUT BY TERRITORIES  
TERRITORIES, SO
 MEANING IF   YOU OWN A VIDEO 
THAT
 HAS FOUR   OR FIVE COPYRIGHTS 
FOR
 LYRICS   AND LIVE PERFORMANCE 
AND
   DIGITAL STREAMING, ET CETERA,
   ET CETERA,
 IF YOU HAVE THOSE,   SAY, IN 
THE U.S.,
 IT'S NOT   NECESSARILY TRUE 
THAT YOU
   ALSO HAVE THOSE IN OTHER   
COUNTRIES.

USE
 YouTUBE WHILE YOU'RE   
TRAVELING,
 YOU MAY HAVE SEEN,   &quot;THIS 
VIDEO NOT
 AVAILABLE&quot; IN   WHATEVER 
COUNTRY YOU
 HAPPEN   TO BE IN, ALTHOUGH YOU
 JUST
   YESTERDAY WATCHED IT BEFORE  
 YOU
 ENTERED THE PLANE; RIGHT? 
AND THIS IS WHY.  SO THE   OWNER
 OF
 THE VIDEO HAS   MANAGED TO GET 
THE
 COPYRIGHT   IN THE U.S., HAS 
NOT MANAGED
   TO GET IT SOMEWHERE ELSE.    
BUT
 OVERALL, THE CONTENT IS   
PROTECTED,
 SO WHEN WE LOOK AT   THIS AND 
TRY
 TO STREAM THIS,   WE SAY, OKAY,
 UNTIL
 THIS IS   RESOLVED, SORRY, YOU 
CAN'T --
   WE CAN'T HELP YOU ON. 
SO THAT IS, I THINK, THE   
BIGGEST
 DIFFERENTIATOR TO   OTHERS. AND
 BRINGS
 A LOT OF   PEOPLE THAT CREATE 
CONTENT,
   LIKE MUSICIANS, ARTISTS, TO  
 STICK
 WITH OUR PLATFORM. 
NEXT TO THAT, WE HAVE SOCIAL   
COMPONENTS.
YOU CAN COMMENT   ON THE VIDEOS.
  YOU
 CAN INTER  INTERACT WITH YOUR 
FANS,
 FOR   EXAMPLE, IF YOU'RE A 
MUSICIAN
  MUSICIAN.  AND IT'S A PRETTY  
 HIGH-TRAFFIC
 SOCIAL COMPONENT   IN THAT. 
YOU HAVE PERSONALIZATION.    YOU
 MAY
 RECOGNIZE THAT YOU   GET 
RECOMMENDED
 VIDEOS IF YOU   WATCH A CERTAIN
 SET
 OF VIDEOS  VIDEOS, YOU GET   
OTHERS
 THAT   WE THINK YOU MIGHT BE   
INTERESTED
 IN.  THAT IS BASED   ON 
PERSONALIZATION
 ENGINE   THAT LEARNS FROM YOUR 
  BEHAVIOR.
WE HAVE ONE OF THE LARGER   
SEARCH
 COMPONENTS THAT ARE   OUT THERE
.
WHEN I CHECKED   THIS BEGINNING 
OF
 THE YEAR,   WE WERE NUMBER TWO.
  SO
 WE   STILL ARE PROBABLY PRETTY 
  HIGH
 UP THERE. 
THE SEARCH IS, OBVIOUSLY,   
OPTIMIZED
 FOR VIDEO MEDIA.    SO IF YOU 
PUT
 THE SAME SEARCH   INTO 
GOOGLE.COM
 AND DO You  YOUTUBE.COM, YOU 
WILL
 GET   DIFFERENT RESULTS, 'CAUSE
 ON
   OUR SIDE, YOU GET VIDEOS AND 
  NOT
 NEWS REPORTS AND OTHER   THINGS
; RIGHT?
I MENTIONED THE PLATFORMS WE   
ARE
 ON.  IT'S PRETTY MUCH   
ANYWHERE YOU
 CAN THINK OF,   WITH SOME 
TROUBLE
 SPOTS LIKE   I MENTIONED THE TV
s
 AND SET  SET-TOP BOXES.  A 
VARIETY
 OF   BROWSERS, A VARIETY OF   
VERSIONS
 OF ANDROID.  YOU   MIGHT HAVE 
HEARD
 THAT WE HAVE   MORE THAN ONE 
OUT THERE.

A
 VARIETY THERE AS WELL  WELL.  
SO WE
 HAVE THE USUAL   MATRIX OF 
TESTING
 AND   COMPATIBILITY. 
THERE'S LEGISLATION AN ASPECT 
ALSO
 AN ASPECT -- WE   MOVE ON TO, 
REALLY,
 THE USER   INTERFACE, THE 
CLIENT SIDE,
   THERE IS A -- THE CHALLENGE  
 TO
 KEEP IN SYNC THOSE CLIENTS   
WITH
 ALL THE CHANGES THAT   HAPPEN 
ON THE
 MID-TIER THAT   ARE PUSHED ON A
 PRETTY
   FREQUENT BASIS, ET CETERA,. 
WE STARTED OUT WITH JUST   
BROWSER,
 AS I MENTIONED.  AND   BY NOW, 
WE
 NOT ONLY HAVE WHAT   WAS ON THE
 BROWSER
 BEFORE ON   THE MOBILE 
PLATFORMS IN
 OUR   YouTUBE APP, BUT WE ALSO 
  DIVERSIFIED AND HAVE NOW MORE 
  APPS
 NEXT TO EACH OTHER;   RIGHT?  
WE CALL
 THEM THE   VERTICALS.  ONE 
VERTICAL
 THAT   WAS PRETTY POPULAR 
THROUGH
   THIS YEAR WAS MUSIC.  WE   
LAUNCHED
 A MUSIC APP, WHERE   YOU GET AN
 OPTIMIZED
 ACCESS   THROUGH THE INTERFACE,
   OPTIMIZED
 ACCESS TO THE SUB  SUBSET OF 
THE CORPUS
 THAT IS   MUSIC-RELATED. 
WE HAVE A SPECIAL APP FOR   KIDS
 THAT
 HAS A VERY UNIQUE   UI.  IF YOU
 EVER
 LOOKED AT   THIS, IT'S VERY 
DIFFERENT,
   OBVIOUSLY TARGETED FOR KIDS, 
  FOR
 YOUNG PEOPLE.  A LOT OF   
PARENTAL
 CONTROL IN THAT.  A   LOT OF 
RESTRICTIONS.
A LOT   OF SCRUTINY. 
JUST RECENTLY, WE LAUNCHED   OUR
 GAMING
 APP THAT, AGAIN,   HAS -- IT'S 
THE
 SAME IDEA;   RIGHT?  JUST 
PROVIDE
 A VERY   UNIQUE ACCESS TO A SUB
SET
 OF   THE CORPUS.  AND THE 
GAMERS 
  SEEM TO LOVE IT.

THIS
 ENGINE ACTUALLY DOES,   WHAT 
THIS
 MACHINE ACTUALLY   DOES, IF YOU
 HAVE --
 RIGHT   NOW WE'RE LOOKING ABOUT
 300
   HOURS OF UPLOADS PER MINUTE. 
   SO
 ALL OF THESE NOW IN A HUGE   
AMOUNT
 COMING FROM MOBILE,   ALL OF 
THESE
 VIDEOS COME IN   IN ABOUT A 
DOZEN
 FORMATS.  WE   TRANS   
TRANSPOSE THEM,
 WE STORE THEM  THEM, ET CETERA,
. 
WE HAVE ACQUIRED QUITE A BIT   
OF CORPUS
 BY NOW.  IT'S IN   THE BILLIONS
 OF
 VIDEOS.  AND,   OF COURSE, 
THERE IS
 THIS --   IF YOU SAY, YOU KNOW 
--
 TALK   OF THE LONG TAIL.  IF 
YOU SAY
   USERS OVER HOW MANY VIDEOS   
THEY
 ACTUALLY UPLOAD, RIGHT,   
THERE'S
 ONLY A FEW THAT HAVE   
THOUSANDS OF
 THEM.  THEN   THERE'S LOTS AND 
LOTS
 WHO   HAVE ONE OR TWO OR THREE.

 WATCHED.
BUT, STILL, THEY'RE   IN THE 
CORPUS.
WE STORE THEM  THEM, WE 
REPLICATE THEM,
 WE   MOVE THEM.  LOTS OF FUN. 
STREAMING.  YOU HAVE HEARD   
MAYBE
 ABOUT SOME OF THE   HIGHLIGHTS.
  WE
 HAD THE   OLYMPICS A FEW YEARS 
AGO.
WE   HAD THE SPACE JUMP.  THAT 
WAS
   OUR PEAK OUTBOUND STREAM OF  
 SEVERAL
 TERABYTES PER SECOND.    SO WE 
HAVE
 LOTS OF USERS THAT   USE -- 
THAT,
 YOU KNOW,   CONSUME THE MEDIA. 
 WE
   BRIDGED THE 50% MARK OR WE   
STEPPED
 OVER THE 50% MARK OF   MOBILE 
USAGE,
 SOMETHING I   PERSONALLY 
COULDN'T
 IMAGINE   TO HAPPEN.  BUT WE 
HAVE
 HALF   OF THE TRAFFIC NOW 
COMING 
  FROM MOBILE DEVICES; RIGHT?   
 SO
 HALF OF ALL VIDEOS ARE   
WATCHED AND
 CONSUMED ON --   NOT ON THE 
DESKTOP.

THAT
 KIND OF A LITTLE SUB  SUBSYSTEM
 THAT'S
 HUMMING OUT   THERE IS THAT AS 
YOU
 GO TO   THE SITE AND YOU SEE 
THE 
  VIDEOS, YOU ALWAYS GET THESE  
 LITTLE
 THUMBNAILS NEXT TO THE   VIDEOS
; RIGHT?
WHICH IS   BASICALLY AN IMAGE 
SERVER
   THAT SERVES ABOUT 2 MILLION  
 IMAGES
 PER SECOND.  JUST   NOTEWORTHY,
 I
 THOUGHT. 
I TALKED A BIT ABOUT THE   
CONTENT
 SYSTEM.  SO WE HAVE   LOTS OF 
PEOPLE
 WHO USE THAT.    WE CALL THEM 
OUR
 PARTNERS.    MORE THAN 8,000 
INDIVIDUALS
   OR GROUPS THAT MAKE USE OF   
THAT,
 MAKE QUITE A BIT OF   MONEY 
WITH THAT.
AND WE PAID   OUT -- THIS IS THE
 NUMBER
 OF   LAST YEAR.  WE PAID OUT 
OVER
   A BILLION DOLLARS TO THOSE   
OWNERS
 AND RIGHTSHOLDERS. 
SO THIS IS THE SYSTEM I'M   
LIVING
 IN.  AND WHAT WE ARE   GOING TO
 TALK
 ABOUT A BIT IN   THE NEXT HALF 
HOUR
 PROBABLY   IS SOME OF THE 
THINGS THAT
 WE   WE -- THAT I RAN IN IN THE
   LAST
 THREE YEARS AND THAT WE   
TACKLED
 AND ACTUALLY SOLVED.    OR, 
LET'S
 SAY, OUR -- SOME OF   THEM WE 
ARE
 STILL IN THE   PHASE OF SOLVING
 THEM,
 IN THE   PROCESS OF SOLVING 
THEM.
I DON'T THINK ANY OF THESE IS   
NOT
 FAMILIAR -- YOU'RE NOT   
FAMILIAR
 WITH.  YOU'VE ALL   HEARD THOSE
.
EVERYONE HAS   THEIR OWN 
SOLUTIONS
 TO THIS.    I HOPE THIS WILL BE
 SOME
   INSIGHT IN THIS. 
THE FIRST TOPIC IS WHAT DO   YOU
 DO
 IN AN AREA WHERE YOUR   
LAUNCHES ARE
 JUST NOT CLICK  CLICKING ALONG 
THE
 CLOCK AS   YOU WANT THEM TO.  
RIGHT?
  SOME TAKE LONGER.  SOME GO   
OKAY.
BUT YOU CAN'T REALLY   FOR SURE 
PREDICT,
 OKAY,   TOMORROW OR IN THREE 
DAYS
 OR   WHATEVER YOUR SCHEDULE IS 
  THAT
 YOU WILL ACTUALLY HIT   THE 
CLOCK
 AND YOUR LAUNCH IS   READY. 
THE SECOND IS A BIT ABOUT OUR   
MOBILE
 DEVICE LANDSCAPE.  I   
MENTIONED THAT
 ALREADY.  SO A   BIT MORE 
DETAIL THERE.

TECHNICAL
 OR TOOLING QUESTION  QUESTION, 
ALTHOUGH
 WE ALSO   TRY TO SOLVE THIS IN 
A TOOL
  TOOL-BASED APPROACH.  HOW DO  
 YOU
 CHANGE A TEAM'S   DEVELOPMENT 
CULTURE
 FROM VERY   FAST, ALMOST START
UP-LIKE,
   INTO A MORE MATURE, PROCESS- 
 PROCESS-ORIENTED,
 QUALITY-  QUALITY-ORIENTED TEAM
, 
  WITHOUT LOSING THE SPEED AND  
 ITERATION
 SPEED THAT YOU HAVE   IN THE 
STARTUP
 PHASE. 
ALL RIGHT.  UP FIRST. 
SO HERE WE WERE A FEW YEARS   
AGO,
 HAVING A VERY SIMPLE   IDEA, OR
 AT
 LEAST AN IDEA   THAT SOUNDED 
PRETTY
 SIMPLE ON   PAPER. 
AFTER WE UPLOAD AND -- THE   
INITIAL
 STORE OF THE VIDEO   THAT YOU 
SEND
 US, WE CREATE   LOTS AND LOTS 
OF FORMATS,
 AND   THEN WE STORE IT.  AND I 
  ALREADY
 MENTIONED, SOME OF   THEM ARE 
NEVER
 WATCHED.    RIGHT? 
SO PRETTY STRAIGHTFORWARD   IDEA
 IS
 TO SAY, WELL, WHY   DON'T WE 
TRANSFORM
 THEM WHEN   WE STREAM THEM?  
AND WE
 KNOW,   ACTUALLY, AT LEAST 
SOMEONE,
   THERE'S AT LEAST ONE REQUEST 
  FOR
 IT; RIGHT?  AND THEN WE   START
 TRANSFORMING.
AND THEN   WE START STORING, AND
 YOU
 GO   ON FROM THERE.  YOU COULD 
  SAVE
 PROBABLY LOTS OF STORAGE   
SPACE.
WE COULD PROBABLY   SAVE LOTS OF
 PROCESSING
 TIME   DURING UPLOAD, SO YOUR 
VIDEO
   MIGHT BE READY EARLIER.    
SOUNDED
 LIKE THERE IS NOT   THAT MANY 
NEGATIVE
 POINTS TO   THIS, NEGATIVE 
THINGS
 TO THIS  THIS. 
SO WE CAME UP WITH AN IDEA   
THAT WE
 CALL, ON-THE-FLY   TRANSCODING,
 WHICH
 MEANS   EXACTLY THAT.  ON 
REQUEST,
   YOU START, AND THEN YOU   
STREAM
 OUT.  LOTS OF CHANGES.    SOME 
REALLY
 VIDEO-SPECIFIC   TECHNICAL 
CHALLENGES.
BUT   WHAT I WANT TO TALK ABOUT 
IS
   THIS.  DON'T WORRY.  YOU   
DON'T --
  THERE'S NO TEST ON   THIS.  
JUST
 TRYING TO GIVE   YOU AN IDEA OF
 A
 SYSTEM THAT   HAS LOTS OF 
COMPONENTS,
 SOME   DEPENDENCIES IN BETWEEN 
THEM,
   NOTHING NEW. 
WHAT MADE IT HARD WAS, THESE   
COMPONENTS
 WERE DISTRIBUTED   OVER A SET 
OF OFFICES.
AND   YOU SEE THESE LITTLE LINES
   SHOWING
 THROUGH THE BOXES.    SO THERE 
WAS --
 THERE WERE   DEPENDENCIES 
BETWEEN
   COMPONENTS OWNED IN DIFFERENT
   SITES.
SO COMMUNICATION WAS A   PROBLEM
.
COMPLETE   INDEPENDENCE OF 
OWNERSHIP
 OF   THE COMPONENT WAS A BIT OF
 A
   PROBLEM.  THAT WAS ONE   
DIMENSION.

 WE
 LOOKED AT HOW THESE   
COMPONENTS ARE
 ACTUALLY BUILT   AND MADE READY
 TO
 LAUNCH, SO   HOW THE 
CORRESPONDING
   BINARIES WERE CREATED, WE   
FOUND
 A PICTURE THAT, AGAIN,   HAD, 
OKAY,
 SOME LOCALLY, AT   LEAST, 
CONTAINED
 RELEASES,   BUT THERE'S MORE 
THAN
 ONE,   WHICH MEANS, AGAIN, NOW 
YOU
   SEE THE LINES BETWEEN THE RE 
 RELEASE
 BINARIES.  WE HAVE   
DEPENDENCIES
 ON NOT ONLY   CONTENT, BUT NOW 
ALSO
 ON   SCHEDULE.  RIGHT?  SO WHEN
   OUR
 FRONT-END WANTS TO PUSH   AND 
THE
 MID-TIER, THE STORAGE  STORAGE,
 SAY,
 IS NOT QUITE   READY, THEN WHAT
 DO
 WE DO?    RIGHT? 
NO SURPRISE IN WHAT THAT   
RESULTED
 IN; RIGHT?  EVERYONE   HAS SEEN
 THESE
 PICTURES.  WE   START CODING.  
WE
 GET A   RELEASE FINALLY READY 
AND
 PUT   IT IN AN AREA WHERE 
OTHERS 
  CAN ACCESS IT; RIGHT?  SO THE 
  OTHER
 GUY COMES IN, PUTS IN   HIS 
CODE,
 STARTS TO BRING IT   TOGETHER. 
 AND,
 OH, DIDN'T   THINK OF THAT.  
OKAY.
HAVE   TO GO BACK.  WHILE I'M 
GOING
   BACK AND DO SOME FIXES, THE  
 THIRD
 COMPONENT COMES IN;   RIGHT?  
SO WE'RE
 GETTING   THROUGH THE TYPICAL 
WATERFALL
   MODEL OF -- OF BUILDING LARGE
   SYSTEMS;
 RIGHT?  AND I THINK   THERE IS 
ONE
 MORE EXPLOSION   THERE.  YEAH. 
[ LAUGHTER ]  
THIS IS WHEN WE WANTED TO   
LAUNCH,
 OR A FEW DAYS AFTER;   RIGHT? 
SO EVERYONE HAS SEEN THESE   
PICTURES;
 RIGHT? 
THE PROBLEM WAS, OKAY, HOW DO   
WE
 DO THIS?  RIGHT?  WE HAVE   THE
 NEED,
 OBVIOUSLY, FOR   SOMETHING THAT
 CAN
 BE USED IN   ALL THE 
ENVIRONMENTS
 THAT WE   USE IN DEVELOPMENT.  
SO
 THAT   IS MY OWN WORKSTATION, 
KIND
   OF MY LOCAL DEVELOPMENT   
ENVIRONMENT
 THAT IS THE --   ANY STAGING 
TESTING
   ENVIRONMENT THAT WE BUILD UP 
  WHERE
 OTHERS ARE ALREADY   
PARTICIPATING
   WHERE I BUILD   UP.  AND, 
OBVIOUSLY,
 FINALLY,   IT HAS TO WORK IN 
REAL
 LIFE,   WHAT WE CALL WORK OUT B
ORG
 OUT THERE.        WE WANTED TO 
MAKE
 SURE   THAT EACH INDIVIDUAL   
ENVIRONMENT
 IS HERMETIC AND   HAS NO 
DEPENDENCIES
 ON OTHERS  OTHERS.  SO THAT WAS
 THE
   BIGGEST PROBLEM. 
WE WANTED TO BE ABLE TO BUILD   
IT
 FROM HEAD, SO NO DELAYS,   
WHATEVER
 CURRENT CODE IS   SHOULD BE 
MOVED
 FORWARD.  WE   WANTED  DISAGREE
 RUN-
 ZERO RUN-TIME   DEPENDENCIES. 
WE ALSO WANTED TO MAKE SURE   TO
 TAKE
 CARE OF ONE AREA OF   OF -- ONE
 SOURCE
 OF PROBLEMS   WE RAN INTO QUITE
 A
 BIT IS   WHEN WE MOVED   FROM 
OUR
   STAGING AREAS INTO THE   
PRODUCTION
 AREA.  THERE WAS A   SHORT, 
SMALL
 CONFIGURATION   FILE THAT 
DESCRIBED
 EXACTLY   HOW THE DIFFERENT 
SERVERS
 AND   THE DIFFERENT CPUs WERE 
CON
  CONFIGURED AND WHAT   
PRIORITIES THEY
 HAVE, ET   ET CETERA,.  FOR 
LIVE 
  PRODUCTION; RIGHT? 
AND IN WAY TOO MANY CASES, WE   
GOT
 INTO A PROBLEM WHERE   
EVERYTHING
 WORKED FINE ON   STAGING; RIGHT
?
BUT,   ESSENTIALLY, NO ONE 
BELIEVED
   THAT WE ARE REALLY DONE UNTIL
   WE
 OBSERVE THE SAME BEHAVIOR   
REALLY
 IN LIVE, BECAUSE THERE   WERE 
SOME
 I'M NOT QUITE SURE   HOW WE MAP
 THIS.
SO WHEN WE STARTED OUT, WE   
THOUGHT,
 LET'S TRY AND GET   RID OF THAT
 PROBLEM,
 GET RID   OF THAT INSECURITY.  
LET'S --
   LET'S SEE IF WE CAN BUILD A  
 SYSTEM
 THAT IS ABLE TO LOOK   EXACTLY 
THE
 SAME IN OUR TEST   ENVIRONMENT,
 AT
 LEAST IN THE   LARGER ONES, AND
 THEN
 WHEN WE   SWAP OVER, WE DO NOT 
TOUCH
   THE CONFIGURATION. 
ONE SECOND. 
AND, OF COURSE, YOU KNOW,   
COMING
 FROM WHERE WE'RE   COMING FROM,
 WE
 WANTED THIS   TO BE TEST ORIENT
ED
 RIGHT.    SO WE WANTED TO BE 
CONSISTENT
  CONSISTENTLY DESIGNED FOR   
TESTABILITY
 FROM THE GET-GO. 
AFTER ALMOST TWO YEARS WHERE   
WE CREATEED
 THE SYSTEM, WHAT   WE HAVE 
RIGHT NOW
 IS REALLY A   SYSTEM WHERE 
WE'RE ALL
 THESE   VARIOUS BOXES THAT I 
HAD ON
   THE INITIAL PICTURES, THAT'S 
  ABOUT
 200 DIFFERENT SERVICES   OWNED 
BY
 DIFFERENT GROUPS.    SOME OF 
THEM
 IN YouTUBE.    SOME OF THEM IN 
GOOGLE
 THAT   WE MAKE USE OF.  WE HAVE
 ONE
   ENVIRONMENT WHERE WE ACTUALLY
   CAN
 DEVELOP AND TEST ALL OF   THESE
 COMPONENTS
 TOGETHER. 
A NICE SIDE EFFECT WAS THAT   
THE ENGINEERS
 WERE -- ARE NOW   SO INVOLVED 
IN WORKING
 ON   THIS SYSTEM THAT THERE IS 
  REALLY
 NOT THAT BIG A   DIFFERENCE 
ANYMORE
 BETWEEN   DEVELOPING AND 
TESTING,
 RIGHT  RIGHT? 
AND IT WAS ALMOST A SIDE   
EFFECT.
WE SAID, YES, WE   WANTED THE 
SYSTEM
 TO BE -- TO   BE TARGETED FOR 
TESTABILITY,
   WANTED TO BE EASY TO BE TEST 
 TESTED
 ON.  BUT THE WAY IT   LOOKS 
RIGHT
 NOW IS WORKING IN   THIS 
ENVIRONMENT
 IS -- EQUALS   TO TESTING WHICH
 IS
 GREAT. 
ALSO, THERE IS NO SEPARATE   
INTEGRATION
 FAZE ANYMORE PHASE ANYMORE.    
ONCE
 YOU COMMIT YOUR CODE, IT   IS 
DEPLOYED
 IN THIS   INFRASTRUCTURE AND 
YOU LIVE
   IN THAT BIG SYSTEM SO WE SAVE
   THE
 WHOLE STACK.  AND WE   ACTUALLY
 HIT
 THE NO SURPRISE   OBJECTIVE 
THAT WE
 SET   OURSELVES TO SAY WHEN WE 
  SWITCH
 OVER WE DON'T HAVE TO   CARE.  
WE
 CAN USE EXACTLY THE   
CONFIGURATION
 FROM THE LIVE   SYSTEM. 
IF YOU REMEMBER THE LITTLE   
EXPLOSION
 CHART I HAD BEFORE,   RIGHT, SO
 WE
 HAD A --   HONESTLY UN
PREDICTABLE
   RELEASE   CALENDAR.  BECAUSE 
OF SO
 MANY   DEPENDENCYIES WE WERE 
BASIC
  BASICALLY CONTINUEOUSLY   
PUSHING.
WHENEVER SOMETHING   WAS READY 
-- WHENEVER
 THE   PUSH WAS READY, WE 
STARTED 
  OVER THE NEXT ONE AND WORKED  
 OUR
 WAY THROUGH. 
AND WE WENT UP TO SOMETIMES   
THREE,
 FOUR, SOMETIMES FIVE   WEEKS IN
 REALLY
 BAD CASES. 
AND WHAT WE GOT TODAY IS A   
SYSTEM
 WHERE WE HAVE NIGHTLY   BUILDS 
THAT
 ARE READY FOR   CONSUMPTION, IF
 WE
 CHOOSE TO   DO SO.  AND THE 
MAIN REASON
   FOR THIS IS REALLY POINT TWO 
  AND
 THREE.  THERE IS ALMOST   NO 
DIFFERENCE
 BETWEEN   DEVELOPMENT 
ENVIRONMENT
 AND   TEST ENVIRONMENT.  AND   
WHENEVER
 YOU ARE DONE   DEVELOPING, YOU 
ALSO
 KNOW   THAT IT'S ACTUALLY 
WORKING
   AND WE CAN PUSH THIS OUT.  SO
   WE
 ARE ON A MOSTLY DAILY --   WE 
DON'T
 HIT EVERY DAY BUT   MOST OF THE
 DAYS
 WE GOT A   SUCCESSFUL BUILD.  
NOT
 THAT   IT'S PUSHED NECESSARILY 
INTO
   LIFE EVERY DAY, BUT IT IS   
SOMETHING
 READY.  WHICH MAKES   MAKES -- 
HAS
 USUALLY POSITIVE   IMPACT, 
CONSEQUENCES,
 RIGHT?    SMALL DELTAS IN CODE 
CHANGES
   FROM DAY TO DAY.  IF   
SOMETHING
 COMES UP, THERE IS   A SMALL 
SCOPE
 TO LOOK FOR BUG  BUGS, ET 
CETERA.
ALL THE   WELL-KNOWN THINGS. 
SO THAT WAS PRETTY -- WE WERE   
PRETTY
 HAPPY ABOUT THAT AND   STILL 
WORKING
 NOW TO GET THIS   COMPLETELY 
100%
 FOR ALL THE   200-PLUS SERVICES
, A
 FEW   STRAGGLEERS ARE OUT THERE
, 
  TAKE A BIT LONGER.  BUT WE   
PLAN
 TO HAVE THIS REALLY   READY AND
 AVAILABLE.
SO THAT WAS PRETTY HAPPY   STORY
.
AND IT TOOK US ABOUT   TWO YEARS
 TO
 GET THROUGH THIS  THIS, RIGHT? 
 TO
 BUILD THIS   WHOLE 
INFRASTRUCTURE
 INTO   WHICH TO DUMP THESE   
COMPONENTS.

NOW,
 YOU KNOW, IT'S UNBELIEVE  
UNBELIEVABLE
 THE AMOUNT OF   TIME EVERYONE 
SAVES
 BY NOT   GOING TO WAIT FOR 
SOMETHING
   OR TO LOOK IN A PILE OF CODE 
  THAT
 IS OLD FOR CHANGES THAT   MAY 
OR MAY
 NOT IMPACT THE   CURRENT THING.

ONTO THE NEXT TOPIC.  MOBILE.   
 SO
 IF YOU RECALL, WE HAVE   THIS, 
QUOTE-UNQUOTE,
 MATRIX   THAT I HAVE TO CARE 
ABOUT
 ON   THE CLIENT TIER.  WHILE 
THE 
  MIDTIER AND THE BACKENDS ARE  
 PRETTY
 WELL MOVEING ON A DAILY   CLICK
 WITH
 NEW PUSHES FOR THE   LIVE SITE,
 IF
 YOU LOOK AT THE   STATE OF APPS
 THAT
 WE NOW   HAVE, IT'S A SLIGHTLY 
  DIFFERENT
 STORY. 
ONE, WE HAVE TO MAKE SURE   THAT
 ANY
 OF THE MID-TIER AND   BACKEND 
CHANGES
 KEEP ALIVE   ALL THE VARIANTS 
WE HAVE
 OUT   THERE.  SO ON THE BROWSER
   SIDE,
 THAT'S EASY BECAUSE WE   PUSH 
THAT
 AS A WHOLE STACK   AND THEY'RE 
IN
 SYNC BY   DEFINITION.  BUT FOR 
ANDROID
   APPS, iPHONE APPS, FOR THE   
TV
 APPS WHERE WE HAVE NO   CONTROL
 OF
 WHEN THEY ARE   ACTUALLY 
SHIPPED OUT
 FOR XBOX   OR PS2, THEY HAVE 
REALLY
 LONG   DEVELOPMENT CYCLES OR 
LAUNCH
   CYCLES, RATHER, WE HAVE TO   
MAKE
 SURE THAT WHATEVER WE   SHIP A 
YEAR
 AND A HALF AGO IS   STILL 
WORKING
 WITH TOMORROW'S   UPDATE OF THE
 LIVE
 SITE. 
THAT BRINGS WITH IT A WHOLE   
NEW DIMENSION
 OF TEST MATRIX,   IF YOU WANT. 
 WE
 CALL IT   COMPATIBILITY OF 
WHAT'S
 OUT   THERE TO WHAT WILL BE   
AVAILABLE
 TOMORROW IN THE   SERVERS. 
THE WAY WE TACKLEED THAT WAS   
LIKE
 THIS.  SO HERE'S' A   STACK OF 
VARIOUS
 DEVELOPMENT   AND/OR TEST 
ENVIRONMENTS
   INCLUDING THE PRODUCTION   
SYSTEM.
MOST OF THEM WE HAVE   IN 
MULTIPLE
 VARIANTS.  AND   THE CHALLENGE 
WAS
 HOW TO GET   THE APPS PLATFORMS
 CONNECTED
   TO THESE INTEGRATION   
ENVIRONMENTS
 OR TEST   ENVIRONMENT.S.S ON ON
 A
 NOT   MANUAL AND NOT 
NECESSARILY 
  HARDWARE-DEVICE BASE IDEALLY. 
   YOU
 DON'T WANT JUST -- WE   HAVE 
MAYBE
 200 DEVELOPERS IN   THAT GROUP 
RUNNING
 AROUND   WITH TEN DEVICES EACH 
TO
   FIGURE OUT WHAT WORKS AND   
WHATNOT.
SO WHAT WE DID, USUAL   APPROACH
, TWO
 PARTS, RIGHT?    WE HAVE A 
HARDWARE
 LAB THAT   HAS A FEW HUNDRED 
DEVICES
   THAT ARE CENTRALLY MANAGED,  
 CREATEED,
 KEPT UP AND RUNNING   THAT YOU 
CAN
 AS A DEVELOPER   CAN LOG INTO 
AND
 EXERCISE   YOUR TEST OR SEE A 
CHANGE.
  AND THEY CAN CONNECT TO ONE   
OR MORE
 OF THOSE DEVELOPMENT   
ENVIRONMENTS
 OR TEST   ENVIRONMENTS. 
NEXT TO THAT -- SO THESE ARE   
AS CLOSE
 AS TAKING A TABLET   AND START 
TAPPING,
 RIGHT?    NEXT TO THAT WE HAVE 
THE
   EMULATOR SET FOR -- AT LEAST 
  FOR
 THOSE WHERE WE HAVE   EMULATORS
.
SO FOR ANDROID,   iOS. WE HAVE 
MACHINES
 THAT DO   EXACTLY THE SAME.  
THAT'S
   MAINLY THE BASIS FOR ALL OF  
 THE
 ATED TESTS. AUTOMATEED TESTS.  
WHAT
 WE   ARE STILL WORKING ON WITH 
A 
  BIT OF PROGRESS BUT HAVE   
QUITE A
 BIG SPOT ON THE MAP   TO STILL 
COVER
 IS WHAT I HEAR   CALL DEDICATED
 HARDWARE
 FOR,   CALL THEM, NON-STANDARD 
  DEVICES,
 RIGHT? 
SO TVs, FOR EXAMPLE, IS   HARD 
BECAUSE
 I HAVEN'T FOUND   A GOOD ANSWER
 TO
 AUTOMATE ON   A TV FOR SOME 
LINUX
   DERIVATIVE THAT IS -- SURE,  
 YOU
 COULD AUTOMATE IT, RIGHT?    
IT'S
 A HUGE EFFORT.  BUT THEN   WHAT
 DO
 YOU DO WITH THE NEXT   TV AND 
THE
 TVs SEEM TO POP   UP EVERY 
HOLIDAY
 SEASON. 
SO OPEN QUESTION.  WE HAVE   ONE
 FOR
 THE SUBSET OF ALL THE   DEVICES
 WHERE
 WE HAVE TO RUN   THAT ARE -- 
THAT
 HAVE A VIDEO   OUT CARD, WHERE 
WE
 INTERCEPT   THAT AND DO 
COMPARISON --
   SNAPSHOT COMPARISON, THAT   
WORKS
 PRETTY WELL.  BROUGHT   US TO 
THE
 POINT WHERE, FOR   EXAMPLE, FOR
 HTML5
 BROWSERSES   ON TVs, WE CAN FOR
 EVERY OF   THE A DAILY BUILDS 
WE RUN
 A   SMOKE TEST
 THAT DOES THIS,   RIGHT?
AND ALTHOUGH XBOX IS   KIND OF 
THE
 SAME STORY   UNDERNEATH, XBOX 
HAS
 AN   EXTREMELY LONG LAUNCH 
CYCLE.
  SO WE COULD -- WE HAVE SAID   
BEFORE,
 WELL, WE CARE ABOUT   ALL OF 
THIS
 WHEN IT COMES   CLOSEER TO THE 
HOLIDAYS,
 RIGHT  RIGHT, WHEN THERE'S AN 
UPDATE
  UPDATE. 
BUT IN JANUARY, FEBRUARY,   
MARCH NO
 ONE REALLY CARED   ABOUT THIS 
YET.

EVERYONE
 CYCLE OF THE BACKEND  BACKEND, 
WE
 CREATE THE   CORRESPONDING 
BUILD AND
 WE   HAVE THROUGH THESE 
DEDICATED
   HARDWARE SETUPS SOME WAY TO  
 SMOKE
 TEST THOSE AND SAY, AT   LEAST 
EVERYTHING
 IS STILL   RUNNING WITH THE 
VERSION
 WE   SHIPPED.  WHICH IS NICE.  
BUT
  BUT, AS I SAID, THIS IS A   
TOPIC
 I'M REALLY INTERESTED   IN 
TALKING
 TO SOME OF YOU   HOPEFULLY. 
ALL RIGHT.  AND THEN LASTLY   
LASTLY --
 SO, NO, THIS IS A   SUMMARY OF 
WHERE
 WE GOT HERE.    ALL PLATFORMS 
INCLUDING
 THOSE   WEIRD ONES, WE HAVE 
FOUND
 A   WAY TO VALIDATE AT LEAST   
EVERY
 DAILY PUSH.  SO AT   LEAST NOW 
WE
 ARE NOT BREAKING  BREAKING.  
HAVE
 AUTOMATEED   SMOKE TESTS FROM 
THOSE.
AND   BECAUSE WE NOW HAVE THE   
AUTOMATION
 PLATFORMS, THE   AMOUNT OF 
TESTING
 THAT WAS   MANUAL WAS REDUCED  
 DRAMATICALLY.
AND I'M NOT AN   ADVOCATE FOR 
NOT HAVING --
   TOO MANY &quot;NOTES&quot;.&quot;  I'M AN   
ADVOCATE
 FOR HAVING MANUAL   TESTS. 
[ LAUGHTER ] 
TOO MANY NEGATIONS.  I'M AN   
ADVOCATE
 FOR HAVING MANUAL   TESTING.  
IT SHOULD
 BE   EXPLORATORY TESTING, NOT  
 SCRIPTED
 REGRESSION TESTS.    SO WANT TO
 SPEND
 EVERY DAY   WHEN I CREATE A NEW
 DRIVER
 X   NUMBERS OF HOURS TO JUST 
MAKE
   SURE EVERYTHING WORKS, RIGHT?
  I WANT TO SPEND THAT EFFORT   
AND
 ENERGY ON THE NEW FEATURE   
THAT IS
 WE DEVELOPED, MAKE   SURE 
THEY'RE
 OKAY. 
AND WITH THE PLATFORMS WE   HAVE
 NOW,
 WE WERE ABLE AND WE   GOT A BIT
 MORE
 OF THAT LATER   LATER -- WE 
WERE ABLE
 TO CUT   THE AMOUNT OF MANUAL 
TESTS
   NEEDED ON THOSE DEVICES TO 50
  50%
 WHILE -- COMPARED TO A   YEAR 
AGO
 WHILE WE WERE ADDING   THREE 
DIFFERENT
 APPS.  SO IT   WAS PRETTY 
DRAMATIC
 REDUCTION  REDUCTION. 
THE LAST TOPIC I WANT TO TALK   
A BIT
 ABOUT IS WHAT I CALL   THE 
CULTUREAL
 CHANGE.  SO WITH   ALL THIS 
AUTOMATION --
 SO   STEP BACK.  THREE, FOUR 
YEARS
   AGO WHEN WE TALKED ABOUT   
TESTING
 AT YouTUBE, IT WAS   A HUGE 
AMOUNT
 OF MANUAL WORK.    RIGHT?  EVEN
 WHEN
 WE HAD ONLY   THE LIVE SITE -- 
THE
 SITE,   THE BROWSERS-BASED 
CLIENTS,
   IT WAS A HUGE AMOUNT OF   
MANUAL
 TESTING.  WE DID UNIT   TESTS, 
YES.
WE DID SOME   INTEGRATIONS.  BUT
 MOST
 OF   THE END-TO-END WAS DONE   
MANUALLY.

INTRODUCE
 THESE PLATFORMS,   YOU ALSO 
WANT TO
 INTRODUCE A   CULTURE WHERE 
EVERYONE
 KNOWS   THESE PLATFORMS AND 
KNOWS
   WHAT TO DO OF THEM.  AND IT'S
   AS
 EASY AS POSSIBLE FOR   SOMEONE 
TO
 PICK THOSE UP AND   LEARN THAT.
  SO
 THAT EVERY   DEVELOPER ACTUALLY
 HAS
 AN   EASY WAY TO GET TO THE   
PLATFORMS
 AND DO THE JOB, THE   TESTING 
JOB.
SO AS AN ORGANIZATION, WE   
DECIDEED,
 OKAY, QUALITY IS A   THING NOW.
  WE
 NEED TO   SOMEHOW GET TO A 
BETTER
 LEVEL   OF WHERE WE ARE.  WE 
WANT
 TO   REDUCE MANUAL.  BUT WE 
ALSO 
  AT THE SAME TIME DO NOT WANT  
 TO
 INCREASE BUGS OBVIOUSLY.    
RATHER
 REDUCE THEM. 
WE LOOKED AT WHERE WE ARE,   AND
 THIS
 WAS ABOUT 18 MONTHS   AGO OR SO
 WHEN
 WE -- 18   18 MONTHS AGO WHEN 
WE SET
 OUT   TO DO THIS.  AND WE TOOK 
A 
  SNAPSHOT OF WHERE WE ARE   
TODAY.
A NUMBER OF PARTNER   SELECT, 
PUN BUGS
 OUT BUG OF P0, P1   BUGS.  HOW 
MANY
 DO WE FIND   HERE, THE TYPICAL 
ANALYSIS,
   WE GO THERE. 
WE LOOKED AT IT AND CAME UP   
WITH
 METRICS OF WHAT WE   ACTUALLY 
WANT
 TO LOOK AT ON A   CONSISTENT 
BASIS
 AND WHAT SLA  SLAs ARE WE 
SETTING
   OURSELVES.  WHAT'S OUR GOAL? 
   IF
 WE NOW HAVE 20P0s   HAPPENING 
IN
 A WEEK, IS THAT   GOOD, IS THAT
 BAD?
WHAT DO   YOU WANT TO DO ABOUT 
IT?
IS   THAT THE NEW GOAL? 
WE STARTED PRETTY SIMPLE.    
WHERE
 WE ARE, WE CUT   EVERYTHING IN 
HALF
 WITHIN TWO   QUARTERS AND SEE 
WHERE
 WE   COME WITH THIS.  HAVE TO 
HAVE
   A GOAL. 
TO WE SET THE SLAs.  THE   NEXT 
PROBLEM
 THEN WAS HOW DO   WE TALK ABOUT
 THESE?
HOW   DOES EVERYONE KNOW WHERE 
WE 
  ARE AND SPECIFICALLY WHERE   
THE TEAM
 IS THAT I'M PART OF,   RIGHT?  
AM
 I DOING OKAY?  AM   I IMPROVE
ING?
AM I SLACKING?    WHAT? 
SO WE WANTED IN ORDER -- WE   
THOUGHT
 IN ORDER TO GET THESE   GOALS 
RIGHT,
 WE NEED A TOOL   THAT ALLOWS US
 TO
 LOOK AT OUR   METRICS ACROSS 
THE BOARD
 AND   BE ABLE TO DRILL DOWN, GO
 AS
   BIG SCOPE AS YOU WANT OR AS  
 DID
 HE GRANULAR AS YOU WANT   AND 
SAY,
 THE ORGANIZATION   ITSELF LIKE 
THIS,
 THIS TEAM   IS DOING HERE
   AND FIND
 OUT WHO IS DOING   WELL, HOW 
CAN WE
 LEARN, HOW   CAN WE TRANSFER 
BEST
   PRACTICES. 
WE ALSO THOUGHT ABOUT THE   
DIFFERENT
 TYPES OF WHAT   QUALITY COULD 
MEAN,
 RIGHT?    THERE IS OBVIOUSLY 
THE 
  PRODUCT QUOTE, RIGHT?  WHAT   
DOES
 THE PRODUCT DO WHAT IT   WANTS?
  IS
 IT EASY TO   NAVIGATE?  IS IT 
RESPONSIVE?
  IS IT INTUITIVE IF YOU CLICK  
 HERE,
 THIS WILL HAPPEN?    ESPECIALLY
 IF
 YOU WANT -- AS   WE WENT OUT TO
 THE
 PLATFORMS   WHERE THE UI IS SO 
FAR
 AWAY   FROM WHAT WE WERE USED 
TO IN
   THE BROWSER WORLD.  IF YOU   
LOOK
 AT A TV OR THE KIDS APPS   AN 
EXTREME,
 YOU HAVE VERY   DIFFERENT UI 
METHODOLOGIST
   AND WE WANTED METHODOLOGYIES 
  AND
 WE WANTED TO HAVE A   STATEMENT
 ARE
 WE OKAY?  ARE   WE NOT AS GOOD 
WE
 THINK WE   SHOULD? 
THE SECRETARY TOPIC WAS SECOND 
TOPIC
 WAS   OPERATIONS.  HOW ARE WE 
WITH
   DEVELOPMENT EXCELLENCE, IF   
YOU
 WANT.  THE FIRST IS   PRODUCT 
EXCELLENCE.
THE   SECOND ONE WAS DEVELOPER  
 EXCELLENCE.
HOW MANY BUGS DO   WE HAVE?  
WHERE
 DO WE FIND   THEM?  HOW IS OUR 
COVERAGE?
  HOW MANY MANUAL TESTS DOES IT 
  STILL
 NEED?  THAT WAS MY   FAVORITE. 
 DO
 WE STILL HAVE   MANUAL STUFF IN
 REGRESSION
   HAPPENING AND WHERE AND WHY  
 IS
 IT NOT MOVEING? 
AND THE LAST TEST THAT WAS   
MORE SPECIFIC
 FOR THE TEST   ORGANIZATION TO 
GO
 AFTER ARE   WE DOING THE RIGHT 
THINGS
 TO   HELP THE LARGEER 
ORGANIZATION
   TO DO THEIR JOB, RIGHT?  AND 
  QUITE
 OBVIOUSLY OUT OF ALL   THIS, WE
 WANTED
 TO HAVE   AUTOMATION WHEREVER 
POSSIBLE.
  IT'S PRETTY OBVIOUS WHEN WE   
TALK
 ABOUT THIS, EVERYONE   THINKS 
OF TEST
 AUTOMATION.    BUT THERE'S LOTS
 AND
 LOTS OF   OTHER AREAS WHERE 
AUTOMATION
   HELPS.  SO IF YOU THINK ABOUT
   THE
 PUSH PROCESS ITSELF, HOW   WE 
RELEASE
 A PRODUCT, WE HAD   LOTS OF 
MANUAL
 STEPS IN   BETWEEN THAT SLOWED 
THINGS
   DOWN, NATURAL SYNC POINTS BUT
   SINGLE
 POINTS OF FAILURE IF   
SOMETHING DIDN'T
 WORK OUT.    SO ACROSS THE 
BOARD,
 LOOK FOR   OPPORTUNITIES TO 
AUTOMATE
 AND   ONE BY ONE TAKE THEM DOWN
. 
MY PERSONAL FAVORITE GOAL, NO   
MANUAL
 REGRESSION.  NOT QUITE   THERE 
YET
 BUT WE MADE SOME   HEADWAYS 
THERE.

GOALS --
 I WAS A BIT OF   MYSELF HERE. 
SO WE PICKED WHERE WE WERE.    
WE CUT
 IT IN HALF.  WE SAID   GO.  AND
 THEN
 WE TRACKED, AND   THE TRACKING,
 I
THINK, IS   MORE IMPORTANT THAN 
THE
   ACTUAL GOAL BECAUSE YOU CAN  
 ALWAYS
 RESET THE GOAL WHEN   YOU GET 
CLOSEER
 AND YOU THINK   IT'S STILL -- 
YOU
 SHOULD   STILL IMPROVE, RIGHT? 
THEN WE MAPPED THIS BACK TO   TO
 --
 YOU PROBABLY HEARD   ABOUT THE 
OKRs
 IN GOOGLE.    SO THE COMMITMENT
 OF
 EVERY   INDIVIDUAL TO THE TEAM,
 OKAY,
   I'M GOING TO DO THIS AND WE  
 SET
 KIND OF BOTH DOWNSTREAM   AND 
FROM
 BOTTOMS BOTTOM-UP OBJECTIVES   
FOR
 THE QUARTER.  THESE WERE   KIND
 OF
 ENFORCEED OBJECTIVES   FOR THE 
TEAM.
YOU HAVE TO   HAVE THIS STATE IN
 THE
 METRIC  METRICS THAT WE GIVE 
YOU FROM
   THE TOP, RIGHT?  AND THOSE   
WERE
 THE TYPICAL, OKAY, NO P0  P0s 
IN
 PRODUCTION AND KIND   OF THE 
OBVIOUS
 THINGS. 
BUT WE BUILT THE TOOL IN A   WAY
 THAT
 THE TEAMS THEMSELVES   COULD 
COME
 UP AND SAY, WELL,   I HAVE 
SOMETHING
 THAT'S   REALLY IMPORTANT TO ME
 FOR
 MY   INTERPRETATION OF WHAT   
QUALITY
 MEANS FOR MY SUBSET   OF THE 
SYSTEM
 THAT NO ONE   ELSE REALLY CARE 
IS
 ABOUT,   RIGHT?  BUT FOR ME 
IT'S 
  IMPORTANT SO WE ALLOWED THIS  
 TO
 BE INCORPORATED
. 
AND, FINALLY, WE HAD ALSO TO   
DO SOME
 WORK ON WHO WE HAD ON   BOARD. 
 THAT'S
 SPECIFICALLY   FOR ME. 
I HAD A TEAM MIX THREE YEARS   
AGO
 THAT IS DRAMATICALLY   
DIFFERENT FROM
 WHAT WE HAVE   NOW.  NOW WE 
HAVE MUCH
 MORE   SOFTWARE ENGINEERING 
TYPES
 ENGINEER TYPES THAT   CAN HELP 
BUILD
 THE TOOLS AND   AUTOMATION AND 
HELP
   UNDERSTAND THE SYSTEMS AND   
LESS
 CORE TEST ENGINEERS   CONCERNED
 ABOUT
 LARGEER   SYSTEMS, CONSISTENT 
PLANS.
  WE STILL HAVE THEM.  WE STILL 
  NEED
 THEM.  BUT MY PROBLEM IS   I 
DIDN'T
 HAVE THE OTHER AS   WELL.  SO 
WE BUILT
 THAT UP   AND NOW I HAVE A MIX 
THAT
 IS   BETTER EQUIPPED TO TACKLE 
  THIS.

USED --
 I CAN'T REMEMBER THE   AMERICAN
 PHRASE.
THE TOOL   THAT WAS MOST USEFUL 
IN
 THIS   THAT WE USED TO GET TO 
CHANGE
   IN THE LARGEER ORGANIZATION  
 WAS
 THIS.  YOU DON'T HAVE   TIME 
FOR MANUAL.
BECAUSE OF   THAT, YOU HAVE TO 
THINK
 ABOUT   HOW TO AUTOMATE AND 
WHAT TO
   AUTOMATE AND LET EVERYONE   
ELSE
 KNOW WHAT YOU NEED TO DO   TO 
HELP
 YOU GET THERE. 
SO WE SAID OKAY, THREE YEARS   
AGO,
 ON DOMAIN SIDE EVEN, WE   HAD 
EVERY
 FEW WEEKS WE HAD A   PUSH.  AND
 WE
 SAID, OKAY, WE   GO TO DAILY 
BUILDS --
 SORRY,   DAILY LUNCH LAUNCHES, 
DAILY
   PUSHES EVERY DAY.  IF YOU   
THINK
 FROM THREE WEEKS DOWN   TO ONE 
DAY,
 THERE'S A LOT OF   TIME YOU 
DON'T
 HAVE ANYMORE   TO DO ALL KINDS 
OF
 THINGS OR   YOU HAVE TO STOP DO
ING
 ALL   KINDS OF THINGS. 
THIS WAS THE SINGLE MOST   
IMPORTANT
 DECISION WE MADE   FROM AN 
ORGANIZATION
 TO GET   TO THAT.
  THIS IS A CURRENT
   SNAPSHOT OF WHERE WE ARE.    
YOU
 CAN SEE TOP LEFT -- TOP   LEFT 
THE
 LITTLE DAWN TREND.    THAT'S 
THE AMOUNT
 OF MANUAL   REGRESSIONS WE   
REGRESSION
 TESTS WE STILL   HAVE IN THE 
SYSTEM.
WE ARE   35,%.  SO A THIRD OF 
ALL 
  TESTS -- IFS CLASSIFYIED ALL  
 OUR
 TESTS, OUR P0 TESTS WE   CALL 
THEM
 THAT HAVE TO RUN ON   EACH 
RELEASE
 BEFORE WE SAY   YOU CAN GO, 
RIGHT?
AND 2/3   OF THOSE ARE NOW 
AUTOMATEED.
  AND, AS I SAID, KEEP IN MIND  
 WHICH
 PLATFORMS WE TALK ABOUT  ABOUT.
  IN
 SOME I HAVE NO   IDEA HOW TO 
EVER
 GET REALLY   DOWN. 
AND WE ADDED A COUPLE OF   INTER
FACES
 AND APPS.  SO I'M   PRETTY 
PROUD OF
 THE TAKE-DOWN   BUT OBVIOUSLY 
NOT
 COMPLETE   YET.  UNIT TESTS, WE
 KEPT
   PRETTY STABLE WHICH IS ALSO  
 GOOD
 BECAUSE OF, AGAIN, OF   THESE 
NEW
 VERTICALS THAT WE   LAUNCHED, 
RIGHT?
THE STANDARD, THE DEFAULT   
DISCUSSION
 AT EVERY POINT   WHEN DECISION 
IS
 MADE THAT AN   ADDITIONAL APP 
WILL
 BE LAUNCH  LAUNCHED IS &quot;OH, WE 
HAVE
 TO   GO TO MARKET TOMORROW.  WE
   DON'T
 HAVE TIME FOR ANYTHING&quot;  
ANYTHING.&quot;

KNOWS
 THAT, TOO, THE FIRST   THING 
THAT
 GETS CUT BACK IS   WORK ON 
AUTOMATION,
 RIGHT?    I'LL DO THIS WHEN WE 
LAUNCH.
  I DON'T KNOW HOW THE SYSTEM   
LOOKS
 LIKE, HOW THE INTERFACE   LOOKS
 LIKE.
I DON'T WANT TO   SPEND ANY 
CYCLES
 ON THIS   QUITE YET.  I'LL DO 
THIS
   LATER. 
 SO LOOKING AT A COVERAGE   
CURVE THAT
 STAYED FLAT OVER   THOSE 
ADDITIONAL
 NEW   VERTICALS IS, I THINK, A 
  PRETTY
 GOOD RESULT OUT OF   THIS. 
AND ON THE RIGHT SIDE IS OUR   
CURRENT
 SNAPSHOT OVER THE   LAST -- HOW
 FAR
 BACK DOES   THIS GO? -- ABOUT A
 YEAR,
 I   THINK.  YEAH, ABOUT A YEAR 
  BACK
 ON OUR RELEASE PLANS.    SO WE 
SET
 OUT THAT WE WANT   DAILY PUSHES
, WE
 WANT DAILY   LAUNCHES.  AND SO 
THIS
 SHOWS   HOW OFTEN WE HIT -- SO 
DAILY
   IN OUR WORLD MEANS FOUR,   
ACTUALLY,.
WE HAVE A FOUR-DAY   WEEK.  WE 
DIDN'T
 WANT TO PUSH   ON FRIDAYS, 
BECAUSE
 WE DIDN'T   WANT PEOPLE TO WORK
 ON
   SATURDAY AND SUNDAY TO FIX   
THE
 BUGS THAT WE INTRODUCED   
FRIDAY POTENTIALLY.
SO WE   SAID, OKAY, WE WANT TO 
GO 
  MONDAY THROUGH THURSDAY.  SO  
 WE
 HAVE A TARGET OF FOUR PER   
WEEK.
AND HERE YOU SEE THAT   WE GET 
THREE,
 THREE AND A   HALF OUT OF THAT 
MOST
 OF THE   TIMES.  THERE ARE SOME
 WEEKS
   THAT HAVE HOLIDAYS IN THEM   
WHERE
 WE DIDN'T NEED FOUR   REALLY.  
AND
 AS I SAID BEFORE   THIS, IN MY 
MIND,
 THIS WAS   THE BEST DECISION WE
 EVER
   MADE, TO PUSH FOR THIS.    
BECAUSE
 THAT SQUEEZED   EVERYONE'S 
ALLOWANCE
 FOR WHAT   CAN HAPPEN.  WE HAVE
 RIGHT
   NOW A HONEST TEST WINDOW ON  
 THE
 RELEASE LEVEL OF THREE,   FOUR 
HOURS,
 WHERE TESTERS   ACTUALLY GO AND
 MANUALLY
 DO   SOMETHING.

HAVE
 REDUCEED TO EXPLORATORY.    SO 
WE
 ARE NOT GOING THROUGH   STRIPT 
  DISRUPTED
 TESTS, BUT WE SPEND   THE TIME 
TO
 SAY, YOU KNOW THE   APP, WE 
KNOW IT
 SHOULD WORK.    LET ME KNOW 
WHETHER
 WE ARE   GOOD TO GO OR 
SOMETHING IS
   OFF. 
WHAT REMAINS WAS THE QUESTION   
OF
 HOW TO TALK ABOUT THIS;   RIGHT
?
HOW DO YOU LET THE   
ORGANIZATION KNOW
 HOW WE'RE   DOING AND HOW DO 
YOU FIND
 OUT   WHERE WE'RE NOT DOING SO 
WELL
   AND WE SHOULD REFOCUS AND   
CHANGE
 THINGS THAT ARE NOT   WORKING. 
SO THIS IS AN EYE CHART.    
YOU'RE
 NOT SUPPOSED TO READ   THIS.  
JUST
 GIVE YOU AN   OVERVIEW.  THIS 
IS HOW
 THE   TRACKING SITE LOOKS LIKE.

CHART
 OF YouTUBE AS THE TOP   
ORGANIZATION,
 AND THEN YOU GO   THROUGH THE 
DIFFERENT
 WE CALL   THEM FUNCTIONAL AREAS
 AND
   INVESTMENT AREAS AND TEAMS.  
  SO
 WE PICKED THREE LEVELS   DOWN, 
SPLIT
 THE WORLD UP INTO   A TREE OF 
DEPTH
 THREE,   PROJECTED IT, AND SAID
, OKAY,
   SO HERE'S WHO WE LOOK AT.    
AND
 THEN WE TRACK, FOR   EVERYONE, 
A MIX
 OF A FIXED   SET OF MET TRI 
SEES THAT
 ARE   PREVIOUSLY DESCRIBED AND 
YOU
   CAN'T ICANN OPT OPT OUT OF 
AND AN
   ARBITRARILY   ARBITRARY LIST 
OF METRICES
   THAT YOU SAY THE VIDEO TEAM, 
  THEY
 HAVE A FEW METRICES THAT   THE 
ANDROID
 APP REALLY   DOESN'T CARE ABOUT
.
    OKAY  OKAY.  YOU PUT IT IN, 
YOU
   LEAVE IT OUT.  FINE.  BUT   
ONCE
 YOU PUT IT IN, YOU WILL   BE 
TRAPPED.
AND THEN YOU CAN DRILL DOWN ,  
,IF
 YOU GET A SLIGHTLY   DIFFERENT 
VIEW
 OF THE VARIOUS   ASPECTS.  AND 
I MENTIONED,
 WE   HAVE -- I MENTIONED BEFORE
, 
  WE LOOK AT PRODUCT, WE LOOK   
AT RELEASE,
 WE LOOK AT TEST. 
AND FURTHER DOWN -- THIS IS   
THE LOWEST
 LEVEL -- MY GROUP   ACTUALLY 
COULD
 GO AND SAY,   HOW ARE WE DOING?
  WE
 HAD   SOME PRODUCTION BUGS IN 
P1.
  THIS IS PROBABLY THIS TOOL   
WE'RE
 TALKING ABOUT THAT HAD   A BUG.
  AND
 YOU SEE KIND OF   VERY EASILY 
WHERE
 ARE HOT   SPOTS, WHERE DID WE 
NOT
 MEET   THE SLAS.  WE STILL 
THINK IN
   SIX-WEEK SPRINTS.  SO THIS   
LITTLE
 BAR CHART YOU SEE UP   TOP 
GIVES YOU
 THE HISTORY OF   THE LAST EIGHT
 OR
 NINE,   SIX-WEEK SPRINTS NEXT 
TO EACH
   OTHER.  SO YOU ALSO GET A   
TREND
 WHETHER YOU'RE ACTUALLY   
IMPROVING
 OR   YOU'RE DE  DEGRADING, YOU 
KEEP
 YOUR   LEVEL.  YOU SEE PRETTY  
 QUICKLY
 WHERE YOU SHOULD BE   CONCERNED
 ABOUT
 AND WHERE   YOU'RE DOING FINE. 
AND THEN THE NEXT STEP,   
OBVIOUSLY,
 AFTER THAT IS TO   THINK ABOUT 
ONGOING
   IMPROVEMENT OF THIS. 
BUT WHAT WE GOT OUT OF THIS   IS
 NOW
 A VOCABULARY TO TALK   ABOUT 
QUALITY
 IN THIS   ORGANIZATION THAT 
EVERYONE
   UNDERSTANDS, EVERYONE KNOWS  
 WHERE
 TO GO AND LOOK.  ALL   THESE M
ETRICES
 WE DEFINED,   EVEN IF IT'S IN A
 TEAM
 NEXT   TO YOU, YOU LEARN A BIT 
ABOUT
   WHAT THEY CARE ABOUT. 
IT IS TRANSPARENT.  EVERYONE   
CAN
 LOOK AT THIS.  THERE'S A   BIT 
OF
 PUBLIC SHAMING GOING   ON, 
OBVIOUSLY.
YOU DON'T   WANT TO BE THE ONE 
RED
 SPOT   IN A LONG LIST OF GREEN,
 ALL
   POSITIVE THINGS. 
AND MAPPING THIS DOWN TO THE   
TEAMS
 ALLOWED ALSO TO HAVE IT   VERY 
EASY
 TO KNOW WHO TO TALK   TO ABOUT 
A PROBLEM;
 RIGHT?    IT'S THIS TEAM, AND I
 DON'T
   CARE WHICH COMPONENT IN THE  
 CODE
 AND BLAH, BLAH, BLAH.    YOU DO
 THIS
 YOURSELF; RIGHT?    THIS TEAM 
SHOWS
 UP AS RED OR   AS DECLINING.  
WE NEED
 TO   TALK.  WE NEED TO DO   
SOMETHING
 ABOUT IT.  IT'S   REALLY COOL. 
AND WHAT'S LEFT HERE?  SO WE   
WANT
 TO THINK ABOUT HOW DO WE   WE 
-- IF
 WE ARE AT GREEN AND   SOME OF 
THOSE
 HAVE SOME   HISTORY WHERE THERE
 ARE
 THREE  THREE, FOUR, FIVE 
SPRINTS ON
   GREEN, WHAT DOES THAT MEAN?  
  DOES
 THAT MEAN WE'RE DONE?    OR 
DOES THAT
 MEAN WE SHOULD   LOOK AT THE 
GOAL
 WE SET AND   WHETHER WE CAN 
IMPROVE
 THAT?    RIGHT? 
THERE IS AN ONGOING   DISCUSSION
, ESPECIALLY
 WITH   THE AFOREMENTIONED FAST-
TO-
  FAST-TO-MARKET NEEDS OF TEAMS 
 TEAMS,
 WHICH IS A REALITY.    LOOK AT 
OUR
 GAMING APP.  WE   WANTED THE 
GAMING
 APP OUT   THERE AS FAST AS 
POSSIBLE.
  BUT THE QUESTION IS, WHAT IS  
 &quot;AS
 POSSIBLE&quot;?  WHAT DOES   THAT 
REALLY
 MEAN?  WHAT ARE   YOU WILLING 
TO JEOPARDIZE
 IN   ORDER TO GET THERE? 
AND, OBVIOUSLY, IN THE WAY OF   
GETTING
 OUT THERE AS FAST AS   POSSIBLE
 IS
 ALL THE PROCESS,   I WOULD CALL
 THIS
 PROCESS   WORK, AROUND IT TO 
ACTUALLY
   KEEP EVERYONE FROM RUNNING   
TOO
 FAST AND INTRODUCING TOO   MANY
 PROBLEMS;
 RIGHT? 
SO THAT'S AN ONGOING   
DISCUSSION THAT
 ON THE PLUS   SIDE IS ACTUALLY 
ON
 THE   SURFACE.  RIGHT?  IT'S 
NOT 
  SOME HIDDEN JUST ONE TEAM HAS 
  THIS
 PROBLEM.  IT'S ON THE   SURFACE
, BECAUSE
 WE PROBABLY   SEE A LOT OF RED 
AREA
 IN THIS   THIS -- OF RED COLOR 
IN
 THESE   AREAS, AND WE ARE 
FORCED TO
   THINK ABOUT WHAT WE DO.

THE
 EXISTING CULTURE IS HOW   FAR 
YOU
 GO WITH ASKING PEOPLE   TO DO 
THINGS
 A CERTAIN WAY.    RIGHT?  WE 
TYPICALLY
 TYPICALLY TRY TO   STAY WAY 
BACK FROM
 THAT   STATEMENT; RIGHT?  YOU 
CAN
   CHOOSE YOUR TOOLS.  YOU CAN  
 CHOOSE
 YOUR -- YOUR   DEVELOPMENT 
PROCESS.
YOU CAN   SPRINT OR SCRUM OR DO 
  WHATEVER
 YOU WANT, AS LONG AS   YOU 
DELIVER;
 RIGHT? 
BUT WE ARE NOW AT A POINT   
WHERE WE
 START SEEING TEAMS   WHO DO 
REALLY
 WELL AND CAN   SEE THE -- THE 
POSITIVE
   TRENDS AND IMPACT ON THAT,   
AND
 THINK ABOUT WHETHER WE   WANT 
TO TURN
 THIS AROUND AND   NOT SAY, OKAY
, WE
 CAN USE   THIS OR THIS OR THIS 
TOOL,
   BUT TOO PRESCRIBE ONE TOOL   
SET
 ACROSS A LARGER PART OF   THE 
ORGANIZATION.
AND IF   YOU'RE NOT IN THAT, YOU
 NEED
   TO HAVE REALLY GOOD REASONS; 
  RIGHT?
BUT WE'RE NOT QUITE   THERE YET.
  IT'S
 ON THE TABLE  TABLE. 
MY BIGGEST PROBLEM, WE STILL   
HAVE
 PLATFORMS THAT ARE HARD   TO 
AUTOMATE
 THAT WE HAVEN'T   CRACKED, THAT
 I'M
 JUST   WITHOUT A GOOD SOLUTION.

  PUSH
 EVERY DAY, EVERY WORKDAY  
WORKDAY,
 OR EVERY PUSH DAY.    SO PRETTY
 CONSISTENT
 FOR   PROBABLY 80% OF THE 
CODEBASE
   OR THE COMPONENT SET.  AND   
WE'RE
 NOW STARTING TO THINK   IF AND 
HOW
 WE PUSH THIS   FORWARD; RIGHT? 
 SO
 DAILY?    SHOULD WE HAVE TWO A 
DAY?
  SHOULD WE HAVE FOUR A DAY?    
WHAT'S
 THE RIGHT NUMBER?    SHOULD WE 
PUSH
 EVERY TIME   CODE IS READY?  
WHAT
 WE CALL   PUSH ON GREEN?  RIGHT
, YOU
   SUBMIT YOUR CODE.  IT GOES   
THROUGH
 ALL KINDS OF TESTS.    AND AT 
THE
 END OF THAT   PROCESS, YOU'RE 
LIVE;
 RIGHT? 
HOW FAR ON THAT DIMENSION DO   
WE WANT
 TO PUSH?  NOT QUITE   OBVIOUS. 
HUH.  TEAM -- 
LET'S TALK ABOUT MY OTHER BIG   
PROBLEM
 OF GETTING THE RIGHT   PEOPLE 
FOR
 THIS TYPE OF WORK,   RIGHT, 
WHICH
 I FOUND RATHER   HARDER THAN I 
EXPECTED.
HIRING IS A REAL STRUGGLE,   
BOTH IN
 TERMS OF NUMBERS AND   IN TERMS
 OF
 THE RIGHT SKILL   LEVEL, OR -- 
LEVEL
 AND SKILL   SET.  PEOPLE WHO 
ARE REALLY
   PASSIONATE OF THIS TOPIC, OF 
  NOT
 WORKING ON THE FRONT, YOU   
KNOW,
 LOOK, MOM, I BUILT A   NEW APP,
 BUT
 MORE IN THE BACK   OFFICE.   
THIS
 ROOM IS   PROBABLY MORE -- IT'S
 MUCH
   MORE EASIER TO CONVINCE   
PEOPLE
 HERE TO DO THIS TYPE   OF WORK.
  BUT
 IF YOU GO TO   THE GENERAL SWE,
 SOFTWARE
   DEVELOPER POPULATION, THEY'RE
   HARD
 TO FIND.  VERY VALUABLE   AND 
HARD
 TO FIND. 
AH, NOW I REMEMBER WHAT THIS   
OTHER
 WAS. 
ANOTHER ORGANIZATIONAL   PROBLEM
 ON
 THE TEAM IS, IF   YOU RECALL 
THE --
 I TRY TO   GIVE A FLAVOR OF HOW
 DIVERSE
   AND HOW BROAD THE   
TECHNOLOGIES
 ARE, THE SET OF   TECHNOLOGY IS
 THAT
 IS USED TO   BUILD THIS YouTUBE
 OFFERING  OFFERING; RIGHT? 
AND ALMOST IN EVERY AREA OF   
TECHNOLOGY,
 THERE IS A   SPECIALTY FOR HOW 
DO
 YOU   ACTUALLY VALIDATE THIS 
AND 
  MAKE SURE YOU HAVE IMPROVED;  
 RIGHT?
SO YOU THINK ABOUT   MACHINE 
LEARNING
 AND MODEL  MODEL-BASED TESTING 
ON
 ONE --   AS ONE EXAMPLE.  YOU 
GO DOWN
   AND YOU HAVE HARD-CORE VIDEO 
  PROCESSOR
 IMAGING THINGS.    YOU GO UP TO
 THE
 APPS, AND   YOU HAVE UI, HUMAN-
COMPUTER
   INTERACTION TOPICS.  RIGHT?  
  SO
 IT'S   A BROAD SET.  IT'S   A 
BROAD
 SPECTRUM.  AND WE   HAVE NOT 
THAT
 MANY PEOPLE.    SO MOST OF THEM
 ARE
 SPECIAL  SPECIALIZED IN SOME OF
 THOSE
   AREAS; RIGHT?  AND THAT'S   
WHAT
 I MEANT HERE WITH THE --   WITH
 THE
 TEAM IDENTITY.  HOW   DO YOU 
MAKE
 THESE HUNDRED   PEOPLE THAT DO 
THIS
 FEEL AS   ONE TEAM THAT SOLVES 
THIS
   PROBLEM FOR YouTUBE, VERSUS  
VERSUS,
 OH, I'M IN THE SEARCH   GROUP. 
 OH,
 AND I'M IN THE   PERSONAL
IZATION GROUP.
AND I   DO THIS OTHER THING.  
RIGHT?

STRUGGLE.
AND THEN THE HIRING. 
SO THANKS FOR YOUR TIME.  I   
HOPE
 IT WAS A BIT INTERESTING  
INTERESTING.
I TRIED TO NOT   GET INTO TOO 
MUCH
 OF THE --   THIS IS THE TOOL WE
 USE,
 AND   THIS IS THE   LANGUAGE WE
 DO
   IT IN, RIGHT, BUT MORE ON A  
 HIGHER
 LEVEL TO SEE WHETHER   WE CAN 
HAVE
 SOME DISCUSSION. 
I'M HERE FOR THE NEXT TWO   DAYS
, VERY
 EAGER TO TALK TO   YOU GUYS 
ABOUT
 HOW CAN WE DO   THIS BETTER?  
WHAT
 ARE YOUR   EXPERIENCES?  SO 
TAKE IT
 AS   ONE OF THOSE   EXPERIENCE 
  DROPS
 IN THE BACK AND SEE   WHAT IT 
CAN
 DO FOR YOU. 
WITH THAT, THANK YOU. 
I'M NOT SURE HOW WE'RE DOING   
ON TIME.
DO WE HAVE TIME FOR   QUESTIONS?
&amp;gt;&amp;gt;Yvette Nameth:  WE ARE GOOD   
FOR
 QUESTIONS. 
&amp;gt;&amp;gt;Juergen Allgayer:  OH,   
EXCELLENT.
IS -- WILL THIS SHOW ME THE   
THE --

&amp;gt;&amp;gt;Juergen Allgayer:  -- THE   
ONLINE?

WASN'T
 SHOWING UP ON MY -- 
CAN YOU CLICK SO IT'S SHOWING   
THE
 TOP TAB, PLEASE. 
&amp;gt;&amp;gt;Juergen Allgayer:  YOU   
MODERATE;
 RIGHT? 
&amp;gt;&amp;gt;Yvette Nameth:  YEAH. 
&amp;gt;&amp;gt;Juergen Allgayer:  THERE'S   A
 NEGATIVE
 ONE.  WHAT DOES   THAT MEAN, 
DON'T
 ASK THAT   QUESTION? 
&amp;gt;&amp;gt;Yvette Nameth:  APPARENTLY   
I'M
 NOT ALLOWED TO ASK YOU     THAT
. 
[ LAUGHTER ]  
THAT RED BUTTON. 
COULD YOU DESCRIBE THE   
TRANSITION
 TO A TEST   ENVIRONMENT THAT 
MATCHES
   PRODUCTION. 
&amp;gt;&amp;gt;Juergen Allgayer:  I'LL TRY  
TRY.
SO THE PROBLEM WAS THAT IN   OUR
 PRODUCTION
 SYSTEM, THE --   THE 
CONFIGURATION
 INFORMATION   IS STORED IN CON
FIG
 FILES;   RIGHT?  OLD TRADITION.
  SO
 WE   HAVE INFORMATION ABOUT 
WHICH
   DATA CENTERS TO DEPLOY TO,   
HOW
 MANY CPUs, WHAT   PRIORITY 
LEVEL
 OF THE CPUs,   WHO TALKS TO 
WHOM,
 WHAT IS   THE BACKUP BACKUP 
PHILOSOPHY,
 ET   ET CETERA,.  SO THERE'S A 
  LENGTHY
 DESCRIPTION OF ALL   THESE 
CONFIGURATION
 FLAGS AND   WHAT VALUES, ET 
CETERA,.

 ENVIRONMENT,
 YOU   DON'T HAVE OR NEED THAT  
 DETAIL.
RIGHT?  SO IF YOU   IGNORE THAT 
AND
 JUST THINK   ABOUT THE 
DEVELOPMENT
   ENVIRONMENT, YOU PROBABLY   
ALSO
 COME UP WITH SOME   
CONFIGURATION.
BUT IT   DOESN'T HAVE ALL THE   
INTRICACIES,
 AND ESPECIALLY   NOT ALL THE 
TUNING
 PART, THAT   WE HAVE IN THE 
LIVE WORLD;
   RIGHT?  SO THE PROBLEM WAS   
THAT
 YOU BASICALLY HAVE TWO   
DIFFERENT
 SYSTEM   CONFIGURATION 
DESCRIPTIONS,
   RIGHT, AND WHILE YOU KNOW IN 
  YOUR
 DEVELOPMENT ENVIRONMENT   
EVERYTHING
 WORKS FINE, THERE   WAS A 
PRETTY GOOD
 LEVEL OF UN  UNCERTAINTY ABOUT 
WHAT
   HAPPENS IF I DEPLOY INTO THIS
   ONE
 WITH THIS SET OF   
CONFIGURATIONS
 ABOUT
, TO SAY   WE DON'T HAVE TO REDO
 ALL OUR   TESTING AGAIN.  WE 
WERE
 DONE   HERE, AND THEN WE 
DEPLOYED.
  AND AS WE SLOWLY ROLLED OUT,  
 WE
 RERUN LOTS OF OUR TESTS,   JUST
 TO
 MAKE SURE, JUST TO   MAKE SURE,
 QUOTE,
UNQUOTE,   IT'S A QUOTE, JUST TO
 MAKE
   SURE.  RIGHT? 
AND WHAT WE NOW HAVE DONE IS,   
TO
 START OUT WITH A THE   
CONFIGURATION
 FILES OF THE   LIVE SYSTEM, USE
 THAT
 AS   INPUT TO THE DEVELOPMENT  
 SYSTEM.
RIGHT?  IGNORE WHAT   CAN BE 
IGNORED.
REALLY, THAT   WE DON'T CARE 
ABOUT.
BUT   MAKE SURE ALL THE REST IS 
  EXACTLY
 LIKE IT IS IN LIFE.    EVEN IF 
IT'S
 OVERKILL, AND   EVEN IF IT'S 
TOO MUCH
 AND WE   DON'T NEED THIS, WHO 
CARES;
   RIGHT?  IT MAKES THE STEP   
FROM
 ONE TO THE OTHER SO MUCH   LESS
 ERROR-PRONE.
SO THAT   WAS THE PROBLEM I 
TRIED TO
   DESCRIBE.  SORRY IF I WASN'T 
  TOO --
 TOO -- TOO CLEAR ON   THAT. 
&amp;gt;&amp;gt;Yvette Nameth:  IF YOU   
ACCOMPLISH
 THE GOAL OF HAVING   NO MANUAL 
REGRESSION,
 HOW   WILL YOU VALIDATE THE 
LOOK 
  AND FEEL? 
&amp;gt;&amp;gt;Juergen Allgayer:  SO I   
THINK I
 MENTIONED THAT AS   WELL. 
I DON'T WANT THE REGRESSION   
REGRESSION --
 THE MANUAL   REGRESSION TO BE 
SCRIPTED,
   FIRST OF ALL.  RIGHT?  SO WE 
  DO
 RIGHT NOW ALLOW A TIME   WINDOW
 OF
 THESE THREE HOURS   THAT WE 
HAVE WHEN
 THE NEW   LEVEL IS READY AND 
IT'S
 NOT   READY TO GET ROLLED OUT .
  WE
   USE THAT FOR FREE-FORM   
TESTING,
 FOR EXPLORATORY   TESTING. 
WHAT I DON'T WANT IS TO SAY,   
OH,
 I HAVE THESE SCRIPTS AND   
THESE HUNDREDS
 OF SCRIPTS   HAVE TO GO THROUGH
, 
  AND THE   ONLY WAY TO SCALE 
THIS
 IS TO   QUIET   GET MORE BODIES
 IN
 FRONT OF   KEYBOARDS.  THAT'S 
WHAT
 I   DON'T WANT.  I WANT THESE  
 SCRIPTS
 TO BE IN THE OTHER   WORLD, 
WHERE
 THEY'RE RUN   AUTOMATICALLY, SO
 THAT
   EXACTLY THIS CAN HAPPEN IN   
THE
 TIME WE HAVE.  YOU   SHOULDN'T 
WORRY
 ABOUT, OKAY,   DOES THIS RESULT
 IN
 THAT;   RIGHT?  YOU SHOULD 
WORRY 
  ABOUT DOES IT LOOK RIGHT, DID 
  WE
 BREAK SOME OF THE USUAL   
THINGS IN
 INTERNATIONAL  
INTERNATIONALIZATION
 AND --   RIGHT?  DOES IT LOOK 
RIGHT?
  IS THE INTEGRATION OF THE NEW 
  FEATURE
 INTO YESTERDAY'S   SYSTEM 
ACTUALLY
 LOOKING OUT   THERE AS IT 
SHOULD?
THINGS   LIKE THAT.  SO IT'S 
EXACTLY
   THAT, I THINK, THAT I WANT.  
  NO
 MANUAL SCRIPTED REGRESSION  
REGRESSION,
 BUT USE THE TIME   FOR 
EXPLORATORY.

TELL
 PEOPLE IN THE LOCAL   AUDIENCE,
 I
 AM PRIMARILY   TAKING QUESTIONS
 OFF
 OF THE   WEB SITE.  SO IF YOU 
WANT
 TO   ASK ONE, FEEL FREE TO ADD 
  YOURS
 THERE, TOO,. 
THIS ONE MIGHT BE HARD TO   
ANSWER.

YEAH.
&amp;gt;&amp;gt;Yvette Nameth:  BECAUSE -- 
&amp;gt;&amp;gt;Juergen Allgayer:  I THINK   
WE SHOULD
 HAVE A CONFERENCE   ON TOOLS. 
&amp;gt;&amp;gt;Yvette Nameth:  YEAH, WHAT   
TOOLS
 DO WE USE, JUERGEN?    CAN I 
SHARE
 SOME OF YOURS?    WELL, WE CAN 
SHARE.
BUT CAN   WE SHARE IT WITH THESE
 GUYS
   WHAT TOOLS WE USE? 
&amp;gt;&amp;gt;Juergen Allgayer:  SO WE   
COULD
 SHARE.  USUALLY WHAT IS   
BEHIND THE
 QUESTION IS, CAN I   USE THAT 
TOOL;
 RIGHT? 
&amp;gt;&amp;gt;Yvette Nameth:  NO. 
&amp;gt;&amp;gt;Juergen Allgayer:  AND THIS   
IS
 WHERE IT GETS A BIT TRICKY  
TRICKY,
 BECAUSE A LOT OF OUR   TOOLS 
ARE SPECIALLY
 MADE FOR   THE WHOLE 
PROPRIETARY STACK
   THAT WE BUILD.  SO IT STARTS 
  STARTS --
 EVERYONE KNOWS THAT  THAT, TOO,
.
IT STARTS WITH A   LOW-LEVEL, 
SLIGHTLY-TUNED
   LINUX SYSTEM THAT HAS ITS OWN
   COMPILER
 AND ITS OWN -- AND   THEN YOU 
WORK
 UP THE TREE.    AND ONCE YOU 
GET TO
 THE TEST   ENVIRONMENTS, A LOT 
OF
 THEM   ARE VERY  FINELY 
INTEGRATED
   WITH 25 OTHER SYSTEMS. 
ALTHOUGH, ON THE OTHER HAND,   
WE HAVE
 A FEW THAT WE OPEN   SOURCED.  
WEBDRIVER
 HAS BEEN   A VERY PROMINENT ONE
.
THERE   ARE SOME.  BUT I 
HONESTLY 
  DON'T KNOW -- I MEAN, IF YOU  
 HAVE
 MAYBE A LIST OF 25 TO 30   
DIFFERENT
 TOOLS THAT MAKE UP   OUR 
ENVIRONMENT,
 20 -- IF   IT'S 25, 23 OF THOSE
 ARE
 NOT   REALLY VERY USABLE 
OUTSIDE.

THEM
 IS GOOGLE DRIVE FOR   SHARING 
TEST
 DOCUMENTS. 
&amp;gt;&amp;gt;Juergen Allgayer:  THAT IS   
TRUE.
BUT NOT IN   SPREADSHEETS 
ANYMORE.

 CASE
 MANAGEMENT AND   SPREADSHEETS. 
&amp;gt;&amp;gt;Juergen Allgayer:  WE DON'T   
DO
 THAT. 
BUT MAYBE ALSO WANT TO   MENTION
 THAT
 ONE OF OUR BIG   WORK, OUR, 
GOOGLE,
 BIG WORK   ITEMS   SINCE A FEW 
QUARTERS
   IS TO BRING A LOT OF THESE   
DEVELOPMENT
 TOOLS AND TESTING   TOOLS OUT 
INTO
 THE CLOUD FOR   DEVELOPERS TO 
USE
 AND SHARE;   RIGHT? 
SO WHILE RIGHT NOW THE ONLY   
PATH
 FOR US, REALLY, IS TO GO   
THROUGH
 THE WORK, TO OPEN   SOURCE 
SOMETHING
 THAT WE USE,   IF WE THINK IT 
REALLY
 CAN BE   ABSTRACTED AWAY AND IS
 STILL
   USEFUL BY ITSELF, TO SAY SAY,
   FORGET
 THIS.  A WHOLE   DIFFERENT 
APPROACH.
HERE'S A   STACK OF TOOLS TO USE
 IF   YOU DEVELOP ON THIS 
PLATFORM,
   THEN     YOU GET ALL THESE   
TEASE
 FOR FREE, BUILD TOOLS,   
INTEGRATION
 TOOLS, ROLL OUT   TO DEPLOY, 
BLAH,
BLAH, BLAH,   BLAH, BLAH, 
INCLUDING
 THE   PLATFORMS TO RUN THE 
TESTS ON
  ON; RIGHT?  SO INCLUDING   
EMULATORS
 FOR ANDROID   PLATFORMS, OR 
EVEN LABS
 THAT   RUN REAL PHYSICAL 
MACHINES
   THAT YOU CAN, AS A DEVELOPER,
   REACH.
THAT'S STILL A BIT   OUT THERE, 
I HEAR.
MAYBE   ANOTHER WEEK OR TWO.  
BUT 
  IT'S COMING. 
&amp;gt;&amp;gt;Yvette Nameth:  BECOME   
FRIENDS
 WITH A GOOGLE CLOUD   TESTER 
AND FIND
 OUT WHAT YOU   CAN ABOUT WHAT 
IS CURRENTLY
   AVAILABLE IN THAT SPACE. 
THANK YOU, JUERGEN. 
&amp;gt;&amp;gt;Juergen Allgayer:  ALL   RIGHT
. 
[ APPLAUSE ] 
I'M AROUND.
  I'M AROUND AND   REALLY
 APPRECIATE YOUR BEING   AROUND.

TRYING
 TO STEAL MY CLICKER. 
SO A LITTLE HOUSEKEEPING   
BEFORE WE
 GO ON TO THE NEXT   ONE.  IT 
WILL
 BE ONLY A   SECOND, GUYS. 
WE HAVE SOME EMPTY SEATS.  IF   
YOU
 GUYS COULD SMUSH IN SO   THAT 
THE
 SEATS ON THE AISLE   ARE THE 
EMPTY
 ONES, WE'RE   GOING TO BE SEND
ING
 SOME POOR   FOLKS IN FROM THE 
OVERFLOW
   ROOMS IN IN THE NEXT BREAK OR
   IN --
 ACTUALLY, HOPEFULLY, AT   THE 
VERY
 BEGINNING  OF THIS   TALK.  SO 
PLEASE
 HELP US OUT   WITH THAT. 
IT IS OKAY IF YOU ABSOLUTELY   
HAVE
 TO TO SIT IN ONE OF THE   
HEARING-IMPAIRED
 SEATS,   BECAUSE THERE ARE NO 
OTHER
   SEATS LEFT.  HOPE FLI, WE'VE 
  ALREADY
HOPEFULLY, WE'VE   ALREADY 
ACCOMMODATED
 THOSE   WHO NEED THEM.  AND IF 
NOT,
   LET A COMMITTEE MEMBER FIND  
 THE
 PROPER SEATING SO THEY   CAN 
SEE.

 FROM
 UBER WHO HAVE   COME TO TALK TO
 US
 ABOUT   OCTOPUS, TAKING ON THE 
UBER
   CHALLENGE.  I'D LIKE TO   
WELCOME
 APPLE CHOW AND BIAN   JIANG, 
FROM
 UBER, TO THE   STAGE. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Apple Chow:  HI, EVERYONE.    
MY
 NAME IS APPLE, AND I   MANAGE 
THE
 MOBILE TESTING   INFRASTRUCTURE
 TEAM
 AT UBER.    I'M VERY EXCITED TO
 BE
 HERE   TODAY. 
SO FIRST, LET ME GIVE YOU   SOME
 INFORMATION
 ABOUT MYSELF  MYSELF.  I AM AN 
EX-GOOGLER.
  I WAS AT GOOGLE FOR NINE   
YEARS.
AND I LET THE TESTING   TESTING 
--
 LED THE TESTING   TEAM ON A 
WIDE ARRAY
 OF   PROJECTS, INCLUDING You
TUBE
  YOUTUBE, HANGOUTS,  AND   
GOOGLE
 MAPS. 
AT FIRST I THOUGHT I'VE SEEN   
IT ALL
 IN THE WORLD OF   AUTOMATED 
TESTING.
WHEN I   JOINED UBER IN MARCH, 
HOWEVER
  HOWEVER, I FOUND THAT THE   
LEVEL
 OF CHALLENGES WE FACE   AT UBER
 IS
 AT A UNIQUELY   DIFFERENT LEVEL
. 
I'M VERY EXCITED TO SHARE   WITH
 YOU
 SOME OF THE   TECHNOLOGIES WE 
BUILT
 FROM   SCRATCH TO SOLVE THOSE  
 CHALLENGES
 AT UBER. 
AND WE ARE ALSO PLANNING TO   
OPEN
 SOURCE SOME OF THE   SOLUTIONS 
VERY
 SOON.  SO I   HOPE THAT YOU 
FIND SOMETHING
   USEFUL IN OUR TALK TODAY   
WHICH
 YOU CAN APPLY TO YOUR   
PROJECTS.

TESTING
 AT UBER UNIQUE?    BEFORE I 
REVEAL
 THE ANSWER TO   MY QUESTION, 
FIRST,
 LET'S   TAKE A QUICK SURVEY. 
HOW MANY OF YOU HAVE USED   UBER
? 
WOW.  THAT'S A LOT OF YOU.    
THAT'S
 GREAT. 
AND MY NEXT QUESTION.  HOW   
MANY OF
 YOU KNOW THAT THERE'S   A 
SEPARATE
 DRIVER APP? 
I SEE.  NOT THAT MANY OF YOU. 
OKAY.  NOW TO MY THIRD   
QUESTION.
HOW MANY OF YOU HAVE EVER   
TRIED OUT
 TO BE AN UBER   DRIVER? 
WELL, THERE'S LOTS OF PERKS   
ABOUT
 BEING AN UBER DRIVER,   BUT 
THAT'S
 NOT THE POINT OF   TODAY'S TALK
. SO 
 AFTER MY PREVIOUS HINT,   NOW 
CAN
 YOU GUESS THE ANSWER   TO MY 
QUESTION:
WHAT MAKES   TESTING UBER'S 
MOBILE
 APPS   SIGNIFICANTLY DIFFERENT 
FROM,
   LET'S SAY, TESTING GOOGLE   
MAPS?
ANYONE WANT TO TELL ME   THE 
ANSWER?
ANY GUESS? 
(SPEAKER OFF MICROPHONE.). 
&amp;gt;&amp;gt;Apple Chow:  TWO APPS.    GOOD
, THAT'S
 GREAT.  SO   WHAT'S OUR UBER 
CHALLENGE?
  THE DRIVER APP AND THE RIDEER 
  APP
 ARE TIEED TOGETHER.  SO   THIS 
IS
 ONE OF THE FIRST   CHALLENGES 
WE FACED
 WHEN WE   WERE INVESTIGATING UI
 TESTING
   TOOLS FOR AUTOMATEING THE 
TEST 
  SCENARIOS FOR THE MOBILE ORG  
 AT
 UBER.  WE FOUND THAT MANY   OF 
THE
 SCENARIOS REQUIRED THE   RIDEER
 APP
 AND THE DRIVER APP   INTER
ACTING CLOSELY
 WITH ONE   ANOTHER IN ORDER TO 
COMPLETE
   THE SCENARIO. 
SO HOW DO WE SOLVE THIS?  AND   
NOW
 LET'S FIRST TAKE A MOMENT   AND
 THINK
 ABOUT OUR CURRENT   AND 
PREVIOUS PROJECTS.
HAVE   YOU EVER ENCOUNTERED A 
CASE
   WHERE MULTIPLE USERS HAVE TO 
  COLLABORATE
 TOGETHER IN ORDER   TO FINISH A
 SCENARIO?
AND   HAVE YOU EVER FACED A   
SCENARIO
 WHERE YOU HAVE USERS   USERS --
 YOUR
 APP HAS TO TALK   WITH ANOTHER 
APP
 IN ORDER TO   FINISH A SCENARIO
? 
I CAN IMMEDIATELY THINK OF A   
FEW
 CASES WHERE THIS APPLYIES. 
FOR EXAMPLE, AT HANGOUTS WE   
HAVE
 ONE-TO-ONE OR GROUP   
CONVERSATIONS
 OR VIDEO CALLS   WHERE MULTIPLE
 USERS
 HAVE TO   COLLABORATE TOGETHER 
TO
   FINISH THOSE SCENARIOS. 
ALSO, MY FRIENDS AT GAMES,   
THERE
 ARE SO MANY GAMES THAT   
REQUIRE MULTIPLE
 USERS   PARTICIPANTING TOGETHER
 TO
   FINISH A GAME.  SO, BASICALLY
  BASICALLY,
 ANYTHING THAT   INVOLVES 
MULTIPLE
 USER   TALKING WITH ONE ANOTHER
 IN
   ORDER TO FINISH A SCENARIO   
WILL
 FACE A SIMILAR CHALLENGE  
CHALLENGE.
SO WHAT'S UNIQUE TO UBER IS   
THAT
 OUR CORE FLOW IS   CONSISTENT 
CONSIST
  CONSISTED OF MANY DISTINCT   
STEPS
 THAT ARE HAPPENING NOT   JUST 
ACROSS
 DIFFERENT DEVICES   BUT ACROSS 
APPS,
 THE DRIVER   APP AND THE RIDER 
APP.
SO   THAT MAKES IT EVEN MORE   
CHALLENGING.

IS THAT
 YOU HAVE MULTIPLE   DEVICES 
INTERACTING
 WITH ONE   ANOTHER BUT STILL 
WITH
 THE   SAME APP.  SO HOW DO WE 
SOLVE
   IT?  OUR SOLUTION IS CALLED  
 OCTOPUS.
SO EVEN THOUGH OUR   CHALLENGE 
IS UNIQUE,
 OUR   SOLUTION IS A GENERIC 
TEST 
  RUNNER THAT CAN BE APPLYIED TO
   RUN
 ANY SCENARIOS THAT ARE   
INVOLVING
 CROSS-DEVICE OR   CROSS-APP 
COMMUNICATION.
SO READY TO SEE OCTOPUS IN   
ACTION?
FIRST LET'S WATCH A   QUICK DEMO
 SHOWING
 THE INTER  INTERACTIONS BETWEEN
 THE
   DRIVER AND THE RIDER FOR OUR 
  CORE
 CHIP FLOW SCENARIO WHERE   THE 
UBER
 DRIVER IS GIVING A   RIDER A 
RIDE.

SURFACE
 AND SEE WHAT OCTOPUS   IS DOING
.
SO IN THIS DEMO,   YOU SEE 
OCTOPUS
 LAUNCHING TO   EMULATORS 
RUNNING SIDE
 BY   SIDE, ONE RIDING THE RIDER
   APP,
 ONE THE DRIVER APP.  SO   LET'S
 PLAY
 THE VIDEO. 
SO HERE YOU CAN SEE THE RIDER   
AND
 DRIVER BOTH SIGN IN.  THE   
LEFT SIDE
 IS THE RIDER.  THE   RIGHT SIDE
 IS
 THE DRIVER.  SO   FIRST THE 
RIDER
 SETS THE PICK  PICKUP LOCATION.
  AND
 THEN   THE DRIVER GOES ONLINE 
AND
   IT'S READY TO GET REQUESTS.  
  AND
 NOW THE RIDER ON THE LEFT   
CLICKS
 ON REQUEST UBERX TO   REQUEST 
FOR
 UBERX.  DRIVER   GETS A DIS
PATCH,
 ACCEPTS IT,   AND IS EN ROUTE 
TO PICK
 UP   RIDER. 
DRIVER THEN PICKS UP RIDER,   
BEGINS
 THE TRIP.  THE RIDER   ON THE 
LEFT
 SEES THAT ERIC   SCHMIDT NOW ON
 TRIP.
AND   DRIVER ARRIVES AT 
DESTINATION
  DESTINATION, DROPS OFF RIDER, 
  RATES
 THE RIDER, AND THEN   RIDER 
WILL RATE
 THE DRIVER. 
SO THIS IS THE SEQUENCE OF   OUR
 MOST
 BASIC TRIP-FLOW   SCENARIO 
WHERE THE
 DRIVER   GIVES THE RIDE TO THE 
RIDER.

 SCENARIO
 LIKE THE   UBER POOL.  I'M NOT 
SURE
 HOW   MANY OF YOU HAVE USED 
UBER 
  POOL.  IN AN UBER POOL   
SCENARIO,
 YOU HAVE ONE DRIVER   AND 
USUALLY
 AT LEAST, LIKE,   TWO TO THREE 
DIFFERENT
   PARTIES OF RIDERS.  SO OVER  
 THERE
 YOU HAVE THREE TO FOUR   RIDERS
 COMFORTABLEING
 TOGETHER   IN A SCENARIO.  SO 
THE
   SYNCHRONIZEATION GETS EVEN   
MORE
 COMPLICATED. 
NOW, LET'S LOOK AT THE   
SCENARIO STEP
 BY STEP.    REMEMBER IN THE 
PREVIOUS
 DEMO   I SHOWED THAT OCTOPUS 
LAUNCH
  LAUNCHED BOTH THE DRIVER APP  
 AND
 THE RIDER APP AT THE SAME   
TIME AND
 EACH OF THE DRIVER   TESTS AND 
RIDER
 TESTS GOES IN   AND EXECUTES 
THEIR
 OWN   SEQUENCE OF STEPS. 
NOW LET'S IMAGINE WHAT COULD   
GO WRONG
 THERE.  REMEMBER   THAT THOSE 
TWO
 TESTS ARE   RUNNING IN TWO 
SEPARATE
   PROCESSES, EVEN THOUGH IT   
LOOKS
 LIKE IT'S ALL TOGETHER   IN ONE
 SCENARIO.
SO UNDERNEATH THE COVER IS   
RUNNING
 IN TWO DIFFERENT   PROCESSES.  
WHAT
 IF THE RIDER   LOGS IN BEFORE 
THE
 DRIVER AND   REQUESTS FOR THE 
RIDE
 BEFORE   THE DRIVERS IS READY 
TO 
  ACCEPT THE RIDE?  THEN THE   
REQUEST
 COULD TIME OUT AND   THEN YOU 
WOULDN'T
 BE TESTING   THE SCENARIO THAT 
YOU
 WANT TO   TEST, RIGHT? 
SO HOW DOES THE RIDER KNOW   
THAT DRIVER'S
 ONLINE AND NOW   I CAN SEND THE
 REQUEST?
SO THIS IS WHERE OCTOPUS   COMES
 IN.
SO OCTOPUS, WE   INTRODUCED THIS
 CONCEPT
 OF   SIGNALING.  SO USING 
SIGNAL  SIGNALING,
 OCTOPUS CAN -- THE   DRIVER APP
 CAN
 TELL THE   REQUIRED THAT, HEY, 
I'M
   ONLINE NOW.  NOW WE CAN   
REQUEST.
THEN THE RIDER TEST   CAN GO A
HEAD
 AND REQUEST.  SO   USING SIGNAL
ING,
 OCTOPUS   ALLOWS YOU TO SET UP 
  DIFFERENT
 CHECKPOINTS ALONG   YOUR TEST 
SCENARIO
 TO MAKE   SURE THE STEPS ARE 
EXECUTED
   IN THE RIGHT ORDER SO THAT   
YOU
 IT CONTINUES TO   COMMUNICATE 
WITH
 ONE ANOTHER. 
SO WOULD OCTOPUS HELP?  SO   
HERE'S
 THE CORRECT SEQUENCE.    SO 
AFTER
 THEY LOG IN, FIRST   THE DRIVER
 GOES
 ONLINE BY   CLICKING ON &quot;GO 
ONLINE&quot;.&quot;
AND   THEN THE REQUEST GOES TO 
THE
   BACKEND AND THE BACKEND   
ACKNOWLEDGES
 IT. 
NOW, OCTOPUS SENDS A SIGNAL   
FROM
 THE DRIVER TEST TO THE   RIDER 
TEST
 AND SAY, HEY, I'M   ONLINE NOW.
  NOW
 WE CAN   REQUEST. 
THE RIDER TEST NOW CLICKS ON   &quot;
REQUEST
 UBERX&quot;.&quot;  AND THE   REQUEST 
GOES TO
 THE BACKEND   AND THEN THE DIS
PATCH
 GETS   SENT TO THE DRIVER.  SO 
IN
   THE SIMILAR FASHION, YOU CAN 
  SEE
 THAT ALONG THE WAY YOU   CAN 
PUT IN
 DIFFERENT   CHECKPOINTS.  MAYBE
 AFTER
   THAT THE DRIVER CAN TELL THE 
  RIDER,
 HEY, I ACCEPTED THE   RIDE.  
THEN
 THE RIDER TEST   CAN CHECK THE 
STATUS
 BAR ON   THE TOP AND SAY, OKAY,
 I
 CAN   SEE THE DRIVER IS EN 
ROUTE TO
   PICK ME UP, THINGS LIKE THAT.

OCTOPUS.
SO WHAT WERE ALL   THE REASONS 
BEHIND
 WHY WE   BUILT OCTOPUS?  FIRST,
 WE
   WANTED A UNIFIED TEST RUNNER 
  FOR
 BOTH OUR ANDROID AND i  IOS 
APPS.
SECONDLY, WE WANTED ESSENTIAL  
ESSENTIALITY
   EXTENSIBILITY TO OUR RUNNER  
 CAN
 BE INTEGRATED WITH   DIFFERENT 
UI
 FRAMEWORKS. 
THIRDLY, WE WANTED TO SUPPORT   
PARALLELIZEED
 RUN SO WE CAN   SPEAK UP OUR 
TESTS.
LASTLY,   AS I SHOWED IN THE 
PREVIOUS
   DEMO, WE WANT TO SUPPORT   
SIGNALING
 SO OUR TESTS CAN   COMMUNICATE 
WITH
 ONE ANOTHER   EVEN THOUGH THEY 
ARE
 RUNNING   ACROSS DEVICE AND 
ACROSS
 APPS  APPS. 
AND MOST OF OUR TALK IS GOING   
TO
 FOCUS ON A SIGNALING   
FUNCTIONALITY
 SINCE THAT'S   WHAT ENABLEED US
 TO
 DO THE   CROSS-APP AND 
CROSS-DEVICE
   COMMUNICATION.

WELL,
 OCTOPUS STREAMLINES THE   
FOLLOWING
 FUNCTIONALITYIES IN   THE 
COMMENT
 LINE.  SO WHETHER   IT'S RUN BY
 AN
 END USER ON A   LAPTOP OR IT'S 
RUNNING
 BY OUR   GENERAL KINS KIN   JEN
KINS
 CI, IT IS THE SAME   EXACT 
COMMAND.
SO THIS TAKES   JENKINS EASY.  
FIRST,
 IT   PREPARES THE TEST TARGETS 
SO
   TEST TARGETS I MEAN EITHER IT
   CAN
 BE A DEVICE OR IT CAN BE   AN 
ANDROID
 EMULATOR OR iOS   SIMULATEOR. 
SO IT INSTALLS APPS ON THEM,   
PUTS
 ALL THE TEST   CONFIGURATION 
DATA
 ON THE   DEVICE AND LAUNCHES 
THE APP,
   FOR EXAMPLE,. 
AND THEN IT RUNS THE TEST AND   
THEN
 HANDLES THE UNDERLIEYING   
COMMUNICATION
 ACROSS   DIFFERENT TESTS USING 
SIGNAL
  SIGNALING AND THEN AT THE END 
  OF
 THE TEST, IT CREATES A   TEST 
REPORT
 AND ALSO PULLS   ALL THE 
NECESSARY
 TEST   ARTIFACTS LIKE BUG 
REPORTS,
   SCREEN SHOTS FROM A DEVICE OR
   EMULATORS
 AND PERFORMS ANY   NECESSARY 
CLEANUPS.
NOW, LET'S SEE ANOTHER DEMO   OF
 OCTOPUS
 IN ACTION.  IN   THIS DEMO, YOU
 SEE
 OCTOPUS   LAUNCHING MULTIPLE i
OS
   SIMULATEORS AT ONCE AND RUN 
AS 
  TEST ON THEM, WAITS FOR ALL   
OF THEM
 TO FINISH BEFORE IT   FINALLY 
EXITS.

SEE
 OCTOPUS LAUNCHES FIVE i  IOS 
SIMULATORS.
EACH   REPRESENTS A DIFFERENT i
OS
   VERSION.  SO IT RUNS THE LOG-
  LOG-IN
 AND LOGOUT FOR ALL OF   THE 
SIMULATORS.
AND ONE BY   ONE THEY LOG OUT 
AND THEY
   EXIT.  AND OCTOPUS WILL WAIT 
  FOR
 ALL OF THEM TO FINISH   BEFORE 
IT
 FINALLY EXITS. 
SO USING PARALLELIZEED TEST   
RUNS,
 WE CAN USE IT TO SHORE   OUR 
TEST
 ACROSS MULTIPLE TEST   TARGETS 
TO
 SPEED UP OUR TESTS  TESTS.  
ANOTHER
 USEAGE IS THAT   SIMILAR TO THE
 WEB
 TESTING   WORLD, YOU CAN RUN 
THE SAME
   TESTS ACROSS DIFFERENT iOS   
VERSIONS
 TO MAKE SURE THE   TEST RUNS 
FOR ALL
 OF THEM.

OVER
 TO BIAN WHO IS GOING TO   DEEP 
DIVE
 INTO THE DESIGN OF   OCTOPUS. 
&amp;gt;&amp;gt;Bian Jiang:  THANK YOU,   
APPLE.
MY NAME IS BIAN, I'M   FOR THE 
TESTING
 TEAM AT UBER.    BEFORE UBER I 
WAS
 WORKING FOR   FACEBOOK ON THE 
PERFORMANCE
   TESTING FRAMEWORK FOR MOBILE 
  APPLICATIONS.
TODAY LET'S   TALK ABOUT SOME 
TECHNICAL
   DETAILS.  BEFORE THAT, LET ME
   SHARE
 WITH YOU SOME OF THE   DESIGN 
PHILOSOPHYIES.
SO,   FIRST OF ALL, WE WANT TO 
MAKE
   SURE OCTOPUS IS EASY TO USE. 
   SO
 ALL THE DEMOS YOU SEE   TODAY 
IN THE
 SLIDES IS   TRIGGER BID A 
SINGLE OCTOPUS
   COMMAND LINE WHICH IS UNIFY
IED 
  AND SIMPLIFYIED ACROSS   
DIFFERENT
 PLATFORMS. 
AND WE WANT TO MAKE SURE   
OCTOPUS
 WORKS THE SAME WAY   WITH 
DIFFERENT
 PLATFORMS LIKE   ANDROID, iOS, 
SIMULATOR,
   EMULATOR, AND REAL DEVICES. 
AND WE CHOSE TO INTEGRATE   WITH
 THE
 EXISTING TESTING   FRAMEWORKS 
SUCH
 AS YAM,   ESPRESSO, OR UI 
AUTOMATION
 SO   YOU CAN USE THE 
FUNCTIONALITY
   DIRECTLY AND NOT INTRODUCING 
  ANOTHER
 LAYER. 
LET'S TALK ABOUT SIGNALING.    
BEFORE
 I GET INTO THE   TECHNICAL 
DETAILS
 LET ME   SHARE WITH YOU SOME OF
 THE
   TECHNOLOGYIES.  THE TEST HOST
   IS
 WHERE OCTOPUS RUNS.  IT   COULD
 BE
 A iPAD MINI OR A   LAPTOP THAT 
YOU
 WORK ON EVERY   DAY.  AND THE 
ACTUAL
 TEST   CODE IS RUNNING ON A 
TEST 
  TARGET WHICH COULD ACTUALLY   
BE SIMULATORS,
 EMULATORS AND   REAL DEVICES.  
AND
 BETWEEN   TEST TARGETS, WE HAVE
   COMMUNICATION
 CHANNELS.  AND   IN THE 
COMMUNICATION
 CHANNELS  CHANNELS, WE PASS 
AROUND
   SIGNALS.  WE WANT TO MAKE   
SURE
 THAT OCTOPUS IS SIMPLE   TO 
UNDERSTAND
 AND EASY TO   IMPLEMENT.  SO WE
 JUST
 USE   VERY SIMPLE STREAMS FOR  
 SIGNALS.
AND IT IS THE TEST   TARGETS AND
 TEST
 CODE'   RESPONSIBILITY TO 
INTERPRET
   THE MEANING OF THE SIGNALS   
FOR
 THE DRIVER ONLINE AS   APPLE 
MENTIONED
 EARLIER. 
SO HOW DOES IT WORK?  USING   
THE SAME
 EXAMPLE IN THE   END-TO-END 
APPLE
 JUST   MENTIONED WE HAVE DRIVER
 TEST
   TARGET AND THE RIDER TEST   
TARGET.
SO FIRST THE DRIVER   SENDS -- A
 DRIVER
 ONLINE TO   THE RIDEER TEST 
TARGET
 AND THE   RIDER TEST TARGET 
REQUESTS
   FOR A TRIP AND SENDS ABOUT A 
  CAN
 ANOTHER SIGNAL TELLING   DRIVER
 THAT
 I HAVE ALREADY   REQUESTED A 
TRIP
 AND YOU CAN   GO -- YOU CAN 
PROCEED
 FOR THE   VERIFICATION UI 
ORESTES
 STEPS  STEPS. OR TEST STEPS  
STEPS.

WORKFLOW
 WE INTRODUCED TWO   VERY SIMPLE
 APIs.
THE
 READ   SIGNAL WHICH UNTIL IT IS
   BLOCKED OR TIMEOUT.  IT IS A 
  SIGNAL
 FROM A CHANNEL IN THE   STREAM 
OR
 IT WILL TIMEOUT.    
CORRESPONDINGLY
 WE HE WILL   HAVE WRITE SIGNAL 
WHICH
   WRITES ANOTHER STREAM TO A   
CHANNEL
 WHICH IS A NON-  NON-BLOCKING 
CALL.
THE API WORKS AS BELOW USING   
THE
 SAME EXAMPLE, WE HAVE   DRIVER 
AND
 THE RIDER.  SO,   FIRST, THE 
RIDER
 CALLS READ   SIGNAL AND THE 
CHANNEL
 IS   RIDER INBOX.  THE RISEER 
INBOX
   IS A CHANNEL THAT CONTAINS   
ALL
 THE INCOMING MESSAGES FOR   THE
 RIDER.
AND THEN THE   DRIVER WILL CALL 
THE
 WRITE   SIGNAL ON ON THE SAME 
CHANNEL
   WITH A SIGNAL CALLED DRIVER  
 ONLINE.
AND THIS FUNCTION   CALL WILL 
TRIGGER
 THE RETURN   OF THE READ SIGNAL
 ON
 THE   RIDER SIDE. 
AFTER THAT, THE DRIVER WAITS   
FOR
 ANOTHER SIGNAL BY CALLING   A 
RESIGNAL
 ON ANOTHER CHANNEL   WHICH IS 
DRIVER
 INBOX WHICH   IS ALL THE 
INCOMING
 MESSAGES   FOR THE DRIVER.  AND
 THIS
   READ SIGNAL FUNCTION CALL   
WILL
 BE TRIGGERED BY ANOTHER   
FUNCTION
 CALLED WRITE SIGNAL   FROM THE 
RIDER
 SIDE.  SO THIS   IS HOW THE API
 WORKS
 AT A   VERY HIGH LEVEL. 
SO HOW DO WE (INDISCERNIBLE).   
 AT
 A VERY HIGH LEVEL, WE HAVE   
THE TWO-WAY
 COMMUNICATION   CHANNEL BETWEEN
 TEST
 TARGETS.    BUT INTERNALLY WE 
HAVE
 TWO   ONE-WAY COMMUNICATION 
CHANNEL
  CHANNELS LIKE THE RIDER INBOX 
  AND
 THE DRIVER INBOX. 
SO IT'S CALLED P2P   
COMMUNICATION
 BETWEEN TWO   TEST TARGETS OR 
MULTIPLE
 TEST   TARGETS.  IT IS EASY TO 
THINK
   OF SOME P2P TECHNOLOGYIES 
LIKE 
  BLUETOOTH, DIRECT INTERNET   
CONNECTION,
 NFC OR AIR DROP.    SO WE HAVE 
PLENTY
 OF CHOICES   BUT WE DO HAVE A 
PROBLEM
   WHICH IS THE CONSISTENCY.    
BECAUSE
 ONE TECHNOLOGY MIGHT   WORK 
PERFECTLY
 ON ONE   PLATFORM BUT NOT ON 
ANOTHER.
  SO IF WE CHOOSE DIFFERENT   
INVITATIONS
 OR DIFFERENT   TECHNOLOGYIES ON
 DIFFERENT
   PLATFORMS, WE WILL END UP   
WITH
 MULTIPLE INVITATIONS FOR   
DIFFERENT
 PLATFORMS WHICH   WILL THEN 
INCREASE
 THE   COMPLEXITY OF OUR SYSTEM.

CONSISTENT
 WAY WHICH IS THE   RELAY TEST 
HOST
 BECAUSE IN   THE TEST SCENARIO,
 THE
   COMMUNICATION CHANNEL BETWEEN
   TEST
 HOST AND TEST TARGET IS   
ALWAYS CONSISTENT
 AND RE  RELIABLE.  SO IN THE   
BEGINNING
 WE CHOSE A CLIENT   SERVEER 
ARCHITECTURE
 WHICH IS   VERY EASY TO THINK 
ABOUT.
SO   THE TEST TARGET AND TEST 
HOST
   COMMUNICATES WITH SOME   
NETWORK
 PROTOCOL.  THIS IS   EASY, AND 
THIS
 IS TYPICAL.    BUT THERE'S A 
PROBLEM
 IN THIS   ARCHITECTURE, TOO, 
WHICH
 IS   THE REACHABILITY. 
BECAUSE YOUR TEST HOST, YOUR   
MACK
 MINI   MAC MINUTE ME OR LAPTOP 
IS
   RUNNING IN YOUR PROTECTED   
NETWORK
 LIKE YOUR DATA CENTER   OR YOUR
 CORP
 NET.  YOUR TEST   TARGET MIGHT 
BE
 RUNNING IN   THE PUBLIC WiFi OR
 EVEN NO   NETWORK IF YOU WANT 
TO TEST
   IT IN OFFLINE MODE. 
SO IT'S NO GUARANTEE THAT A   
TEST
 HOST IS ALWAYS REACHABLE   BY 
THE
 TEST TARGET.  SO THAT   MEANS 
WE NEED
 TO FIND   SOMETHING MORE RE
LIABLE
 AND   ALWAYS AVAILABLE BECAUSE 
  WE'RE
 RUNNING A TEST SCENARIO   SO WE
 CHOSE
 A MORE RELIABLE   CONNECTION 
WHICH
 IS AN USB.    SO IMAGINE YOU 
ARE DOING
 YOUR   DEVICE TESTING.  YOU 
ALWAYS
   CONNECT YOUR DEVICES USING AN
   USB
 CABLE TO YOUR DEVICE HOST  
HOST.
IT WORKS THE SAME WAY   WITH THE
 SIMULATOR
 AND THE   EMULATOR BECAUSE THE 
TESTING
   FRAMEWORK PROVIDES THE   
CONSISTENT
 COMMUNICATION   CHANNEL BETWEEN
 TEST
 HOST AND   TEST TARGET. 
SO BY USING THIS, WE   IMPLEMENT
 A
 VIRTUAL TWO-WAY   COMMUNICATION
 BETWEEN
 TEST   TARGETS.  SO NOW WE HAVE
 THE
   COMMUNICATION PROTOCOL OR WE 
  HAVE
 THE COMMUNICATION   CHANNEL.  
WHAT
 DO WE PASS   AROUND IN THE 
COMMUNICATION
   CHANNELS? 
WE CHOSE THE MOST FUNDAMENTAL   
AND
 MOST RELIABLE STORAGE   UNIT IN
 THE
 OPERATING SYSTEM,   WHICH IS A 
FILE.
HERE'S HOW   IT WORKS.  SO, 
FIRST,
 THE   DRIVER GENERATES THE FILE
   CONTAINING
 A STRING CALLED   DRIVER ONLINE
 ON
 THE TEST   TARGET.  AND THEN 
THIS
 FILE   IS PASSED FROM THE TEST 
  TARGET
 TO THE TEST HOST. 
AND THE TEST HOST RELAYS THE   
SIMULATOR --
 THE SIGNAL   STREAM TO A TEST 
TARGET.
SO   LOGICALLY, WE HAVE THE SAME
   (INDISCERNIBLE)
 OF WRITE   SIGNAL. 
NOW THE QUESTION BECOMES HOW   
DO WE
 PASS AROUND FILES?  SO   
SPECIFICALLY
 WE HAVE TWO   QUESTIONS TO 
ANSWER.
THE   FIRST ONE IS:  HOW DO WE 
SEND
   A FILE OVER THE STREAM FROM  
 TEST
 TARGET TO TEST HOST?    WHICH 
IS ESSENTIALLY
 THE   IMPLEMENTATION OF THE 
WRITE
   SIGNAL.  AND CORRESPONDINGLY,
   WE
 HAVE ANOTHER QUESTION, HOW   DO
 WE
 WATCH WHILE MONITORING   A FILE
 FROM
 THE TEST HOST TO   THE TEST 
TARGET
 BECAUSE YOUR   TEST CODE IS 
RUNNING
 ACTUALLY   ON THE TEST TARGET 
WHICH
 IS   ESSENTIALLY THE IMITATION 
OF
   THE READ SIGNAL.  THIS IS THE
   WAY
 OCTOPUS DIVERGES ON   DIFFERENT
 PLATFORMS
 SO LET'S   TALK ABOUT THEM ONE 
BY
 ONE.

PROVIDES
 A VERY CONVENIENT   API CALLED 
UIA
 HOST.PERFORM  HOST.PERFORMTASK
WITHPATH
  ARGUM     
HOST.PERFORMTASKWITHPATHARGUM
   ENTSTIME-OUT WHICH IS THE   
EQUIVALENT
 OF EXEC.  YOU CAN   SHARE ANY 
COMMAND
 HOSTS ON   THE TEST HOST WHICH 
IS
 REALLY   CONVENIENT.  WITH THAT
, THE
   WRITE SIGNAL AND READ SIGNAL 
  BECOME
 VERY SIMPLE TO   IMPLEMENT.  SO
 FOR
 THE WRITE   SIGNAL, WE JUST 
WRITE
   SOMETHING TO SOME FILE ON THE
   TEST
 HOST. 
AND FOR READ SIGNAL, WE JUST   
USE
 CAT TO CHECK THE CONTENT   OF 
THE
 FILE.  SO THE ACTUAL   
IMPLEMENTATION
 OF READ SIGNAL   ON iOS IS A 
LITTLE
 BIT MORE   COMPLICATED.  WE 
HAVE A
 SHELL   LOOP WHICH IS 
CONSTANTLY 
  CHECKING THE FILE CONTENT FOR 
  THE
 SIGNAL AND THEN TRIGGERED   THE
 RETURN
 OF READ SIGNAL   ONCE THE FILE 
CONTENT
 HAS   CHANGED. 
ON THE OTHER SIDE, ANDROID --   
UNFORTUNATELY
 THERE'S NO   DIRECT EXEC.  
EVERYTHING
   SHOULD BE INITIATED FROM TEST
   HOST.
SO WE HAVE TO USE ADB   SHELL AS
 A
 RELAYER. 
SO HERE IS HOW IT WORKS. 
FOR THE WRITE SIGNAL, THE   TEST
 HOST
 STARTS A DAEMON   PROCESS WHICH
 MONITORS
 A   SIGNAL FILE ON THE TEST   
TARGET --
 ON ONE OF THE TEST   TARGETS 
USING
 ADB SHELL.  AND   THEN THE 
DRIVER
 GENERATES THE   FILE OR CHANGES
 THE
 FILE   CONTENT ON THE TEST 
TARGET
   WHICH WILL BE DETECTED BY THE
   TEST
 HOST, BY THE DAEMON   RUNNING 
ON TEST
 HOST. 
AND THEN THE TEST HOST GRABS   
THE
 FILE FROM THE DRIVER TEST   
TARGET
 AND RELAYS IT TO THE   OTHER 
TEST
 TARGET FOR THE   RIDER.  SO 
LOGICALLY
 WE   IMPLEMENTED WRITE SIGNAL 
FROM
   THE DRIVER TO RIDER. 
BECAUSE WE WE ARE PUSHING A FILE

TARGET,
 THE READ SIGNAL   BECOMES 
REALLY SIMPLE.
WE   JUST USE THE FILE OBSERVE  
 YEAREND
 DO TO MONITOR THE   CONTENT OF 
THE
 FILE ONCE IT'S   CHANGED, WE 
TRIGGER
 THE   RETURN OF THE READ SIGNAL
. 
 AS YOU CAN SEE THE DESIGN OF   
THE
 SIGNALING OCTOPUS IS   REALLY 
FLEXIBLE
 AND SCALEABLE   SO THAT IT IS 
VERY
 EASY TO   IMPLEMENT ONE-TO-ONE 
SIGNAL
  SIGNALING, ONE-TO-MANY SIGNAL 
 SIGNALING,
 AS WELL AS THE M   MANY-TO-MANY
 SIGNALING.
THE   MAJORITY OF SIGNALING IS  
 PLATFORM
 AGNOSTIC.  THE ONLY   THING 
THAT DIVERGES
 IS THE   ACTUAL FILE 
OBSERVATION ON
   DIFFERENT PLATFORMS.  SO THAT
   IT'S
 EASY TO IMPLEMENT THE   CROSS-
PLATFORM
 SIGNALING.    IMAGINE YOU HAVE 
AN
 iOS   RIDER TALKING TO AN 
ANDROID
   DRIVER. 
SO GIVEEN THAT, I WOULD LIKE   
TO SHOW
 YOU ANOTHER DEMO   WHICH SHOWS 
THE
 MOST   COMPLICATED TEST 
SCENARIO IN
   UBER APPLICATION WHICH IS   
UBER
 POOL.  AS APPLE   MENTIONED, IF
 YOU
 HAVE   MULTIPLE RIDERS COMING 
TO THE
   SAME LOCATION, THEY CAN SHARE
   THE
 SAME CAR WITH THE SAME   DRIVER
 WHICH
 REQUIRES ONE   DRIVER AND 
MULTIPLE
 RIDERS.    SO AS YOU CAN SEE, 
WE HAVE
   THREE SIMULATORS, A DRIVER   
AND
 TWO RIDERS.  ALL OF THEM   SIGN
 IN.
THE DRIVER GOES   ONLINE. 
AFTER THAT, IT SENDS THE   
DRIVER ONLINE
 SIGNAL TO THE   FIRST RIDER.  
THEN
 THE FIRST   RIDER PICK UP A 
LOCATION
 AND   SELECTED A DESTINATION   
REQUEST
 FOR THE SHARED RIDE   WHICH IS 
UBER
 POOL WHICH WILL   BE CAPTUREED 
BY
 THE DRIVER.    AND THE DRIVER 
WILL
 PICK UP   THE FIRST RIDER AND 
THEN
 SEND   ANOTHER SIGNAL TO A 
SECOND
   RIDER SAYING I ALREADY PICKED
   UP
 THE FIRST RIDER.  THE   SECOND 
RIDER
 CAN START TO   REQUEST THE UBER
 TRIP
 NOW.    THE SECOND RIDER GOT 
THE 
  SIGNAL, PICK UP THE LOCATIONS 
  AND
 REQUEST FOR A SHARED RIDE  
RIDE.
AND AS YOU CAN SEE ON   THE 
DRIVER
 SIDE, THE SECOND   PICKUP HAS 
DIFFERENT
 UI SO WE   WILL HAVE DIFFERENT 
  VERIFICATIONS
 OF THE TEST   STEPS. 
AND AFTER THE TWO RIDERS ARE   
PICKED
 UP, THE DRIVER WILL   START THE
 TRIP
 AND THEN DROP   OFF THE FIRST 
RIDER.

 AND AFTER THAT, THE DRIVER   
WILL --
 THE RIDERS AND THE   WHOLE TEST
 SCENARIO
 . 
SO AS I MENTIONED, THE WHOLE   
?RO
 IS TRIGGERED   SCENARIO IS 
TRIGGERED
 BY ONE   OCTOPUS.  IT HANDLE   
BOOTSTRAPPING, --
 AND THE   SAMUELS BETWEEN   
SIMULATION
 BETWEEN TEST   TARGETS.  IT IS 
HANDLED
 BY   OCTOPUS SIGNALING. 
SO THAT'S WHAT I HAVE. 
QUESTIONS.

FIRST TWO
 QUESTIONS ARE   PRETTY MUCH 
DUPLICATES,
 WHICH   IS, WHY IS THERE A NEED
 TO
   TEST BOTH THE APPS AT THE   
SAME
 TIME, WHY NOT SIMULATE   
REQUESTS
 AND RESPONSES AND   HAVE FAKE 
BACK-ENDS?
&amp;gt;&amp;gt;Bian Jiang:  SO WE DO HAVE   
DIFFERENT
 TEST MODES.  SO   THIS ONE IS 
THE
 FULL   END-TO-END TEST MODE.  
THE
   REASON WHY WE NEED THIS IS   
SOMETIMES
 WHEN YOU TEST THE   DIFFERENT 
CONFIGURATIONS
 ON   THE SERVER SIDE, FOR 
EXAMPLE,
   WE HAVE A TEST CD WITH   
CERTAIN
 FUNCTIONALITIES   ENABLED, WE 
HAVE
 OTHER TESTS   WITH DIFFERENT   
FUNCTIONALITIES.
WE HAVE   SOME DYNAMICS ON THE 
SERVER
   SIDE, WE WANT TO MAKE SURE WE
   HAVE
 A TEST SCENARIO TO COVER   
DIFFERENT
 SCENARIOS, BOTH ON   THE CLIENT
 SIDE
 AND THE   SERVER SIDE.  THAT'S 
WHY
 WE   NEED END-TO-END WHICH   
SCHMALTZ
 BOTH THE RIDER AND   THE DRIVER
 SIDE.

LIKE,
 REPLACEMENT FOR UNIT   TESTS OR
 MEDIUM-LEVEL
   COMPONENT TESTS WHERE YOU CAN
   MOCK
 OUT SERVER RESPONSES.    THIS 
IS MEANT
 FOR A SMALL   FRACTION OF YOUR 
--
 YOU KNOW,   LIKE, YOUR CORE 
HAPPY
 PATH   TESTS THAT GIVE YOU THE 
FINAL
   CONFIDENCE THAT YOUR SYSTEM  
 SYSTEM --
 YOU KNOW, THE   HIGH-LEVEL 
COMPONENTS
 IN YOUR   SYSTEM IS CONNECTED 
CORRECTLY
  CORRECTLY.  SO IT'S ONLY A   
SMALL
 FRACTION OF IT THAT   GIVE YOU 
FINAL
 CONFIDENCE.    SO WE ARE USING 
ALL
 DIFFERENT   MODES IN OUR TESTS.

LIKE IT
 WOULD BE HARD TO   IDENTIFY 
ROOT CAUSES
 OF TEST   FAILURE WHEN THERE 
ARE TWO
   SEPARATE UNITS UNDER TEST AND
   THERE
 ARE DIFFERENT TESTS IN   
DIFFERENT
 PROCESS SPACES .    HAS THIS 
PROVEN
 TO BE A   CHALLENGE PRACTICE? 
&amp;gt;&amp;gt;Apple Chow:  ACTUALLY, FOR   
FOR --
 USING THIS ACTUALLY   MAKES OUR
 TESTS
 EASIER TO DE  DEBUG, BECAUSE 
EACH
 TEST IS   ONLY WAITING FOR ONE 
THING
 AT   A TIME.  SO WHEN SOMETHING
   FAILS,
 YOU -- THERE'S NO   DOUBT BY, 
LIKE,
 FOR EXAMPLE,   DID THE RIDER --
 DID
 THE   DRIVER GO ONLINE BEFORE I
   REQUEST?
LIKE, IF SOMETHING   FAILS, YOU 
KNOW
 THAT, OKAY,   DRIVER ALREADY 
SENT
 THE   SIGNAL.  THAT'S ONLINE.  
THAT
   MEANS IT'S SOMETHING ON THE  
 RIDER
 SIDE. 
SO WE'RE -- IF YOU DON'T HAVE   
THIS,
 YOU WOULD BE POOLING   FOR 
DIFFERENT
 CONDITIONS, AND   SOMETIMES THE
 CONDITIONS
 ARE   NOT EVEN VISIBLE ON THE 
UI 
  AND IT'S REALLY HARD.  SO I   
THINK
 HAVING THIS DEFINITELY   MAKES 
THE
 TEST EASIER TO   WRITE AND 
EASIER
 TO DEBUG. 
&amp;gt;&amp;gt;Yvette Nameth: 
 DO YOU   EXPERIENCE
 FLAKKINESS WHEN   SENDING 
SIGNALS
 BETWEEN   EMULATORS? 
&amp;gt;&amp;gt;Bian Jiang:  SO BECAUSE --   
BECAUSE
 THE TEST CODES ARE   RUNNING ON
 DIFFERENT
   SIMULATORS, SO   
(INDISCERNIBLE)
 IS   CHALLENGING.  SO THAT'S 
WHY 
  WE CHOSE THE -- AS RELIABLE   
AN APPROACH
 AS POSSIBLE, LIKE   THE FILE
-BASED
 SIGNALING, THE   USB CONNECTION
, TO
 REDUCE THE   FLAKYINESS. 
SO SO FAR, WE DIDN'T SEE MANY   
FLAKINESS.
IT'S PRETTY   STABLE, BECAUSE WE
 USED
 THE   MOST RELIABLE TECHNOLOGY.

 APPIUM,
 FOR EXAMPLE, THAT   WE LOOK 
INTO SERVER-SIDE
   ARCHITECTURE.  SO FAR, THE   
FLAKINESS
 WE FOUND IS NOT   FROM THE 
SIMULATOR.
IT'S   MORE FROM THE REAL-TIME  
 SERVER
 RESPONSES,   OCCASIONALLY, IT 
TIMES
 OUT.    BUT IT'S NOT ABOUT 
SIGNALING.
&amp;gt;&amp;gt;Yvette Nameth:   OKAY.    
COULD YOU
 CLARIFY WHAT THE   SYSTEM UNDER
 TEST
 ACTUALLY IS  IS.  IT SOUNDS 
LIKE YOU --
 MY   QUESTION LEFT. 
[ LAUGHTER ]  
I'M SORRY. 
DO YOU HAVE IT, DIEGO, THAT I   
CAN
 READ? 
&amp;gt;&amp;gt;&amp;gt; WHICH QUESTION? 
&amp;gt;&amp;gt;Yvette Nameth:  THE -- 
IS IT BACK THERE?  OH, YEAH.    
THERE
 IT IS.  THANKS, GUYS,   FOR UP
LOADING.
IT SOUNDS LIKE YOU COMPROMISE   
PERFORMING
 END-TO-END TESTING   WITH YOUR 
TEST
 INFRASTRUCTURE   IN BETWEEN THE
 APPS,
 WHICH IS   NOT THE CASE IN 
PRODUCTION.
  COULD YOU ELABORATE ON THAT. 
SO WHAT ARE YOU ACTUALLY   
TRYING TO
 TEST WITH THIS TYPE   OF TEST, 
IS
 BASICALLY THE   QUESTION.  AND 
WHAT --
 YOU   KNOW, WHAT WERE THE   
COMPROMISES
 MADE?  OR WHAT   OTHER THINGS 
DID
 YOU HAVE TO   PUT INTO PLACE TO
 MITIGATE
   ANY -- 
&amp;gt;&amp;gt;Apple Chow:  I THINK, ON   TOP
 OF
 HAVING UNIT TESTS AND   THEN 
THE TESTS
 THAT, LIKE, IF   YOU MOCK OUT 
THE
 DRIVER AND   LOOK AT THE RIDER 
  SPECIFICALLY,
 THIS ALLOWS YOU   TO TEST, LIKE
, THE
 CORE FLOW,   THE MORE 
COMPLICATED
   INTERACTIONS BETWEEN THE TWO 
  TO
 MAKE SURE WHEN YOU GO   THROUGH
, LIKE,
 THE CORE CHIP   LOAD, WHICH IS,
 LIKE,
 ONE OF   OUR CORE CASES, RIGHT,
 TO
   MAKE SURE, LIKE, EACH APP CAN
   GO
 THROUGH THE EXPECTED   SEQUENCE
 OF
 STATE CHANGES AND   THEN IS 
ABLE TO
 COMPLETE THE   TRIP, AND, YOU 
KNOW,
 COMPLETE   THE HAPPY PATH.  AND
 THEN
 AT   THE END, THEY CAN REACH 
EACH
   OTHER. 
&amp;gt;&amp;gt;Bian Jiang:  SO OCTOPUS IS   
NOT
 MAKING ANY MODIFICATIONS   ON 
THE
 APPLICATION ITSELF.    IT'S NOT
 --
 IT'S NOT   MODIFYING THE 
BACK-END
 AS   WELL.  SO WE'RE TESTING   
WHATEVER
 WE HAVE.  EITHER   IT'S 
PRODUCTION
 OR IT'S TEST   STAGE 
ENVIRONMENT,
 OR IT'S   THE BETA APPLICATION.
&amp;gt;&amp;gt;Yvette Nameth:  WELL, THANK   
YOU,
 APPLE AND BIAN. 
[ APPLAUSE ]

RESTROOMS ARE LOCATED IN THE   
COMMON
 AREA.  THERE'S COFFEE,   TEA, 
WATER,
 ET CETERA, OUT   THERE.  BE 
BACK BY
 NOON.    WE'VE GOT A ROBOT TO 
WATCH.


TOM STOCKY
   TOUCH SENSOR
 CHO SEUNG-HUI
   CHIPT
 CHYNOWETH CHIPT
   MURA MURS
 MURA HAPTIC HAPT   HAPT
 ANIMATION
 ANIMATION
   ANIMATE MEMBER STATE MAGS
   ANIMATION ANIMATE MEMBER   
STATES
   TOUCHBOT TONY FADELL TAMPERE,
   FINLAND
&amp;gt;&amp;gt;Yvette Nameth:  WELCOME   BACK
, EVERYONE.

PRESENTER
 ON STAGE WITH US. 
ONE --  BY THE WAY, IF YOU   
HEAR THE
 COWBELL LIVE, YOU   NEED A 
BETTER
 WATCH OR PHONE   THAT KEEPS 
TIME.
SO PLEASE   DON'T HEAR THE 
COWBELL
 LIVE. 
FOR EVERYONE HERE, REMEMBER,   
WE ARE
 POSTING THE SLIDES   ONLINE 
AFTERWARDS.
SO DON'T   FEEL COMPELLED TO 
WRITE
   EVERYTHING DOWN THAT YOU'RE  
 SEEING
 ON THE SLIDES OR THE   
INFORMATION
 OR WHATNOT.  THAT   WILL BE 
AVAILABLE
 LATER. 
BUT WITHOUT FURTHER ADO, I   BET
 YOU'RE
 WONDERING WHAT   THIS ROBOT 
DOES.
I AM. 
SO HANS AND NATALIA FROM   
OPTOFIDELITY
 ARE GOING TO   TALK ABOUT ROBOT
-ASSISTED
   TEST AUTOMATION. 
&amp;gt;&amp;gt;Hans Kuosmanen:  ALL RIGHT.   
 HELLO,
 EVERYBODY.  MY NAME IS   HANS 
KUOSMANEN,
 VP OF TEST   SOLUTIONS AT 
OPTOFIDELITY.
  I'M HERE WITH NATALIA   
LEINONEN,
 OUR SENIOR SOFTWARE   ENGINEER,
 AND
 WE'RE REALLY   EXCITED TO HAVE 
THIS
   OPPORTUNITY TO TELL YOU GUYS 
  ABOUT
 ROBOT-ASSISTED TEST   
AUTOMATION.

 TO
 GO THROUGH TODAY,   FIRST OF 
ALL,
 I'M JUST GOING   TO TELL A 
LITTLE
 BIT ABOUT   WHO WE ARE AND 
WHERE WE'RE
   COMING FROM. 
AND WE'RE GOING TO TELL YOU   
THINGS
 ABOUT MEASURING USER   
EXPERIENCE
 OF MOBILE DEVICES. 
ALSO, THE HARDWARE TESTING   
LANDSCAPE,
 WHERE THE   REQUIREMENTS ARE 
COMING
 FROM,   AND SO FORTH. 
AND ALSO, WHEN YOU SHOULD USE   
ROBOTICS
 TO TEST APPLICATIONS   AND 
DEVICES.

ABOUT
 GOOGLE CHROME TOUCHBOT   THAT 
WE'VE
 DELIVERED DURING   THE SUMMER. 
AND THEN WE WILL HAVE THE   DEMO
, WHICH
 EVERYBODY IS   PROBABLY WAITING
 FOR.

TO HAVE
 SOME Q&amp;amp;A LATER ON,   TOO,.

LITTLE
 BIT ABOUT OPTOFIDELITY  
OPTOFIDELITY.
PARTLY BECAUSE   THE MARKETING 
PEOPLE
 JUST   TOLD ME TO. 
[ LAUGHTER ]  
BUT ALSO BECAUSE   I LIKE TO   
TELL
 YOU WHERE -- WHAT'S THE   
BACKGROUND
 OF THE COMPANY. 
SO WE'RE A FINNISH COMPANY,   
ESTABLISHED
 IN 2005.  AND   WE'VE BEEN 
WORKING
 WITH TEST   AUTOMATION FOR 
RADCLIFFE
 R&amp;amp;D FOR MOBILE   DEVICES.  SO 
WE'RE
 KIND OF   HARDWARE-CENTRIC 
PEOPLE.

THE
 OPTICAL TEST AND   MEASUREMENT,
 SO
 IMAGING,   MACHINE VISION.  
THAT'S
   PRETTY MUCH THE PROJECTS THAT
   WE
 WERE WORKING ON IN THE   
BEGINNING.
AND THEN AT ABOUT 2008, WE   
STARTED
 GETTING MORE AND MORE   
INVOLVED IN
 ROBOTICS.  THE   REASON FOR 
THAT WAS
 THE   EMERGING OF TOUCH PANELS 
AND
   TOUCH SENSING ON THOSE   
DEVICES,
 ON MOBILE,   MULTIMEDIA DEVICES
. 
SO FAR, WE'VE BEEN DELIVERING   
SOLUTIONS
 TO PRETTY MUCH ALL   THE MAJOR 
ECOSYSTEMS
 AND ALSO   TO MOST OF THE CHIP 
VENDORS
   THAT PROVIDE TECHNOLOGY TO   
SMARTPHONES
 AND TABLETS. 
WE --  IN THE SPACE OF MOBILE   
DEVICE
 TESTING, WE ARE PRETTY   MUCH 
THE
 LEADERS IN   ROBOT-ASSISTED 
TEST AND
   AUTOMATION, WHICH MEANS   
UTILIZING
 ROBOTICS IN   ACTIVATING THE 
PRODUCTS,
   SIMULATING HUMANS.  WE'RE   
KIND
 OF BUILDING A HUMAN   SIMULATOR
 FOR
 TESTING DEVICES  DEVICES. 
THE HUMAN-LIKE UI PERFORMANCE   
TESTING
 IS SOMETHING THAT WE   ARE 
USING HIGH-SPEED
 CAMERAS   AND EXTERNAL SENSORS 
TO
   MEASURE THE ACTUAL USER   
EXPERIENCE
 OF THE END USER OF   THE 
PRODUCT.
IT CAN BE   EITHER APPLICATION 
OR JUST
 A   DEVICE ITSELF. 
ON TOUCH PERFORMANCE TESTING,   
WE
 HAVE DELIVERED SYSTEMS FOR   
CHARACTERIZING,
 CALIBRATING,   TESTING TOUCH 
SENSORS,
 VERY   ACCURATE ROBOTICS 
INVOLVED
   THERE. 
THE FIRST PROJECT, ACTUALLY,   
THAT
 WE STARTED OFF WITH WAS   ABOUT
 VIDEO
 QUALITY TESTING,   SO PERCEIVED
 VIDEO
 QUALITY OF   MOBILE DEVICE.  WE
 HAVE
   TECHNOLOGY, WE CAN MEASURE   
AND
 ANALYZE VIDEO DIRECTLY   FROM 
THE
 SCREEN OF THE DEVICE  DEVICE.  
BECAUSE
 MANY TIMES,   YOU DON'T HAVE 
ACCESS
 TO THE   ACTUAL VIDEO PLAYBACK 
OR
 YOU   DON'T HAVE RELIABLE 
ACCESS TO
   IT. 
AND ONE THING   THAT'S PRETTY   
CLOSE
 TO THE VIDEO PLAYBACK   IS THE 
UI
 ANIMATION AND HOW   SMOOTHLY 
THE UI
 IS ACTUALLY   WORKING.  IT ALSO
 GIVES
 THE   END USER THE PERCEPTION, 
IF
   THE UI IS GOOD OR IF IT'S BAD
   IF
 YOU HAVE, LIKE, A -- FRAME  
FRAME-SKIPPING
 OR THINGS     LIKE THAT WHEN 
YOU'RE
   ACTUALLY OPERATING, OPENING  
 APPS
 OR SWITCHING BETWEEN   APPS AND
 SO
 FORTH. 
THERE'S ACTUALLY ALSO SOME   
IMAGES
 OF THE TYPE OF   ROBOTICS THAT 
WE
 HAVE   DELIVERED.  SO WE --  
THIS
 IS   JUST ONE EXAMPLE.  SO WE  
 PROVIDE
 A LOT OF DIFFERENT --   A LOT 
OF DIFFERENT
 PLATFORMS,   A LOT OF DIFFERENT
 FORM
   FACTORS FOR DIFFERENT   
APPLICATIONS.

MEASURING
 THE USER EXPERIENCE  
EXPERIENCE.
I MEAN, USER   EXPERIENCE IS 
KIND OF
 A LARGE   CONCEPT.  SO THERE'S 
THINGS
   LIKE LOOK AND FEEL AND, YOU  
 KNOW,
 WHAT KIND OF COLORS YOU   NEED 
TO
 HAVE ON THE UI.    THAT'S NOT 
WITHIN
 OUR SCOPE.    SO IN OUR SCOPE, 
WE
 ARE   LOOKING FOR THINGS THAT 
WE 
  CAN ACTUALLY MEASURE AND GIVE 
  MEASUREMENT
 RESULTS
 FOR OUR   DATA .  THERE'S
 A COUPLE OF   THINGS ON THE 
SLIDE
 THERE   THAT ARE CONTRIBUTING 
TO A
   GOOD USER USER EXPERIENCE.  
AND
   THESE THINGS NEED TO BE IN   
ORDER
 FOR THE END USER TO   PERCEIVE 
THE
 QUALITY AS BEING   GOOD. 
I JUST WANT TO HIGHLIGHT A   
COUPLE
 OF THINGS WHERE   ROBOTICS IS 
GOING
 TO ADD SOME   BENEFIT AND SOME 
VALUE
 TO THE   TESTING. 
ONE OBVIOUS THING IS THE   TOUCH
 SENSOR.
SO THERE'S   REALLY NO OTHER WAY
 TO
   CHARACTERIZE, TO VALIDATE THE
   PERFORMANCE
 OF TOUCH OTHER   THAN HAVING 
ROBOTICS
 IN THERE   AND ARTIFICIAL 
FINGERS,
   STYLUS $,AND WHAT HAVE $ES.  
AND
 THE TOUCH IS   SOMETHING THAT'S
 ALSO
   EMERGING INTO WEARABLES AND  
 TO
 CARS.  IT'S PRETTY   
COMMONPLACE ALREADY
 IN THE   SMARTPHONES AND 
TABLETS,
   OBVIOUSLY.  BUT THERE'S A LOT
   OF
 DIFFERENT APPLICATIONS   COMING
 UP,
 EVEN JUST   HOUSEHOLD 
APPLIANCES ARE
   HAVING TOUCH ON IT.  SO TOUCH
   IS
 REALLY BIG, BIG THING.    I'M 
SURE
 THERE'S A TOASTER   WITH TOUCH 
INTERFACE
 ON IT. 
SO WE ARE PROVIDING SOLUTIONS   
FOR
 THE TOUCH ACCURACY, TOUCH   
RESPONSIVENESS.
THERE'S ALSO   PROXIMITY, LIKE 
HOVER
 OF THE   TOUCH.  THAT'S ANOTHER
 USER
   INPUT TO THE DEVICE.  ALSO   
FORCE-SENSING.
AND NOW, LIKE  LIKE, SURFACE PRO
 AND
 THE i  IPAD PRO -- NOW THE 
STYLUS
   SEEMS TO BE COMING BACK AS AN
   INPUT
 SOLUTION OR AN OPTION.    AND 
IT SEEMS
 THAT THERE'S   MUCH MORE 
TECHNOLOGY
 BEHIND   IT.  SO IT'S NOT JUST 
THE
 RE  REPLACEMENT OF THE FINGER. 
   THERE'S,
 LIKE, ANGLE AND   FORCE-SENSING
 ON
 THOSE   DEVICES ALSO. 
SO WE CAN PROVIDE THE   
EQUIPMENT,
 THE METHODS TO   TEST AND 
CHARACTERIZE
 ALL OF   THIS.

IMPORTANT
 AREA.  WE HEARD ON   THE 
KEYNOTE THAT
 THERE'S 300   HOURS OF VIDEO 
BEING
 UPLOADED   TO YouTUBE ALONE PER
 HOUR.    AND, YOU KNOW, 
EVERYBODY'S --
   20% OF INTERNET USERS ARE -- 
  THEY
 HAVE AN INSTAGRAM   ACCOUNT.  
EVERYBODY'S
 POSTING  POSTING, EVEN ME, POST
ING
     THEIR LUNCH PICTURES AND   
BREAKFAST
 TO FACEBOOK.  SO   USER -- END 
USERS
 ARE   EXPECTING THE IMAGE 
QUALITY
   TO BE PERFECT AND THE VIDEO  
 VIDEO --
 RECORDED VIDEO TO BE   REALLY 
GOOD.

 DEVICE
 MANUFACTURERS HAVE   TO FIND 
WAYS
 OF HOW TO GET A   BETTER IMAGE 
QUALITY,
 HOW TO   GET BETTER VIDEO 
QUALITY.
  AND IT'S NOT JUST ADDING MORE 
  MEG
 PIXELS, IT'S, LIKE,   
INTEGRATING
 THE SENSOR, LIKE   ACCELERATION
 GYROS,
 ALL THIS   INTO THE IMAGING 
CHAIN.
AND   THIS MAKES IT VERY   
COMPLICATED
 TO USE SOFTWARE  SOFTWARE-BASED
 INSTRUMENT
  INSTRUMENTATION IN THE   
PRODUCT,
 BECAUSE THERE'S SO   MUCH INTER
ACTION
 BETWEEN   THESE DIFFERENT 
HARDWARE
   COMPONENTS INSIDE THE DEVICE.

 BEING
 INTEGRATED INTO   THE -- THE 
PRODUCTS,
 LIKE   NEAR FIELD, WIRELESS 
SENSING,
   AND GYROS, ACCELERATION.  YOU
   NAME
 IT, THERE'S MORE AND   MORE 
STUFF
 COMING UP.  SO     THE MORE 
COMPLEX
 THE DEVICE   GETS, THE MORE 
INTERACTIONS
   YOU GET, THE MORE DIFFICULT  
 IT
 IS TO USE SOFTWARE-BASED   
AGENTS
 TO MEASURE AND TO TEST   AND 
VALIDATE.
SO WE ARE FOCUSING ON DOING   
ALL THE
 TESTING NONINTRUE   CIVIL SO WE
 DON'T
 HAVEINTRUSIVE  NONINTRUSIVELY, 
SO
 WE ARE   USING ROBOTICS  TO 
ACTIVATE
   THE PRODUCTS.  AND THIS GIVES
   US
 A MUCH MORE ROBUST WAY   THAT 
WORKS
 ACROSS DIFFERENT   TYPES OF 
EQUIPMENT
 AND   DEVICES.

TERM,
 WHERE ARE THE   REQUIREMENTS 
COMING
 FROM? 
SO, WELL, THE REQUIREMENTS   ARE
 COMING
 FROM THE END USER.    THAT'S 
ONE OF
 THE REASONS WHY   WE ARE KIND 
OF DOING
 THE   HUMAN-LIKE TESTING.  WE 
TRY
   TO TEST THE WAY THAT THE END 
  USER'S
 PERCEIVING THE   OPERATION AND 
THE
 FEEDBACK   FROM THE PRODUCT. 
THE APP AND SOLUTION   
DEVELOPERS ARE
 KIND OF THE IN  IN-BETWEEN 
MESSENGERS
 TO THE   OPERATING SYSTEMS, 
ECOSYSTEMS
  ECOSYSTEMS, OF WHAT KIND OF   
FEATURES
 THE END USERS ARE   LOOKING AT.
  AND
 ALSO FINDING   NEW WAYS -- NEW 
ATTRACTIVE
   FEATURES FOR THE END USER TO 
  WANT.
SO THAT INFORMATION   KIND OF 
GETS
 INTO THE   ECOSYSTEM LEVEL.  
AND THEN
   THERE'S A WHOLE COMPLETE   
VALUE
 CHAIN BEHIND IT FOR   BUILDING 
THOSE
 DEVICES AND   VALIDATING THE 
COMPONENTS
   THAT GO INTO THEM. 
THERE'S CERTIFICATION IN SOME   
CASES,
 LIKE GOOGLE HAS THE CT  CTL, I 
THINK.
AND WINDOWS   HAS THE HCK.  SO 
THERE
 ARE   SOME REQUIREMENTS THAT 
COME
   FROM THE USER -- THE END USER
   LEVEL
 INTO THE ACTUAL   HARDWARE AND 
THE
 COMPONENTS. 
BUT OFTENTIMES IT'S JUST THE   
EQUIPMENT
 MANUFACTURER THAT   PRETTY MUCH
 MAKE
 UP THE   REQUIREMENTS, MAKE UP 
THE
   LIMITS. 
AND THEN ALL THESE LIMITS --   
OR THE
 METHODS AND THE LIMITS   GO 
INTO THE
 VALUE CHAIN TO R&amp;amp;  R&amp;amp;D TEAMS, 
TO PRODUCTION
 OF   THE EQUIPMENT, TO AFTER 
SALES
  SALES, LIKE, REFURBISHED   
BUSINESS.
ALL THESE GUYS ARE   USING THE 
SAME
 REQUIREMENTS. 
AND OUR SOLUTIONS, AS THEY   ARE
, LIKE,
 END-TO-END, NOT   INTRUSIVE WAY
S,
 YOU CAN USE   THEM FOR ALL OF 
THESE
   DIFFERENT PLAYERS ON THE   
ECOSYSTEM.
THE OTHER WAY TO LOOK AT THAT   
IS,
 LIKE, THE PRODUCT LIFE   CYCLE.
  SO
 FIRST YOU TRY TO   VALIDATE THE
 COMPONENTS
 AND   THE SENSE -- THE ACTUAL 
BITS
   AND PIECES AND THE CHIPSETS  
 AND
 WHAT HAVE YOU.  SO THE   
CHIPSET AND
 PLATFORM   PROVIDERS ARE DOING 
MOST
 OF   THE TESTING .  THE DEVICE 
  MANUFACTURERS
 GET INTO IT   ONCE THEY START 
TO INTEGRATE
   THESE INTO PRODUCTS.  THEN   
THERE'S
 GOING TO BE   FUNCTIONALITY, 
STABILITY,
 AND   INTERACTION OF THOSE 
HARDWARE
   COMPONENTS.  THE DEVICE OEMs 
 OEMs
 START TO DO MOST OF   THE 
TESTING.

 LAUNCHED
 AND ONCE THEY   ARE, LIKE, 
FINALIZED
 AND NEW   VERSIONS COME OUT, 
THERE'S
 A   WHOLE AREA OF SYSTEM-LEVEL 
  TESTING
 THAT I'M PRETTY SURE   MOST OF 
YOU
 GUYS ARE INVOLVED   IN THAT 
INVOLVE
 THE SOFTWARE,   THE APPLICATION
S,
 THE SERVER   BACK-ENDS AND WHAT
 HAVE
 YOU.    SO YOU GET OPERATOR AND
   SERVICE
 PROVIDERS,   APPLICATION 
DEVELOPERS
 ARE   MORE DOING THE ACTUAL 
TESTING
  TESTING.  BUT THIS MIGHT --   
THIS
 IS KIND OF A LIVING   THING 
THAT SOME
 OF THAT   TESTING IS KIND OF 
GOING
 BACK   TO THE DEVICE LEVEL ALSO
.
SO   THERE'S -- NOT ALL THE   
PLATFORMS
 ARE VERY STABLE IN   A WAY THAT
 YOU
 HAVE TO TAKE   INTO ACCOUNT A 
LITTLE
 BIT OF   THE HARDWARE.  AND 
THAT'S
 WHY   THERE'S A LOT OF TALKS 
ALSO
   IN THIS CONFERENCE ABOUT   
TESTING
 IN THE HARDWARE.    IT'S VERY 
IMPORTANT.
YOU   CAN'T JUST GO AND TEST   
EVERYTHING
 ON AN EMULATOR. 
SO INSTEAD OF JUST USING A   
DEVICE
 CLOUD, WHEN WOULD YOU   BE 
TESTING
 WITH A ROBOT? 
WELL, YOU COULD TEST   
EVERYTHING WITH
 A ROBOT.  BUT   A LOT OF TIMES 
IT
 DOESN'T   MAKE SENSE TO HAVE 
ALL YOUR
   TEST CASES RUN ON THAT.  BUT 
  THERE
 ARE SPECIFIC AREAS   WHERE THE 
ROBOTICS
 IS GOING   TO ADD A LOT OF 
BENEFIT
 AND A   LOT OF TEST COVERAGE TO
 YOUR
   TEST PORTFOLIO. 
MOST IMPORTANTLY, IT'S THE   
COMPLEX
 INTERACTIONS.  SO   MORE AND 
MORE
 HARDWARE   COMPONENTS, MORE AND
 MORE
   APPLICATIONS ARE RUNNING AT  
 THE
 SAME TIME WHEN YOUR APP   IS 
RUNNING.
AND OFTENTIMES   IT'S KIND OF 
HARD
 TO MAKE   SURE THAT YOUR TEST 
CONDUIT
   OR YOUR INSTRUMENTATION IS   
NOT
 ACTUALLY ONE PART OF THAT   
COMPLEX
 INTERACTION AND   AFFECTING 
YOUR TEST
 RESULTS. 
ALSO, WHEN YOU'RE USING   
PRODUCTION
 SOFTWARE, YOU   MIGHT NOT HAVE 
ALL
 THE   INSTRUMENTATION AVAILABLE
.
  YOU MIGHT NOT HAVE ALL THE DE 
 DEBUG
 FEATURES AND THE HOOKS.    OR 
IF YOU'RE
 TESTING HOW YOUR   DEVICES ARE 
BOOTING,
 LIKE,   THIS IS MORE LIKE 
OPERATING
   SYSTEM STUFF, SO IF YOUR   
DEVICE
 DOESN'T BOOT, HOW ARE   YOU 
GOING
 TO GET YOUR   INSTRUMENTATION 
SOFTWARE
 UP   AND RUNNING? 
SO A LOT OF TIMES, YOU NEED   
SOME
 SORT OF ROBOTICS, LIKE,   JUST 
PRESSING
 THE POWER   BUTTON OR, YOU KNOW
, DIS
  DISCONNECTING A POWER CABLE   
OR SOMETHING
 LIKE THAT. 
IN MEDICAL INDUSTRY, THERE'S   A
 LOT
 OF REGULATIONS THAT YOU   
CANNOT HAVE
 ANY   INSTRUMENTATION IN YOUR 
-- IN
   YOUR SYSTEM.  YOU CAN'T EVEN 
  HAVE
 EXTRA HARDWARE   COMPONENTS IN 
IT
 TO, YOU KNOW  KNOW, PULL OUT A 
DISPLAY
 TO A   FRAME DRIVER OR 
SOMETHING.
  SO YOU DON'T REALLY HAVE THE  
 MEANS
 TO GET THE DATA THAT   YOU 
COULD USE
 ON YOUR TEST   CASES. 
WHENEVER YOU NEED   CONTROLLABLE
, REPEATABLE
 UI   ACTUATION, THAT'S ALSO -- 
A 
  ROBOT WILL DO IT.  YOU CAN DO 
  IT
 PER MILLIMETER, EVEN 100-  
100-MICRON,
 10 MICRON, EVEN.    IF YOU NEED
 TO
 MOVE THE   PRODUCT AROUND, FOR 
EXAMPLE,
   TO ACTIVATE THE SENSOR LAYER 
  OF
 IT, THEN ROBOTICS IS THE   WAY 
TO
 GO. 
ALSO,   IF YOU NEED REAL-LIVE   
SENSOR
 DATA, LIKE IMAGE   
STABILIZATION OF
 A CAMERA,   FOR EXAMPLE, IT'S 
-- WHEN
   YOU'RE OPTIMIZING YOUR   
ALGORITHMS,
 IT GIVES A LOT OF   BENEFIT TO 
ACTUALLY
 MOVE THE   CAMERA AROUND, MOVE 
THE
   TARGETS AROUND IN A PRE  
PREDETERMINED
 FASHION SO THAT   YOU CAN 
ITERATE
 YOUR SOFTWARE   USING THE SAME 
TEST
   CONDITIONS EVERY TIME. 
BENCHMARKING AGAINST YOUR,   YOU
 KNOW,
 NEIGHBORING   OPERATING SYSTEM 
IS
 ALSO ONE   THING THAT IF YOU'RE
 DOING
 IT   WITH SOFTWARE 
INSTRUMENTATION
  INSTRUMENTATION, YOU'RE   
PROBABLY
 NOT GOING TO BE   COMPARING 
APPLES
 TO APPLES.    YOU MIGHT HAVE A 
LITTLE
 BIT   DIFFERENT PERFORMANCE OF 
YOUR
   SOFTWARE INSTRUMENTATION ON  
 DIFFERENT
 OPERATING SYSTEM   PLATFORMS. 
AND THEN AS I EARLIER   
MENTIONED ABOUT
 THE TOUCH   SENSOR, IF YOU NEED
 TO
 DO   THINGS VERY ACCURATELY TO 
THE
  THE, YOU KNOW, 10-MICRON   
LEVEL,
 ROBOTICS IS REALLY THE   ONLY 
WAY
 TO GO.  AND A LOT OF   THIS IS 
HARDWARE-CENTRIC.
  BUT SOME OF THIS THIS ALSO   
TRICKLES
 DOWN A LITTLE BIT TO   THE 
SOFTWARE
 LAYERS. 
THE -- SOME OF YOU MIGHT HAVE   
HEARD
 ABOUT THE GOOGLE CHROME   
TOUCHBOT.
SO IT'S A SYSTEM   WE DELIVERED 
TO
 THE   CHROMEBOOK TEAM OVER IN  
 MOUNTAIN
 VIEW.  AND WHAT IT'S   USED FOR
, IT'S
 USED FOR   MEASURING THE 
END-TO-END
   LATENCY OF THE USER INTERFACE
   ON
 ANDROID AND CHROME OS   DEVICES
.
SO IT'S PART OF,   LIKE, A 
CONTINUOUS
   INTEGRATION SYSTEM WHERE THE 
  NEW
 FIRMWARE UPLOADS ARE   GETTING 
AUTOMATICALLY
 INTO   THE DEVICES.  AND AS YOU
 CAN
   SEE HERE, THERE'S, LIKE, A --
   FIVE
 UNITS ON THE SAME ROBOT.    AND
 YOU
 CAN FIT ANOTHER FIVE   THERE 
PRETTY
 EASILY. 
SO ALL OF THESE GET THE NEW   
SOFTWARE
 BUILT INTO IT.  AND   THEN THE 
ROBOT
 WILL GO AND   ACTIVATE THE 
PRODUCT,
   ACTUALLY, A LITTLE BIT   
SIMILAR
 WAY WHAT WE HAVE HERE   ON THE 
DEMO.
AND WE'RE   LOOKING FOR THINGS 
LIKE
 HOW   QUICKLY THE DISPLAY IS   
RESPONDING
 TO THE ACTUAL   PHYSICAL TOUCH.

SYSTEMS.
ONE IS -- THE ONE   ON THE 
PICTURE
 HAS, LIKE, A   TWO-FINGER ACT
UATOR.
SO YOU   CAN DOES ALSO PINCH 
ZOOM 
  MOTIONS.  THERE'S ANOTHER ONE 
 ONE,
 WHICH IS ACTUALLY THE   BIGGEST
 ROBOT
 WE'VE EVER   DELIVERED, WHICH 
HAS
 ONE-  ONE-FINGER ACTUATION, BUT
 YOU
   CAN  FIT SEVERAL -- MUCH MORE
   UNITS
 UNDER IT TO GET -- TO   GET 
TESTED
 DURING THE   INTEGRATION CYCLE.

BUT THEN IT'S DEMO TIME.  SO   
THIS
 IS PROBABLY WHAT YOU'VE   ALL 
BEEN
 WAITING FOR. 
SO I'LL JUST GO -- LET   NATALIA
 DO
 HER THING.

ON
 THERE, PLEASE. 
&amp;gt;&amp;gt;Natalia Leinonen:  YEAH. 
&amp;gt;&amp;gt;Hans Kuosmanen:  THERE WE   GO
. 
&amp;gt;&amp;gt;Natalia Leinonen:  OKAY.    SO
 HERE
 IS THE DEMO SETUP.    SO WE 
HAVE AN
 ACTUAL SMALL,   THREE-AXIS 
ROBOT HERE.
AND   IT'S EQUIPPED WITH A BRASS
   FINGERTIP
 FOR INTERACTIVITY   DEVICE. AND
 A
 HIGH-SPEED   CAMERA TO MEASURE 
THE
 LATENCY  LATENCIES OF THE 
GRAPHICAL
   USER INTERFACE, AND ALSO A   
SMALL
 CAMERA FOR NAVIGATING   THE UI 
AND
 FOR CONFIGURING   THE LOCATION 
OF
 THE DEVICE.AND CAN WE HAVE THE 
  LIVESTREAM NOW?
OKAY.  GREAT  GREAT.
  SO OUR SOFTWARE
 WHICH   RUNS ON THIS LAPTOP 
HERE 
  PROVIDES EASY-TO-USE   
PROGRAMMING
 INTERFACE.  SO   THE USER WHO 
WILL
 USE THIS   ROBOT TEST DEVICE 
DOESN'T
   NEED TO KNOW ABOUT ANYTHING  
 ABOUT
 HOW TO CONTROL THE   ROBOT OR 
ABOUT
 ROBOT'S   COORDINATED SYSTEM.  
ONCE
 WE   HAVE CONFIGUREED THE 
LOCATION
   OF THE DEVICE, THEN WE CAN   
JUST
 SAY THAT TAP ON A   CERTAIN 
LOCATION
 OR SWIPE   ACROSS THE SCREEN OR
 TAKE
 A   SCREEN SHOT AND VERIFY THAT
   THERE'S
 CERTAIN ICON OR TEXT   VISIBLE 
ON
 THE SCREEN. 
AND IN THIS DEMONSTRATION,   
WE'LL
 BE MEASUREING SO-CALLED
   PEN LATENCY
 WHICH IS,   BASICALLY, THE 
DISTANCE
   BETWEEN THE FINGERTIP AND THE
   LINE
 THAT IS BEING DRAWN   WHILE WE 
SWIPE
 WITH THE   FINGER.  AND THERE 
ARE
 ALSO   SEVERAL OTHER TYPES OF 
UI 
  LATENCY MEASUREMENTS LIKE,   
FOR EXAMPLE,
 HOW LONG IT TAKE  TAKES FOR A 
DEVICE
 TO REACT   WHEN USER TAPS OR 
HOW LONG
 IT   TAKES, FOR EXAMPLE, FOR   
CAMERA
 APPLICATION TO LAUNCH,   THINGS
 LIKE
 THAT.  BUT NOW   LET'S TAKE A 
LOOK
 AT THIS   DEMO HERE.

SCRIPT
 WHICH WILL EXECUTE   THREE 
IDENTICAL
 SWIPES ON   THIS DEVICE
.  AND IT WILL
   MEASURE THE PEN INK LATENCY  
 FOR
 EACH SWIPE AND THEN PLOT   THE 
RESULTS
 ON THE SCREEN. 
SO LET'S START. 
FIRST, THE ROBOT OPENS OUR   
TEST APPLICATION
 WHICH,   BASICALLY, JUST DRAWS 
A LINE
   ON THE SCREEN IMMEDIATELY   
AFTER
 RECEIVEING THE TOUCH,   AFTER 
DETECTING
 THE TOUCH. 
AND WE COULD USE ANY PAINTING   
SOFTWARE.
THE REASON WHY   WE'RE USING 
THIS HERE
 NOW IS   THAT WE CAN BE SURE 
THAT
   THERE IS NO EXTRA LATENCY   
COMING
 FROM THE APP ITSELF.

 (INDISCERNIBLE)
 SCRIPT  SCRIPT.  WE HAVE TOOLS 
FOR
   CREATEING SIMPLE MEASUREMENTS
   LIKE
 THIS WITHOUT KNOWING ANY   
PROGRAMMING
 LANGUAGES BUT   USING -- CREATE
ING
 BYTEN   SCRIPTS PROVIDEING 
BETTER
 PLEX   BUILT AND BETTER 
INTEGRATION
   TO CONTINUEOUS INTEGRATION   
TOOLS
 AND TEST FRAMEWORKS.    HERE WE
 ARE
 PROVIDEING AN API   AND IT IS 
EASY
 TO USE AND TO   BE INTEGRATED 
INTO
 ANYTHING
. 
AND NOW WE HAVE THE RESULTS
   AND PROBABLY
 CAN'T SEE IT BUT   IT'S -- THE 
PEN
 INK LATENCY   FOR THIS DEVICE 
WHICH
 IS   NEXUS 4 WHICH IS AROUND 80
   80 MILLISECONDS
 AND USUALLY   ANYTHING BELOW 
800 
  800 MILLISECONDS IS CONSIDER  
CONSIDERED
 TO BE IMMEDIATE TO   THE 
RESULTS ARE
 PRETTY GOOD. 
[ LAUGHTER ] 
SO GOOD. 
AND, YEAH, THAT'S IT. 
&amp;gt;&amp;gt;Hans Kuosmanen:  ALL RIGHT.   
 ARE
 THERE ANY QUESTIONS? 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANKS,   HANS
, NATALIA,
 AND ROBOT. 
[ LAUGHTER ] 
LET ME SNEAK ACROSS.  SO IT   
SEEMS
 LIKE THE FIRST ONE IS   IS IT 
FAST
 ENOUGH, INCLUDING   MOVEMENT, 
IMAGE
 RECOGNITION,   ET CETERA, TO BE
 APPLICABLE
   TO GAME TESTING? 
&amp;gt;&amp;gt;Hans Kuosmanen:  WELL, WELL  
WELL,
 THIS ROBOT HERE IS   REALLY, 
REALLY
 A LOW-END   THING.  SO YOU CAN 
GET
 MORE   SPEED WITH SCALA ROBOTS,
   DELTA
 ROBOTS.  THE MORE   PROBLEMATIC
 IS
 GOING TO BE   THE IMAGE 
RECOGNITION
 PART.    WE DO HAVE SOLUTIONS 
FOR
   MEASUREING FRAME RATES, FOR  
 EXAMPLE,
 DIRECTLY FROM THE   SCREEN.  
BUT DETECTING
 ICONS   AND THEN -- IT DEPENDS 
ON
 HOW   QUICKLY YOU NEED TO REACT
 TO
   THEM.  AND AT THE END OF THE 
  DAY,
 YOU CAN JUST BUILD A   SERVEER 
RACK,
 YOU KNOW, BEHIND   IT.  ITS 
JUST MATH
 PRETTY   MUCH. 
&amp;gt;&amp;gt;Natalia Leinonen:  DEPENDS   
ON THE
 GAME. 
&amp;gt;&amp;gt;Hans Kuosmanen:  WITH A   
LAPTOP,
 IT'S PROBABLY NOT   GOING TO 
WORK
 RIGHT NOW.    WE'LL WAIT FOR A 
COUPLE
 OF   YEARS. 
&amp;gt;&amp;gt;Natalia Leinonen:  YEAH.    
BUT IF
 YOU ARE PLAYING CLASH   OF CLAN
S WITH
 THIS, YOU CAN   SEE VIDEOS ONLY
 HOW
 THIS   ROBOT -- 
&amp;gt;&amp;gt;Hans Kuosmanen:  PLEASE GO   
TO
 YouTUBE AND SEARCH FOR   
OPTOFIDELITY.
THERE IS A   WHOLE BUNCH OF FUN 
STUFF
   THERE. 
&amp;gt;&amp;gt;Yvette Nameth:  HOW DO YOU   
TEST
 YOUR OWN TEST MACHINES   ARE 
WORKING?

REALLY
 GOOD QUESTION.  WELL,   WE DO 
CHARACTERIZE
 THE ROBOT  ROBOTICS FOR 
ACCURACY AND
 THE   TIMING WITH EXTERNAL   
EQUIPMENT,
 LIKE OPTICAL EN  ENCODEERS AND 
THINGS
 LIKE THAT  THAT. 
I'M NOT SURE IF THAT ANSWERS   
THE
 QUESTION DIRECTLY.  WE'RE   
USING
 READY-MADE LIBRARYIES   FOR 
DETECTING
 ICONS, FOR   EXAMPLE,.  IF THE 
QUESTION
 IS   MORE OF ARE WE GETTING 
FORCE
   FAILURE GET GETTING   FALSE 
FAILURES
 OR GETTING   FALSE PASSES, WE 
COME --
 THE   BACKGROUND OF THE COMPANY
 IS
   FROM IMAGE PROCESSING AND   
MACHINE
 VISION.  SO WE'VE   WORKED WITH
 A
 LOT OF THE   IMAGE LIBRARYIES 
FOR
 ICON   DETECTION.  BUT -- WE 
HAVEN'T
   IMPLEMENTED ALL OF THE   
ALGORITHMS
 BEHIND IT.  WE   TEND TO MORE 
USE
 THE EXISTING   LIBRARYIES. 
&amp;gt;&amp;gt;Yvette Nameth:  OKAY.  IT   
SEEMS
 LIKE THIS ONLY MAKES   SENSE 
FINANCIALLY
 TO RUN IN   VERY HIGH-VALUE 
SCENARIOS?
  HOW FEASIBLE IS IT TO ROLL   
THIS
 OUT FOR FUNCTIONAL TEST  
TESTING?
HOW FEASIBLE IS   THIS FOR 
FUNCTIONAL
 TESTING   FOR MIDDLE OR LOWER-
FINANCE
   OR LOWER-VALUE SCENARIOS? 
&amp;gt;&amp;gt;Hans Kuosmanen:  WELL,   RIGHT
 NOW
 WHAT WE'RE SEEING   IS THIS IS 
USED
 FOR A SUBSET   OF TESTING, A 
SUBSET --
 THE   THINGS THAT CANNOT BE 
DONE 
  WITH SOFTWARE. OR THE SOFTWARE
   INSTRUMENTATION
 IS NOT RE  RELIABLE ENOUGH. 
ROBOTICS IS DEVELOPING ALL   THE
 TIME,
 SO THE PRICES ARE   COMING DOWN
.
THE SPEEDS ARE   GOING UP.  AND 
IN
 THE NEAR   FUTURE, IT MIGHT BE 
FINANCIAL
  FINANCIALLY MORE -- WELL, I   
MEAN,
 WE'RE HAPPY TO PROVIDE   ALL 
THIS
 STUFF.  THAT'S NOT A   PROBLEM.

BUT, YOU KNOW, RIGHT NOW IT'S   
PROBABLY
 JUST A SUBSET.  BUT   WE'RE 
GOING
 TO WAIT FOR A   COUPLE OF YEARS
, AND
 I'M   PRETTY SURE THERE'S GOING
 TO
   BE A LOT OF -- A LOT OF LOW- 
 LOW-COST
 ROBOTICS.  I MEAN,   THERE'S, 
LIKE,
 3D PRINTERS   COMING OUT EVERY 
DAY.
AND   ALL THIS DEVELOPMENT GOES 
  INTO
 THE ROBOTICS.  WE ARE   KIND OF
 HARVESTING
 ON THAT. 
&amp;gt;&amp;gt;Yvette Nameth:  GREAT.  I   DO
 HAVE
 TIME FOR ONE MORE. 
HOW IS THIS ROBOT CONTROLLED?   
 CAN
 IT TALK USING JAVA?  AND   HOW 
IS
 THE VALIDATION DONE   ACROSS 
DIFFERENT
 DEVICES?    LIKE, DO I NEED 
DIFFERENT
   SCRIPTS FOR DIFFERENT DEVICES
  DEVICES?

THE API
 THAT WE'RE USING,   IT'S 
ACTUALLY
 HTML.  IT'S   LIKE A REST INTER
FACE.
SO   THAT WILL WORK PRETTY MUCH 
  WITH
 EVERYTHING.  SO IF YOU   WANT 
TO USE
 JAVA, THAT'S   PERFECTLY FINE. 
 WE
 PROVIDE A   PYTHON LIBRARY OR 
WRAPPER
   NATALIA LEINONEN C WRAP. 
&amp;gt;&amp;gt;Natalia Leinonen:  C SHARP,   
C++.

TOOLS
 FOR DOING CONFIGURATION   AND 
POSITIONING
 THE DEVICE   AND ALL THAT, 
THOSE COME
 WITH   THE SYSTEM NAY.  SO THE 
INTER
  INTERFACE WHEN YOU ARE   
BUILDING
 YOUR SCRIPTS IS   REALLY SIMPLE
.
AND YOU CAN   USE PRETTY MUCH 
WHATEVER
   LANGUAGE YOU WANT. 
&amp;gt;&amp;gt;Yvette Nameth:  WHAT ABOUT   
REUSING
 THE SAME SCRIPT ON   MULTIPLE 
DEVICES?
SO YOU   HAVE A NEXUS 4 AND A 
NEXUS
 10   THAT YOU WANT TO RUN, SAY,
   THAT
 SPEED TEST ON? 
&amp;gt;&amp;gt;Hans Kuosmanen:  THAT'S   
POSSIBLE
 BECAUSE -- ACTUALLY   THE ICON 
DETECTION --
 WE ARE   NOT USING BITMAP 
COMPARISON
   ON THE ICON OR THE OCR.  SO  
 IF
 THE DISPLAYS ARE DIFFERENT  
DIFFERENT,
 EVEN IF THE COLOR   SCHEME IS A
 LITTLE
 BIT   DIFFERENT, IT WILL ADAPT 
VERY
   EASILY.  OBVIOUSLY YOU CAN   
WRITE
 A SCRIPT THAT DOESN'T   WORK 
BUT,
 YOU KNOW, ... ALWAYS.    A 
POSSIBILITY.
[ LAUGHTER ] 
&amp;gt;&amp;gt;Natalia Leinonen:  AS LONG   
AS THE
 NAVIGATION LOGICS   DOESN'T 
CHANGE,
 THEN IT   SHOULD WORK. 
&amp;gt;&amp;gt;Yvette Nameth:  AND ONE   LAST
 QUESTION.
ARE THESE   ROBOTS MEANT PRIMARY
ILY
 FOR   DEVELOPMENT?  OR ARE THEY
   SOMETHING
 THAT MIGHT BE USING   FOR 
SAMPLEING
 OF THE ENTIRE   PRODUCTION RUN?
&amp;gt;&amp;gt;Hans Kuosmanen:  WE HAVE   
DELIVERED
 ROBOTS FOR   PRODUCTION OF 
DEVICES
 OF   EQUIPMENT.  SO WE'RE USING
   THE
 SAME TECHNOLOGY OR PARTS   OF 
THE
 TECHNOLOGYIES.  IT'S   NOT 
IDENTICAL
 TO THIS.  SO   TYPICALLY THE 
TYPE
 OF THINGS   THAT WE'RE DEMOING 
HERE,
   THESE WOULD BE ON R&amp;amp;D TEAM   
WOULD
 BE INTERESTED IN THESE   KIND 
OF RESULTS.
BUT WE'RE   USING THE SAME 
TECHNOLOGY.
  WE HAVE SOME ROBOT PLATFORMS  
 WE
 USE ON PRODUCTION LINE AND   
THE TECHNOLOGY
 THAT WE'VE   DEVELOPED, SOME OF
 THESE --
   LIKE THE ACT FEWATIONS FEWU
ATIONS
 AND THE   FINGERPRINTS AND THE 
  AUTOMATIC
 LOCATIONING, THAT   IS ALSO 
USED IN
 PRODUCTION. 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU   
AGAIN
 TO THE TWO OF YOU AND   YOUR 
ROBOT.
[ APPLAUSE ] 
JUST SO EVERYONE KNOWS, WE   
HAVE TO
 PAUSE FOR ABOUT TWO   MINUTES 
TO GET
 THIS TORN DOWN  DOWN.  WHILE 
THAT'S
 HAPPENING  HAPPENING, A FEW 
REMINDERS.
  IF YOU NEED TO ASK QUESTIONS  
 EVEN
 IF YOU ARE SITTING HERE,   
WHETHER
 OR NOT YOU ARE, POLLE  POLLEV
.COM
 OTHERWISE GTAC
.COM SLASHES GTAC15.
  DON'T WORRY IF YOU ARE NOT   
TAKING
 NOTES.  THE SLIDES   WILL BE 
ONLY
 AFTER THE   CONFERENCE IS OVER.
  IF
 FOR   SOME REASON YOUR QUESTION
   DOESN'T
 GET ANSWER, REMEMBER   THE 
SPEAKERS
 ARE IN   ATTENDANCE HERE.  FIND
 THEM
   DURING ONE OF THE BREAKS.    
SEE
 THEM DURING LUNCH.  SIT   DOWN 
AT
 THEIR TABLE.  TALK TO   NEW 
PEOPLE.
THAT'S WHAT THIS   IS ALL ABOUT.
  SO
 GO SAY HI. 
WHERE IS MY NEXT SPEAKER, DAN  
DAN?

SO OUR NEXT FEW TALKS ARE   
GOING TO
 BE PRETTY QUICK SO   TO GET US 
STARTED
 WITH OUR   FIRST LIGHTNING TALK
 OF
 THE   DAY, IT'S DAN GIOVANNELLI
   FROM
 GOOGLE TO TALK ABOUT   JUGGLE
ING CHAINSAWS.

ROBOT
 IS A TOUGH ACT TO   FOLLOW BUT 
I WILL
 SEE WHAT I   CAN DO. 
SOMEONE HAD TO. 
[ LAUGHTER ] 
MY NAME IS DAN.  I WORK AT   
GOOGLE
 IN NEW YORK AS A   SOFTWARE 
ENGINEER
 IN TOOLS   AND INFRASTRUCTURE. 
 TALK
 IS   CALLED &quot;JUGGLEING CHAINSAW
S 
  FOR FUN AND PROFIT&quot; AND I'M   
HERE
 TO TELL YOU SOME OF THE   
MISTAKES
 MY TEAM MADE   BUILDING CROSS-
MOBILE
   PLATFORM SYSTEMS.  LIKE I   
SAID,
 MY NAME IS DAN   GIOVANNELLI.  
PRIMARYILY
 WORK   ON MOBILE.  AND MY 
EXPERIENCE
   IS SPECIFICALLY IN iOS.  ON  
 A
 TEAM CALLED THE MOBILE   
DISPLAY ADS
 TESTING   INFRASTRUCTURE TEAM 
WHICH
   FROM THE NAME YOU MIGHT GUESS
   MEANS
 WE BUILD TESTING   
INFRASTRUCTURE
 FOR MOBILE   DISPLAY ADS.  A 
LITTLE
 MORE   SPECIFICALLY, OUR 
CUSTOMERS
   ARE OTHER ENGINEERS WHO ARE  
 WORKING
 ON A WHOLE BUNCH OF   DIFFERENT
 AD
 PRODUCTS --   DISPLAY AD 
PRODUCTS
   SPECIFICALLY ALL SERVEING TO 
  MOBILE
 DEVICES.  SO AS A RULE  RULE, 
IF IT
 HAS A SCREEN AND   NO KIND, 
THAT'S
 US.  PHONE,   TABLE, WATCH, ALL
 THAT
 KIND   OF STUFF.  THIS, 
BASICALLY,
   MEANS WE HAVE TO BUILD   
TESTING
 INFRASTRUCTURE FOR A   BUNCH OF
 DIFFERENT
 AD   PRODUCTS SERVEING THROUGH 
  SEVERAL
 DIFFERENT NATIVE SDK  SDKs ON 
BOTH
 ANDROID AND i  iOS. 
SO WHEN OUR TEAM FIRST GOT   
STARTED
 ABOUT TWO YEARS AGO,   WE WERE 
SORT
 OF FACING THIS   REALLY THORNY 
PROBLEM,
 WHICH   IS WE HAD THESE 
ENGINEERS
   BUILDING VERY, VERY   
COMPLICATED
 BACK-END STACKS   WITH A LOT OF
 DIFFERENT
 MOVE  MOVING PARTS AND THEY 
NEEDED
   TO BE ABLE TO TEST THEIR   
CHANGES
 TO THOSE STACKS ON   MOBILE AND
 MAKE
 SURE THAT   THEY WEREN'T BREAK
ING
   ANYTHING ON MOBILE DEVICES. 
UNFORTUNATELY, THEY WEREN'T   
MOBILE
 DEVS.  THEY WERE   USUALLY 
BACK-END
 DEVS SO,   JAVA, C++.  THEY'RE 
NOT
   MOBILE EXPERTS AND THEY DON'T
   REALLY
 HAVE THE TIME AEROBID   TO 
BECOME
 MOBILE EXPERTS.    THAT WAS OUR
 JOB.

CAUGHT
 UP IN WHAT WE CALLED   THE 
MATRIX
 WHICH INJURY AGAIN   TALK
 JUERGEN
 TALK  TALKED ABOUT IN THE 
KEYNOTE
   WHICH MEANS YOU HAVE MULTIPLE
   VERSIONS
 MULTIPLE DEVICE   TYPES AND YOU
 HAVE
 THIS   EXPLOSION OF THINGS YOU 
HAVE
   TO TEST THAT GETS REALLY OUT 
  OF
 HAND REALLY, REALLY   QUICKLY. 
SO WHAT IS OUR PLAN?  WE   
DECIDEED
 PRETTY EARLY ON THAT   WE WERE 
GOING
 TO LET OUR   USERS WRITE TESTS 
IN
 THIS   SORT OF NON-MOBILE 
DOMAIN-
  DOMAIN-SPECIFIC LANGUAGE.  IT 
  LOOKED
 A LOT LIKE JSON AND   YOU CAN 
SEE
 AN EXAMPLE OF ONE   OF THOSE 
TESTS
 UP THERE. 
BASICALLY, THEY'RE DATA-  
DATA-DRIVEN
 TESTS.  THEY LAY   OUT THE MOST
 IMPORTANT
 PARTS   OF A TEST, WHAT AD TO 
LOAD,
   WHAT SIZES TO LOAD IT ON,   
WHAT
 TO DO WITH THAT AD. 
AND THEN WE UNDER THE HOOD   RAN
 THOSE
 ON MOBILE.  WE,   BASICALLY, 
HAD OUR
 OWN   PIPELINE TO CONVERT THOSE
 TO
   SOMETHING THAT WORKED ON   
MOBILE
 AND RUN THEM SO OUR   CUSTOMERS
 DIDN'T
 HAVE TO   WORRY ABOUT THAT. 
WE DECIDEED ALSO PRETTY EARLY   
ON
 TO RUN ON SIMULATOR JUST   THAT
 MAKES
 THE WHOLE MATRIX   THING A LOT 
EASIER
 TO DEAL   WITH BECAUSE YOU 
DON'T HAVE
   TO WORRY ABOUT HAVING ALL   
THESE
 DIFFERENT DEVICES AND   DEVICES
 ARE
 HARD.  THEY CRASH  CRASH.  THEY
 BREAK.
THEY   CATCH ON FIRE SOMETIMES. 
   THAT
 ACTUALLY HAPPENED ONCE.    SO 
WE FIGURED
 SIMULATORS WAS   SORT OF THE 
EASIER
 WAY TO GO. 
WE WANTED TO MAKE OUR RESULTS   
JUST
 REALLY EASY TO   UNDERSTAND AND
 HAVE
 CLEAR   ACTION SO RATHER THAN 
SAYING
   &quot;SOMETHING'S BROKEEN&quot;,&quot; MAKE 
IT
   MORE &quot;THIS IS BROKEEN, THIS 
IS 
  HOW YOU SHOULD FIX IT&quot;.&quot; 
AND AS SORT OF A PARALLEL   
REQUEST,
 OUR CUSTOMERS WANTED   A MANUAL
 TESTING
 APP.  SO,   BASICALLY, AN APP 
THAT
 THEY   COULD JUST IN FRONT OF 
THEM
   AS PART OF THEIR DEVELOPMENT 
  CYCLE
 LOAD UP AN AD, INTERACT   WITH 
IT,
 SEE WHAT HAPPENS IN   ADDITION 
TO
 THE AUTOMATEED   FRAMEWORK. 
SO HOW DO WE ACTUALLY BUILD   
THIS
 THING?  LIKE I SAID, WE   HAD 
CUSTOM
 PYTHON SCRIPTS TO   TAKE THOSE 
DSL
 TESTS AND BOTH   WHAT WE REFER 
TO
 AS UNFOLDING   THEM WHICH WAS 
TAKING
 ONE   TEST AND TURNING IT INTO 
A 
  BUNCH OF TESTS ACROSS   
OPERATING
 SYSTEMS AND ALL   THAT AND 
CONVERT
 IT INTO   INTERMEDIATE FORMATS 
THAT
   PLAYED NICE ON MOBILE, JSON  
 FOR
 ANDROID AND P LIST WHICH   IS A
 BINARY
 XML FORMAT THAT   APPLE AND 
APPLE
 ALONE USES.    SURPRISE, 
SURPRISE.

WE HAD CUSTOM ANDROID AND i  IOS
 APPS THAT ALLOWED FOR   MANUAL 
TESTING,
 LIKE I SAID   BEFORE, THE APPS 
THAT
 COULD   OPEN AN AD AND RUN 
THROUGH
   THEM.  AND THEN THOSE SAME   
APPS
 WERE, BASICALLY, DRIVEN   BY 
THOSE
 TESTS FOR AUTOMATION   TESTING.
  THOSE
 RAN ON   SIMULATOR AND THEY 
WERE 
  DRIVEN BY ESPRESSO ON ANDROID 
  AND
 THEN INTERNAL iOS   FUNCTIONAL 
TESTING
 FRAMEWORK   FOR iOS. 
WE HAD AN APPENGINE BACK-END   
THAT
 WE USED FOR STOREING GOLD  
GOLDEN
 IMAGES SO FOR TESTING   RENDER
ING
 YOU COULD COMPARE   AN AD TO A 
KNOWN
 GOOD IMAGE   AND IT ALSO STORED
 SOME
   ADDITIONAL DATA FOR TESTS. 
WE HAD INTERNAL GOOGLE   SYSTEMS
 FOR
 ACTUALLY SPINNING   UP THE 
SIMULATORS
 AND INTER  INTERACTING WITH 
THEM AND
   GETTING DATA FROM THEM.  BUT 
  THERE
 WAS REALLY NOTHING   THERE THAT
 YOU
 COULDN'T BUILD   AT HOME FROM 
OPEN
 SOURCE   PARTS.  WE JUST WERE 
LAZY
 AND   USED SOME PREEXISTING 
STUFF
   FOR IT, INTERNAL PREEXISTING 
  STUFF.
NOT OPEN SOURCE   PREEXISTING 
STUFF.
AND WE INTEGRATED WITH THE   
EXISTING
 GOOGLE TOOLING FOR   BUILDING 
BINARYIES
 AND RUNS   TESTS.  SO, 
BASICALLY,
 WE   COULD INTEGRATE VERY NICE
LY 
  INTO OUR USERS' DEVELOPMENT   
WORKFLOW,
 THE SAME SYSTEMS   THAT THEY 
WERE
 USED TO FOR   RUNNING UNIT 
TESTS AND
   INTEGRATION TESTS, THEY COULD
   JUST
 KICK OFF THESE TESTS AND   GET 
RESULTS
 BACK THE WAY THEY   WERE USED 
TO TO.

DIAGRAM
 THERE THAT I WON'T   SPEND TOO 
MUCH
 TIME ON, BUT,   BASICALLY, THE 
STUFF
 THAT'S   IN THE CLOUDS IS 
EXISTING
   GOOGLE INFRASTRUCTURE.  SO WE
   WERE
 ABLE TO KICK OFF OUR   SYSTEM 
FROM
 THAT AND THEN   SORT OF HOOK 
BACK
 INTO IT. 
SO THE BRAGGY PART, WHAT WENT   
RIGHT?
WE PUT A LOT OF   THOUGHT INTO 
HOW
 TO AVOID THE   MATRIX AND IT 
PRETTY
 MUCH   WORKED BETWEEN RUNNING 
ON 
  SIMULATOR AND USING THAT   
DOMAIN-SPECIFIC
 LANGUAGE.  WE  WE, OUR TEAM, 
HAD TO
 WORRY   ABOUT THE MATRIX A LOT,
 ALL
   THE TIME.  BUT IT WAS   
COMPLETELY
 OPAQUE TO OUR   USERS.  THEY 
DID NOT
 HAVE TO   CARE ABOUT HOW THEY 
WERE
   GOING TO RUN ACROSS ALL THESE
   DIFFERENT
 DEVICES WHICH WAS A   MAJOR 
GOAL OF
 OURS. 
AND ON A SIMILAR NOTE, OUR   
BACK-END
 DEVELOPER CUSTOMERS   REALLY 
APPRECIATED
 THAT THEY   DIDN'T HAVE TO KNOW
 ANYTHING
   ABOUT MOBILE.  THEY COULD   
WRITE
 THESE JSONY TESTS, KICK   THEM 
OFF
 IN THE SYSTEMS THEY   KNEW, GET
 BACK
 RESULTS IN THE   SYSTEMS THEY 
KNEW.
THEY   REALLY LIKED THAT.  AND 
IT 
  WAS A USEFUL SYSTEM.  WE HAD  
 GREAT
 ADOPTION FOR BOTH THE   MANUAL 
AND
 THE AUTOMATION   COMPONENTS.  
WE HAD
 A LOT OF   METRICS AND THEY 
SAID NICE
   THINGS. 
NOW THE FUN PART.  WHAT DID   WE
 MESS
 UP?  WE THOUGHT A LOT   ABOUT 
THESE
 BACK-END   DEVELOPERS WHO WERE 
GOING
 TO   BE AN USING OUR SYSTEM.  
WHAT
   WE DIDN'T THINK ABOUT WAS THE
   DEVELOPERS
 WHO WERE ALSO   WORKING -- WHO 
WERE
 ACTUALLY   WORKING ON THE 
NATIVE SDKs
   THAT WE WERE BUILDING INTO   
OUR
 APPS WOULD ALSO WANT   THESE 
KINDS
 OF TESTS.  THEY   WOUND UP 
USING THE
 SYSTEM,   TOO, BUT THOUGH 
WANTED LESS
   ABSTRACTION.  THEY WANTED TO 
  BE
 ABLE TO WRITE TESTS NATIVE  
NATIVELY
 AND THEY WANTED TO   KICK THEM 
OFF
 FROM THEIR IDE  IDEs.  
UNFORTUNATELY
   BECAUSE OF HOW OUR SYSTEM WAS
   ARCHITECTED
 WE COULDN'T GIVE   THEM THAT.  
WE
 COULDN'T   INTEGRATE IT WITH 
THE NATIVE
   DEVELOPMENT CYCLE AND THAT   
BECAME
 MORE OF A PROBLEM AS   TIME 
WENT ON.

SYSTEMS
 WHICH SHOULD HAVE   BEEN REALLY
 LIGHTWEIGHT
 THAT   WERE SORT OF STUCK 
TOGETHER
   BECAUSE AS WE'RE DEVELOPING, 
  WE
 HAD, YOU KNOW, THE MANUAL   
VERSUS
 THE AUTOMATION.  WE   HAD ALL 
THESE
 DIFFERENT SDKs  SDKs AND WE 
KEPT
 STAPLEING   THEM ONTO THE 
SYSTEM UNTIL
 IT   BECAME THIS KIND OF FRANK
EN 
  SYSTEM WHEREVER WHEN SOMEONE  
 THING
 BROKE TOTALLY UNRELATED   
THINGS WOULD
 BREAK BECAUSE   THEY WERE 
CLOSELY
 TETHERED   AND THAT CAUSED UN
NECESSARY WE
   FLAKEYANCE. ALSO DIDN'T THINK
 THROUGH   PLATFORM DIFFERENCES.
  WE
 SORT   OF THOUGHT FROM THE 
BEGINNING
   WE'D BUILD THINGS FOR ANDROID
, 
  WE'D BUILD THINGS FOR iOS,   
WE'D
 PROVIDE THEM BOTH.  IT   DIDN'T
 REALLY
 WORK LIKE THAT   BECAUSE 
THEY'RE VERY
 DIFFERENT   PLATFORMS.  AND WE 
WOUND
 UP WITH   THINGS THAT WERE A 
LITTLE
 HARDER   TO IMPLEMENT ON ONE 
PLATFORM
 OR   THINGS THAT WERE 
COMPLETELY 
  IMPOSSIBLE TO IMPLEMENT ON   
ANOTHER
 PLATFORM.  AND THAT SORT   OF 
LED
 TO THIS PROBLEM WHERE WE   HAD 
INCONSISTENT
 FEATURE SETS.    AND YOU WOULD 
TEST
 THAT COULD   ONLY RUN ON 
ANDROID OR
 ONLY RUN   ON iOS, AND THAT ADD
ED
   COGNITIVE LOAD FOR OUR USERS 
WHO
   NOW HAD TO WORRY ABOUT WHERE 
OUR
   TESTS COULD RUN, WHICH SORT 
OF 
  DEFEATED THE PURPOSE OF THE   
ENTIRE
 SYSTEM. 
SO  WHAT DO I WISH I'D KNOWN   
FROM
 THE GET-GO?  WHAT DID WE   
LEARN FROM
 THIS? 
SUBDIVIDE YOUR SYSTEMS.  IT'S   
REALLY
 EASY TO THINK, OH, I'M   
BUILDING
 SOMETHING THAT'S SORT   OF 
BUILT ON
 TOP OF SOMETHING   ELSE, SO 
I'LL JUST
 PUT IT IN   THERE AND THAT GETS
 YOU
   VELOCITIES IN THE SHORT TERM,
   BUT
 CAUSES ALL SORTS OF PROBLEMS   
IN
 THE LONG TERM.  IF YOU THINK   
YOU
 SHOULD BE IN TWO DIFFERENT   
CODEBASES,
 YOU'RE PROBABLY RIGHT  RIGHT.  
IDEALLY,
 YOU WANT TO   HAVE SORT OF 
LOGICALLY
 DIVIDED   SYSTEMS SHARING 
COMMON 
  INFRASTRUCTURE.  IF ANY OF YOU
   ARE
 THINKING MICROSERVICES,   
THAT'S --
 YEAH. 
THE WHOLE IDEA OF THE GOD OBJECT

OBJECT-ORIENTED
 PROGRAMMING FROM   ONE OBJECT 
THAT
 DOES EVERYTHING   AND NOTHING, 
THAT
 APPLIES TO   SYSTEMS, TOO,.  
YOU KNOW,
 IT'S   GENERALLY JUST GOOD 
SOFTWARE
   ENGINEERING PRACTICE.  BUT IT
 IS
   IMPORTANT TO KEEP IN MIND.  
YOU
   KNOW, THE MORE THINGS CHANGE,
   THE
 MORE THEY STAY THE SAME. 
NO WHO YOUR CUSTOMERS ARE. --   
KNOW
 WHO YOUR CUSTOMERS ARE AND   
HAVE
 A PLAN TO GIVE THEM WHAT   THEY
 WANT.
AND NOTICE I DID NOT   SAY KNOW 
WHO
 YOU THINK YOUR   CUSTOMERS ARE 
AND
 WHAT YOU THINK   THEY WANT, 
BECAUSE
 YOU WILL BE   WRONG.  TAKE SOME
 TIME
 TO GO OUT   THERE, TALK TO 
PEOPLE
 WHO MIGHT   BE USING YOUR 
SYSTEMS,
 GET A   SENSE OF WHO THEY ARE 
AND
 HOW TO   BUILD WHAT THEY WANT. 
 AND
 THE   ANSWER MAY BE, THERE ARE 
GOING
   TO BE PEOPLE WHO WANT TO USE 
A 
  GIVEN SYSTEM WHERE IT'S REALLY
   NOT
 THE RIGHT FIT.  AND THAT'S A   
GREAT
 THING TO KNOW AT THE   
BEGINNING,
 BECAUSE YOU CAN SAY,   THIS IS 
NOT
 THE SYSTEM FOR YOU,   WE'LL 
BUILD
 YOU SOMETHING NEXT,   RATHER 
THAN
 THEM TRYING TO USE   IT AND NOT
 BEING
 ABLE TO DO WHAT   THEY WANT AND
 GETTING
 FRUSTRATED  FRUSTRATED. 
DON'T IGNORE PLATFORM DETAILS   
FOR
 ANY GIVEN FEATURE,   HAVE AT   
LEAST
 A PRETTY CLEAR IDEA OF HOW   
YOU'RE
 GOING TO IMPLEMENT IT ON   
WHATEVER
 PLATFORMS YOU'RE USING.    AND 
IF
 IT'S GOING TO BE MUCH   HARDER 
ON
 ONE THAN THE OTHER,   HAVE AN 
IDEA
 OF HOW TO MITIGATE   THAT.  
MAYBE
 THAT MEANS PUTTING   MORE 
DEVELOPMENT
 RESOURCES   BEHIND THE HARDER 
ONE
 OR   DELAYING RELEASE OF ONE 
EVEN
   AFTER IT'S FINISHED UNTIL THE
   OTHER
 IS FINISHED.  JUST HAVE   SOME 
IDEA
 OF HOW YOU'RE GOING TO   
ADDRESS THE
 FACT THAT THE   PLATFORMS ARE 
DIFFERENT.
SIMULATORS ARE GREAT IN   
AUTOMATION.
THEY LET YOU DO ALL   SORTS OF 
GREAT
 STUFF WITH   SHARDING AND 
PARALLELISM.
YOU   DON'T HAVE TO WORRY ABOUT 
THEM
   CATCHING ON FIRE.  YOU'RE 
ALWAYS
   GOING TO NEED SOME AMOUNT OF 
  REAL
 DEVICE TESTING.  THERE ARE   
BUGS
 THAT WILL ONLY POP UP ON   REAL
 DEVICES.
THERE ARE   FEATURES THAT YOU 
CAN ONLY
 TEST   ON REAL DEVICES.  SO 
THINGS
 LIKE   NFC OR CAMERA.  BUT SAVE
 THAT
   FOR MANUAL TESTING.  ANYTHING
   THAT
 YOU CAN RUN ON SIMULATOR   FOR 
AUTOMATION,
 YOU SHOULD RUN   ON SIMULATOR, 
IN
 OUR EXPERIENCE. 
SO THAT'S IT.  GOT MOWER MINUTES

  IF
 THERE ARE ANY   QUESTIONS, I'LL
 TAKE
 THOSE. 
&amp;gt;&amp;gt;Yvette Nameth:  CAN WE SWITCH 
  TO
 TOP VIEW. 
iOS AUTOMATION IS PAINFUL FOR   
EVERYONE.
ARE YOU GUYS GOING TO   OPEN 
SOURCE
 ANY OF THESE   INTERNAL TOOLS? 
&amp;gt;&amp;gt;Dan Giovannelli:  SOME OF THEM

.
  THERE'S A GREAT TOOL CALLED   
MARTIAN
 THAT WE USE FOR   APPROXIMATE 
PROXYING
   REQUESTS FOR MOCK MOCKING OUT
 NETWORK
   RESPONSES.  THE PEOPLE WHO 
BUILT
   THAT ARE HERE AT GTAC.  SO IF
   YOU
 SEE (SAYING NAME), SAY HI. 
SOME OF THE TOOLS WE WANT TO   
OPEN
 SOURCE BUT CAN'T FOR   VARIOUS 
REASONS.
AND SOME WE   WANT TO OPEN 
SOURCE BUT
 IT'S A   SLOW PROCESS.  AND 
IT'S IN
   PROCESS, BUT WHEN THAT WILL  
 HAPPEN,
 THERE ARE A LOT OF   VARIABLES 
AS
 TO WHEN THEY'LL   COME OUT. 
&amp;gt;&amp;gt;Yvette Nameth:  SO WHAT   
SIMULATOR
 AND TEST TOOL SET DO   YOU USE 
TO
 AVOID A BIG LAB OF   MATRIX OF 
DEVICES,
 OS, BROWSER   COMBOS? 
&amp;gt;&amp;gt;Dan Giovannelli:  FOR THE   
SIMULATOR,
 WE'RE JUST USING,   LIKE I SAID
, IT'S
 MOSTLY OPEN   SOURCE.  SO ON 
ANDROID,
 WE'RE   USING THE ANDROID 
EMULATOR.

 TO
 IT THAT WE'VE MADE.  BUT IT'S  
 THE
 SAME EMULATOR THAT YOU ALL   
KNOW
 AND PROBABLY HATE  HATE. 
SAME ON iOS.  IT'S THE   
STANDARD
 XCODE iOS SIMULATOR. 
WE'RE USING THE JUST SIM CONTROL

VERSIONS
 TO ACTUALLY DRIVE THOSE  THOSE.
  BEFORE
 THOSE WERE   AVAILABLE, THERE 
WERE
 CERTAIN   OPEN SOURCE TOOLS, 
LIB 
  (INDISCERNIBLE) DEVICE THAT 
YOU 
  COULD USE FOR SIMILAR EFFECT. 
   AND
 THEN IT'S JUST SOME INTERNAL   
TOOLING
 TO SORT OF BRING THOSE   
TOGETHER
 NICELY.  ABOUT THE LIKE   I 
SAID,
 IT'S NOTHING THAT YOU   
COULDN'T BUILD
 AT HOME.


HOW DO YOU CHOOSE THE DEVICES TO
  TEST FOR PREVENTING BEING 
SUCKED
   INTO THE MATRIX? 
&amp;gt;&amp;gt;Dan Giovannelli:  USAGE   
METRICS
 ARE REALLY IMPORTANT.    IF YOU
 KNOW
 THAT .012% OF YOUR   USERS ARE 
RUNNING,
 I DON'T KNOW,   JELLYBEAN ON A 
ROCK
 SOMEWHERE,   THEN THAT'S 
PROBABLY
 NOT WORTH   TESTING. 
[ LAUGHTER ]  
REALLY, IT'S -- THIS IS A --   
IT'S
 A REALLY GOOD QUESTION.    AND 
IT
 SORT OF FALLS INTO THE   SAME 
BUCKET
 AS DON'T ASSUME THAT   YOUR 
CUSTOMERS
 ARE WHO YOU THINK   THEY ARE.  
DON'T
 ASSUME THE   DEVICES ARE WHAT 
YOU
 THINK THEY   ARE, BECAUSE YOU 
WILL
 BE WRONG.    MAYBE 60% OF YOUR 
CUSTOMERS
 ARE   USING JELLYBEAN ON A ROCK
.
  REALLY, JUST HAVING GOOD 
METRICS
   AROUND WHAT DEVICES YOUR CODE
 IS
   RUNNING ON IS -- AND 
OPERATING 
  SYSTEMS AND ALL THAT, IS 
REALLY 
  IMPORTANT FOR JUST KNOWING 
WHAT 
  TO TEST ON. 
AND JUST AS IMPORTANTLY, WHAT   
NOT
 TO TEST ON  ON. 
&amp;gt;&amp;gt;Yvette Nameth:  AND, DAN,   
SINCE
 YOU TALK REALLY FAST, YOU   GET
 ONE
 MORE. 
WHY DID YOU CHOOSE TO IMPLEMENT 
  YOUR
 OWN LANGUAGE RATHER THAN   ADD
ING
 A LIBRARY FOR SOMETHING   LIKE 
PYTHON?

ACTUALLY
 IS PYTHON. 
[ LAUGHTER ]  
THOSE ARE PYTHON DICTIONARIES.  
  AND
 WE USE PYTHON SCRIPTS TO   TURN
 THEM
 INTO NON-PYTHON. 
BUT, BASICALLY, IT'S NOT SO MUCH
  THAT WE DECLARED OUR OWN   
LANGUAGE
 AS MUCH AS YOU CAN SORT   OF 
THING
 THINK OF IT AS WE DECLARED   
OUR OWN
 SCHEMA.  WE SAID THESE   ARE 
THE ELEMENTS
 OF DATA THAT A   TEST NEEDS.  
THESE
 ARE THE   ELEMENTS OF A DATA 
THAT
 A TEST   CAN HAVE BUT DOESN'T 
NECESSARILY
   NEED.  YOU STRUCTURE THAT AS 
A 
  PYTHON DICTIONARY, AND THEN WE
   DO
 THE REST. 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU, DAN
  DAN.
&amp;gt;&amp;gt;Dan Giovannelli:  THANKS. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  NEXT UP, WE   
HAVE
 JOUKO FROM BITBAR TO TALK   
ABOUT
 USING
 IMAGE RECOGNITION   FOR MOBILE
 APP AND GAME TESTING. 
&amp;gt;&amp;gt;Jouko Kaasila:  HELLO. 
OKAY.  SO MY NAME IS JOUKO   
KAASILA.
I'M THE COFOUNDER AND   CEO OF 
BITBAR,
 THE COMPANY   BEHIND PRETTY 
AWESOME
 SERVICE   CALLED TESTDROID 
CLOUD.
IT'S A   DEVICE CLOUD OF ANDROID
 AND
 i  IOS DEVICES FROM EVERY 
SINGLE
   MARKET IN THE WORLD, 
INCLUDING 
  JAPAN, CHINA ,KOREA, AND INDIA
. 
WE ALSO HOST PRIVATE DEVICE   
CLOUDS
 FOR PEOPLE WHO DON'T WANT   TO 
SHARE
 THEIR DEVICES.  AND WE   
LICENSE OUR
 TECHNOLOGY TO   COMPANIES WHO 
BUILD
 LARGE SCALE   ON-PREMISE DEVICE
 LABS.
SO IN THE NEXT TEN MINUTES, I'M 
  GOING
 TO TELL YOU HOW TO GET RID   OF
 60
 MANUAL TESTERS WITH -- AND   RE
PLACE
 THEM WITH ONE SMART ONE.    AND
 THIS
 IS ACTUALLY SOMETHING   THAT 
HAS HAPPENED
 WITH ONE OF   OUR CUSTOMER 
ORGANIZATIONS.


  100%
 AUTOMATED TESTING USING   REAL 
DEVICES.

 HAVE
 A GIFT FOR ALL OF YOU IN   THE 
SPIRIT
 OF THE HOLIDAY SEASON  SEASON. 
SO LET'S START. 
SO IF YOU LOOK AT THE -- THE   
CHARTS
 OF THE MOST GROSSING APPS   ON 
ANDROID
 OR THE GOOGLE PLAY   TODAY, ON 
THE
 TOP 50 -- LIST OF   THE MOST-
GROSSING
 APPS, THERE IS   ONLY ONE APP 
THAT
 IS NOT A GAME.    AND IF YOU 
LOOK
 AT THE TOP 100   MOST GROSSING 
APPS,
 THERE ARE   ONLY THREE APPS 
THAT ARE
 NOT   GAMES.  SO IT'S PRETTY 
OBVIOUS
   WHO IS MAKING THE MONEY ON 
THE 
  APP STORES. 
AND USUALLY, GAMES ARE FREE TO  
 DOWNLOAD,
 AND THEY MONETIZE WITH   IN-APP
 PURCHASES.
SO IT TAKES A   LITTLE BIT OF 
TIME,
 OR YOU HAVE   TO ENGAGE THE 
USER LONG
 ENOUGH   TO MAKE REALLY ANY 
MONEY
 ON THAT  THAT.  BECAUSE 
CURRENTLY,
 THE   AVERAGE CUSTOMER 
ACQUISITION
   COST OR THE COST PER DOWNLOAD
 ON
   ANDROID AND iOS IS AROUND $5.
  SO IT MEANS THAT YOU HAVE TO  
 KEEP
 THE CUSTOMER FOR LONG -- AS   
MANY
 RELEASES AS POSSIBLE IN   ORDER
 TO
 RECOVER THAT $5 INVEST  
INVESTMENT
 AND MAKE SOME PROFIT   ON TOP 
OF IT.
SO IT'S VERY HIGH   MOTIVATION 
FOR
 TESTING IN   GENERAL AND MAKING
 SURE
 THAT   YOUR GAME WORKS ON EVERY
 SINGLE
   DEVICE OUT THERE. 
SO GIVEN THE COMMERCIAL   
INCENTIVE,
 WHY HASN'T THIS ALL   BEEN 
AUTOMATED
 A LONG TIME AGO?    YOU KNOW, 
THESE
 GUYS DO HAVE A   LOT OF MONEY. 
 THAT'S
 NOT THE   PROBLEM.  THE PROBLEM
 IS
 THAT   MOBILE GAMES ARE NOT 
REALLY
 EASY   TO AUTOMATE.  THEY ARE 
VERY
   DIFFICULT TO AUTOMATE. 
SO THE MAIN REASON IS THAT THE  
 GAMES
 USE DIRECT SCREEN ACCESS   IN 
THE
 FORM OF OpenGL OR   ACTIVE X.  
AND
 THEY EFFECTIVELY   BY   BYPASS 
ALL
 THE OPERATING SYSTEM   CONTROLS
 OR
 SERVICES YOU HAVE.    SO THAT 
MEANS
 THAT ANY OF YOUR   YOUR -- ANY 
OF
 THE MOBILE --   NATIVE MOBILE 
TEST
 AUTOMATION   FRAMEWORKS THAT WE
 KNOW
 CAN'T   REALLY ACCESS ANY OF 
THE 
  INTERNAL DATA OF THE GAME.  SO
   YOU
 ONLY HAVE TO RESORT TO X AND   
Y CLICKS
 AND, YOU KNOW, READING   THE 
SCREEN
 BUFFER.  YOU   BASICALLY HAVE 
TO TEST
   EVERYTHING FROM THE OUTSIDE 
OF 
  THE GAME. 
AND, OF COURSE, IN TERMS OF   
AUTOMATION,
 THAT'S PRETTY TRICKY  TRICKY. 
THE SECOND THING IS THAT THE   
GAMES
 ARE VERY PERFORMANCE-  
PERFORMANCE-DRIVEN.
SO, FIRST   OF ALL, THEY CONSUME
 A
 LOT OF   RESOURCES.  SO THE 
GAME BINARIES
   ARE TWO TRIGABYTES TODAY.  
THEY
   USE A LOT OF MEMORY, CPU, 
THEY 
  UTILIZE A LOT OF GPU, THEY   
UTILIZE
 THE SENSORS.  IT'S   PRETTY 
CLEAR
 THAT THESE GUYS   DON'T TEST 
ANYTHING
 ON EMULATORS   AND SIMULATORS. 
 IT
 JUST DOESN'T   MAKE ANY SENSE. 

AND THERE'S ANOTHER INTERESTING 
  INCENTIVE,
 IS THAT  ONE OF OUR   CUSTOMERS
 TOLD
 US THAT, YOU KNOW  KNOW, IF 
THEY CAN
 ADD ONE MORE   VERY POPULAR 
CHINESE
 ANDROID   DEVICE ON THE LIST OF
 THEIR
   SUPPORTED DEVICES, IT CAN 
BRING
   UP TO 5 MILLION REVENUE OVER 
THE
   LIFETIME OF THE GAME.  SO YOU
   CAN
 INVEST QUITE A LOT ON   
OPTIMIZING
 YOUR GAME ON THAT   MODEL. 
SO ALL THE DIFFICULTIES HAVE   
ACTUALLY
 LED TO THIS.  SO THE   GUYS 
HAVE RESOURCES,
 AND IT'S   DIFFICULT TO 
AUTOMATE GAMES.
SO   ALL THE GAMING COMPANIES, 
THE
   LARGE GAMING COMPANIES, HAVE 
  VERY
 LARGE MANUAL DEVICE FARMS   ON 
THEIR
 FAVORITE LOCATIONS.    AND 
THAT'S
 -- OF COURSE, IT   DOESN'T 
SCALE VERY
 WELL.  AND   THAT LEADS TO 
ANOTHER
 PROBLEM,   THAT THE QA PROCESS 
CAUSES
   DELAYS ON THE ACTUAL RELEASE 
OF
   THE GAME, WHICH INCREASES THE
   TIME
 TO MARKET.  AND THAT'S THE   
REAL
 COST OF THE MANUAL TESTING,   
THAT,
 YOU KNOW, THINGS GET   DELAYED,
 AND
 YOU DON'T STICK TO   THE 
SCHEDULE.
AND, OF COURSE, EVEN WITH GAMES,
  THERE IS -- THERE'S STILL A 
LOT 
  OF ROOM FOR MANUAL TESTING.  
BUT
   THAT SPACE IS MORE FOR THE   
QUALITATIVE,
 YOU KNOW, TESTING   OF THE 
FLUIDITY
 OF THE GAME PLAY   AND THAT 
SORT OF
 ASPECTS, NOT TO   GO THROUGH 
EVERY
 SINGLE MENU ON   EVERY SINGLE 
LANGUAGE
 ON EVERY   SINGLE DEVICE.  
THAT'S
 THE JOB   FOR THE AUTOMATION. 
SO THE MOST TYPICAL ASSIGNMENT  
 WE
 GET IS THAT, YOU KNOW, GUYS,   
WE
 ONLY NEED TO AUTOMATE THE   
BASIC
 GAME -- BASIC   FUNCTIONALITY 
OF THE
 GAME, SO --   ON AS MANY 
DEVICES AS
 POSSIBLE   AND IT HAS TO RUN AS
 FAST
 AS   POSSIBLE, BECAUSE THEY 
WANT TO
   AUTOMATE IT ON EVERY SINGLE  
 BUILD.
AND, OF COURSE, WITH THESE GUYS,
  THE CHALLENGE IS NEVER THE   
ACCESS
 TO THE DEVICES.  YOU KNOW  
KNOW, FOR
 THE MANUAL TESTING,   THEY HAVE
 HUNDREDS
 OF DEVICES.    THAT'S NOT A 
PROBLEM.
THE   PROBLEM IS THAT HOW TO 
AUTOMATE
   THESE, LIKE, MONOTONOUS 
ROUTINES
  ROUTINES, AND ESPECIALLY IN A 
  WAY
 THAT THEY PRODUCE ACTIONABLE   
ACTIONABLE --
 ACTIONABLE RESULTS   IN -- SUCH
 AS,
 LIKE, PERFORMANCE   DATA LOGS, 
SCREENSHOTS,
 AND   VIDEOS AT SCALE.  YOU 
KNOW,
 WITH   MANUAL TESTING, YOU 
CAN'T --
 YOU   CAN GET THOSE, LIKE, ONE 
BY
 ONE,   BUT YOU CAN'T GET IT AT 
SCALE.

 OF
 COURSE THESE TEAMS, THEY   
DON'T HAVE,
 LIKE, PROGRAMMING   SKILLS OR 
BACKGROUND
 ON SCRIPT  SCRIPTING, WHICH 
SEVERELY
 LIMITS   THE TOOLS AND THE 
FRAMEWORKS
   THAT CAN BE USED.  AND ALSO, 
  THESE
 GUYS -- THESE TEAMS ARE   
USUALLY
 QUITE SEPARATED FROM THE   
ACTUAL
 DEVELOPMENT TEAM.  SO ANY   
KIND OF,
 LIKE, WHITE BOX TESTING   OR 
INSTRUMENTING
 THE GAME ITSELF   IS NOT 
USUALLY FEASIBLE
 FOR   THESE GUYS.  THESE GUYS 
GET
 THE   APK THROWN OVER THE FENCE
, AND
   IT'S LIKE PURE, 100% BLACK 
BOX 
  TESTING SCENARIO. 
SO WITH THESE TWO REQUIREMENTS  
 IN
 MIND, SO, NEED FOR, LIKE,   
VERY SIMPLE
 SCRIPTING WITHOUT   ANY 
COMPUTER SCIENCE
 SKILLS, AND   THE PURE 100% 
BLACK
 BOX APPROACH  APPROACH, WE 
STARTED
 LOOKING AT   THE OPEN SOURCE 
SPACE
 THAT, YOU   KNOW, WHAT SORT OF 
BUILDING
   BLOCKS COULD WE FIND TO, LIKE
, 
  (INDISCERNIBLE) UP A SOLUTION 
  THAT
 ACTUALLY SOLVES THIS SORT   OF 
PROBLEM.

SOLUTION,
 WE SELECTED APPIUM.    AND THE 
FACT
 THAT APPIUM IS
   CROSS-PLATFORM TEST
 AUTOMATION   FRAMEWORK WORKS 
REALLY
 WELL HERE  HERE, BECAUSE THE 
GAME --
   USUALLY THE GAME IS EXACTLY 
THE
   SAME ON ANDROID AND iOS.  SO 
I 
  I -- AN IDEAL CASE, YOU CAN 
USE 
  THE SAME SCRIPT TO RUN YOUR   
AUTOMATION
 ON BOTH ANDROID AND   iOS. 
ALSO, APPIUM PROVIDES A PRETTY  
 NICE
 AND ABSTRACTED API THAT WE   
CAN USE
 FOR THE NEXT LEVEL OF   OUR   
AUTOMATION
 TO RUN.  SO --   IN THIS 
SCENARIO,
 WE CAN NOT USE   ANY OF THE, 
LIKE,
 ADVANCED   FEATURES OF APPIUM, 
LIKE --
 LIKE   THE OBJECT -- INSPECTING
 THE
   OBJECT AND THOSE SORT OF 
THINGS.
  WE CAN ONLY USE, LIKE, X AND Y
   CLICKS
 AND DRAGS. 
FOR THE NEXT LEVEL, WE HAD TO   
KIND
 OF FIGURE OUT THREE THINGS.    
HOW --
 FIRST, HOW CAN WE -- HOW   CAN 
WE
 KNOW WHERE IN THE GAME   FLOW 
WE ARE?
HOW CAN WE GET   THAT INFO? 
THEN, WHEN WE GET THAT INFO,   
WHERE
 SHOULD WE CLICK NEXT?    WHAT 
IS THE
 NEXT X AND Y   COORDINATE TO 
CLICK?

 SOMETHING,
 DID WE ACHIEVE WHAT   WE WANTED
 TO
 DO?  DID THE GAME   GO TO THE 
NEXT
 STAGE AS -- AS WE   EXPECTED? 
SO THE -- TO DRIVE THE EXECUTION
  100% FROM THE OUTSIDE OF THE  
 GAME,
 WE SELECTED OPEN CV IMAGE   
RECOGNITION
 LIBRARY.      SO,   BASICALLY, 
WE
 FEED THE LIBRARY   WITH 
SCREENSHOTS
 AND REFERENCE   IMAGES.  AND IT
 DOES,
 LIKE, A --   PICKS A COMPARISON
, PICKS
 A PICK PIXELS   MATCHING.      
AND
 WHEN IT FINDS   THE MATCHING 
LOCATION,
 IT WILL   FEED THE X AND Y 
COORDINATES
 TO   THE APPIUM SCRIPT THAT 
THEN 
  EXECUTES THAT ON THE REAL   
DEVICES.
IT'S PRETTY -- THE   OPENCV 
LIBRARY
 IS VERY GOOD FOR   THIS, 
BECAUSE IT'S
 CUSTOMIZABLE.    IT'S 
RESOLUTION-AGNOSTIC,
 WHICH   IS REALLY GOOD ON REAL 
MOBILE
   TESTING -- LIKE, REAL DEVICE 
  TESTING
 CONTEXT.  AND IT CAN   EVEN 
RECOGNIZE
 IMAGES THAT ARE   STRETCHED OR,
 LIKE,
 SOMEHOW AT   AN ANGLE.  SO YOU 
CAN
 EVEN TEST,   LIKE, 3D GAMES AS 
WELL.

 ONLY
 TWO SIMPLE TASKS THAT THE   
TEST AUTOMATION
 ENGINEERS NEED   TO DO.  THEY 
NEED
 TO CUT THE   REFERENCE IMAGES 
AND
 THEN CHANGE   ONLY, LIKE, ONE 
LINE
 OR -- LIKE,   ONE LINE OF CODE 
TO
 DEFINE WHAT   KIND OF CLICK 
NEEDS
 TO BE DONE   WHEN THE REFERENCE
 IS
 MATCHING   OR WHEN YOU GET THE 
COORDINATES.
SO THEN PARALLELIZING THIS WAS  
 QUITE
 INTERESTING. 
SO IN THE -- IN THE DEVICE CLOUD
  CLOUD,
 LIKE, REMOTE DEVICE CLOUD   
CONTEXT,
 THE APPIUM CLIENT SITS   ON THE
 REMOTE
 MACHINE, WHICH IS   TYPICALLY A
 DEVELOPER
   WORKSTATION OR A MOBILE -- 
LIKE,
   A (INDISCERNIBLE) SERVER, ON 
THE
   OTHER SIDE OF THE INTERNET,  
 WHERE
 THE DEVICES ARE.  AND THIS   
THIS --
 APPIUM CREATES WHIP   DRIVER 
SESSION
 FROM THE APPIUM   CLIENT TO THE
 APPIUM
 SERVER,   WHICH IS IN THE CLOUD
, AND
 THEN,   YOU KNOW, USING THAT 
SERVER,
 ALL   THE DATA -- ALL THE DATA 
FLOWS
   OVER THE WEBDRIVER SESSION,  
 INCLUDING
 THE LOGS AND THE   SCREENSHOTS 
AND
 ALL THE CONTROL   COMMANDS. 
AND THE WAY YOU SCALE THIS IS   
THAT
 YOU JUST SPIN A LOT OF   
WEBDRIVER
 SESSIONS ON THE SAME   SAME -- 
SAME
 REMOTE MACHINE, AND  AND, YOU 
KNOW,
 YOU JUST KEEP   RUNNING IT. 
BUT THAT EFFECTIVELY RENDERS THE

   BOTTLENECK.
AND ESPECIALLY IN   OUR SCENARIO
, WHERE
 WE RUN THE   OPENCV IMAGE 
RECOGNITION
 STACK   ON TOP OF THE APPIUM 
CLIENT
 AND   WE ARE TRANSFERRING VERY 
LARGE
   SCREENSHOTS ALL THE TIME ON 
ALL
   THE DEVICES, WE REALLY HIT   
PERFORMANCE
 WALL ON, LIKE, FIVE,   SIX, 
SEVEN
 DEVICES PER REMOTE   MACHINE.  
IT
 DIDN'T SCALE.  WE   HAD TO LOOK
 FOR
 SOMETHING ELSE. 
SO OUR SOLUTION WAS THAT WE   
MOVED
 ALL THE PROCESSING, THE   WHOLE
 TEST
 EXECUTION, ON THE   SERVER SIDE
.
SO WE CREATED   VIRTUAL MACHINE 
IMAGES
 THAT   INCLUDED THE WHOLE STACK
, 
  INCLUDING THE OPENCV, THE 
APPIUM
   CLIENT AND THE APPIUM SERVER,
   AND
 THIS VIRTUAL MACHINE   
AUTOMATICALLY
 CONNECTS TO ONE   INDIVIDUAL 
ANDROID
 OR iOS   DEVICE AT A TIME. 
THEN WE CAN RUN THE -- A LOT OF 
  THESE
 ON ONE PHYSICAL SERVER, WE   
CAN RUN
   AS MANY OF THESE AS WE   WANT
.
AND THE SERVER HAS ENOUGH   
PROCESSING
 POWER TO DO ALL THE   PIXEL 
COMPARISON,
 ALL THAT.  WE   DON'T HAVE TO 
TRANSFER
 THE   SCREENSHOTS OVER THE 
INTERNET.
  AND, ACTUALLY, -- IT'S 
ACTUALLY 
  MADE THIS VERY ROBUST AND VERY
   FAST.
SO IN A WAY, IT'S LIKE APPIUM ON
  STEROIDS, BECAUSE, YOU KNOW, 
IT 
  RUNS, LIKE, THREE TIMES FASTER
   THAN
 YOUR NORMAL APPIUM.  AND   IT'S
 REALLY
 A VERY SCALABLE --   AND THE 
END USER
 DOESN'T HAVE TO   WORRY OF ANY 
OF
 THE -- HOW TO   SPIN THIS UP 
AND HOW
 TO SCALE IT  IT.  FROM THE END 
USER
 POINT OF   VIEW, IT'S LIKE 
RUNNING
 ONE   SESSION.  THEY UPLOAD 
JUST ONE
   SCREEN AND IT RUNS   SCRIPT, 
AND
 IT RUNS -- THEIR   ONLINE 
SYSTEM SCALES
 ALL THAT   EXECUTION FOR THEM 
SO WE PREPARED A DEMO.
 ON HOW   ALL THIS WORKING. 
 IN PRACTICE.
 WORK WORKS IN   PRACTICE.  SO 
CAN
 WE START   THE VIDEO?

&amp;gt;&amp;gt;Jouko Kaasila:  OKAY.  SO   
THAT'S
 A DEMO.  AND AS   PROMISED, THE
 GIFT.
ALL THE   SAMPLE CODE, ALL THE  
 INSTRUCTIONS,
 EVERYTHING YOU   CAN GET ACCESS
 TO
 THOSE AT   TESTDESTROYED.COM 
SLASHES
 GT
   TESTDROID.COM/GTAC15.    
QUESTIONS?

DON'T
 HAVE TIME FOR QUESTIONS  
QUESTIONS.
&amp;gt;&amp;gt;Jouko Kaasila:  GOOD. 
&amp;gt;&amp;gt;Yvette Nameth:  GOOD? 
[ LAUGHTER ] 
&amp;gt;&amp;gt;Jouko Kaasila:  YOU CAN   
REACH ME
 TODAY AND TOMORROW.    I WILL 
BE HERE
 THE WHOLE DAY.    ANY QUESTIONS
 ON
 AN AUTOMATE  AUTOMATING GAME 
TESTING
 OR   SCALEING APPIUM, JUST 
REACH ME
  ME. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  TWO QUICK   
LOGISTICS
 ANNOUNCEMENTS.    I'VE HAD 
PEOPLE
 ASK WHERE CAN   WE FIND THE 
SLIDES
 AND   PRESENTATIONS AFTER GTAC?
  THE ANSWER IS DEVELOPERS 
DEVELOPER
   DEVELOPERS.GOOGLE.COM/GTAC.  
  IT
 IS ALSO VERY LIKELY AND I   
WILL MAKE
 SURE IT HAPPENS   THAT WE WILL 
POST
 THE GOOGLE   BLOG WHEN WE HAVE 
POSTED
 THE   SLIDES AND THE VIDEOS.  
SO 
  THAT IS THERE FOR YOU. 
NOW, LUNCH, OH, MY GOSH,   
EXCITEING.
JUST OUTSIDE OF   BOSTON COMMON,
 IN
 THE COMMON   AREA THERE WILL BE
 LUNCH
   AVAILABLE BOTH ON THIS FLOOR 
  AND
 THERE'S ACCESSIBLE STAIRS   TO 
GO
 UPSTAIRS WHERE WE HAVE   TABLE 
AND
 CHAIRS AVAILABLE AS   WELL AS 
ANOTHER
 BUFFET OF THE   SAME FOOD BOTH 
FLOORS.
SO GO   FOR THAT. 
IF YOU HAVE ANY DIETARY   
RESTRICTIONS
 OR LIMITATIONS   AND IF YOU 
HAVE ANY
 CONCERNS,   PLEASE FIND 
SOMEBODY WITH
 A   BLACK LANYARD.  THEY ARE 
YOUR
   LINK TO FINDING THE FOOD THAT
   CAN
 ACTUALLY FEED YOU LUNCH.    AND
 WITH
 THAT BEING SAID, WE   WILL SEE 
YOU
 BACK HERE AT   2:00. 
&amp;gt;&amp;gt;Yvette Nameth:  WELCOME   BACK
, EVERYONE.
HOW WAS   LUNCH?  I HOPE 
EVERYONE IS
   FULL AND HAPPY.  AND IN THAT 
  SPIRIT,
 TO MAKE YOU HUNGRY   AGAIN WE 
HAVE
 A COOKING   LESSON FROM TONI 
CHANG
 ON HOW   TO MAKE STANLEY CUPS. 
   SOUP DUMPLINGS. 
&amp;gt;&amp;gt;Toni Chang:  I HOPE WE ALL   
HAD
 A GOOD LUNCH BECAUSE I   WAS 
TOLD
 MY PRESENTATION WAS   PUT AFTER
 LUNCH
 FOR GOOD   REASON.  SO MY NAME 
IS
 TONI   CHANG AND I'M A FOODIE. 
 I'M
   A TEST OVERFROM GOOGLE.    
SINCE
 PART OF MY WORK IS TO   
INFLUENCE
 TEST BEST PRACTICES  PRACTICES,
 I
 FIND MYSELF   HAVING TO 
CONVINCE PEOPLE
   WITH VERY DIFFERENT   
BACKGROUNDS
 LIKE ENGINEERS,   ENGINEERING 
MANAGER,
   DEVELOPER RELATIONSHIP   
MANAGER,
 AND PRODUCT MANAGERS  MANAGERS,
 WHY
 WE WANT TO DO   COMPONENT TESTS
.
AFTER   REPEATING THE BASIC TEST
   CONCEPT
 OVER AND OVER AGAIN,   I DECIDE
ED
 I WANT TO MAKE THIS   MORE 
INTERESTING.
I'M GOING   TO USE SOUP DUMPLING
 AS
 AN   ABSTRACT EXAMPLE TO   
DEMONSTRATE
 CREATION OF   END-TO-END TEST 
CASE
 AND THEN   BREAKING THEM DOWN 
INTO
   COMPONENT TESTS. 
AND DID I MENTION I'M A FOOD  
FOODIE?
A FEW YEARS AGO, I   WENT TO A 
REALLY
 FANCY   RESTAURANT AND ORDERED 
MY
   FAVORITE FOOD, THE SOUP   
DUMPLING,
 EXPECTING SOMETHING   SOFT AND 
JUICEY,
 I GOT   SOMETHING TOUGH AND DRY
.
I   WENT TO THE WAITRESS AND   
ASKED,
 WHAT IS GOING ON?  SHE   SHRUG
GED
 HER SHOULDERS AND   SAID:  
SOMETIMES
 GOOD.    SOMETIMES BAD. 
[ LAUGHTER ] 
SHOCKED AT HER ANSWER, I WENT   
TO
 THE OWNER.  THE OWNER IS A   
LOT MORE
 CUSTOMER CENTRIC AND   TOLD HER
, &quot;WE
 ARE A HIGH-END   RESTAURANT AND
 YOU
 NEED TO   MAKE SURE EVERYTHING 
IS
 OF   HIGH QUALITY BEFORE YOU 
SERVE
  SERVE&quot;.&quot; 
FOR THOSE THAT IS NEW TO THIS   
FOOD,
 HERE'S THE ANATOMY OF A   SOUP 
DUMPLING.
IT'S GOOD   REALLY THIN DELICATE
 SKIN
   WITH SOUP AND MEAT WRAPPED   
INSIDE,
 USUALLY SERVEED WARM. 
THE WAITRESS TOOK A PASS AND   
SAID,
 &quot;I GUESS I CAN TRY ONE   BEFORE
 I
 SERVE EACH PLATE&quot;.&quot;    SO EACH 
PLATE
 WILL NEED A   TEST SAMPLE FOR 
HER
 TO DRY   BEFORE SHE SERVEED. 
DO YOU THINK THIS IS GOING TO   
WORK?
AT LEAST IT WON'T BE   HORRIBLE,
 BUT
 THERE ARE LIMIT  LIMITATIONS.  
AND
 I SEE AT   LEAST THREE.  FIRST,
 SHE
   WON'T KNOW OR THE ASPECTS TO 
  LOOK
 FOR SO THAT'S THE LACK   OF 
BASELINE.
AND THEN SHE IS   GOT LIMITED 
STOMACH
 SPACE, SO   IF SHE SERVES, I 
DON'T
 KNOW,   A PLATE EVERY FIVE 
MINUTES
   SHE WILL GET FULL REALLY SOON
   SO
 THIS IS NOT SCALEABLE AT   ALL.

SOMETHING THAT
 WAS NOT RIGHT   WITH THE 
DUMPLING,
 THE   CUSTOMER WOULD NEED TO 
SIT 
  THERE AND WAIT FOR EVERYTHING 
  TO
 BE REMADE FROM SCRATCH.    SO 
THE
 TURNAROUND TIME IS WAY   TOO 
LONG.
FAST FORWARD A FEW YEARS, I'M   
NOW
 A TEST ENGINEERING.  I   EXPECT
 ENGINEERS
 TO AN   EFFICIENT AND SUSTAIN
ABLE
   TEST.  HOW CAN I HELP?  USING
   MY
 LEARNINGS FROM SOFTWARE   
TESTING,
 LET'S SEE WHAT I'M   GOING TO 
DO DIFFERENT.

THE
 SPEC.  THE SPEC WILL   SPELL 
OUT THE
 DIFFERENT   REQUIREMENT AND 
CRITERIA
 TO   LOOK FOR WHICH WILL 
ADDRESS 
  LIMITATION NUMBER ONE.  IN   
SOFTWARE,
 WE WILL HAVE   DIFFERENT 
DOCUMENTATIONS
 WITH   VARYING DIFFERENT LEVEL 
OF
   DETAIL.  LIKE THE FIRST   
COLUMN,
 THE ONE-PAGEER HAS THE   REALLY
 HIGHLY
 ATTRIBUTE OF   WHAT A SOUP 
DUMPLING
 SHOULD   BE LIKE.  IN THE 
SECOND 
  COLUMN, YOU HAVE THE PRD   
WHICH SPELLS
 OUT THE CASES.    AND THEN IN 
THE
 THIRD COLUMN   YOU HAVE THE 
FUNCTIONAL
 SPEC   WHICH HAS THE ACTUAL   
IMPLEMENTATION
 DETAIL. 
LET'S USE SAFE TO EAT AS AN   
EXAMPLE.
IF YOU WOULD HAVE   BEEN CREATE
ING
 A MANUAL TEST   CASE, YOU CAN 
JUST
 GO BY THE   PRD BECAUSE YOUR 
HUMAN
 TESTER   HAS THE COGNITIVE 
ABILITY
 TO   FIGURE OUT WHETHER 
SOMETHING
   IS COOKED OR NOT.  WHEREAS,  
 IF
 YOU ARE DOING AUTOMATION,   YOU
 MIGHT
 NEED TO SPELL OUT   WHAT &quot;COOK&quot;
 MEANS
 TO DEFINE   IT.  JUST LIKE WHEN
 YOU
 ARE   TESTING SOFTWARE, YOUR 
HUMAN
   TESTER WILL HAVE THE ABILITY 
  TO
 FIGURE OUT WHETHER A   SYSTEM 
HAS
 BEEN BOOTED   SUCCESSFULLY.  
WHEREAS,
 YOUR   AUTOMATION WILL NEED TO 
LOOK
   FOR SOMETHING MORE SPECIFIC  
 LIKE
 WHAT EVENTS TO LOOK FOR,   WHAT
 EVENT
 CONSTITUTES TO A   SUCCESSFUL 
BOOT.

SPEC
 HAS DEFINED COOKED AS   180 
FAHRENHEIT.
AND YOUR   AUTOMATION WILL BE 
HAPPY.
SO HERE IS HOW YOUR AUTOMATE  
AUTOMATABLE
 TEST CASE COULD   LOOK LIKE.  
MEASURE
 THE   DUMPLING WHEN IT COMES 
OUT OF
   THE STEAMER AND MAKE SURE   
THAT
 IT IS 180 FAHRENHEIT OR   ABOVE
. 
AND THEN YOUR SPEC ALSO SAYS   
YOUR
 DUMPLING NEEDS TO LOOK   PRETTY
.
AND IT SPELLS OUT   PRETTY AS 18
 FOLDS
 AT THE TOP  TOP.  YOUR AUTOMATE
ABLE
 TEST   CASE COULD LOOK LIKE 
COUNT
   THE FOLDS AND VALIDATE THAT  
 IT
 IS 18.  AS YOU CAN SEE,   BOTH 
OF
 THE TEST CASES NO   LONGER 
REQUIRE
 YOU TO   ACTUALLY EAT THE 
DUMPLING
 SO   IT ADDRESSES THE LIMIT
ATION 
  CHALLENGE -- I MEAN, THE   
SCALEABILITY
 LIMIT IATION. 
   IATION. 
HOWEVER, SOME OF THIS COULD   BE
 DIFFICULT
 TO VALIDATE.    SAFE, FOR 
EXAMPLE,
 THE SOFT   AND JUICEY CRITERIA,
 THE
 SPEC   SAYS IT NEEDS TO BE 30/
70 
  SOUP/MEAT RATIO.  IN ORDER TO 
  AUTOMATE
 THAT YOU HAVE TO --   OR 
VALIDATE
 THAT, YOU NEED TO   EXTRACT THE
 SOUP,
 PULL OUT   THE MEAT, WEIGHT 
THEM 
  SEPARATELY, CALCULATE THE   
RATIO
 BEFORE YOU KNOW IT HAS   MET 
THAT
 CRITERIA. 
CAN WE DO SOMETHING BETTER?    
PROBABLY
 NOT NOT WITH OUR CURRENT   
UNDERSTANDING
 BECAUSE WE HAVE   BEEN LOOKING 
AT
 THE DUMPLING   AS A FINAL 
PRODUCT
 AND HAVE   NO INSIGHT INTO ITS 
  PRODUCTION
 PROCESS.  THE BEST   WE KNOW 
YOU'VE
 GOT SOME RAW   MATERIAL, DO 
SOME AUTO
 MAGIC   AND THEN, BOOM, YOU 
HAVE YOUR
   FINAL SOUP DUMPLING. 
BUT, IF WE UNDERSTAND THE   
ACTUAL
 PRODUCTION PROCESS, WE   MIGHT 
ACTUALLY
 BE ABLE TO DO   BETTER.  SO 
LET'S
 GO THROUGH   THIS BRIEFLY.  
FIRST,
 YOU   MAKE A CHUNK OF DOUGH, 
DIVIDE
   IT INTO LITTLE PIECES, ROLL  
 THEM
 INTO SKIN, AND THEN PUT   SOME 
MEAT
 IN THERE, PUT SOME   SOUP 
JELL-O IN
 THERE, WRAP IT   UP AND THEN 
STEAM
 IT.  AFTER   YOU STEAM, THE 
SOUP JELL-O
   WILL MELT TO BECOME SOUP.    
THAT'S
 WHERE YOU GET YOUR   SOUP/MEAT 
RATIO
 FROM. 
AND IF YOU FILL IN THE DETAIL   
THAT
 YOU HAVE JUST LEARNED   ABOUT 
IN THIS
 DIAGRAM, YOU   WILL SEE THAT 
YOU WILL
   UNDERSTAND THE DUMPLING   
CREATION
 FLOW A LOT MORE.    DOES THIS 
RESEMBLE
 ANY OF   YOUR SOFTWARE 
ARCHITECTURE
   DIAGRAM?  AND IF YOU LOOK   
CAREFULLY,
 YOU WILL SEE THAT   THERE ARE A
 FEW
 MAJOR   COMPONENTS IN THERE. 
THE FIRST ONE IS DIVIDE.  IT   
TAKES
 AN INPUT OF A BLOCK OF   SOUP 
JELL-O
 AND OUTPUT THE   RIGHT AMOUNT 
FOR
 ONE DUMPLING  DUMPLING.  THE 
DIVIDE
   COMPONENT TAKES MORE THAN ONE
   INPUT
 TYPES.  IT ALSO TAKES   IN MEAT
 AND
 OUTPUT THE   CORRECT AMOUNT. 
YOUR NEXT COMPONENT TAKES IN   
BOTH
 THE SOUP AND MEAT PIECE   AND 
MAKES
 IT INTO BECOME FILL  FILLING.  
AS
 YOU CAN SEE,   EACH OF THESE 
COMPONENTS
 HAVE   THEIR INDEPENDENT INPUT 
AND
   PRODUCES THE OUTPUT THAT IS  
 EXPECTED
 FROM THEM.  AND IF   YOU 
ITERATE THROUGH
 THE WHOLE   PROCESS, YOU WILL 
SEE
 THAT   THIS IS HOW THE WHOLE 
FLOW
   LOOKS LIKE.  EACH OF THE   
COMPONENT
 HAS A CLEARLY   DEFINED INPUT 
AND
 A CLEARLY   DEFINED OUTPUT. 
AND TESTABLE SOFTWARE DESIGN   
ALSO
 LOOKS LIKE THIS.  THEY   HAVE 
WELL-DEFINED
 COMPONENTS  COMPONENTS. 
AND YOU ASK:  HOW DOES THIS   
HELP
 ME?  WELL, REMEMBER THAT   LAST
 TEST
 CASE WHERE YOU NEED   TO 
ISOLATE THE
 SOUP AND THE   MEAT AND ALL 
THAT?
LET'S SEE   IF WE CAN DO BETTER 
WITH
   COMPONENT-LEVEL VIDEOS. 
   VALIDATION.    NOW THAT YOU 
HAVE
 YOUR   COMPONENT ISOLATED, YOU 
CAN
   SEE THE DIVIDE COMPONENT IS  
 REALLY
 THE ONLY ONE THAT   CONTRIBUTES
 TO
 THIS END   RESULT.  IF YOU CAN 
MAKE
 SURE   THAT YOUR DIVIDE 
COMPONENT
 IS   OUTPUTTING THE RIGHT 
AMOUNT 
  OF SOUP JELL-O AND THE RIGHT  
 AMOUNT
 OF MEAT PIECES, IT IS   REALLY 
HIGHLY
 LIKELY THAT   YOUR END RESULT 
RATIO
 IS   GOING TO BE CORRECT. 
SO IF YOU DO A COMPONENT-  
COMPONENT-LEVEL
 VALIDATION,   ALL I NEED TO DO 
IS
 VALIDATE   THAT THE SOUP JELL-O
 IS
 OF X   GRAM AND THE MEAT IS OF 
Y 
  GRAM. 
THE WRAPPING TEST CASE,   
REMEMBER
 EARLIER YOU WERE   COUNTING THE
 FOLDS
 AFTER IT   WAS COOKED?  NOW 
THAT YOU
   HAVE THIS DIAGRAM, YOU CAN   
EASILY
 SEE THAT WRAPPING THE   FILLING
 IN
 SKIN IS REALLY THE   ONLY 
COMPONENT
 THAT HAS AN   EFFECT ON THIS 
FINAL
 RESULT.    SO INSTEAD OF 
WAITING FOR
 THE   STEAM PROCESS, YOU CAN   
VALIDATE
 THAT IT HAS 18 FOLDS   RIGHT 
AFTER
 YOUR WRAPPING   COMPONENT IS 
COMPLETE.
AND   AS YOU CAN SEE, BOTH OF 
THESE
   TEST CASES DEMONSTRATED HOW  
 COMPONENT-LEVEL
 TESTS CAN   GREATLY REDUCE THE 
TURNAROUND
   TIME AND IDENTIFY ISSUES   
EARLIER
 IN THE DEVELOPMENT   CYCLE. 
AND THE LAST TEST CASE,   
REMEMBER
 THE COOK TEST CASE   WHERE IT 
NEEDS
 TO BE 180   FAHRENHEIT?  WITH 
THE
 SAME   DIAGRAM, YOU QUICKLY 
IDENTIFY
   THAT STEAM IS THE ONLY   
COMPONENT
 THAT IS AFFECTING   THIS END 
RESULT.

 HAS
 BEEN COOKED TO 180   FAHRENHEIT
, IF
 YOU LOOK   THROUGH -- THINK 
THROUGH
 IT A   LITTLE BIT MORE, YOUR 
STEAMER
   IS NOT REALLY YOUR SYSTEM   
UNDERTEST.
IF YOU HAVE A RE  RELIABLE STEAM
ER,
 YOU SHOULD   BE ABLE TO KNOW 
THAT
 AS LONG   AS YOU COOK IT FOR N 
MINUTES,
   IT WILL REACH THE TEMPERATURE
   THAT
 YOU DESIRE.  SO YOUR   TEST 
CASE CAN
 BE GREATLY   SIMPLIFYIED TO 
MAKE SURE
 IT   HAS BEEN STEAMED FOR N   
MINUTES.
THINK ABOUT IT IN SOFTWARE   
TERMS,
 IF YOU'RE ABLE TO   CLEARLY 
DEFINE
 WHAT YOUR   SYSTEM UNDERTEST IS
 AND
 NOT   CONFLATE IT WITH ALL THIS
   DEPENDENTSY,
 YOU CAN ALSO   SIMPLIFY YOUR 
TEST
 CASE   GREATLY TO TEST FOR ONLY
 WHAT
   YOU WANT TO TEST FOR AND NOT 
  ANYTHING
 ELSE. 
 SOME PEOPLE SAY IT DOESN'T   
WORK
 FOR MY PROJECT!  MY   PROJECT 
IS TOO
 COMPLICATED   FOR IT TO BE 
DIVIDEED
 UP.  OR   OTHERS SAY, THAT'S 
NOT REALLY
   TESTING THE END-TO-END   
SCENARIO.
OR THEY SAID IF I   TEST ALL THE
 END-TO-END
   SCENARIOS IN THE WORLD, I CAN
   COVER
 MY COMPONENTS ANYWAYS. 
WELL, IF YOU LOOK AROUND,   
COMPONENT
 TESTING IS ACTUALLY   
EVERYWHERE,
 EVEN BEFORE THERE   IS SOFTWARE
.
WHEN YOU GO TO   SEE HOW KIDS 
LEARN
 GYMNASTICS  GYMNASTICS, YOU SEE
 THEY
   REPEATEDLY STICK THEIR FEET  
 OUT,
 JUST THAT, AND THAT   THEIR 
INSTRUCTOR
 WILL TELL   THEM TO CORRECT 
EVERY
 MINEOR   MOVEMENT OF THEIRS. 
AND AFTER THEY GOT THAT PART   
RIGHT,
 THEN WOULD THEN   CONNECT IT 
TOGETHER
 TO BECOME   A ROUTINE.  IF YOU 
PLAY
 IN AN   ORCHESTRA, FOR EXAMPLE,
 ALL
   THE INDIVIDUAL INSTRUMENTS   
WILL
 NEED TO MAKE SURE THAT   THEIR 
PART
 IS FLUID BEFORE   THEY COMBINE 
IT
 TO BECOME A   SYMPHONY. 
OR IF YOU PLAY SOCCER, YOUR   
COACH
 IS GOING TO ASK YOU TO   DRILL 
ON
 INDEPENDENT SKILLS   LIKE 
DRIBBLEING
 AND RUNNING   EVEN THOUGH IT IS
 COVERED
 AS   PART OF THE GAME. 
SO I HOPE YOU SEE A PATTERN   
HERE.
ANY PRODUCT THAT IS OF   COMPLEX
ITY,
 BEING IT A   PHYSICAL PRODUCT 
LIKE
 A SOUP   DUMPLING, OR AN 
EXPERIENCE
   LIKE A SYMPHONY, IN ORDER TO 
  DO
 IT WELL, YOU NEED TO BREAK   IT
 DOWN.
WHY DO WE THINK SOFTWARE IS   
ANY DIFFERENT?
IF YOU ARE   SEMICONVINCED AND 
WANT
 TO   THINK ABOUT IMPLEMENTING 
THIS
  THIS, THERE'S A TON OF   
RESOURCES
 ONLINE ABOUT TEST-  TEST-DRIVEN
 DEVELOPMENT,
   REFACTORING, TESTABLE DESIGN.
  YOU JUST NEED TO LOOK AROUND  
 AND
 FIND WHAT IS RIGHT FOR   YOU.

REALLY
 GOOD COMPONENT-LEVEL   TESTS?  
UNFORTUNATELY
 NOT.    COMPONENT TESTS IS 
REALLY
   JUST A STEPPING STONE TO A   
FINAL
 QUALITY.  IT IS NOT A   REPLACE
MENT
 OF YOUR   END-TO-END TEST.  
EVERY
 ONCE   IN A WHILE YOU DO WANT 
TO EAT
   YOUR SOUP DUMPLING AND EVERY 
  ONCE
 IN A WHILE DIVIDE YOUR   OWN 
DOGFOOD
 EVERY   PRODUCT.  MAKE NOT 
EVERY 
  PLATE AND NOT EVERY CHANGE   
THAT
 YOU MAKE.  I HOPE THIS   HAS 
GIVEEN
 YOU A NEW   PERSPECTIVE OF SEE
ING
 YOUR   OWN PRODUCT AND NEXT 
TIME 
  WHEN I USE IT, IT'S SOMETIMES 
  GOOD,
 OTHER TIMES ALSO GOOD. 
THANK YOU. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  SO THANK   YOU
, TONY.
WE HAVE NNI.  WE HAVE A FEW   
QUESTIONS
 FOR YOU.  IS A   COMPONENT 
LEVEL TEST
 THE SAME   AS A UNIT TEST? 
&amp;gt;&amp;gt;Toni Chang:  IT IS A TIME   OF
 COMPONENT
 TEST.  IF YOU   WANT TO DEFINE 
IT
 MORE   CLEARLY, UNIT TEST IS A 
  LITTLE
 BIT SMALLER TEST THAN   A 
COMPONENT.
&amp;gt;&amp;gt;Yvette Nameth:  TO WHAT   
EXTENT
 IS COMPONENT TESTING   
DEPENDENT UPON
 SERVICE-ORIENT  
SERVICE-ORIENTED ARCHITECTURE
  ARCHITECTURE?  CAN YOU   
COMPONENT
 TEST A MONOLITHIC   APPLICATION
?

COMPONENT
 TESTING IS   DEPENDENT ON A 
DESIGN
 THAT   WILL ALLOW YOU TO BE 
ABLE TO
   TEST THINGS IN ISOLATION.  SO
   I
 WOULD SAY IT IS HIGHLY   
DEPENDENT
 ON HOW THE   ARCHITECTURE IS 
AND HOW
 IT'S   DESIGNED.

FLIPPING.
[ LAUGHTER ] 
SOMETIMES YOUR COMPONENTS   HAVE
 UNEXPECTED
 CONSEQUENCES.    SAY YOU CHANGE
 TO
 A NEW   DECORATION THAT 
SOMETIMES
   PUNCTURES THE DUMPLING AND   
CAUSES
 THE SOUP TO DRAIN.    HOW CAN 
YOU
 HANDLE THIS? 
&amp;gt;&amp;gt;Toni Chang:  I THINK STUFF   
LIKE
 THIS WILL BE CAPTUREED IN   THE
 FINAL
 VALIDATION IN FINAL   
END-TO-END TEST
 THAT YOU'RE   NOT SKIPPING: 
I THINK THE POINT OF   COMPONENT
 TEST
 IS REALLY TO   MAKE SURE THAT 
YOU'RE
   CATCHING THINGS EARLY, THAT  
 YOU
 CAN TEST A COMPONENT   LEVEL 
AND NOT
 REPLACING   THINGS THAT YOU 
ABSOLUTELY
   NEED END-TO-END TESTS TO   
COVER --
 TO UNCOVER LIKE FOR   YOUR 
EXAMPLE.
&amp;gt;&amp;gt;Yvette Nameth:  HOW DOES THIS 
  COMPARE
 TO THE ACC METHODOLOGY   IN THE
 NOW-ABANDONED
 GOOGLE TEST   ANALYTICS PROJECT
? 
&amp;gt;&amp;gt;Toni Chang:  I AM ACTUALLY NOT
  FAMILIAR WITH THE GOOGLE TEST 
  ANALYTIC
 PROJECT.  SO SORRY     ABOUT 
THAT.

WE'RE
 GOING TO CALL THAT THE   LAST 
QUESTION,
 SINCE WE JUST   HAVE A FEW 
SECONDS
 REMAINING. 
SO THANK YOU, TONI. 
&amp;gt;&amp;gt;Toni Chang:  THANK YOU VERY   
MUCH.
[ APPLAUSE ]

 WE
 HAVE BRIAN GOGAN, TALKING   
ABOUT
 CHROMECAST TESTING. 
&amp;gt;&amp;gt;Brian Gogan:  HI, GUYS. 
SO AFTER ALL THAT TALK OF   
DELICIOUS
 DUMPLINGS AND LUNCH,   I'M SURE
 THERE'S
 SOME POST-FOOD   COMA SETTING 
IN.
I'LL TRY TO   KEEP IT FAST. 
MY NAME IS BRIAN GOGAN, I'M A   
SOFTWARE
 ENGINEER, TOOLS AND   
INFRASTRUCTURE,
 AT GOOGLE.  AND   I'VE BEEN 
LUCKY
 ENOUGH TO BE   WORKING ON 
CHROMECAST
 FOR THE   LAST COUPLE OF YEARS.
SO I'M GOING TO DO A LITTLE BIT 
  OF
 CONTEXT-SETTING FIRST, JUST,   
YOU
KNOW, TO KIND OF SET THE   STAGE
. 
FOR CHROMECAST, YOU KNOW, IT'S  
 PART
 OF, I GUESS, A WIDER   MOVEMENT
 THAT'S
 GOING ON IN THE   INDUSTRY 
ABOUT INTERNET
 OF   THINGS.  SO EVERYBODY'S 
KIND
 OF   AWARE OF THIS.  WE HAVE 
LOTS
   MORE DEVICES BEING RELEASED 
ONTO
   THE MARKET, BEING CONNECTED 
TO 
  THE INTERNET, AND INTER
OPERATING
   WITH EACH OTHER. 
SO THIS IS A BIG TEST CHALLENGE 
  FOR
 US.  THE NUMBERS OF DEVICES   
ARE
 PRETTY BIG.  RIGHT NOW,   WE'RE
 SOMEWHERE
 AROUND ABOUT 5   BILLION 
DEVICES IN
 THE MARKET.    AND BY 2020, 
THAT'S
 EXPECTED TO   GROW PRETTY HUGE
LY.
SO WHY DO WE CARE?  WELL,   
SOFTWARE
 REALLY POWERS ALL OF   THESE 
DEVICES.
YOU KNOW,   TYPICALLY, THERE'S 
PRETTY
   EXTENSIVE SOFTWARE STACKS   
RUNNING
 ON THESE DEVICES.  AND   AS WE 
ALL
 KNOW, SOFTWARE NEEDS   TESTING.
  SO
 LOTS OF OPPORTUNITY   FOR US. 
SO CHROMECAST, JUST WANT TO KIND

CHROMECAST.
I THINK MOST PEOPLE  PEOPLE, 
HOPEFULLY,
 KNOW WHAT   CHROMECAST IS.  BUT
 FOR
 THOSE OF   YOU THAT DON'T, IT'S
 A
 DONGLE   THAT PLUGS INTO THE 
BACK
 OF YOUR   TV AND IT ALLOWS YOU 
TO
   STREAM   CONTENT FROM THE 
INTERNET
 ONTO   YOUR TV.  AND THAT 
CONTENT
 CAN   BE MOVIES, CAN BE TV 
SHOWS,
 IT   CAN BE VIDEOS, IT CAN ALSO
 BE
   MUSIC CONTENT OR PHOTOS. 
  SO IT'S KIND OF A -- IT'S A   
CHALLENGING
 DEVICE IN SEVERAL   FACETS.  IN
 TERMS
 OF INTERNET OF   THINGS AND HOW
 IT
 ALL FITS   TOGETHER, IT'S KIND 
OF
 A GOOD   EXAMPLE OF SOME OF THE
   CHALLENGES
 THAT WE FACE.  THERE   ARE, YOU
 KNOW,
 MULTIPLE DEVICES   TALKING TO 
EACH
 OTHER.  IN ORDER   TO GET 
CONTENT
 ONTO YOUR TV, YOU   USE THE 
PHONE.
YOUR PHONE IS   YOUR REMOTE 
CONTROL.
THEREFORE,   THERE IS 
COMMUNICATION
 BETWEEN   THE PHONE AND THE 
CHROMECAST
   DEVICE ITSELF.  SO YOU'VE GOT
 A
   LOT OF ASYNCHRON JUST   
COMMUNICATION
 GOINGSYNCHRONOUS   
COMMUNICATION GOING
 ON, A LOT OF  OF, YOU KNOW, 
CHALLENGING
 THINGS   TO TEST. 
THE DEVICE ITSELF HAS BEEN   
PRETTY
 SUCCESSFUL.  WE'VE SOLD   ABOUT
 20
 MILLION OF THEM.  WE'VE   GOT 
OVER
 1,000 APPS IN THE   MARKET, 
WHICH
 MEANS IT'S, YOU   KNOW, MORE 
AND MORE
 CHALLENGING   FOR US TO RELEASE
 NEW
 FEATURES   AND MAKE SURE THAT 
WE MAINTAIN
   QUALITY OF THE ECOSYSTEM. 
SO I'M GOING TO TALK A LITTLE   
BIT
 ABOUT TEST AUTOMATION FOR   
CHROMECAST,
 TALK ABOUT SOME OF   THE 
CHALLENGES
 THAT WE, YOU KNOW  KNOW, HAVE 
FACED,
 AND KIND OF   MAP OUT SOME OF 
THE
 FUTURE WORK   THAT WE HAVE, NOT
 JUST
 FOR   CHROMECAST, BUT FOR 
INTERNET
 OF   THINGS IN GENERAL. 
I'M GOING TO FOCUS MOSTLY ON   
DEVICE
 TESTING, BECAUSE THAT'S   KIND 
OF
 PROBABLY THE MOST FUN   STUFF 
THAT
 WE DO.  BUT, YOU KNOW  KNOW, 
ONE QUESTION
 THAT ALWAYS   POPS UP IS, DO WE
 USE
 EMULATORS.    AND THE ANSWER IS
, ABSOLUTELY.
  YOU KNOW, VIRTUALIZED DEVICES 
  RUNNING
 IN THE CLOUD, IT'S A   SCALABLE
 SOLUTION,
 ALLOWS US TO   DO END-TO-END 
TESTING
 FROM, FOR   EXAMPLE, ANDROID 
PHONES
 TO   CHROMECAST DEVICES.  WE 
PUT SOME
   PLUMBING TOGETHER TO MAKE 
SURE 
  THAT THEY CAN COMMUNICATE WITH
   EACH
 OTHER, AND THEN THAT GIVES   US
 A
 VERY NICE, CLEAN, HERMETIC   
TEST
 ENVIRONMENT.  SO YOU GET A   
LOT OF
 BENEFITS THERE, LIKE   
FLAKINESS ELIMINATION.
AND IT'S   SCALABLE IN A COUPLE 
OF
 SENSE.    ONE, IT'S SCALABLE 
THAT
 YOU CAN   JUST RUN AS MANY -- 
AS MANY
   SERVERS AS YOU HAVE IN THE 
CLOUD
   YOU CAN TEST.  AND ALSO IT   
ENABLES
 INTERNAL PARTNERS THAT   WE 
HAVE AT
 GOOGLE, LIKE You  YOUTUBE, PLAY
,
 PHOTOS, TO USE   THAT 
INFRASTRUCTURE
 IN THEIR   END-TO-END TESTING. 
THEN THE QUESTION COMES UP, WHY 
  WOULD
 WE TEST ON REAL DEVICES AT   
ALL.
SO THERE ARE CLASSES OF   TESTS 
WHERE
 YOU JUST HAVE TO   TEST ON REAL
 DEVICES.
FOR   EXAMPLE, PERFORMANCE 
BENCHMARK
  BENCHMARKING, INTEROPERABILITY
   TESTING,
 YOU KNOW, WE HAVE   STACKS OF A
V AND
 DRM ON THE   DEVICE THAT WE CAN
 ONLY
 TEST ON   THE ACTUAL HARDWARE 
ITSELF.
AND   THERE'S CERTAIN TYPES OF 
BUGS,
   AS WELL, AND ISSUES THAT WILL
   ONLY
 BE FOUND ON THE DEVICE.    
LARGELY,
 THESE ARE KIND OF   TIMING
-RELATED
 ISSUES. 
SO THE CHALLENGE, THOUGH, IS   
GETTING
 A VERY GOOD, SOLID   SIGNAL-TO-
NOISE
 RATIO FROM OUR   TEST RESULTS. 
 WE
 HAVE A LOT OF   HARDWARE AND 
NETWORK
 VARIABILITY  VARIABILITY, AND, 
YOU
KNOW, THE   END RESULT OF THAT 
IS THAT
 WE   HAVE A PROBLEM OF DEVICE  
 MANAGEMENT
 THAT WE NEED TO SOLVE  SOLVE. 
SO I'LL TALK A LITTLE BIT ABOUT 
  SOME
 OF THOSE CHALLENGES. 
FIRST OF ALL, WE -- OUR DEVICE  
 LAB
 FOR CHROMECAST, JUST KIND OF   
PUT
 SOME NUMBERS AND CONTEXT   
BEHIND
 IT, 450 DEVICES WE HAVE   UNDER
 TEST.
THAT KIND OF SPANS   THE RANGE 
OF DIFFERENT
 CAST-  CAST-ENABLED DEVICES 
THAT ARE
 IN   THE MARKET, INCLUDING 
ANDROID
 TV  TV, CAST FOR AUDIO AND 
VARIOUS
   DIFFERENT GENERATIONS OF   
CHROMECAST.
LOTS OF BUILDS   COMING OUT PER 
DAY,
 MILLIONS OF   TEST RUNS, ALL 
THAT
 GOOD STUFF,   LOTS OF GANGNAM 
STYLE
 PLAYBACKS.    WE CONTRIBUTED 
PRETTY
 HEAVILY TO   THAT. 
MANAGING ALL THESE DEVICES, WHAT
  WE DID FOR THIS WAS TO BUILD A
   TOOL,
 OUR DEVICE MANAGER.  THERE   
ARE QUITE
 A FEW DIFFERENT TOOLS   AT 
GOOGLE,
 KIND OF WORKING   TOWARDS 
SOLVING
 THIS.  WE FOUND   WE HAVE TO 
BUILD
 ONE OURSELVES   FOR A COUPLE OF
 REASONS.
      ONE, WE HAVE SOME PRETTY 
CUSTOM
   SETUPS, OF WHICH THE OTHER   
SOLUTIONS
 IN THE MARKET OR AT   GOOGLE 
WEREN'T
 SUPPORTING.  THE   OTHER ONE IS
 THAT
 THE GROUPING   OF DEVICES, WE 
HAVE
 FAIRLY   SPECIFIC GROUPINGS OF 
DEVICES
   THAT ARE NECESSARY FOR 
SPECIFIC
   TYPES OF TESTS.  AND WE 
NEEDED 
  TO BE ABLE TO SUPPORT THAT. 
SO THAT'S JUST -- YOU CAN KIND  
 OF
 SEE THERE THE UI OF WHAT THE   
DEVICE
 MANAGER LOOKS LIKE.  KIND   OF 
GIVES
 YOU AN IDEA. 
SO WHAT THIS DEVICE MANAGER DOES
  IS, WHEN A TEST STARTS, THIS  
 MANAGER
 ACTS AS A BROKER.  IT   
ALLOCATES
 A DEVICE TO A TEST AND   THEN 
TESTS
 WILL RUN   ON THAT   DEVICE FOR
 A
 SPECIFIC PERIOD OF   TIME. 
IN TERMS OF STUFF THAT GOES   
WRONG,
 LOTS OF STUFF GOES WRONG.    
KIND
 OF BASIC, OBVIOUS ONES ARE,   
YOU
KNOW, WE DON'T HAVE ENOUGH   
DEVICES
 TO RUN TESTS, SO   STANDARD 
CAPACITY
 ISSUE.  YOU   KNOW, WE KIND OF 
SOLVE
 THAT BY   THROWING MORE 
HARDWARE AT
 THE   PROBLEM. 
THERE'S ALSO THE VARIATION OF   
TEST
 RESULTS ACROSS DEVICES.    
WE'VE FOUND
 THAT THERE WERE, YOU   KNOW -- 
EVEN
 BETWEEN DIFFERENT   REVS OF THE
 HARDWARE,
 WE WOULD   FIND VARYING RESULTS
.
SO THAT   WAS REALLY TRICKY TO 
KIND
 OF DE  DEBUG IN SOME CASES.  
YOU KNOW,
   WE KIND OF BUILT A LOT OF 
TRACE
  TRACEABILITY OF DEVICES INTO 
THE 
  THE -- INTO THE SYSTEM SO THAT
   WE
 COULD REALLY NAIL DOWN   
EXACTLY WHERE
 DIFFERENCES WERE   AND ISOLATE 
ISSUES.

  UNRELIABLE
 DEVICES, MAINLY.    WE'VE -- A 
LOT
 OF HARDWARE IN   THE LOOP.  AND
, YOU
KNOW,   HARDWARE LIKES TO FRY 
ITSELF
 OR   OVERHEAT.  IT LIKES TO DIS
  DISCONNECT
 FROM THE NETWORK FOR   
ARBITRARY REASONS.
WE ALSO GET   STUFF LIKE KERNEL 
BUGS,
 WHICH   MEAN IT'S REALLY HARD 
TO RECOVER
   THE DEVICES.  WE'VE ALSO HAD 
  CASES
 WHERE THE MAC ADDRESSES OF   
THE DEVICES
 JUST CHANGE   FOR   ARBITRARY 
REASONS,
 PROBABLY   BREAKING SOME IEEE 
RULES.
JUST   HAPPENS. 
SO COUNTERMEASURES THERE, LOTS  
 OF
 MONITORING, LOTS OF LOGGING,   
REDUNDANCY
 AS WELL.  WE THREW A   LOT OF 
HARDWARE
 AT THE PROBLEM   SO IF A DEVICE
 DOES
 GO DOWN, WE   HAVE REDUNDANT 
BACKUPS.
ALSO,   BEFORE WE ALLOCATE A 
DEVICE
 FOR   A TEST, WE'LL DO SOME 
KIND OF
   BASIC SANITY CHECKS TO 
VALIDATE
   THAT, YOU KNOW, THIS IS A   
REASONABLE
 DEVICE TO USE. 
AND THEN KIND OF ONE OF THE   
WORST-CASE
 SCENARIOS THAT WE   SOMETIMES 
RUN
 INTO IS THE KIND   OF BAD BUILD
 EFFECT
 WHERE A   DEVICE GETS A BAD 
BUILD
 AND IT   BREAKS THE DEVICE.  
AND,
 YOU   KNOW, THIS BECOMES A 
PRETTY
   VIRULENT CASCADING EFFECT AND
   PRETTY
 QUICKLY TAKES OUT THE   ENTIRE 
LAB.
REALLY PAINFUL,   HORRIBLE STUFF
.
YOU'VE GOT TO   GO IN THERE AND 
RECOVER
 ALL   THESE DEVICES MANUALLY.  
NOT
 FUN  FUN, ESPECIALLY WHEN 
YOU'VE GOT
   HUNDREDS OF DEVICES, AND 
TRYING
   TO TRACE DOWN THE ONES THAT 
ARE
   ACTUALLY BROKEN. 
SO WE'VE KIND OF ESTABLISHED A  
 QUARANTINE
 SYSTEM BEFORE WE PUSH   BUILDS 
ONTO
 A WIDER POPULATION   OF DEVICES
, WE
 WILL PUSH THEM   ONTO A SMALLER
 SUBSET
 OF DEVICES  DEVICES, WHICH ARE 
KIND
 OF OUR   TASTE TESTERS OF SORT.
SO I THINK JUST KIND OF     TO  
 SUMMARIZE
 IN TERMS OF THE   TOOLING 
REQUIREMENTS
 FOR JUST   GENERAL DEVICE 
MANAGEMENT
 AND   INTERNET OF THINGS 
TESTING.
SO   DEVICE ALLOCATION AND 
BROKERING
   MECHANISMS, THAT'S KIND OF A 
  GIVEN.
WE ALSO NEED A SYSTEM TO   BE 
SOMEWHAT
 DEVICE TYPE AGNOSTIC  AGNOSTIC,
 AS
 WE'RE WORKING WITH   VARIOUS 
DEVICES,
 INTEROPERATING   WITH EACH 
OTHER.
AND PLENTY OF   MONITORING.  
MONITORING
 IS SUPER   IMPORTANT. 
SO THE OTHER KIND OF MAJOR   
CHALLENGE
 THAT WE FACE WITH   CHROMECAST 
IS
 WI-FI.  SO I'LL   TALK A LITTLE
 BIT
 ABOUT SOME OF   THE CHALLENGES 
HERE.
SO THE REQUIREMENTS FOR A GOOD  
 WI-FI
 SYSTEM OR TEST SYSTEM ARE   
KIND OF
 SOMEWHAT, YOU KNOW,   COUNTER 
TO EACH
 OTHER.    OBVIOUSLY YOU WANT 
RELIABLE
 TEST   SIGNAL.  YOU WANT TO 
ISOLATE
   AWAY ANY WI-FI INTERFERENCE 
SO 
  THAT THE TEST IS SOMEWHAT 
ROBUST
  ROBUST.  AT THE SAME TIME, YOU
   WANT
 TO HAVE SOME LEVEL OF   
CONTROLLED
 INTERFERENCE SO THAT   WHEN YOU
 DO
 RUN A TEST, IT'S   ACTUALLY 
EXERCISING
 SOME OF THE   LOGIC THAT'S ON 
THE
 DEVICE FOR   ROBUSTNESS. 
AT THE SAME TIME, YOU WANT TO DO

 ENVIRONMENT,
 WHICH IS SOMEWHAT   CHALLENGING
 TO
 GENERATE IN A LAB  LAB. 
AND AT THE SAME TIME, YOU WANT  
 TO
 TEST ACROSS A WHOLE BUNCH OF   
APs.
THERE'S HUNDREDS OF APs  APs OUT
 THERE THAT PEOPLE ARE   USING. 
AND THEN THE KIND OF HOLY GRAIL 
  IS
 ALSO TO BE ABLE TO REPRODUCE   
WI-FI
 ISSUES THAT HAPPEN IN THE   
FIELD.
THAT'S KIND OF AN OVER  OVERALL 
INDUSTRY
 CHALLENGE THAT   WE HAVE. 
SO LIKE I SAY, SOME OF THOSE MAY

   STRATEGY,
 REALLY, FOR THIS, FOR   ATTACK
ING
 THIS PROBLEM, HAS BEEN   TO 
IMPLEMENT
 VARIOUS DIFFERENT   TEST BEDS. 
 WE
 HAVE TEST BEDS   FOR THESE 
VARIOUS
 DIFFERENT   ENVIRONMENTS.  AND 
I'LL
 JUST   KIND OF QUICKLY WALK 
THROUGH
   THESE. 
FIRST ONE IS, THESE ARE RFI   
ISOLATION
 BOXES THAT WE USE N   OUR TEST 
LAB,
 ONE OF THE   CHALLENGES WE HAVE
 IS
 THE WI-FI   INTERFERENCE FROM, 
YOU
KNOW,   VARIOUS OTHER DEVICES 
THAT
 ARE   AROUND.  SO EVEN IF WE --
 YOU
   KNOW, IF WE JUST HAVE A TEST 
  RUNNING
 ON A DEVICE IN THE LAB,   IT'S 
PROBABLY
 GOING TO BE SUPER   FLAKY.  SO 
WE
 PUT THE DEVICES   INTO THESE 
BOXES.
THESE FREEWAY   ABOUT PROVIDE   
ABOUT
 80DBs OF ATTENUATION AND   GIVE
 US PRETTY CLEAN TEST SIGNAL  
SIGNAL.
ONE OF THE COOL THINGS ABOUT   
WORKING
 AT GOOGLE IS WE HAVE   LOTS OF 
OTHER
 TEAMS WORKING ON   SIMILAR 
PROBLEMS.
THE CHROME OS   GUYS HAVE DONE 
AN AMAZING
 JOB OF   PUTTING TOGETHER AN 
INTER
  INTEROPERABILITY ENVIRONMENT  
 WHERE
 THERE'S 50-PLUS OF THE   MOST 
POPULAR
 APs IN THE MARKET   IN A FULL 
SETUP.
WE CAN DROP   OUR CHROMECASTS 
INTO
 THIS   ENVIRONMENT.  YOU CAN   
COMMUNICATE
 WITH JUST ONE AP AT   A TIME  .
  AND
 THIS IS WHAT WE   USE FOR SETUP
 TESTING,
 FOR   EXAMPLE, ON THE 
CHROMECAST TO
   MAKE SURE THAT IT INTER
OPERATES
   WITH THESE VARIOUS DIFFERENT 
AP
  APs.  THIS IS  -- TURNS OUT TO
   BE PROBABLY ONE OF OUR   
CORNERSTONES
 OF OUR ENTIRE TEST   STRATEGY 
FOR
 WI-FI ON CHROMECAST  
CHROMECAST. 
LET'S SEE. 
ANOTHER KIND OF ENVIRONMENT THAT
  WE HAVE.  SO THIS IS LESS ON 
THE
   AUTOMATED SIDE, MORE ON THE  
 MANUAL
 TEST SIDE, IS A SED OF   
SHIELDROOMS
 THAT WE'VE BUILT,   FARADAY 
CAGES
 ABOUT THE SIZE OF   AN OFFICE. 
 WE
 HAVE PEOPLE IN   THERE TESTING.
  WE
 HAVE SOME   AMOUNT OF OUGHT 
AUTOMATION
 WE DO   IN THERE WHERE WE ARE 
MIRRORING
   FROM A DEVICE TO A CHROMECAST
 .
  AS FAR AS WI-FI'S CONCERNED,  
 THAT'S
 A PRETTY CHALLENGING SET  SETUP
.
THERE'S MULTIPLE STREAMS   GOING
 FROM
 DEVICE TO DEVICE.  SO   A 
SHIELDROOM
 IS VERY, VERY   USEFUL THERE.  
ONE
 KIND OF   INTERESTING STRESS 
TEST
 WE CAN   DO THERE IS START OFF 
A 
  MIRRORING SESSION AND THEN   
SLOWLY
 OPEN THE DOOR AND JUST   WATCH 
THE
 SESSION DEGRADE .    IT'S KIND 
OF
 FUN TO WATCH. 
ANOTHER MORE RECENT ADDITION TO 
  OUR
 LAB IS AN OCTO BOX.  THIS   
EQUIPMENT
 GIVES US A COUPLE   DIFFERENT 
LEVERS
 .  ONE IS AN   ATTENUATOR.  SO 
WE'LL
 PUT A   ROUTER IN ONE OF THE 
CHAMBERS,
   AND THE DEVICE OWNER TEST IN 
A 
  SECOND CHAMBER AND WE CAN VARY
   THE
 ATTENUATION IN A VERY   
CONTROLLED
 MATTER.  IT ALSO HAS   A MULTI
PATH
 EMULATOR WHICH KIND   OF 
SIMULATES
 THE REAL-WORLD   INTERFERENCE 
OR ECHOING
 THAT   HAPPENS IN A WORLD FROM 
AN
 AP TO   A DEVICE .  AND WE -- 
IT ALSO
   ALLOWS US SOME LEVEL OF   
INTERFERENCE
 GENERATION TO   INJECT THAT 
INTO THE
 BOX. 
SO THIS IS -- YOU KNOW, WE DO   
SOME
 LEVEL OF AUTOMATED TESTING   IN
 THIS.
BUT IT'S PRIMARILY,   YOU KNOW, 
AN
 EXPERIMENTAL SETUP   WHICH KIND
 OF
 ALLOWS US TO KIND   OF SOLVE, 
YOU
KNOW, WHEN WE GET   A NEW WI-FI 
DRIVER,
 TO VALIDATE   THAT THE QUALITY 
IS
 THERE. 
  AND THE FINAL ONE THAT WE KIND

  ENVIRONMENT.
SO THIS HAS BEEN   VERY USEFUL, 
FOR
EXAMPLE, WITH   MIRRORING WHERE 
WE
 WANT TO HAVE   A VERY 
CONTROLLED SET
 OF   ENVIRONMENTS WHERE WE 
INJECT
 A   LOT OF LATENCY OR PACKET 
LOSS
   AND IT GIVES US, YOU KNOW, 
GOOD
   METRICS   ON THE QUALITY OF 
THE
   MIRRORING SESSION. 
SO THE DEVICE LAB.  I HAVE SOME 
  PHOTOS
 TO SHOW.  WHEN I WAS   TALKING 
A LITTLE
 BIT EARLIER   ABOUT, YOU KNOW, 
IF
 THE -- WE   GET A BAD BUILD ON 
A BUNCH
 OF   DEVICES, IT'S PRETTY 
PAINFUL
 TO   GO THROUGH. 
SO HERE IS THE UGLY PREVIOUS   
SITUATION.
SO YOU CAN IMAGINE   TRYING TO 
FIND
 DEVICE NUMBER 22   IN THAT MESS
.
NOT A LOT OF FUN.    WE KIND OF 
HAD
 THIS UGLY BEAST   OF A THING 
WHICH
 WE   ANTHROPOMORPHIZED INTO AN 
AN
 ANIMAL   WE CALL CASTY, NASTY 
CASTY.
SO WE SPENT A LOT OF TIME ON   
DESIGNING
   A BETTER SETUP.  AND   THIS 
IS KIND
 OF WHAT WE HAVE NOW  NOW.  SO 
LOTS
 OF, YOU KNOW, NEAT   FEATURES 
HERE.
A COUPLE OF --   OBVIOUSLY, 
WE'VE GOT
 NICE   LABELING SO YOU CAN 
FIGURE
 OUT   WHICH DEVICE IS WHICH.  
IT'S
 ALL   LOGICALLY LAID OUT.  COOL
 THING,
   YOU CAN SEE FROM ON THE 
SECOND FROM
   TOP SHELF, YOU CAN SEE WE 
HAVE 
  SWITCHES THERE.  THOSE 
SWITCHES 
  US ALLOW US TO VIEW THE HDMI  
 OUTPUT
 OF ANY OF THE CHROMECASTS   ON 
THE
 RACK.  EACH RACK HOLDS 72   
CHROMECAST
 DEVICES ALL RUNNING   
CONTINUOUS INTEGRATION
 TESTING. 
CLOSEUP.  THERE YOU CAN SEE SOME

   THE
 (INDISCERNIBLE) CONNECTION   IS
 THERE.
THAT'S ROUTED UNDER   THE SHELF 
AND
 UP TO THE TOP   SCREENS VIA THE
 SWITCHES.
HERE YOU CAN SEE KIND OF THE   
BACK
 SIDE OF IT, WHERE WE HAVE   
ETHERNET
 CONNECTIVITY TO ALL OF   THE 
DEVICES.
THAT'S ONE OTHER   POINT.  ALL 
THESE
 DEVICES UNDER   TEST ARE HARD 
CONNECTED
 VIA   ETHERNET, WHICH, 
OBVIOUSLY,
   CLEANS UP -- MAKES FOR MORE  
 RELIABLE
 TEST RESULTS. 
HERE YOU CAN SEE THE SERIAL   
CONNECTIONS
 COMING FROM THE   BOTTOM OF THE
 DEVICES.
WE HAVE   A CLASS OF TESTS AS 
WELL
 THAT   REQUIRE HDMI SINKS TO BE
   CONNECTED
 TO.  SO IT'S KIND OF   FUN TO 
WATCH
 TESTS RUNNING ON   ALL THESE 
DIFFERENT
 SCREENS.    HERE YOU CAN SEE 
OUR NEXT-
  NEXT-GENERATION CHROMECAST   
DEVICES
 CONNECTED UP. 
SO I HAVE SOME QUICK PHOTOS OF  
 THE
 BUILDOUT OF THE LAB RACK.    WE
 KIND
 OF CAME UP WITH THIS   CONCEPT,
 SOURCED
 THESE   COMPONENTS.  AND, YOU 
KNOW,
 KIND   OF BUILT OUT THE -- THE 
LAB
 RACK   AS WAS.  SO WE STARTED 
OFF
 WITH   SOME CARDBOARD, WENT 
FROM HERE
   ALL THE WAY TO A FULLY 
FLESHED-
  FLESHED-OUT PROTOTYPE.  AND 
THEN
   STARTED BUILDING UP ON A RACK
.
  AND THEN ENDED UP WITH WHAT WE
   HAVE
 TODAY. 
SO OPPORTUNITIES.  I THINK, YOU 
  KNOW,
 INTERNET OF THINGS, LIKE I   
SAY,
 IT'S A NASCENT AREA,   
ESPECIALLY
 AS FAR AS TEST   ENGINEERING IS
 CONCERNED.
I   THINK THERE'S A LOT OF US IN
   THIS
 ROOM HERE WHO ARE WORKING   ON 
VARIOUS
 DIFFERENT APPROACHES   TO THIS.
  BUT
 I THINK IT'S FAIR   TO SAY THAT
 THERE'S
 NO BROADLY   ADOPTED FRAMEWORKS
 IN
 THE MARKET   AT THE MOMENT.  SO
 LOTS
 OF   OPPORTUNITIES FOR TESTING 
IN
 THE   CLOUD, FOR VIRTUALIZATION
, INTER
  INTEROPERABILITY LABS.  WE 
HAVE 
  EMERGING STANDARDS COMING OUT 
  WITH
 THREAD, WEAVE, AND VARIOUS   
DIFFERENT
 STANDARDS LIKE THAT.    SO 
THERE ARE --
 THERE IS   CONVERGENCE 
HAPPENING,
 BUT KIND   OF, LIKE I SAY TO MY
 TEAM,
 YOU   KNOW, WE HAVE PROBABLY 
DECADES
   OF WORK AHEAD OF US IN ORDER 
TO
   SOLVE THESE PROBLEMS. 
SO THAT'S IT. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU. 
AND SADLY, WE DON'T HAVE TIME   
FOR
 QUESTIONS AFTER THIS ONE. 
&amp;gt;&amp;gt;Brian Gogan:  I USED IT ALL UP
  UP.

DECIDED
 TO USE IT ALL UP SHOWING   US 
SOME
 PICTURES. 
SO NEXT WE HAVE SHAUVIK ROY   
CHOUDHARY,
 WHO IS GOING TO TALK   TO US 
ABOUT --
 I CANNOT REMEMBER   THE TITLE 
-- USING
 ROBOTS TO   TEST YOUR ANDROID 
APP.


EVERYBODY.
THIS IS THE -- THIS   IS MY 
SECOND
 TIME AT GTAC.  LAST   TIME, I 
LED
 A ROUNDTABLE   DISCUSSION ON 
CROSS-PLATFORM
   MOBILE TESTING.  AND NOW, 
THIS 
  TIME, I'M GLAD TO COME BACK TO
   TALK
 ABOUT USING ROBOTS FOR APP   
TESTING.
SO A --  SO ONE THING, RIGHT, SO
  I'M GOING TO TALK ABOUT, YOU  
 KNOW,
 SOFTWARE AND NOT LIKE THE   GUY
S 
  GUY   OPTOFIDELITY GUYS WHO 
SHOWED
 A   REAL ROBOT. 
LET ME TELL YOU A LITTLE BIT   
ABOUT
 MYSELF.  I GOT MY PH.D.   FROM 
GEORGIA
 TECH IN THE SUMMER.    MY 
THESIS WAS
 IN THE LINES OF   HOW TO DO 
BETTER
 CROSS-PLATFORM   TESTING AND 
MAINTENANCE
 FOR  WEB   AND MOBILE 
APPLICATIONS;
 RIGHT?    AND OVER THE PAST FEW
 YEARS,
   I'VE BEEN LUCKY ENOUGH TO 
WORK 
  AT SEVERAL COMPANIES.  GOT A 
LOT
   OF INDUSTRY EXPERIENCE.  AND 
IN
   THE PAST ONE YEAR, I HAVE 
BEEN 
  TAKING PART IN THE DIFFERENT  
 ENTREPRENEURSHIP
 PROGRAMS AT   GEORGIA TECH, YOU
 KNOW,,
 YOU KNOW.  AND   THAT HAS LED 
ME TO
 CHECKDROID.    IF YOU HAVE ANY 
INEFFICIENCY
 IN   TESTING, REACH OUT TO ME, 
FIND
   ME DURING THE BREAK. 
 TODAY'S TALK WILL BE MAINLY   
FOCUSED
 ON PRESENTING RESULTS   FROM 
THIS
 RESEARCH PAPER THAT WE   WROTE;
 RIGHT?
SO AUTOMATED TEST   INPUT 
GENERATION
 TECHNIQUES FOR   ANDROID.  ARE 
WE
 THERE YET?    THAT'S THE 
QUESTION
 THAT WE ARE   TRYING TO ADDRESS
 IN
 THIS PAPER. 
AND MY COLLABORATORS FOR THIS   
PROJECT
 WERE MY ADVISOR, DR.   DR. ALEX
 ORSO
 AND DR. ALESSANDRA   GORLA FROM
 SOFTWARE
 INSTITUTE,   SPAIN. 
THIS PARAM WILL BE PAPER WILL BE
 PRESENTED
 IN   LINCOLN, NEBRASKA AT THE A
SE.

TESTING.
LET'S FIRST SEE HOW   THE TEST 
STRUCTURE
 LOOKS LIKE.    WE ALL ARE 
FAMILIAR
 WITH THIS;   RIGHT?  TEST 
STRUCTURE
 HAS, YOU   KNOW, THREE 
DIFFERENT --
 FOUR   DIFFERENT STEPS.  START,
 YOU'LL
   HAVE THE SETUP PHASE WHERE 
YOU 
  INITIALIZE YOUR ENVIRONMENT 
AND 
  GET IT READY FOR TESTING. 
THE NEXT PHASE IS THE EXERCISE  
 PHASE.
AND WHAT YOU DO HERE IS   THAT 
YOU,
 YOU KNOW, INTERACT   WITH THE 
APP,
 PROVIDE IT INPUTS   AND 
EXERCISE IT;
 RIGHT? 
AND THE NEXT STEP, WHICH IS   
VERIFY,
 YOU WILL CHECK WHETHER   THE 
APP ,YOU
KNOW, CAME IN   EXPECTED STATE 
OR NOT.
IF IT   HAS THE INPUTS YOU GAVE 
IT.
AND THE FINAL STEP IS THE TEAR  
TEARDOWN,
 WHERE YOU CLEAN UP THE   
ENVIRONMENT
 AND GET READY FOR   THE NEXT 
STEP.


RIGHT?
SO LET'S SAY, YOU KNOW, WE HAVE 
  A
 ROBOT FOR THE TEST SETUP PHASE 
 PHASE,
 IT CAN SAY THAT, OKAY,   LET ME
 START
 THE APP.  LET ME   INSTALL THE 
APP
 ON THE DEVICE   AND LET'S START
 IT.



  LET'S
 HAVE AN ARTICLE OR A   POLICY 
THAT
 THE APP MAY NOT   CRASH, IT 
MIGHT
 NOT SHOW ANY   ISSUES THAT YOU 
CAN
 IDENTIFY. 
BUT THE MOST IMPORTANT OR THE   
MOST
 CHALLENGING THING FOR SUCH   A 
ROBOT
 IS WHAT INPUTS SHOULD IT   GIVE
 THE
 APPLICATION SO THAT IT   COULD 
MEANINGFULLY
 EXERCISE THE   APPLICATION; 
RIGHT?

THIS
 TALK WHERE WE ARE GOING TO   
EVALUATE
 EXISTING INPUT   GENERATION 
TECHNIQUES;
 RIGHT? 
SO LET ME FIRST INTRODUCE YOU TO
  THE SIMPLEST AND MAYBE MOST OF
   YOU
 SHOULD ALREADY BE FAMILIAR   
WITH
 THE ANDROID MONKEY TOOL.    WHO
 HERE
 HAS USED THE ANDROID   MONKEY 
TOOL?

YOU.  SO THIS IS. A   TOOL
 WHICH COMES AS A PART OF   THE 
ANDROID
 SDK.  IF YOU HAVE   THE ANDROID
 SDK
 INSTALLED,   YOU SHOULD HAVE 
THIS
 TOOL.    AND YOU CAN INVOKE IT 
USING
   ADB SHELL SO YOU CAN SAY ADB 
  SHELL,
 GIVE IT THE PACKAGE   NAME FOR 
YOUR
 APP, AND GIVE   IT A NUMBER OF 
EVENTS,
 LET'S   SAY 500, RIGHT?, AND 
WHAT
 IT   WILL DO IS IT WILL JUST 
PICK
   RANDOM EVENTS AND THROW IT AT
   YOUR
 APP TO INVOKE IT TO MAKE   IT 
DO DIFFERENT
 THINGS, RIGHT  RIGHT? 
AND THIS TOOL ALSO HAS SOME   
ADVANCED
 OPTIONS, RIGHT?  SO   SINCE 
IT'S USING
 RANDOM  RANDOMIZATION, YOU CAN 
SET
 A   NUMBER SEED FOR THE RANDOM 
 RANDOMIZATION,
 RIGHT?  YOU   COULD ALSO 
THROTTLE
 THE TOOL.    YOU COULD SAY 
BETWEEN
   DIFFERENT EVENTS GIVE THIS   
MUCH
 TIME OR GIVE THIS MUCH   WEIGHT
 FOR
 THIS MANY   MILLISECONDS.  YOU 
WOULD
 TELL   IT WHEN CHOOSEING THE   
DIFFERENT
 EVENTS, RIGHT,   FOCUS MORE ON 
THIS
 KIND OR   THIS CATEGORY OF 
EVENTS
 SO   YOU CAN GIVE A PERCENTAGE 
  DISTRIBUTION.
AND BY DEFAULT   THIS TOOL.STOP 
AFTER
 IT FINDS   THE FIRST ISSUE.  SO
 YOU
 CAN   TELL IT TO IGNORE ISSUES 
LIKE
   EXCEPTIONS OR TIMEOUTS AND SO
   ON.

, RIGHT?
AND WE LOOKED   AT AN ACADEMIC 
PAPERS
 AND   INDUSTRY TOOLS AND FOUND 
THAT
   THERE WERE SEVERAL SUCH TOOLS
   WHICH
 WERE OUT THERE IN   RESEARCH 
PAPERS
 AND IN BLOG   POSTS.  SO WE 
WANTED
 TO SEE   HOW DO THESE TOOLS 
COMPARE
   AGAINST EACH OTHER, RIGHT?   
 AND
 IS THERE NEED FOR   ADDITIONAL 
RESEARCH
 YET?    RIGHT?  SO THAT'S THE  
 QUESTION
 WE ASKED, FOR THIS   INPUT 
GENERATION
 TOOLS, HAVE   ANY OF THESE 
TOOLS SOLVEED
 THE   PROBLEM AND ARE WE THERE 
YET?
  THAT WAS THE QUESTION WE WERE 
  ASKING.
AND WHILE DOING THE STUDY, WE   
CONSIDERED
 THESE TOOLS AS   ROBOTS, RIGHT?
  WE
 CONSIDERED   THEM AS PUSH-
BUTTON TECHNIQUE
  TECHNIQUES.  YOU GIVE THIS   
TOOL
 YOUR APP AND START IT   AND IT 
SHOULD
 TEST YOUR APP   AND GIVE YOU 
ALL THE
 PROBLEMS   THAT YOUR APP HAS.  
SO
 LET ME   CLARIFY A LITTLE BIT 
THE
 GOAL   OF TESTING IN GENERAL, 
RIGHT?

BE
 TO MAKE THE APP CRASH AND   
ALSO TO
 EXERCISE THE   DIFFERENT 
BEHAVIORS
 THAT ARE   THERE IN THE APP, 
RIGHT?
SO   IF THE ROBOT EXERCISED A   
PARTICULAR
 BEHAVIOR OR A   PARTICULAR 
FUNCTIONALITY
 OF   THAT APP AND IF IT COULD 
NOT
   CRASH THAT FUNCTIONALITY,   
THEN
 YOU HAVE AT LEAST SOME   LEVEL 
OF
 A CONFIDENCE, RIGHT? 
AND FOR THIS TYPICALLY   
COVERAGE IS
 THE WEIGHT OR THE   APPROXIMATE
 TO
 MEASURE THIS   KIND OF
   APPROXIMATEY
 TO MEASURE THIS   THIS -- PROXY
 TO
 MEASURE THIS   KIND OF A THING.

THE OTHERS
 BASED ON THE   STRATEGY IT USES
.
I WILL   SHOW YOU FOUR THINGS 
THAT
   ACTUALLY INFORM THE TOOL   
STRATEGY.
THE FIRST IS THE   INSTRUMENT
ATION
 STRATEGY,   RIGHT?  SO EACH 
TOOL HAS
 TO   INTERACT WITH THE APP AND 
  KNOW
 OR UNDERSTAND WHAT   HAPPENED 
AS A
 RESULT OF THIS   INTERACTION.  
SO
 THE TOOL   MIGHT MODIFY THE APP
 BY
   INJECTING PROBES IN OR IT   
MIGHT
 MODIFY THE PLATFORM TO   KNOW 
WHAT'S
 GOING ON IN THE   PLATFORM, 
RIGHT?
SO THIS IS WHAT I MEAN BY   
INSTRUMENTATION
 STRATEGY  STRATEGY. 
THE NEXT ONE IS DOES THE TOOL   
INTERACT
 WITH THE APPLICATION   THROUGH 
--
 ONLY THROUGH AN UI   OR DOES IT
 ALSO
 SEND A SYSTEM   EVENTS.  SO, 
FOR EXAMPLE,
   PARTS OF YOUR APP MIGHT BE   
TRIGGERED
 VIA EXTERNAL   NOTIFICATIONS OR
 BY
 SMS   MESSAGES.  LET'S SAY YOUR
   MESSAGE
 GETS A SMS AND YOUR   APP IS 
LISTENING
 TO THAT.  IN   ORDER TO TRIGGER
 SUCH
   FUNCTIONALITY, YOU HAVE TO   
SEND
 THE SYSTEM EVENTS IN   ORDER TO
 SEE
 WHICH TOOLS DO   WHAT. 
THE THIRD ONE IS -- DOES THE   
TOOL
 REQUIRE THE SOURCE CODE   OF 
THE APP
 TO DO THE TESTING   OR CAN IT 
DO IT
 IN A BLACK   BOX FASHION. 
AND THE FOURTH AND THE MOST   
IMPORTANT
 STRATEGY IS THE   EXPLOREATION 
STRATEGY.
THIS   DECIDES HOW THIS TOOL IS 
  GOING
 TO EXPLORE THE STATE   SPACE OF
 THE
 APPLICATION,   RIGHT?  I'M 
GOING TO
 COVER   THIS IN MORE DETAIL.  
THERE
   ARE THREE SUCH STRATEGYIES,  
 RIGHT?,
 RANDOM, MODEL-BASED   AND 
SYSTEMATIC.
LET'S DIVE INTO THIS A LITTLE   
BIT
 AND LOOK AT THE DIFFERENT   
EXPLOREATION
 STRATEGYIES THAT   THESE TOOLS 
HAVE.
SO THE   FIRST ONE IS RANDOM, 
RIGHT?
  SO HERE IT'S JUST LIKE   
ROLLING THE
 DICE AND PICKING   A RANDOM 
NUMBER.
SO THESE   TOOLS, THE TOOLS IN 
THIS
   CATEGORY, MONKEY AND   
DYNODROID,
 THEY RANDOMLY   SELECT EVENTS 
AND
 THROW IT AT   THE APP.  SO THE 
GOOD
 PART   ABOUT THIS IS THAT YOU 
CAN
 DO   THIS EFFICIENTLY, RIGHT?  
YOU
   CAN RANDOMLY PICK SO MANY   
EVENTS
 AND YOU THROW IT AT   THE APP. 
HOWEVER, -- AND ALSO IT MAKES   
IT
 VERY SUITABLE FOR STRESS   TEST
ING
 BECAUSE YOU CAN SEE   HOW WELL 
YOUR
 APP BEHAVES   WHEN SO MANY 
EVENTS
 ARE   THROWN AT IT, RIGHT? 
HOWEVER, THE PROBLEM WITH   SUCH
 TECHNIQUES
 IS THAT THEY   ARE HARDLY 
SPECIFIC.
YOU CAN   HARDLY TELL MONKEY, 
MAKE
 MY   APP GO TO THIS PARTICULAR 
  ACTIVITY
 OR THIS PARTICULAR   STATE, 
RIGHT?

SPECIFIC.
THEY'RE NOTING A NOT TICK --   
THEY
 ARE AGNOSTIC OF THE   BEHAVIOR,
 SO
 IF YOU HAVE   ALREADY COVERED 
SOME
   FUNCTIONALITY, YOU WILL --   
THE
 TOOLS DON'T CONSIDER THAT   AND
 THEY
 MIGHT HAVE LATENCY   IN THE 
EVENS
 THAT THEY SUPPLY  SUPPLY.  THEY
 MIGHT
 BE   TESTING THE SAME THING 
AGAIN
   AND AGAIN. 
AND, FINALLY, THESE TOOLS   HAVE
 NO
 STOPPING CRITERION.    THEY 
DON'T
 KNOW IF THEY HAVE   TESTED 
ENOUGH.
AS I HAVE   SHOWN IN MONKEY'S 
CASE,
 YOU   GIVE IT NUMBER OF EVENTS 
TO
   FIRE.  OTHER APPROACHES COULD
   BE
 TO HAVE A TIMEOUT, LIKE   LET'S
 SAY
 I TEST MY APP FOR   AN HOUR AND
 TELL
 ME ALL YOU   FOUND, RIGHT? 
SO THIS IS ABOUT THE RANDOM   
EXPLORATION
 STRATEGY.  NOW   LET ME TALK 
ABOUT
 THE SECOND   STRATEGY WHICH IS 
THE
 MODEL-  MODEL-BASED EXPLORATION
   STRATEGY.
THESE TOOLS, WHAT   THEY WILL DO
 IS
 AS THEY ARE   EXPLOREING YOUR 
APPLICATION,
   THEY WILL BUILD A MODEL OF   
THE
 APPLICATION, RIGHT?  AND   THIS
 MODEL
 IS TYPICALLY GUI   BASED OR GUI
 BASED
 MODEL   WHICH CAN BE AN EXAMPLE
 OF
   THIS MODEL IS SHOWN ON THE   
RIGHT-HAND
 SIDE FOR THE   DIALER 
APPLICATION.
SO THIS   IS A GRAPH-BASED MODEL
 WHERE
   THE STATES ARE DIFFERENT GUI 
  SCREENS
 AND THE EDGES ARE   ACTIONS YOU
 DO
 TO GO INTO   ANOTHER STATE OR 
SCREEN,
   RIGHT? 
SO THE TOOLS IN THIS CATEGORY   
ARE
 A3E AND SWIFTHAND AND GUI  
GUIRIPER
 AND PUMA AND ORBIT.    THESE 
ARE MORE
 EFFECTIVE   BECAUSE YOU KNOW 
WHAT
 THEY   ARE TESTING AND THESE 
TOOLS
   ARE ALSO LESS REDUNDANT   
BECAUSE
 ONCE THEY KNOW I HAVE   REACHED
DED
 THIS ACTIVITY AND   I HAVE SEEN
 IT
 BEFORE, I   DON'T HAVE TO TEST 
IT
 AGAIN.    SO THEY ARE LESS 
REDUNDANT
   THAN RANDOM TOOLS. 
HOWEVER, THESE TOOLS ONLY   
CONSIDER
 THE GUI STATE SPACE.    THEY 
DON'T
 KNOW WHAT'S GOING   ON BEHIND 
THE
 GUI.  SO THEY   CANNOT MODEL 
THEM.
THEY   CURRENTLY DON'T MODEL 
THEM IN
   THE MODEL. 
NOW, LET'S LOOK AT THE THIRD   
CATEGORY
 WHICH IS A   SYSTEMATIC 
EXPLORATION
   STRATEGY.  SO THESE TOOLS,   
WHAT
 THEY DO IS THEY USE   
SOPHISTICATED
 TECHNIQUES LIKE   ACT EXECUTION
 TO
 COUGH THE   STATE SPACE OF THE 
  APPLICATION.
SO THE TOOL   TOOLS IN THIS 
CATEGORY
 ACTEVE   AND EVO DROID.  WHAT 
IT MEANS
   IS THAT GENERALLY IT COLLECTS
   CONSTRAINTS
 FROM WITHIN THE   APPLICATION 
WHEN
 IT'S   EXECUTING.  FOR EXAMPLE,
 ON
   THE RIGHT-HAND SIDE YOU CAN  
 SEE
 A CONSTRAINT WHICH IS THE   ON 
THE
 X AND Y COORDINATE   THAT THE 
TOOL
 HAS TO CLICK.    ONCE IT GETS 
THIS
 CONSTRAINT,   IT CAN PASS IT TO
 A
 RESOLVEER   AND GET SOLUTION 
FOR A
   CONSTRAINT.  ONCE HAVE YOU   
TESTING
 THIS HAD PART YOU CAN   FLIP 
THIS
 CONDITION TO GET   OTHER PARTS 
AND
 YOU CAN TEST   OTHER PARTS, 
RIGHT?
SO THIS IS ONE WAY THESE   TOOLS
 OPERATE
 AND THE GOOD   THING ABOUT 
THESE TOOLS
 IS   THAT THEY CAN 
SYSTEMATICALLY
   EXPLORE, RIGHT?, MORE THAN --
   THEY
 CAN DIRECT THE TESTING   
TOWARDS ONE
 PARTICULAR PART,   RIGHT? 
HOWEVER, BECAUSE IN THESE   
TECHNIQUES
 ARE HEAVY WEIGHT,   THEY ARE 
LESS
 SCALEABLE THAN   RANDOM. 
SO THESE WERE THE THREE   
DIFFERENT
 EXPLORATION   STRATEGYIES.  AND
 WE
 CONSIDER  CONSIDERED A SUBSET 
OF THE
   TOOLS BECAUSE THE OTHER TOOLS
  TOOLS,
 THEY WERE NOT   AVAILABLE.  
THEY WERE
 ONLY IN   A RESEARCH PAPER BUT 
THEY
   WERE NOT OPEN SOURCE OR   
AVAILABLE
 FOR TESTING.  AND   SOME OF THE
 TOOLS
 WERE   FOCUSED ONLY ON TESTING 
OF
   VERY SPECIFIC PART AND THEY  
 ARE
 NOT GENERATETIVE ENOUGH.    AS 
I SHOW
 IN THIS TABLE,   THESE ARE 
SEVEN TOOLS.
  MONKEY -- WELL IS FROM GOOGLE 
 GOOGLE.
THE OTHER TOOLS ARE   ACADEMIC 
TOOLS.
ANDREW KNODT   EVE, DINEDROID, A
3E,
   SWIFTHAND, GUIRIPER AND PUMA.
  IF DOES IT MODIFY THE APP OR  
 THE
 PLATFORM?  AND AS WE CAN   SEE,
 MONKEY
 DOES NOT AND PUMA   WHICH IS 
THE LAST
 ONE DOES   NOT MODIFY ANYTHING.
  PUMA
   USES THE ACCESSIBILITY API   
AND
 THROUGH THAT IT CAN KNOW   THE 
STATUS
 OF YOUR APP. 
WHEREAS, ANDREW KNODT EVE   
MODIFYIES
 BOTH   MODIFY ACTEVE TO GET   
CONSTRAINTS.
DYNODROID   MODIFYIES THE 
PLATFORM
 WHEREAS   THE OTHER THREE TOOLS
 MODIFY
   THE APP. 
AS FAR AS THE NEXT COLUMN   SHOW
S,
 WHAT ARE THE EVENTS   THAT THE 
APP
 SUPPORTS OR THE   TOOL SUPPORTS
, RIGHT?
SO ALL   THE TOOLS SUPPORT UI 
EVENTS.
  THEY CAN INTERACT WITH THE   
APPLICATION
 THROUGH THE GUI,   RIGHT?  
WHEREAS
 ONLY TWO   TOOLS, ACTHEAVE AND 
DINE
 DYNODROID   SUPPORT SYSTEM 
EVENTS.
AS   YOU CAN SEE IN THIS, TWO   
TOOLS,
 MONKEY AND DYNODROID   ARE 
RANDOM
 TOOLS.  A3E IS   SYSTEMATIC AND
 THE
 OTHER FOUR   ARE MODEL-BASED 
TOOLS.
OUT   OF ALL THESE TOOLS ONLY 
ACT  ACTEVE
 NEEDS THE SOURCE CODE.    ALL 
THE
 OTHER TOOLS CAN   OPERATE IN A 
BLACK
 BOX   FASHION. 
NOW I HAVE INTRODUCED YOU TO   
THESE
 TOOLS, LET ME TELL YOU   ABOUT 
OUR
 EXPERIMENTS AND HOW   WE 
EVALUATEED
 THESE TOOLS.  SO   BEFORE DOING
 OUR
 EXPERIMENTS,   WE HAD FOUR 
RESEARCH
 CRITERIA  CRITERIA.  THE FIRST 
ONE
 WAS   HOW EASY IS THE TOOL TO 
SET
   UP AND USE, RIGHT?  AND THE  
 SECOND
 CRITERIA WAS WHAT ARE   THE 
DIFFERENT
 VERSIONS OF THE   ANDROID 
FRAMEWORK
 THAT THESE   TOOLS SUPPORT?  
THE THIRD
 ONE   WAS:  HOW MUCH COVERAGE 
CAN
   THESE TOOLS ACHIEVE ON   
GENERAL
 SUBJECTS?  AND THE   FOURTH WAS
 WHAT
 IS THE FAULT   DETECTION 
ABILITY OR
 CAN   THESE TOOLS REVEALS 
FAILURES
   IN APPLICATIONS AUTOMATICALLY
  AUTOMATICALLY?
SO FOR OUR EXPERIMENTS WE   USED
 68
 OPEN SOURCE SUBJECTS.    ALL OF
 THESE
 WERE USED IN   SOME OR THE 
OTHER TOOLS
 ON   EVALUATION.  BUT WE 
CONSIDER
  CONSIDERED AN UNION AND EVEN  
 MORE
 SUBJECTS.  AND AS YOU   CAN SEE
 THIS
 SHOWS THE   DISTRIBUTION OF THE
 SUBJECTS
   AND THE CATEGORYIES FROM PLAY
   STORE.

 THEM
 ON A LINUX DEB YEN DEBIAN   
HOST.
WE USED VIRTUALIZATION   
TECHNOLOGY.
WE USED VIRTUAL   BOX AND 
VAGRANT TO
 CONTROL   THE VIRTUAL BOX.  ON 
TOP
 OF   THIS WE HAD UBUNTU GUEST 
AND
   ANDROID EMULATORS.  WE CHOSE 
  THREE
 VERSIONS OF THE ANDROID   
EMULATOR,
 2.3, 4.1 AND 4.4.    THIS WAS 
BECAUSE
 SOME TOOLS   WERE SPECIFIC -- 
YOU
 WANTED   SPECIFIC VERSIONS OF 
THE
   ANDROID EMULATOR.  AND KIT   
KAT
 WAS THE LATEST WHEN WE   DID 
THIS
 EXPERIMENT. 
SO WHAT WE DID WAS ON THE UBU  
UBUNTU
 GUEST, WE REMOVEED ANY   
TIME-OUT
 TOOLS THEY HAD SO WE   WANTED 
TO RUN
 ALL THE TOOLS   FOR A SPECIFIC 
TIME.
AND WE   USED THEIR DEFAULT   
CONFIGURATION
 WHICH MEANS   THAT WE DID NOT 
TUNE
 ANY   SPECIFIC TOOL TO AVOID 
BIAS.

HAVE
 SHOWN YOU OUR EXPERIMENT  
EXPERIMENTAL
 SETUP, LET ME   SHOW YOU HOW WE
 DID
 THIS   EXPERIMENT.  WHAT WE DID
 IS
   WE TOOK EACH TOOL AND FOR   
EACH
 BENCHMARK WE RAN IT FOR   ONE 
HOUR.
THEN SINCE THERE   CAN BE NON-
(INDISCERNIBLE)
   WHILE RUNNING THE ANDROID SDK
  SDK,
 THINGS CAN CRASH, THINGS   
CANNOT
 BEHAVE IN A   RUDIMENTARY 
FASHION,
 TO   ACCOUNT FOR THESE THINGS 
WE 
  RAN THESE EXPERIMENTS TEN   
TIMES
 AND IGNOREED ANYTHING   THAT 
WAS OUTSIDE
 THE STUD   RATE. STANDARD   
DEVIATION
 RATE AND WE COLLECT  COLLECTED 
REPORTS.
FOR THE   RESULTS WE COLLECTED 
TWO
   THINGS.  THE FIRST HUNDRED   
WAS
 EVERY FIVE MINUTES WE   COLLECT
ED
 THE COVERAGE REPORT  REPORT, 
HOW MUCH --
 DID THE   COVERAGE REPORT OVER 
TIME.
  THAT'S WHAT WE COLLECTED. 
AND WE ALSO COLLECTED THE LOG  
LOGCAT
 OR THE LOGS FROM THE   DEVICE 
FROM
 WHICH WE EXTRACT  EXTRACTED 
FAILURES.
SO   SPECIFICALLY WHAT WE DID 
WAS 
  WE USE THE DEFAULT EMA TOOL.  
  EMA,
 IF YOU KNOW, IT DOES NOT   GIVE
 YOU
 STATEMENT-BY-  
STATEMENT-BY-STATEMENT
   COVERAGE INFORMATION BY   
DEFAULT.
SO IT'S PRESENTED   IN THE HTML 
REPORTS
 SO WE   EXTRACTED THIS 
INFORMATION
   FROM THE HTML REPORTS. 
AND FOR LOGCAT, WHAT WE DID   IS
 WE
 WROTE A CUSTOM PARSEER   WHICH 
EXTRACTED
 UNIQUE STACK   TRACES.  WE WANT
ED
 TO HAVE   UNIQUE STACK TRACES 
TO FIND
   DIFFERENT FAILURES AND WE   
VERIFYIED
 THESE MANUALLY TO   MAKE SURE 
THAT
 OUR PARSEING   LOGIC WAS 
CORRECT.
SO NOW LET ME SHOW YOU THE   
RESULTS,
 RIGHT?  SO FOR THE   FIRST 
RESEARCH
 CRITERIA, EASE   OF USE AND 
ANDROID
   COMPATIBILITY, WE MANUALLY   
SET
 UP THESE TOOLS IN OUR   
INFRASTRUCTURE
 AND EVALUATEED   THEM.  SO AS 
YOU
 CAN SEE, TWO   TOOLS, MONKEY 
AND DYNODROID,
   REQUIRED NO EFFORT.  THAT WAS
   BECAUSE
 MONKEY COMES AS A   PART OF 
ANDROID
 SDK.  WE DID   NOT HAVE TO DO 
ANYTHING,
   RIGHT? 
IN IN THE CASE OF DYNODROID,   
THE
 AUTHORS ACTUALLY RELEASEED   A 
VM
 SO IT WAS VERY VIRTUAL MACHINE 
SO
 IT WAS   HE IS TO RECREATE 
THEIR 
  EXPERIMENTS AND EASILY USE   
THE TOOL.
FOR TWO TOOLS, A3E AND PUMA,   
WE HAD
 TO SPEND A COUPLE OF   DAYS TO 
FIX
 MINEOR BUGS AND WE   GOT THEM 
RUNNING.
FOR THREE   OTHER TOOLS, IT TOOK
 US
 WEEKS   TO INTERACT WITH THE   
DEVELOPER
 BECAUSE THESE TOOLS   WERE NOT 
MAINTAINED
 ANYMORE   BUT WE FINALLY GOT 
THEM
   RUNNING. 
AS WE CAN SEE ON THE THIRD   
COLUMN,
 ACTEVE AND DYNODROID,   BOTH OF
 THEM
 WERE MODIFYIED   THE FRAMEWORK.
  SO
 THEY HAVE   A DEPENDENCY ON THE
 FRAMEWORK
   VERSION AND THE VERSION THEY 
  PROVIDE
 ONLY WORKS FOR   ANDROID 2.3, 
GINGERBREAD.
SWIFTHAND SUPPORTS ANDROID   4.1
 MUST
 BECAUSE THAT'S WHEN   IT WAS 
BUILT.
AND PUMA   SUPPORTS ANDROID 4.3 
PLUS
   BECAUSE IT USES THE   
ACCESSIBILITY
 API WHICH WAS   MAJORLY ENHANCE
ED
 IN 4.3.  AND   THREE TOOLS, 
MONKEY,
 A 3, E   AND PUMA CAN WORK ON 
ANY
   VERSION OF ANDROID. 
SO NOW LET'S GET TO THE   
COVERAGE
 RESULTS.  SO THIS   GRAPH SHOWS
 YOU
 THE COVERAGE   COVERAGE -- THE 
DISTRIBUTION
   OF COVERAGE FALL ACROSS ALL  
 THE
 DIFFERENT APPS FOR ALL   THE 
DIFFERENT
 TOOLS.  SO AS   YOU CAN SEE IN 
THIS
 GRAPH,   FOR SOME APPLICATIONS,
 MOST
   OF THESE TOOLS WERE ABLE TO  
 GET
 HIGH COVERAGE.  BUT THE   
MEDIAN IS
 VERY DIFFERENT,   RIGHT?  SO, 
FOR
EXAMPLE, BOTH   MONKEY AND 
DYNODROID
 HAVE   HIGH MEDIAN VALUES.  THE
 LAST
   THREE TOOLS HAVE VERY LOW   
MEDIAN
 VALUES. 
LET ME SHOW YOU THE NEXT   
RESULT WHICH
 SHOWS YOU THE   PROGRESS OF 
COVERAGE
 OVER   TIME.  SO THIS GRAPH 
SHOWS
   YOU HOW THE COVERAGE IMPROVE
ED 
  OVER TIME.  SO AS YOU CAN SEE 
 SEE,
 IN THE FIRST FIVE   MINUTES, 
ALL THE
 TOOLS WERE   ABOUT TO -- 
QUICKLY GET
   ALMOST EITHER MAX COVERAGE.  
  40%
 COVERAGE.  SO THIS SHOWS   THAT
 EVEN
 IF WE HAD RUN THIS   EXPERIMENT
 FOR
 ANOTHER HOUR,   IT WOULD HAVE 
STILL
 BEEN FLAT  FLAT, RIGHT?  SO IT 
WOULDN'T
   HAVE IMPROVEED THE RESULTS   
DRASTICALLY.

 PINK
 LINE WHICH IS THE   GUIRIPER 
TOOL.
WHAT THAT   TOOL PARTICULARLY 
DOES
 IS   CREATES SNAPSHOTS AT   
INTERMEDIATE
 STEPS AND RE  RESTARTS THE 
APPLICATION
 FROM   THOSE SNAPSHOTS.  THAT'S
 WHY
   BECAUSE OF THIS CONTINUEOUS 
RE  RESTART
 IT TAKES A LONG TIME   FOR THAT
 TOOL
 TO REACH ITS   MAX COVERAGE. 
NOW LET ME SHOW YOU THE NEXT   
RESULT.
SO THIS SHOWS THE   MEAN OF 
COVERAGE
 ACROSS ALL   THE DIFFERENT 
TOOLS.
SO AS   YOU CAN SEE, FOR SOME 
APPS
   ALL TOOLS COULD GET 80% OR 90
  90%
 COVERAGE.  WHEREAS FOR   SOME 
APPS,
 THEY GOT REALLY   LESS COVERAGE
.
MOST OF THE   APPS WERE IN THE 
MIDDLE,
   RIGHT?  SO WE WANTED TO   
UNDERSTAND
 WHY.  AND WE SAW   THAT ON THE 
RIGHT
 HAND OF THE   SPECTRUM LIEED 
VERY
 SIMPLE   APPS.  SOME OF THESE 
WERE
   SAMPLES FROM GOOGLE AND THEY 
  HAD
 A VERY LIMITED STATE   SPACE.  
ALL
 THE TOOLS COULD   GET DECENTLY 
HIGH
 COVERAGE ON   THEM. 
ON THE LEFT SIDE OF THE   
SPECTRUM
 WERE TOOLS -- WERE   APPS WHICH
 REQUIRED --
 FOR   WHICH NUN OF THESE NONE 
OF THESE
 TOOLS WAS   ABLE TO COVER STATE
 SPACE.
  WE FOUND THESE APPS REQUIRED  
 A LOT
 OF MANUAL CONFIGURATION  
CONFIGURATION.
FOR EXAMPLE,   THE FIRST ICON 
THERE
 PRESENTS   K9MAIL, IT'S AN 
EMAIL CLIENT.
  IT REQUIRES TO YOU SET UP AN  
 EMAIL
 SERVEER, SET UP THAT   
CONFIGURATION,
 RIGHT?, AND FOR   OUR 
EXPERIMENTS
 IT WAS NOT   POSSIBLE BECAUSE 
IT'S
   EXTERNAL DEPENDENCY THAT WE  
 WERE
 TO RELEASE IT AFTER   EVERY 
EXPERIMENT.
BUT WE FOUND THAT THIS WAS A   
GREAT
 LEARNING THAT FOR SUCH   TOOLS 
IT
 IS HARDER TO TEST   THEM BY ANY
 OF
 THESE   AUTOMATED ROBOTTING 
TESTING
   TOOLS. 
SO NOW LET ME SHOW YOU   RESULTS
 FROM
 THE FAULT   DETECTION ABILITY. 
 SO
 HERE   WHAT WE DID WAS WE 
COUNTED
   THE DIFFERENT FAILURES THAT  
 WERE
 INVOKEED BY THESE TOOLS,   
RIGHT?
AND AS YOU CAN SEE,   THE 
FAILURES
 ARE COLORED   WHICH MEANS -- 
WHICH
 SHOWS   THE DIFFERENT PACKAGES 
THEY
   BELONG TO.  FOR EXAMPLE, THE 
  BLUE
 COLOR REPRESENTS THE   JAVA.LAN
G.
AND ONE EXCEPTION   IN THAT 
PACKAGE
 IS THE NULL   POINTER EXCEPTION
, RIGHT?
SO   AS YOU CAN SEE, IN THE CASE
   OF
 MONKEY, IT COULD GET A LOT   
MORE
 JAVA.LANG EXCEPTIONS   THAN 
OTHER
 TOOLS.  WHEREAS,   FOR A TOOL 
LIKE
 PUMA, IT GOT   JAVA.ION, JAVA.L
ANG.
AND THE PINK COLOR EXCEPTIONS   
ARE
 THE CUSTOM EXCEPTIONS   WHICH 
WERE
 DEFINED IN THE APP   ITSELF AND
 ONLY
 TWO TOOLS   WHICH IS MONKEY AND
 SWIFTHAND
   WOULD REVEAL THOSE EXCEPTIONS
  EXCEPTIONS.

THESE
 TOOLS PAIR WISE WHICH   MEANS 
EACH
 PAIR OF THESE   TOOLS.  THE 
NEXT GRAPHIC
 IS   GOING TO SHOW YOU THAT. 
SO IN THIS CHART, ABOVE THE   
DIAGONAL,
 YOU SEE THE   COVERAGE RESULTS 
FOR
 EVERY   PAIR OF TOOLS.  BELOW 
THE
   DIAGONAL, YOU SEE THE FAILURE
   RESULTS
 FOR EVERY PAIR OF   TOOLS.  LET
 ME
 EXPLAIN THIS   IN A LITTLE BIT 
MORE
 DETAIL. 
SO LET'S LOOK AT COVERAGE.    SO
 HERE
 YOU CAN SEE THAT TWO   TOOLS, 
MONKEY
 AND DYNODROID,   THEY HAD 43% 
OF STATEMENTS
   WERE COVERED BY BOTH OF THESE
   TOOLS,
 RIGHT?  WHEREAS, 5% OF   
STATEMENTS
 IN THE SUBJECT   APPLICATIONS 
WERE
 ONLY COVER  COVERED BY MONKEY 
AND
 8% WERE   ONLY COVERED BY 
DYNODROID.
SIMILARLY FOR THE FAILURES,   AS
 YOU
 CAN SEE, 6 EXCEPTIONS   OR SIX 
FAILURES
 WERE COMMON   BETWEEN GUIRIPPER
 AND
 A3E   TOOLS WHICH THREE WERE 
INVOKE
  INVOKED BY GUIRIPPER AND 20   
WERE
 INVOKEED BY A3E.  NOW I   HAVE 
EXPLAINED
 YOU THIS, YOU   CAN SEE THE 
OVERALL
 GRAPH,   MANY THIS THE 
STATEMENT 
  COVERAGE WE STILL HAVE --   
THERE'S
 A LOT IN COMMON   BETWEEN THE 
TOOLS,
 RIGHT?    BUT THERE IS A LOT 
MORE
 THAT   NEEDS TO BE COVERED, 
RIGHT?
  MOST OF THESE TOOLS JUST   
REACH 50%.

CAN
 SEE, THERE'S VERY LESS   COMMON
 BETWEEN
 THE TOOLS.  SO   YOU NEED MORE 
THAN
 ONE TOOL   TO EXPOSE THOSE 
DIFFERENT
   FAILURES, RIGHT?

THAT
 RANDOM APPROACHES SEEM   TO BE 
DOING
 THEIR JOB, RIGHT?    RANDOM 
NUMBER
 OF APPROACHES   SEEM TO BE 
EFFECTIVE
 IN THIS   CONTEXT, DYNODROID 
AND MONKEY
   ARE BOTH DOING WELL, RIGHT? 
NOW LET ME NOW PRESENT YOU   OUR
 FINDINGS
 WHICH I'LL SPLIT   IN TWO 
DIFFERENT
 CATEGORYIES.    FIRST IS BEST 
PRACTICES
 THAT   WE SAW IN SOME TOOLS 
WHICH
   MADE THEM STAND OUT AND LIMIT
  LIMITATION
 THAT IS WE SAW IN   TOOLS THAT 
NONE
 OF THE TOOLS   IMPLEMENTED 
THESE PRACTICES,
   RIGHT? 
 SO LET'S
 TALK ABOUT BEST   PRACTICES. 
SO THE FIRST THING WAS, WAS THAT

THEY 
  DID WAS THEY INVOKED -- THEY  
 SENT
 SYSTEM EVENTS; RIGHT?    WHICH 
CAN --
 FOR EXAMPLE, SMS.    SO IF YOUR
 APP
 IS LISTENING FOR   SMSs, YOU 
WOULDN'T --
 ANY   FAILURES IN THAT PART OF 
CODE,
   UNLESS YOU SENT AN EVENT.  SO
   THIS
 WAS  A VERY GOOD FEATURE OF   
THOSE
 TOOLS. 
THEN, AS I MENTIONED TO YOU, THE
  TOOL (INDISCERNIBLE) GUI TOOK 
A LONG
 TIME TO GET   ITS MAX COVERAGE.
  SO
 THEY   SHOULD MINIMIZE THE RE
STARTS
 IN   THE APPLICATION THAT THEY 
HAVE.

FOR,
 YOU KNOW, ROBOTIC CRAWLERS.    

   STUCK
 WHENEVER THEY SEE A SCREEN   
LIKE
 THIS.  BECAUSE A ROBOT WILL   
NOT
 KNOW WHAT TO ENTER HERE;   
RIGHT?
SO SPECIFIC TOOLS LIKE GUI   
RIPPER
 AND DYNODROID, WHAT THEY   DID 
WAS
 THEY ALLOWED TO -- IN   THE 
CONFIGURATION,
 YOU COULD   SPECIFY THE 
DIFFERENT,
 YOU KNOW,   USER MODEL/PASSWORD
 PAIRS
 PAIR   USER NAME/PASSWORD PAIRS
 THAT
   THE ROBOT COULD USE AND THEN 
GET
   PAST SUCH SCREENS. 
THEN AN APPLICATION -- THE   
BEHAVIOR
 IS DEPENDENT ON THE   START 
STATE.
FOR EXAMPLE, FOR   THE MAIL 
CLIENT,
 IF THERE IS NO   EMAIL MESSAGES
 IN
 ITS CONTENT   PROVIDER, IT WILL
 NOT,
 YOU KNOW,   EXPOSE ANY BEHAVIOR
; RIGHT?
SO   TOOLS LIKE GUIRIPPER 
ALLOWED THE
   SPECIFICATION OF DIFFERENT   
STARTING
 STATES BY LOADING THE   APP IN 
THAT
 PARTICULAR STARTING   STATE, 
RIGHT,
 AND LETTING THE   TOOL RUN 
AFTER THAT.
 AND THE FINAL ONE IS THAT IN   
OUR
 EXPERIMENT INFRASTRUCTURE,   WE
 USE
 VIRTUAL MACHINES, SO WE   COULD
 CLEAR
 EVERYTHING AS AN   EXPERIMENT. 
 BUT
 SOME OF THESE   TOOLS WHAT THEY
 ALLOW
 FOR IS A   PARTIAL CLEANUP OF 
INSTALLING
   THE APP AND INSTALLING THE 
DATA.
  SO WE THOUGHT THAT WAS ALSO A 
  VERY
 GOOD FEATURE IN THESE TOOLS  
TOOLS.

KNOW,
 SOME LIMITATIONS OR FUTURE   
WORK
 THAT THESE TOOLS NEED TO   
IMPROVE
 ON. 
SO THE FIRST ONE IS RE  
REPRODUCIBILITY;
 RIGHT?  SO A   ROBOT MIGHT MAKE
 AN
 APPLICATION   CRAR, BUT IT'S 
VERY
 HARD TO   ACTUALLY LOOK AT THE 
ROBOT'S
 LOG   AND TO FIGURE OUT WHAT 
DID IT
 DO   TO, YOU KNOW, CRASH THE   
APPLICATION;
 RIGHT? 
WE BELIEVE THAT SUCH THINGS   
SHOULD
 BE A PART OF THE TOOLS   OUTPUT
; RIGHT?
IT SHOULD GIVE   YOU A TEST CASE
, IDEALLY,
 THAT   YOU CAN REPRODUCE THAT 
TYPE
 OF   BUG .  AND WE THOUGHT NONE
 OF
   THE TOOLS HAD THIS. 
THE NEXT THING WAS, WHEN YOU'RE 
  TESTING,
 YOU ALWAYS TEST IN A   HERMETIC
 ENVIRONMENT.
AND NONE   OF THESE TOOLS 
ALLOWED FOR
 YOU   TO SPECIFY MOCKS.  AND 
THEY
 ALL   INTERACTED WITH THE REAL 
SYSTEMS
  SYSTEMS. 
THE THIRD ONE WAS THAT WHILE   
YOU'RE
 DOING TESTING, THERE CAN   BE 
SOME
 HARMFUL OPERATIONS.    LET'S 
SAY YOU'RE
 TESTING THE   UBER APP.  IF 
YOU'RE
 NOT TESTING   IT IN THE RIGHT 
FASHION,
 YOU   ACTUALLY MIGHT ORDER A 
REAL
 CAB;   RIGHT?  OR YOU MIGHT 
SEND OUT
   REAL EMAILS OR SMSs.  YOU   
DON'T
 WANT TO DO THAT.  NONE OF   
THESE
 TOOLS ALLOWED FOR SANDBOX  
SANDBOXING
 TO A AVOID THESE SIDE   EFFECTS
. 
YOU ALL ARE FAMILIAR WITH THIS  
 PICTURE.
THERE WAS NO ROBOT OR   TOOL 
FOCUSED
 ON FINDING DEVICES   ACROSS 
DEVICES.
NONE OF THEM   WERE TARGETED TO 
CROSS-DEVICE
   TESTING. 
IN SUMMARY, WHAT I SHOWED YOU   
WAS
 I MOTIVATED THE FACT OF HOW   
YOU
 CAN USE A ROBOT TO DO THE   
TESTING
 .  I SHOWED YOU   DIFFERENT 
EXPLORATION
 STRATEGIES   THAT CURRENT TOOLS
 USE;
 RIGHT?    AND I SHOWED YOU 
DETAILS
 ABOUT   OUR EXPERIMENTS AND THE
 RESULTS.
  AND I'VE SHOWN YOU SOME BEST  
 PRACTICES
 AND LIMITATIONS IN THE   EXIST
ING
 TOOLS. 
SO ALL OUR -- THE VIRTUALIZED   
INFRASTRUCTURE
 IS AVAILABLE AT   THIS URL.  
YOU CAN
 ALSO GO TO MY   WEB SITE, 
SHAUVIK.COM,
 AND GET A   LINK TO THAT.  THAT
 VIRTUAL
   MACHINE HAS ALL THESE TOOLS 
?AWD
   ALREADY WITH ALL THE SUBJECTS
   THAT
 WE USED.  SO YOU DON'T HAVE   
TO GO
 AND BUILD THESE TOOLS FROM   
SOURCE.
YOU CAN JUST GET THIS   AND USE 
IT
 IN YOUR PROJECTS. 
AND THAT BRINGS ME TO THE END OF
  MY TALK. 
THANKS. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU.  I 
  THINK
 WE HAVE TIME FOR A FEW   
QUESTIONS.

 RECOMMENDATIONS
 FOR iOS ROBOTS  ROBOTS? 
&amp;gt;&amp;gt;Shauvik Roy Choudhary:    
THERE'S
 A TOOL CALLED UI MONKEY.    
IT'S THE
 COUNTERPART OF MONKEY   FOR iOS
.
IT USE THE   UIAUTOMATOR THAT i
OS
 HAS.  SO   YOU COULD USE THAT .
&amp;gt;&amp;gt;Yvette Nameth:  THESE TOOLS   
MAY
 BE ABLE TO FIND APP CRASHES,   
BUT
 HOW DO YOU THEN COME UP WITH   
A REPEATABLE
 SET OF STEPS THAT   CAN RE
PRODUCE
 THE PROBLEM AND   HELP FIND A 
ROOT
 CAUSE? 
&amp;gt;&amp;gt;Shauvik Roy Choudhary:  SO   
THIS
 IS THE HARD PART.  FOR   
EXAMPLE,
 IN MONKEY, YOU CAN ASK   IT TO 
BE
 VERBOSE, AND MONKEY   WILL TELL
 YOU
 IT DID THESE STEPS  STEPS; 
RIGHT?
AND THEN YOU SEE   THIS 
EXCEPTION;
 RIGHT? 
SO WHAT IT MEANS IS THAT YOU   
HAVE
 TO GO THROUGH ALL THESE   STEPS
, AND
 YOU HAVE TO FIND A   MINIMAL 
SET OF
 STEPS.  RIGHT,   YOU HAVE TO 
REDUCE
 THIS TO A   MINIMAL SET OF 
STEPS THAT
 CAN   HELP YOU, YOU KNOW, FIND 
THAT
   PROBLEM; RIGHT? 
SO THIS IS ACTUALLY A VERY HARD 
  THING.
AND WE ARE WORKING ON,   YOU 
KNOW,
 SOME OF THESE AREAS TO   
GENERATE
 TEST CASES.  BUT, YEAH,   SO 
THERE'S
 CURRENTLY NO EASY   SOLUTION 
FOR THIS.
&amp;gt;&amp;gt;Yvette Nameth:  CAN YOU   
PROPOSE
 A NEW WAY TO COMPARE THE   
QUALITY
 OF TESTS GENERATED BY   THESE 
TOOLS
 BEYOND THOSE OF   COVERAGE AND 
CRASHES?

COVERAGE
 AND CRASHES, YOU KNOW,   OF 
COURSE,
 I SHOWED IT. 
ANOTHER THING IS THAT, OKAY,   
YOUR
 TEST CASES, RIGHT, IF YOU   
HAVE --
 YOU SHOULD HAVE A   MINIMAL SET
 OF
 TEST CASES THAT   CAN GENERATE,
 YOU
KNOW, THE SAME   ERRORS; RIGHT? 
 SO
 LET'S SAY IF   YOU HAVE 100 
TEST CASES
 THAT   GIVE YOU FIVE ERRORS 
VERSUS
 YOU   HAVE FIVE TEST CASES THAT
 CAN
   GIVE YOU FIVE ERRORS.  AND 
THESE
   TESTS -- AND, OF COURSE, THE 
  SAME
 COVERAGE AS WELL.  SO   HAVING 
A MINIMAL
 SET OF TEST   CASES IS ALSO 
SOMETHING
 THAT   PEOPLE, YOU KNOW, LOOK 
OUT
 FOR,   BECAUSE THEN YOU CAN RUN
 THESE
   TEST CASES FAST INSTEAD OF   
RUNNING
 (INDISCERNIBLE) TESTS. 
&amp;gt;&amp;gt;Yvette Nameth:  COOL.  AND I  
 THINK
 THAT'S ALL WE HAVE TIME   FOR. 
SO THANK YOU VERY MUCH. 
&amp;gt;&amp;gt;Shauvik Roy Choudhary:  THANKS
  THANKS.
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  I JUST WANT TO
  MAKE ONE QUICK NOTE.  I DO SEE
   LOTS
 OF COATS ON, AND I'VE BEEN   
TOLD
 MULTIPLE TIMES IT IS COLD   IN 
HERE.
FACILITIES HAS BEEN   NOTIFIED. 
 WHAT
 THAT MEANS, I   COULD NOT KNOW 
DO
   NOT KNOW, OTHER THAN THEY 
HAVE 
  BEEN NOTIFIED. 
WITH THAT BEING SAID, WE HAVE   
ONE
 MORE TALK BEFORE OUR NEXT   
BREAK,
 WHERE YOU CAN GO WARM UP. 
AND THIS IS ALISTER SCOTT,   
TALKING
 ABOUT A VERY SENSITIVE   
SUBJECT.

HELLO, THERE. 
I'M GOING TO BE USING THE &quot;F&quot;   
WORD
 A LOT IN THIS TALK.  LIKE,   A 
LOT.
I APOLOGIZE IN ADVANCE IF I   
OFFEND.
YOU ALL KNOW THE &quot;F&quot;   WORD, 
DON'T
 YOU?  IT'S ALSO   KNOWN AS THE 
&quot;F&quot;
 BOMB.  WE TEST   ENGINEERS USE 
IT
 ALL THE TIME.    YES, THAT'S 
ONE.
FLAKY.

  KIRKLAND.
AND LIKE A LOT OF   OTHER PEOPLE
 THERE,
 I WAS VERY   SHOCKED BY THE 
LANGUAGE.
EVERY   SECOND TALK WAS DROPPING
 THE
   HIGHLY OFFENSIVE &quot;F&quot; WORD.  
OVER
   LUNCH, WE WERE JOKINGLY CALL 
IT
   FLAKY TESTCON 14.  THERE WERE
   LOTS
 OF TALKS ABOUT HOW TO   REDUCE 
IT,
 WAYS TO MINIMIZE IT,   AND WHAT
 TO
 DO WHEN YOU HAVE A   FLAKY TEST
. 
FLAKY TESTS ARE SOMETHING THAT  
 MOST
 OF US EXPERIENCE ALMOST   EVERY
 DAY
 IN OUR LIVES.  THEY   CAUSE US 
NO
 END OF DESPAIR.  AND   WE 
SHOULD BE
 AFRAID, VERY AFRAID  AFRAID. 
THE CONCEPT OF FLAKY TESTS HAS  
 THE
 POTENTIAL TO BRING OUR   
TESTING PROFESSION
 DOWN. 
THERE'S BEEN LOTS OF SOLUTIONS  
 PROPOSED
 AROUND TEST DESIGN AND   TEST 
RESILIENCE.
BUT WE   CONTINUE TO SUFFER FROM
 THIS
   PROBLEM.  THE SOLUTIONS DON'T
   WORK.
AS THE &quot;F&quot; WORD GETS DROPPED   
MORE
 AND MORE, PEOPLE START TO   
DOUBT
 WHETHER ANY TESTS ARE   
RELIABLE.
AND IF TESTING'S   WORTH IT AT 
ALL.
WHAT IF TEST  TESTERS   ARE 
FLAKY,
 LIKE LIKE THEIR   TESTS?  WE 
NEED
 TO KILL THE TERM   &quot;FLAKY.&quot;

  CONFERENCE,
 AND I WAS SITTING AT   MY DESK,
 AND
 HE OVERHEARD A   DEVELOPER DIS
MISS
 A FAILED BUILD   AS, &quot;OH, 
THAT'S JUST
 SOME FLAKY   TESTS.&quot; 
I WAS SHOCKED.  I WAS -- I WAS  
 SHOCKED
 AND OFFENDED.  THE &quot;F&quot;   WORD, 
AN
 EXCUSE TO IGNORE   TESTING.  
PEOPLE
 WERE TALKING   ABOUT OUR WORK 
AND
 NOW USING THE   &quot;F&quot; WORD. 
SO I SWORE TO MYSELF FROM THAT  
 MOMENT
 FORWARD THAT I WOULD NOT   DIS
MISS
 ANY ISSUES AS FLAKINESS.    I 
WOULD
 STOP CALLING OUR TESTS   FLAKY.
  BUT
 IF OUR TESTS AREN'T   AT FALL, 
WHAT
 IS?  OUR   APPLICATIONS. 
YOU SEE, FLAKINESS IMPLIES THAT 
  IT'S
 A TEST PROBLEM AND THAT NO   
ONE NEEDS
 TO WORRY ABOUT IT FROM   AN 
APPLICATION
 DEVELOPMENT POINT   OF VIEW.  
BUT
 WHAT IF IT'S NOT   THE TEST 
PROBLEM?
WHAT IF IT'S   OUR APPSS'S   OUR
 APP'S
 PROBLEM. 
DEVELOPERS HAVE STARTED TO USE  
 THE
 TERM&quot; &quot;FLAKY&quot; TO DESCRIBE ANY  
 USEFUL
 TEST. 
IMAGINE HOW USEFUL A FLAKY SMOKE
  ALARM WOULD BE.  IT WOULD GO 
OFF
   OFTEN.  AND PEOPLE WOULD BE  
 SAYING,
 THAT SMOKE ALARM, IT'S   JUST 
FLAKY.
LET'S JUST IGNORE   IT.  YOU MAY
 AS
 WELL NOT HAVE A   SMOKE ALARM. 
 YOU
 MAY AS WELL   IGNORE  ALL TEST
ING.
WHY HAVE   TESTERS?  WHY HAVE 
TEST
   ENGINEERS?  AND LIKE THAT, 
OUR 
  PROFESSION BECAME UNDER THREAT
. 
SO HOW DO WE GET TO THE BOTTOM  
 OF
 FLAKY? 
WELL, IMAGINE YOU HAD A TOASTER 
  THAT
 WAS SITTING DIRECTLY   
UNDERNEATH
 YOUR SMOKE DETECTOR   AND IT 
WAS ON
 A VERY HIGH   SETTING.  IS YOUR
 SMOKE
 ALARM   STILL FLAKY?  OR IS THE
 THING
   THAT YOU'RE MEASURING NOT 
QUITE
   RIGHT? 
WE NEED TO GET TO THE BOTTOM OF 
  IT.
WE NEED TO LOOK AT THE   WHOLE 
STORY
 AND STOP USING THE   &quot;F&quot; WORD. 
LET'S LOOK AT OUR APPLICATIONS.

HAPPENED,
 WE HAD ANOTHER ISSUE   WITH IN
CONSISTENT
 OR FLAKY TESTS   AT MY WORK.  
SO WE
 HAD A WHOLE   BUNCH OF ACCEPT
ANCE
 TESTS, AND   THEY GAVE US 
REALLY GOOD
   CONFIDENCE THAT OUR APP WAS  
 READY
 TO RELEASE TO PRODUCTION.    
AND WE
 DO THAT VERY FREQUENTLY.    AND
 WE'D
 NEVER RELEASE OUR APP   UNLESS 
ACCEPTANCE
 TESTS HAD PASS  PASSED. 
WE HAD ABOUT 500 TESTS, AND WE  
 RAN
 THEM IN PARALLEL IN ABOUT 50   
GROUPS,
 EACH HAVING ABOUT TEN   TESTS. 
 AND
 IT MEANT THAT THE   ENTIRE 
SUITE COULD
 RUN IN AS   LITTLE AS TEN 
MINUTES
 FOR THE   ENTIRE SUITE, WHICH 
WAS
 PRETTY   SWEET. 
AND SO WE WANTED TO GET A BUILD 
  RELEASED.
AND FIVE OF OUR 50   GROUPS 
FAILED
 ON THE FIRST RUN. 
SO WHAT WE DID WAS, WE RERAN   
THOSE
 FIVE GROUPS.  AND I THINK   
THEN ONE
 GROUP JUST FAILED.  SO   WE RE
RAN
 THAT ONE GROUP.  AND IT   PASS
ED.

RELEASED
 IT TO PRODUCTION. 
WE DIDN'T ASK WHY OUR TESTS HAD 
  FAILED
 IN THE FIRST PLACE. 
SO SHORTLY AFTER RELEASE TO   
PRODUCTION,
 WE STARTED SEEING   OUR 
CUSTOMERS
 WERE LOSING THEIR   SESSIONS 
AND CRASHING.
BUT ALL   OUR TESTS HAD PASSED. 
 WE
 HAD A   CLOSER LOOK AND FOUND 
THAT
 WE   HAD AN OBSCURE LOCATION 
BUG 
  WHERE THE DISPLAY MODE BETWEEN
   DESKTOP
 AND MOBILE WAS BEING IN  
INCORRECTLY
 CACHED AND DISPLAYED   FOR THE 
WRONG
 USER'S SESSION.    THIS WAS 
KILLING
 THE USER'S   SESSION AND IT WAS
 AFFECTING
 OUR   SALES. 
IT WASN'T IMMEDIATELY OBVIOUS,  
 AS
 IT WASN'T HAPPENING FOR EVERY  
 CUSTOMER.
IT WAS ONLY HAPPENING   FOR 
ABOUT 10%.

10%.
OUR TESTS HAD FOUND THIS   BUG, 
BUT
 WE'D COMPLETELY IGNORED   THEM.
  WE'D
 IGNORED THEM UNTIL   IT DIDN'T 
HAPPEN
 ANYMORE.  BUT   OUR TESTS KNEW 
THAT
 WE HAD AN   ISSUE. 
TRUST THE TESTS.  DON'T RERUN   
BLINDLY
 UNTIL YOU GET THE   RESPONSE 
THAT
 YOU WANT.  FIND   THE ISSUE AND
 FIX
 IT.  KILL ANY   POSSIBILITY FOR
 FLAKINESS.


AND 
  WE WERE RUNNING SOME TESTS IN 
  PARALLEL,
 BECAUSE RUNNING TESTS   IN 
PARALLEL
 IS VERY EFFICIENT   AND 
REPLICATES
 HOW OUR USERS USE   OUR SYSTEMS
. 
WE ENCOUNTERED SOME FLAKINESS OR

RESULTS.
OUR APP HAPPENED TO HAVE A   
FEATURE
 THAT WE DIDN'T KNOW   ABOUT 
WHERE
 SUBSEQUENT LOGIN TO   THE FIRST
 WOULD
 DESTROY THE   ORIGINAL SESSION 
IN
 SOME CASES.    SO IF TWO OF OUR
 TESTS
 HAPPENED   TO RUN IN PARALLEL 
AT EXACTLY
   THE SAME TIME, THE SECOND 
TEST 
  WOULD MAKE THE FIRST ONE FAIL.
SPENDING TIME TRYING TO MAKE OUR
  TESTS RESILIENT OR RELIABLE   
WOULD
 BE FRUITLESS.  IT WAS   BUILT 
INTO
 OUR APPLICATION   DESIGN.  OUR 
APP
 SHOULD HAVE   BEEN TESTABLE, 
AND IT
 SHOULDN'T   HAVE KILLED THE 
SUBSEQUENT
   SESSIONS.  THAT WASN'T MEANT 
TO
   HAPPEN. 
SO RATHER THAN GOING ON A   
FLAKINESS
 HUNT FOR OUR FLAKY   TEST, WE 
REFUSED
 TO BELIEVE IN   IT, AND WE 
DISCOVERED
   APPLICATION QUIRKS THAT WERE 
  DISGUISED
 AS TEST FLAKINESS. 
OUR FAITH IN TESTING WAS RE  
RESTORED.
OUR TESTS HAD   REVEALED THE 
TRUE STORY.
THANK   GOODNESS IT WASN'T A 
FLAKY
   MONSTER UNDER OUR BED.  WE 
HAD 
  SHOWN OUR TORCH, OUR TRUSTED  
 TEST
 ON IT, AND REALIZED IT WAS   
JUST
 SOME DUSTY BITS OF OUR   
APPLICATION
 DESIGN.  THERE WAS   NOTHING TO
 BE
 AFRAID OF.

  WEB
 APP THAT I WAS WORKING ON,   
AND IT
 USED DIALOGUES MON   DIALOGUES,
 WITH
 POPUPS AND   ASYNCHRONOUS 
SERVER CALLS
   EVERYWHERE.  OUR TESTS WOULD 
DIS
  DISMISS A DIALOGUE, AND IT 
WOULD
   MIRACULOUSLY REOPEN WHEN A   
CALLBACK
 WAS LATER RECEIVED.  IT   WOULD
 MAKE
 OUR TESTS VERY FLAKY. 
WHAT WE COULD HAVE DONE WAS MAKE
  OUR TEST RESILIENT AS TO 
ACCEPT 
  ACCEPT -- AS TO EXPECT A 
RANDOM 
  POPUP AT ANY MOMENT AND 
DISMISS.
   IT.  AND I HAVE SEEN THAT 
DONE.
  BUT WHY SHOULD WE WRITE SUCH  
 COMPLICATED
 TESTS?  WHAT'S THE   REAL ISSUE
? 
WHY SHOULD WE HAVE HIGHLY   
RESILIENT
 TESTS FOR SUCH A CLUNK  CLUNKY 
APPLICATION?
  SHOULDN'T   WE LOOK AT THE 
REASON
 BEHIND THE   FLAKY   FLAKE? 
WE DECIDED TO WORK AS A TEAM TO 
  MAKE
 OUR APP MORE TESTABLE, TO   
SHOW SPINNERS
 FOR AJAX CALLS, TO   MAKE 
DIALOGUES
 NOT MIRACULOUSLY   REAPPEAR, 
AND TO
 PROVIDE HOOKS   SAYING YOU 
COULD KNOW
 WHEN   ASYNCHRONOUS STUFF WAS 
HAPPENING
   VIA JAVASCRIPT. 
WE DID THIS.  AND GUESS WHAT?   
 OUR
 TESTS WERE SUDDENLY   
CONSISTENTLY
 PASSING. 
FLAKINESS ZERO.  APPLICATION   
TESTABILITY,
 ONE
  ONE. 
I WORKED ON ANOTHER APP.  AND IT

  MULTISTEP
 FLOW.  AND EVERY STEP   RELIED 
ON
 SOME STATE FROM A   PREVIOUS 
STEP.
IF WE WERE TO WRITE TESTS THAT  
 INCLUDED
 EVERY STEP AND ANY   
COMBINATION OF
 STEPS, THERE   WOULD BE LOTS OF
 POSSIBILITIES
   FOR FLAKINESS AND IN  
INCONSISTENCIES.
INSTEAD, WE   CHOSE TO WRITE A 
TEST-SPECIFIC
   CONTROLLER WHICH WAS EMBEDDED
 AS
   PART OF OUR APPLICATION TO   
INSTANTLY
 DISPLAY ANY PAGE   IN   OUR APP
 WITH
 ANY STATE THAT YOU   REQUIRED. 
 SO
 THERE WAS NO   NAVIGATING OF 
PAGES
 AND NO   CONSTRAINTS AROUND 
TIME OR
 DATA. 
IF YOU CAN SET UP A SINGLE URL  
 WITH
 EVERYTHING THAT YOU NEED TO   
TEST
 ON FUNCTIONALITY, THIS   MEANS 
YOUR
 TESTS CAN BE FOCUSED   ON 
TESTING
 AND AVOIDING FLEAKS   BY AVOID 
A 
  FLAKINESS BY AVOIDING 
NAVIGATION
   AND LAYERS ARE SET UP, AND   
OPTIONS
 . 
WE BUILT TESTABILITY WELL AND   
TRULY
 INTO OUR APP.  THE   
INTEGRATION OF
 TESTING INTO   SYSTEM 
DEVELOPMENT
 SAVED US FROM   FLAKINESS AND 
COMPLICATED
 AFTER-  AFTER-THE-FACT TEST 
WRITING.

TESTABILITY-SPECIFIC
 FEATURES TO   YOUR APPS THAT 
DON'T
 SERVE A   FUNCTIONAL PURPOSE. 
I RECENTLY HAD TO GET TIRES, NEW
  TIRES ON MY CAR, AND I 
REALIZED 
  THAT A LOT OF TIRES HAVE TEST 
 TESTABILITY
 FEATURES.  THEY'RE   CALL TREAD
 INDICATORS.
THEY   DON'T SERVE ANY FUNCTION
AL 
  PURPOSE.  A TIRE DOESN'T NEED 
A 
  TREAD INDICATOR TO OPERATE.  
BUT
   IT DOES MAKE IT POSSIBLE TO  
 QUICKLY
 AND EASILY TEST THE   TREAD OF 
A TIRE
 WITHOUT ANY   COMPLICATED 
MEASUREMENT
   INSTRUMENTS. 
WHY DON'T YOU CONSIDER ADDING --

ABILITY
   FEATURES FOR YOUR APPS.

ANNOYING
 MESSAGES AND POPUPS I   SEE ON 
INTERNET
 SITES THAT ARE   USED.  THEY 
ARE PARTICULAR
 TO   SITES THAT DON'T CATER 
WELL FOR
   BROWSER NAVIGATION. 
SO TESTS FOR THESE SITES CAN BE 
  FLAKY,
 AS IT'S REALLY HARD TO   HANDLE
 THESE
 POPUPS AND TEST   AUTOMATION.  
THEY
 ALSO CAUSE A   LOT OF FEAR IN 
OUR
 USERS.  HAS   IT TAKEN MY MONEY
?
HAVE I   DOUBLE-BOOKED?  HOW 
LONG SHOULD
   I LOOK AT THIS SCREEN BEFORE 
I 
  REFRESH? 
[ LAUGHTER ]  
SO THERE'S A LOT OF USER PANIC. 
BUT WHAT IF WE BUILT OUR APPS SO

PROBLEMS?
OUR TESTS WOULDN'T   NEED TO 
CATER
 FOR THEM, AND WE'D   HAVE A 
BETTER
 USER EXPERIENCE. 
HOW?  WELL, WE DESIGN AND BUILD 
  YOUR
 APP WITH TESTABILITY IN   MIND,
 AN
 INTEGRATED TEAM OF TEST  
TESTERS AND
 DEVELOPERS   THROUGHOUT THE 
WHOLE
 PROCESS IS   IDEAL.  A TESTABLE
 APP
 IS A   USABLE APP  APP.  AND 
USABLE
 APPS       AREN'T FLAKY. 
 SO YOU MIGHT BE ASKING WHAT   
CAN
 I DO TO HELP KILL FLAKY?    WE 
ALL
 HAVE A ROLL TO PLAY IN   RE
STOREING
 FAITH IN OUR   PROFESSION AND 
PUSHING
 FLAKY  FLAKINESS INTO 
EXTINCTION.
  NUMBER ONE, DON'T BLINDLY RE  
RERUN
 TESTS, IF YOU ROLL A   DICE A 
NUMBER
 OF TIMES, IT   WILL GIVE YOU 
THE NUMBER
 THAT   YOU WANT BUT IS THAT THE
 SAME
   THING THAT HAPPENS IF A REAL 
  USER
 ROLLED A DICE.  NO.    IT'S NOT
 REALISTIC.
WE NEED   TO LOOK AT WHY IT 
FAILED
 THE   FIRST TIME, WHY YOU 
DIDN'T 
  ROLL THE SIX STRAIGHT-AWAY.   
 THERE'S
 A REASON YOU DIDN'T   ROLL A 
SIX OF
 THE IT'S A DICE   AFTER ALL.  
MAYBE
 YOU NEED TO   USE A DIFFERENT 
APPROACH
 ALL   TOGETHER. 
NUMBER TWO, USE FLAKY TESTS   AS
 INSIGHTS
 INTO YOUR APPS.    FLAKY TESTS 
ARE
 NOT USELESS.    THEY'RE TELLING
 YOU
 SOMETHING  SOMETHING.  YOU JUST
 NEED
 TO   WORK OUT WHAT THAT 
SOMETHING
   IS. 
BE THE TEST WHISPERER AND DE  
DECODE
 IT.  YOU'LL BE RE  REWARDED 
WITH A
 SECRET ABOUT   YOUR APP OR AN 
AREA
 FOR   ENHANCEMENT. 
AND, NUMBER THREE, BUILD   
TESTABILITY
 INTO YOUR APPS.    FLAKYINESS 
COMES
 FROM AFTER   THE FACT TESTING. 
 WE
   ARE NOT AN AFTERTHOUGHT.    
TESTERS
 AND TEST ENGINEERS   SHOULD BE 
PART
 OF APPLICATION   DESIGN TEAMS. 
 WE
 NEED TO   CONSIDER AND BUILD 
TESTING
   AND TESTABILITY INTO OUR   
APPLICATION
 DESIGNS.    EFFICIENCY, 
EFFECTIVENESS,
   AND TESTING CONFIDENCE COMES 
  FROM
 THIS STRONG BASE
. 
I'D LIKE TO FINISH WITH A   
FINAL MESSAGE
 TO FLAKY TESTS.

PARTICULAR
 SET OF SKILLS,   SKILLS I HAVE 
ACQUIREED
 OVER A   VERY LONG TESTING 
CAREER.
  SKILLS THAT MAKE ME A   
NIGHTMARE
 FOR FLAKY TESTS   LIKE YOU.  I 
WILL
 LOOK FOR   YOU.  I WILL FIND 
YOU.
AND I   WILL KILL YOU. 
[ LAUGHTER ] 
CHEERS. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU,   A
LISTER.
YOU HAVE A LOT OF   QUESTIONS 
COMING
 YOUR WAY SO   IT'S A GOOD THING
 THAT
 WE'VE   GOT A LOT OF TIME. 
SO FIRST ONE:  ISN'T IT A   
QUESTION
 OF PROBABILITIES?  A   BUG THAT
 MANIFESTS
 IN A FLAKY   RESULT IS LESS 
LIKELY
 TO BE   SEEN IN PRODUCTION THAN
 A
   TEST THAT ALWAYS FAILS.  HOW 
  DO
 YOU CONVINCE A TEAM   MEMBERS 
THAT
 FIXING FLAKINESS   IS A 
PRIORITY IN
.
&amp;gt;&amp;gt;Alister Scott:  I GUESS   SORT
 OF
 DISAGREE BECAUSE I   HAVE SEEN 
A LOT
 OF FLAKY --   LIKE, DOING A LOT
 OF
 RESEARCH   INTO THESE FLAKY 
TESTS
 WHICH   I HAVE SORT OF 
DEMONSTRATED
   TODAY, LIKE I HAVE ACTUALLY  
 SHOWN
 THAT A LOT OF THESE   THINGS DO
 ACTUALLY
 COME   THROUGH IN PRODUCTION, 
WE 
  JUST DON'T REALIZE IT.  LIKE, 
  SO
 MY EXAMPLE OF WHERE WE HAD   A 
QUIRK
 IN OUR APPLICATION   WHERE, 
LIKE,
 MULTIPLE LOGIN  LOGINNING, THE 
SECOND
 ONE   WOULD GIVE THE FIRST, NO 
ONE
   HAD NO IDEA.  OUR FANTASTIC  
 FANTASTIC --
 OUR TEST WAS   FLAKY BECAUSE OF
 IT
 BUT IT   WAS AN APPLICATION 
ISSUE
 ALL   ALONG SO IT WAS ACTUALLY 
IN
   PRODUCTION. 
THE QUESTION'S NOT THERE   
ANYMORE.
THAT'S MY ...

CONVINCE
 THE TEAM MEMBERS   THAT FIXING 
THE
 FLAKYINESS IS   A PRIORITY IS 
THE
 OTHER PART. 
&amp;gt;&amp;gt;Alister Scott:  I THINK A   
GOOD
 WAY TO DO THAT IS TO   MAKE 
FLAKYINESS
 VERY PROMINENT   AND SO WAYS 
I'VE
 DONE THAT   BEFORE IS MAKE SURE
 THAT
   EVERYONE CAN SEE THAT WE'VE  
 GOT
 A FLAKY BUILD.  SO HAVING   
THINGS
 LIKE BUILD LOTS AND   BUILD 
MONITORS
 AND THINGS   LIKE THAT MAKING 
IT REALLY
   CLEAR OUR BUILD IS FAILING   
AND
 IT IS RED, WE CAN'T PUSH   THAT
.
AND THEN PEOPLE WILL   START SEE
ING
 THAT AND SAY,   WHY IS IT RED. 
 OKAY,
 LET'S   HAVE A LOOK INTO IT.  
AND
   THEN SORT OF DISMISSING THAT,
   HEY,
 IT SAYS FLAKY TEST AND   REALLY
 STARTING
 TO DELVE INTO   IT.  AND PEOPLE
 WILL
 SAY IT   WILL COST A LOT OF 
TIME AND
   MONEY TO DO THIS.  BUT NOT DO
  DOING
 IT IS ALSO GOING TO   COST A 
LOT OF
 TIME AND MONEY   AND PROD ISSUE
S AND
 THINGS   LIKE THAT.  SO, YEAH. 
&amp;gt;&amp;gt;Yvette Nameth:  OBVIOUS   
TEAMS FAME
 DUE TO HARDWARE, O  OS, NETWORK
 AND
 JOB MANAGE  MANAGEMENT PROBLEMS
 OFTEN
   ENOUGH THAT IT IS NOT WORTH  
 INVESTIGATING
 FLAKYINESS BELOW   A CERTAIN 
THRESHOLD.
DO YOU   AGREE WITH THIS 
STRATEGY?
&amp;gt;&amp;gt;Alister Scott:  NO.  I   THINK
 THAT --

[ APPLAUSE ] 
&amp;gt;&amp;gt;&amp;gt; YES!  YES! 
&amp;gt;&amp;gt;Alister Scott:  SO ANY ONE   
OF THOSE
 THINGS LIKE CAN   CAUSE A FLAKY
INESS
 IN OUR TEST  TEST.  SO IF YOU 
ARE
 FINDING   THOSE, WE NEED TO 
ACTUALLY
   MAKE A TESTABILITY FEATURE   
THAT
 WE CAN GET RID OF THAT   
FLAKINESS.
SO IF WE'VE GOT   LIKE -- IF 
WE'VE
 GOT AN ISSUE   WITH, LIKE, 
NETWORK,
 WE NEED   TO SAY, HEY, HOW CAN 
WE
 MAKE   OUR APP, LIKE, BETTER SO
 IT
   CAN RUN ON, LIKE, FLAKY   
NETWORKS.
OR HOW CAN WE MAKE   OUR APP 
BETTER
 WHERE IT CAN   RUN IN THE TEST 
MODE
 SO IT   DOESN'T HAVE TO USE THE
   NETWORK
 OF THE OR HOW CAN WE   IMPROVE 
OUR
 APP TO MITIGATE   ANY OF THESE,
 LIKE,
 POTENTIAL   REASONS FOR 
FLAKINESS?
IF   YOU CAN -- LIKE AN EXAMPLE 
  LIKE
 WE HAD ALL THESE ISSUES   
AROUND FLAKINESS
 AROUND TIME,   HOW ABOUT WE 
JUST,
 LIKE, MAKE   OUR APPS SO THAT 
WE'VE
 GOT A   MODE WHERE IT DOESN'T 
SORT
 OF   WORRY ABOUT TIME.  WE CAN 
  TEST
 EVERYTHING ELSE AND THEN   WE 
CAN
 TEST TIME SEPARATELY.    
INSTEAD OF
 TIME AFFECTING   EVERY SINGLE 
TEST
 THAT WE'VE   GOT, WE DIDN'T 
WORRY
 ABOUT   TIME AND THEN WE COULD 
JUST
   TEST IN THIS LITTLE THING   
OVER
 HERE. 
I THINK THIS IS WORTH LOOKING   
AT
 ANY OF THESE ISSUES THAT   
PEOPLE
 SAY, HEY, THAT'S THE   REASON 
FOR
 FLAKINESS AND THEN   TRYING TO 
WORK
 OUT HOW CAN WE   USE 
TESTABILITY TO
 SOLVE   THOSE. 
&amp;gt;&amp;gt;Yvette Nameth:  THE   
CHALLENGE WITH
 FLAKY TESTS IS   THAT THEY ARE 
VERY
 DIFFICULT   TO REPRODUCE.  DO 
YOU
 HAVE A   SUGGESTION FOR PINNING
 THESE
   DOWN? 
&amp;gt;&amp;gt;Alister Scott:  THAT'S A   
VERY GOOD
 QUESTION.  WHAT   I'VE FOUND TO
 WORK
 OUT WHAT   IT IS -- BECAUSE, AS
 I
SAID,   I'VE SPENT A LOT OF TIME
   DOING
 THIS, THINGS LIKE LOG  LOGGING 
AND
 SCREEN SHOTS AND   RECORDING 
VIDEOS
 OF TESTS   RUNNING, THESE ARE 
REALLY
   GOOD THINGS.  A LOT OF CI   
TOOLS
 DO THIS ANYWAY.  BUT   THEY ARE
 REALLY
 GOOD   TECHNIQUES TO ACTUALLY, 
LIKE,
   BASICALLY, BE THAT TEST TO   
WORK
 OUT EXACTLY WHY IT'S   
HAPPENING.
OFTENTIMES, LIKE,   YOU CAN RUN 
IT
 LOCALLY IN A   DEV ENVIRONMENT 
AND
 IT PASSES   EVERY TIME AND THEN
 EVERY
   TIME YOU RUN IT IN CI BUT   
WHEN
 IT IS RUNNING IN   PARALLEL IT 
WILL
 FAIL.  SO IF   YOU CAN PUT 
THINGS
 LIKE --   TURN LOGGING ON, PUT 
IN
 DEBUG   STATEMENTS, IF YOU CAN 
  CAPTURE
 SCREEN SHOTS EVERY   TIME IT 
FAILS
 OR YOU HAVE A   MODE THAT EVERY
 TIME
 IT RUNS   IT DOES A SCREEN SHOT
 ON
   EVERYTHING IT DOES, ALL THESE
   DIFFERENT
 THINGS YOU CAN DO,   YOU CAN 
USE ALL
 THAT   INFORMATION TO REALIZE, 
HEY,
   THIS IS WHY IT'S FLAKY. 
AND THAT'S WHAT WE DID FOR,   
LIKE,
 THE ISSUE WHERE WE HAD   THE 
SUBSEQUENT
 LOG-ONS.  WE   NEED TO START 
LOOKING
 AT THE   SCREEN SHOTS AND THE 
LOGS
 TO   WORK OUT WHY IT IS EXACTLY
   FAILING.
BECAUSE EVERY TIME   WE RAN A 
TEST
 LOCALLY AS A   SINGLE TEST, IT 
WOULD
 PASS.    THERE WOULD BE NO WAY 
IT
   WOULD FAIL.  BUT WHEN WE RUN 
  IT
 IN PARALLEL, WE WOULD FAIL  
FAIL.

 ADD
 ONE THING TO THAT   BECAUSE I 
HAVE
 THE POWER OF   THE MICROPHONE. 
 I
 WOULD ALSO   SAY PRODUCTION 
MONITORING.
  SO YOU ACTUALLY REALIZE THIS  
 IS
 A REAL PROBLEM IN   PRODUCTION.
  THIS
 ISN'T JUST   A FLAKY TEST.  
ACTUALLY
 10%   OF USERS COULD BE 
CORRELATED
   TO THIS THING IN PRODUCTION. 
&amp;gt;&amp;gt;Alister Scott:  EXACTLY,   
YEAH.
LIKE THE EXAMPLE I   GAVE WHERE 
10%
 OF OUR USERS   WERE COMPLETELY 
AFFECTING
 OUR   SALES.  LIKE, THAT WAS   
PRODUCTION
 MONITORING.  IT'S,   LIKE, 
REALLY
 IMPORTANT. 
&amp;gt;&amp;gt;Yvette Nameth:  OKAY.  BACK   
TO
 QUESTIONS.  WHAT ABOUT   
DIMINISHING
 RETURNS OF TEST   STABILITY?  
HOW
 DO WE JUSTIFY   X WEEKS OF 
SOFTWARE
   ENGINEERING'S TIME THAT   
EFFECTS
 ONLY TESTS VERSUS   STABILIZE
ING TESTS
 THEMSELVES? 
&amp;gt;&amp;gt;Alister Scott:  THAT'S A   
GOOD QUESTION
 AS WELL.    YVETTE, I THINK YOU
 TALKED
   THIS MORNING ABOUT GOOGLE   
MAPS
 AND SPENDING TWO WEEKS   ON THE
 SORT
 OF &quot;FLAKY TEST&quot;   TEST&quot; -- 
&amp;gt;&amp;gt;Yvette Nameth:    
UNFORTUNATELY I
 DID. 
&amp;gt;&amp;gt;Alister Scott:  I MEAN, WE   
ALREADY
 SPEND -- LION WE   SPEND A HUGE
 AMOUNT
 OF MONEY   AND INVESTMENT ON 
FLAKY
 TESTS  TESTS.  WE DO THAT 
ALREADY.
  BY REINVESTING THAT EFFORT IN 
  TESTABILITY
 I'VE SEEN THAT   THE BENEFITS 
ARE
 MUCH MORE   SUBSTANTIAL.  SO 
IT'S
 NOT   ABOUT -- IT'S NOT ABOUT  
 SPENDING
 MORE MONEY ON   TESTABILITY.  
IT'S
 ABOUT   SPENDING MORE MONEY ON 
  FLAKINESS,
 SPENDING MORE   MONEY ON 
TESTABILITY. --
   DIVERTING THAT MONEY TO   
TESTABILITY.
I'VE SEEN IT IN   ALL THE 
EXAMPLES
 I'VE   PRESENTED.  I HAVE SEEN 
IT
 IN   A TEAM HOW GREATLY -- MUCH
   THE
 TEAM IS SO MUCH MORE   
CONFIDENT IF
 THEY CAN HAVE   CONSISTENT 
GREEN BUILDS
 AND   BEING ABLE TO RELEASE TO 
  PRODUCTION
 CONSISTENTLY   WITHOUT ANY 
FLAKY TESTS.
  IT'S LIKE A PRICELESS THING   
TO HAVE.
SO ... 
&amp;gt;&amp;gt;Yvette Nameth:  IS IT OR IS   
IT
 NOT A GENERAL BEST   PRACTICE 
TO SHIP
 INTERNAL   TESTABILITY HOOKS AS
 PART
 OF   THE SHIPPING SOFTWARE 
PACKAGE
  PACKAGE?  IF WE DO, AREN'T WE 
  EXPOSING
 INTERNAL TOOLS TO   CUSTOMERS 
THAT
 INCREASES THE   SIZE OF THE 
SHIP SOFTWARE
 BUT   PROVIDE NO USE TO THE   
CUSTOMER?
&amp;gt;&amp;gt;Alister Scott:  SO ALL THE   
TESTABILITY
 STUFF THAT I   MENTIONED IN MY 
TALK,
 WE,   BASICALLY, THROUGH CONFIG
 WE
   DISABLEED IT IN PRODUCTION   
BUILDS.
AND I THINK WE'VE   EVEN IN 
STAGING
 BUILDS, WE   ACTUALLY DISABLEED
 IT
 AS WELL   BECAUSE WE WANTED DEV
 TO
 BE   VERY MUCH LIKE PRODUCTION.
SO ANY SORT OF TESTABILITY   
FEATURE
 LIKE I TALKED ABOUT   THE PIZZA
 APP.
SO ANY   ABILITY TO, BASICALLY, 
LIKE
   JUMP STRAIGHT INTO A CUSTOM  
CUSTOMIZEING
 A PIZZA OR IN   SETTING UP ALL 
THIS
 DIFFERENT   DATA, THERE WAS NO 
WAY
 A USER   COULD ACCESS THAT IN A
   PRODUCTION
 OR STAGING   ENVIRONMENT.  SO 
WE'RE
 VERY   VERY -- AND WE HAD A LOT
 OF
   CONFIG TESTS, SO WE'RE VERY  
 VERY --
 EVERYTHING WAS   HEAVILY DRIVEN
 BY
 CONFIG AND   WE CAME UP WITH A 
COLLECTIVE
   DATA TO HAVE UNIT TESTS FOR  
 CONFIG.
SO YOU COULD   ACTUALLY -- EVERY
 TIME
 YOU   CHANGE CONFIG YOU WOULD 
WRITE
   A UNIT TEST FOR IT.  WE HAD A
   LOT
 OF CONFIDENCE, I GUESS,   THAT 
OUR
 PRODUCTION CONFIG   DIDN'T 
INCLUDE
 ANY OF OUR   TESTING STUFF 
BECAUSE
 I DON'T   THINK IT'S VERY GOOD 
--
 LIKE   FROM A SIZE POINT OF 
VIEW AND
   ALSO FROM A, LIKE, RISK   
MANAGEMENT
 POINT OF VIEW,   IT'S NOT VERY 
GOOD
 TO   ACTUALLY, LIKE, SHIP   
TESTABILITY
 FEATURES TO   CUSTOMERS. 
&amp;gt;&amp;gt;Yvette Nameth:  HOW DO YOU   
KNOW
 THAT YOU'RE VALIDATES   REAL-
WORLD
 CONDITIONS WHEN   YOU TEST A 
SPECIFIC
 CONTROL  CONTROLLER? 
&amp;gt;&amp;gt;Alister Scott:  YEAH, SO   
WITH THE
 TEST CONTROLLER,   LIKE, IT WAS
 FULL
 STACK.  SO   IT DID USE 
SERVICES.
IT DID   USE A DATABASE.  IT 
JUST WAS
   REALLY, LIKE, -- I GUESS LIKE
   A
 SETUP, LIKE A QUICK   MECHANISM
.
SO IT WAS,   BASICALLY, A WAY OF
 SETTING
   UP STATE IN YOUR APPLICATION 
  AND
 REDIRECTING TO A CERTAIN   
POINT SO
 THAT YOU COULD   ACTUALLY SEE 
THAT.

QUESTION
 BECAUSE, LIKE, THEY   WEREN'T 
THE
 ONLY TESTS THAT   WE HAD.  SO I
 THINK
 WE   MENTIONED WE HAD ABOUT 500
   TESTS
 AND ABOUT 450 OF THOSE   
APPROXIMATELY
 WOULD HAVE USED   THE TEST 
CONTROLLER.
SO THEY   ARE VERY TARGETED.  
THEY
   WOULD JUST BE -- THE WAY THE 
  TEST
 WOULD WORK, IT WOULD SAY  SAY, 
HEY,
 I CALL THIS TEST   CONTROLLER. 
 I
 GET TO WHERE I   WANT AND I DO 
SOME
 SESSIONS. 
THE REMAINING 50 OR THE SORT   
OF,
 LIKE, THE TOP OF OUR TEST   
PYRAMID,
 THEY ARE OUR   END-TO-END REAL 
USER
 TEST.    THEY, BASICALLY, GO 
THROUGH
   FROM THE START OF, LIKE,   
SPECIFYING
 WHO YOU ARE TO   ORDER PIZZA, 
SELECTING
 YOUR   ADDRESS, GOING THROUGH, 
  CHOOSEING
 HAWAIIAN PIZZA, DO  DOING ALL 
SORTS
 OF STUFF TO   IT AND SAYING, 
HEY,
 IT NEEDS   TO BE DELIVERED TO 
MY DOOR
   AND BEING ABLE TO SEE A PIZZA
   TRACKER.
WE HAD A HANDFUL OF   THOSE.  WE
 LIMITED
 THEM.    THERE WAS NOWHERE NEAR
 AS
   MANY BUT THEY DIDN'T USE ANY 
  OF
 THE TEST TESTABILITYIES   SORT 
OF
 FEATURES BECAUSE THEY   WERE 
REPRESENTATIVE.
AND THE   BENEFIT OF THOSE AS I 
SAID
   BEFORE, OUR TESTABILITY STUFF
   WAS
 DISABLEED IN PRODUCTION   
BECAUSE
 OUR END-TO-END TESTS   DIDN'T 
USE
 ANY OF THAT, WE   COULD 
ACTUALLY RUN
 THOSE IN   PRODUCTION WHICH WE 
DID.
WE   ACTUALLY RUN THEM IN DEV 
TEST
   STAGING AND WE ACTUALLY RAN  
 THEM
 IN PRODUCTION.  EVERY   TIME WE
 DID
 A PRODUCTION   RELEASE, WE'D 
RUN THOSE.
  THEY WOULD ORDER THREE WEEKS  
 IN
 ADVANCE SO WE COULD HAVE   TIME
 TO
 CANCEL THEM.  BUT,   YEAH, SO, 
WE
 COULD ACTUALLY   USE THOSE 
TESTS.

WEREN'T JUST
 USING   TESTABILITY FEATURES.  
WE
   WERE ACTUALLY, LIKE,   
COMPLEMENTING
 IT WITH REAL   END-TO-END 
TESTING.
&amp;gt;&amp;gt;Yvette Nameth:  OKAY.  WHAT   
ABOUT
 HEISENBUGS?  INSTRUMENT  
INSTRUMENTATION
 CHANGES   OUTCOME, PREVENTS RE
FROM
   PRODUCTION.  WHAT DO YOU DO  
 WHEN
 YOUR ACTUAL INSTRUMENT  
INSTRUMENTATION
 AND HOOKS   CAUSE SOMETHING TO 
CHANGE?

DIDN'T
 SEE THAT WHOLE AMOUNT.    ANY 
OF THESE
 TESTABILITY,   LIKE, HOOKS OR 
CHANGES
 WERE,   LIKE, COMPLETELY RE
PRODUCEIBLE
   IN A DEVELOPMENT ENVIRONMENT.

 APP
 LOCALLY IN DEBUG MODE   AND 
ACTUALLY
 USE ONE OF THESE   TESTABILITY 
FEATURES
 AND SEE   EXACTLY WHAT WAS 
HAPPENING
   AND JUST RUNNING IT IN DEBUG,
   YOU
 COULD ACTUALLY SEE THE   VALUES
 OF
 EVERYTHING.  SO, I   GUESS, 
BEING
 ABLE TO DO THAT,   WE COULD 
ACTUALLY
 IRON OUT   WHETHER THERE WERE 
ANY
 ISSUES   IN THAT. 
BUT THE BENEFITS FAR OUTWEIGH  
OUTWEIGHED
 ANY ISSUES THAT WE   EVER HAD 
WITH
 THAT.  I HAVE   NEVER HEARD OF 
HEISENBUGS
 BUT   I WILL LOOK THAT ONE UP. 
&amp;gt;&amp;gt;Yvette Nameth:  WAS IT   
DIFFICULT
 TO CONVINCE PEOPLE   TO UNDER
TAKE
 THIS EFFORT? 
&amp;gt;&amp;gt;Alister Scott:  YEAH, IT   WAS
.
PARTICULARLY --   PARTICULARLY 
DEVELOPERS
   BECAUSE, AS I SAID, -- LIKE  
 WITH
 THE QUESTION WE HAD   BEFORE, 
LIKE
 IT IS A FAIR BIT   OF EFFORT.  
BUT
 IT IS ABOUT,   I GUESS, 
CHANGING YOUR
 FOCUS.    IT WAS HARD TO 
CONVINCE
   PEOPLE.  BUT AS SOON AS WE   
ACTUALLY
 MADE SOME GAINS AND,   LIKE, 
JUST
 MAKE. 
TAKING, LIKE, A SINGLE BUG   
THAT YOU
 HAVE IN PRODUCTION   AND THEN 
SAYING
 HOW CAN WE   TEST THIS SMARTLY,
   INTRODUCING
 A TESTABILITY   FEATURE FOR IT 
AND
 ACTUALLY   DOING THAT, BUT DO
ING SMALL
   EXAMPLES AND PROVEING AND 
SHOW  SHOWING
 HOW THEY CAN BE   EFFECTIVE, 
YOU SOON
 GET BIND.    AS SOON AS YOU 
HAVE 
  CONSISTENT BUILDS PASS CAN,   
EVERYONE
 THINKS IT IS THE   BEST THING 
IN THE
 WORLD   BECAUSE THEY ARE NO 
LONGER
   QUESTIONING THE QUALITY. 
&amp;gt;&amp;gt;Yvette Nameth:  I'M GOING   TO
 THROW
 IN MY OWN FOLLOW-UP   QUESTION 
WHICH
 IS HOW DO YOU   MEASURE FLAKY
INESS
 AND SORT OF   FOLLOW THAT ALONG
?
YOU'RE   TALKING ABOUT, LIKE, 
YOU KNOW
  KNOW, SHOWING PROOF OF   
CONCEPT AND
 THEN ITERATEING ON   THAT.  HOW
 DO
 YOU ACTUALLY   MEASURE 
FLAKINESS?

ONLY
 WAY YOU CAN REALLY   MEASURE IT
 IS
 BY EVERY FAILED   BUILD THAT 
YOU HAVE,
 LOOKING   AT IT AND THEN IT'S 
ASKING
   WHETHER IT'S A LEGITIMATE   
FAIL.
AND SO FIRSTLY HOW   MANY BUILD 
FILES
 YOU HAVE AND   IF YOU ARE 
HAVING BUILDS
 THAT   ARE FAIL, LOOKING AT 
THEM AND
   SAYING IS THIS A LEGITIMATE  
 BUG
 AND HOW QUICKLY YOU CAN   
DETERMINE
 THIS IS A   LEGITIMATE BUG WE 
NEED
 TO FIX  FIX.  ONCE YOU START 
REALIZE
  REALIZING THAT EVERY BUILD   
THAT
 FAILS IS A LEGITIMATE   BUG, I 
GUESS
 THAT'S WHEN YOU YOU   HAVE 
CONFIDENCE
 THAT YOU HAVE   A FLAKINESS. 
&amp;gt;&amp;gt;Yvette Nameth:  ONE LAST   
QUESTION.
WHAT HELPS YOU TO   INCULCATE --
 YOU
 GUYS ARE   TEACHING ME NEW 
WORDS,
 THANK   YOU -- A CULTURE OF 
TESTABLE
   DESIGN WITHIN THE DEVELOPER  
 COMMUNITY?
WHAT DO YOU DO   WHEN THEY WANT 
TO
 CUT CORNERS   TO RELEASE URGENT
 FEATURES?

REALLY
 GOOD QUESTION.  I   THINK IT 
SORT
 OF GOES BACK TO   WHAT I SAID, 
THAT
 IT IS   REALLY LIKE A LONG-TERM
 VIEW
   AND IT'S JUST REALLY LIKE   
SHOWING,
 LIKE, DEMONSTRATING   THE 
ABILITY
 OF, LIKE, THE   EFFECTIVENESS 
OF DOING
 THIS.    AND THEN IN SMALL 
AMOUNTS
 AND   THEN SORT OF GAINING 
MOMENTUM
   OVER TIME. 
AND, LIKE, ULTIMATELY, LIKE,   
EVERY
 DEVELOPER I HAVE WORKED   WITH 
HAS
 ACTUALLY BEEN SORT   OF 
INVOLVED IN
 THIS.    ULTIMATELY THEY LOVE 
IT 
  BECAUSE IT GIVES THEM REALLY  
 GOOD
 CONFIDENCE TO MAKE   CHANGES 
WHICH
 EVERY DEVELOPER   WANTS.  IT 
GIVES
 THEM REALLY   GOOD CONFIDENCE 
TO DO
 A   RELEASE AND IT REDUCES HOW 
  MANY
 CALLS THEY GET AFTER  
AFTERHOURS BECAUSE
 SOMETHING  SOMETHING'S CRASHED.
SO, YEAH, EVERYONE I'VE BEEN   
INVOLVED
 WITH HAS ACTUALLY   LOVEED THIS
 PROCESS.
BUT IT'S   JUST A MATTER OF, 
LIKE,
   CHANGING THAT CULTURE OVER   
TIME
 AND REALLY THE ONLY WAY   TO 
DELIVER,
 LIKE, FAST   SOFTWARE SUSTAIN
ABLY
 IS TO   HAVE, LIKE, VERY RE
LIABLE
   NON-FLAKY TESTS. 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU,   A
LISTER.
[ APPLAUSE ] 
SO WITH THAT WE ARE GOING TO   
GO TO
 A BREAK.  PLEASE RETURN   TO 
THIS
 ROOM BY 4:00 SO WE   CAN FINISH
 UP
 OUR DAY.    REFRESHMENTS, 
BEVERAGES
 OUT  OUTSIDE THE ROOM. 
&amp;gt;&amp;gt;Yvette Nameth: 
. 
&amp;gt;&amp;gt;Yvette Nameth:  WELCOME BACK. 
WE HAVE OUR LAST FEW   
PRESENTATIONS
 OF THE DAY. 
WE'RE GOING TO KICK IT OFF  WITH

LARGE-
  LARGE-SCALE AUTOMATED VISUAL  
 TESTING.
[ APPLAUSE ] 
&amp;gt;&amp;gt;Adam Carmi:  THANK YOU.  THANK

HI, EVERYONE.  I'M ADAM CARMI.  
  I'M
 THE COFOUNDER OF VP R&amp;amp;D   
APPLITOOLS.
WE ARE A COMPANY   THAT PROVIDES
 TOOLS
 FOR   AUTOMATED VISUAL TESTING.
LARGE-SCALE AUTOMATED  VISUAL   
TESTING
 IS A REALITY TODAY.  AND   THIS
 TALK
  WILL FOCUS ON THE KEY   TIPS 
AND
 GUIDELINES THAT ARE   CRUCIAL 
TO SUCCEEDING
 WITH   VISUAL TESTING AT THIS 
SCALE.

  FAMILIAR
 WITH VISUAL TESTING,   I'LL 
START
 WITH A BRIEF   INTRODUCTION.  
I'LL
 EXPLAIN WHAT   VISUAL TESTING 
IS AND
 WHY IT   SHOULD BE AUTOMATED.  
I'LL
 ALSO   EXPLAIN HOW AUTOMATED 
VISUAL
   TESTING TOOLS WORK. 
AND THE REMAINDER OF THE TALK   
WILL
 FOCUS ON THE SCALEUP TIPS   AND
 WE'LL
 HAVE TIME TO ANSWER   ANY 
QUESTIONS
 THAT YOU MAY HAVE. 
SO WHAT IS VISUAL TESTING?  IT'S

 AIMED
 TO VERIFY THAT A GRAPHICAL   
USER
 INTERFACE APPEARS CORRECTLY   
TO USERS.
NOW, THIS GOES BEYOND THE   
TRADITIONAL
 FUNCTIONAL TESTING   THAT YOU 
USED
 TO DO WITH TOOLS   LIKE 
SELENIUM AND
 APPIUM, WHERE   YOU TEST THE 
FUNCTIONALITY
 OF   THE APPLICATION THROUGH DU
 GOOGLE
   I/O. GUI.  WE   WANT TO MAKE 
SURE
 EACH UI   ELEMENT APPEARS IN 
THE RIGHT
   COLOR, SHAPE, AND SIZE AND IT
   DOESN'T
 OVERLAP OR HIDE ANY   OTHER UI 
ELEMENT
 . 
THIS TYPE OF TESTING HAS BECOME 
  INCREASINGLY DIFFICULT TO   
PERFORM
 IN RECENT YEARS, MANY   DUE TO 
THE
 EXPLOSIONS OF BROWSER  BROWSERS
, DEVICES,
 OPERATING   SYSTEMS, AND SCREEN
 RESOLUTIONS
   THAT APPLICATIONS ARE 
EXPECTED 
  TO RUN ON TODAY. 
SO HERE YOU CAN SEE AN EXAMPLE  
 OF
 A VISUAL BUG THAT WE FOUND IN  
 THE
 MICROSOFT (INDISCERNIBLE)   
MANAGEMENT
 PORTAL.  YOU CAN SEE   HOW IT 
EXCEEDED
 THE EXPECTED   BOUNDS OF THE 
PAGE.
THIS IS HOW   THE AMAZON WEB 
SITE LOOKED
 LIKE   FOR SEVERAL HOURS FOR 
SOME
   CUSTOMERS DURING AMAZON PRIME
   DAY
 THREE MONTHS AGO.  I'M SURE   
YOU'VE
 ALL SEEN THESE TYPE OF   BUGS, 
AND
 MAYBE IN YOUR OWN   APPLICATION
, AND
 YOU UNDERSTAND   THEIR VERY 
ELEVATOR.
THEY CAN   BE VERY EMBARRASSING 
AND
 DAMAGE   THE BRAND OF THE 
COMPANY.
AND   IN SOME SITUATIONS, THEY 
CAN
   COMPLETELY CRIPPLE THE   
FUNCTIONALITY
 OF THE APPLICATION   AND END UP
 COSTING
 A LOT OF   MONEY, WHICH IS 
PROBABLY
 WHAT   HAPPENED IN THIS CASE. 
SO WHY SHOULD WE AUTOMATE THIS  
 TYPE
 OF TESTING? 
THERE ARE MANY REASONS.  BUT THE

 TEST
 MATRIX IS JUST TOO BIG TO   
COVER
 MANUAL LITH.  THINK OF ALL   
THE DIFFERENT
 WEB BROWSERS,   DEVICES, AND 
SCREEN
 RESOLUTIONS   THAT YOUR 
APPLICATION
 IS   EXPECTED TO RUN ON.  WE 
ALL KNOW
   THAT A WEB SITE THAT LOOKS 
GOOD
   ON CHROME DOESN'T IMPLY THAT 
IT
   LOOKS GOOD ON IE, AND AN   
APPLICATION
 THAT LOOKS GOOD ON A   WIDE 
SCREEN
 DOESN'T MEAN THAT IT   WILL 
LOOK GOOD
 ON A SMARTPHONE. 
SO WE HAVE TO TEST OUR   
APPLICATION
 IN ALL OF THESE   DIFFERENT 
ENVIRONMENTS,
 WHICH   CAN BE VERY INEFFECTIVE
 AND
 COST  COSTLY TO DO MANUALLY. 
IF YOUR APPLICATION IS   
RESPONSIVE,
 AND MOST MODERN   APPLICATIONS 
ARE,
 THEN YOU ALSO   NEED TO TEST 
ALL THE
 DIFFERENT   LAYOUT MODES IN ALL
 THE
   DIFFERENT ENVIRONMENTS. 
IF IT'S LOCALIZED, THEN YOU ALSO
  NEED TO CHECK -- FACTOR IN THE
   FONTS,
 RESOURCES, IMAGES, AND   
CONTENT THAT
 IS SPECIFIC TO EACH   LANGUAGE.
AND, OF COURSE, EVEN IF YOU   
DON'T
 CHANGE A LINE OF CODE IN   YOUR
 APPLICATION,
 STILL YOU   DEPEND ON 
THIRD-PARTY
 UPGRADES   THAT CAN INTRODUCE 
VISUAL
 BUGS   TO YOUR APPLICATION. 
AN EXAMPLE FOR THAT IS A WEB   
BROWSER
 THAT UPDATES EVERY FEW   WEEKS,
 AND
 WHENEVER IT DOES, IT   CAN 
INTRODUCE
 INCOMPATIBILITIES   WITH YOUR 
WEB
 SITE THAT MAY BE   MANIFEST AS 
VISUAL
 BUGS.  SO YOU   HAVE TO TEST A 
LOT
 OF THINGS   MANY TIMES, AND 
IT'S JUST
 TOO IN  INEFFECTIVE TO DO 
MANUALLY.
WHAT MAKES THINGS EVEN WORSE IS 
  THE
 FACT THAT RELEASE CYCLES   KEEP
 GETTING
 SHORTER AND SHORTER  SHORTER.  
SO
 COMPANIES THAT ARE   DOING 
CONTINUOUS
 DEPLOYMENT   TODAY, WHICH IS 
THE CURRENT
 HYPE  HYPE, ARE RELEASING TO   
PRODUCTION
 SEVERAL TIMES A DAY.    AND 
WITH SUCH
 RELEASE CYCLES,   THERE'S NOT 
ENOUGH
 TIME TO DO   MANUAL TESTING TO 
MAKE
 SURE YOUR   APPLICATION LOOKS 
GOOD
 IN SO   MANY EXECUTION 
ENVIRONMENTS.

THESE
 TOOLS ACTUALLY WORK. 
SO THERE ARE MANY AUTOMATED   
VISUAL
 TESTING TOOLS OUT THERE.    AND
 THEY
 ALL SHARE THE SAME WORK   FLOW 
WITH
 THESE FOUR SIMPLE   STEPS. 
IN THE FIRST STEP, YOU DRIVE THE

TAKE
   SCREENSHOTS. 
IN THE SECOND STEP, THE TOOL   
TAKES
 THOSE SCREENSHOTS AND   
COMPARES THEM
 WITH BASELINE   IMAGES.  THESE 
IMAGES
 DEFINE THE   EXPECTED 
APPEARANCE OF
 THE   APPLICATION.  AND IN THE 
  MAJORITY
 OF CASES, THESE ARE   SIMPLY 
SCREENSHOTS
 THAT WERE   TAKEN IN THE PAST 
AND
 APPROVED   BY A HUMAN TESTER. 
IN THE THIRD STEP, THE TOOL   
GENERATES
 A REPORT FOLLOWING THE   TEST 
RUN
 THAT INCLUDES ALL THE   
SCREENSHOTS,
 ALL OF THE BASELINE   IMAGES, 
AND
 ANY DIFFERENCES THAT   WERE 
FOUND
 DURING THE TEST. 
AND IN THE FOURTH STEP, TESTER  
 HAS
 TO LOOK AT THE REPORT, IF   ANY
 CHANGES
 WERE FOUND, AND   DECIDE FOR 
EACH
 CHANGE IF IT'S A   BUG, IN 
WHICH CASE
 HE OPENS A   BUG; OR IF IT'S A 
VALID
 CHANGE   TO THE APPLICATION, HE
 SIMPLY
   APPROVES THE NEW SCREENSHOT 
TO 
  BE USED AS A BASELINE IMAGE 
FOR 
  SUBSEQUENT RUNS. 
  HERE, YOU CAN SEE AN EXAMPLE  
 OF
 THE FIRST TWO STEPS, TAKING   
SCREENSHOTS
 AND (INDISCERNIBLE)   THEM.  
WITH
 AN OPEN SOURCE   VISUALTEST 
AUTOMATION
 TOOL   CALLED WEBDRIVER CSS, AS
 YOU
 CAN   SEE, JAVASCRIPT BASE AND 
IT
   EXTENDSED WEBDRIVER IO 
WEBDRIVER.
  AND THIS TEST IS VERY SIMPLE. 

BY --
   WITH THE INSTANCE OF THE   
WEBDRIVER
 IO.  IT INITIALIZES IT  IT, 
WHICH
 CAUSES THE BROWSER TO   OPEN.  
IN
 THIS CASE, IT WOULD BE   A 
LOCAL CHROME
 BROWSER.  THEN IT   NAVIGATES 
TO THE
 EXAMPLE OF   CHROME URL.  IT 
PERFORMANCE
 A   VALIDATION POINTS WHICH 
TAKES
   THREE PARAMETERS  .  THE 
FIRST 
  IS THE NAME FOR THE CHECK 
POINT.
  THAT'S HOW IT WILL APPEAR IN 
THE
   REPORT.  AND THEN A LIST OF  
 ELEMENTS
 THAT YOU WANT TO   VALIDATE.  
IN THIS
 CASE, THERE   ARE TWO ELEMENTS,
 HEADER
 AND   HERO.  AND THEY ARE BOTH 
DEFINED
   WITH THE CSS LOCATORS. 
AND THE THIRD PARAMETER THAT IS 
  A
 CALLBACK, THAT IS CALLED IF   
DIFFERENCES
 ARE FOUND.  THERE   YOU CAN 
ASSERT
 AND MAKE SURE   THAT THE 
DIFFERENCES
 DO NOT   EXCEED ANY MISMATCH   
(INDISCERNIBLE)
 TO FIND.  SO YOU   CAN SEE HOW 
EASY
 IT IS TO TAKE   AN EXISTING 
FUNCTIONAL
 TEST, IN   THIS CASE, A 
WEBDRIVER
 TEST, AND   JUST TURN IT INTO 
AN AUTOMATED
   VISUALTEST WITH A FEW LINES 
OF 
  CODE. 
HERE YOU CAN SEE AN EXAMPLE OF  
 THE
 TWO LAST STEPS, VIEWING THE   
REPORT
 AND UPDATING IT, WITH A   TOOL 
CALLED
 GEMINI, ALSO AN OPEN   SOURCE 
TOOL.
YOU CAN SEE A LIST   OF ALL THE 
CHECK
 POINTS .  THE   ONE THAT HAS 
THE DIFFERENCES
 ARE   MARKED IN RED.  AND YOU 
CAN
 SEE   FOR EACH DIFFERENCE THAT 
IS
   FOUND THAT YOU HAVE AN IMAGE 
OF
   THE BASELINE.  IT'S CALLED   
REFERENCE
 IN THIS TOOL.  THE   
SCREENSHOTS THAT
 ARE BEING   VALIDATED.  AND 
ALSO A
 DIFF   IMAGE, WHICH IS 
BASICALLY A
   SCREENSHOT WITH ALL THE   
DIFFERENT
 PIXELS HIGHLIGHTED IN   PINK SO
 IT
 WILL BE EASY TO   IDENTIFY THE 
CHANGE.
AND THE   MAINTENANCE OPERATION 
THAT
 YOU   NEED TO DO IF YOU DECIDE 
THAT
   THIS IS NOT A BUG IS JUST 
CLICK
   THIS BUTTON OVER HERE, THE 
ARROW
  ARROW.  AND THIS WILL REMAIN 
AND
   SET THE SCREENSHOT AS THE   
BASELINE
 FOR SUBSEQUENT RUNS. 
THERE ARE MANY VISUALTEST   
AUTOMATION
 TOOLS AVAILABLE.  SO   IF YOU 
WANT
 TO GET STARTED WITH   THEM, YOU
 HAVE
 A LOT OF OPTIONS   TO CHOOSE 
FROM.
IT IS IMPORTANT   TO HIGHLIGHT 
THAT
 THE MAJORITY   OF TOOLS, ALL OF
 THEM
 ALMOST,   ONLY WORK FOR WEB 
SITES.
THEY   WON'T WORK FOR MOBILE   
APPLICATIONS.
THE ONLY TWO   EXCEPTIONS ARE 
FACEBOOK'S --
   SORRY ABOUT THAT -- FACEBOOK 
  SNAPSHOT
 TEST CASE BY FACEBOOK   THAT WE
 CAN
 TEST iOS   APPLICATIONS, AND 
APPLITOOLS
 I   THAT WILL WORK FOR ANY 
MOBILE
   APPLICATION THAT CAN BE 
DRIVEN 
  WITH APPIUM. 
AND THAT CONCLUDES OUR BRIEF   
INTRODUCTION
 TO VISUAL TESTING. 
LET'S PROCEED WITH THE SCALE   
UPDATES.

  NATURALLY,
 USE A ROBUST IMAGE   COMPARISON
 ENGINE.
AND IF YOU   ALLOW ME TO QUOTE, 
THEN
 ONE DOES   NOT SIMPLY DO BIT 
MAP COMPARISON
  COMPARISON. 
AND THE REASON YOU DON'T DO THAT
  IS, IF YOU DO IT, YOU GET A 
LOT 
  OF FALSE POSITIVES, IN THE   
CONTEXT
 OF VISUALTESTING IS A   CASE 
WHERE
 THE TOOL TELLS YOU   THAT 
THERE'S
  A DIFFERENCE, BUT   YOU AS A 
HUMAN
 BEING CANNOT SEE   IT, OR IT'S 
SO
 MINUTE THAT YOU   DON'T CARE 
ABOUT
 IT. 
AND THERE ARE MANY, MANY REASONS

 YOU'RE
 JUST DOING SIMPLE PIXEL-  
PIXEL-TO-PIXEL
 COMPARISON COMPARISON.  AND   
LET'S
 TAKE A LOOK AT SOME OF THE   
MOST
 COMMON ONES. 
SO THE FIRST ONE HAS TO DO WITH 
  AN
 IMAGE PROCESSING EFFECT   
CALLED ANTIALIASING.
HERE'S AN   EXAMPLE OF IT.  YOU 
CAN
 SEE WE   HAVE AT THE BOTTOM OF 
THE
 IMAGE   A NAVIGATION BAR.  AND 
THE
 PLAY   LIST BUTTON IS MAGNIFIED
.
YOU   CAN SEE ON THE BOTTOM IT 
APPEARS
   IN WHITE.  AND PROBABLY 
THAT'S 
  WHAT THE COLOR OF THE TEXT WAS
.
  BUT YOU CAN SEE IN THE 
MAGNIFIED
   IMAGE THAT ACTUALLY MANY OF 
THE
   PIXELS ARE NOT WHITE.  THEY 
HAVE
   DIFFERENT SHADES OF BLUE.  
THIS
   IS  ANTIALIASING AT WORK.    
BASICALLY,
 THE RENDERING ENGINE,   WHICH 
IS THE
 GRAPHICS CARD OR   WHATEVER IS 
RESPONSIBLE
 FOR   RENDERING THIS IMAGE, IS 
PAINT
  PAINTING CERTAIN PIXEL ALONG 
THE
   BORDER OF THE LINES IN 
DIFFERENT
   SHADES AND INTENSITIES AND   
COLORS.
AND IN ORDER TO MAKE   THE TEXT 
APPEAR
 SMOOTHER TO US.    
THE PROBLEM WITH ANTIALIASING IS
  IS,
 IF YOU RUN YOUR TEST ON   
SEVERAL
 MACHINES, WHICH MAKES   SENSE 
IF YOU
 HAVE MORE THAN ONE   TESTER IN 
YOUR
 TEAM OR IF YOU'RE   RUNNING 
YOUR TEST
 IN A LAB,   WHICH MAKES SENSE 
IF YOU
 ARE   TRYING TO SCALE UP, IS 
THAT
   YOU'LL GET DIFFERENT   
RENDERING
   ENGINES PAINTING THOSE PIXELS
, 
  WHICH MEANS DIFFERENT   
IMPLEMENTATIONS
 OF THE ANTIALIAS  ANTIALIASING 
ALGORITHM.
SO THIS, FOR INSTANCE, IS HOW   
ANTIALIASING
 WILL LOOK LIKE ON A   DIFFERENT
 MACHINE.
I WILL   TOGGLE BETWEEN THE TWO 
AND
 YOU   CAN SEE HOW DIFFERENT THE
 PIXELS
   ARE.  NOT THAT DIFFERENT.  
HOW 
  DIFFERENT THEY ARE IN POSITION
   AND
 COLOR. 
THEN QUAEN AGAIN, YOU NEED A 
VERY
   SOPHISTICATED IMAGE 
COMPARISON 
  ENGINE TO BE ABLE TO IDENTIFY 
  THAT
 THESE DIFFERENT PIXELS ARE   
ACTUALLY
 INVISIBLE TO THE HUMAN   EYE 
AND JUST
 IGNORE THEM,   OTHERWISE YOUR 
TEST
 WILL FAIL. 
A SIMILAR CASE HAS TO DO WITH   
PIXEL
 BRIGHTNESS WHEN RUN ON   
DIFFERENT
 MACHINES OR EVEN ON   THE SAME 
MACHINE
 WHICH IS   CONNECTED TO A 
MONITOR
 WITH   DIFFERENT CAPABILITIES. 
YOU CAN SEE HOW DIFFERENT THE   
INTENSITY
 OF THE PIXELS CAN BE  BE. 
THIS EXAMPLE HAS TO DO WITH THE 
  POSITIONING
 OF TEXT.  SO THIS IS   IS -- 
YOU PROBABLY
 RECOGNIZE IT   IT -- IS THE 
DROPBOX
 WEB SITE.    AND YOU CAN SEE 
THAT
 THE UPGRADE   ACCOUNT ELEMENT 
IS MOVING.
THE   REASON THAT IT'S MOVING IS
 THAT,
   TO THE RIGHT OF IT, THERE IS 
A 
  USER NAME.  AND WHENEVER WE 
RUN 
  THE TEST, THERE'S A DIFFERENT 
  USER
 NAME.  IT HAS DIFFERENT   
LENGTH.
AND BECAUSE OF THAT,   THE UP
GRADE
 ACCOUNT ELEMENT IS   MOVING.  
SO WE
 WOULD STILL WANT   TO VISUALLY 
VALIDATE
 IT.  SO ONE   SIMPLE SOLUTION 
TO THIS
 PROBLEM   WOULD BE TO JUST 
CAPTURE
 A   SCREENSHOT OF THE UPGRADE  
 ACCOUNT
 ELEMENT AND COMPARE IT   TO A 
BASELINE
 THAT'S JUST FOR   THAT ELEMENT.
  AND
 SO IT DOESN'T   REALLY MATTER 
WHERE
 IT APPEARS   ON THE PAGE.  
THAT'S
 A VERY GOOD   IDEA.  BUT IF 
YOU'RE
 DOING PIXEL  PIXEL-TO-PIXEL 
COMPARISON,
 IT   WILL STILL NOT WORK, 
BECAUSE
   ALTHOUGH IT SEEMS THAT THE UP
  UPGRADE
 ACCOUNT ELEMENT MOVES AS   A 
WHOLE,
 ACTUALLY, EACH   INDIVIDUAL 
LETTER
 IS POSITIONED   ON ITS OWN.  SO
 YOU
 CAN SEE HOW   THE A AND C AND O
 LETTERS
 ARE   POSITIONED IN DIFFERENT 
PIXELS.
  AND THEN AGAIN, YOU NEED THE  
 IMAGE
 COMPARISON ENGINE TO BE   ABLE 
TO
 REALIZE THAT ALL THESE   
DIFFERENT
 PIXELS ARE ACTUALLY --   THEY 
ACTUALLY
 LOOK THE SAME TO A   HUMAN. 
THE LAST EXAMPLE I'LL SHOW YOU  
 HAS
 TO DO WITH IMAGE SCALING,   
WHICH
 HAPPENS ALL THE TIME IN   EVERY
 APPLICATION.
WHAT YOU SEE HERE IS THIS CAR   
HERE
 AND THE SMALL NAG ANY MAGNIFIED
 BOX
   HERE.  AND WHAT HAPPENS IS 
THAT
   WHENEVER YOU HAVE AN IMAGE   
ELEMENT
 IN YOUR APPLICATION AND   THE 
SOURCE
 IMAGE THAT IT'S   SHOWING IS 
NOT EXACTLY
 OF THE   SAME SIZE, THE 
RENDERING
 ENGINE   WILL ACTUALLY SCALE IT
 SO
 IT   WOULD FIT THE TARGET 
POSITION.
  AND THEN AGAIN, TWO DIFFERENT 
  RENDERING
 ENGINES WOULD USE A   DIFFERENT
 SCALING
 ALGORITHM.    AND THAT WOULD 
ACTUALLY
 RESULT   WITH EXTREMELY 
DIFFERENT
 PIXELS,   AS YOU CAN SEE HERE. 
SO, AGAIN, EXTREMELY DIFFERENT  
 PIXELS,
 BUT COMPLETELY INVISIBLE   TO 
US AS
 HUMANS.  AND, AGAIN,   THIS IS 
SOMETHING
 THAT THE TOOL   NEEDS TO BE 
ABLE TO
 TAKE CARE OF  OF. 
AND THERE'S MORE.  THERE COULD  
 BE
 ARBITRARY PIXEL OFFSETS.    
SOME COULD
 BE SMALL, LIKE TEXT   OR 
PARAGRAPH
 DISPLAYED AT ONE   PIXEL OFFSET
.
SOME COULD BE   MORE SEVERE, 
LIKE COLUMN
 OF A   TABLE BEING ONE PIXEL 
WIDER.
  AND THAT WOULD MOVE THE ENTIRE
   PAGE
 ONE PIXEL TO THE SIDE,   RESULT
ING
 WITH WITH A 70% PIXEL-  
PIXEL-WIDE
 CHANGE OF THE IMAGE,   BUT 
STILL COMPLETELY
 INVISIBLE   TO US.  YOU NEED TO
 BE
 ABLE TO   DEAL WITH DYNAMIC 
CONTENT
 SUCH   AS DATES AND ADS AND 
USER NAMES.
  MOVING ELEMENTS LIKE THE UP
GRADE
   ACCOUNT SAMPLE THAT WE SAW   
BEFORE.
COMPARING IMAGES OF   DIFFERENT 
SIZES.
AND, OF COURSE  COURSE, THE 
IMAGE COMPARISON
   ENGINE HAS TO BE EXTREMELY 
FAST.
  OTHERWISE, YOUR TEST WILL TAKE
   FOREVER
 TO RUN. 
AND THERE ARE THOSE THAT ALWAYS 
  GET
 MISMATCHES.  AND THERE'S   
NOTHING
 YOU CAN DO ABOUT IT.    BUT, 
SERIOUSLY,
 VISUALTEST   AUTOMATION TOOLS 
HAVE
 COME A   VERY, VERY LONG WAY 
AND THEY
 CAN   VERY SUCCESSFULLY HANDLE 
THESE
   TYPE OF FALSE POSITIVES TODAY
. 
BEFORE BEFORE YOU START WORKING 
  WITH
 A VISUALTEST AUTOMATION   TOOL,
 YOU
 NEED TO MAKE SURE THAT   IT 
WORKS
 VERY STABLE FOR YOUR   APP.  
BECAUSE
 IF YOU WON'T BE   ABLE TO GET 
AWAY
 FROM THESE   FALSE POSITIVES, 
THERE
 IS NO WAY   THAT YOU WILL BE 
ABLE
 TO SCALE   UP YOUR TESTS. 
TIP NUMBER TWO, USE A SINGLE   
BASELINE
 ACROSS DEVICES AND   BROWSERS. 
SO THE IDEA HERE AS TO IS TO 
REDUCE
   THE AMOUNT OF MAINTENANCE 
THAT 
  YOU HAVE TO DO, ESPECIALLY 
WITH 
  REGARDS TO CROSS-BROWSER AND  
 CROSS-DEVICE
 TESTING, BY   REDUCING THE 
AMOUNT
 OF BASELINE   IMAGES THAT YOU 
NEED
 TO MAINTAIN  MAINTAIN.  AND 
THIS IS
 HOW YOU   DO IT.  YOU KEEP A 
SET OF
   BASELINE IMAGES   FOR YOUR   
APPLICATION
 ON A -- FOR A   SPECIFIC 
EXECUTION
 ENVIRONMENT.    LET'S SAY 
CHROME ON
 WINDOWS.    AND WHENEVER YOU 
HAVE
 A NEW   RELEASE OF YOUR 
APPLICATION,
 YOU   USE THAT SAME BASELINE TO
   VALIDATE
 THAT NEW RELEASE ON   EXACTLY 
THE
 SAME ENVIRONMENT. 
BASICALLY, YOU'RE DOING VISUAL  
 REGRESSION
 TESTING.  YOU CAN   FIND UN
EXPECTED
 CHANGES. 
YOU CAN USE A VERY STRICT   
MATCHING
 ALGORITHM TO DO THAT,   BECAUSE
 YOU --
 YOUR APPLICATION   IS RUNNING 
ON THE
 SAME EXECUTION   ENVIRONMENT, 
AND
 SO IT SHOULD   RENDER EXACTLY 
THE
 SAME. 
ONCE YOU ARE DONE WITH THAT   
PROCESS
 AND YOU HAVE UPDATED   YOUR 
BASELINE
 TO REFLECT THE NEW   VERSION.  
YOU
 CAN THEN USE THE   SAME SET OF 
BASELINE
 IMAGES TO   MAKE SURE THAT YOUR
 APPLICATION
   RENDERS CORRECTLY IN OTHER   
EXECUTION
 ENVIRONMENTS, SUCH AS   OTHER 
BROWSERS,
 OTHER DEVICES OR   FORM FACTORS
, BY
 MAKING SURE   THAT THEIR LAYOUT
 OR
 STRUCTURE   IS CONSISTENT WITH 
THAT
 OF THE   BASELINE. 
AND I'LL SHOW YOU AN EXAMPLE OF 
  THIS
 TO CLARIFY IT, USING   
APPLITOOLS
 EYES. 
OKAY.  SO THE FIRST EXAMPLE IS 
IS
   FOR FOR A CROSS-BROWSER TEST.
  YOU CAN SEE THE BASELINE IMAGE
   HERE
 ON THE LEFT-HAND SIDE.  AND   
THE
 SCREENSHOT THAT WE ARE   
VALIDATING
 ON THE RIGHT-HAND   SIDE.  YOU 
CAN
 SEE THAT THE   BASELINE IMAGE 
WAS
 TAKEN     ON   CHROME AND THE 
SCREENSHOT
 WAS   TAKEN ON IE. 
IF WE TOGGLE BETWEEN THE TWO   
IMAGES,
 YOU CAN SEE HOW   DIFFERENT THE
 BROWSER
 RENDERS   THESE IMAGES.  YOU 
CAN SEE
 THAT   THE FONTS ARE SLIGHTLY 
SMALLER
   OR BIGGER, THEY CHANGE 
POSITION,
   THE TEXT HERE WRAPS A BIT   
DIFFERENTLY.
BUT WHEN WE ARE   PERFORMING A 
STRUCTURAL
   COMPARISON, ALL OF THIS IS 
FINE.
  THE IMAGES ARE CONSISTENT IN  
 TERMS
 OF LAYOUT AND STRUCTURE. 
WE HAVE THIS BUTTON THAT WE CAN 
  CLICK
 HERE TO FIND ANY   DIFFERENCES 
THAT
 WELL, FIND.    AND WE CAN SEE 
THAT
 WE HAVE A   DIFFERENCE AT THE 
BOTTOM.
IF WE   ZOOM IN TO IT, WE 
DISCOVER
 THAT   WE ACTUALLY DID HAVE A 
MISSING
   ELEMENT IN IE.  SO THIS IS AN
   EXAMPLE
 OF HOW YOU CAN USE    
STRUCTURAL MATCHING
 TO FIND BUGS   BETWEEN -- 
ACROSS BROWSERS.

CROSS-DEVICE
 TEST.  THIS IS   TWITTER ON TWO
 DIFFERENT
 MOBILE   DEVICES.  AND WE HAVE 
TWO
   VIOLATIONS HERE. 
SO THE FIRST ONE, OF COURSE,   
HERE.
THE BASELINE IMAGE   DICTATES 
THAT
 THE PARAGRAPH   SHOULD BE ALIGN
ED
 TO THE RIGHT   OF THE IMAGE.  
AND
 THIS IS   BROKEN HERE. 
HERE AT THE BOTTOM, WE HAVE AN  
 IMAGE,
 BUT IT IS MISSING IN THE   
SCREENSHOT.
SO, AGAIN, ALL THESE STRUCTURAL 
  CHANGES
 CAN BE CAUGHT.  AND IF   YOU 
SEE WHEN
 I TOGGLE THE   SCREENSHOT, THE 
TWO
 TWEETS IN   THE MIDDLE, 
ALTHOUGH THEY
 HAVE   DIFFERENT IMAGES AND 
TEXT IN
   THEM, ARE NOT HIGHLIGHTED AS 
  DIFFERENT,
 BECAUSE STRUCTURALLY,     THEY 
ARE
 EQUIVALENT. 
ANOTHER VERY POWERFUL   
APPLICATION
 OF STRUCTURAL OR   LAYOUT 
MATCHING
 IS MONITORING   AND TESTING 
DYNAMIC
 APPLICATIONS  APPLICATIONS. 
SO IN THIS CASE, WE HAVE THE   
YAHOO!
 WEB SITE.  AND THE   SCREENSHOT
 AND
 THE BASELINE WERE   TAKEN IN A 
24-HOUR
 DIFFERENCE.    YOU CAN SEE HOW 
DIFFERENT
 THE   IMAGES ARE AND THE 
ARTICLES.
  BUT STILL, STRUCTURALLY, THEY 
  ARE
 EQUIVALENT, AND NO   DIFFERENCE
 IS
 REPORTED. 
IF I WOULD CHANGE THIS TO A MORE

   ALL
 THE DYNAMIC PARTS ARE   
HIGHLIGHTED
 AND THE FIXED ONES   AREN'T. 
BUT IF I WOULD DO PIXEL-TO-PIXEL
  COMPARISON ON THIS PAGE, YOU 
CAN
   SEE THAT ACTUALLY EVERYTHING 
IS
   HILTD   HIGHLIGHTED.  AND THE
 REASON
 IS   EVERYTHING HERE IS 
DIFFERENT,
   ONLY WE CANNOT SEE IT.  AND  
 STRICT
 MATCHING IS POWERFUL   ENOUGH 
TO TAKE
 CARE OF ALL OF   THAT. 
BACK TO THE SLIDES.OKAY.  TAKE 
NUMBER 3.    BASELINE 
MAINTENANCE
 SHOULD   BE CODELESS.  IN THE 
MAJORITY
   OF CASES, MAINTAINING THE   
BASELINE
 INVOLVES LOOKING AT   THE 
SCREEN SHOT
 AND CLICKING   A BUTTON TO 
APPROVE
 IT AS A   BASELINE.  IN SOME 
RARE
   SITUATIONS, YOU ALSO NEED TO 
  MARK
 ONE OR MORE REGIONS ON   THAT 
BASELINE
 THAT ARE   DYNAMIC AND YOU 
DON'T WANT
   THEM TO BE MATCHED DURING   
IMAGE
 COMPARISON. 
SO ACTUALLY THERE IS NO REAL   
VALUE
 OR BENEFIT TO DOING   THIS KIND
 OF
 MAINTENANCE IN   CODE.  ON THE 
OTHER
HAND, IF   YOU DO IT IN A 
CODELESS
 WAY,   THERE'S A HUGE ADVANTAGE
.
  FIRST, EVERYONE IN YOUR TEAM  
 CAN
 DO IT, EVEN THOSE MEMBERS   OF 
YOUR
 TEAM THAT DON'T KNOW   HOW TO 
CODE.
MORE IMPORTANTLY, THEY CAN DO   
IT
 IMMEDIATELY WHEN THEY SEE   THE
 CHANGE.
SO JUST THINK   ABOUT A HUGE 
DIFFERENCE
 IF   YOU HAVE HUNDREDS OF 
BASELINE
   IMAGES TO MAINTAIN AND WHEN  
 YOU
 SEE A DIFFERENCE, INSTEAD   OF 
JUST
 CLICKING A BUTTON AND   ACCEPT
ING
 IT, YOU NEED TO   OPEN UP AN ID
E,
 FIND THE TEST   CODE RELATED, 
CHANGE
 THE CODE   THERE AND MAKING 
SURE YOU
   DON'T INTRODUCE NEW BUGS OR  
 EVEN
 WORSE FIND THE GUY   
RESPONSIBLE FOR
 A TEST, OPEN   A TICKET FOR HIM
 TO
 FIX THE   TEST.  IT COULD BE A 
  DIFFERENCE
 OF HOURS AND HOURS   OF WORK 
FOR EVERY
 TEST RUN. 
THERE'S ANOTHER MINI TIP HERE   
THAT'S
 A BIT COUNTERINTUITIVE  
COUNTERINTUITIVE,
 AND IT IS   TO PREFER FULL PAGE
   VALIDATION
 TO AVOID ELEMENT   SPECIFIC 
VALIDATION.
IT IS   PREFERABLE TO ALLOW YOU 
TO
   AVOID ELEMENT LOCATEERS IN   
CODE
 THAT TEND TO BREAK WHEN   THE 
UI CHANGES.
TIP NUMBER 4, MAINTAIN AT THE   
TEST
 SUITE LEVEL RATHER THAN   AT 
THE TEST
 LEVEL.  NOW, THIS   SEEMS A BIT
 TRIVIAL.
BUT   ACTUALLY IT'S A VERY   
IMPORTANT
 TIP.  THERE ARE   SITUATIONS 
WITH
 VISUAL   TESTING WHERE THERE IS
 ONE
   BUG OR ONE CHANGE IN THE   
SYSTEM
 OR VERY FEW CHANGES   THAT ARE 
CAPTUREED
 BY MULTIPLE   CHECKPOINTS 
ACROSS MANY,
 MANY  MANY, MANY OF YOUR TESTS.
  JUST THINK HOW FRUSTRATEING IT
   WOULD
 BE IF YOU WOULD HAVE A   BUILD 
THAT
 FAILS AND THEIR   REPORT WOULD 
SHOW
 YOU 200   TEST THAT IS HAVE 
FAILED
 AND   NOW YOU HAVE TO GO OVER 
ONE
   BY ONE CHOOSEING THE FIRST   
TEST,
 LOOKING AT THE   DIFFERENCE, RE
SERVEING
 THEM,   GOING BACK TO THE LIST,
   LOOKING
 AT THE NEXT TEST AND   SO ON 
AND SO
 FORTH. 
WHAT IS MUCH PREFERABLE IS   
JUST TO
 SEE ALL THE CHANGES   THAT 
HAPPENED
 DURING THAT   BUILD AND 
IMMEDIATELY
 HAVE   THE ABILITY TO RESOLVE 
THEM
   AND COMPLETELY IGNORE THE   
TESTS.
IN FACT, WHAT YOU   WOULD REALLY
 WANT
 TO HAVE IS   THE ABILITY TO SEE
 ONLY
 THE   UNIQUE CHANGES AND NOT 
ALL OF
   THEIR OCCURRENCES.  AND THIS 
  LEADS
 US TO THE FINAL TIP   WHICH IS 
AUTOMATE
 YOUR   MAINTENANCE.  AND IN 
ORDER
 TO   EXPLAIN TO YOU WHAT 
AUTOMATE
   THE MAINTENANCE MEANS, I WILL
   SHOW
 YOU ANOTHER DEMO WITH   
APPLITOOLS
 EYES. 
ANOTHER DEMO.
  SO FOR THE   PURPOSE
 OF THIS DEMO, I   PREPARE A 
SMALL
 TEST SUITE   FOR THE GTAC WEB 
SITE.
AND I   RAN IT.  I CREATEED A 
BASELINE
  BASELINE.  I SIMULATEED THE   
DIFFERENCE,
 AND THEN I RUN IT   AGAIN.  AND
 LET'S
 SEE THE   RESULTS. 
SO IN THIS CASE, WE SEE THAT   
THE
 TEST SUITES OR BATCHES WE   
CALL IT
 IS CALLED GTAC.  IT   RAN AND 
IT APPEARS
 AS RED   MEANING THAT IT FOUND 
  DIFFERENCES.
A SMALL SUMMARY   HERE TELLS US 
THAT
 THERE WERE   28 TESTS THERE.  
THEY
 COVERED   THREE ENVIRONMENTS.  
THOSE
   WOULD BE IE, FIREFOX AND   
CHROME
 ON A WINDOWS MACHINE.    THREE 
FORM
 FACTORS THAT   CORRESPONDED TO 
THREE
 LAYOUT   MODES THAT THE WEB 
SITE 
  SUPPORTS.  IT'S A RESPONSIVE  
 WEB
 SITE.  IN TOTAL, WE HAD   91 
CHECKPOINTS
 THAT ALL OF   THEM FOUND 
DIFFERENCES.

IMAGE,
 CLICK THE RADAR AND   SEE AND 
WE SEE
 WE HAVE A   SMALL DIFFERENCE 
HERE
 AT THE   FOOTER.  LET'S ZOOM IN
 AND
   SEE WHAT WE FOUND.  WE TOGGLE
  TOGGLED
 BETWEEN THE IMAGES   AND WE SEE
 THAT
 WE HAVE A   PLUS SYMBOL CHANGE 
TO
 A MINUS  MINUS.  SO LET'S 
ASSUME FOR
   THE -- 
[ LAUGHTER ] 
LET'S ASSUME FOR THE SAKE OF   
THE
 DEMO THAT THIS IS NOT A   BUG 
BUT
 ACTUALLY IT'S A RE  REBRANDING 
OF
 THE PRODUCT. 
[ LAUGHTER ]

 BUT
 BEFORE WE DO, LET'S LOOK   AT 
THE
 OTHER IMAGES.  SO WE   LOOK AT 
THIS
 ONE, AND, OH,   IT'S THE SAME 
PLACE.
IT'S   PROBABLY THE SAME CHANGE,
   RIGHT?
OOPS, LET ME GO BACK HERE. 
AND THIS ONE PROBABLY THE   SAME
.
AND THIS ONE AT THE   BOTTOM, 
AGAIN,
 THE SAME.  SO   IT MAKES SENSE,
 RIGHT?
WE   JUST CHANGE THE NAME OF THE
   PRODUCT,
 IT PROBABLY APPEARS   IN ALL 
THE IMAGES.
SO WE ARE   REALLY TEMPTED TO 
CLICK
 THIS   BUTTON THAT SAYS &quot;ACCEPT
 ALL&quot;
  ALL.&quot;  I'M NOT GOING TO DO   
THAT.
I'M GOING TO CLICK ON   ANOTHER 
BUTTON.
AND I'LL   EXPLAIN WHY I'M NOT 
CLICKING
   THAT BUTTON.  &quot;ACCEPT ALL&quot;   
BASICALLY,
 MEANS OVERWRITE   THE BASELINE 
WITH
 ALL THE   SCREEN SHOTS THAT I 
FOUND
 AND   ALL THE VISUALIZATION 
TOOLS
   ALLOW TO YOU DO THAT.    
ACTUALLY
 IT'S A VERY   DANGEROUS THING 
TO DO
 BECAUSE   WHAT YOU ARE ACTUALLY
 DOING
   IS SKIPPING MAINTENANCE.  SO 
  YOU
 COULD INTRODUCE BUGS,   REAL 
BUGS,
 INTO YOUR BASELINE   AND THEN 
PREVENT
 THE TOOL   FROM FINDING THEM 
LATER
 ON. 
SO IF I WAS TO FREE TO CHOOSE   
THE
 NAME FOR THIS BUTTON, IT   
WOULD BE
 &quot;SKIP MAINTENANCE&quot;   AND THE 
TOOL
 TIP WOULD BE &quot;  &quot;I'M TOO LAZY 
TO DO
 MY JOB&quot;.&quot; 
[ LAUGHTER ] 
BASICALLY, WHAT I JUST DID IS   
I ASKED
 THIS TOOL TO DO THIS   
MAINTENANCE
 OPERATION FOR ME   IN AN 
AUTOMATEED
 WAY.  I ASKED   IT TO FIND ALL 
THE
 SIMILAR   DIFFERENCES AND THE 
RESULT
 IS   THAT FROM THIS BUILD THAT 
HAD
   ALL THESE FAILURES, I ONLY   
HAVE
 TWO IMAGES TO LOOK AT   RIGHT 
NOW.
90 OF THE   CHECKPOINTS HAVE 
EXACTLY
 THE   SAME CHANGE, ALTHOUGH 
THEY 
  RAN ON DIFFERENT BROWSERS AND 
  THEY
 RAN IN DIFFERENT LAYOUT   MODES
 AND
 FORM FACTORS.    STILL A PLUS 
CHANGEED
 TO A   MINUS AND THAT'S IT.  SO
 I
   CAN JUST GO AHEAD AND APPROVE
   THAT
 BECAUSE THAT'S WHAT I   WANT TO
 DO.

 LET'S
 SEE WHAT WE FOUND   HERE.  AND,
 ALTHOUGH
 IT'S   OBJECTIVE, I THINK THAT 
YOU
   CAN AGREE WITH ME THAT WE   
FOUND
 A BUG. 
[ LAUGHTER ] 
AND SO WE WON'T ACCEPT IT BUT   
REJECT
 IT.  AND WITH THAT,   WE'RE 
DONE MAINTAINING
 THE   TEST RUN. 
SO THERE ARE MANY   
OPPORTUNITIES WITH
 VISUAL   TESTING TO DO THIS 
TYPE OF
   AUTOMATIC MAINTENANCE.  AS   
YOU
 CAN REALIZE, IT GOES A   VERY 
LONG
 WAY IN ALLOWING YOU   TO SCALE 
UP
 YOUR TEST WITHOUT   INTRODUCING
 MORE
 OVERHEAD TO   YOUR MAINTENANCE.
  AND
 WITH   THIS, I CONCLUDE MY TALK
 AND
   I HOPE THAT YOU LEARNED   
SOMETHING
 AND ENJOYED IT.    AND I WILL 
BE HAPPY
 TO TAKE   YOUR QUESTIONS NOW. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU,   
ADAM.
YOU HAVE EARNED YOUR   FREE 
LUNCH BY
 FINDING BUGS ON   OUR WEB SITE.
[ LAUGHTER ] 
SO FOR THE FIRST QUESTION,   HOW
 DOES
 YOUR BASELINE   STRATEGY WORK 
IN A
 CONTINUEOUS   BUILD AND RELEASE
 MOLD?
&amp;gt;&amp;gt;Apple Chow:  SO, BASICALLY,

NOTHING
 TO DO WITH CONTINUEOUS   
RELEASE OF
 BUILD MODEL.  YOU   RUN THE 
TEST,
 THERE ARE   FAILURES.  YOU LOOK
 AT
 THEM.    IF THERE'S A FAILURE, 
YOU
   DON'T RELEASE IMMEDIATELY,   
YOU
 WAIT UNTIL SOMEONE   APPROVES 
IT.
SO IT'S,   BASICALLY, -- IT FITS
 RIGHT
 IN   THERE.  AND IT'S ACTUALLY 
THE
   SAFE WAY TO DO CONTINUEOUS   
DEPLOYMENT
 BECAUSE INSTEAD OF   JUST 
RELEASEING
 STUFF WITHOUT   LOOKING AT IT, 
YOU
 KNOW WHEN   THERE'S A CHANGE. 
&amp;gt;&amp;gt;Yvette Nameth:  HOW DO YOU   
MINIMIZE
 THE COST OF WRITING   AND 
MAINTAINING
 A NEW SET OF   TESTS? 
&amp;gt;&amp;gt;Adam Carmi:  SO THERE ARE   
DIFFERENT
 STRATEGYIES   DIFFERENT TEAMS 
USE
 TO DO   VISUAL TESTING.  SOME 
WOULD
   WRITE NEW TESTS, VERY SIMPLE 
  TESTS
 TO JUST BROWSE THROUGH   THE 
APPLICATION.
IF IT'S A   WEB SITE, USUALLY 
THEY'LL
   JUST PUT IN A SET OF URLs   
OF
 ONE -- MAYBE IN A FEW LINE  
LINES
 OF CODE AND IT WILL   JUST GO 
OVER
 THE ENTIRE SET   OF PAGES ON 
ALL THE
 DIFFERENT   EXECUTION 
ENVIRONMENTS.
AND   YOU'RE DONE. 
OTHER TEAMS WILL TAKE THEIR   
EXISTING
 TEST AND JUST ADD   VALIDATION 
POINTS
 WHERE THEY   WANT TO.  AND 
OTHERS
 WILL GO   TO THEIR TEST 
INFRASTRUCTURE.
  USUALLY YOU HAVE SOME KIND OF 
  OBSTRUCTION
 AROUND THE TEST   DRIVER, AND 
YOU
 WOULD JUST   HOOK IT INTO SOME 
OBSERVATION
   THAT IS WOULD AUTOMATICALLY  
 TRIGGER
 VALIDATION POINTS.    SO ONE OF
 THE
 BEST PRACTICES   IS TO DO A 
VALIDATION
 POINT   IMMEDIATELY AFTER YOU 
CHANGE
   TO A DIFFERENT URL.  AND THE 
  OTHER
 ONE IS JUST BEFORE YOU   CLICK 
A BUTTON
 OR A LINK.  SO   THAT COVERS, 
LIKE,
 80% OF   EVERYTHING YOU NEED.  
AND
 IT   IS JUST CENTRALIZEED AT 
ONE 
  PLACE AND IT IS DONE AND YOU  
 ARE
 DONE WITH WHATEVER TEST   YOU 
HAVE
 RUNNING. 
&amp;gt;&amp;gt;Yvette Nameth:  HOW WOULD   
YOU USE
 THE TOOL TO TEST A   WEB SITE 
OR MOBILE
 APP THAT   HAS NOT YET LAUNCHED
?
CAN IT   BE RUN LOCALLY? 
&amp;gt;&amp;gt;Adam Carmi:  BASICALLY, IF   
YOU
 ARE ASKING -- IF THE   QUESTION
 IS
 SPECIFIC FOR   APPLITOOLS OR 
FOR ANY
 OTHER   TOOLS?  WHAT'S 
INTERESTING?
  OKAY.  SO, BASICALLY, -- 
&amp;gt;&amp;gt;Yvette Nameth:  YOU PICK. 
&amp;gt;&amp;gt;Adam Carmi:  THE OPEN   SOURCE
 TOOLS,
 ALL OF THEM,   THEY RUN LOCALLY
 SO
 THERE'S   NO PROBLEM USING THEM
 LOCALLY
  LOCALLY.  WITH APPLITOOLS   
SPECIFIC,
 WE SUPPORT ON   (INDISCERNIBLE)
 DEPLOYMENTS
   AND ALSO PRIVATE CLOUD AND   
PUBLIC
 CLOUD DEPLOYMENTS.    BUT,
ANYWAY,
 THE TEST ALWAYS   RUNS BEHIND 
THE
 FIREWALL.    THERE IS NO NEED 
TO OPEN
 OUT   FROM OUTSIDE TO YOUR 
INTERNAL
   ORGANIZATION.  WE USED   
SELENIUM
 AND WE SEND THEM OUT  OUTSIDE. 
 SO
 IF YOU CAN   GOOGLE OUT OF YOUR
 TEST
   MACHINE OUT OF YOUR MACHINE  
 THAT
 IS RUNNING YOUR TEST,   THEN 
YOU CAN
 WORK WITH THE   SERVICE.  YOU 
DON'T
 NEED --   IT CAN BE BEHIND THE 
FIREWALL
  FIREWALL. 
&amp;gt;&amp;gt;Yvette Nameth: 
 CHANGING   ORDER.
WHAT'S YOUR DEV ENGINE?  IS   IT
 DIFF
 ENGINE?  IS   IT PUBLIC? 
&amp;gt;&amp;gt;Adam Carmi:  THE DIFF   ENGINE
 IS
 SOMETHING WE HAVE   BEEN 
WORKING ON
 FOR MORE THAN   THREE YEARS.  
IT IS
 NOT   PUBLIC.  THAT'S OUR 
SECRET.
  WE DON'T PATENT IT SO WE NEED 
  NEED
 TO EXPOSE IT.  IT HAS --   IT'S
 NOT
 OPEN SOURCE AND   THERE'S 
NOTHING
 OUT THERE   THAT WE BUILD ON.  
IT'S
   COMPLETELY FROM SCRATCH TO   
HANDLE
 THIS TYPE OF WORK. 
&amp;gt;&amp;gt;Yvette Nameth:  DO YOU USE   
THESE
 TOOLS AS ACCEPTANCE   TESTS 
RATHER
 THAN AS TESTS TO   FIND BUGS? 
&amp;gt;&amp;gt;Adam Carmi:  USING THIS   TOOL
 AS
 AN ACCEPTANCE TEST IS   A VERY,
 VERY
 EFFECTIVE WAY TO   WORK WITH 
THE TOOL,
 BY THE   WAY,.  IF YOU DON'T 
WANT
 TO   BOTHER YOURSELF WITH EACH 
  BUILD
 AND UPDATE THE CHANGES,   
ALTHOUGH
 THIS BECOMES AN   AMAZING 
COLLABORATION
 TOOL IN   THE TEAM BECAUSE 
IMMEDIATELY
   YOU SEE EVERYTHING THAT   
CHANGE,
 NOT BUGS.  EVEN IF   YOUR PM 
DOESN'T
 LIKE THE   COLOR OF THE BUTTON 
THAT
 THE   DEVELOPER JUST CHANGED A 
  MINUTE
 AGO OR TEN MINUTES AGO  AGO, WE
 CAN
 IMMEDIATELY GIVE   THEM THIS 
FEEDBACK.
BUT IF YOU DON'T WANT TO DO   
THAT,
 THEN YOU CAN JUST USE   IT AS 
AN ACCEPTANCE
 TEST.    RUN IT ONCE BEFORE 
RELEASE
   INTO PRODUCTION OR USE YOUR  
 STAGING
 ENVIRONMENT AS A   DYNAMIC 
BASELINE
 TO MATCH   YOUR NEW CANDIDATE 
TO TEST
 IT  IT, MAKE SURE THERE AREN'T 
UN
  UNEXPECTED CHANGES.  THAT   
WOULD
 BE GREAT WAY TO DO IT. 
SO FOR ACCEPTANCE TESTING,   
THAT'S
 GREAT.  WHAT WAS THE   OTHER 
ONE?
I FORGOT?  WHERE   IS IT? 
&amp;gt;&amp;gt;Yvette Nameth:  I DON'T   KNOW
 THAT
 THERE WAS MORE TO   THAT 
QUESTION.

WAS.
I FEEL THERE WAS BUT I   DON'T 
REMEMBER.
&amp;gt;&amp;gt;Yvette Nameth:  SORRY. 
&amp;gt;&amp;gt;Adam Carmi:  OKAY, OKAY, NO   
PROBLEM.
&amp;gt;&amp;gt;Yvette Nameth:  WHAT ABOUT   
FALSE
 POSITIVES?  FOR EXAMPLE  
EXAMPLE,
 THINGS ARE EXPECTED   TO BE 
DIFFERENT
 VISUALLY   ACROSS RUNS OR 
BROWSERS
 OR   PLATFORMS. 
&amp;gt;&amp;gt;Adam Carmi:  THEN YOU CAN   
JUST
 HAVE A DIFFERENT   BASELINE FOR
 EACH
 OF THEM.    SO THAT'S FINE, NO 
PROBLEM.
&amp;gt;&amp;gt;Yvette Nameth:  COOL.  AND   
WE ARE
 OUT OF TIME.  SO THANK   YOU, 
ADAM.

WELCOME.
THANK YOU. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  SO NEXT WE   
HAVE
 PUNEET TALKING ABOUT   TESTING 
INTEGRATION
 BETWEEN   TWITTER SERVICES WHEN
 HE
 IS   READY.

RIGHT.
SO OCTOBER 8th LAST   YEAR 
TWITTER
 SIGNUP WAS BROKE  BROKEN FOR 
ALMOST
 TWO DAYS,   STOCK WAS DOWN 
ALMOST
 5%.    HOW MANY PEOPLE REMEMBER
 THAT
  THAT? 
[ LAUGHTER ] 
YEAH.  SO FOR THE FOLKS WHO   
RAISED
 THEIR HANDS, THAT   ACTUALLY 
NEVER
 HAPPENED AND   THIS IS THE 
REASON
 WHY IT   DIDN'T HAPPEN. 
[ LAUGHTER ] 
SORRY. 
[ APPLAUSE ] 
ALL RIGHT.  SO I ORIGINALLY   
CAME
 FROM PLATFORM   ENGINEERING AND
 THEN
 STARTED   REALIZEING THAT WE 
HAD BIGGER
   PROBLEMS TO SOLVE AND ENDED  
 UP
 SPINNING UP A NEW TEAM   CALLED
 FRAMEWORKS
 AND RUN OF   THE FIRST THINGS 
WE BUILT
 WAS   THIS TOOL.  AND THE 
PROBLEM
   WE WERE TRYING TO SOLVE WITH 
  THIS
 TOOL WAS THAT, YOU KNOW,   HE 
JUST
 REFACTORRED YOUR CODE  CODE.  
WE WERE
 IN THE PROCESS   OF MIGRATEING 
OVER
 FROM A HUGE   MONOLITHIC RUBY 
APP
 TO MICRO  MICROSERVICES OR 
INTER  INTERARCHITECTURE.
SO LOTS   OF OPPORTUNITIES TO 
BREAK
   THINGS. 
AND AT THE END OF A REFACTOR,   
HOW
 DO YOU KNOW THAT YOU   HAVEN'T 
BROKEEN
 SOMETHING? 
IF YOU ARE A SRE, ASIDE FROM   
LIABILITY
 ENGINEER, YOU ARE   IN DEV OPS,
 YOU
 HAVE AN EVEN   BIGGER PROBLEM 
BECAUSE
 YOU   HAVE NO UNDERSTANDING 
ABOUT
   THE CODE THAT'S ABOUT TO BE  
 DEPLOYED
 AND YOU ARE IN THE   POSITION 
TO MAKE
 A CODE AS TO   WHETHER OR NOT A
 BUILD
 IS   GOOD ENOUGH TO PUT OUT 
INTO 
  PRODUCTION AND YOU TRY TO   
MITIGATION
 THAT RISK BY   CONSENSUSSING 
AND DOING
 DO   CANARYING AND ALL SORTS OF
   FUN
 THINGS.  BUT YOU WANT TO   GET 
TO
 CONTINUEOUS CONTINUEOUS DEPLOY 
AND
   THAT ENDANGERED SPECIES UP   
BEING
 A HARD PROBLEM. 
OUR NATURAL FIRST LINE OF   
DEFENSE
 COMES OUT TO BE UNIT   TESTS 
AND COMPONENT
 TESTS.    AND I PERSONALLY HAVE
 TO
 MEEK   A CONFESSION WHAT BETTER
   AUDIENCE
 THAN THIS ONE TO   MAKE THIS 
CONFESSION,
 THAT I   HATE WRITING TESTS. 
[ LAUGHTER ] 
AND THE REASON IS THE   
FOLLOWING.
IF YOU LOOK AT   UNIT TESTS, IT 
CAN
 OFTEN TAKE   YOU MORE TIME TO 
WRITE
 GOOD   UNIT TESTS THAN WRITE 
THE 
  CODE THAT'S BEING TESTED.    
LET'S
 SAY YOUR METHOD HAS   FIVE 
POSSIBLE
 CODE PATHS AND   YOU ARE 
INTERESTED
 IN 100%   PATH COVERAGE, THEN 
ONE
 TEST   WILL GET YOU 20% 
COVERAGE.
  YOU WRITE FIVE TESTS AND   
YOU'RE
 DONE. 
GREAT.  I MEAN, I CAN WRITE   
FIVE
 TESTS.  THAT'S NOT A   PROBLEM.
  BUT
 FIVE TESTS FOR   EVERY METHOD, 
EH ...

AMBITIOUS
 AND YOU SAY I WANT   COMPONENT 
TEST
 COVERAGE AND   THIS EXAMPLE, I 
HAVE
 FIVE   METHODS IN MY SERVICE.  
SO
 MY   COMPONENT IS A MICRO
SERVICE 
  AND THE REQUEST PATH HAS FIVE 
  METHODS
 IN IT.  AND EACH   METHOD HAS 
FIVE
 INDEPENDENT   CODE PATHS.  SO 
THIS
 WORKS   OUT TO ABOUT 15,000   
INDEPENDENT
 CODE PATHS.  WHO   HERE HAS 
WRITTEN
 15,000 TESTS   FOR ANYTHING? 
[ LAUGHTER ] 
RIGHT? 
WOW.!  I HAVE A LOT OF   RESPECT
 FOR
 YOU, SIR. 
&amp;gt;&amp;gt;&amp;gt; OUR TEAM HAS BILLIONS OF   
TEST
 CASES. 
&amp;gt;&amp;gt;Puneet Khanduri:  RIGHT,   
RIGHT.
QUEUE GO DOUGHS TO   YOU GUYS 
DOUGH
KUDOS TO YOU GUYS. 
THE THING TO BE COGNIZANT OF   
HERE
 IS AS THE COMPLEXITY OF   THE 
SYSTEM
 THAT YOU'RE TRYING   TO TEST 
GROWS --
 THE, THE RELATIVE   IMPACT OF 
EVERY
 HANDWRITTEN   TEST IS SMALLER 
AND
 SMALLER.    IF I TAKE THE 
EXAMPLE
 OF ONE   OF OUR SERVICES IN 
PRODUCTION
   AND I USE THE PRODUCTION   
CLUSTER
 THAT'S RUNNING THAT   SERVICE 
JUST
 TO RUN TESTS, IT   WOULD TAKE 
ABOUT
 A THOUSAND   YEARS FOR THAT 
CLUSTER
 TO   FINISH RUNNING ALL THE 
TESTS
   COVERING EVERY SINGLE   
POSSIBLE
 CODE PATHS,   MEANWHILE THE 
LIFE CYCLE
 OF   THAT SOFTWARE IS BARELY A 
  WEEK
 BECAUSE THAT'S HOW LONG   IT 
WILL
 BE BEFORE THE NEXT   VERSION OF
 THE
 CODE WILL GET   DEPLOYED. 
SO WE NEED TO BE COGNIZANT OF   
THE
 IMPACT THAT WE CAN MAKE   AS 
COMPLEXITY
 GROWS.  AND IF   YOU DON'T 
TRUST ME,
 HOPEFULLY   YOU TRUST THIS GUY.
  SO
   WHAT'S OUR APPROACH TO   
AUTOMATICALLY
 TRYING TO FIND   REGRESSIONS 
AND FIGURING
 OUT   WHETHER WE HAVE BROKEEN  
 SOMETHING?

YOU
 LOOK AT A TEST, IT'S   FINDING 
A WAY
 TO TRIGGER A   BEHAVIOR, RIGHT?
  WHICH
 IS   PROVIDEING A TEST INPUT.  
AND
   WHAT BETTER WAY TO TRIGGER   
THE
 BEHAVIOR THAT YOU'RE   
INTERESTED
 IN THAN TO USE   PRODUCTION 
TRAFFIC
 FOR MICRO  MICROSERVICES.  WE 
STARTED
   USING PRODUCTION TRAFFIC TO  
 DRIVE
 THE BEHAVIOR OF UN  UNDEPLOYED 
CODE.
AND THAT,   BASICALLY, MADE SURE
 THAT
 WE   WERE EXERCISING THE CODE  
 PATHS
 THAT WERE EVENTUALLY   GOING TO
 BE
 EXERCISED IN   PRODUCTION.  WE 
PREFER
 THIS   TO RANDOMIZEED TESTING 
OR 
  OTHER KINDS OF TESTING   
BECAUSE WITH
 THOSE APPROACHES  APPROACHES, 
WHILE
 YOU MIGHT   DIFFERENT KINDS OF 
COVERAGE
   AND WHATNOT, THERE ARE A LOT 
  OF
 DATA-DRIVEN THINGS IN YOUR   
CODE
 WHICH ONLY HAPPEN TO   SURFACE 
WHEN
 YOU GET THE RIDE   SEQUENCE OF 
CHARACTERS
 AND   WHATNOT THAT ARE EASY TO 
FIND
   IN PRODUCTION TRAFFIC THAN   
RANDOMLY
 GENERATED STRINGS   AND THINGS 
LIKE
 THAT. 
SO USING PRODUCTION TRAFFIC   TO
 DRIVE
 THE BEHAVIOR OF UN  UNEMPLOYED 
CODE
 TURNED OUT TO   BE A GOOD 
APPROACH.
AND THEN   THE SECOND PART IS 
ONCE
   YOU'VE HAD YOUR INTERACTION  
 WITH
 THE UNDEPLOYED CODE,   THEN YOU
 WANT
 TO ASSERT THAT   THE BEHAVIOR 
WAS
 CORRECT.  SO   HOW DO YOU DO 
THAT?
AND YOU   MAKE THE ASSUMPTION 
THAT
 THE   STUFF THAT'S CURRENTLY 
DEPLOY
  DEPLOYED IN PRODUCTION ISN'T  
 BROKEEN.
SOMETIMES THAT CAN   BE THE 
WRONG ASSUMPTION,
 BUT   MOST OF THE TIMES IF   
PRODUCTION
 IS ON FIRE, YOU   FIND OUT 
PRETTY
 SOON.  AND IF   IT'S NOT, THEN 
YOU
 CAN ASSUME   THAT THE STUFF IN 
PRODUCTION
   IS GOOD. 
BUT THERE IS A PROBLEM.    
YOU'RE USING
 THE SAME REQUEST  REQUEST.  
YOU'RE
 SENDING IT   TO THE NEW CODE 
AND TO
 THE   OLD CODE AND THEN YOU'RE 
  COMPARING
 THE RESPONSES THAT   ARE COMING
 BACK
 FROM THESE   TWO DEPLOYMENTS. 
AND IN THIS RESPONSE YOU   MIGHT
 HAVE
 A LOT OF FIELDS,   DEEPLY NEST
ED FIELDS.
AND   SOME OF THESE FIELDS MIGHT
 BE
   INHERENTLY NOISEY.  SO HOW DO
   YOU
 DEAL WITH THEM, RIGHT?    YOUR 
NOISE
 COULD BE, FOR   EXAMPLE, FROM 
SERVEER
   GENERATED TIME STAMPS BECAUSE
   THE
 CLOCK IS NEVER GOING TO   
EXACTLY
 THE SAME ACROSS TWO   DIFFERENT
 MACHINES.
IT'S NOT   THE SOFTWARE'S FAULT.
  IT'S
   JUST A DIFFERENT CLOCK. 
YOU COULD HAVE RANDOM NUMBER   
GENERATEORS
 AND YOU MAY NOT   HAVE SET THE 
SEED
 IN WHICH   CASE YOU HAVE 
ANOTHER SOURCE
   OF NON-DETERMINEISM.  YOU   
MIGHT
 HAVE LIVE DATA FOR DOWN  
DOWNSTREAM
 SERVICES THAT   YOU'RE USING 
FOR BOTH
 THE   ENVIRONMENTS AND IF THAT 
DOWN
  DOWNSTREAM DATA IS CHANGING   
RAPIDLY,
 THEN THAT CAN BE YET   ANOTHER 
SOURCE
 OF NON-  NON-DETERMINEISM 
BECAUSE
 YOU   CAN HAVE A WRITE-IN 
BETWEEN
   THE TWO READS THAT THE TWO   
LIVE
 AND UNDEPLOYED VERSIONS   DO. 
 SO HERE'S THE
 BIG IDEA WITH   DIFFY, WHERE, 
YOU
KNOW, ONCE YOU   HAVE PRODUCTION
 TRAFFIC
 THAT   YOU'RE DRIVING THROUGH 
THE
 DIFFY   PROXY, IT WILL MULTI
CAST THIS
   TRAFFIC TO NOT -- NOT JUST TO
   THE
 OLD CODE AND TO THE NEW CODE  
CODE,
 BUT TWO VERSIONS OF THE   OLD 
CODE.
SO IN THIS DIAGRAM, YOU SEE A   
CANDIDATE
 AT THE TOP.  THIS IS   THE NEW 
CODE;
 RIGHT?  THE CODE   THAT NEEDS 
TESTING.

TWO
 DEPLOYMENTS OF THE EXACT   SAME
 KNOWN
 GOOD CODE, WHICH ALSO   HAPPENS
 TO
 BE DEPLOYED IN   PRODUCTION.  
SO ALL
 OF THESE   THREE INSTANCES ARE 
RUNNING
 IN   MY ISOLATED STAGING 
ENVIRONMENT.
THEN WHEN THE TRAFFIC HITS THESE
  INSTANCES AND WE GET THE   
RESPONSES
 BACK, WE DO A   COMPARISON 
BETWEEN
 THE CANDIDATE   AND PRIMARY.  
SO THAT'S
 A   COMPARISON BETWEEN THE NEW 
CODE
   AND THE OLD CODE, WHICH GIVES
 US
   A RAW SET OF DIFFERENCES; 
RIGHT?

DIFFERENCES
 HAS A LOT OF NOISE   IN IT; 
RIGHT?
AND THEN BY   COMPARING TO THE 
-- BY
 COMPARING   THE OLD CODE TO 
ITSELF,
 WHICH IS   THE COMPARISON 
THAT'S HAPPENING
   HERE BETWEEN PRIMARY AND   
SECONDARY,
 WE ISOLATE ALL THE   FIELDS 
THAT ARE
 INHERENTLY NOISY  NOISY.  SO 
ANYTHING
 THAT SHOWS   UP AS NOISE HERE 
BETWEEN
 PRIMARY   AND SECONDARY GETS 
SUBTRACTED
   OUT FROM THE RAW DIFFERENCES,
   AND
 YOU GET A FINAL FILTERED SET   
OF
 DIFFERENCES THAT ALLOWS YOU   
TO FOCUS
 IN ON THINGS THAT YOU   SHOULD 
BE
 LOOKING AT AS OPPOSED   TO, YOU
 KNOW,
 TRYING TO FIND A   NEEDLE IN A 
HAYSTACK.
AND WITH THAT, LET ME SWITCH   
OVER
 TO THE DEMO. 
SO AS I SHOWED YOU IN THAT   
DIAGRAM,
 WE NEED THREE INSTANCES  
INSTANCES.
SO THE FIRST ONE UP   HERE, 
RUNNING
 ON PORT 9000 IS MY   PRIMARY.  
THE
 SECOND ONE HERE,   RUNNING ON 
PORT
 9100, IS MY   SECONDARY.  AND 
THEN
 MY   CANDIDATE IS RUNNING ON 
THIS
   PORT 9200.  RIGHT? 
SO LET ME LOOK AT MY DIFFY   
CONFIGURATION.


91  9100.
  GREAT.

OKAY.  SO I HAVE MY DIFFY   
INSTANCE
 DEPLOYED NOW.  AND NOT   DOING 
ANYTHING
 INTERESTING.  SO   LET'S SEND 
SOME
 TRAFFIC TO IT. 
AND SINCE I DON'T HAVE A   
PRODUCTION
 TRAFFIC SOURCE, I'M   JUST 
GOING TO
 RUN A BUNCH OF   PEARL COMMANDS
 THAT
 I HAVE IN   THIS SCRIPT HERE.

BUNCH
 OF TRAFFIC TO THIS DIFFY   
INSTANCE.
IT SHOWED UP IN THE   LOGS HERE.
  AND
 THEN YOU CAN   ALSO SEE THAT 
TRAFFIC
 BEING   MULTICAST TO ALL OF 
THESE,
 YOU   KNOW, SERVICE INSTANCES. 
 SO
   LET'S GO BACK TO THE DIFFY   
INSTANCE.
WOW, 100% OF THE   TRAFFIC 
FAILING.
THAT TELLS ME   THAT THIS END 
POINT
 IS CALLED   JSON.  SO LET'S GO 
TAKE
 A LOOK   AT WHAT THESE 
DIFFERENCES
 LOOK   LIKE. 
OKAY.  DATES COMING OUT TO BE   
DIFFERENT.
49 SECONDS, 50   SECONDS.  OKAY.
WHAT ELSE IS DIFFERENT? 
NAMES ARE COMING OUT TO BE   
DIFFERENT.
INTERESTING. 
AND THEN TIME STAMPS ARE COMING 
  OUT
 TO BE DIFFERENT. 
SO NOTICE THAT IT SAYS THAT, YOU

.
  SO THE 100% FAILING HERE IS   
SAYING
 THAT 100% OF THE TIME,   
PRIMARY AND
 CANDIDATE DISAGREE   WITH EACH 
OTHER.
AND THE 100%   NOISE MEANS THAT 
100%
 OF THE   TIME, PRIMARY AND 
SECONDARY
   DISAGREE WITH EACH OTHER. 
NOW, IN THIS SORT OF SITUATION  
 WHERE
 100% OF THE TIME, PRIMARY   IS 
DISAGREEING
 WITH SECONDARY,   YOU CAN BE 
FAIRLY
 CONFIDENT THAT   IT'S NOT YOUR 
CODE'S
 FAULT;   RIGHT?  WHEREAS UP 
HERE,
 IN THE   NAME FIELD, 12% OF THE
 TIME,
   PRIMARY IS DISAGREEING WITH  
 CANDIDATE,
 BUT PRIMARY AND   SECONDARY ARE
 ALWAYS
 AGREEING   WITH EACH OTHER.  SO
 IN
 THIS   SITUATION, YOU CAN BE 
FAIRLY
   CONFIDENT THAT IT IS YOUR 
CODE'S
   FAULT.  RIGHT? 
SO USING THIS PRIMITIVE LOGIC   
AND
 SOME PRIMITIVE STATISTICAL   
ANALYSIS,
 YOU CAN APPLY THIS   AUTO 
EXCLUSION
 LOGIC, AND IT   AUTOMATICALLY 
ELIMINATES,
 YOU   KNOW, THESE OTHER FIELDS 
WHERE
   THE NOISE THRESHOLD IS FAIRLY
   HIGH.
AND IF WE DEEP DIVE INTO ONE OF 
  THESE
 GUYS, WE SEE THAT THE   WORDS 
HERE
 IN THE RESPONSES, THE   NAMES 
IN THE --
 NAME FIELD IN   THE RESPONSES 
ARE
 CAPITALIZED   HERE, WHEREAS 
IT'S LOWERCASE
   HERE.  AND IT'S, YOU KNOW,   
CAPITALIZED
 HERE AND IT'S   LOWERCASEED 
HERE.
SO THAT'S SORT   OF A REGRESSION
 IN
 MY SERVICE.    AND I CAN DEEP 
DIVE
 INTO THE   RESPONSE BY, YOU 
KNOW,
 BLOWING   THIS UP, AND IT GIVES
 ME
 THE   FULL-BLOWN REQUEST THAT 
WAS
 USED   TO TRIGGER THIS BEHAVIOR
, SO
 I   CAN REPRODUCE IT IF I WANT.
  AND
   IT HIGHLIGHTS, YOU KNOW, 
THESE 
  NICE FIELDS FOR ME AND TELLS 
ME 
  EXACTLY WHAT'S DIFFERENT 
ACROSS 
  THE TWO. 
AND THE SORT OF DOGFOODING   
THAT'S
 HAPPENING HERE DIFFING THAT'S  
 HAPPENING
 HERE IS IT'S   RECURSIVELY 
PARSING
 THE DATA   STRUCTURE.  IN THIS 
CASE,
 IT   HAPPENS TO BE JSON, BUT WE
 CAN
   ALSO PARSE THRIFT RESPONSES 
AND
   HTML AND DO THIS SORT OF   
ANALYSIS
 THROUGHOUT THE   STRUCTURE OF 
THE
 RESPONSE.

POINT,
 WE CAN SWITCH OVER TO THE   
MASTER
 DECK AGAIN
. 
GREAT. 
ANY QUESTIONS?


TOP,
 PLEASE.

ALWAYS
 STAY THERE. 
HOW CAN YOU HANDLE SITUATIONS   
WHERE
 PRODUCTION TRAFFIC   CONTAINS 
PRIVATE
 USER DATA?  HOW   CAN YOU DEBUG
? 
&amp;gt;&amp;gt;Puneet Khanduri:  HOW DO YOU  
 HANDLE
 SITUATIONS WHERE   PRODUCTION 
TRAFFIC
 CONTAINS   PRIVATE USER DATA.  
HOW
 CAN YOU   DEBUG? 
SO WHEN PRODUCTION TRAFFIC   
CONTAINS
 PRIVATE USER DATA, FOR   RE
DIRECT
 REQUESTS, WE'RE JUST   ABLE TO 
USE
 PRODUCTION BACK-ENDS  
BACK-ENDS.
AND THE WAY WE'RE   SOURCING 
TRAFFIC
 IS BY   INSTRUMENTING OUR 
PRODUCTION
   CLUSTER.  AND SO THE READS 
ARE 
  FINE, YOU KNOW, AS LONG AS   
THEY'RE
 BACKED WITH PRODUCTION   
BACK-ENDS.
WRITES ARE A BIT MORE   
COMPLICATED.
AND THAT'S WORK IN   PROGRESS.  
I CAN
 TALK A LITTLE   BIT ABOUT IT. 
SO WHAT WE'RE DOING THERE IS,   
NOT
 ONLY ARE WE RECORDING THE   
REQUESTS
 IN PRODUCTION, BUT ALSO   ALL 
THE
 INTERACTIONS WITH THE   
ENVIRONMENT
 FOR THAT REQUEST.    AND SO AS 
A RESULT
 OF THAT, WHAT   YOU END UP 
DOING IS,
 IN YOUR   TEST ENVIRONMENT, 
YOU'RE
 ABLE TO   REPLICATE OR 
DYNAMICALLY
 MOCK   THE BEHAVIOR OF THE 
ENVIRONMENT
   AS IT, YOU KNOW, WAS RECORDED
 IN
   PRODUCTION. 
SO THAT ALLOWS YOU TO DECOUPLE  
 THE
 COMPONENT THAT'S BEING   TESTED
 COMPLETELY
 FROM THE   ENVIRONMENT, AND YOU
 CAN
 DO THIS   SORT OF TESTING IN 
COMPLETE
   ISOLATION WITHOUT HAVING ANY 
  DOWNSTREAM
 DEPENDENCIES. 
&amp;gt;&amp;gt;Yvette Nameth:  HOW DO YOU   
TELL
 DIFFY TO IGNORE EXPECTED   
CHANGES,
 SUCH AS BUG FIXES? 
&amp;gt;&amp;gt;Puneet Khanduri:  GOOD   
QUESTION.
WE DON'T, AND VERY   DELIBERATE
LY SO.

EXPERIMENTED
 WITH THAT EARLIER   ON, AND WE 
FOUND
 THAT GIVING   PEOPLE THE 
ABILITY TO,
 YOU KNOW,   WRITE EXCLUSION 
LOGIC
 THAT, YOU   KNOW, YOU CAN 
IGNORE THESE
   FIELDS CREATES A BLIND SPOT. 
   BECAUSE
 THOSE EXCLUSIONS HAVE A   LIFE 
CYCLE
 OF THEIR OWN.  AND,   YOU KNOW,
 IT
 CREATES A BURDEN OF   
MAINTENANCE
 ON THE SERVICE   OWNERS THAT, 
YOU
KNOW, THEY HAVE   TO ACTIVELY 
MAINTAIN
 THAT LIST,   SO THAT, YOU KNOW,
 IN
 THE NEXT   RELEASE, THEY DON'T 
FORGET
 TO,   YOU KNOW, RETIRE THE 
EXCLUSIONS
   THAT WENT OUT IN THE PREVIOUS
   RELEASE.
AND SO THE WAY OUR AUTOMATIC,   
YOU
KNOW, ARTIFACT PROMOTION   
PROCESS
 IS BEING BUILT IS THAT   IF WE 
DON'T
 FIND ANY REGRESSIONS  
REGRESSIONS,
 WE AUTOMATICALLY   PROMOTE THE 
ARTIFACT.
BUT IF WE   FIND ANY REGRESSIONS
, WE
 REQUIRE   A HUMAN TO SIGN OFF 
ON THOSE
   REGRESSIONS AND SAY THAT, YES
, 
  THESE CHANGES ARE FINE TO GO  
 INTO
 PRODUCTION.  BUT, YOU KNOW,   
FROM
 DIFFY'S POINT OF VIEW, WE   
DON'T,
 YOU KNOW, GIVE THEM THE   
RESPONSIBILITY
 TO MAINTAIN A   LIST OF 
EXCLUSIONS
 OR ANYTHING   LIKE THAT. 
&amp;gt;&amp;gt;Yvette Nameth:  COOL.  WE HAVE

HOW DO YOU MOCK THE DATA   
BACK-END
 SUCH THAT THE UN  UNDEPLOYED 
CODE
 DOESN'T AFFECT   IT ADVERSELY, 
WHILE
 STILL   MAINTAINING THE 
SIMILARITY
   BETWEEN RESPONSES? 
&amp;gt;&amp;gt;Puneet Khanduri: 
 I'M NOT SURE 
  IF I FULLY UNDERSTAND THE   
QUESTION.
&amp;gt;&amp;gt;Yvette Nameth:  BASICALLY, IF 
  YOU'VE
 GOT A BACK-END THAT IS   PART 
OF THE --
 THE SYSTEM UNDER   TEST AND YOU
 KNOW
 YOUR FRONT-END   IS TAKING 
REQUESTS --
 IF YOU'RE   ONLY REALLY TRYING 
TO
 TEST THAT   FRONT-END AND YOU 
DON'T
 CARE   ABOUT SOME DEPENDENCY 
THAT'S
   GIVING YOU, LIKE, WEATHER   
INFORMATION
 THAT'S ALSO APPLIED   TO THE 
TWEET,
 HOW DO YOU MAKE IT   SO THAT 
THAT
 ISN'T ACTUALLY WHAT   DIFFY'S 
FINDING?

SO JUST FOR, YOU KNOW, CLARITY, 
  IN
 TERMS OF THE SCOPE OF DIFFY,   
DIFFY
 DOES NOT TAKE OWNERSHIP OF   
DEPLOYING
 YOUR DOWNSTREAM   DEPENDENCIES.
  AND
 THAT STORY IS   LEFT UP TO THE 
USER.

  WHAT
 A LOT OF SERVICES DO AT   
TWITTER
 IS THAT WE WRITE OUR   CUSTOM 
BACK-ENDS
 OR, LIKE, MOCKS   FOR BACK-ENDS
 FOR
 THESE   PARTICULAR REASONS. 
SO, FOR EXAMPLE, IF YOU WANT TO 
  REPLAY
 RIGHTS, ONE OF THE THINGS   
THAT WE'RE
 ABLE TO DO OR SOME   SERVICES 
ARE
 ABLE TO DO IS WRITE   -- CREATE
 A
 MOCK BACK-END WHICH   RETURNS 
THE
 OKAY 200 RESPONSE   BUT 
ACTUALLY 
 THROWS THE DOWN  DOWNSTREAM 
WRITE
 AWAY.  SO IT'S   NOT ACTUALLY 
PERSISTING
 THE   WRITE.  AND IT'S NOT 
TRYING
 TO   PROPAGATE THAT CHANGE FOR 
THE
   DOWNSTREAM.  IT ISOLATES IT. 
   AND
 THAT ALLOWS YOU TO AGAIN   KEEP
 YOUR
 COMPONENT DECOUPLED   FROM YOUR
 DOWNSTREAM
   DEPENDENCIES. 
HAPPY TO CHAT MORE ABOUT IT   
AFTERWARDS.
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU. 
[ APPLAUSE ]

BURKHARDT,
 WHO IS GOING TO TALK   ABOUT 
AUTOMATED
 SCEBLGET TESTING   FOR 
ACCESSIBILITY
   TESTING FOR ANDROID 
APPLICATIONS
  APPLICATIONS. 
&amp;gt;&amp;gt;Casey Burkhardt:  THANK YOU. 
GOOD AFTERNOON, EVERYONE.  MY   
NAME
 IS CASEY BURKHARDT.  I'M A   
MEMBER
 OF GOOGLE'S ACCESSIBILITY   
ENGINEERING
 TEAM IN MOUNTAIN   VIEW, 
CALIFORNIA.
I'M HERE TODAY TO TALK ABOUT   
ACCESSIBILITY
 IN TERMS OF MOBILE   APPS, AND 
SPECIFICALLY
 HOW YOU   CAN LEVERAGE SOME NEW
 TOOLS
 TO   AUTOMATE ACCESSIBILITY 
TESTING
   TO A DEGREE WITHIN YOUR OWN  
 ANDROID
 APPS. 
LET'S SEE WHAT WE HAVE ON THE   
AGENDA
 TODAY. 
FIRST WE'RE GOING TO COVER IN   
GENERAL
 WHAT'S ACCESSIBILITY,   HOW 
DOES IT
 MANIFEST ITSELF ON   ANDROID. 
WE'RE GOING TO REVIEW THE TOP   
DEVELOPER
 MISTAKES THAT WE SEE   BOTH AT 
GOOGLE
 EXAM IN   THIRD-PARTY APPS. 
WE'RE GOING TO INTRODUCE A FEW  
 TOOLS
 AND INTEGRATIONS OF OUR   TOOLS
 TO
 IDENTIFY ACCESSIBILITY   ISSUES
 AUTOMATICALLY.

  TOOL
 WORKS, AND SPECIFICALLY   WHAT 
IT
 WILL WORK FOR, WHAT IT   WILL 
NOT
 WORK FOR. 
AND, FINALLY, WE'LL INTRODUCE   
HOW
 YOU CAN LEVERAGE THIS TOOL,   
THESE
 TOOLS, IN YOUR   APPLICATIONS 
AND
 IN YOUR TESTS   TO SPOT 
ACCESSIBILITY
 ISSUES   EARLY AND EASILY.

ACCESSIBILITY?
ACCESSIBILITY REALLY, THE CORE  
 OF
 IT IS HELPING USERS WITH   
DISABILITIES
 ACCESS YOUR   PRODUCTS AND 
SERVICES,
 MAKING   SURE IT'S VERY EASY 
AND 
  STRAIGHTFORWARD FOR THESE 
USERS 
  TO USE YOUR APPS. 
I LIKE TO PHRASE IT A LITTLE   
DIFFERENTLY
 THAN THAT, THOUGH.    I LIKE TO
 SAY
 IT'S ABOUT   CHALLENGING THE 
ASSUMPTIONS
 WE   MAKE AS DEVELOPERS ABOUT 
OUR
   USERS.  OKAY?  SO SOME 
EXAMPLES
   OF THIS.  WHEN WE'RE WRITING 
OUR
   APPS, I'M SURE EVERYONE IN 
THIS
   ROOM HAS WRITTEN A MOBILE APP
   BEFORE
 OR WEB SITE OR ANY SORT   OF 
APPLICATION,
 HAS SAID I CAN   ASSUME THAT 
THE USER
 CAN READ   THE SCREEN.  
ACCESSIBILITY
 IS   ABOUT CHALLENGING THAT   
ASSUMPTION.
BUT THERE'S A   NUMBER OF OTHER 
ASSUMPTIONS
 WE   WANT TO CHALLENGE AS WELL.

 ABLE
 TO ACTUALLY INTERACT WITH A   
TOUCH
 SCREEN?  CAN WE ASSUME   THAT 
THE
 USER'S ABLE TO   DIFFERENTIATE 
COLOR?
CAN WE   ASSUME THAT THE USER IS
 ABLE
 TO   HEAR SOUND THAT MY APP IS 
  PRODUCING?
SO ACCESSIBILITY IS ABOUT TAKING
  ALL THESE ASSUMPTIONS AND   
BUILDING
 SOFTWARE THAT DOESN'T   MAKE 
THEM.

 UNIVERSAL
 DESIGN  DESIGN. 
ACCESSIBILITY ALSO AFFECTS --   
 WHEN
 WE TALK ABOUT ACCESSIBILITY  
ACCESSIBILITY,
 WE OFTEN HEAR THE   PHRASE &quot;THE
 LONG
 TAIL.&quot;  BUT,   ACTUALLY, WE'RE 
TALKING
 ABOUT A   SUBSTANTIAL NUMBER OF
 USERS.
  ONE IN FIVE USERS IN THEIR   
LIFETIME
 WILL SELF-IDENTIFY AS   HAVING 
A DISABILITY.
SO WE'RE   TALKING ABOUT A 
SUBSTANTIAL
   NUMBER OF PEOPLE.  WE'RE NOT 
  TALKING
 ABOUT SORT OF FRINGE   USERS OR
 THE
 LONG TAIL   NECESSARILY.  WE'RE
 TALKING
   ABOUT A SUBSTANTIAL SLICE OF 
THE
   POPULATION HERE. 
THE OTHER THING I'D LIKE TO   
MENTION
 IS, AT ONE TIME OR   ANOTHER, 
WE ALL
 HAVE A   DISABILITY.  WE HAVE A
 FUNCTION
  FUNCTIONAL DISABILITY.  SO, 
FOR 
  EXAMPLE, IF YOU'RE DRIVING 
YOUR 
  CAR, YOU CAN'T BE LOOKING AT  
 YOUR
 MOBILE -- WELL, YOU   SHOULDN'T
 BE
 LOOKING AT YOUR   MOBILE DEVICE
. 
IF YOU'RE COOKING AND YOU HAVE  
 GREASY
 HANDS, YOU MAY NOT   
NECESSARILY BE
 ABLE TO INTERACT   WITH THE 
TOUCH
 SCREEN ON YOUR   DEVICE WITHOUT
 GETTING
 IT DIRTY.    SO AT ONE POINT OR
 ANOTHER,
 WE   ALL HAVE SOME SO FAR 
FUNCTIONAL
   DISABILITY. 
FINALLY, ACCESSIBILITY AND TEST 
 TESTABILITIES
 ARE VERY CLOSELY   RELATED.  SO
 ,ESSENTIALLY,
 THIS   IS A TECHNICAL ARTIFACT.
  MOST
   UIAUTOMATION FRAMEWORKS THAT 
  MODERN-DAY
 FLARMS EXPOSE PLATFORMS EXPOSE 
  UNDER
 THE HOOD ARE IMPLEMENTED   BY 
USING
 THE ACCESSIBILITY APIs  APIs ON
 THE PLATFORM.      SO   YOUR UI
 TESTS
 ARE PRETTY MUCH   LINKED, THEY 
HAVE
 THE SAME   BEHAVIOR AND THE 
SAME CODE
 PATH   EXECUTES WHEN YOU ACTION
   SOMETHING
 IN A UI TEST, AS WILL   BE 
EXECUTED
 BY AN ACCESSIBILITY   SERVICE 
OR ASSISTIVE
 TECHNOLOGY   ON A GIVEN 
PLATFORM.
WE HAD AN EXAMPLE THIS MORNING  
 WHERE
 WE WERE TALKING ABOUT   OFFLINE
 MAPS
 IN GOOGLE MAPS FOR   MOBILE, 
ABOUT
 TWO WEEKS SPENT DE  DEBUGGING 
AN ISSUE
 WHICH CAME   DOWN TO A 
DEVELOPER'S
 ASSUMPTION  ASSUMPTION, THE 
ASSUMPTION
 THAT   THE USER COULD TOUCH THE
   PHYSICAL
 DISPLAY.  WHEREAS THE   TESTING
 TOOL,
 WHICH MOST LIKELY   USED THE 
ACCESSIBILITY
 APIs,   COULD NOT.  IT'S 
POSSIBLE,
   ACTUALLY, IT'S PROBABLE, THAT
   THIS
 IS ALSO -- WAS AN   
ACCESSIBILITY
 ISSUE IN THIS   PRODUCT FOR A 
USER
 WHO'S UNABLE   TO TOUCH THE 
SCREEN
 AND IS USING   ANOTHER DEVICE 
AS AN
 INPUT   MECHANISM, WE CAN VERY 
EASILY
     SEE HOW THEY CAN RUN INTO 
THE
   SAME SITUATION.  AND THAT   
ASSUMPTION
 CAME BACK AND   ACTUALLY 
PRODUCED
 A BUG IN THE   PRODUCT. 
SO THAT'S AN OVERVIEW OF   
ACCESSIBILITY.
LET'S BRIEFLY GO OVER HOW THIS  
 MANIFESTS
 ITSELF ON ANDROID. 
SO WHAT WE SEE HERE ARE THREE   
ACCESSIBILITY
 SERVICES.  AN   ACCESSIBILITY 
SERVICES
 ON THE   ANDROID PLATFORM IS 
SORT
 OF A   LONG RUNNING SERVICE 
THAT'S
   MEANT TO BE PRESENT WHENEVER 
THE
   DEVICE IS BEING USED OR   
INTERACTED
 WITH, BASICALLY, FOR   THE 
DURATION
 THAT THE DEVICE IS   ON.  AND 
ACCESSIBILITY
 SERVICES   PRETTY MUCH CHANGE 
THE
 INTER  INTERACTION MODEL ON THE
 DEVICE.
  SO THEY ALLOW THE USER TO 
ACCESS
   CONTENT ON THE DEVICE IN A 
WAY 
  THAT WORKS FOR THEM.  AND IT  
 ALSO
 ALLOWS THE USER TO INTERACT   
WITH
 THAT CONTENT OR ACTION   
CONTROLS
 ON THE DEVICE IN A WAY   THAT 
THEY'RE
 ABLE. 
SO THE THREE EXAMPLES I HAVE   
HERE
 ARE THE THREE ACCESSIBILITY   
SERVICES
 THAT GOOGLE SHIPS.  THE   FIRST
 IS
 TALKBACK.  IT'S A   SCREEN 
READER
 FOR ANDROID THAT   BASICALLY 
CHANGES
 THE INTER  INTERACTION MODEL TO
 SUPPORT
 A   SERIES OF GESTURES.  USERS 
  NAVIGATE
 USING THESE GESTURES   AND MOVE
 FOCUS
 ON THE DISPLAY   AND HEAR THE 
CONTENT
 THAT GAINS   FOCUS SPOKEN TO 
THEM
 THEM   THROUGH THE DEVICE'S 
TEXT-TO-
  TEXT-TO-SPEECH ACTION. 
BRAILLE BACK IS ANOTHER.  IT   
USES
 THE SAME APIs AS TALKBACK  
TALKBACK.
BUT INSTEAD OF   PRODUCING 
SPEECH UP
 THERE THE   TEXT-TO-SPEECH 
ENGINE,
 IT WILL   OUTPUT DEVICE CONTENT
 ON
 A   DEVICE LIKE THIS.  THIS IS 
A 
  REFRESHABLE BRAILLE DISPLAY.  
IT
   CONNECTS TO ANDROID PHONES 
AND 
  TABLETS OVER BLUETOOTH AND   
ALLOWS
 THE USERS TO ESSENTIALLY   READ
 DYNAMIC
 BRAILLE OFF THIS   ROW OF 
BRAILLE
 CELLS.  AND IT'S   BETTER IN 
SITUATIONS
 WHERE   PRIVACY  IS IMPORTANT. 
 YOU
   DON'T NECESSARILY WANT THAT  
 DEVICE
 CONTENT SPOKEN OUT LOUD   TO 
THE WORLD.
FINALLY, OUR THIRD SERVICE IS   
SWITCH
 ACCESS.  IT'S INTENDED     TO 
HELP
 USERS WITH MOBILITY   IMPAIR
MENTS
 ACCESS CONTENT ON   THEIR 
DEVICE BY
 ALLOWING THEM TO   INTERACT 
WITH THE
 DEVICE IN A   DIFFERENT WAY. 
A LOT OF USERS WITH MOBILITY   
IMPAIRMENTS
 WON'T HAVE THE   TYPICAL TOUCH 
PRECISION
 THAT WE   HAVE WHEN WE INTERACT
 WITH
 A   TOUCH SCREEN.  SO WE'LL USE
   ANOTHER
 DEVICE, LIKE AN ADAPTIVE   
SWITCH.
    THIS IS AN EXAMPLE   OF ONE 
--
 WHICH BASICALLY     PROVIDES A 
DIFFERENT
 INPUT   MECHANISM.  WITH THIS 
SWITCH
 AND   SWITCH ACCESS ENABLED ON 
AN
   ANDROID DEVICE, YOU CAN   
ESSENTIALLY
 CONTROL THE ENTIRE   DEVICE 
JUST THROUGH
 THESE TWO   SWITCHES. 
  IN ADDITION TO ACCESSIBILITY  
 SERVICES,
 THE PLATFORM EXPOSES A   COUPLE
 OF
 CORE ACCESSIBILITY   FEATURES, 
TOO,.
THERE ARE AFFORD  AFFORDANCES ON
 THE
 PLATFORM FOR   MANIPULATING THE
 SIZE
 OF TEXT AS   WELL AS SUPPORTING
 MAGNIFICATION
   OF THE ENTIRE DISPLAY. 
THERE'S A MECHANISM TO INVERT   
COLORS.
SO PEOPLE WHO ARE LIGHT  LIGHT-
SENSITIVE,
 LIKE MYSELF,   CAN VIEW APPS IN
 A
 MORE   COMFORTABLE MANNER. 
THERE'S AFFORDANCES FOR CHANGING
  THE APPEARANCE OF TEXT WITH 
THE 
  AIM TO INCREASE CONTRAST. 
THERE'S ALSO SUPPORT FOR   
CAPTIONING.
SO ACROSS THE   PLATFORM, VIDEO 
VIEWS
 AND OTHER   APPS THAT PREVENT 
VIDEO
 CONTENT   HAVE A WAY OF 
DISCOVERING
 THE   USER'S CAPTIONING 
PREFERENCES.
AND THERE'S ALSO FEATURES THAT  
 BASICALLY
 ALLOW FOR COLOR   CORRECTION.  
SO
 USERS WHO ARE   COLORBLIND AND 
UNABLE
 TO   DISTINGUISH TWO COLORS CAN
   ESSENTIALLY
 SHIFT THE DISPLAY'S   COLOR 
SPACE
 INTO AREAS THAT   THEY'RE MORE 
EASILY
 ABLE TO   DISTINGUISH. 
SO WE'VE COVERED A LOT OF   
ACCESSIBILITY
 FEATURES THAT THE   PLATFORM 
OFFERS,
 A LOT OF   ACCESSIBILITY 
SERVICES
 THAT ARE   AVAILABLE.  AND IT'S
 IMPORTANT
   TO THINK OF ACCESSIBILITY NOT
   ONLY
 IN TERMS OF ONE OF THESE   
SERVICES,
 BUT ALL OF THESE   SERVICES, 
AND EVEN
 COMBINATIONS   OF THE SERVICES 
AT
 THE SAME TIME  TIME.  I STILL 
HEAR
 PEOPLE COME   UP TO ME AND THEY
 GO,
 OH, I   TESTED MY APP WITH THE 
SCREEN
   READER.  IT WORKED GREAT.  
ALL 
  THE ANNOUNCEMENTS WERE -- CAME
   THROUGH
 AT THE EXACT TIME I   WOULD 
EXPECT.
SO I'M DONE WITH   ACCESSIBILITY
. 
SURPRISE.  YOU'RE NOT.  YOU   
SHOULD
 BE LOOKING AT ALL OF   THESE 
SERVICES
 AND MAKE SURE   THAT YOUR APP 
IS EXPOSING
 ITS   CONTENT SEMANTICALLY IN A
 WAY
   THAT WORKS WELL WITH EACH OF 
  THESE
 FEATURES. 
SO SOME COMMON DEVELOPER   
MISTAKES
 THAT WE SEE. 
PROBABLY THE MOST COMMON IS MIS 
 MISLABELED
 OR UNLABELED CONTENT.    SO, 
FOR EXAMPLE,
 IF YOU USE AN   IMAGE VIEW 
SOMEWHERE
 IN YOUR   ANDROID APPLICATION 
AND
 THAT HAS   SOME MEANING TO THE 
USER,
 YOU   NEED TO PROVIDE A CONTENT
   DESCRIPTION
 TO ALLOW A SCREEN   READER OR A
 BRAILLE
 USER TO   UNDERSTAND WHAT THAT 
IMAGE
   REPRESENTS. 
EQUALLY IMPORTANT IS MAKING SURE
  THAT YOUR DESCRIPTION IS   
REASONABLE
 AND YOU'RE USING THE   RIGHT 
ATTRIBUTES
 TO EXPOSE THAT   INFORMATION. 
WE WANT TO ENSURE THAT WE HAVE  
 LARGE
 ENOUGH TOUCH TARGETS.  SO   
USERS,
 FOR EXAMPLE, WITHOUT FINE   
MOTOR
 CONTROL MAY NOT BE ABLE TO   
HIT SMALLER
 TOUCH TARGETS ON THE   DISPLAY.
  SO
 WE RECOMMEND THAT   ALL YOUR 
TOUCH
 TARGETS ARE AT   LEAST 48 BY 48
DIPPS.
ENSURE THAT   YOU HAVE PROPER 
FOREGROUND
 TO   BACKGROUND CONTRAST.  WHAT
   YOU'RE
 LOOKING FOR IS A RATIO OF   
FOUR AND
 A HALF TO ONE BETWEEN   THE 
BACKGROUND
 AND FOREGROUND   COLOR THAT 
YOUR APPS
 USE.  IF   YOU'RE NOT SURE HOW 
TO
 COMPUTE   THAT, THERE'S TONS OF
 ONLINE
   TOOLS AVAILABLE TO HELP YOU. 
AND, FINALLY, YOU WANT TO MAKE  
 SURE
 THAT YOUR VIEW IS EXPOSING   
THE RIGHT
 SEMANTICS.  IF YOUR   VIEW IS 
CLICKABLE,
 ADVERTISE IT   AS CLICKABLE.  
MAKE
 SURE YOU'RE   USING THE AFFORD
ANCES
 IN THE   PLATFORM FOR HANDLING 
CLICKS.
  IF IT'S NOT CLICKABLE, MAKE 
SURE
   IT'S NOT REPORTED AS CLICK
ABLE.
  THIS, FOR EXAMPLE, CAN PREVENT
   USERS
 FROM EFFICIENTLY   NAVIGATING 
YOUR
 APP WITH SWITCH   ACCESS. 
SO THESE ARE A FEW EXAMPLES OF  
 COMMON
 DEVELOPER MISTAKES.  BUT   HOW 
CAN
 WE FIND OF THEM?  HOW DO   WE 
DISCOVER
 THEM? 
AND I THINK THE BEST ANSWER TO  
 THIS
 IS, THROUGH MANUAL TESTING.    
MANUAL
 QA INVOLVES A HUMAN GOING   
THROUGH
 YOUR APP WITH ASSISTIVE   
TECHNOLOGY
 ENABLED AND ASSESSING   ITS -- 
THE
 USER EXPERIENCE FOR   CORRECT
NESS.
THIS, IN MY   OPINION, IS THE 
ONLY
 WAY YOU CAN   COMPLETELY GET A 
PERSPECTIVE
 FOR   HOW USERS WITH 
DISABILITIES
 ARE   GOING TO BE INTERACTING 
WITH
   YOUR APP. 
BUT MANUAL TESTING IS A COSTLY  
 AND
 TIME-CONSUMING PROCESS.  SO   
OUR
 TEAM SET OUT TO THINK ABOUT   
WAYS
 IN WHICH WE CAN IMPROVE   THIS 
AND
 SPEED UP MANUAL TESTING   AND 
REDUCE
 THE NUMBER OF   DEVELOPER PSYCH
LES
 AND BACK AND   FORTH THAT PSYCH
   DEVELOPER
 PSYCHLES AND PSYCHLES AND BACK 
AND
   FORTH.  WE -- WE CAN DO THAT 
FOR
   A LOT OF THE COMMON ISSUES WE
   RUN
 INTOIN. 
IN THAT VEIN THAT, WE CREATED 
WHAT   WE'RE
 CALLING THE VEIN, ANDROID   
ACCESSIBILITY
 TEST FRAMEWORK WE -- IT IS   
ESSENTIALLY
 A JAVA LIBRARY   THAT INCLUDES 
LOGIC
 TO DETECT   A NUMBER OF 
ACCESSIBILITY
   ISSUES USING ANDROID UI   
CONSTRUCT. 
S
 SO WE CAN LOOK AT   THE VIEWS 
PRESENTED
 WITHIN   YOUR APPLICATION OR WE
 CAN
   LOOK AT ANOTHER   
REPRESENTATION
 OF THEM CALLED   ACCESSIBILITY 
NODE
 INFO .    ANYONE WHO HAS USED 
UI 
  AUTOMATION ON ANDROID IS   
PROBABLY
 FAMILIAR WITH THAT. 
AND WE, BASICALLY, HAVE   
IMPLEMENTED
 THIS ONE CORE   LIBRARY THAT 
CONTAINS
 ALL OF   THE TESTING LOGIC. 
WE MADE IT VERY SIMPLE TO ADD   
ADDITIONAL
 CHECKS SO IF YOU   WOULD LIKE 
TO CONTRIBUTE
 OR   GIVE US IDEAS ON HOW TO   
EXPAND
 THIS LIBRARY TO FIND   MORE 
ACCESSIBILITY
 ISSUES,   FEEL FREE TO 
CONTRIBUTE
 TO   PATCH OR GET IN TOUCH WITH
 US
  US.  WE'VE ALSO MADE IT   
REALLY EASY
 TO INTEGRATE THIS   FRAMEWORK 
INTO
 OTHER TESTING   FRAMEWORKS 
WHICH IS
 WHAT --   WHICH IS OUR CURRENT 
APPROACH
  APPROACH. 
SO WHAT WE HAVE DONE IS,   
BASICALLY,
 TAKEN OUR   ACCESSIBILITY TEST 
FRAMEWORK
   AND INCLUDEED IT INSIDE   
ESPRESSO
 AND ROBOLECTRIC HAS   AN OPTION
AL
 COMPONENT.  YOU   CAN GET 
ACCESSIBILITY
 TEST   COVERAGE THAT RELYIES ON
 THE
   COVERAGE OF YOUR EXISTING   
TESTS.

ACTUALLY LOOKS
 LIKE.  SO FOR   ESPRESSO, YOU 
WOULD
 ENABLE   THIS FEATURE BY, FIRST
 OF
ALL  ALL, GETTING THE DEPENDENCY
   FROM
 THE ESPRESSO CONTRIB   
DIRECTORY.
WITH YOU IN YOUR   LIFE CYCLE 
CALLED
   ACCESSIBILITY.CHECKS.ENABLE. 
   FOR
 THE LIFETIME OF THAT TEST   WE 
WILL
 RUN OUR ACCESSIBILITY   
EVALUATIONS
 ON ANY VIEW THAT   YOU INTERACT
 WITH
 THROUGH AN   ESPRESSO VIEW 
ACTION.
SO   WE'LL LOOK IF YOU CLICK A  
 BUTTON
 WITH A VIEW ACTION,   WE'LL 
LOOK AT
 THAT BUTTON AND   THAT BUTTON 
POTENTIALLY
 THE   UI AROUND IT FOR   
ACCESSIBILITY
 ISSUES, YOUR   TOUCH TARGET IS 
TOO
 SMALL, IF   YOU ARE MISSING A 
SCREEN
 READ  READER DESCRIPTION, WE 
WILL
   ACTUALLY GO AND FAILURE   
EXISTING
 TEST.  SO WITH VERY   LITTLE 
WORK,
 YOU CAN TAKE   ADVANTAGE OF 
THIS INTEGRATION
   IN ESPRESSO. 
AND ALSO OF NOTE, YOU CAN   
CUSTOMIZE
 THE BEHAVIOR IF   YOU'D LIKE 
AND POTENTIALLY
   EXCLUDE KNOWN BUGS WITH A   
CLASS
 KNOWN AS BUILT VALIDATE  
VALIDATOR.

 LOOKS
 LIKE.  IN THIS   CASE, THIS IS 
THE
 ACTUAL   ESPRESSO OUTPUT.  IT 
IDENTIFY
  IDENTIFIES THAT THERE'S AN   
ACCESSIBILITY
 ERROR.  IT   GIVES YOU THE VIEW
 I.D.
 AND   ESPRESSO'S TYPICAL VIEW  
 REPRESENTATION
 AND NOTES THE   ACTUAL 
PARTICULAR
 ERROR IN   THIS CASE THERE'S A 
SPEAKABLE
   DESCRIPTION MISSING FOR A   
SCREEN
 READER. 
WE'VE TAKEN A SIMILAR   APPROACH
 IN
 ROBOLECTRIC, THE   SETUP IS 
SLIGHTLY
 DIFFERENT.    INSTEAD OF 
CALLING A
 STATIC   METHOD, YOU SIMPLY 
ANNOTATE
   YOUR TEST METHODS OR RELEVANT
   TEST
 CLASSES WITH THE   
ACCESSIBILITY CHECKS
 ANN   NOTATION THAT WILL   
AUTOMATICALLY
 ENABLE   ACCESSIBILITY 
EVALUATIONS.
  AND ANY VIEW YOU INTERACT   
WITH ROBOLECTRIC'S
 SHADOW   VIEW.CLICKON WILL 
RECEIVE
 AN   ACCESSIBILITY EVALUATION. 
   IT'S
 IMPORTANT THAT YOU HAVE   DON'T
 CALL
 VIEW.PERFORM CLICK   DIRECTLY 
OR INVOKE
 CLICK   LISTENER LOGIC BECAUSE 
THAT
   WILL POTENTIALLY BYPASS OUR  
 INTEGRATION
 WITH ROBOLECTRIC. 
WE'VE GOT MORE TOOLS FOR   
SUPPRESSING
 KNOWN ISSUES AND   OTHER 
ADVANCED
 FUNCTIONALITY   COMING SOON.  
IN FACT,
 I   THINK OUR POLL REQUEST FOR 
  SOME
 NEW THINGS IN PROBABLY   JUST 
LANDED
 THIS MORNING.  SO   PLEASE 
CHECK THAT
 OUT. 
HERE'S WHAT AN EXAMPLE OF A   
ROBOLECTRIC
 FAILURE ACTUALLY   LOOKS LIKE. 
 AGAIN,
 YOU SEE   THE MESSAGE THAT VIEW
 HAS
   ACCESSIBILITY ISSUES AND   
MISSING
 SPEAKABLE TEXT FOR A   SCREEN 
READER.
YOU WILL SEE   THE CALL THAT 
CLICKED
 ON THE   RESULT OF OUR 
EVALUATION
   FAILING. 
SO WHAT CAN'T WE DO?  SO,   
FIRST OF
ALL, OUR COVERAGE IS   ONLY AS 
GOOD
 AS YOUR COVERAGE  COVERAGE.  IF
 YOU'RE
 TESTS   DON'T COVER YOUR 
APPLICATION
  APPLICATION'S UI IN A   
COMPLETE WAY,
 YOU MAY NOT GET   ACCESSIBILITY
 EVALUATION
   COVERAGE FOR THAT UI EITHER. 
   SO
 WE RELY ON YOUR EXISTING   
TESTS TO
 DECIDE HOW WE WORK   AND WHAT 
WE DO.
SECONDLY, WE ERROR ON THE   SIDE
 OF
 CAUTION.  IF WE'RE   NOT SURE 
IT'S
 AN   ACCESSIBILITY ISSUE BUT IT
   COULD
 BE, WE EMIT A WARNING   EITHER 
TO
 THE TEST OUTPUT OR   LOGCAT 
DEPENDING
 ON WHAT   PLATFORM -- WHAT 
INTEGRATION
   YOU ARE USING. 
SO PLEASE CHECK THE LOGCAT OR   
THE
 TESTOUT FOR ADDITIONAL   
POTENTIAL
 ACCESSIBILITY   WARNINGS AS 
WELL.
AND, FINALLY, WE ARE NOT A   
REPLACEMENT
 FOR MANUAL   ACCESSIBILITY 
TESTING.
WE   STILL VERY HIGHLY ADVOCATE 
  THE
 USE OF MANUAL QUALITATIVE   QA 
TO
 GO THROUGH YOUR APP   WITH 
ACCESSIBILITY
 SERVICES   AND UNDERSTAND THE 
EXPERIENCE
  EXPERIENCE.  THE EXAMPLE I   
LIKE
 TO USE HERE TO   ILLUSTRATE 
THIS IS
 WE CAN   TELL IF A PARTICULAR 
CONTROL
   HAS A DESCRIPTION FOR A   
SCREEN
 READER OR NOT.  BUT WE   CAN'T 
TELL
 IF THAT   DESCRIPTION MAKES 
SENSE
 TO   THE USER.IST ALWAYS GOOD 
TO 
  HAVE MALQA GO MANUAL QA REVIEW
 YOUR
   IMPLEMENTATIONS.  WE CAN USE 
  THE
 AUTOMATEED TEST FRAMEWORK   AS 
A MECHANISM
 TO SPEED UP   THAT STEP. 
SO WHAT'S NEXT FOR YOU?  GO   
AND TRY
 THIS OUT.  IF YOU   HAVE 
ESPRESSO
 OR ROBOLECTRIC   TESTS, USE THE
 ACCESSIBILITY
   CHECKS CLASS OR ANNOTATION TO
   TURN
 THIS FEATURE ON AND SEE   WHAT 
YOU
 GET.  YOU CAN EVEN   EVEN -- 
YOU PROBABLY
 SHOULD   EXPECT A LARGE NUMBER 
OF
   ISSUES.  WE FIND THAT MOST   
APPS
 THAT TURN ALL THE CHECKS   ON 
AT ONCE
 RUN INTO ISSUE   THAT IS THEY 
THEN
 HAVE TO GO   THROUGH AND 
SUPPRESS.
BUT   THAT'S A GOOD THING.  YOU 
ARE
   FINDING A LOT OF ISSUES IN   
YOUR
 APPS AND YOU'RE IMPROVE  
IMPROVING
 THE ACCESSIBILITY   OVERALL OF 
THE
 ECOSYSTEM   WHICH WE REALLY 
APPRECIATE.
IF YOU HAVE ANY QUESTIONS   
ABOUT THE
 PROJECT, SOMETHING   DOESN'T 
SEEM
 TO BE WORKING AS   YOU'D EXPECT
, PLEASE
 REACH   OUT TO US ON GITHUB, 
FILE
 AN   ISSUE ON OUR GITHUB PAGE. 
 IF
   YOU HAVE IDEAS FOR NEW   
ACCESSIBILITY
 TESTS WE CAN   ADD TO OUR SUITE
, PLEASE
 ALSO   LET US KNOW.  AND ALSO 
PART
   OF THE REASON WE'RE HERE IS  
 TO
 FIND WHAT'S NEXT AND LEARN   
ABOUT
 THE NEXT PLATFORM WE   WANT TO 
INTEGRATE
 WITH.  IF   YOU HAVE FOUGHT OR 
  RECOMMENDATIONS
 OR   SUGGESTIONS FOR ANY OF 
THAT,
   PLEASE REACH OUT TO US AS   
WELL.
THANK YOU. 
[ APPLAUSE ] 
&amp;gt;&amp;gt;Yvette Nameth:  THANK YOU,   
CASEY.

HAVE YOU CONSIDERED INCLUDING   
ACCESSIBILITY
 EVALUATION AS   PART OF THE 
GOOGLE
 PLAY UP  UPLOAD PROCESS? 
&amp;gt;&amp;gt;Casey Burkhardt:  THAT'S AN   
EXCELLENT
 IDEA.  WE HAVE   NOTHING TO 
ANNOUNCE
 TODAY   REGARDING THAT.  BUT 
IT'S
   DEFINITELY SOMETHING OUR TEAM
   HAS
 BEEN DISCUSSING AND WE'D   LIKE
 TO
 PURSUE IT FURTHER.    YEAH. 
&amp;gt;&amp;gt;Yvette Nameth:  WELL, THAT   
WAS
 SORT SO I WILL GIVE YOU   ONE 
MORE.

ACCESSIBILITY
 AUTOMATION   INTEGRATION WITH 
GOOGLE'S
 UI  UIAUTOMATEOR V2. 
&amp;gt;&amp;gt;Casey Burkhardt:  WE ARE   
LOOKING
 AT IT.  IT USES A LOT   OF THE 
SAME
 CONSTRUCT THAT IS   WE CAN 
EVALUATE.
IT'S   DEFINITELY ONE PATH TO 
MOVE
   FORWARD AND EXPAND THE SUITE 
  OF
 FRAMEWORKS THAT WE   ACTUALLY 
INTEGRATE
 WITH.  BUT   WE'LL BE TALKING 
TO THE
   ANDROID TEAM ABOUT THAT.    
DEFINITELY.

YOU.
&amp;gt;&amp;gt;Casey Burkhardt:  GREAT.    
THANKS.

PLUS PLUS. 
&amp;gt;&amp;gt;Yvette Nameth:  SO WITH   THAT
 I
 HAVE A FEW THINGS TO   SAY 
BEFORE
 I SEND YOU ON YOUR   WAY.  I'M 
GOING
 TO ACTUALLY   START WITH AN 
OBSERVE.
I'M   TRYING TO DECIDE OVER 
TODAY'S
   TALKS WHETHER I'M ON TEAM   
EMULATOR
 OR TEAM DEVICE. 
WE'VE SEEN A LITTLE BIT OF   
BOTH.
WE'VE SEEN REALLY   HIGHLY 
ORGANIZED
 CHROME OS   LABS.  WE'VE SEEN 
ROBOTS
 DO   AUTOMATION TEST ON DEVICE 
  TESTING
 AND WE'VE SEEN SOME   REALLY 
AWESOME
 EXPANSIONS ON   USING THE 
EMULATOR.

SPLIT
 LITTLE QUESTION IN MY   OFFICE.
  I
 SEE THE DEVELOPERS   WHO ARE 
WRITING
 GOOGLE MAPS   MOBILE FEATURES 
LIKE
 THE OFF  OFFROAD FEATURE USING 
THEIR
   DEVICES ALL THE TIME FOR   
THEIR
 DAY-IN/DAY-OUT.  DID   THAT 
WORK?
DID THAT WORK?    WHAT DID THAT 
TWEAK?
DOES   THAT ACTUALLY WORK 
CORRECTLY.
I MYSELF NEVER USE A PHYSICAL   
DEVICE
 FOR TESTING.  ALL OF   MY TESTS
 RUN
 ON EMULATORS.    SO WE'RE 
OBVIOUSLY
 A SPLIT   OFFICE.  I'M WONDER
ING WHAT
   YOU GUYS ARE THINKING AND I'M
   HOPING
 THAT YOU'RE FORMING   YOUR OWN 
OPINIONS
 ABOUT MAYBE   NOT IS IT ONE OR 
THE
 OTHER   BUT WHEN DO WE USE EACH
 ONE?
  WHEN DO WE USE EMULATORS?    
WHEN
 DO WE USE DEVICES? 
AND I HAVE TO DO THIS BECAUSE   
I'M
 A CHEESEY DAUGHTER.  MY   MOM 
WHO
 IS JUST A FEW DAYS   OUT OF 
SURGERY
 HAS BEEN   WATCHING THE 
LIVESTREAM
 ALL   DAY LEARNING ALL ABOUT 
WHAT
 I   DO AT GOOGLE BECAUSE SHE'S 
  ALSO
 CHEESEY LIKE THAT AND   PROUD 
OF HER
 DAUGHTER. 
SO HI MOM. 
AND, MOM, YOU ARE ON TEAM   
EMULATOR.
[ APPLAUSE ] 
AND THAT APPLAUSE WAS FOR YOU  
YOU.

YOU'RE
 TEAM EMULATOR BECAUSE   THAT'S 
WHAT
 I'M CURRENTLY   USING AT LEAST.
  MAYBE
 YOU   WILL BE TEAM DEVICE SOME 
DAY.
SO NOW WHAT ARE WE GOING TO   DO
?
WELL, AT 6:00, GOOGLE   RECRUIT
ING
 HAS SET UP THE   CONSENSUS 
NIGHT 
  CASINO NIGHT I MENTIONED THIS 
  MORNING.
IT WILL BE JUST UP  UPSTAIRS IN 
THE
 COMMON SPACE.    THERE WILL BE 
A BUNCH
 OF   TABLETOP CASINO GAMES.  
THERE
   WILL BE FOOD.  THERE WILL BE 
  DRINKS.
THERE WILL BE GOOGLE   RECRUITER
S.

BUT IT'S FREE.  SO TAKE THAT   
AS YOU
 WILL. 
I ALSO WANTED TO GIVE A   
SPECIAL THANKS
 TO SOMEBODY   WHO MAY OR MAY 
NOT BE
 IN THE   ROOM.  SONAL WHO HAS 
BEEN
 OUR   PHOTOGRAPHER TODAY ALSO  
 PROVIDED
 US WITH THE AWESOME   DEVALI 
TREATS.
THANK YOU, SO  SONAL FOR THE 
DELICIOUS
 GOOD  GOODIES I HOPE YOU ALL 
GOT TO
   TAKE PART OF. 
[ APPLAUSE ]

FOR --
 AT THE END OF TOMORROW   WE 
WILL HAVE
 A VERY LONG   DETAILED POLL 
ABOUT
 WHAT CAN   WE DO BETTER OVERALL
 AT
 GTAC.    BUT WE'RE GOING TO 
SEND YOU
   ON YOUR WAY WITH ONE SMALL   
QUESTION.
WHAT CAN WE DO   BETTER TOMORROW
?
IF THERE'S   ANYTHING THAT YOU 
THINK
 THAT   TONIGHT THOSE FEW OF US 
THAT
   ARE ON THE GTAC PLANNING   
COMMITTEE
 CAN CHANGE SO THAT   TOMORROW 
RUNNING
 MORE SMOOTH  SMOOTHLY, PLEASE 
LET
 US KNOW.    IT'S ACTUALLY THE 
CURRENT
   QUESTION AVAILABLE AT POLLEV 
 POLLEV.COM/GTAC2015
 WHERE YOU   HAVE BEEN 
SUBMITTING YOUR
   OTHER QUESTIONS.  IF YOU HAVE
   ANY
 OTHER COMMENTS YOU WOULD   LIKE
 ADDRESSED
 BEFORE   TOMORROW, LET US KNOW 
THERE.
  IF THERE ARE LONGER TERMS   
THAT WE
 CAN'T PERFORM MIRACLE  MIRACLES
 AND
 DO TONIGHT, WAIT   UNTIL THE 
SURVEY
 COMES OUT   AFTER GTAC. 
AND WITH THAT, I BID YOU ADO. AA
DI
  AADIEU.  I CAN HANG OUT AND   
CONGREGATE
 UNTIL THEY ARE   READY FOR US 
UPSTAIRS
 WHICH   AT SOME POINT I THINK 
THERE
   MIGHT BE SOME COW BELL.  GO  
 HAVE</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>