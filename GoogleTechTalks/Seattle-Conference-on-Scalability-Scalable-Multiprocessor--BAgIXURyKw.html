<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Seattle Conference on Scalability: Scalable Multiprocessor | Coder Coacher - Coaching Coders</title><meta content="Seattle Conference on Scalability: Scalable Multiprocessor - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Seattle Conference on Scalability: Scalable Multiprocessor</b></h2><h5 class="post__date">2008-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-BAgIXURyKw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">our last speaker of the day is Vijay
Menon from Google and he'll be talking
about scalable multiprocessor
programming via transactional memory and
he's been before being at Google he was
at Cornell and the University of
California Berkeley and Intel thank you
so yeah I'll be giving a general
overview of transactional memory and
interesting technology that's kind of
popped in lots of interesting places
like Chappell for for instance as Brad
mentioned earlier today so a lot of the
talks today have focused on this notion
of scalability over large-scale
distributed systems but scalability is
really not just limited to those systems
any more modern multi processors or
modern processors now have multiple
cores and this is just a natural result
of the power and performance challenges
that hardware architects are facing
today and the current trend suggests
that we're gonna get yet more and more
cores on on a give and die so
scalability is really not just about
servers but now also about what you know
what we we generally considered as
clients desktops laptops like this one
and and even increasingly I think we're
gonna see mobile devices with multiple
cores on them so good performance on
these these systems is now going to
require that we be able to write
scalable applications that really
utilize multiple cores so we need a way
to program these systems and there is a
traditional model that has been out
there to use for these kind of
environments and and that's basically
threads and locks so the the general
idea is that we have multiple threads of
execution for example one per every core
that we have we have some sort of shared
memory to communicate between those
cores and we have locks to coordinate
access from multiple threads to shared
memory great except this is kind of
difficult to program as we all know - in
general fine grained locking is required
if we want to have any kind of good
scalability over this kind of a more
and and that really puts a lot of burden
on the programmer to avoid fun stuff
like deadlock in order to maintain
correct lock discipline to make sure
they use the correct locks for given
data and to also just compose different
modules together under locks is quite
difficult so an alternative that's been
proposed is something that's called
transactional memory and the idea here
is to replace our locked regions in our
programs with transactions and this is
an idea that's been around quite a bit
in the database community we saw it a
couple talks ago Thorson talked about
transactions in over distributed hash
map and here basically what we want to
do is transactions over memory and and
really what transaction our transactions
are are a set of atomic operations that
appear to execute sequentially and when
we apply this to memory there's really
two key ideas we want to take advantage
of the first is this notion of
optimistic concurrency in the
implementation so all those things
appear to execute sequentially we want
to go ahead and try to execute them
concurrently as much as we can get away
with it and leave it up to the system to
figure out how to make that safe and
correct the other thing we really would
really like is declarative safety in the
language and here we want the programmer
to really focus on what safety
properties they want rather than spend a
lot of time figuring out how to get
those safety properties and leave it to
the system to figure out how to do this
efficiently so here's a fancy little
example let's suppose we have a shared
document here a shared bit of data here
and we have two threads on the left and
the right that basically locked this
data this is Java code that's let's
imagine locking the entire document and
doing some operation so under locks if
the the thread on the Left proceeds it's
basically going to acquire the lock and
it's going to block the code on the
right from executing and it's going to
go ahead and do its operation and only
when it's done can the thread on the
right go ahead and proceed and do its
operation right so they have to take
turns in order to do this
so I said as I said with transactions
we'd like to take advantage of this
notion of optimistic concurrency we'd
like to just go ahead and assume that we
can just go ahead and do both of those
operations in parallel notice I've kind
of shown what this might look like in
the language we've replaced synchronized
Java synchronized statement with this
atomic statement and we go ahead and do
both simultaneously in this case
everything's great now of course we
don't just get this for free there's a
reason we call these atomic and so it's
up to the implementation to deal with
conflicts so again here we have two
threads and now they're gonna actually
access the same location right the same
location and again we want to assume
that we can do this concurrently and of
course if we just do this without
checking will we're gonna have garbage
and we'd like to avoid that to make this
usable so it's up to the system to
figure out how to do this correctly to
figure out that that that something bad
happened and to make sure that we're
left with the result that's consistent
so here we have bird which is consistent
with this transaction running before
that transaction and so we get a
consistent final result okay so here's a
quick overview of the talk in general
first I'm going to talk about
implementing atomic I'm sorry
implementing optimistic concurrency both
in hardware and in software and I'll
talk later on about how to integrate
transactions into programming languages
and why you might want to do that and
then I'll conclude so again optimistic
concurrency and transactions is a is a
an old idea the key idea as I said this
transaction should be performed in
parallel we're taking this idea from
databases and now we're applying it to
two random access memory so it's up to
an implementation again to try to figure
out how to make independent transactions
to overlap and to do that the
implementation has to detect and recover
from conflicting accesses in order to
basically recover from this it's
basically got to maintain the original
and new versions of memory as its as it
computes this transaction and the
general idea is if there is no conflict
it's going to go ahead and commit its
transaction when it's done and publish
the new version
for other threads to see if there is a
conflict it's going to abort its
transaction and go ahead and restore the
original version and perhaps depending
on the semantics we want restart the
transaction in order to make it actually
happen so the original idea of
transactional memory actually came up in
a hardware context actually about 15
years ago now so it's been around for a
while and the idea was actually quite
simple it was to leverage existing
multiprocessor Hardware mechanisms in
order to give small scale transactions
and the idea was to use versioning the
idea was to get our versioning by using
caches so basically a cache would
contain the new values and main memory
retains the original so we can just
exploit caches to keep two copies of
memory around in our transaction for
conflict detection we can just basically
rely on extending existing cache
coherency mechanisms in order to do that
and the idea is on a commit the cached
values are going to go ahead and be
committed to main memory but honor abort
the cache values are simply dropped and
a processor has to bring back the old
values from memory there's a lot of
interesting work going on in Hardware
transactional memory you know it's been
it's been some 15 years but the state of
commercial hardware TM is still pretty
modest the two examples two best known
examples are Azul a company that
produces large scale Java based servers
over 500 cores I think the recent
machines uses transactional memory under
the hood so they don't actually expose
it to the programmer but they use it as
a way of actually more efficiently
executing locks another processors I
said that's actually just coming out as
Suns Rock processor was expected next
year and here they're actually going to
expose Hardware transactional memory to
the programmer but transactions are
still pretty limited in size and
allowable operations now basically
they're bounded by the hardware
resources that you have how big your
caches for example so if you want to run
memory operations today well there's
software transactional memory and here
the idea is to do all that necessary
bookkeeping in software instead of using
the cache for example and as you might
expect you're basically in a sacrifice
raw performance that you'd get with the
specialized hardware support but you
gain some flexibility I mean one
important thing is you can actually run
this on existing machines which is quite
nice and you're also not bounded by
hardware resources and limitations so
you could really support unbounded
transactions you can also tailor and
tune your algorithms for doing the
bookkeeping for specific applications
and it does turn out that certain
applications or certain application
behavior tends to like one sort of
implementation of STM versus another and
as I'll talk a little bit later on you
can also support some more interesting
language constructs and semantics that
you might might want to play around with
so to implement transactional memory and
I'm kind of focusing on software
transactional memory here but this
applies to Hardware too you need to as I
said implement conflict resolution and
there's really two basic strategies for
this the first is what I'd call eager
where a system basically assumes that
there's a potential conflict and wants
to prevent it ahead of time and the
basic idea here is to go ahead and
acquire a lock underneath to prevent
concurrent readers or writers depending
on what kind of operation you want to do
the the other strategy is what it call
lazy conflict resolution and basically
the idea here is to assume no conflict
and recover if necessary and if you're
doing a read or write what you're going
to do and I'll show an example of this
in a moment
it's basically record what you did or
buffer what you did and validate that
it's okay to go ahead and commit your
transaction at the end that these reads
and writes were correct hardware TMS are
actually typically lazy but STM's have
the advantage of actually varying
significantly based on what kind of
applications you want to do or what kind
of characteristics you want we also have
this notion of versioning again which we
you know in the hardware case we relied
on cash again there's really two ways of
looking at this one is this eager
strategy which assumes that a
transaction will come
and the general idea here is you know if
I have a write inside of a transaction I
can just go ahead and write it directly
to memory and record the old values in a
log and what I have to do here is that
if I commit I'm basically done the
rights have gone through to memory but
if I abort I have to go ahead and pull
those values from the logs and restore
them back into main memory and the other
alternative is is lazy where we assume
the transaction there's a good chance
that the transaction may abort and here
again in this case we want to buffer the
rights and not actually go ahead and
write them to memory but if we commit
only at that point do we go ahead and
write in memory on the other hand in
this case if we abort we just throw our
buffer away right so to kind of opposite
strategies there so I'll talk about a
particular HTM inflamation conveniently
one that I actually worked on when I was
at Intel this is a this is the McCarty
STM it's a C Java f TM described in
conference paper a couple years ago and
it's actually available on the web and
it uses kind of a mixed strategy for
writes it uses eager conflict resolution
and eager versioning and for reads it
uses lazy conflict detection and again
I'm going to go through walk through an
example of what that actually means so
first and the hardware setting we relied
on the cache to help us do the
bookkeeping if we're implementing
transactional memory and software well
we need some data structures in order to
do this and one set of data structures
that we have are per data data
structures so this there's this thing
that we call a transaction record and
it's somewhat analogous to a lock it
protects some corresponding set of data
the difference though is not user
visible it's managed by the
implementation the programmer actually
never sees the transaction record it's
up to the STM to automatically check and
update this record on any load and store
a transaction record is usually
implemented as a pointer size value and
it can in in the mccarty STM it's in one
of two states it's Ana can be in an
exclusive state or a right state where
the value is a pointer to the owner of
the transaction record and only that
owner can read or write to the data
that's protected by the transaction
record the second state is a shared
state or a read state and in this case
it's a version number and in this case
every thread can go ahead and read the
data but they don't have permission to
write the data and we can distinguish
between those two states just by taking
of the fantage advantage of the fact
that pointers are usually aligned so
it's really just a matter of looking at
the the lower order bit we just require
that all version numbers be odd and so
just by checking the lower order bit you
can see if it's in a right state or a
read state we also do some bookkeeping
per thread we maintain a read set on any
read operation we're going to go ahead
and update that read set and I'll show
an example of how that's built and we
also maintain a right set of the
transaction records that that we're
trying to get a basically exclusive
access to and an undo set of values
again I said this is a eager versioning
system of values original values for
locations that we go ahead and overwrite
so here's kind of what this might look
like in an implementation so this is a
kind of typical layout for a Java object
or a C++ object the first field is some
sort of type descriptor that the system
can use to figure out what type an
object is the second field is something
that we're using for the STM in our
implementation here it's basically the
transaction record and in both of these
cases it's odd so it's a version number
both of these objects are in a read-only
state and the transaction record
basically protects the fields and the
object so in order to access X or Y you
have to go through the transaction
record so let's suppose we have a
transaction that's going to copy a into
B it might look like this we use an
atomic statement to say that we want
this to be a transaction we go ahead and
copy one by one the fields x and y from
A to B what I'm not really showing here
is there there's you know the magic
under the hood it's sort of
up to the system or the compiler to
figure out that it needs to do some STM
operations
so in Java usually what you see is a
load is not just a load when you do
something like a dot X usually check to
see well is it now is it typesafe and so
on and we can actually just modify that
to also say okay and inform the STM that
I'm reading a dot X right so when it
reads a dot X or writes to B dot X it's
going to do some bookkeeping to the STM
data structures now suppose I have a
concurrent thread thread two over there
that's gonna read B and both of these
things are executing at the same time
well if we get the semantics right
there's only two valid results either
thread to execute first or appears to
execute first and we read the values 0 0
or thread to execute 2nd or appears
again to execute 2nd and we read the
values 10 20 if we see a mix of those
two things that we've got incorrect
inconsistent behavior so let's imagine
we're actually executing this in an STM
and again we're going to use this notion
of optimistic concurrency and go ahead
and execute both of these things at the
same time there's going to be some
arbitrary interleaving between these two
threads and again I mentioned the read
set write set and undo set we have these
sets for each thread so I'm going to
show how these how these sets are built
up as we execute so let's imagine thread
to execute first it reads BX and sees
the value 0 over there and B and when it
does it it also appends to its read set
the the tuple B comma 1
so it's recording what object it's red
and it's recording the current version
number of that object which is 1 ok now
let's suppose we start executing a same
thing we're doing a read operation again
we append the read set with the object a
and the version number 7 and the value
of temp is 10 as that's the current
value now when we write to B dot X we
need exclusive access of B ok so now
we're going to change be from a read
only state to a read/write State and the
owner of B is going to be transaction
one so we go ahead and overwrite that
record slot with a pointer to thread one
basically and we append the right set
with B and the version number it used to
be at and again we also append the undo
log in case we need to abort this
transaction we're going to have to go
rewrite B dot X with 0 and let's keep
going with a here it's going to read a
dot Y which is also going to append to
its read set and read the value of 20
and write B dot Y in this last case B is
already locked so and owned by thread 1
so it doesn't really need to do anything
but it does need to go ahead and append
the undo log again with with the value 0
in case it needs to abort and it goes
ahead and writes the value 20 in place
and let's suppose this thread goes ahead
and finishes and it tries to commit so
the again what I said earlier this s TM
is using an eager mechanism for writes
but a lazy mechanism for reads and with
that lazy mechanism for reads means is
that we have to go ahead and validate
our read set to prove that this
transaction is valid and all that really
consists of is walking through our read
set checking the objects and making sure
that the version number hasn't changed
now in this case we just have a in our
read set and the version number is still
7 so we can go ahead and commit the
transaction and once we do that we go
ahead and install a new version number
in B so the transactions over B is no
longer in a right state it's now back in
a read state but we've incremented the
version number by two again because it
has to be odd so let's suppose thread
two picks up at this point
of course again first we clear the the
read write and undo set for thread 1 so
let's suppose thread 2 picks up at this
point it goes ahead and reads B dot Y
again it's got a pen B and it's version
number two the read set and it reads the
value 20 and now it tries to go ahead
and commit
now at this point we have this
inconsistent pair zero and 20 and that's
not a valid result as we talked about
earlier and of course when it goes and
tries to validate its read set at this
point it'll see that it's got an entry B
comma 1 and B is no longer happy B no
longer has the version number 1 so it
has to go ahead and abort this
transaction and and in this case let's
say it's going to go ahead and restart
the transaction that's the semantics
that we want so in this case now if it
goes ahead and reacts Acutes the
transaction it's going to build up a
read set again and in this case no
conflicts the read set validates and we
can go ahead and commit this transaction
and we get the values 10 and 20 so it's
generally how optimistic concurrency
works again there's a lot of sort of
variants on STM algorithms that's just
one but they all have sort of a similar
flavor to them in in some way using a
mix of eager and lazy techniques so now
I'm going to talk a bit more about
transactions in in programming languages
so a major value of transactional memory
is not really just raw performance or
scalability but really program ability
and what excites a lot of people about
transactional memory is that it offers a
much simpler programming model compared
to locks from one its declarative versus
operational as you saw in our examples
you don't have to say what lock you want
to acquire anymore you just say this
body of code is atomic go figure it out
it's also composable in a way that locks
aren't if I just happen to have
operations 1 &amp;amp; 2 and I say I want this
to happen as a transaction I can just
wrap atomic around it I don't have to
again figure out what lock to to acquire
and that can be very very nice if I'm
using fine-grained locking you know in
contrast if I'm using fine-grained
locking in operation 1 and operation -
if I want to compose those together to
be a larger atomic operation it's very
hard to do with locks in an efficient
way an efficient clean way also
transactions give stronger guarantees
that are they're really closer to what
programmers really want when programmers
use synchronized it turns out usually
they want atomic semantics right and if
they just use transactions from the
get-go they get some nice properties
they'll get deadlock of wouldn't usually
programmers don't want to have deadlock
in the program and they also get some of
these nice atomicity consistency
isolation properties that that Thorson
mentioned earlier today and those are
the general the ACI of the acid
properties that we have from database
transactions so very quickly atomicity
basically gives us this appearance of
instantaneous execution right either
everything happened or nothing happened
consistency enforces the validity of the
memory state so we showed an example of
that a little bit earlier with
consistency we reinforced that memory is
in one state or another and not in some
kind of inconsistent unexpected state it
also gives us isolation it prevents
observation of intermediate state by
other transactions and finally it
doesn't actually give us durability this
is usually one thing we give up with
memory transactions because unlike disk
Ram is really just not intrinsically
persistent so we usually just talk about
the ACI properties when we're talking
about memory transactions so here's an
example of why atomic is easier to loot
use in a language than say synchronized
this is kind of a distillation of a
version of the string buffer class in
the Java class library here we have this
append method that takes one buffer and
appends it to this buffer and it's a
synchronized operation and this was
actually in basically in a similar form
in the class library well it turns out
you can take a look at this code it's
actually not thread safe and kind of the
key point here is just because I declare
something SEC synchronized doesn't make
it thread safe so I'll give you guys a
moment to see if you if the bug pops out
at you
yeah it's actually you know something
can happen in between some of these
operations so the problem is buffer is
not locked right if I just declare this
method synchronized it's going to lock
this pointer but it's not going to lock
the parameter that I'm passing in here
so it's perfectly legal for some other
thread to go ahead to take take a lock
on buffer and start changing it right at
this point right between when we read
the size and when we start copying out
of it okay and if that happens another
thread can change the size can do a lot
of different things to it and you know
doing the append consistent result or
even generate an exception in this code
right so you not except you not expect
an exception because you looked at the
size you thought you computed the right
size and you thought you're only
accessing valid locations in that buffer
but if it's shrunk in the interim you
might get an array out of bounds
exception when you do this okay now if
we go ahead and use atomic we're
basically leaving it up to the
implementation to figure out what to
protect and it's going to try to protect
everything that's accessed here so in
another transaction in this case can't
go ahead and alter the parameter that
we're passing in so this code is thread
safe let me go over a couple other sort
of things you can get out of having
transactions in the language failure is
something that in a locked region can
lead to inconsistent state so if I'm
synchronizing again this method let's
imagine it's doing a transfer from
account one to account two of some
amount well I might write the code to
you know basically take a mount out of
a1 and then append we're add in amount
into thread two using these set balance
and get balanced methods but let's
suppose thread a2 is invalid for some
reason and one of these second
operations throws an exception if the
second statement fails well then in this
code
we've already gone ahead and executed
the first statement so the amount is
still withdrawn from a1 we might throw
this exception and basically this this
amount value has disappeared into the
ether we're kind of left in this
inconsistent state now transactions can
provide better consistency guarantees to
the programmer under this sort of
failure or a Bourdon exception or error
semantics what we'll say is that if the
transaction aborts we're going to go I'm
sorry if the transaction generates an
exception we're going to go ahead and
restore the original state so the
semantics under
here is that if we throw this exception
on a2 we're going to go ahead and roll a
1 back to its initial value we're
already doing this bookkeeping anyway
we might take it might as well take
advantage of it to provide nice
semantics to the programmer and if this
thing throws an exception
basically the transaction really never
happened at least as far as effects to
memory are considered and a1 still has
its original value so that can be a nice
thing a nice tool that a programmer can
use to make sure that their data stays
in some sort of a consistent state
that's a good question I don't think it
really makes sense to well actually
there's a few different semantics you
might consider there fulfill your
animosity and it's actually a topic of
hot debate that what is the proper
semantics some people think that you
should never have failure on exception
semantics you should just go ahead and
commit which kind of defeats my argument
here throwing the exception and
cascading it out is kind of interesting
because if the transaction never
occurred where did this exception object
come from right and so there is some
interesting work there and trying to
come up with reasonable semantics for
that that basically lets you expose the
exception but still go ahead and roll
back the values that happen and there
the semantics might be that some type of
exception object is still propagated out
yes yeah
probably another problem with locks is
that they don't really protect us very
well from malicious or buggy data races
so for example let's suppose I have this
lock base code here I check whether a is
not null and I go ahead and return a dot
X so a quick question can this code ever
throw a null pointer exception and then
why absolutely right so very simple
another thread to go ahead and alter a
between this point and this point and
just set a equal to null right it
doesn't have to acquire the lock it's a
bug or maybe it's even worse it's some
sort of malicious code that someone has
figured out how to run and perfectly
interleave with with your thread here
so the answer is yes and this is
actually a common security exploit I've
been told by my friends in the systems
community that's called a time to check
- time to use or tuck - I don't know if
I'm pronouncing that right exploit and
it's commonly used
it's basically exploited at erase
somewhere in the code to generate some
sort of unexpected behavior that the
programmer never anticipated all right
and so you can generate an exception
that exception will cause some behavior
that perhaps the original programmer
didn't anticipate and lead to other sort
of security holes in the program now
transactions in this case can actually
provide more secure behavior under
strong isolation a transactional memory
implementation will prevent another
thread from violating the isolation of
this code so this thing is really
guaranteed to be atomic no other thread
can interfere with it and in this case
the null pointer exception cannot be
thrown another a non transactional
thread let's see this should say the
under strong isolation a non
transactional thread cannot interfere
with the transaction so this is a nice
property to have I can just throw atomic
around something I can just reason about
it locally so since I know this is a
transaction I know it's never going to
throw a nullpointerexception
I don't have to worry about
carefully checking all the other parts
of my program to make sure that they
play nicely with this so some obstacles
to too transactional memory there's a
lot of work to be done there's a lot of
implementation challenges as I said the
current state of hardware transactional
memory is pretty modest current and
forthcoming hardware support pretty
limited transactions and we'd really
like some sort of hardware support to
make this thing work efficiently STM on
the other hand gives us really nice
semantics to play with but there's some
performance challenges there's some
overhead if you're doing this
bookkeeping on reads and writes and and
people will work pretty hard to really
you know get this down from a factor of
say 10 to now really just 20% or 30% so
it might be actually viable in certain
situations but large transactions are
also problematic for a couple reasons if
you have large transactions these read
write sets get fairly large and have
their own cache footprint that can hurt
performance and also the larger your
transaction is and the bigger you are
the harder you fall the larger your
transaction is the more expensive it is
to abort it right the more wasted work
you have there's also some interesting
semantic challenges the Brad's question
kind of touched on the semantics of
exceptions right and that's still
something that people are arguing about
we're still trying to figure out what
what it means to have I owe or other
operations that can't be rolled back
inside of a transaction there's some
interesting work going on there and also
conflicts between transactional
non-transactional accesses are kind of
problematic I talked about strong
isolation but not all STM's provide that
you can kind of think of this as a
difference between memory and data bases
it's as if you had you know a database
that's writing to a file system and
someone on the side that's basically
directly editing the files underneath
with an STM you know what if you don't
use atomic to go ahead and read and
write your memory should it go ahead and
be allowed to do anything to it so
there's still kind of a lot of questions
to work out there in terms of what the
right semantics are so here's a kind of
a general summary transactions hopefully
I've argued that they are an attractive
alternative to locks they do give us a
simpler programming model with stronger
guarantees and the
potentially give us better scalability
in certain cases with optimistic
concurrency there's a lot of research
and development that's still kind of
needed in this area we need to
understand performance for general
transactions and provide good
understandable performance to
programmers that that they can go ahead
and debug and have all these tools for
we need to formalize the semantics of
this and and actually one of the best
resources to find out more about this is
is the Wikipedia entry which is pretty
frequently updated these days with lots
of different STM's you could download
and play around with and probably find
out the latest and greatest in terms of
hardware as well so that's it be happy
to take any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>