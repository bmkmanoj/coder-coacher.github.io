<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Seattle Conference on Scalability: VeriSign's Global DNS... | Coder Coacher - Coaching Coders</title><meta content="Seattle Conference on Scalability: VeriSign's Global DNS... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Seattle Conference on Scalability: VeriSign's Global DNS...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2GspRgFQh9k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">morning again I have Scott Kourtney here
from verisign he's going to tell us a
awful lot about how a service that we
all depend on in our jobs our DNS has
scaled through Vera signs rather
impressive infrastructure they now
handle something like half a million DNS
queries a second in a database that is
constantly changing I don't want to give
too much more on that because I think
Scott's got a lot to tell us so I'm just
gonna let him take off right away Scott
okay thank you Andy good morning we can
make this interactive or not interactive
after two hours you might be ready for
interactivity so if you have anything to
say please let me know there's two names
on here Scott Kourtney impact way
somebody out in the hall said was was
patting my parole officer or a federal
marshal based off of my picture he's not
he's actually from verisign but he's
upstairs sick right now so I'm going to
do his section and my section the only
trick with that is Pat understands his
section right so but we'll see how we
can do on that I'm going to talk about
three things today dns refresher and
that'll really just be focusing on on
some of the pieces we run and then we
use google as example the target then
i'll go into an overview of the ComNet
systems and by systems i mean where
they're hosted sort of macro level what
the sites look like and once we've done
that we get into how Atlas works that
was a part pat was going to talk about
and by atlas i'm talking about the
engine that drives the dns services now
Atlas drives other things too at
verisign but super DNS or this ComNet
service is really the marquee
application for it Atlas is our
scalability engine for lookups and
you'll see how that works and hopefully
it'll make sense to you I have to sort
of be tethered here because I've got I'm
going to be pulling up a demo at two
points in this presentation ok so how
DNS works
actually what I wanted to do is I want
to start a look up right at the root
root dns service so here's what we want
to do picture yourself at home and you
want to pull up google google search
which we've been hearing about this
morning on our device at home our home
computer or cell phone or whatever needs
to translate that of course into a
number now typically what's going to
happen with a site as popular as google
is it's going to be cached already right
inside your device will already know
about it or if it doesn't know about it
the recursive name server that it talks
to one one step upstream well we're
going to pretend here it doesn't we're
going to say that you just rebooted all
your equipment including the upstream
recursive name server starting with a
well-known root server we go right to
the comm service let me stop there for a
second to a little bit of background
here root servers I'm not going to go
into them too much today there are 13
lettered roots are there any rude
operators in the room okay so i can
speak with impunity i can make this up
there are 13 lettered root servers
different people around the world run
them on a voluntary effort verisign runs
two of them the a root in the j root and
we do run the avery we do run this
infrastructure from the same sites that
i'm talking about but we've run it on
different hardware and we also don't use
atlas for it we don't really need to
write because if you can think of a root
zone what's really in it the top of the
DNS hierarchy is just the the top-level
domains immediately behind them and so
I'm talking to Dave calm and that but
you also have the other a lot of other
domains right or all the other top-level
domains or all the ccTLDs as we call
them the country codes dot uk' de right
there's not that many domains and so a
very small memory footprint also another
nice thing about root is it just doesn't
change that much right well you have a
few updates coming in where name servers
change for different countries but you
really don't have a lot of updates
because of that we don't need atlas not
much memory not much going on it does
get query load a little bit of queries
nothing like nothing like comnet but it
doesn't need analyst so not much talk
about route today
I am starting with root though if you
look there can anybody read the slides
in the back of the room this isn't an
eyesight test okay and you see where I'm
doing a little dig query I pulled that
number out of the air the 192 58 1 28 30
that address what that is is it's the
address of je root I didn't want to put
a rate up there cuz it seems like
everybody tests against that all the
time so it's going to try a different
one you're any recursive name server out
there will know this already it'll know
it'll have what's called a root hints
file right and it'll know the 13 route
addresses I think in the last 10 years
three of those addresses have changed so
they don't change too often as soon as
you pull up a recursive name server the
first thing it's going to do it's going
to go query one those addresses and
refresh its route list right okay so we
can assume that it can it can locate a
root server by IP address and that's a
that first a dress that I'm wearing and
what I do is I say I want to look up dub
dub dub google.com well remember the
root only talks to the top level domains
below it so it's going to say it's not
even worried about the dub dub dub part
of the Google part is just going to say
com do I know com in this case it does
it knows with com server is and it gives
the it gives the name records for the
common servers and it turns out just
like the route there's 13 of those now I
did this slide myself and I hope you're
impressed by the little circle up there
that look kind of marketing like what
I'm getting out there is why do we have
13 well the DNS response is you know
traditionally 512 bytes its way it's
been in the past at any rate and so
that's as much as we could fit in to 512
bytes 13 if we could have put 29 in
there we would have a 29 the site's
physically have been in traditionally
North America Europe and Asia with a
heavy preponderance of heavy waiting in
the US okay we look up google look down
there in yellow at the very bottom I
just happen to pull out of the 13 one of
the sites and that's the way the NS will
work right it'll start sort of random
like and then it'll it'll have this
waiting
it will go ahead and wait responses
based upon what came in quickest but but
in reality what it's doing is picking up
one a nameserver so we're going to take
that address at the bottom for one of
the com name service and we're going to
repeat our query in the next slide you
see the dig again we have a different
address up there that's one of the comm
servers that we will be talking about
today to illustrate how Atlas works one
of the common server sites i should say
again we repeat the same old query dub
dub dub google com do you know anything
about it well the column servers don't
know anything about dub dub dub right
they know about the second-level domains
hierarchical DNS infrastructure or
design so what we see is the calm server
in this case it says I know a for Google
name records and here's all four of them
and I highlighted one in yellow we're
just sort of randomly picking one again
this normally wouldn't have to happen
but we're saying we're going from a cold
boot here on your nameservers i show off
to the right i didn't explain this
before but the way we're going through
things you see the dot route is where we
started then we talked to doc on the
comp server now we're talking to a
Google name server when we talked to a
Google name server we're no longer
talking to Vera science name sir sorry
the dot-com name servers the verisign
runs I have like a little interesting
fact here I was going to put a light
bulb in front of it but I couldn't find
the light bulb icon but that's the idea
of air you know doesn't really relate to
what I'm talking about their their
assign as built and operates the comment
for structure for I can we have 70
million names about at any time in the
comm database we actually run the net
database with it so it's closer to about
80 million if you go in there and you
look in ended an alpha search on there
for google com there's a few records
that might appear in front of it that do
appear in front of it as a couple days
ago in the few that appeared below what
was interesting to me is when I did a
like search on Google megabytes back of
names that have been registered just
under the calm and net domains not even
talking about all the other tlds you
guys with me so far okay
and a DNS is old hat but we were almost
done with it and it's kind of necessary
to go forward okay so we go to Google
comms name server when we say okay
finally are we there can we can you give
me dub dub dub and of course there is
and that's not the way things are going
to work here there's a little level of
indirection in the google com name
server points us to something called el
de google com okay so now we say fine
we'll go to el de google we're doing I
derivative name searches right we just
keep going working our way down the tree
we do this final search against the El
that particular Google name server and
again our query hasn't hasn't chain will
actually did change I'm sorry you saw
that the there was a maybe I'll go back
here real quickly the name changed you
can see see name on the top line here so
you can see that dub dub w qu com is in
fact an alias for a canonic canonical
name wld google com anyway we do this
final search were given for a records
any one of these will work and normally
in your browser all you would have seen
is you know the name that you started
with google com and you would gotten
response within hopefully a second or so
in this case if you put any of those IP
addresses in there of course the sidle
up here as well two things I want to
point out here about the lookup and the
first is the name server entry for
google com the remember we went through
two of them it's actually kind of an
interesting design that google has here
they have a name server with a DC the
second field in there that says 300
right okay that's actually the timeout
for the record how long that DNS records
supposed to stay in cash and if you look
at the name servers for that el de
google com it's 86400 which i think is
about a day 24 hours that's in seconds
if you looked at that first level google
name server i don't actually show it on
here but that's a four day time out what
that means is if you're verisign and you
want to see a lot of google traffic
coming across our name servers you're
not going to see it right on comm for
instance the comm nameservers there's
lots of queries probably for dub dub dub
google com but we don't see them because
because the timeout
or the google name server is for days so
all that Google traffic all that Google
look up traffic is mostly going to
Google DNS is done can we proceed ok ok
now we talk about the sites this little
map actually gives an overview of the
entire ComNet name registry and what we
do is to start at the far left where I
have something called comnet domain name
registrar so that would be if anybody
here has ever reserved a name and I
imagine must do you have that would be
where you go in you know and you type is
this name available I want something
with the word goog in it apparently and
they'll tell you whether it is or not
the way that happens is it's all through
an application programming interface to
a database that runs in verisign status
enter that whole gray side of things I'm
not going to really talk about much and
the reason why is it's not part of Atlas
it's a traditional commercial database
infrastructure right oltp coming in
cluster database replicated to an
alternate side synchronous replication
back up in terms of Oracle logs things
like that so that's a traditional design
and I think many people in the room who
we probably understand the details of it
better than I would the stuff in yellow
though and blue is a different matter
we're going to get to Atlas in a couple
of minutes the yellows lie the yellow
portion is all about extracting data
from that database and how paranoid we
try to be when we're doing that and
invalidating it and then distributing it
I think Jeff this morning in the keynote
talked about distributing data around
the world and distributions kind of a
key thing for us as well even though on
in this case a much smaller scale the
blue stuff out there are supposed to
represent sites across the various
continents I ran out of space so i
combined the Americas but when we talk
about that we're actually talking about
colocation sites right down again back
on the left the stuff we're not going to
focus on traditional data center
verisign own we have them you know in
each coast and things like that the blue
sites is more like certainly would have
seen with Google several years back when
you go into Equinix or another facility
in
Trinidad cages or something and so
that's where the DNS lookup
infrastructure is arrows I should
mention the arrows real quick in case
you can't see the direction they're
going all that means is we're pushing
data out to the sites and we're pulling
back statistics all the time you'll see
the statistics real time in just a few
minutes okay i mentioned database design
i'm not going to talk about this slide
at all except for the very last button
our very last bullet and that's
isolation this is actually pretty key
for us we can't tie the database which
is inherently an unavailable system
compared to the lookup systems with the
lookup systems so what that means is if
I decide to go in and change the
registry schema for calm for whatever
reason I I can't have that schema change
make me change what I'm doing out on the
site's right change the we're going to
make a copy of what we're going to
extract what's in that database we're
going to push it around the world and I
can't go ahead and say oh gosh every
time I make a schema change ever here I
got to shut down all my sites that would
be tying the availability of what we
have deployed at the edge to what we
have in the data center entry-level DNS
scalability or what we all do this
really doesn't have anything special to
do with verisign right anybody who runs
a DNS infrastructure does this or
portion of this or a lot of this this
goes for the roots this goes for the
top-level domain operators through
several out there besides verisign and
also goes for people who run the round
DNS infrastructure in some cases the
biggest advantage we have in DNS and
it's it's such an advantage compared to
other applications out there other other
protocols is that DNS is client ready
for failover right in other words i can
go ahead and I can have a resolver out
there and it'll pull back three name
records and one of them dies the
resolver is going to get to the next one
and the next one dies the resolver goes
together the next one when the third one
dies that's when the resolvers sometimes
get a little bit wacky depending on the
implementation so we have the
great availability sort of built into
the client and we take full advantage of
this and everybody those DNS does
caching caching is terrifically
important if caching were to go away and
by caching all i'm saying is i looked up
something and i'm remembering what I did
right I looked at Google's the name
server and I'm remembering it for four
days I looked up Google's dub dub dub
record and I'm remembering it for five
minutes caching is just taking all the
queries that localizing your queries
right so that they don't have to affect
the whole infrastructure if caching went
away the world would be in big trouble
for name lookups okay local load
balancing you know what that's about I
believe put many servers behind a single
VIP global load balancing another
approach to go ahead and scale DNS what
we saw on the google site with that
there was one name server and then it
had we were redirected to another name
server as it were referred to another
name server so it looked like a Google I
don't haven't talked to their site
operators but my guess is they have a
standard DNS infrastructure at the first
layer and then they have something
called global site load balancing at the
next layer down the bottom point is
something I want to bring up and that's
bgp anycast here what you do and again I
don't know if there's a lot of several
network operators in the room but with
any cast the ideas I take an address and
I operated out of many locations right
several of the root many of the root
servers actually run this way we run
this as well for one of the root servers
we operate we make extensive use of BGP
anycast to run it out of 30 some
locations around the world today we do
that also an income net for some of our
stuff we don't do it for everything
though and the reason is with any cast
think about this you have a one address
right that you're trying to go to and if
you can't get to it in Japan you might
be able to get to it in Australia right
because you could have an instance in
Australia one in Japan one in the UK
whatever and so it becomes kind of hard
to debug sometimes the issues that
people have it's also i guess it's very
easy to defend downtime if you're a DNS
operator because you can always say well
it works for me you know where where I
am okay we do take advantage like I said
bgp anycast local load balancing and of
course the DNS resolver we don't take
advantage of gsl be at the edge finally
in tavares ines multi-site design what
is it all about well a real design point
is availability right but since this is
a scalability conference i'm going to
talk about the other the next point down
a massive over-provisioning is what it's
about on the scalability side there
assigns a security company right so we
don't really we have dns people we write
our SES we have rude operators but we're
really about securing commnet in this
case and the root servers that we
operate in some of the managed DNS that
we do as well so we have to in order to
get in order to get massive provisioning
what we find is even though we have what
looks like a trickle of queries and a
trickle to me is something you know like
400,000 a second even though we have not
many we prepare for much more than that
we prepare for big attacks we prepare
for dumb things to happen we have and
you'll see this as I get into the site
dynamic filtering capability built into
the actual name servers themselves the
ComNet name servers that'll be the Atlas
sort of thing aren't running bind right
there or we're running a tiny DNS or
anything i were there running our own
implementation that's a one thing Atlas
provides is the name resolution next
point down the plan plan announced by
our CSO this year was a hundred active
physical sites and we are working with
that we're trying to roll out sites now
the hundred sites aren't a hundred Vic
sites are a lot of them are little teeny
things remember we only have 13 letters
so we have to somehow do 13 letters out
of a hundred sites so what you end up
seeing is one of the letters being any
cast just all over the world but in in
very small implementations where you
know it'd be inside an ISPs
a single rack for instance when we do
this this idea of having many little
sites we don't necessarily advertise
them on the open Internet we've run into
problems before in fact with them we had
a we had a service running in a large
Asian country and what was happening was
we have fifty percent package drop as we
sort of left the borders right so we
ended up just advertising it within that
country and in got around the packet
loss so we don't always advertise these
little sites on the open Internet they
might be just within your own ice be
parallel sites preferred over complex
parallelisms I'm going to get to this
point again and again I think you all
probably know it we are sort of
fanatical about the simple design of
Atlas in the simple design of our sites
we would much rather have a simple
server that can die fall over that
doesn't need to have four power supplies
even though it needs one and four cross
connects on the network cables and you
know extra processors or whatever we
keep them really simple as a matter of
fact the more you put into server
sometimes the lower the availability
right I've not seen too many boxes that
can lose a processor and actually stay
up or or even lose a memory stick last
point here major sites are rotated swung
manually during maintenance maintenance
does happen we don't like to show that
it's happening we don't like to affect
anybody with it happening so if we
happen to know for instance in London
that there's some major work going on
that they're going to be playing with a
router one of the one of the people
providing us transit we'll go ahead and
we'll take the IP address that was
served out of London and we'll swing it
somewhere else and serve up the queries
from their local site design I said
simplicity simplicity is again what it
is about there we hear this a lot in our
shop we try to minimize every line of
code every piece of gear every little
distance over the wire between the
customer or the person using the service
and the service itself simple concept
sometimes a little bit hard to do in
practice when you try to marry different
products together so
second the service responds locally
without dependency upon external systems
huge I told you that a database update
should not require us to take down the
constellation of our servers and it
doesn't we try to make these things we
sort of a principle of isolation right
we try to make every box stand on its
own if I lose a box the load gets moved
over to another if I lose a process on a
box it's detected the Box gets taken out
of rotation if I lose another box that's
tied to 10-under boxes all ten drop but
the other the others on the side pick it
up so everything's sort of modular and
isolated it's done that way at the code
level it's done that weight the system's
level it's done that way on the
statistics and the monitoring that we do
everybody's supposed to be have their
own little independent operations design
layered for scalability I sort of got to
this minute ago and I'll get to that
later the idea of how we have when we
get into a site how we have layers of
servers and we can take some of them
down diversity this sounds like a good
idea and then you try to implement and
it becomes it less good but the least
for your workload right the idea what
diversity is we don't have a single OS
sitting out there right or we don't have
a single hardware platform if for
instance we run until we wouldn't be at
intel on all our servers at that
particular layer we do this at the
router layer routers a little tricky i
get the load balancers of course with
the servers and and and with the code as
well we have our Atlas code but we have
other code diverse code sitting right
next to it and it's live it's just not
getting traffic so if Atlas were to die
this afternoon and this afternoon we
would be running on a different set of
name server code of routers the reason I
mentioned that is we get two layers
right I talked about the picture of me
when I got started and i think i have i
have probably a thirty percent chance of
having a good picture taken of me right
that's what they mean by not photogenic
it means really you're not attractive so
you have to you have to get in there and
catch them at the right picture and then
I think at verisign when I had that
you're taken they had like a thirty
percent success rate of making me look
good right with with the camera and
everything in situation so if you look
at the availability between those layer
or you look at the probabilities we say
thirty percent of this thirty percent of
that my other probability of looking
good is about 9% and that's why the
picture was so bad right right here with
routers we have the same sort of
situation if I have a or between any of
these layers if I have a router layer
for instance it's a cisco layer and I
have an ISP router on you know the ISPs
running something like juniper on top of
that right and I have a day 0 exploit
and it takes out every juniper router on
the network and I say well you know
thank God I'm running cisco well it's
true except i get no traffic to my site
because the upstream router which is in
series with it has now failed monitored
boxes are independently monitored i'll
show you that no one administrative
plane is used for the systems i think
this is old hat to everybody here
automation this is we're going to put a
picture up in it right after the slide
automation we have automated zone
updates occurring all during the day
right so if you go and you decide i
really want you know i'm a Mickey Mouse
fan and I'm not worried about Disney
suing me and I want to reserve Mickey
Mouse is my favorite character calm you
can be gratified to see that sometimes
within depending on how fast the the
transaction was submitted into the
database within 15 to 30 seconds you can
usually see that running around the
world at h one of the sites those
updates are constantly being extracted
validated this whole process is running
and pushed out to the edge it should be
on a what we try for is a 15 second
cycle an update every 15 seconds that's
all automatically applied load is
transfer to servers fail that standard
load balancing with use of a health
check and then last point all components
active huge point with me I I don't know
if you've seen me sometimes it's better
to talk about fail you're right than the
way things work and this didn't happen
on atlas what's happened in our other
infrastructure before where we had a
active load balancer in a passive load
balancer and with the passive led
balance or somebody pulled down the
internal facing interface right but
that's not really monitored and you
don't have live traffic going through it
so what we do is that we took a hit on
the the active load balancer hardware
had it failed flipped over to passive
which is now active and it was working
great on the top it's just kind of
reached the ether behind that and so the
site was unavailable what we prefer is
all active equipment I don't want spare
sitting in racks I don't want spare
sites if I can help it active to
everything nothing like production
traffic to flush out an issue I didn't
want to go there so let me show you
picture now this is monitoring for comm
net we do other things with this is we
do other monitoring as well there's
little teeny tabs at the top for some
other things that are there you're
actually looking at a development system
right now the feeds on it our production
feeds so this is the activity being seen
right now ComNet across the world on the
left hand side there's a little
speedometer it says 265,000 queries a
second it's a Saturday Saturday's are
usually bet 75% of the traffic of a
normal day the peak that you see in the
you see the little graph here with a red
traffic jumping around that's today the
green line that it's following is last
week green line of course is average so
that's why it looks smoother you will
see this almost every day outside of an
attack sort of situation or miss
configuration problem on somebody's name
servers you'll see this very smooth
pattern in the sense that it will follow
last week's pattern right sometimes
seasonal changes will happen where you
get a little tick up or a tick down but
almost always you'll ride on top of the
last week you also see that this is
Eastern Time apologize we're mostly
Eastern operators at this point you see
around noon is noon eastern time 11 am-1
a.m. eastern time is the busy time for
dns for whatever reason that happens
every day of the week okay the little
green dots are sites around the world we
have some statistics at the top which
are somewhat believable and not really
it is hard to believe the peruse
generating ten percent of the traffic
across the world so I think that might
be South America right altogether maybe
intro you can see top requests you know
people are requesting these names that
are showing up and hopefully nothing
nasty also if while we're here this is
where you won't ever see dub dub dub
google com or you shouldn't write
because again Google's got that for
daytime out so we just don't see their
name traffic the ones we see here are
our sites that might be a little site
that all of a sudden got a slashdot
effect or maybe a little safe that's
under attack or possibly site this got a
misconfigured name server site that and
problems like that or issues like that
or whether show up on the far right
we've just broken down what you're
seeing over there with all the little
dots in case you can't read the dots so
on the far right we've got our various
data center or colocation sites that
we're running things out of and you see
the TX column which you won't be able to
read but that's a transmissions we have
something called sin file I TX means
just the number of queries that are
being received at the site i'm sorry
sinful I the SF is f all those are
talking about our updates remember i
talked about updates going out every 15
seconds well we're tracking here how far
we're falling behind palo alto for
instance is 6i six of those 15-second
updates behind we if it becomes a large
number we will take the site out of
rotation it'll generate alerts i'm going
to get back to monitoring a little bit
but this is where i transfer over to the
atlas side of the conversation and could
have a time check in the back okay very
good so we're now going to talk about
the atlas design and that we use for st
knows yes
what are you
yeah i'll try to the question was what
do we do in the case of DDoS attacks how
do we filter them how do we redirect the
traffic away say from a particular site
let me maybe I can get to that and if I
don't consider that i skirted the
question because I don't want to answer
it but I'll try to get to it that's a
good question what kind of traffic
growth are we seeing in the requests per
second when i started at verisign which
is three years ago the peak was sitting
closer to around the 200,000 or
something like that so it's it's gone up
sizably but the traffic growth is
actually much smaller than what we'd
have for something like a text messaging
I don't know if you follow that where it
seems to double every three months in
this nation or still we're seeing
traffic go up it's kind of interesting
you see on the internet spam never goes
away viruses never go away right and so
I guess we should expect that this will
continue should I get into you already
go into Atlas the back Wade portion of
the lecture or talk okay introducing
Atlas key challenge keeping up with four
million update today the four million
updates we're talking about here are the
updates coming into that oltp database
now it may seem strange to a lot of you
that we would be getting four million
updates a day into the oltp database I
it names are you know we all want names
but why would you grab four million of
them in fact what we're seeing is maybe
one and a half million adds one and a
half million deletes and you know
something under a million mods anyway it
sort of works out to about four million
why would you have so many deletes in so
many ads that gets into the the
phenomenon of domain tasting that the
world has seen over the past few years
where people will acquire names hold on
to them for up to five days and then get
rid of them if they're not generating ad
revenue or something
like that serving more than 20 billion
requests today when i read that i always
think of the old McDonald's thing right
20 billion burgers sold or whatever I
really were mostly concerned booth
requests per second not how many we get
per day their assigns answer is Atlas
atlas was begun development effort back
in two thousand was until two thousand
four that we actually had it turned it
on in put the other system on standby
sitting next to it that had been there
before so really careful with ComNet we
haven't had an outage knock on what
we've always been available we're
expected be always available that's what
our SLA is it is a hundred percent what
I can and that's why the reason why we
have so much redundancy built into this
and in so much paranoia Atlas provides
bottom bullet framework to manage dns
resolution services and then
infrastructure for the other services
some of the other services are ocsp if
you've heard about that that's for
certificate revocation list the new way
of doing it so you have to pull down the
whole list who is if anybody here uses
who is for calm we run that Atlas on
that our managed DNS is another one that
we've run on it we do a VoIP lookup
service so it isn't reaching into other
areas of the company nobody sees the
traffic in the company that SDNS does
though that comnet does let me go back
to presentation view here where's a
little dot
I don't normally do PowerPoint my
apologies okay when I drew you here's we
have to remember you know what I'm going
to just show you the picture again let
me flip back real quick entry-level
database design there we go way back
there when we drew this up remember we
have the yellow systems that get the
data out of the database and are
paranoid about that and then we have the
blue systems to serve them up we're
going to talk about the yellow systems
right now the data the systems that get
the data out of the database Atlas
distributing updates okay very good so
I'll go through here try to be quick
I've got a lot of talking two slides so
I'm going to hold the slides up and you
can review them on youtube if I don't
cover the individual points too much
data integrity cannot be compromised we
can't have these sort of things have
happened in the past right but we can't
have for instance microsoft com pointing
to another site that would be very bad
for let's say your security updates you
pull through it it also be probably bad
for the poor little site that got just
overwhelmed with the traffic that be a
an attack on its own so we have to be
very concerned about data integrity
updates when we do updates from the
database we got to distribute them so
that they actually appear at our sites
without gaps between names right we
would hate to send some updates and get
them out of order or you drop a few and
just say whoop suis missed sorry about
that scaling issues I've talked about
their the one that's kind of interesting
is just keeping up with the number of
sites as we go to a hundred sites
distributing the update starts to take
more and more processor resource you
know from our first hub that we
distribute to in terms of distribution
by the way we use a hub-and-spoke
approach we pull from the database do
are things there then we go out to a
site and once we're out of sight we
distribute to with some of the boxes at
the site
the first deal yellow box at the bottom
was extraction how do we extracted from
the database we try again to keep the
simplicity rule here we have I'm going
to just let's see jump down to the
middle selection we collect updates into
files so you have this Oracle database
the updates are coming into it in a
certain order we're pulling them out of
it in a certain order again we don't
want to get the order wrong right we
don't want to a lot of people what
they'll do is they'll they'll delete a
name server and out of the name server
which is good it would be bad to add a
name server and then delete it right
then they'd have no name server out
there so we're very careful to to Maci
really order the updates into and what
we do is we pull them out of the
database and we just put them into
little files now these little files that
we put them into are those send files
are those things i was saying get
shipped out every 15 seconds so yeah you
pull a bunch out of the database crunch
on it for 15 seconds and distribute
amount and then you pull the next bunch
out while they're being distributed and
so on actually yeah okay and that's the
way it works we pull them out and in
distribute so those are called little
those are the 15-second updates the very
bottom thing periodically dumped the
database that gets into that restart
ability thing we want to be able to
restart our name servers that are
running the constellation periodically
by periodically maybe twice a day and
that's sort of a key design point with
us any server any service needs to be
able to root beer II started so what we
do here is we pull the whole thing out
we pull the whole thing out and we ship
it out to the edge sites and we reload
the databases we don't do it all at the
same time if you if we were running bind
and we did a reload of comm net it would
take over 20 minutes I believe it takes
us less but it still takes a bit of time
so we have to sort of stagger our
updates it's actually it's really
interesting those of you who've run DNS
if you've ever worked with at 80 million
records own file it's just a little
different business right you don't grep
it for instance that's a few minutes to
the pool record own validation
terrifically important here we extract
we distribute I'm going to get to
distribute just on the next slide but
well while that's happening
the background were validating each in
each a name that we pull out of the
database each and every name gets
verified all right so we'll we'll pull
them out and we'll go back in and check
the database did it look at or not we
also take that stuff and we pull it into
the validator box looks awful lot like
the boxes we have running his name
servers in the constellation so the same
server same operating system same in
memory image and the reason for that is
by pulling it into the validator and
checking on something that resembles
what we have in production if the
validator would fall over we might say
hey that might not be a good idea to
push that out and knock everything over
sometimes a validation of course can be
a little tricky because we have all this
domain name updates coming in we're 15
seconds behind so we have to play a few
games to keep in touch to be able to
flip back in guarantee that what we're
what we're seeing in our validator
actually was what was in the database 15
seconds ago if we do see conflicts at
this point they're bugs they're bugs in
the system I'll give you an example of a
bug somebody goes ahead and they've
requested to me they create a new domain
name and for some reason we haven't
correctly coded for that and so we push
it over the validator and it just sort
of splats right it doesn't have handle
it that would throw a red alert
exception and we'd all go clamoring to
fix that right away the last point I
want to mention is we do have the
concept of marquee domains VIP domains
that would be a domain that gets a lot
of traffic and it would be very bad
thing for us to send traffic elsewhere
so we in those cases if you at any rate
we we keep a little VIP list of domains
that get a lot of traffic I see some
people in this room are at companies
that would be good candidates for that
list distribution this is just that
concept of we extracted we validated
let's get this thing out to the edge
this actually happens while validation
is going on so we pushed these things
out to the edge because we don't want to
wait and then we'll send a little teeny
control file that says yeah go ahead and
apply it the idea here is we
didn't know if you noticed some of the
sites we have we have one in Kenya and
Kenya a challenge because doesn't have a
lot of bandwidth and every time it rains
the site goes offline it seems like so
we we have trouble sometimes getting
updates out there and we can't use the
normal TCP approach right because when
we do that we we would be seeing our
window restart because we TCP doesn't do
well with even point one percent packet
loss but you had it pull up to like
twenty percent packet loss it becomes a
real bear so we have this very brutal
UDP way of a pushing files out double
check every step of the way i think i've
talked about validation we use check
sums on every packet we use check sums
at the full file and then last point
gets back to isolation no global
synchronization remember we are looking
at that slide and I showed you some a
Palo Alto with six sf's fine but some
sites weren't some sites for current or
one or two behind we ship them out and
it's almost best effort right the site
gets hit the cycads fine if we see the
psychic behind too far again we'll take
it out of rotation but we don't try to
put complex software in place to ensure
that it all gets out there at the same
time and you know the this big lock step
across the all the sites we have that
we're all ready to jump let's jump let's
apply the change we don't do that we
covered the yellow stuff now we're going
to the blue stuff the blue stuff was
actually the site's themselves what are
the sites look like okay and Allah I'll
show you that in just a little bit okay
we talked about the traffic to the site
DNS is susceptible to spikes these are
really interesting it's a it does seem
when something breaks it is you know
much more interesting than seeing
hearing how it works you actually
usually get the true story to when it
breaks we are susceptible to spikes DNS
is susceptible to spikes that's actually
the the is bad as an attack on us so
what we try to do is we try to educate
the community in some cases and we just
try to add lots and lots of servers and
services to get around it there's a
paper out there written by a couple guys
that I work with Matt Larsen and Pete
barber that it's an RFC that published
last fall that goes into some of the
things that happen
it does bring to mind the old cliche
never attribute to malice what can be
explained by incompetents you you would
be surprised at what some of these name
servers have done right y'all okay go on
twin goals minimize response to bogus
traffic and of course maximize response
to valid traffic at the DNS site we have
a front facing box this box all it
serves to do is get interrupted I don't
know if you're like me but if I'm at
home and I'm working on something I
really don't like the doorbell you know
if I'm in the middle of something or the
phone ringing every five minutes the PE
on the other hand or this box we're
talking about is just designed for that
right it doesn't have a big brain it
doesn't have much memory and so I kind
of it does well getting interrupted not
that you supposed to read into that but
so what we do here is we have all the
queries that we're receiving coming in
on these little front end boxes and they
look a lot like the boxes Jeff described
this morning commodity cheap not a lot
availability if they roll over and die
they die we'll get them in 30 days we'll
get them in 60 days it doesn't matter we
have the redundancy at the site we have
redundancy across the sites balance sets
a front end back of machine logical name
stirs don't get to have a second on the
next slide to the extent possible
traffic pattern monitoring is out of
band and what that's talking about is we
actually do monitor for attacks and
things we try not to do that on the PE
too much the PE or this box that I'm
calling PE does fulfill to port roles
that one is it pulls the queries in
bundles them up and ship them out to to
a big name server then it gets them back
and it send them back out okay the other
thing that's really important with it is
this is where we can do filtering this
is our some of our d dasa defense that
you had asked about we can push filters
out to PE and say you know what ignore
queries that look like this that are
from this address the second server and
this is a there's really only two that
are involved in name lookup we have the
little one that gets interrupted any
bundles queries and he sends bundled
queries on to this other server sitting
in the back of them that's the
traditional big name server again
running Atlas code and memory database
and why my in frontline server huh okay
so what you see is that front end server
that gets interrupted since its queries
down here a lookup happens here the
lookup after what we do is we bundle
couple responses together and we ship
them right back out to the front end
server okay this box can handle many
more queries than one of those front end
boxes usually right now today we have
about a 10 to 1 ratio ten little front
end boxes to one of these these boxes
have a lot more cores a lot more RAM go
on ok I'm done actually talking about
the infrastructure and i just am going
to put the slide up not talk to too much
i'll let people who want to look at our
ways of coding they can refer to the
slide in here or ask questions about it
we also do a lot of testing i only want
to make a couple points on this test
slide we test to the breaking point when
we do test the breaking point what we do
is we have a we have a test environment
that looks just like one of those a
production sites you saw and then we'll
throw you know whatever the query
limited is that the this I can handle
against it and we're really interested
in layer layer layer by layer
interaction and interaction across the
layers one thing that we learned is that
monitoring system that i showed you a
few minutes ago is the one that we also
try to use now in tests what we are
finding is the people in tests including
my own team we're writing scripts and
then we get out in production be like oh
something weirds happening and why
aren't our scripts out there well we
have monitoring system why don't we use
it there and so that's kind of a best
practice there's some other best
practices on here that I recommend you
look at and compared with your own notes
seeing if there's anything I want to
mention let severity reset in a
non-state I've talked about that restart
ability how important that is again we
get into isolation monitoring I'm going
to just pull up that HUD one more time
and we'll be
done with out there okay so here we are
we're looking at different sites around
the world the top site today on Saturday
happens to be Amsterdam if I move over
to Amsterdam if I can find it on the map
here and click on it and hopefully I'll
get a response here in trouble with
doing a live demo and presentation I see
what is at the site this in our heads up
display so and you'll just have to
follow the mouse here I'm going to talk
to the monitor apologize but I don't
have a better way of doing it so we have
monitoring boxes we have those head in
boxes remember I described them that is
calling pease here's a bunch of pease
the ones that get interrupted every all
the time then we have those those
servers the backend servers the
in-memory databases and there's a number
of them at the site as well I talked
about distribution and how distribution
starts centrally and it gets pushed out
and we have that hub-and-spoke you can
see we have distribution happening and
distribution service here if I click on
any of these little buttons for any of
the servers just like probably a heads
up to spoil you all might have we see
server statistics popping up including
resource utilization or whatever there's
a separate alerting infrastructure but
what we found is when we're under attack
for instance it's really nice to be able
to go in and see how the individual
servers are behaving so even though we
might be alerting for CPU spike it's
kind of nice to watch it go twenty-five
or thirty percent if I did click on
these boxes you won't see any cpu
utilization the comm infrastructure is
idling under normal load on that main
screen where we should the graph of
activity if you did see a DDoS attack or
you saw a big spam attack you might see
a jump up a teeny bit 50,000 queries a
second or something right and that's a
big attack for some people if you see a
real attack on the comm infrastructure
and I've seen those as well it'll
vertical bar it'll go up and the scales
start changing you hit a million or you
know whatever queries a second
I think that the the largest we saw and
it was there was a paper written about
the whole tack pattern was five or seven
maybe five to seven gigabits of traffic
which turns into just a few million
queries a second as weren't even queries
that was a response as they were sending
to us which gets back to that earlier
question how do we handle things we can
handle it at the network layer I'll give
you one example let's say somebody's
sending us a DDoS attack and they say oh
we're going to hit you with 5 million
queries a response is a second well
that's just BAM with us we don't deal
with DNS responses right we're we're
giving the responses we deal with
queries so we can stop that at the
routing lehren and just say we're not
interested in that sort of traffic ok
any questions I were we've got like five
minutes so I was trying to go fast at
the end there anything you want to know
by verisign SDNS actually I have a
question about attacks how long do what
Google attacks last the big attacks the
first of all there's not many big
attacks fortunately against the DNS
infrastructure I don't think it's a wise
thing to do it puts a lot of eyes on you
when you do things like that but the one
I talked about didn't last long at all
there was I think there's attack week
the week before for maybe half an hour
an hour and then the larger one was only
20 minutes when we see DDoS against
people in the internet community of
course you'd like I'll sure gambling or
some of the payment services those can
go on for weeks right is more of an
extortion attempt there yes
right right okay the question was locked
free data structure how do we do that
how do we avoid doing locks I'm going to
answer this is from what I've seen right
I haven't done the written the code for
that that would have been pat but first
of all we have something very simple all
we're really concerned about our domain
names in name servers so when we pull
the data out of the database weeki it
for domain names and name servers when
we have the updates going in on the site
right there's a little 15 second update
things to come in well actually let me
back up when we restart the database
when we pull when we pull the entire
data structure ever we can shut the
whole thing down so if we're not taking
queries at that point so locks don't
apply but when we have these little
incremental updates that come in we tack
them on as it were to the very end of
the data structure there and we don't
use a lock but we do use and we don't
use a system call lock but we do use a I
guess you'd call it a logical lock in
the sense that will wait if somebody's
requesting that domain we will spend a
little on that does that answer it yeah
okay is that it well thank you for being
here I think it's time for lunch right
turn it back over to you Andy oh yeah
thank you Scott</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>