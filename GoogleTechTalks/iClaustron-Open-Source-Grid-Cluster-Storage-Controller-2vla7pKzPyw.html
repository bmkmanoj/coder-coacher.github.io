<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>iClaustron: Open Source Grid Cluster Storage Controller | Coder Coacher - Coaching Coders</title><meta content="iClaustron: Open Source Grid Cluster Storage Controller - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>iClaustron: Open Source Grid Cluster Storage Controller</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2vla7pKzPyw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is Eunice Carson rocky at Google
and I'm happy to introduce mykonos from
here who's going to talk about cluster
databases and I'm especially happy that
he's here talking about this because
kind of can't blame myself for a lot of
things which he's using inside his
system kind of makes me a little bit
probable things are being used somewhere
else than just being in a book somewhere
so my colostrum he's from Sweden he's a
he built the big cluster database system
which is integrated in the my sequel
cluster and this was a project we
started many years ago but not too many
years ago while I was a PhD student he
was peach student and I think he said
he's actually pre-cursor his PhD studies
in database systems which we worked on
for two ish in Sweden and now he is an
independent consultant at I classroom
and he's still working for my squirrel
clusters and I will give him the tour
here okay thank you so the talk today
I'm planning to talk about this a little
bit some new ideas about how you can use
the technology from Maya's good I call
it a grid cluster so you you'll
understand when the presentation is done
well why that where that word comes from
and it's actually not about databases
it's more about storage and handling
larger sums of data them then database
is traditionally used before I do that I
can just sort of briefly talk a little
bit about mysql cluster so mysql cluster
is is a is a storage engine for with
within mysql and
and you have a mysql server and it
connects to other processes in the back
end which is the actual cluster so the
actual cluster is stored in in notes
that we call em dbd so that's where the
actual data stored so that means that
the mysql server is actually just a
client to the mvd notes so that means
that any number of mysql servers can be
clients to this data cluster so that
that means that you can do an update in
one- girl server and any other my skirt
server will see that update and it
obviously means that there's transaction
protocols that distributed transaction
protocols handling and a lot of things
like that from the beginning mysql
cluster was a main memory database and
the reason of that was because i
originated in this work originated from
a company called ericsson which is in
the telecom business and in telecom this
was used mostly to keep track of where
your mobiles are and it's actually still
at the moment keeping track of that so
it might very well be that that if you
have a mobile hear that it's it's kept a
tracker by usage of mysql cluster
because that's the type of system where
it's fairly heavily used so so there are
millions of users today that uses masco
cluster the very first customer that we
had was actually a broadband customer
that develop this foreign dns and dhcp
solution and interestingly enough that's
the broadband operator that I have at
home so I actually was a partaker of the
technology I developed very early on
myself so first the outline of the
presentation so I'm going to talk a
little bit about one of my pet
applications genealogy so already from
the very beginning when I started my
work on databases I was very very much
interested in genealogy so what I always
wanted to do was to build sort of a
database that was able to handle the
genealogy application but never did from
the very beginning it was pretty obvious
that when I started this work in 93-94
even argued on that that that the kind
of requirements that the genealogy
application had was not something that
was going to be around in the next cell
say 10-15 years but temp 10-15 years has
gone by since that time so you're
actually getting very close now to being
able to handle the technology for
dealing in genealogy application there
are other things like email application
where I'm going to talk about the
architecture this extensibility and talk
a little bit about the components of the
architecture
so start with the genealogy application
the best type of for genealogy
application is all the historical
documents that exists and there are
quite a few of them and this historical
documents have been micro team than
they've been scanned into computers as
well so that they are still good in
digital format and there are literally
billions of images where any image is
about one byte per image that obviously
where is dependent and resolution you
want to happen so forth and I guess most
of you are pretty well have knowledge
about mathematics so you can probably
calculate that that means petabytes and
it also means that so it provides an
image data but there is also terabytes
and not many terabytes of transcribed
data and the transcribed data means the
data that you actually when you take the
image and you put it into text that's
the transcribed a property so they see
these are the typical objects that you
would find in a genealogy application so
it's discount objects that I refer to us
as the images and any other transcribed
objects which is just trying to see what
it will write down where the text is
actually written on this out documents
and then your catalogs over all the
images and then you are the action
reports the actual genealogy that's the
application objects link objects i'm
going to show you in the next slide and
then name translations if you take the
name for example maria it probably has
17 different spellings in in one
particular area of a country so you need
to have ways to translate names in an
you know in a way this is probably too
complex but this is the conceptual
scheme up
but the link object the idea with the
link object is that you have the image
here and then you find for example your
great-great-grandfather in a book and
you're very interested you find his
birth there and then of course you're
interested in to see whether anybody has
transcribed any information so that you
can actually read what it says because
try to read something from the 17th
century you will have a problem the
first time maybe the 100th time you will
have a little bit easier task and if
you're into things like image trying to
resolve an image then it can be even
difficult for the brain to resolve
what's on the image but that's another
subject so let's not go into that one so
anyway the link object will show you
what it actually says well at least
that's one view of what could be so
there could be actually several persons
there that have different views on what
it actually says there and then you
could use technologies like Amazon do
with books for example that people have
quality measures on on different people
so that eventually the ones that pops up
highest on the link object is the gap
guys that has the highest quality
according to the community and in this
case the genealogy community and well
it's not so interesting so if you look
about at the image data and think about
building a system for image data it's a
if you have a system with petabytes of
data and all these historical documents
there are really no really very few hot
spots because American people they come
from America Swedish people come from
Sweden well American people probably
comes from Sweden some of them as well
but but there are no particular image
historical documents that sort of give
you more information about your
ancestors than others it's it's very
much spread out so that means that
caching of
the image data doesn't really make that
much sense but obviously it makes sense
to make sure that you can get to the
data very quickly so that you don't have
to jump on the disk several times in
order to find the data so multi
petabytes storage that means at the
moment tens of thousands of hard disks
and many hundred storage servers a
problem which I presume you're fairly
familiar with it Google and when I
thought about this problem and thought
about sort of how do I build the system
with this then my conclusion is that I
don't really want to be in a cluster
that can handle this kind of
capabilities because it doesn't have to
two reasons one is the reason is that it
doesn't release gain that well if you
have a completely connected system and
you want to have quick access to data
the other reason is that you don't
really want this cluster to fail as one
standalone unit if you take the telecoms
telecom system you don't really want to
have a mobile server that takes care of
50 million users because if that cluster
goes down that means that 50 million
users are out of service that means big
headlines so just to avoid the headlines
is a good idea to to split the system
and also it becomes a bit more
manageable if you have split it up so
the first step then on this grid cluster
architecture is of course to have a
cluster and the idea I have in mind here
is the data nodes here that I refer to
as data nodes here it's nothing else
than the the MDB denotes that I was
talking to you about from mysql cluster
so the idea is that I actually use the
database server as sort of as a
clustered storage engine
and in in five that one in mysql cluster
we have developed support also for
storing things on disk so that means
that the client notes up here they're
using very much a techno already
developed technology to get access to
the data in the cluster so then you need
then you need to just integrate that as
a file system so that means that most of
the components to build this system is
already there which is sort of one of
the in meijer a few one of the most
interesting aspects of open source
technology that that you can build on
others you don't have to start digging
on your own you can actually go and
fetch something from somebody else that
somebody else has developed and then
just continue on that work the storage
controller up there is a new thing
however the storage controller handles
two things first of all it handles the
problem that I don't want to have
everything in one cluster so that means
that then there needs to be a way to
export all the data in the cluster so
that others that want to view a bigger
picture than just one cluster can get
access to the data and and all those
other will get access to the data from
the storage controller here another
aspect of the storage controller is to
handle replication the cluster
technology as it is handles replication
by more Les Deux food replication so you
can have a raid 10 more or less if you
think about it as a disk system so the
two data nodes here are mall as mirrored
but if you think about the disk system I
mean and you want to spend money on
buying a system with 30 petabytes of
disks then add
replicated system and probably might
even want to have three replicas and
then you might want to have another
globally replicated system or even three
of them so that means that you might end
up with nine replicas in the in the end
so it means that these 30 petabytes
might eventually end up with 270
petabytes and that's a big cost so so
that that means that we need to have
replication schemes that are good also
on that that has sort of less overhead
so that means that we more or less need
to apply rate technologies but do it on
the cluster level instead of doing it on
the disc level so we play we apply more
or less the same technology that we do
on the inside of computers and we apply
it on the cluster level that's the idea
and that's that's that's the task of the
storage controller so if i look at the
scaling of one cluster in my opinion one
one cluster can scale up to about fifty
hundred notes that's about as far as
it's a good idea to scale in my opinion
and let's assume that we use something
like those Sun server boxes that came
around lately with 48 whore disks that
means that one cluster could handle
about 750 terabytes so we still far away
from the theater bytes that we're
requiring but it's a fairly decent-sized
cluster anyway so we don't have to have
like thousands of clusters in order to
to buy a solution and to have bigger
clusters than this it is of course
possible to build but I'm not
that are both the problem that it has
that cluster fails that's a very big
thing and also of course the performance
goes down the nesting scale and then
it's obviously so that a big problem in
a system like this is that you also want
to pump date out of the cluster so and
here where we assume that you need to
have Gigabit Ethernet more or less
doesn't really isn't enough I mean you
want to have access to more data than
would gigabit ethernet can give you so
you need to have a system that gives you
much much more bandwidth out their
system and today there are technologies
that can give you say 700 megabytes per
second but you also have to integrate
your application make sure that the
threads so it's really an intricate
thing to write the application such that
that the software actually is able to
push something like 300 megabytes per
second out of the system so this is sort
of interesting work that you have to
think a lot about when you think about
which threads do what and how you have
to thank all the way through the
operating system so so my current
literature is very much Linux kernel Mac
OS X internals windows internals and
things like that to understand how can I
integrate the mysql cluster technology
with the operating system with the
clustering to connect technology and
make sure that i get get this kind of
throughput
and obviously you get a fairly large
cash here as well but the ID where the
cash is not so much to use it for four
is not so much to use it for the actual
disc date though it's more useful to get
the pointer to the disc tape and also to
catch to the file information the
attribute information when it was last
updated and so forth and as I mentioned
the data node software is based on the
cluster technology that means the rate
down there needs to be some things done
with with the MDB technology so that
obviously the price storage has
requirements that mysql cluster at the
moment wouldn't support out of the box
so that means that you have to go in and
and do some stuff there and in order to
get to those 300 megabytes per second
you have to do real-time scheduling you
have to lock memory after lock CPUs you
have to really get the controlled
environment because if you if you do a
normal operating system with time
sharing I mean you don't know anything
about which threads is doing what you
don't know what happens to cache
memories you don't know what happens to
basically to anything so it's very much
about controlling your your environment
and ND b is based on research that I did
in the 90s and very much on that
research is that is that you you want to
avoid using go pre build something on
top of the operating system you want to
use the operating system but you want to
bypass it more or less and the
interesting thing is that the multi core
technology means that this is more or
less possible to do fairly easily
okay and you also need the extensions to
handle cache invalidation protocols so
the file system always have to have a
cache and in order to be able to update
things in the clock in the file system
you need to be able to invalidate caches
and you can either do that in the
software and then you need to go in and
do that in the NDB software there's some
tricks there there is an interpreter in
the NDB that you can actually use for
things like that so you more to send a
message down to the data note and say
that please update this record and by
the way if you find that somebody else
keeps a cache about it send an
invalidation message at the same time
yeah well at the genealogy application
is is is an example it would be
interested I mean I'm when I'm doing
this I I have a little bit broader view
than just the general I agreed on that
for the genealogy it probably won't make
much sense but if i use it for some
other thing it makes sense another way
another way of doing the cache cache
quieren see is actually to put it into
the hardware which is something that
they're doing in dolphins so that you
can actually have a cluster with lots of
notes and that you have a cache
coherency protocol in the hardware
another thing which we've been looking
at this to get extremely fast failover
support so at the moment to failover
time when you have a cluster of say
sixty nodes and one of them fails it
takes the cluster about if you have a if
you have a fairly decent operating
system you can probably fail over today
in about one second or so but with a
multi-core system with the real-time
locking and so for that i disgust you
can actually get it down to a veil over
of
milliseconds so that means that you can
have an application that can basically
do things without noticing and that's
what this would be obviously interesting
in some cases like for example the wall
street or something like that where you
don't want to miss opportunities so
maybe not in a file system for genealogy
but as I said it and this is just well
it's more or less repetition but this is
standard so that the client node
software so the idea is to integrate the
file system in Linux and other operating
systems and there is actually very good
technology for doing that very quickly
today called vuze file system in user
space it's most likely not the most
optimized way of doing it but it's a
very quick way of getting something up
and running so and given that we have
actually a cluster here with lots of
tons of computers it's maybe not the end
of the world if it each client node
spend some extra resources and it
obviously have a protocol towards the
data nodes and it has to handle the file
caching protocol and this is just the
display of what happens with the caching
protocol that so this is the data know
that actually did the update first and
then it discovered that the app that
there was a cache cached copy and then
send an invalidate message which got
that copy away
yes turn into an address please that
that would be part of the data model
that you would do then in the data nodes
that that for each open file you would
have a description that so that you know
exactly on which machine that open file
is yeah oh sorry so I've forgotten the
question already so the question was
that the data now keep track of all the
open files in the system and the idea is
that this is part of the data model so
that every record that describes the
file also have information about all the
users that have this open at the moment
and it should gain fairly well since
that information is spread on all the
notes in the system so do you support
the target appliances the target number
of giants well I would guess that given
my experience of mysql cluster i would
guess that you would have about the same
number of client notes as you have data
notes because normally when you have
that's when you get the fairly balanced
between the CPU power you need on the
client notes and the data notes if you
use the mysql server you probably want
to have more mysql servers than you have
data notes because the mysql server has
a much higher overhead in that it has
the product take care of an SQL protocol
for the fight server obviously is much
simpler though you can go much quicker
the storage controller has mentioned at
the end of the data no protocol so
essentially the idea is that the storage
controller behave
it's as if it was a data node and then
it just takes care of that sort of five
catching replication I mentioned before
and I mentioned that it needs to be in
order to actually get those really high
bandwidth you need to integrate some
clustering to connect into this one as
well and the way we've been doing in nmb
is that we are integrated it all works
with tcp/ip and so at the moment we're
working with class tree interconnects
that have socket implementations and
that's very interesting because then we
don't have to sort of rough right
specific wrappers and rather put the
wrapper in operating system so i talked
about clusters and i noticed that the
cluster doesn't reduce gain enough for
various reasons so the idea is now that
i simply take those clusters and i
create a grid so the client notes up
here now they are actually talking to
the storage controllers in the cluster
nodes and they are to take the clock
line no here can then talk to any
cluster so the client notes on this
level can talk to all the great clusters
in this grid so that means that it had
access to much more data whereas the
client notes here they only have access
to that particular clock clusters data
and the obvious minions to connect here
as well and then the grid storage
controller is there if we want yet one
more level of sophistication here I i'm
pretty sure that the genealogy system
should be able to handle with a grid but
maybe you can come up with a problem
that needs one more level so this gaming
here is let's say that we have about 50
clusters more so that we should be able
to get up to 30 37 0 bytes it sounds
like that
and then the full architecture is when
you have so then on the top level yo you
have client notes so i haven't mentioned
the idea with the sort of the grid
cluster here is more or less that this
is in one side and feel so so we haven't
traded dealt with sort of the global
part of it and the idea with a global
port is that we have only replication
between clusters so we only have
replication on the lowest level in the
architecture so that means that in the
cluster here let's say that this is the
slave cluster or let's say that this is
the slave cluster and this is the
monster cluster so then whenever
something is changed here there is a
signal going from the data nodes up to
the replication controller and then the
replication controller sends date over
to the slave cluster and the replication
controller here has to make sure that it
data is replicated to the other side and
obviously on the slide this is a very
short one but it could be a the entire
globe could be there in between there so
that so that part is expected to be a
wide area network and obviously with a
cluster of 30 data nodes and if you have
a high bandwidth I update rate then
obviously you need to have more than one
replication controller in the system and
you want to have failover of replication
controllers and all that kind of things
and a lot of this is already available
in the mysql cluster product but it's
most likely so that it needs some
tweaking in order to handle this kind of
system so
so then extensibility obviously built
your great storage now we're saying and
now you want to grow it because
customers want to use more so obviously
you can add disks on data nodes because
you can just either you can plug them in
if you have a computer that sir can
handle that then you can obviously push
in new discs and then just type some
commands in that makes those discs
available to the cluster otherwise you
can shut down the machine and start it
up again that's not a problem because
that's handled by the data node software
and the same thing with Ram so it's very
easy to add mishe add things to a
specific machine and then the idea is
that we're also going to be able to add
data nodes in the cluster so that you
have a caster up and running and as you
add more data nodes to that cluster this
obviously means that you might want to
reorganize the data as well to to be
spread out in the cluster not
necessarily but you want to have that
capability at least and then you can of
course with this technology with this
architecture you can add a new cluster
to the grid or you can add a grid so I I
mentioned a little bit about the record
format before so the record format is
that there is always data which is
locked into memory sort of so it's about
50 bytes of memory for one for each file
in this case and what the in-memory data
as a file key and the idea is that you
don't really when you're searching for
data when you searching for a file you
obviously have the file name and the
idea is that you you make a hash on the
file name and then you use the file name
as the hashed filename use that as the
primary key that obviously means that
you have some resolution if there is two
to five names that hash to the same
value but
so that needs to be part of the file key
as well but the actual file name is
stored in the file attribute information
so that's the idea and then the
interesting thing here is that in NB you
can store things in this case if you
like but you can just as well create a
table where this information is stored
in memory so if you want to create the
 the file system that's locked to
memory it's very easy I mean it's just a
different command and then all of a
sudden you have a main memory file
system which is clustered and you can
decide it finally attribute the
information is in main memory but that
the disks the data is on disk so it's
very flexible in that way and I don't
think there's anything particularly new
on this slide snapshot handling well
when you deal with file systems there
are lots of things that are new that
doesn't exist that you don't have as
normal requirement in databases so the
one thing to think about is of course
that the data nodes needs to be stacked
with lots of disks but the most of the
controller storage controllers they
don't really need that much this if this
if they need anything if they need discs
at also means that you need to have
number of computers so the major
technical issues obviously if you have a
system this kind of big it's
manageability it's a very big issue so
most of the work that I'm thinking about
right now is sort of how do you make it
easy to manage a big cluster how do you
make it easy to upgrade it so I mean
just think about upgrading a system with
well I guess you have tried it out
and so it's it's a big big issue
obviously that one has to think about
easy upgradeability dataflow I mentioned
that a couple of times already I mean
you want to really have a data flow
going see not only do we have to get the
data flow going inside the machine but
you also have to get the data flowing
going within the cluster so there's a
lot of dimensioning here you have to
actually before you put the system into
place you have to do dimensioning so
coming from the telecom world that's not
new to me I mean whenever you put a
telecom system into place you always do
dimensioning of the system before you
put it into place and I presume it's not
new to you either or at least not to all
of you shouldn't in you response time to
get response time down in a in a means
that you need to tightly integrate it
and the cash invitation protocol and
then other interesting applications
emails like Gmail share these two
databases that's one of the reasons why
i also think a lot about the update
stuff that for genealogy application
obviously isn't interesting but if you
if you use this file system for example
to run an oracle or something like that
then obviously you want to think about
things like that and these are pretty
obvious places to put custard file
system as well so i think there is some
time for more free questions either on
this or if you want to have questions on
mysql cluster as such
oh so the question was have people at
410 FF intervention to the system and
it's a if you integrate it into the
latest operating system it kind of
becomes an NFS automatically without
using NFS but obviously using NFS could
be interesting as well but but in
essence if you integrate it into the
operating system it is a network file
system by default so you don't really
get much benefits and you can actually
view the storage controller in a sense
is in a sense an NFS similar to an NFS
server and NFS has lots of problems so
you obviously have it out there in the
industry so I'm pretty sure that if we
put something that there will obviously
be places where NFS will be used anyways
but it has many drawbacks when it comes
to reliability so failover and things
like that with NFS is not really great
you can get logging you can get five
locks that stay around even after
crashes and things like that Maribeth so
yeah other than the telephones is
allegories
so the question is hotter than the
telecom customers are there other people
using mysql cluster and one other area
which is fairly common to use mysql
cluster is you see is in session
management for web servers so obviously
when you go to a site then you have for
example you're trying you're buying
things for example and you put something
into a session and you want to be able
to come back to that that's a very
popular place to put my SQL clustering
and there are a couple of others as well
but that's these are the two most
popular variants at the moment and then
we're there are lots of others that that
sort of don't come up immediately in my
head but so I think that I have a
question here so it took you quite a
while to build man to be in the first
place right so so whenever you finish
that is well I'm retiring in 14 years so
before definitely couldn't okay so I
mean you could do this a little bit as a
vision so it's not the bum deal or
anything like that but I like to work
with visions so when I did the end the
big cluster yeah I did the PhD as
Jonah's mentioned in 1998 and it's eight
years later now and it's now in
operation in all kinds of places I think
it will go faster with this one because
I'm not building from scratch this time
so i have lots more technology to start
from but it's obviously not going to be
a complete done deal next year yes as it
turns out his PhD thesis is quite
interesting reading because it's
actually this science the whole autotext
for a TV clustering goes very much into
details about storage unit
so a lot of things have been caught up
in the bathroom yeah I asked it's not
they have been thinking about those
problems since the 9th is so so any more
questions do you have any actual numbers
for performance like we run performance
of this clusters on this clusters or on
my skullbuster well we have been doing
in 2002 for example within a test with
my skill tree and leaf clusters it was
at that time and this was with ultra
sport 900 megahertz CPUs and then we
managed with the 13 notes after to get
up to one and a half million reads per
second and 300,000 update / seconds on
my local sort of two dual core machine
running to data nodes 1 science no I'm
able to run 107,000 reads per second and
about 70,000 replicated updates per
seconds so they initially these are very
small updates and reads them so it's not
like keep skin while
so do you have any numbers performance
because using some machines which means
that using ice scuzzy I'll basically
because of disks and some hardware we
tried different platforms yeah we have
we have tried it sorry the repeating of
the question can you repeat it you're
probably a better memory so the question
was if we have tried it on other hall
within some hardware with scott cities
and yes very very much so we tried it
without salt at iskcon with walk and two
pieces i mean it's it's very well names
over the globe so i'm pretty sure we
have tried for that everything is
eventually possible and 24 you for my
doctor is really bandwidth to the disk
we don't really we don't really do very
much sort of random access in the main
memory variant it's all sequential it so
it's all writing and the actual thing
what we have managed to do with the
architecture when we have added disk
data is actually that whenever you do an
update or an insert you more or less
right sequentially still so we have very
much a sequential writing to the disk so
that means that it's not that important
to have a very fast obviously when you
do random access of disks and so forth
of the smaller items then obviously the
disk will but in a file system most of
the data is actually fairly large so so
i don't really see any major benefits
with the skazhi disks sorta disks will
play out fairly well as well in most
cases is the main advantage
you wanna use software over my squirrel
like many muscles that he can banish not
just a great movie together across its
inputs and
that was at the main
then if your hope you say is the main
event list we all go it sounds like
Queen Lord brings us or something what
is the ye is great that why not just
killing my cigar well first of all the
question so the question was what sort
of it's the benefits of this technology
is it a great thing that's or why not
just build this into my as well as such
well the first thing is is with MySQL as
such is that it's a database technology
so where is this is something completely
different or not completely different
but it's the database it's a file system
and and in in many aspects I mean I'm
building upon my SQL technology is so
it's not like that i'm inventing those
parts that comes from mysql that fits
into the picture will be reused of
course so it's not the idea that i will
rewrite anything of that I mean it's
open source so I can grieve that the
great thing is obviously a new thing
that's a completely new idea that hasn't
been in mysql before and hasn't been in
in database technology i mean oracle
calls their 10th version oracle grid but
it's just really as the cluster but i'm
pretty sure that oracle has this kind of
technology in the works as well so so
this is actually where I think that the
cluster technology that is in this is
the sort of the past that plus the
technology both in file systems and in
databases is going so I think that's a
major contribution and then another
thing which i mean i think i'm pretty
sure that the performance of this thing
and the high availability is another
thing that that is i mean if you look at
the custard file systems that are
available out there it's very few of
them that give you high availability as
an open source technologies
there are many more questions
okay thanks for coming and catch us
again on google video</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>