<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Seattle Conference on Scalability: Building a Scalable... | Coder Coacher - Coaching Coders</title><meta content="Seattle Conference on Scalability: Building a Scalable... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Seattle Conference on Scalability: Building a Scalable...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PTT6Oz_glcs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to introduce khalid ahmed from
the platform computing group Thank you
Thank You member so I'll have my 15
minutes of fame on YouTube on these days
okay great thanks for coming out here
and thanks for Google to put on this
conference so what I'll be talking about
is scalability in the context of grid
computing giving a little bit of
background into a platform and our
products and architecture and how it
works and then talking about some
experiments and and scenarios that we
did in some large-scale clusters and
show how we address some of the
bottlenecks that we found and how we're
kind of going forward in terms of
supporting these large-scale distributed
computing infrastructures so just a bit
of a platform probably a lot of you have
not heard of who platform is where a
private software company based out of
Toronto Canada but 500 people we've been
around for 15 years working in a number
of vertical industries enabling our
customers to deploy out large scale
computing infrastructures so companies
like in electronics manufacturing and
financial services who use computers to
do a lot of their design work
simulations like chip design car crash
simulations risk modeling financial
analysis and so on they use our software
to help manage their distributed
infrastructures and enable their
applications to run within this virtual
supercomputer or virtual computer okay
this is just a overview of the products
that we sell into the market basically
what we provide is a layer of workload
management software that allows you to
run different types of applications
whether they be batch or
service-oriented high performance
computing
applications and so on on a common set
of resources we support a variety of OSS
and platforms integrating them into a
sort of a heterogeneous resource pool so
the main products that we sell in the
market are LSF family of products that
deal with batch types of workload
primarily used in electronics and
manufacturing industries are Symphony
middleware which is oriented at high
performance computing in a financial
services context where you have a bunch
of services that need to be provisioned
and started up and messaging layer
allowing you to send task to these
services and and do the computations and
so on around that oh we have a number of
other products that we're also selling
in the market and embedding our
technologies and other applications so
for example we have an arrangement with
SAS that uses some of our grid computing
software within their their bi analysis
and those kinds of tools so underlying
the products that we sell is basically a
common technology platform that we call
the enterprise grid orchestrator that's
more of a marketing term but and this is
what I'm going to be talking about
primarily today and and and talk a
little bit about the how we use this
this enterprise grade orchestrator layer
within the the LSF and symphony product
family okay so let me just give you a an
idea of the kind of approach that we've
evolved to over the years in working
with a variety of customers in different
industries right so we see there's
there's a need for you know all there's
all different types of applications
within these customer environments you
have the traditional you know batch
types of parallel computations you have
more of the service-oriented
applications you have j2ee and so on
right there's all these different types
of middleware and what we need to do is
provide a way of getting those
applications
to run within a common infrastructure or
shared infrastructure so our approach is
really to look at all these devices the
nodes within the environment as
basically an anonymous collection of you
know server CPUs memory and disk right
and we treat the OS that runs on the
those devices as basically a device
driver right so you're really trying to
aggravate all these devices together and
create this virtual computer on top of
it and you're using these underlying
devices as components right so this is
very similar to the Google model right
of disposable computing where these
resources can come and go and fail and
so on so in order to address the issue
of connecting these resources to the
applications on top we break up the
problem of distributed computing into
two layers right one is is a generic
resource management layer right so the
idea is basically to create a meta OS or
a grid OS on top of the individual note
note os's and this is I'm using the term
OS in the loose sense right but the idea
is to aggregate all these machines and
be able to out monitor them allocate
them instantiate activities or processes
on them so a lot of the basic primitives
that OS provides on one machine you're
looking at trying to extend out onto a
large-scale distributed environment so
beyond that to connect the applications
what you need is another layer of
software that interacts with this
generic resource manager that deals with
the nuances or the special requirements
of each of these different types of
applications right so we have the notion
of a batch workload manager that's again
an hour lsf context we have notion of a
SOA or parallel services workload
manager in our Symphony product the idea
is that we can enable other types of
middleware such as j2ee and
message-oriented middleware or third
party or custom applica
nations by creating these adapters or
workload managers at the next layer up
to be able to basically understand the
service levels that are associated with
that application what what a unit of
work is within that application is
different across the different
applications right in a batch job is
just a process that you launched in a
service-oriented it might be something a
computational service or a transactional
service that you instantiate in some
sort of container so the kinds of work
and the kinds of the way you measure the
service levels associated with that work
is different but on top of these these
different workload managers you need a
common sorry a common resource
management layer right so there has to
be a single global resource manager that
is able to see the workloads or the
request from from different types of
applications and is able to make
arbitration decisions about what to
allocate to what application how to
handle things like failover right if a
node goes down how do i recover from
that how do I relaunch processes on
other machines and so on so all those
kinds of common capabilities that you
see is being needed across different
types of applications in Middle where we
try to encapsulate that into that
resource management layer right so the
traditional approach has been to build
resource management within the workload
management that's that the traditional
approach so you do it on a silo on a per
application basis you you build all the
capabilities for you know failover
monitoring resource detection and
resource allocation within that but then
the issue is that you cannot support
it's harder to support different types
of workloads okay so that's the approach
that we're taking so let me dive down a
little bit more giving you some
background into the components right
focusing on the resource management
layer first so you know what what's
actually installed on the devices and
the machines and so on and this is
important to set the context because
when i talk about scale there's
bottlenecks within some of these
components and and i'll talk about how
we address those bottlenecks over time
okay so on each of the devices that that
we managed is basically a couple of
demons or low-level agents that are
running one is the the limb load
information manager and that's basically
the forms the the kind of eyes and ears
of the system right it monitors the
resources it understands what's
available on that resource what the load
state is static properties such as you
know OS types and versions and all those
kinds of things are collected through
that so it's a very lightweight low
overhead data collection mechanism that
that we have in there right the PM is a
process execution manager that is more
of the arms and legs in a sense right to
be able to instantiate in control
activities on those bosses launch
processes control them monitor them all
those kinds of things so on top of that
we have this centralized master right a
master machine that has the the lemon
and Pam on there as well and there's an
extra a couple of demons on there so the
first is this virtual execution machine
Colonel demon that is basically the
allocation service within our software
so that's the the component that the
other clients go to when they need
resources right it applies policies on
the use of those resources by different
applications and allows you to control
those according to the the various rules
that you set another component is the
service controller and again if you use
the OS analogy for a distributed
environment this is the equivalent of
the windows service service control
manager or entity on on the UNIX
platform what it does is acts as a
bootstrap mechanism for all the other
services which will run within the
environment so the other services again
are things like our session manager in
our high-performance computing parallel
services are master batch demon which is
the batch scheduler and other other
components so the service controller
manager basically allows you to define
services ensures that they're all
running if the the node fails it detects
that from information that is gathering
from from the underlying infrastructure
and it restarts those services and
things like that okay so that's the
basic component model let me give you a
little bit of operational overview of
how things work within the environment
when you have a workload manager running
on top of this this resource management
infrastructure so our symphony
application or a symphony middleware
basically allows you to define or
register applications that consist of a
set of parallel services right within
the environment and one of the
components within the that middleware is
a session manager right that's the kind
of the central master for a given
application it can be multiple session
managers running on an infrastructure so
to support different types of
applications so what the session manager
does is basically in response to client
requests for processing computations on
a grid environment it will talk to the
the allocation services of mkd to
request resources so this is the model
again if you use the OS analogy of a
memory manager on an OS and a program
doing a Mallick call to request memory
except in this case we're looking at a
distributed set of machines so we're
requesting give me 500 cpus with this
much memory which this OS on it and so
on these attributes on it to be able to
run my computation so the the the ego
Colonel basically applies a resource
policy the set of resource policies that
arbitrates between a set of consumers
right the consumers of resources that
are going to be using that resources and
you define thresholds about how much
resource each consumer has access to and
then their ability to potentially share
resources between them right so one
application can say that I need you know
100 CPUs but when I
not using those hundred CPUs I can lend
at those CPS to somebody else who might
need it okay so that's the the colonel
resource policies okay so then once the
resources have been granted the session
manager or any workload manager running
on top of this this resource management
layer then makes use of the execution
services so in the symphony context we
have components for managing services
that the lifecycle of service is a
service instance manager down here and
then the actual oops okay going the
wrong way then the actual service is
within that so once that is done the
resource management system basically
acts more than a monitoring and control
layer after that so that all the
messages begin to flow to the services
the computations are done and then the
results are sent back to the services
now the system only gets involved when
there's a failure right so a node goes
down will inform the session manager
about oh here's a node that went down
i'm going to give you another node as a
substitute in its place right it'll tell
you when the you know processes go up
and down if it started or if it exited
or if it failed and so on so it's
basically on an exception basis and then
also we get involved when there's a
reallocation decision that needs to be
made let's say another application came
in that was a higher priority and needed
those resources so that we reclaim
resources from the the the client that
we granted them to so that's the the
basic components in the architecture
what I'm going to focus on next is the
the way we gather the information so the
limb and how that works right so we're
seeing requirements from a variety of
customers to scale the the kinds of
clusters that we manage to thousands of
machines today we are able to in one
cluster one
one management domain be able to handle
about 5000 nodes and we're seeing some
requirements in and especially in
financial services electronics and so on
that are driving these these numbers up
quite significantly right so you know
today we are at 5,000 nodes and we're
looking at going to in the next year or
so going to 10,000 nodes with about you
know if you look at 20 k sockets and 40
k cores right within that environment
and then going even beyond that to
fifteen thousand and twenty thousand in
the future so the question arises you
know how do we scale our infrastructure
to be able to deal with these kinds of
numbers right so not only are the number
of machine scaling but the workloads on
those machines are also becoming more
complex right so you're talking about
you know millions of jobs within the
system at any given time and jobs in the
sense can be either sequential jobs
running on one machine at a time or a
large parallel computation requiring
multiple machines okay so this is where
the customers are pushing us towards and
what we were doing in our experiments is
to see our basic clustering layer
clustering infrastructure is built
around this this Lim Lim component right
so as I mentioned the limb basically
runs on every node is able to collect a
bunch of formance information so we have
a bunch of metrics that we have out of
the box you have the ability to extend
that and add additional metrics up to
255 dynamic metrics that you can also
add that that need to be able to be
collected on those devices right so
there's a central master in here and
that you know every time you have a
central master you think okay that's
going to be a bomb line right so how do
we address that as I said you know today
we have ability to handle for 5000 nodes
with 11 central master and then
looking at scaling that beyond that ok
so the limb comes with a set of AP eyes
and so on that allow you to tap in that
information basically the master limb
maintains a a centralized kind of
real-time or near real-time inventory of
all the machines and the current load
status right so you know what's going on
in those machines from a memory CPU
utilization run queue lengths and all
those kinds of metrics from that
perspective so here's just a little bit
of a screenshot of being able to take
that information from the master limb
right so one central point where you can
query you know 5,000 nodes and and push
that into a kind of more real-time
monitoring console so we integrated with
a open source technology that allows you
to do the graphing and charting and all
those kinds of things so let me drill
into a little bit more into the
architecture of the limb it's it's a
relatively simple component it's all
written in C and and most of our
technology at the at the resource
management layer is and see in order to
be optimized and so on so so the limb
basically keeps a in-memory database of
cluster information hosts information
and other types of resource information
and what happens it's it's basically a
there's a information collection
component that periodically gathers
information from the OS by either using
API calls into the OS layer and into the
OS kernel or potentially by if you're
getting external load information by
invoking commands or whatnot to get that
so the other component is is basically
information distribute distribution
mechanisms so we have you know
collection capabilities on all those
nodes then we have protocols to allow
you to centralize that right so you we
publish that information back to the
master node so that clients can query it
and make decisions about what's going on
ok an underlying that we there's
basically
communication channel oops just based on
TCP and UDP so we have a lightweight
library that wraps around these services
to abstract away some of the details
about connection management and those
kinds of things so through the through
the channel mechanisms we communicate
with other limbs or communicate with
clients and so on okay so let me talk a
little bit about the protocols within
within the limb how they communicate
with each other so basically because
we're using you know using this to get
basic information about the nodes
whether it's up or down whether its
availability and so on we decided very
early on to use a very lightweight UDP
protocol so when a limb comes up there's
one of them is elected as the master so
there's an election algorithm to handle
that I won't go into too many details
about that just because of time but one
of them is is becomes the master and he
sends out master announcements so these
are UDP packets very small pockets you
know on the order of a few dozen bytes
that announces itself to the other
slaves the slaves registered themselves
by basically sending a confirmation
message saying that ok here I am here's
my basic static information about you
know OS type and a number of CPUs and
total memory configuration that I have
right so that registers itself with the
master then after that they periodically
send load updates right so these are
done on so we sample every five seconds
by default and we can send updates every
up to every 15 seconds right to the
master node so we get a you know a good
idea but what's going on in in somewhat
near time about that we do some
optimizations in here to make sure that
you know if the load hasn't changed very
much you don't send that information
right but there's the load updates also
act as a heartbeat so that at certain
times you have to within a timeout you
have to send and load update right so
you see that
within an environment you're going to
see a lot of these load updates being
flowing to the master right and the
master being able to to aggregate all
these and collect these and and and
publish them to two clients that that
needed so this is the basic single
cluster mechanism right what we have in
terms of protocols is also the ability
for two clusters that are independent to
communicate with each other each other
and exchange information as well at that
level so this is the the multi cluster
type of technology that we've actually
had for quite a while as a base protocol
that enabled two clusters to communicate
with each other and exchange load
information about each other so that
they can make you know again decisions
either for monitoring purposes or
scheduling and resource allocation so
what happens in this model is that
there's basically some protocol messages
to allow you to discover who the master
is on the other cluster so one of the
bootstrap mechanisms that you that you
need is that each cluster has to be
configured to know at least some of the
nodes right it doesn't matter which ones
they are at least some of the nodes
within the other cluster so that it can
query them and say you know who's your
master so then it dynamically locates
the master establishes some
synchronization information between the
master so that they know what machines
there are within that cluster and you
know what their basic information is
right and then on top of that so what
happens is that we establish TCP
connections between them between the
masters and then we do load information
exchange between them but unlike the
single cluster case where each node is
publishing information to the master
periodically we do this load exchange on
demand right so if a client on one
cluster needs to know the information on
on the other cluster it will query that
cluster and get that information over
TCP connection right and that TCP
connection
maintained over the lifetime of the two
if it drops then we connect and so on so
we want basically a low latency
mechanism because the amount of
information that is going between
clusters it's much larger than from a
node to the to the master on one cluster
okay so you know there's some more
details about that how we do some of the
load information there's a bunch of
techniques that we use to make that
efficient and scalable within that
within those clusters okay so let me
talk a little bit about some experiments
we did up at CERN I mean you know trying
to address scalability issues when we r
you know relatively small software
company we don't have the infrastructure
of Google we have to rely on our
customers to be able to work with us and
so on to enable us access so CERN has a
long term lsf customer of ours they have
access to a fairly large cluster at
least in that context but 7000 cpus
close to 3,000 host physical hosts and
what we did was to allow us to simulate
much larger clusters and what is
physically available we have this this
what we call our own kind of
virtualization technique where we can
run multiple limbs on a machine and
simulate the effect of multiple hosts
within that cluster so that we can
simulate you know 20k 10k 20k types of
physical machines because the bottleneck
is going to be around the master not on
the slaves right so the master
configuration that we had you know
basically a dual core or quad core
machine with two CPUs 16 gigabytes of
memory and what we did was you know
we're using a variety of you know basic
low-level tools to basically measure
what the bottlenecks are around the
master and what we can do to potentially
alleviate them okay so this was actually
experiments that we did a few years back
when we you know trying to get to that
that 5,000 number and we
did some optimizations that I'll talk
about then go going forward what we're
trying to think we're going to do for
much larger clusters right so actually
it turns out that this is for a 3000
host cluster right it turns out and this
is measuring the actual number of
messages or per second that are going to
the master right from it from the
machines oops what actually happens is
that there's a peak that occurs at
initialization that's where the bomb
neck actually is when the cluster first
comes up when a cluster first comes up
and it sends out all these announcement
messages right to a 5,000 node cluster a
lot of those packets get dropped right
by the OS itself the network is not
actually a bottom like it actually
delivers all these messages to all those
nodes and and all those nodes actually
receive it and then they send back
messages quickly right to initialize and
then you get kind of a flood of messages
that the master cannot handle at steady
state it's it's relatively okay in terms
of the number of messages per second the
the master limb is able to process all
those messages and and update the the
in-memory data structures and so on so
it's really the initialization period
that happens either when you're starting
up the cluster or when there's a
failover that's a bottleneck so there's
actually a fairly slow restart time
where the master reconnects with all the
machines and gets their their load state
and so on again so it takes you know on
a five-thousand-dollar it took about you
know 35 minutes to for everything to
kind of start to sync up again right
where you get most of the hosts becoming
available and so on and then the the
peak loads within those are listed here
right so as you see that you know
typically that this is going to overflow
the default UDP kind of buffer buffer
sizes within the OS although we can
increase them you know the we found that
there's actually a better ways of
handling that okay so this was kind of
the first bottleneck that we faced a few
years back and we looked at a
variety of solutions right so as I
mentioned that you know we can handle
the steady-state behavior but it's the
peak loads that give us the trouble
right and you get into a situation where
you're receiving messages from the you
know previous master limb that was
running they have to be discarded
basically right so you know you know
having these the the software already
running in production and being you know
used in given environment you know we
considered various options right you
know one of them was to okay you know
change the protocols right so that we we
don't have to send as many messages and
that kind of thing of course that has an
impact on stability and behavior and so
on what customers expect so we didn't we
didn't do that what we looked you know
some of the other options things like
multi-threading we considered again
because we run on a variety of platforms
and and and that kind of thing so we
decided to kind of avoid that for now
right and if you look at some of the
other really highly scalable event
processing software like the complex
event processing engines and so on they
don't generally multi-thread because
then multithread also has its own
overhead in terms of synchronization and
conflict between the threads and all
that right so we actually you know took
a conservative approach and we said you
know the problem is that we're sending
out too much information too quickly
right and if we just distribute that the
the master announcements and the
configuration updates and so on over a
longer period of time sorry we would
avoid all the the buffer overflows that
normally occur right so that's actually
what we did so initially we were sending
the master announcements the
initialization protocol over trying to
get all that synchronized within one
minute right and therefore exchanging a
lot of messages within that period of
time so what we did basically relax that
right so by not trying to do so much you
actually get more done in a shorter
period of time right so that's the basic
premises
so we reduce the packet exchange
interval at initialization and then what
we're doing going forward is is to look
at the you know ultimately one master is
not going to scale right at some point
if it's it's it's too much for one
process one machine to handle it's like
putting all your eggs in one basket
right so the obvious thing is to go to a
multi master type of configuration so
this is where we're going to leverage
the capabilities we have in our multi
cluster protocol so that basically you
have you divide up the machines into sub
clusters where each sub cluster maybe
you know one a you know one subnet or
one machine room or one you know data
center within a site right so each of
those so you can have multiple sub
clusters within the environment each
running a master limb receiving the load
updates from that master so that it's it
makes it available then we would use our
multi cluster protocols which actually
exists today right and actually running
in productions to do more of a
peer-to-peer type of clustering right to
use that that capability in a
hierarchical manner so we basically have
another level of master on top of that
right so basically a master master limb
that would in effect run a a one host
kind of cluster right that aggregates
the information from the sub masters and
allows that information to be used and
published to climb so that they can make
decisions on what's going on with an
environment ok ok so we actually did
some experiments in that configuration
again back at CERN and we went for
trying to get you know before we found
that at five K nodes it was about 35
minutes of initialization time we bumped
it up to 10 K nodes right with the
relaxed relaxed message exchange in
initialization and we found that we
could get the initialization time you
know from
look at down here when the cluster kind
of starts up to over here when most of
the nodes have joined the cluster it
takes about 12 minutes on 10,000 notes
right and what we did was again using
the the simulation facilities that we
had at CERN was to see how we go up to
20 k right so we created two sub
clusters each with 10k and measured the
initialization time of the all the
packet exchange and so on that's that's
occurring within those and we found that
you know too thanks of the parallelism
that occurs within that environment when
you have to club sub clusters coming up
at the same time that to 20,000
knowledge about 15 minutes of
initialization okay so that's that's
that's probably okay right for the kinds
of environments that we're targeting and
the kinds of availability and so on that
we need okay so this other diagram here
shows the response time to the master
master lemon the top level master to
request right for load information so
you're making a request for 20,000 give
me the all the load on 20,000 machines
right and we can get that I mean it's
fairly because we're using you know
lightweight binary protocols and so on
it takes about half a second to fetch
information from 20,000 machines across
this environment right a steady state
initially there's some peaks at various
times basically when we're leveraging
the multi cluster so it's kind of doing
it on demand so as the load request
comes in we cash the information for a
little while and then fetch it again if
if it if it's out of date right so
that's where some of these Peaks come in
okay so that's the approach that we are
using at the host level to basically
aggregate a bunch of hosts and know the
state of all the machines within that
environment so okay so the next thing on
top of the limb I mentioned is this
location service so let me talk a little
bit about that and how we are
architecting that and trying to get that
to scale as well right so the allocation
service is basically a a component that
runs on on the the master node that
takes requests from clients to basically
you know allocate me a set of nodes for
to in order to run my work the clients
can when they're done with the nodes
they can release them back into the pool
or the the allocation service can
reclaim them at various times so we've
architected this allocation service to
be able to have a plug-in model so it's
kind of a framework that allows you to
plug in different types of resources
within the environment so our default
approach is to use the information that
we have from our own information
collection service the load information
manager but theoretically it can be
plugged into anything because it's any
other load information collection
service that's out there can also be
used to gather that information and and
publish it into into this vehm Katie we
can also we have a generic resource
model so we also are able to deal with
other resource types beyond just servers
so things potentially X torridge and
networking being able to consider those
as factors in the scheduling decisions
so the allocation service basically
operates on this notion of a consumer
tree right the consumer tree is
basically just a hierarchical division
of the users of the resources right so
all the different applications that can
potentially use those resources can be
organized similar to the way you might
do an LDAP organizational structure
right so if you're a investment bank you
might have a or a bank you might have a
Investment Banking decision a retail
backing group within those you have
different applications and sub
applications and so on so what the
policy engine basically does is allows
you to set thresholds about you know
things like what each unit
owns in terms of number of CPUs how much
they're willing to share within those if
there's any limits within those
environments how much they can use up to
right so it's doing this in a
distributed environment looking at all
the resources that you know we're
getting from the the master limb and
making those scheduling decisions so the
scheduling plug scheduling algorithms
themselves are also plug in so that we
can you know change these algorithms to
see suit different needs in different
industries right different approaches to
doing the allocation that might arise
okay so putting all this together within
the within this resource management
layer right you know you're going to
have basically multiple sub clusters
with a master limb on top of it a
centralized allocation service that's
doing sort of bulk allocation or coarse
grained allocation of resources within
the environment and then multiple
different workload managers dealing with
batch services j2ee or what have you
requesting resources from this
coarse-grained allocation service and
then using those resources to run
whatever workload there is within that
environment okay so that's from the the
information side an allocation side then
when you get down into the execution
side we're also building out this
hierarchy among the execution agents so
that the process execution managers
within those rather than you know one
client talking to all these services
individually to start you know if you if
you need 5000 nodes to run a computation
you don't necessarily want to make 5000
connections from the client to all these
nodes you want to kind of distribute
that so there's going to be a hierarchy
within these these execution managers so
you have basically a broker at every
level that allows you to localize these
things within the environment so you
might do this localization either for
again for scalability or if you want to
control the network traffic so some of
these might be and
sites right different locations so that
you can only go through let's say you
know certain port certain firewalls and
so on so you can isolate the incoming
connections and the outgoing connections
to these okay so this is the the
approach that we've come across based on
the experiences that we've had both you
know experiments that we've done in real
world customer situations that where
we've you know kind of looked at the
bottlenecks and so on and understood
what's going on okay so this is
basically i'll give you a summary at the
the the host level host scalability
level and maybe i can take a few
questions if there are any and then i'll
dive into the to the workload management
aspects of the scalability situation
that we've done so at the information
collection level we found that it's a
good combination to use UDP for this
dynamic load kind of information where
you know the the latency and the updates
are fairly frequent and you want a
lightweight protocol and then use TCP
between kind of clusters or between
submasters and the master master where
you're exchanging a large amount of
information ok you know the whole
hierarchical model that we've you know
we've settled on is is the approach that
were we think allows you to give a
single system view of all these
distributed resources while still
maintaining some locality and the
collection right we still have the
notion of a centralized resource
allocation service because we feel
that's more efficient to do than trying
to do a distributed scheduling problem
right so we do distribute distributed
scheduling but at different layers so in
terms of the coarse-grained resource
allocation all that is centralized right
and then the fine-grained
decision-making about what work unit
what task and so on to run on what
compute node we delegate that up to the
higher order workload manager right so a
combination of centralized coarse grains
and distributed fine-grain scheduling is
kind of the approach that we're taking
okay there are any questions at this
stage okay yeah
yeah yeah
yeah yeah so let me I forgot to mention
that right because I didn't talk much
about data right within within this
thing and data is very important right
but what we found again based on the
requirements of the different kinds of
application there's no one data solution
that works for every type of application
so if you look in the you know batch
processing and eda there's a commonly
the data infrastructure is nice right
filers that allow you to handle all
these you know lots of design files very
sometimes they're very small large
numbers of files in the high performance
computing and financial services where
you're dealing with lots of real-time
changes in market data right that that
is coming and going and you have to
reevaluate your risk positions
constantly writes a lot of computations
based on dynamically changing data the
data infrastructure and those kinds of
environments is often in memory caches
right so different beast and then file
systems if you're running MPI types of
applications highly parallel
applications things like the lustre guys
are doing with cluster file systems are
the appropriate approach in the j2ee
context databases right and sand storage
and so on so each of these environments
are different in the kind of data back
end that you need to support that and
make best use of that so we don't
dictate that that's a whole separate
area right but what we do is do
integrate with those data data storage
mechanisms so that when we do the
allocation of resources we're aware of
things like data locality right we treat
data in that sense as a resource so one
of the situations we had in electronic
design is that we were able to send out
you know thousands of jobs to all these
compute nodes but what they do is you
know fetch the design files and you know
hammered the file is really really hard
and take them to their knees right so
then you get into situations where you
need to be able to wear be aware of what
the load is on the filers and kind of
throttled back right
of the processing that you're doing
right you know ultimately if you have a
infinitely scalable file system or an
infinitely scalable Fowler than you we
won't need that right but the reality is
that there's different bottlenecks
within the storage that is triggered by
the ability to do all these distributed
computations okay I don't know if that
answers your questions or not but at a
high level that that's kind of you know
for the j2ee environments then you know
it's it's a the databases part maybe you
know whether you want to run them on the
grid or not is an open question right
how dynamic you want to make them is
another open question the j2ee is
probably easier to do at the app server
cluster right so at the weblogic or the
jboss where it's they're relatively
either they're stateless or they have
their own clustering mechanisms that
allow them to synchronize the state in
between between requests okay
yeah yeah it's so the question was what
is the overhead on the running limb
right so our customers always want to
use their resources to run their work
and not to manage right so limb is very
lightweight you're talking it's a
written in C and uses system calls to
get all the information by default right
so you're talking less than one percent
CPU overhead if even that and then on
the network side it's it's trivial right
again less than one percent maybe about
10 15 Meg's in memory on the node so
that's on each slave node on the master
node obviously it's a little bit more
okay okay let me just give you a quick
overview of some of the stuff that we're
doing on the workload side I'll go
through this a little fast because
probably running out of time here as
well so in terms of the the workload
scalability our symphony middleware is
again a way of paralyzing a single
computation right so it provides you
api's to decompose your application into
services that run on the compute nodes
and clients that access those services
to do a computation in a kind of a
master worker parallel calculation right
so the components in here I've talked
about a little bit before the main
bottleneck in the symphony environment
is this session manager that's the
central point that receives all the
messages right for doing the computation
it handles the data distribution of
those messages to the to the slave nodes
right to the the compute nodes and gets
the results back and returns them to the
client right so so what you know the
requirements in a more real-time kind of
environment are
around latency and throughput and making
sure that we efficiently utilize the the
resources that are given to us so we
have a variety of techniques that you
know from thread pooling in the sm this
so this is the SSM is written in in a C
C++ it's a multi-threaded application
because we're doing a lot of i/o it
makes sense to kind of handle that right
at the communication layer both both
disk i/o and network i/o and so we did
some experiments at IBM lab and they're
deep computing things to measure the
scalability of this messaging middleware
this just gives you a little bit of a
diagram of the the environment a whole
bunch of racks with Cisco switches and
so on so you know all these the yellow
ones are all compute nodes there's some
management nodes over here which run our
session manager and some of the other
components so we measured things like
efficiency right cpu efficiency so even
if the resource manager gives you access
to 5,000 nodes can you actually make use
of them efficiently can you run all your
computations can you keep the all the
nodes going at full throttle for all the
time assuming that you have enough task
to run ok so what we found is that you
know again this was the the latest
generation we had you know previous
experiences where we have scalability
bottlenecks and and so on around pushing
data through the messaging layer I'll
talk about some of the things that we
did in terms of optimizing the
communication protocols originally we
had things using you know web services
in HTTP on the front end we found those
were bottlenecks right so we switched
over to a binary protocol lightweight
common data representation and so on
that that allows us to transfer these
messages and we got you know fairly good
speed up for tasks that are you know
relatively faster than you know shorter
than you would find in it you know
typical batch environment on the order
of seconds and
maybe you know 30 40 seconds and so on
so we're able to get good speed up with
in those environments fairly you know
almost linear at that at this point we
have the ability to make persistency
within the SSM so that if the client
goes away or the services go away
optional right so that when the messages
are sent to the SSM you can specify a
quality of service that says I will
persist data to disk to handle
reliability or I won't process data to
disk again to get the speed out and
obviously when you don't persist dated
this you get this kind of speed up right
okay so another measurements that we did
was measure kind of round trip time and
again we found that fairly fairly
lightweight you know but five
milliseconds latency on some of these
computations and we're able to get that
down and so on so again basically a
summary of the the approaches I
mentioned initially we had you know web
services and and those kinds of
protocols those don't really scale if
you want to get to that level and that
kind of latency so we're using your
native communication mechanisms and so
on right again a c c++ implementation as
opposed to a java implementation we use
a push approach to pushing out the
messages rather than having the workers
kind of call up to the central session
manager and pull work down we find that
that's more controlled okay and then as
i mentioned making the disk operations
all you know efficient by using multi
threading and and handling the network
i/o through multiple threads and so on
okay so that's basically the approach
that i'll stop here and take questions
because I think we're basically at a
time I do have more sex slides on our
batch experiences but I can you know
handle that in Q&amp;amp;A afterwards so any
questions and/or comments and so on
okay clear as mud sure yeah so the
question was is the master limb a single
point of failure no it's not right so
there's I didn't mention the master
election protocols and algorithms that
we have but basically as part of the the
communication we detect if the master
goes down and one of the slaves
basically picks up as the the role of
the master so it takes depending on you
know how you set the thresholds and so
on it can take up to a minute or two for
that to happen right but you know you
recover all the state and and everything
continues to work so when the master
goes down it doesn't affect all the
other computations that are all already
ongoing so once you've done all the
resource allocation decisions and so on
all those computations are continuing to
process and not being affected by you
know what's happening at the resource
management layer question
yeah so the question was how do we feed
the grid from java based applications so
are the answer is that our middleware or
the server-side components are written
in C C++ but on the client side we do
provide Java api's and Java libraries
and so on right and for in terms of the
management infrastructure we have a base
capi as well as a web services interface
again it's more for control operations
right monitoring troubleshooting all
those things are exposed via Web
Services so you can access and we
provide Java API is on top of that right
to support that or you know you can use
perl python or whatever web service is a
ready language that you have ok any
other questions ok great thank you very
much for your time and patience</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>