<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Selling Interest by the Eye Ball | Coder Coacher - Coaching Coders</title><meta content="Selling Interest by the Eye Ball - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Selling Interest by the Eye Ball</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3cvZT2Y8_iE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody so today we will be
hearing about socially aware
applications to PageRank for the real
world so it's going to be about
computing technology that is sensitive
to human attention and the speakers will
be professor Royal vertical and master
student Jamie Hart from Queen's
University in Canada
we live in a world of noise of confusion
information is everywhere yet no
whereabouts will eat scattered
existences surfing channels of light
through email cell phone to instant
messages and in my quest to find
somewhere down the line was famous we
did not lose our ability to focus but it
seems we may be lost our ability to
focus on the right things
it seems the instant has become the
message now this video will show that
this is dire consequences
super idea with a TV and a cellphone
Carlos you're fired hmm so maybe not
let's do a little experiment I'm gonna
show you slide and I ask you to count
the red squares on that slide ready go
all right how many blue circles were
there on that slide this little
experiment shows us that we are very
capable of directing our attention at
certain stimuli and when we do so we
actually filter out information from the
real world now let me tie this back to a
couple of problems that exist I believe
in in computing today first of all with
the advent of more ubiquitous computer
we now have too many computers so every
two years the number of computers will
double and increasingly these computers
and networked around the globe serving
as information appliances connecting us
to social networks and that means we're
always connected and always on and
always available for disruption of our
work the second problem is that
computers have become simply too much
here we see a pretty standard spec sheet
on in this case a pom one device which
shows 26 features including a messaging
button application button a customizable
button which is even cooler but how do I
make a call the third problem is that
computers are unsociable they're
basically designed to be operated with
the user in full control and
human-computer interaction the H in
human-computer interaction could someone
sometimes be perceived to be standing
for hands hands computer interaction but
what happens in a day and age where
computers themselves become
communication appliances that they lead
a life of their own and I don't know
when the last time was you had a
conversation with your screwdriver but
they're not very good at it
buddy simply enter or changer
information on our automated
registration card when you finish please
make sure that you are connected to the
information and then click the register
meat button below
I will automatically register you what a
fresh perspective
so inattentive agents can be a real pain
and what I would like to suggest is that
we need to actually start paying
attention in design to attention itself
each appliance today still dominates
attention as if it were your personal
computer as if it were the only thing
you had and there's a very poor
coordination or no coordination
whatsoever between appliances so if
you're in the conversation your cell
phone will ring happily not knowing
you're in a conversation and your emails
will keep popping up so the way to fix
this is by having appliances pay
attention to what we do and since when
we're available and when we're busy and
decide how important their message
really is now this ties into a separate
notion that we live in an economy of
attention attention indeed is the fabric
of our economy according to gold harbour
customers buy and sell attention and
technology dominates that attention and
stands in the way distorts that economy
however technology can also measure
attention and that will be the topic of
my talk today so page rank at Google is
a great example of how the world
economies rely on user attention hate
rank more-or-less measures these are
attention by examining amongst others
how much conscious attention a page has
received for example by counting links
towards it and this measure has
revolutionized the online search
business and part of our effort has been
to find an equivalent measure for real
world interaction with customers so
let's go back to attention itself what
is attention what
could say it's the mines operating
system the UM mind is limited in what it
can process in its allocation of
resources and the term retention refers
to the way it allocates processing
resources through focusing of mental
effort in a way that's selective
shiftable as well as divisible and this
happens as early as right in the eye we
see here a picture of the human eye with
the retina at the back and what we see
there is a dark red spot which we call
the fovea now the information that's
being processed in the fovea vis a much
higher resolution than anywhere in
peripheral vision
so there's a real drop-off of resolution
outside that 2 to 5 degree area and that
means we need to move our eyes in order
to focus things in order to filter
things and one question you can ask is
that something that occurs because of
stimuli in the real world or because of
thoughts we have internally and the
answer is both here's a very very famous
study done by Y Arbus in 1967 that shows
that if you ask a different question for
example do these people know each other
how long has this person been away or
can you remember their clothing you get
very very different eye movement
patterns which you see plotted there for
various questions so attention is a
fabric that connects the outside world
to our brain and it's influenced both by
our brain and by the outside world and
without it we're in deep trouble now
I'll show you two pictures and the
question is what's the difference
between two pictures I'll point it out
anyone noticed that big engine dropping
off the plane there well if you're an
aircraft inspector you're in trouble
because you've just missed a very very
important defect of that plane
so how can you measure attention well
here's the current state of the art it's
the Toby 1750 tracker that is also
deployed here at Google in order to
study these ability of a page layout
design and how people use information
and queries and it's it's a highly
problematic device eye tracking has
always been highly problematic this
thing doesn't work over 60 centimeters
users have to sit still within a 20
centimeter radius
it requires calibration for each user so
the system is not walk up to use you
can't just sit behind and it will work
it costs $25,000 us and about 10 years
ago we thought this is silly we need to
do something about this
you know there's no need for these
devices to be that expensive and there
should be ways in which we can make this
technology calibration free walk up and
use and deploy them in everyday use
scenarios like as if it were a mouse for
the real world
so in communication two eyes reveal the
attention of others and this cue is used
to a great extent I show who talked to
whom and they show interest that in a
way that does not interfere with speech
and as such it's a critical cue in group
conversations and we've done a lot of
empirical studies in this in this area
showing that by and large whom you look
at correlates with whom you listen to
and whom you speak to so I'm going to
show he's an excerpt from one of the
experiments we did this was an
experiment we did in 1997 showing four
people you only see three the fourth
person is seated where you are and what
you see is the measurements we took from
the fourth individual that you don't see
so you see on the top there where this
person was looking this is the fovea and
in the bottom you see lights that
indicate a score that was taken after
the conversation asking whom were you
listening to or whom were you speaking
to and what we'll notice is that these
two measures are almost entirely
correlated
don't know me so right now he's
listening to her and he switches to
listening to him and as the scale starts
speaking he indicates attention for all
three but the eye movements become
distributed because of selective
attention you have to look at either one
person or the next do you get this
typical iterative pattern and what you
also see is people look more in that
scenario so this brought us to think
more carefully about that tunnel that
lies between people when they
communicate we can't see who intrudes
because he doesn't notice the ongoing
conversation like people ubiquitous
computer sheets since social
interactions before interrupting people
move in and out of each other's focus of
attention all the time by a proximity
body orientation or even eye contact we
regulate our spheres of communication
aura merit is an art piece that tries to
capture this process it is a video
mirror that paints the bubbles of
attention that people have standing in
front of the mirror on top of their
reflections it uses computer vision to
detect when people are talking to each
other and when they're looking at the
mirror and discussing the art piece when
they are talking to each other there
bubbles merge the already being that
when they look back at the mirror to
discuss this it pops all right so we
took these principles and thought about
how could we apply them to user
interface design we came up with five
different ways in which attention can
apply to user interface design this was
published in communications of ACM 2
2003 special issue on attentive user
interfaces so first of all interfaces
need to show users attention second of
all they need to think about the users
attention and reason about that
attention resource thirdly they need to
sense user attention
ever to know where that attention lies
fourthly they need to negotiate use
their attention and encourage a kind of
turkey turn-taking process particularly
when it's not entirely clear what the
user wants and finally you can actually
augment user attention by actually
increasing the resources that are
available to the human and essentially
allowing a computer to take over part of
the attentive process of the user and
I'll be giving some examples of each of
these categories of enhancement now
first of all this is nothing new this is
a fairly famous picture called the Mona
Lisa it was a picture - it was a painted
awhile ago and one of the controversies
over this picture has been why is it's
so ambiguous why is it so attractive
what's going on here and very often you
hear the story that Mona Lisa is an
interesting picture because she makes
eye contact with you wherever you stand
but that's true for any picture where
the person is looking at the lens of the
camera so that can't be it if we look a
little bit closer at the eyes at the
Mona Lisa we notice that she's actually
not looking at you she's looking off to
the right except it's a bit of an
ambiguous cue because her head is off to
the other side now if we do a Fourier
analysis of this we actually see that
this ambiguity leads to eye contact
perception in very very low resolution
cases such as on the left and we can see
that there's no eye contact in high
resolution cases such as on the right at
the same time there's something funny
going on with the mouth and this is work
that's been done a while ago at a
different American University where they
try to filter the smile and see how it
affected perception of that smile and
what we see is that the very very fine
use of brush strokes in the smile are
essentially not seen when you're looking
at the eyes and the smile disappears
when you're looking at the eye
when you're looking at the mouth however
you can see the smile very very clearly
now conversely when you look at the eyes
she's not making eye contact when you
look at the smile because of fovea
resolution and low resolution in
peripheral vision she appears to be
making eye contact you're essentially
seeing the image on the left and so when
you're looking at the smile she's making
eye contact she's smiling at you she
likes you when you look at the eyes she
stopped looking at you in fact she looks
just just to the right of you which is
particularly annoying and she stopped
smiling what is she doing she's playing
hard to get so this is the first
attentive display in recorded history
and it required no technology other than
brushstrokes
here's another attentive technology the
graphical user interface this is the
first graphical user interface running
on the Xerox Alto in 1973 this is Bravo
the text editor what we see here is that
windows are all about attention windows
are there for a focused task you see
everything in high resolution whereas
icons are there for peripheral vision
and they're usually on the side of the
screen and they are either future or
past tasks that you can open up and
increase the light resolution of now
someone called rick bolt at MIT cut on
to this in the early 80s and designed
some really really interesting
interfaces that were by and large
mock-ups because the technology to do
them for real didn't exist at the time
here we see Rick with a self built eye
tracker in his glasses and a video wall
containing 20 TV stations that would
basically select the audio the moment
you look at these TV screens and that
allowed a kind of cocktail phenomenon
and kind of cocktail MO launched style
browsing of TV channels alright so back
to our principles so first of all to
show attention we've done a lot of work
in video conferencing and this is
arguably one of the more
state-of-the-art video conferencing
systems on the market today the Apple I
side with the I chat conferencing
environment what we see here is that
this person is staring down and the
reason for that is that there's a large
parallax between where the camera is
and where the eyes are represented on
the screen so when the camera is not
exactly where the eyes of the remote
individual are that remote individual
will not perceive eye contact and that
entire queue for turn-taking is broken
and that means that in group
conversations turn-taking efficiency
goes down by about 25 percent and this
is the sole reason why you can't do
telephone conferences why during
telephone conferences you need to have
someone who manages the floor for you if
you show as much as a still picture with
eye contact at the appropriate times you
can manage the conversation and video
does very little to enhance it so here's
a system we built called gaze 2 this was
done in 2002 which shows essentially a
windowing environment like a chat where
the windows flip and rotate to indicate
whom you're looking at and this was
measured with an eye tracker built into
the screen video feeds were selected
from cameras that were positioned behind
the screen using a silver half-silvered
mirror solution such that we could
always select a camera that provided eye
contact and then we would rotate that
image towards the person you were
looking at we could also do
cocktail-party filtering techniques such
as enhancing the resolution of the
person you've been looking at the
longest or enhancing the audio of the
person you're looking at the longest
alright reasoning about attention it's
been a lot of work done at Microsoft by
Eric Horvitz amongst others on this
problem and Eric came up with this
Bayesian solution which was featured in
a special issue on these technologies of
Scientific American in 2005 what we see
here is very scenarios such as for
example a meeting where a person gets an
email from a boss to her inbox
but the inbox doesn't notify until the
appointment with the job candidate has
ended in another scenario maybe the
system senses that the person is at RPC
and composing an email and wait until
that email is done before notifying on
the screen and another scenario may be
your mobile and the system notices that
your mobile and it'll forward the
notification to your blackberry or other
mobile device but it's very very
complicated and
moreover if you don't know what the
person is doing in terms of sensing
stuff in the real world then what you
can do is very very limit it all you can
do is reason about calendar appointments
that may or may not be real and you
don't know for example whether there are
people in the room that a person is
having a conversation with and who they
are and so this is the area where we put
a large research effort in to sense
attention so how can you sense attention
well the eye trackers that I talked
about are very very good in terms of
sensing attention towards a display very
very accurately you can pinpoint where a
user is looking on the display with him
about one to two centimeters however
many of these ubiquitous circumstances
you need something different and we look
back at communication and how humans do
it we see that humans really aren't
interested in where you look they're
interested in whether you look at them
or not they're not even interested in
where other people look the only cue
that's available to them for turn-taking
is actually contact with the other
person and so we design sensors that
mimic that behavior and the cool thing
about that is they do not require a
coordinate space and you do not require
calibration so how does this work well a
camera has an infrared camera has
infrared lights associated that are
placed on axis with the camera lens
Wendy's flash the retina will flash back
this is true for all mammals in order to
increase night vision the retina will
essentially amplify the incoming light
and bounce it back towards wherever it
came from which in this case is where
the camera is as well so in the camera
you'll see this image on the right which
is a bright pupil effect and we all know
this as the red-eye effect in photos
that we so desperately try to get rid of
what we also see is a corneal glint this
is essentially an indicator of where the
camera is on the mirror surface that is
the cornea and so when these two
correspond you know that the person is
looking at the camera it's that simple
in order to find the eyes you have
another set of lights which are set off
axis and what's really cool about this
is the light may
still bounced out of the eye if it does
reach it out of the eye it certainly
does not go back into the camera because
it will flash back to wherever the
lights work and so what we see here is
exactly the same image but now we're
seeing it as a dark pupil subtract the
two images and what you've just done is
found the pupils and this works very
very robustly it's in in Hardware
subtraction all right so with this
technology we said about and created a
number of consumer appliance
technologies that solve certain problems
we believed were due to the lack of
knowledge or sensing capability of human
attention and one of the categories is
called eye appliances and these are
essentially any kind of appliance with
an eye sensor mounted on top what you
see here is a light appliance with an
eye contact sensor on top and in working
with these appliances human group
communication is used as a chief
metaphor so you don't use the eyes to
press buttons you simply use the eyes to
indicate open or closed communication
channels and then the hands or the voice
may provide the commands so here's what
happens if you don't do that turn on the
TV not that one this one turn on the TV
by the fan maybe not
on
turn it off
on turn it up so now the lamp is no
longer there listening to because I'm no
longer looking at it on turn it off
the reason this lamp knows that I'm
talking to it is because it's got this
iconic sensor on top of it that scans my
eyes all the time and it can tell the
lab that I'm currently looking at it and
then a lamp speech recognition engine
decides I'm talking to it just like a
chip this is the iconic sensor mounted
on top that allows it to tell that I'm
looking at it you can do the same thing
with the phone they've also designed an
attentive phone it may look more like
Elmo but I assure you it is a phone and
it won't disturb you by ringing instead
it will search for your eyes and once
it's established eye contact it will
simply put the call through
I roll what's up have you taken a look
at the proof in the article um yeah it
looks good don't think we need change
figure one okay what do you can do I
don't know let's get together an
epilogue sure okay fine so now the
appliance loses eye contact it starts
scanning and then drops the call you can
do the same thing with home theater
appliance all with traditional remote
control such as this universal remote
control is that they have too many
buttons they become very complicated and
they might get stuck in a modality for
example I might be controlling the DVD
player and then when I want to control
the TV the remote control doesn't work
at all so let's get rid of it you might
use a mouse but the problem with the
mouse is I need a surface to move it on
and I also need to specify some kind of
directionality what is it to control it
so let's get rid of it instead we're
using a single button remote control and
we're using our eyes to specify where
that single button goes to what we see
here is an attentive display with a
number of LEDs associated with panes of
content in the display there's a camera
here that is basically focusing light on
my eyes and seeing what kind of corner
and display I'm looking at and all this
is completely calibration free and no
wires attached so let's look at paint
number two here which is streaming some
content from Apple now if I click the
remote here it'll simply blow up that
pain and I have a TV that's just focused
on that content click again and it's
back now let's go to pay number four
which is playing the office and the
moment I look at the pane I can hear the
content if I go to pay number one which
is streaming some content from A to C
the sound goes to that stream or maybe
pane number three here playing a Boeing
concert that I went to and we can listen
to the Bowie concert so let's blow that
up and now I want to see if I have that
song in my iTunes collection so let's
see what I have here so the moment the
speaker
sees me looking at it he'll show me
what's currently on the iTunes list and
currently the song is under pressure so
that's forward to the next song here and
then hit play because that's life on
Mars and now I get the recorded version
so when I want to go back to my during
my live show I need to do some please
bring it myself to my display and play
all right so there are other ways in
which we can use attention and that is
to augment environments and augment the
human brain itself here's a video of a
system we did or cubicles which called
the attentive office cubicle they
demonstrated a scenario that's familiar
to anyone who's ever tried to get some
work done
distraction doesn't just delay the task
at hand there's a cost to brain power
too
it interrupts your train of thought
which isn't always easy to get back it's
something called recollected intent the
worker wears noise-reduction headphones
which are also equipped with a marker on
top one that is read by an infrared
camera in the ceiling his colleague
wears one to their positions inside
their cubicles are detected and mapped
thanks to a special software this is
what's called their social geometry when
a colleague taps on the window a slight
click is heard in the workers headphones
and he can decide whether to acknowledge
it or not if he does he turns in his
chair a connection is made and where
there was once a wall presto it's now
glass are you working on the paper
yeah I'm chef ruining it all morning and
looks looks pretty good and of course we
can a commander worry like that as well
we can have portable versions of these
iconic sensors and record what you do I
contact when I'm receiving eye contact
from an onlooker this led a series of
infrared lights here produces a red-eye
effect in peep
pupils kind of like you have when you
take a picture and there's sort of a red
eye and in the photograph that you don't
want well we take advantage of that that
eye contact triggers the camera to
record the conversation so I'm gonna
come up and speak with rural and have a
conversation with them and and we're
just gonna make make eye contact like we
normally do when we talk with each other
and I'm just gonna say a few things
about well I accept I can't see your
eyes because you're wearing shades dude
well within seconds the video appears on
Connors our blog so this shows how
iconic sensing technology can be
completely wearable but we can also do
the inverse it turns out we can track
the eyes of the wearer and more or less
get an idea of where this person is
looking now prior to this technology it
required a setup like this and this is
actually used by supermarkets to see
what chelle's customers look at and to
actually price out the shelves if
they're if customers are renting those
shelves this is very very sturdy
technology and that it has to be really
really tightly placed on the head if it
shifts a little bit your calibration is
off and all your measurements are gone
what's cool about the view pointer
technology that I would like to to ask
Jamie Hart my my student to to come
demonstrate is that it doesn't require
any calibration whatsoever instead when
users look at a tag using a camera that
is essentially mounted on the head and
that looks at it from maybe a 45 degree
angle or so we can still see that that
tag appears in the center of the pupil
which is what you see here tags are very
very small you basically stick a tag
it's got a battery in it a couple of
LEDs and it beams a code that bounces
off the cornea of the user into a
wearable computer and then you simply
record that and you know what you've
looked at throughout the day this could
be products this could be anything or
this could be interactive and so what
Jamie's going to demonstrate to us is is
how this technology might be used in
order to improve hearing aids
Jamie Hart so this is the current
version of the viewpoint camera that
rule was mentioning um it's very
lightweight wraps around your head and
it's completely in my peripheral vision
so we wanted to think of a way that we
could use this camera to kind of help
out is a lot of research done with icon
to eye tracking and assistive technology
so this is a slightly different approach
a couple of stats on hearing impairment
in general hearing impairment affects
approximately 3.1 million people
sorry 31 million people that's
approximately 8% of the American
population I think it's this estimate is
often underestimated and that you don't
really see many hearing aids around but
it's greater than you think
the major problem with hearing aids is
that they amplify everything in your
environment so I was doing some research
on this recently and one lady I was
speaking to that she said that she can't
eat a bag of chips anymore because the
crinkling noise from the bag is
absolutely deafening so it really does
affect people's quality of life research
has shown that the number one
improvement requested by hearing abusers
is better understanding of speech and
noise as a result of this it seems that
most hearing aid users tend to simply
avoid noisy environments leading to
depression and withdrawal behavior
antisocial nough states have shown that
the amount of noise of background noise
at hearing yard users can tolerate is a
big indicator of how successful their
hearing aids will be so just a couple of
the existing methods of dealing with
background noise the first is called
personal FM systems these are commonly
used in environments such as churches or
meeting rooms they work really well
where there is one speaker and many
listeners the problem is if there's more
than one speaker in the environment
there can be interference and there also
some privacy concerns because anyone
with a receiver can pick up what the
speaker is saying
second of all we have digital noise
reduction strategies so these are
frequency based so they basically
eliminate any noise it's outside of the
frequency range of human speech
the problem is if the background noise
is speech itself they don't work or if
the noise is in the same frequency of
speech they don't work at all a third
approach are directional hearing aids so
these just use directional microphones
to amplify sounds coming from in front
the user the problem with these is that
the sound from the desired sound from
the speaker and the background noise
have to be spatially separated so in a
restaurant environment this wouldn't
work very well because even though I'm
looking at the person directly in front
of me I ought to be getting noise
further back um so this is the current
system we have with a wearable computer
it's the attentive hearing aid we've
called it and it is a wearable
calibration free eye contact sensor that
detects users looking at small infrared
tags in the environment so the idea is
that users can specifically target which
sound source they want to listen to so
they could tag their spouse they could
tag their television their radio their
their doorbell their alarm clock
anything in the environment that they
want to listen to and we're in the
process of getting started on an
evaluation to kind of compare the
attentive hearing aid to some other
methods out there
thanks a lot Jamie so Jamie will be
demonstrating this technology right
after the talk for anyone who's
interested so we live
in a world of noise and a lot of the
questions we've been asking is how can
we allow people to continue to focus
within that world of noise and I think
it's time that we start designing
computers such that they show attention
think attention sense attention broker
attention all commands attention in
order to focus attention I thank you
very much for your attention
oh one more thing
one more thing
there's a new worldwide market emerging
that is a networked ambient advertising
market it's a key growth market in 2005
in the UK alone there were 94 thousand
ambient advertising display units with a
63 percent growth per annum
we now have technology that allows us to
sense whether users are interested in
these ads so that we can sell
advertisements by the eyeball by the
attention and we can provide per view
business model for advertising in the
digital signage industry very much like
that exists online already so
essentially what we set out to do with
the company called Zook is to do
PageRank for the real world to measure
the flow of attention of anything and
for this the spin-off has developed a
revolutionary new live tracking
technology that will own feel today
called eye box - and it's the world's
longest range eye sensor it's got a 1.3
megapixel image sensor it does 15 frames
per second over USB - connection and a
fairly lightweight computer powers the
computer vision and it finds eyeballs
and up to 10 meters distance and it's
available as if now for 999 dollars
that's a factor 25 reduction in the cost
of eye tracking associated with this
technology is a viewing stats software
package and website technology
that is called AI analytics and it
allows us to basically track whether
users are interested in advertisers or
not and let me see y'all go to that
website
so what we're seeing here is analytic
data not sure we're online
okay
yeah we don't appear to be online
and what I would like to demo at the end
of my talk is the eye box technology
it's standing right here I need to make
a couple of switches and then we can
show you this exciting new eye tracker
can you get me online
so Jamie if you would like to stand over
there
always here is this eye box is tracking
her from well over eight meters and it
can track as many people as you want
at no additional processor cost so this
for the first time makes eye tracking a
reality for the real world it allows
walk up the use kind of applications and
it allows advertisers to track hits on
their I ever KY spend much like webpages
can today
thank you very much Jamie
you managed to get the link up I
so let's see how are you doing here
there we go
okay so what you see here is a website
that a customer sees and the customer is
running ads at various locations and can
essentially browse the statistics for
that ad in Barrie's malls and various
locations
so if I click New York here I can see
the ads running only in New York in this
case for this customers two ads running
and I can see two vital statistics I can
see the number of people that are
looking at any particular day and I can
also see the average percentage of time
that people are looking at that ad and
that's a percentage of the whole ad as
it runs if it's a moving ad I can then
go to a specific location and look at
the day and I can see very very detailed
statistics on attendance of that
advertisement at any particular moment
in time and what this allows us to do
for example is migrate ads on a national
network to essentially chase wherever
the people are alright with that I would
like to end the talk thank you very much
for your attendance and if you're
interested we'll set up a demo for the
attentive hearing aid you can come and
have a closer look at that thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>