<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Node.js: JavaScript on the Server | Coder Coacher - Coaching Coders</title><meta content="Node.js: JavaScript on the Server - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Node.js: JavaScript on the Server</b></h2><h5 class="post__date">2010-07-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/F6k8lTrAE2g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hello everybody I have to say there's
a lot of people coming here it looks
like Ryan here is very controversial
it's a pleasure to have him here he's
actually the author of no J's just out
of curiosity how many of you guys have
heard about it yes the first time I
heard about no J's I said what a crazy
guy why would we try to put JavaScript
on a server when everybody's trying to
put Java on the client but you know
since then I have seen the light and
it's quite interesting and amazing stuff
so I'm very excited to have him here so
Ryan's going to talk about his project
nodejs and I'm gonna let Ryan do the
work hi umm yeah well just get started
right so so so notice is this project to
bring javascript to the server side but
in particular I'm very interested in
scripting network servers which gives
the project a certain flavor I think
that that scripting servers is a good
road into scripting other things like
GUI applications if you can do well with
you know a web server with 10,000 people
connected to it at a time then you can
probably handle GUI applications so I'm
very focused on how to deal with TCP
connections and UDP things and that sort
of thing so the I think
the basic thesis here is is probably
that that we need to avoid making
abstractions there's a lot of different
ways to write servers especially for for
high level languages and everybody kind
of employs their own flavor of how to
abstract this problem of dealing with
possibly thousands of different people
connecting to your server at a time and
I think that we need to be careful about
how we make these abstractions and I
mean the the problem is that at some
point you you might have to use those
and you just might feel trapped by them
at some point so really I think one of
the major points of node which I'll try
to describe to you is just to avoid
making all these abstractions and just
kind of present the low-level interface
and allow people to build on top of that
so we want to write high-performance
servers easily important point is easily
I think writing high-performance servers
is kind of a solved problem what we want
to do is be able to throw them together
in a matter of minutes instead of months
so without going into too much detail I
think it's well known that that using an
OS thread for each TCP connection to
your server is not optimal these threads
are too heavyweight to be handling many
thousands at a time the context
switching and the memory overhead is is
just too much and that's why you have
projects like nginx in light HTTP and
Cherokee that have a event loop that our
event loop web servers versus Apache
that used threads so
in order to get beyond this limitation
you somehow need to multiplex a lot of
i/o into each OS thread this is how you
achieve these really high performance
servers and it's really not a mystery
how this is done you use some IO
multiplexer like a polar kick you you do
non-blocking i/o calls you don't share
memory too much between your TCP
connections and then you spawn a bunch
of threads and you probably do some sort
of pre forking sort of things so that
you can accept connections on each of
these threads so each thread has an
event loop running and you push many
thousands of connections into each OS
thread so this is basically how super
high-performance servers are structured
at least in NC that's how they're
structured in other in higher-level
languages like Python or Ruby or err
Lang there's different abstractions that
people use on top of this sort of event
loop plus thread model and I think there
are basically two ideas one is that you
can have green threads which is kind of
a fake little thread that presents your
i/o as as blocking so that you can go
query database return some value read
from socket returns data from from that
socket and it looks very blocking but
underneath you have multiple execution
stacks and you jump back to the event
loop you're all contained inside of this
big OS thread and jumping between these
these little these little green threads
underneath it's the same thing though
green threads are great you can
you can make your code look very
synchronous you can achieve very high
performance concurrency but at the end
of the day it's an abstraction on top of
an event loop airline processes are a
bit more interesting basically the same
thing their processes they're not
actually processes they're they're green
processes if you will the difference is
that that they don't share an address
space with with the other processes they
they they're isolated somehow and
because of this the airline scheduler
can open a bunch of different OS threads
and schedule these these processes into
each of these threads as necessary so
this is super cool because you can now
scale over multiple cores kind of
transparently and I think what's what's
really cool is and kind of the killer
feature of air Lang is that you can kill
these these individual processes without
disrupting the rest of the system just
because they're there in their their own
address space and then there there's
some other concepts of how you deal with
with really high concurrency and I think
a lot of these concepts can be summed up
in message passing systems like actors
some little entity that passes messages
between different things the idea being
that if you don't share memory you can
scale across multiple kernel schedulable
units you can you can scale across
multiple OS threads over multiple
machines if you pass messages and tell
each other what to do so these are great
but this is kind of at a higher level
than we're dealing then
we really want to talk about we're
talking about kind of what the
concurrency mechanism looks like to the
programmer what what does it look like
at the thread level this is something
that's built on top of these other
mechanisms so all these things are great
lots of PhDs have been done with with
these ideas and these these green
threads and airline processes are super
cheap you can spin up thousands tens of
thousands at a time and cost almost
nothing but underneath it's still an
event loop with some OS threads and some
non-blocking i/o so I like C and I
actually like programming with with
non-blocking i/o and event loops I don't
find that this is a bad thing that we
need to avoid necessarily and in
particular I like this this concept
because when you get notified that a
file descriptor is readable and then you
read some some data from it then you
execute some callback and when you're in
that callback you're kind of in a world
unto yourself you're you're somehow
side-effect free I mean not not totally
because you know you can call printf and
that might do something funky or you
know there there's definitely still some
IO some side effects involved but
largely you're just with yourself you
can run your parser you're not going to
be unscheduled you're you're it's it's
just somehow how simpler then dealing
with the fact that another thread might
start running at any point and that you
need to make all of your functions
totally thread safe
it's easy to reason with and I think the
the other point about just this kind of
basic C event loop non-blocking i/o
model is that basically the first 10,000
20,000 30,000 TCP connections or UNIX
sockets or whatever are free I mean they
can they can be put into a single OS
thread you don't need to really worry
about a multiple core concurrency when
you're only dealing with 10,000
connections at once now if you're
dealing with a hundred thousand
connections at once then then things
have to change but at this level of say
less than ten thousand or less than
twenty thousand I think it's fairly
appropriate to write a single threaded
system and I think there's a lot of
applications where you don't need to
worry about more than ten thousand IO
streams at once in particular GUI
applications or simple request/response
web servers that aren't holding
connections you don't have ten thousand
people connected at a time like a long
pull server or something but you're just
sending some request response cycle you
don't have so many connected at a single
time or maybe like implementing a fuse
file system you really don't need
hundreds of thousands of file
descriptors
and this just simplifies everything if
you can just stay inside of one thread
you can have global variables you don't
need to worry about locking you don't
need to do any IPC your world is very
simple insane and nice there's problems
with this
well first problem which is not listed
is that you have to program and see
which is painful and you you you can't
think synchronously no you you have to
yeah right you can't think synchronously
everything has to be somehow
non-blocking right you can't just read
data from a socket and expect that data
to arrive you need to wait until the
data comes to the socket and then be
notified when when that's ready you
can't just make a database call and
expect the results right away you make
the database call you go away you come
back it's arrives later on and it's kind
of all or nothing you can't really mix
in non-blocking libraries which is a
really difficult thing especially if
you're interfacing with something like
MySQL that doesn't have a real
non-blocking client library available
readily so if you're writing something
that needs to interface with MySQL you
probably aren't willing to rewrite Lib
MySQL client so this approach is not
appropriate for you okay so back to our
goal we want to write high performance
or servers easily so basically I'm
pretty much ok with with C and event
loop and non-blocking i/o but C is kind
of the annoying part right it's takes a
very long time to program and C relative
to some of these scripting languages
available so enter JavaScript in the
last year or two years or so it's become
clear that there's an arms race among
companies like you guys and
other guys for making these JavaScript
virtual machines very fast which is
great
v8 is released BSD licensed thank you
so it's an appropriate language in terms
of performance to use more importantly
javascript doesn't come with any
preconceived notions about how to do i
oh it has no printf method right it's
only has the Dom that was it's only i/o
before and that's great because it
probably would have been totally messed
up if somebody else tried to do it it's
great because we can experiment and we
can try out all these all these
different ideas about how I Oh has to do
and not have to play into how JavaScript
already does i/o and browser JavaScript
importantly is a single threaded
interface it has a non-blocking i/o you
make a XML HTTP requests and you well I
guess you can do it synchronously but
for the most part people are doing all
this stuff asynchronously and getting
callbacks when you click a button you
get a callback you don't start a thread
for each button on your web page and
this is worked out brilliantly what a
great idea
it's it's very easy to program with and
personally I think that this is the
reason that the web browser and
JavaScript have become as popular as as
they have it's a very simple interface
and I think the the last point is is
that we have a generation of programmers
who have grown up now learning how to
interact with the computer through this
sort of invented browser interface and
so they're very familiar with what it's
like to program with callbacks
that's not necessarily true of Java
server side guys they find a callbacks
and stuff very difficult to deal with so
node is a project to make a set of
bindings to v8 to do non browser work to
access sockets and files and well other
things what else is there yes that's it
doing timeouts so it only exposes a
non-blocking asynchronous interface it's
only one thread and it's only one call
stack there's no green threads inside
there's no co-routines it has a lot of
low-level features like half closed TCP
connections that nobody cares about
until you really care about it or TCP
throttling or UDP and has really good
HTTP support which is important because
HTTP is is the backbone of our society
basically these days so I said that we
should be careful of making abstractions
I think that node is attempting to not
make any abstractions what it does is
take away certain interfaces well
obviously it turns these POSIX API s
into JavaScript interfaces so I mean at
some level that that's that's changing
things but more or less it's it's
limiting you away from things that you
shouldn't do like synchronous i/o rather
than exposing new high-level ways of
doing things so because the interface is
purely non blocking users tend to
achieve decent concurrency without
knowing what they're doing you don't
to know what an event loop is or what
non-blocking i/o is you live in this
non-blocking Jail when you use node and
it's impossible to escape so you start
writing a web server and you run Apache
bench on it or you start having a bunch
of people from hacker news connect to it
and you go well hey it works pretty well
and everybody's very surprised it's only
that it's not that nodes necessarily so
fast compared to say other invented web
servers it's just that it doesn't let
you do anything that you shouldn't be
doing and because it's this non-blocking
jail there's no mutex locks only one
callback is happening at a time it's
like browser JavaScript there's no
thread safety issues only one thing
happens at a time so once an event is is
emitted once your socket says that it's
readable
you're basically side-effect free almost
there's there's some exceptions um but
that's that's what you want it's it it
calms you as a developer you just you
can relax and just just kind of chill
out because you just don't have to worry
there's not going to be some other
thread that jumps in and you know starts
executing a bunch of stuff when you get
your event you've got it you've got
control of the process and I think that
that for at least for beginners at least
for not super advanced UNIX programmers
this is a fairly nice interface to have
to not have to worry about these things
so the the major complaint is that note
is single threaded oh my god that means
it can't scale across multiple CPUs it
doesn't automatically scale across your
data center this is this is total crap
right
I mean what don't you know Ryan that
like we're have computers now with like
five million CPUs and like we got really
big data centers and you know any new
programming language should definitely
be able to just scale across the entire
world
well don't fear you you really should
not fear there's this great thing in
UNIX called processes and when you have
multiple processes the kernel can
schedule them however it wants to and so
this is really not a cop-out I really
think that this is how you should scale
to multiple cores or to multiple
machines you simply use multiple
processes and mmm
depending on the problem different
problems require different solutions you
might attack this in different ways if
you're a web server you might want to
load balanced say you have eight cores
you might want to spawn eight node
processes start a server file descriptor
and just send message that file
descriptor to the other processes node
provides this primitive it's an age old
UNIX trick and then each of these
processes can simply accept connections
into their own into their own world this
is a fine way to scale this is how
Engine X does it right it's a pre
forking web server without the the
forking part which you can ask me about
later or just traditional IPC we make
creating UNIX sockets very easy so
there's no excuse to not pass messages
around you can just open slash temp node
dot slash temp slash node dot sock or
whatever and have all your processes
connect to it and start sending it JSON
messages or over this and tell it what
to do this is how you scale to multiple
cores this is how you scale to multiple
machines you replace UNIX sockets with
TCP connections
so note doesn't have a built-in actor
library it doesn't have some sort of
framing protocol for doing IPC nicely it
doesn't have an RPC system but it could
it's it's fairly trivial to write any of
those things on top of it so if you want
that you can check out for example Peter
crisis increases a web worker module
which does exactly that and yeah memory
these are processes so so they are
isolated you can kill them individually
if you have a server if you if you
actually had your a core server and you
split your server socket across all the
eight cores and you're accepting
connections on all of them
that's cool if something goes wrong you
might bring down one of those processes
like in Erlang remember we could bring
down any any connection basically
individually because each of that each
each thread each process was was in its
own address space and you could kill
them individually they could crash by
themselves that's fine
that's very cool actually you can do the
same in node you'll just bring down
10,000 connections with it but not
necessarily the other seven processes
that you have running on your server so
you could imagine a system that resends
that server file descriptor after a
crash process back to it note is very
low level it doesn't address these
issues but these issues can be built on
top of it because we're trying to do the
correct building blocks that you can do
the rest in JavaScript on top of this so
just quickly about the architecture of
node node is basically three things it's
it's v8 to interpret JavaScript it's a
thread pool to do file IO or any other
blocking system call you can't get
around that so it has this internal
thread pool by itself but it's only for
executing the these blocking system
calls and then it has an
Loup library which is fairly simple it's
it's instead of having to write a back
end for K Q and E pole and event ports
and select this is a very small layer on
top of it Libby V that allows you to
simply compile to those things depending
on your platform so it eases development
very very well very much um and then it
has some sort of thin set of bindings in
C++ that more or less expose some very
low-level interface basically
non-blocking POSIX POSIX calls the rest
of note is written in JavaScript on top
of that and so the API is that you see
on on the documentation are more mostly
implemented in in JavaScript on top of
these rather low-level C bindings so
that that's the architecture i I think
it's fairly simple so let me just do
some examples to talk about what to show
what what I'm talking about here so
first of all just to make it totally
clear note is a command-line tool so you
you have to download it and compile it
doesn't have very many dependencies
other than Python the AIT's included so
here's the first example this should
seem very familiar to browser JavaScript
people you can do a set timeout which
executes its first argument a callback
after n milliseconds which is its second
argument exactly the same as you have in
the web browser and we also have this
console.log thing which is like the the
Firebug interface that prints something
to standard out so what this program
does is it is it prints hello and then
it prints world after two seconds hello
first so importantly note is a
exiting after it's done so it prints
hello it weights it doesn't exit that
prints world in it exit so note always
exits after there is no other callbacks
to be completed when the event loop has
no timeouts or file descriptors on it it
exits automatically so if you wanted to
do this just to make things super
explicit put that text into a hello
world Jas file call it with the note
program you get hello two seconds later
you get world and it exits so another
example what we could do is loop in and
print hello every 500 milliseconds and
then on sig int on the interrupt signal
when you hit control C you can print by
and then exit the process and so what
we're going to do is use the special
process object so in browser JavaScript
you have this special window global
variable and node you have this process
global variable it's kind of the center
note is very process-oriented
you are inside a single process very
much like in browser JavaScript you're
inside a window okay so first three
lines you're printing hello every half a
second with the set interval function
which is just like browser JavaScript
and on line five through eight you are
setting up a callback you are listening
for the SIGINT event on the process
object so the process emits a the
process object emits a SIGINT event when
it catches a SIGINT signal then it
prints by and because we've overrated
the the signal handler we have to exit
the process ourselves so we do process
exit right so so the process object
emits an event when it receives a signal
so this should all seem very Dom like to
you when you click a button you get a
click event when
you mouse-over something you get a
mouse-over event when you get a signal
you get a SIGINT event or whatever so
this should seem familiar to browser
programmers so just a little bit about
this process object there's a lot of
things that hang off of it so you could
get the the paid and the the arguments
in the environment and could get the
memory usage which is kind of cool
because that's totally a platform
dependent and spent a lot of time
researching what how to figure out the
resident memory for every platform and
so on so the process isn't the only
thing that emits events in node lots of
things emit events a TCP server emits a
connection event every time somebody
connects an HTTP upload if you're
uploading a movie to a web server emits
a data event every time a a new packet
of information comes it's this event
emitting is is the kind of the
fundamental model in node they're kind
of nice interfaces wrapped around file
descriptor notifications so let's let's
do a little TCP server you listen on
port 80 you when somebody connects you
send it a message you send it hello and
then you close the connection just to
see what what servers look like so this
requires a module require is how you
load a module in note this is the common
jas module specification so you load the
net module which is how you create a TCP
server and you do net create server
gives you a server instance and then you
listen for the connection event on that
object that connection event gives you a
callback with with a socket which we
call see here and all you do is you you
on that callback you you do a see end
which sends
the argument to the to the connection
and closes the closes it in one fell
swoop and then if that's all you had if
you omitted line 9 the the program would
just exit immediately but if you start
listening on port 8000 which is what
line 9 does then the the process stays
open because it's it's waiting for
connections now so if you want to try
that you could put into server je s and
run it with the node program and then
you could tell that to port 8000 and you
would get hello and it would close your
connection so you can do file IO in the
node as well so this example uses the FS
module which is where all the the file
system methods lie and what we do in
line 1 is just pull out the stat
function from from that module and what
we want to do is find out the last time
that EDC password was modified and so we
stat EDC password just like the POSIX
call and we get a callback so right I
mean very likely EDC password is somehow
cached and this function this system
call that we actually make two stat like
execute very very quickly but it could
be that it's not we don't really know
and it could be that you know an actual
physical disk has to spin to figure out
the time that EDC password was last
modified because of that we don't want
to wait for that especially if we're
inside of a crazy server that's got
10,000 people connecting to it at the
same time and we have to manage all
these people at the same time we can't
wait for some disk to spin very very
slowly so we don't we do it in the
thread pool and we get a callback when
the internal thread pool has executed
the stat system call
so that callback gives you two arguments
the first is error which
is some sort of error object I if this
call was successful then then that that
object is null if not it's it's it's
some it's some error object saying EDC
password was not found or something like
that so if we have that error object
then then we could throw it and and
we'll get a stack trace otherwise we're
just going to print a print out the last
M time from from the result okay so a
simple HTTP server getting progressively
more interesting so we can load the HTTP
module and we can create an HTTP server
on line three and what we get is a
callback this callback is not executed
for every connection but for every
request because of course we have
keepalive sessions these days and you
have many requests per connection and
for each request you get a request end
response object and all we do here is we
write a header which says 200 ok content
type text plane and then we write hello
and then we write world and then we end
the response and then on line 9 we we we
bind to support and start listening so
this is slightly more complicated than
say if you're familiar with Ruby the the
rack interface where you just return the
body of the response but there's a good
reason for this added complexity and
that's to enable all the many
possibilities of things that we can do
with with HTTP requests and responses
example forthcoming so it is output the
this code into HTTP server Jas run it
with the note program curl it and you
will get hello world with some headers
if you notice a happily the connection
defaults to keep alive yes and also
transfer encoding is chunked it's not
the identity transfer encoding there's
no content link
that's because we while we were writing
out the header we didn't really know how
long the body was somebody could have
just kept streaming some responses some
some more data so we couldn't possibly
have given a content length so the
server defaults to chunked encoding and
and chunks those things out so that you
can stream them okay so so now a real
streaming HTTP server everything is the
same here we write a 200 okay content
type text plane on line five we write
hello but now on line seven we set up a
timeout for two seconds and at the end
of two seconds we rewrite out world and
end the response so this timeout it's
not a sleep the the server does not shut
down when it hits the the timeout it
simply goes back to the event loop it
registers that callback and goes back to
the event loop it hangs that connection
more people can connect to it and they
also won't get responses immediately it
can handle many connections at the same
time it's not sleeping the process
doesn't shut down it's simply waiting
for those timeouts to happen and when
those two seconds are up it responds
with world world world world to all the
various requests that are connected to
the web server
this may seem initially slightly
esoteric but it's it's exactly what you
need to do the sort of long polling type
of websites that are becoming more
prevalent these days you need to be able
to hang a connection and respond to it
when you want to respond to it not when
the server wants to respond to it
and we can do that with note it's very
good at that
so if we wanted to try this out we could
put that code into HTTP server to us run
it with the node program curl it and we
would get hello and two seconds later we
would get world we can stream responses
so this HTTP module is quite low level
if you noticed it allows streaming
requests and responses allows requests
to be hung while waiting for other
things which is necessary for long
pulling all of what I just said the HTTP
interfaces at the message level it
doesn't try to understand the content it
only tries to pull out the body and the
headers of the HTTP message this is a
good level to work out because HTTP in
general is extremely complicated and
there's very many things that you can do
with it but by presenting this level of
abstraction for for HTTP just on the
message level you can basically do what
you want with it you can layer on
whatever sort of framework or or ignore
what you want to on top of that all we
all we try to do at the node layer is is
parse out the HTTP messages which is
non-trivial very non-trivial HTTP is is
very difficult and I you might be like
what no it's not I mean it's just like
HDPE slash 1.1 space 200 okay return
content you know you think it's it's
very simple but it's it's very not
simple when you get into HTTP 1.1 with
keepalive sessions and chunked encodings
and all the various bugs and different
web servers and web clients there
there's a lot of intricacies in there
and so this is made possible by by an
HTTP parser which parses both requests
and responses the interesting thing is
that it doesn't buffer anything it never
buffers any header it never buffers any
body of the message it just walks
through the message and
and parses it as it comes in it's
interrupted and it requires only 36
bytes per hgp stream that's per
connection which i think is is optimal I
mean if you have many many people
connecting to a web server at once I
mean you you have to be very careful
with the memory usage per connection
you can't allocate 4 megabytes of memory
for every connection to a web server if
you want to handle 10,000 connections
well maybe you can't but it becomes
heavy it's it's much better to try to be
very careful with with the memory you
use per connection right so we can just
two more examples we can we can execute
child processes so this uses the child
process module it pulls out the the
execute function and here we execute LS
slash right which again may spin the
desk we have no idea how long this this
process is going to take to complete it
may take forever
we have no idea so we have to have a
callback here we we simply cannot shut
down our server and wait for LS slash to
complete we have to set up a file
descriptor a pipe to that sub process
and stick it on the event loop and go
back to the event loop and wait for it
to complete so what this function does
is it buffers up all the output from
standard out and standard error and
returns it to the callback again it has
this error function like like in the
file module so all this does is print
out print out LS slash opens a LS / sub
mutt sub process takes the standard out
from it and pipes it to its to the own
the own standard out of node so but we
don't really want that all the time like
we don't always want to force buffering
so there's a lower-level API to start
child processes where we can totally
do streaming through through the
standard error standard out standard in
of the child process
they're just pipes so we can just talk
to it so this this gives you a very
simple form of
inter process communication so this is
called the spawn function which is how
execute is implemented and here what
we're going to just spawn the cat
function the cat program and so so cat
which you all know when you write to it
it sends whatever you wrote back to it
it echoes everything so we write on line
five to cats
standard in hello and we set a timeout
on on line seven through nine
- right - right by - cat and then close
the the standard in of cat as we write
that and cat has the property that the
child that that it will exit when it's
standard in is closed when you control D
right and then what we're going to do is
we're just going to listen on cats
standard out and we'll get data as as it
comes out of cat and then we'll we'll
just pipe it right into our own standard
out and so what we'll see is we'll see
hello two seconds
bye this is cool this is this is a nice
tool maybe you want to tail - F a log
file or something you can just keep
streaming this data in so connecting
streams is a fairly common sort of thing
that you want to do you you take data
from here and you put it out there and
and so for this we have kind of a nice
little function for this called assist
pomp and so this is the exact same
example with the cat except on the last
line instead of actually setting up a
callback for the data event on cats
standard out we just do pump cat dot
standard out to process standard out so
we we it's just going to pump the data
from that stream into into our standard
out it's the same thing just sets up a
callback internally
but eases the the coding so I said we
should be fearful of abstractions and
I'm also fearful of this abstraction but
we're playing around with it and and I
kind of like it and I think that we're
going to have more things like this
because I mean basically most of our
computers are proxy proxies in some way
right you connect to a database you
start getting some data you kind of like
stick on some HTML tags and you send it
out the other side right I mean the more
or less this is what are our processes
are doing they're just kind of piping
data from one place to the other and you
know running some some function across
it so I would like to have more sort of
pump like functions this one's fairly
simple it just pumps it directly but
maybe we can have other things that that
add stuff some sort of mapping pump for
streams okay so very quickly some fun
modules for four-note right you can you
can create add-ons for node and you can
you can create your own modules so so
Tim's Tim cast will step a library
allows you to do some some async control
flow so you might think that doing all
of this file i/o with callbacks is going
to get extremely tedious very quickly
right you're just going to go in
indention levels very quickly when you
have a bunch of serial things to do
rather than immediately jumping on the
green threading bandwagon let's just
chill out a while a year or two and and
think about how we could possibly do
this in other ways without going through
the process of adding multiple call
stacks and writing our own little
scheduler so was this thing do it allows
you to set up a bunch of functions that
can be called in serial in parallel and
makes it rather easy so that you don't
have to go in accuse them up so a
Matt Rani's pcap library pcap is is a
very a synchronous sort of thing it's a
binding to live pcap so you can pull raw
packet data off of an interface which is
fun and you could imagine many uses for
throwing together a little note server
that can sit there idly and just kind of
listen to two packets coming in there's
an M DNS module so for service discovery
sort of things and this is another one
of these very asynchronous sort of
things waiting for some web server or
some message queue out in the out in
your data center to you know know to
notify and advertise itself that it
exists so you can just get a call back
and your process just sits idly and
waits for that there's no overhead oh
wait
ignore that so that's it I would like to
take some questions I think I have seven
minutes or so yeah
so the question is is module loading
also asynchronous there is a way of
doing asynchronous module loading and
initially I was remember when I said
almost all the time when we when we had
these side effects this is one of these
so initially when I wrote node it was
all asynchronous and you had to have a
load callback much like in the in the
web browser where you get a load
callback when all of your scripts are
loaded I've backed off of this quite
heavily in the last half year and now
most requires are synchronous and all
the libraries are using synchronous
requires I think this is an OK
compromise it really it pained me for
months to drop the purity of having an
asynchronous module system but I think
it's okay there is a way of doing
asynchronous module loading but I think
it will be removed in the near future
just to clean up the code a bit I don't
encourage it yes
you'll be able to say a couple of things
what what pain points for causing you to
switch to sequence mom
so the question is what pain points
caused me to switch to module loading
well the two synchronous module loading
um the pain point is a is a mailing list
called common je s which is very
annoying sometimes and demanded that
that modules be in a certain way and I
felt it necessary to comply with them in
retrospect I don't find it such a bad
idea you are of course accessing the
discs which may be over an NFS sort of
thing but these are not the sort of web
page sort of things that are being
loaded you know a million times a second
that you really need to be careful about
how fast it loads discs are pretty fast
so it simplifies the code a lot to be
able to just stick and require require
require and not have to do a unload
callback and I think that that's been a
relatively ok compromise well so we've
described at the beginning of your talk
for series of reasons why asynchronous
loading of asynchronous callback style
helps you along you've discovered at
least one case where a synchronous
callback style is either beneficial or
easier for some subset of the population
do you think that there is a there's
some more generalized template or more
generalized style programs that you need
to extract away so that both
okay so I'm going to repeat your
question even though is here long yes
there are situations where synchronous
i/o is very beneficial like module
loading and you're asking if maybe there
there needs to be some sort of
abstraction that makes use of this fact
of life that that sometimes you want to
do things synchronously maybe I'm not so
sure there is a so the other thing that
I have in in here is is I showed you
some file system methods that were a
synchronous with callbacks all of those
have synchronous counterparts basically
because I don't want to be you know a
total asshole and force everybody to do
these sort of asynchronous things
there's really two parts to your program
there's the loading and starting up
phase where you're going to like move
this thing over there and you're going
to delete that and you're going to
create the socket and do all of these
sort of things and you don't really care
how fast that runs you're going to load
modules and stuff the setup phase of
your daemon generally is synchronous
it's when you get into your event loop
for serving requests that you want to be
very careful about this I don't know I
mean somebody needs to write a PhD
thesis on this like I said I just want
to bind to these kind of simple things
that we know about and I I will give
people synchronous file i/o if they do
it in servers yeah yeah it will probably
suck a little bit but it won't be
terrible right the important thing is is
to never let them do synchronous network
i/o yes
require maybe can you come up to that
microphone I'm not sure if it works have
you looked at remote providers for
require sorry loading modules not off
the local disk write any code again
system for require where you could pull
it from somewhere else right so we also
we can also we have all this HTTP stuff
built in so we can pull modules off of
the off of HTTP I will also probably
remove this because it must be
asynchronous because the HTTP has no no
synchronous counterpart but also I just
don't think it's necessarily a good idea
and it's too annoying and I just want to
be pragmatic about this so module
loading very likely will only be from
the disk and backing off of network
loading of course you yourself can you
know get some URL and evaluate it
yourself and there's there's fairly good
Valene sort of creating contacts and
that sort of stuff
bindings and node that that are exposed
to users that so that you can actually
do your asynchronous loading yourself
but I don't think that that it will be
part of the suggested thing yes invoking
the DNS resolver asynchronously so how
do I do asynchronous DNS requests I use
a library called series I would really
like to write my own asynchronous DNS
thing but DNS is is extremely
complicated
and I am fearful of doing it but yes I
use I use async I use C Ares which is a
is a nice little C library which is what
Curl uses it's by the same author it's
it's fairly minimal and and good at it
and it does it on the event loop right
it doesn't it doesn't do it in a thread
pool
with specialized systems like apples
resolver doing download sorry oh right
yeah so so so I don't I do have a I have
a binding to to get address info which
executes in the thread pool so if you
want to so what I do actually is I is I
branch on dot local and I go to the to
the system call so that you can go to
the name services for a non Internet
domain names DNS is so
it's such like hi I mean my god it's
it's just a hash table I mean why is it
so complicated it's very hard and it's
very annoying but luckily there see Ares
yes what's your so there's a there's a
website called Plurk which is a Twitter
for Japan I think I'm not sure which has
reported hundreds of thousands of users
on on node instances yahoo mail is I'm
not sure what their deployment status is
but they are working on it heavily I
think yeah that's about it
yes I can't hear you so well can you
come up here okay this will be the last
question so in some of the examples the
right calls appeared to be written in
synchronous style oh right so is so
right so so III right to the socket
right and and and it may be that the
kernel send buffer is full like what
what's going to happen right that's your
question right so node in turn so it's
very difficult to deal with that
situation in C land and basically
everybody buffers it internally when
they can't do it I mean you want to
write that data out what you do want to
be notified is that the kernel send
buffer is full and that like you should
really stop writing data right now you
should back off it is suggested that you
back off the return value to write is
true or false
true being okay we could flush it to the
send buffer false being we could not
flush it to the send buffer we buffered
it in userspace and you know when that
file descriptor becomes writable we will
flush it out to the send buffer but you
should really stop writing to me right
now or you're going to fill up memory so
so that is completely non blocking and
it is possible to throttle TCP sockets
if you're uploading a file to somebody
you can't just dump that into memory
right you if it's a very large file you
need to do it pull it off the disk put
it into the socket pull it off the disk
put it in the socket and so there's
notifications for that but for the
normal users who just approach this for
the first time they don't want to deal
with oh my god okay now the send buffer
is full I have to like write this whole
like crazy you know get notified when
it's not full and doing it so node
buffers it internally by default okay so
so thank you and please come and ask me
questions later I'm happy to answer them</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>