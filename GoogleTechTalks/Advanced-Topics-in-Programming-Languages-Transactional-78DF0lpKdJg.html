<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Topics in Programming Languages: Transactional... | Coder Coacher - Coaching Coders</title><meta content="Advanced Topics in Programming Languages: Transactional... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Advanced Topics in Programming Languages: Transactional...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/78DF0lpKdJg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">and welcome to the latest in our series
of programming languages talks where we
get people from within and without
Google to come and give talks about
interesting topics and programming
languages one of the most interesting
topics in programming languages right
now is the notion of transactional
memory and that is what our speaker
today is going to speak about our
speaker today is Mark Moyer who works at
Sun labs and before that was a professor
at the University of Pittsburgh for four
years and before that was at UNC and
before that was the University of
Maryland for a very brief period of time
and didn't Zeeland and I'm sure that he
can fill in more if you actually want to
know and he will be talking as I said
about transactional memory and at and at
that point I will turn it over to him
they turned me back on there we go yeah
turns out that Jeremy can reverse a
story that you tell them accurately so
very good
so my screen is not working I'll use
this one you guys watch that one so
thanks for introduction I'm mark Moyer I
lead the scalable synchronization
Research Group at sun labs and i'm gonna
tell you about some of the work that we
do on transactional memory and first I'm
going to tell you that it's as Jeremy
said a very popular hot topic in in a
variety of research communities these
days this is a very brief list of
conferences off the top of my head that
have had papers directly related to
transactional memory I'm sure it's not
complete I'm sure it's not even accurate
but it gives you a rough idea give a
pointer laser pointer or something no
now the mouse I can't see on there so
that's fine anyway you can see up in the
top left there there's a couple of
papers in the early to mid 90s sort of
introducing the idea of transactional
memory then a period of some quiet which
is not like nothing was going on either
late at most of my own career from here
but in the last few years has just been
an absolute explosion of excitement
enthusiasm and innovation around
transactional memory across a whole
bunch of conferences and you can see
workshops dedicated to transactional
memory popping up so why is that why why
is this all all this excitement right
now well as I think most of you know
anyway the long tradition of waiting
until next year's processor came out to
hide your software bloat is coming to an
end and the reason is that although
Moore's Law continues and it looks set
to continue for a while yet the practice
of running things faster and making them
more complex in order to make single
processors go faster is running into
diminishing returns and perhaps more
importantly running into fundamental
limits with power and heat that are just
not acceptable some percentage of data
centers that I don't remember are at or
very close to their power and heat and
cooling and space budgets and this is a
area of great concern and so it's not
okay to just keep going for single
threaded performance at at all costs so
there's been a fairly dramatic shift
over the last few years and the computer
industry towards building not bigger
better faster stronger processors but
putting more cores on a single processor
chip making them smaller sacrificing to
some extent the single threaded
performance in order to get better
throughput so you have lots of cores on
the same chip and each one of those
might not be twice as fast as last
year's one but you've got lots of them
you might have twice as many as there's
last time sort of thing so this is great
for throughput if you've got a whole
bunch of machines in your server room
running a whole bunch of applications
you can take a bunch of those put them
on a single multi-core system and
get better throughput easier
administration less heat less power less
cooling and all of that however what
about a few would like to exploit
advances and technology to improve the
performance of your single application
well what it means is basically that
application is going to have to be able
to take advantage of multiple cores
concurrently and that increasingly means
that ordinary programmers will have to
become concurrent programmers but here's
the problem concurrent programming is
way too hard
today's synchronization and today's
concurrent programs is largely based
around locks and condition variables
which introduce a variety of problems
and trade-offs with performance
scalability and software engineering and
only experts can really get it right and
the truth is they don't get it right all
the time either and there are lots of
painful subtle concurrency bugs that are
difficult to reproduce difficult to
diagnose and so on and so this is a real
problem now and it's going to get worse
as more and more programmers need to
become concurrent programmers so our
strong belief is that transactional
memory can help so that's what I'm going
to talk about so I've got a silly little
example here my silly little example is
slightly different from everyone else's
silly little example but they're all
pretty silly a little but anyway here's
the example so suppose I have a system
that has a bunch of five-foot Q's in it
which I'd like to share amongst a bunch
of threads on a bunch of cause if I use
a single lock to protect all of those
Q's then life is simple but not scalable
right that lock becomes a bottleneck so
I'd like to have one or maybe two lakhs
per Q however suppose that in my system
I've implemented these 500 queues I've
got in Q and D queue operations and then
one day I decided mmm wouldn't it be
good if I had a operation which would
transfer a value from the end of one
over the front of one queue to the end
of another and let that happen
atomically in other words so no other
thread will notice for example that the
item is missing from any of the queues
or that it's in both of the queues at
the same time I'd like not to have to
worry about that possibility in the rest
of my code I'd like to just have
to make it appear to everyone else as if
this happened instantaneously so I take
my lock based implementation and I try
to compose the in Q and D Q into a
transfer value operation like this one
so here's some code on the right sorry
on the left I hope all of you already
spotted three problems with it the first
one is that because I've got to hold the
locks for both Q's while I do these
operations I can no longer hide the
implementation inside these operations
I've got to expose those locks to the
client code and that means that the
program has got to know the locking
convention remember it and obey it
and so that's ugly for software
engineering purposes of course if I'd
like to improve the implementation of of
the FIFO queues I then got to go and
change the code that uses it everywhere
obviously not ideal and furthermore as
I'm sure you've spotted this quote
solution is broken because there's
deadlock if if there's a transfer from
q1 to q2 concurrent with a transfer from
q2 to q1
they'll grab those locks in different
order and nothing much will happen for
quite a long time and so to address that
problem you have to make this code even
uglier than it is and since my point is
not to teach you how to program with
locks I won't bother doing that but
instead I'll show you an alternative
wouldn't it be nice if you could just
say it I want to do this code atomically
and leave it to the system to figure out
how to support that atomicity I'm sure
you would all agree you'd rather write
that code than that code if all else
were equal and particularly you'd rather
write that code than the fixed up code
to avoid deadlock so no surprises
transactional memory is a strong
candidate for implementing this kind of
semantics and so that's what I'm going
to talk about so I'll stop for a minute
here since somebody asked me on the way
over from lunch this question there's a
new group let me introduce my group very
quickly the top bullet is the other main
members of my group Dave dice recently
joined us from Java software
organization victim luchenko has been
with us for a while he's a language and
Theory expert than me we just hired
Kevin Moore he joined us a couple of
weeks ago from the University of
Wisconsin
and Dan Nussbaum has been with us for a
few years as has nearshore vite
we also work a lot with Professor Morris
Herlihy from Brown University and I was
going to say we work a lot with Yosi
live but I would be more accurate to say
he works a lot with us
he's our eternal intern so here is just
a sampling of some relevance to
transactional memory papers written by
members of my group not necessarily
while they're in my group first one is a
sort of a seminal paper proposing
Hardware transactional memory back in
ESCO 93 by Morris Hill he and Ella
Elliott moss there's also a short while
later proposal for software
transactional memory or they they they
coined the term software transactional
memory and introduce that idea that was
near Savita and one of her students then
to it to last year in s+ I and other
members of my group published a paper on
hybrid transactional memory I'm going to
talk and some amount of detail about
that today
Dave Dyson there should be together with
near student or he shall live who was
also a former intern of ours came up
with the tl2 transactional locking to
software transactional memory algorithm
which is a significant advance in
software transactional memory and widely
regarded to be one of the
state-of-the-art ones last year Morrison
Victor and I published a paper in
Uppsala presenting DST m2 which is a
Java based framework that allows you to
plug in your SCM implemented and and
compare it against other STM
implementations using the same
programming interface and it comes with
a couple of sort of strawman
implementations as well for you to look
at and play with and that's available
you can download it and play with it as
I still to by the way and then I had to
reduce this font on this slide yesterday
to add in log to M since we just hired
Kevin log T M is a hardware based
unbounded transactional memory proposal
and I'll say what that means in just a
moment and in just a minute
and Kevin and his colleagues at
Wisconsin
have worked on that so here's a really
broad strokes summary of approaches to
implementing transactional memory the
first one is a bounded Hardware
transactional memory which is what
Morrison Elliott proposed back in this
car 93 basically the idea for
implementing a transaction as you gather
together all of the cache lines covering
the variables that you'd like to access
in your transaction while you've got
exclusive ownership of them you can make
a local decision to apply things to them
quote atomically and because you don't
give up the cache lines until you've
done that no one can tell that it wasn't
atomic so that's nice and simple fits
with existing cache coherence protocols
and so on but it's bounded it's
implemented in a fixed size
transactional cache and so a programmer
needs to be aware of that cache and its
size and think about whether his or her
transaction will map into that will fit
into that structure now I would argue
remember I said what we're trying to do
here is make concurrent programming
easier I would argue that if we ask
programmers to start thinking about how
many cache lines are touched by each
block of their code we probably didn't
help them much so that's why I've got
this big fragile thing next to it it's
it's not a doesn't support directly
support a very good programming model
the next bullet here is for best effort
Hardware transactional memory so that's
like bounded in the sense that it can
commit some transactions and not other
transactions and so again the programmer
needs to understand what to do in case
the the transactional memory doesn't
doesn't support the particular
transaction and the situation is
actually even worse here because best
effort I should clarify here what I mean
to best effort is not a particular
implementation that I have in mind so
please don't ask me for the details of
it it's a class of things what it means
is give me your best effort right you
commit whatever transactions you can and
whatever transactions you can't don't
commit them so now it's not I commit
everything up to 64 cache lines and
nothing beyond its I might support this
huge transaction and not be able to
support that small one and so this from
a programmers point of view is even more
fragile right but it but it's easier and
more flexible from a hardware
designers point of view because they
don't have to make specific guarantees
about exactly which transactions will
and won't be able to commit so the
fragility of those kind of designs I
think there's a big part of the reason
that in the in the 15 plus years since
transactional memory has been proposed
it has not a not become widely adopted
and recognizing that and also the
increasing importance of making
concurrent programming easier in the
past few years there have been quite a
lot of proposals for so-called unbounded
Hardware transactional memory meaning
the hardware transactional memory has to
be able to commit all the transactions
and it doesn't matter if they don't fit
in the cache or whatever and so all of
these proposals do something along the
lines of you know they all try to use
the caches for performance but when they
exceed the bounds of the cache or some
other resource on chip they then start
spilling data out into memory out into
the address space of the thread that's
executing it and that results in a
really big jump in complexity and I
would say I mean things are improving
but almost all of the proposals out
there are sufficiently complex and leave
unresolved a sufficient number of
difficult and critical issues that it's
too risky and too complex for us to
expect it to show up in our Hardware in
the near future so recognizing all of
that and the fact that we don't have
anything to play with people came up
with the idea of software transactional
memory and there's again been a lot of
work on software transactional memory
much more flexible doesn't have these
issues you know architecture specific
issues but of course as you would expect
it's significantly more expensive than
what a hardware transactional memory
could be reasonably expected to do I'd
say roughly one to two orders of
magnitude is a good way to think about
it so that's kind of the of the broad
picture of of ways to implement
transactional memory
and that's still it okay
so that it depends on some issues
depending what kind of model you'd like
to support that's that's a key issue in
under discussion in implementing
software transactional memories these
days but but the short answer is there
are there are there are systems that
have the answer is either one of those
two and if you want some stronger
guarantees you then have to go and put
the overhead on even on transactional
code and that can be largely optimized
away but it's still significant oh yeah
I'm sorry so the question was when I
said you should think of software
transactional memory as roughly one to
two orders of magnitude slower than
Hardware transactional memory the
question was do you mean for the
transactional code or for all code okay
and I guess now you can rewind and
listen to the answer thanks for the
reminder okay so we recognizing that all
of the classes of proposals had some
significant drawbacks came up with the
idea of hybrid transactional memory
which I'll talk about for a while now so
hybrid transactional memory has at least
a fully functional software
transactional memory and that means that
it can operate in existing systems today
with no additional hardware support
allowing programmers to start developing
testing transactional programs getting a
feel for transactional programming
styles and so on hybrid transactional
memory goes past software transactional
memory in the it can use best-effort
Hardware transactional memory to improve
performance right and so because it
because best effort Hardware
transactional memory is sufficient that
significantly simplifies the burden on
hardware designer who would like to
support of transactional programming
model okay there's more flexibility so
if you get into a particular corner case
or there's some case that you think is
going to be very rare but it's going to
slow things down in the common case you
can simply say I'm not going to support
that case if I ever run into it I'll
just abort the transaction leave
software to deal with it it also means
you can pick and choose which of the
many features that you know for every
bizarre feature there's at least three
people who think that the
will not make progress until this is
supported and transactional memory
hardware designers can choose which ones
they think are going to be the ones that
are important to make common and that
they can fit into their complexity and
risk profile and integrate with whatever
other ideas they're doing in there in
the next processor so best effort is
significantly easier and simpler to
implement and hardware than unbounded
and I believe that that that making best
effort Hardware transactional memory
useful is critical to beginning the
process of using Hardware transactional
memory adopting transactional memory in
general so here's a silly little picture
that kind of illustrates the idea here
we have the big heavy weight software
transactional memory I draw on the
previous slide of course we and others
continue to make significant progress to
improve the overheads but now if someone
comes along and puts transactional
memory onto a chip then we can improve
the performance of the hybrid
transactional memory system using that
software transactional memory it's not
required you can run without it it will
improve performance when it comes and
you can put transactional memory plus on
your next chip improve its performance
improve the the size a number of
transactions that it can combat all the
functionality that it supports and so we
we turn what really used to be a
catch-22 where software guys wouldn't
rate transactional software because no
support and hardware guys wouldn't
support hardware transactional memory
because there were no programs into a
more sort of cooperative relationship
where each encourages and motivates and
guides the other to get better and
better and just as an aside I was the
one who put this this rotated TM on this
chip the chip I stole from Morris
Herlihy if you recognize any you
probably recognize his little chips I
put the TM on there I can tell you it's
hard to put TM on a chip that rotation
was really tricky so anyway this is the
this is the idea with hybrid
transactional memory let's get started
let's try to encourage people to give us
hardware support and we can continue
improving as we go along
okay so the basic idea of basic design
philosophy is a familiar one make the
common case fast and make the uncommon
case work correctly so the programmers
don't have to think about alternative or
backup mechanisms which would complicate
their code significantly and of course
the idea is we'll use Hardware
transactional memory for the hopefully
common case to make it fast and
otherwise we use a compatible software
transactional memory and that compatible
is important to explain why the hardware
and software transactions must
interoperate with each other correctly
right so for example what if a
transaction executed using Hardware
transactional memory conflicts with one
executed using software transactional
memory we should detect that and make
sure that the system behaves correctly
and of course software is just one of
those applications out of there from the
hardware point of view so the hardware
transactional memory is not specifically
aware of the software transactional
memory so instead the idea is you make
the code executed using Hardware
transactions aware of the software
transactions and leverage the hardware
transactional memory as a more generic
facility so I'm gonna try not to get
into too much technical detail but just
to give you sort of a little bit of
insight into how this works
our prototype that we've built and is
described in our s+ paper last year
comprises a library and a compiler and
the compiler produces a code path to
execute transactions with hardware and a
code path to execute it with software
transactional memory and in both paths
it inserts appropriate calls into the
library and here is an explanation of
what goes on in the hardware path so
here's a tiny little transaction x and y
are shared variables and I can't write
assembly code and I don't want to ask
you to read it right after lunch so this
is sort of you know you translate the
pseudocode in your head if you can don't
worry if you can't it's not really the
point so this is the functionality that
the compiler produces so it emits a
transaction a
an instruction to begin a hardware
transaction specifies an address to go
to if the transaction is unable to be
committed at aborts and then here's the
normal code load X into a temporary
variable add five to an add it to Y but
these additional things in yellow here
give us the hooks to detect conflicts
with software transactions so for just
before a read we call Ken Hardware read
this address and just before a write
similarly we call Ken Hardware right and
the library makes the decision whether
there is a potential conflict with a
software transaction if it says no the
transaction the hardware transaction
explicitly aborts itself and so
therefore we don't have we eliminate
potentially incorrect conflicts between
software and hardware transactions so
the basic idea of what goes on in the
library to support that software
transaction maintain data structures for
readwrite ownership of the locations
that they're accessing and those can
Hardware read and can't Hardware write
library functions look up those data
structures to to detect the potential
conflict and if there is a conflict they
say no you can't do that the transaction
aborts itself explicitly if there is not
a conflict that time at that time the
library will say sure go ahead it's fine
but what if a conflict shows up later
well because this Ken Hardware read was
called within a hardware transaction if
a software conflict actually shows up
later and before that Hardware
transaction commits that'll cause that
Hardware transaction to a board so
that's a key point in understanding why
it's okay to say yeah there's no
conflicts now and don't worry if they
arise in the future okay
so I'm going to present some experiments
that we've done with our hybrid
transactional memory prototype we've
done these on several platforms I'm
going to talk about two one is a big
real multiprocessor machine and we can
do that because we don't depend on
Hardware transactional memory and then
the other is a simulator that supports a
form of best-effort Hardware
transactional memory the simulator
starts with simek's and the Wisconsin
gems memory model and the Wisconsin log
TM simulator which simulates that
unbounded Hardware transactional memory
proposal that I mentioned earlier that
Kevin and others have worked on so we
start with that we rewire the
instructions produced by our compiler so
that they call the hardware instructions
supported by the log TM simulator that's
just a little bit of plumbing no big
deal but more importantly are the next
two points we added support for failing
and support for an explicit abort
handler because log TM is an unbounded
Hardware transactional memory it's its
mission and life is to get that
transaction done it doesn't need a
software interface for saying oh do I
couldn't do it right but a best-effort
Hardware transactional memory has the
flexibility for any transaction to say
ah too hard too many resources I got a
context switch whatever it can just
abort whenever it wants to and branch to
that fail address that I talked about
and then we can either retry or we can
go and execute it in software
transactional memory and that is
controlled by policies in the library
that we can configure and then finally
we so-called neutered Blagh TM again log
TM as an unbounded Hardware
transactional memory that has additional
complexity for spilling things out into
memory and thus metadata
out and memory state and so on we said
forget all of that we're just going to
make we're just going to pretend like it
all users only on chip resources so if
we get a cache eviction for something
with read transaction we're just going
to kill the transaction at that point
we're not going to go off and do the
complicated log TM stuff and similarly
we say if the log which is is the the
list of places that you've written to
gets past a certain size which is you
know controllable as a parameter in our
simulator then we'll just abort the
transaction too and so the idea is to so
giving ourselves a so-called best effort
hydro transactional memory to play with
where it supports some transactions but
it also puts the burden back on us the
hybrid transactional memory library
designers in other cases
feel free to swim me down or ask
questions or whatever
okay all right so the question is
basically about the details of how how
the hardware transactional memory asks
the software for permission or or
whether there's a potential conflict
right so so again the the hardware
transactional memory doesn't know about
the software or the hybrid transactional
memory it just executes memory
transactions where the the hook is is in
the code produced by the compiler for
the hardware path right so the compiler
omits calls into the library the library
contains the software transactional
memory implementation so it understands
how ownership data is maintained and so
on and so the those special library
calls that are used as sort of the the
glue between hardware and software
transactions they know they go look up
the software transactional memory
metadata
that's right should I also repeat his
comment I think he just accurately
summarized what I said yet yeah
okay sorry can you yeah yeah also so
okay so the the metadata that I'm
talking about that the right now the
question is about how does you know this
that's kind of like the question is is
it Turtles all the way down right so how
do you update this metadata so if you
don't have Hardware transactional memory
which presumably you don't because
you're on the path where the hardware
transactional memory didn't work right
okay so so that's a good question
and really I spent the first ten years
of my career training to answer that
question basically it's it's tricky
blocking or non blocking synchronization
down in the library now the programmer
never has to see or understand that code
but it's the kind of code that we're
trying to make sure no one else has to
write in the future yeah but it's using
compare and swap for example to make
sure if you and I are both trying to
acquire ownership of something you know
you can think of it that you know
simplistically as a bunch of read/write
locks it's more than that but that's
sort of a reasonable analogy okay all
right so those are our two experimental
platforms and I'll talk we've done a
number of benchmarks not enough I don't
think anyone's done enough benchmarks
and there are not enough real
applications out there but things are
improving dramatically in the last year
and hopefully we'll continue to do so
a couple of the benchmarks or the first
benchmark that I'm going to concentrate
on most today involves the Berkeley DB
lock subsystem so as you probably know
Berkeley DB is an open source database
system it has a lock subsystem in it
which supports both the database
implementation and there's also exposed
to clients and what it does is it
manages locking for for the client so
the client says here's an object I'd
like to lock it for reading or I'd like
to lock it for writing the lock
subsystem is responsible for finding the
lock that's associated with this object
if there is one or allocating an
initializing one if there is not one and
then handling the synchronization so
that the right
so that it grants permission to the
clients appropriately the production
implementation in Berkeley DB that
everyone is using uses a single lock and
implementation locks not to be confused
with the locks being implemented to
protect all of the data structures
required to do that and what no I
thought I had a question okay so we went
and transact afaid that code in other
words we went in and said okay instead
of using that single lock to protect
these data structures we can access
these data structures with transactions
and having done that we then you know
found that there was actually
centralized synchronization inside the
library not just for that lock but also
on things like free lists and we did
some additional work to distribute those
free lists which turns out that's kind
of a tricky concurrency problem but if
you've got transactions it's remarkably
simple so it kind of gave us a real
concrete feeling that our intuitions
were right okay
now having done that we then designed a
real simple benchmark to test the
scalability of our systems so in this
benchmark we have some number of threads
you'll see that on the x-axis and all of
the graphs that I show each thread has
its own object and it sits there
repeatedly locks and unlocks its own
object okay so from the clients point of
view there's no synchronization in this
program right there all accessing
different objects and so in principle it
should scale very well here are results
on the big multiprocessor that I
mentioned what we see first of all is
that the original lock based solution
scales very poorly almost without
exception you add more threads the
performance gets worse okay so the
performance is measured and throughput
operations per second and so if we're
doing things that don't synchronize and
we add more threads we should get more
throughput right but in fact we're
getting less and of course the culprit
is that single coarse-grained lock and
the original implementation and I want
to point out too that these are both log
scales so that is close to
not sure maybe more than two orders of
magnitude drop off as you added up to
127 threads during that is in the
production implementation of Berkeley DB
there's a single lock protecting the
data structures used to implement the
lock subsystem so it's not that it uses
a single client lock it does allocate
different locks for different objects
but to to synchronize the data
structures required to maintain those
locks it uses a single lock does that
make sense so the question is do we have
an implementation that doesn't use
transactional memory but just uses plain
locks okay so you mean plain client
locks so we okay all right so the
question is did we do the experiment
where we don't use the Berkeley DB
system at all for the locking we just
have a lock per object and we said okay
we didn't do that that would be an
interesting thing to do but the point
here really I mean that would scale well
but it's not really the point right the
point is that you know here's this
complicated piece of production code
with this single lock in there and by
the way when we started digging into the
source code for Berkeley DB we found
comments and they're basically saying
that the engineers who worked on this
lock subsystem explored fine-grained
locking they basically had it scoped out
and roughly working but they abandoned
it because it was too complex to be
worthwhile and so that again made us
feel like oh you know if we can get the
the scalability of fine-grained locks
with the programming complexity of
coarse-grained locks that that's exactly
kind of the what transactional memory
should to try to achieve
yeah
yeah that's true this this benchmark is
sorry so what's the question right the
question is isn't this experiment bias
towards transactional memory because
you're not going to have any aborts okay
so you're actually you're sort of right
and wrong it's biased towards a good
transactional memory implementation
right because a bad transactional memory
implementation might itself use a
coarse-grained lock to synchronize
everything and that would look bad as
well right so yes this is designed to
demonstrate that a good transactional
memory implementation can scale better
than code that we find out there in the
real world so yeah yeah it's biased but
it's trying to make the point now I've
got another benchmark I'll show you in a
moment where we've deliberately put
contention and we'll see a different
story there okay but what this shows is
first of all that that coarse-grained
lock doesn't scale that's not very
surprising to anybody but it also
evaluates the scalability of various
transactional memory implementations and
what we've got here of course because
this is running on a real machine we're
only using software transactional
memories the blue one is the tio2
algorithm that I mentioned earlier and
the green and orange ones are two
variants of the software transactional
memory that is a component of our hybrid
transactional memory system for those of
you who know a little bit about
transactional memory that one uses semi
visible reads and that one uses
invisible reads and the that kind of
makes sense I'm not going to go into
that level of detail unless you begged
me to
okay so coarse-grained locks scaled
really badly the the transactional
memories scaled better in a situation
where they should right that's that's
what we're if we saw I mean so right
here look at this that's a problem that
transactional memory implementation is
not scaling well and when we see that we
say hey we've got to go solve that
problem and then what we figured out was
that the the semi visible reads which
are great for hybrid transactional
memory were not great so great for
software only transactional memory okay
all right so on the next slide I'll show
you these same curves again but run on
the simulator together with some hybrid
and hardware transactional memory
implementations so those are the same
fall curves that you saw looking roughly
qualitatively similar I'll point out
that this is only up to 32 threads which
is sort of pushing the bounds of what we
can simulate in reasonable time the top
blue line there is the log TM that's the
unbounded Hardware transactional memory
used directly and again that is an
unbounded Hardware transactional memory
that we believe Intel's too much
complexity so what we're really trying
to show is how well can you do with best
effort Hardware transactional memory and
that's what we've got right here sorry
that's a little bit faint but that blue
line is our hybrid transactional memory
using the simulated best effort Hardware
transactional memory so there's a couple
of ways to look at this one is it's kind
of disappointing there's I think it's a
factor of six or so off of the unbounded
Hardware transactional memory but you
don't have Hardware too unbounded
Hardware transactional memory so in some
sense that's not the right comparison
perhaps this is the right comparison you
can this shows that you can get use best
if at hybrid transactional memory to
improve by I think it's roughly again a
factor of six over the over the software
transactional memories and out here at
32 threads you're improving over that
over the coarse grain lock which is
what's being used today in practice by
two orders of magnitude yes
okay yeah the question is why doesn't
the hybrid transactional memory do as
well as the unbounded one for this
simple case and this is exactly what I'm
gonna get into okay oh so one thing is
we recently did some inlining work and
that got us a factor of two so now we're
only a factor of three off of the
hardware transactional memory but we'd
still like to do better we'd like to
understand as you would why do we have
that remaining gap right and that that's
basically the point that we got up to
with with our hybrid transactional
memory work and we asked ourselves I
mean that was a key question for us why
can't we get closer where's the overhead
here and so this is what we figured out
first of all the hybrid transactional
memory and poses a significant overhead
on the code path executed using Hardware
transactional memories in order to do
those calls out into the library to
detect conflicts with the software
transactions okay so even if there
aren't any software transactions you
still got to go look up conflicts with
them and that accounts for a good chunk
of that remaining gap well it's
necessary because there might be
software transactions and if there are
okay so so the question is why why is it
necessary right you've got atomic
software transactions you've got atomic
Hardware transactions why don't they
just play nicely right so the reason is
that software transactional memory
basically fakes a de Missa tee right so
it can't arrange to actually go and
change a bunch of memory locations
instantaneously instead what it does is
it makes sure that no one notices that
it's actually updating them one at a
time and so that no one has to include
the hardware transactions so make sense
again so that so the question is is this
the same over here we'd be imposing on
all code transactional end on
transactional and again that depends on
the model that the buzzwords are okay
okay that's a valid point of view which
I don't strongly disagree with the
comment was weak models are not useful
so let's assume strong I'm fun with that
so let me think yeah so right you would
have to impose the same overhead on even
on transactional code to go and make
sure that it's playing correctly with
potential software transactions that
potentially conflict if you want the
stronger model which is called strong
atomicity that's right I should say that
you can optimize those overheads away
quite a bit implementing a transaction
that you know does a single read or a
single write is a lot simpler than the
general transaction yeah
since the drink
it's big bachelor there with respect to
the basic motivation breadline
not nothing
just like they did that's because you
stopped picking out there actually
software because
okay the question is is this remaining
overhead because of oh this one okay
right oh and you're talking about the
single threaded case right okay so why
why the the gap here is is it because
you were calling software transactions
or is it because of the overhead on the
hardware transactions produced by the
need to look up for potential software
transactions okay got it it's the latter
that in these in this experiment it's
just about the hardware transactions how
well can we do when it's hard with
transactions okay so this is overhead
for looking for conflicts with software
transactions that don't exist okay all
right and so and so you know these
questions are getting right to the
matter of what we asked ourselves and
what we found was yeah that overhead is
significant and even doing some inlining
and some other engineering there's still
a significant gap we're not gonna just
engineer that stuff away right unless we
change to a different design point so
that's what we did next so so we talked
a lot about the overhead imposed on
Hardware transactions by hybrid TN the
other thing the hybrid TM the the other
aspect of hybrid TM that that makes life
difficult for us is that the the the
design space for the software
transactional memory is constrained to
allow those Hardware transactional
Hardware transactions to look it up
right so what that means is on systems
that don't have any Hardware
transactional memory or on hypothetical
future systems that have some beste fat
Hardware transactional memory that
happens not to be effective for my
particular workload it's tough to
compete with the best software
transactional memories out there because
we have this constraint that they don't
right so those two things made us
basically scratch our heads for a while
and come around to this idea of what we
call pH TM it was going to be called PTM
but the folks at san diego stoled PTM at
s+ last year so now we have pH TN so the
idea with pH team is you support
different execution modes and an in each
mode you can have different you know
entirely different implementations of
transactional memory they don't have to
interact with each other because they're
not executing concurrently okay
and so you can imagine many different
varieties of modes and I'll talk about a
few on the next slide and so of course
the idea here is try to find the best
mode for your workload for your
execution environment and so on and
either stay there if those things are
static or dynamically adapt and switch
to another mode if your workload changes
or whatever the cases okay so here's a
set of modes that you might consider so
the first one is Hardware only mode okay
in this mode software transactions are
not allowed to run therefore we don't
have to look for conflicts with them and
so we can eliminate all of that overhead
that we just talked about forget
inlining it just throw it away then you
might have a software mode where only
software transactions will run and so in
that mode you can use the
state-of-the-art STM more or less just
plug it in because it doesn't need to
provide the ability for hardware
transactions to look it up okay then you
might have a hybrid mode that's like
what I've already described in some
circumstances that might be the right
thing to do and another couple of modes
you can think about how about a
sequential mode if it's a sequential
mode this means there's only one
transaction and so that transaction
doesn't need to conflict detect
conflicts with other transactions and
that allows you to eliminate a lot of
the overhead of software transactional
memory particularly for single threaded
cases that would be a useful thing to do
right and then going further if you have
a single transaction which somehow you
know and perhaps it's through compiler
analysis or perhaps because the
programmer has promised it will never
request to explicitly abort itself then
you don't need to do logging to roll it
back either
and so you can get basically down to
just executing the sequential code the
same as the coarse grained lock does
right so there's five modes you can
probably think of three variations on
each one and so it goes of course in
practice you don't want to have every
mode you can think of for every possible
workload in an environment that you'd
like to try and choose a sweet spot in
this sort of complexity flexibility
trade-off so to explore that and to
explore the viability of the pH TM
approach we built a very simple
prototype which supports just two modes
the hardware mode that I mentioned
before plus the software mode plus a
software mode and the software mode is
configured such that you can plug it in
different STM implementations so we can
compare different systems that would be
hardware mode in software mode and
housing software mode implemented and so
the idea is you know start in hardware
mode if you're lucky and everything
always commits and hardware then you run
almost unencumbered it's not completely
because you've still got to have a
little bit of overhead to respect the
mode but you get rid of this ribéry and
write barrier on every single
transactional memory operation then of
course what if you're best if at
Hardware transactional memory fails at
some point you can't just say okay bad
luck can't retry forever you've got to
switch modes so you can switch to the
software mode execute that transaction
and software and then if it's
appropriate according to your you know
monitoring and measuring and whatever
mechanisms you're using to try to adapt
then you can switch back to hardware or
it might be that you figure out look
it's just note there's no point let's
stick in this software mode and let's
use the best software transactional
memory implementation we can for this
workload right and you can imagine
implementations that have three modes
and you can switch between two different
types of software transactional memory
and there's every everybody who's
written at least one paper and software
transactional memory knows the answer to
the question which one is best as it
depends right and so it might be that
you know if you want it to be if you
want it to win in every single case
you'd probably have to have 17s TMS in
there but the right thing to do is you
know pick the right number to keep your
things simple but but the nice thing is
that by separating the different SCM
implementations into different modes the
complexity is additive instead of
multiplicative you don't have to make
all of them work in the same code base
you just sort of separate them out and
run one at a time
okay so there's a little bit of detail
here at perhaps I won't get into just
talking about how do we make sure that
we eventually get back to hardware mode
and how do we make sure that we don't
get back there too soon before the
before the guys who wanted to go they're
complete so we do it's it's quite a
simple mechanism there's some details in
our paper I should have mentioned that
we have a paper accepted to the transact
workshop this year on this stuff and I
think we're supposed to finish that up
in the next week or two all right so
here's some experiments adding pH TM
into the mix everything else that you
saw is the same as before and there is
pH TM configured with two different
STM's one of them is T l2 and one of
them is the STM from their hybrid
implementation you notice that they
perform just the same as each other
that's not surprising because again in
this benchmark we're executing
everything using only hardware
transactions but the nice thing is that
this illustrates that this the pH TM
gives you more freedom and more
flexibility in implementing your
software transactional memory
implementation because the software
transactional memory implementation
doesn't have a performance impact on the
hardware mode it's not not relevant
whereas it did for hybrid TN and so you
notice that we've now sort of eliminated
another factor of three and we're down
to a factor of two or so there and once
more with inlining we'll get a little
bit closer again now I think it's
roughly on the order of 50 percent
overhead or 50 percent better
performance for this hypothetical
unbounded thing which we plane you can't
have right well can't have in the in the
short term so that's sort of where we're
up to as of yesterday
okay so I promised you a benchmark where
it's not sort of stacked in favor of no
contention this this benchmark is a red
black tree accessed by this number of
threads which repeatedly decide at
random what operation to do insert
delete or lookup and I think it's 20%
insert 20% delete and 60% lookup which
is significantly more mutation than a
lot of the benchmarks out there do and
same thing again operations completed
per second across all threads log-log
scale threads on the x-axis so again of
course we see the single lock doing very
very badly some of the STM is doing
better this is again only STM's because
we're on the on the real multiprocessor
here and this this benchmark is if you
like well I'm trying to sort of change
change your words to say that this is
not stacked and in favor of the non
conflict situation there are conflicts
right if you've got 127 threads banging
on a red black tree doing their
insertions and deletions and rotations
up towards the root and so on there are
going to be conflicts right and so what
you see there you know the best
implementation in the world is not going
to be perfectly scalable because there
really is interaction between the
operations but what we notice is that
again the coarse grained lock does very
poorly some of the STM's do much better
as you get more and more threads banging
on it the contention gets higher and
higher and so of course at some point it
doesn't scale doesn't continue to scale
and the SCM with the semi visible reads
does even worse than before and we
actually have some ideas about that
maybe I'll tell you another day
here are the here is the same experiment
now run on the simulator and adding the
hardware transactional memory versions
again log TM at the top hybrid
transactional memory down here and pH TM
with the two different STM variants and
you can notice now although it's a
little bit more noisy because of the
contention that actually the the pH TM
implementation is very competitive with
LOD TM and the reason now is exactly
like you said before when there are no
conflict it's all about the overheads on
no conflict now things are retrying and
so life is a lot more about fighting
over cache lines and so on and so those
additional overheads on the pH TM code
path versus the unencumbered Hardware
path for the unbounded one they become
much less relevant than the contention
and fighting over cache lines so all of
these things and other experiments we
have done make us really convinced that
we would like to have some Hardware
transactional memory support even before
all those geniuses out there figure out
all of their issues and figure out how
you can really do unbounded Hardware
transactional memory and in a way that
is robust and reliable enough to
actually go and put into a computer
product
all right so we're working on some other
things too I'll switch gears a little
bit here
our prototype that I've been talking
about is built into a production quality
C C++ compiler but it supports only a
fairly rudimentary programming interface
and of course we would like to improve
on that and in fact this is probably the
reason that I'm here today because I
used to work with Lawrence that son
before you people poached him and and we
were having some discussions actually
quite soon before he left I don't think
they were directly the reason he left
but you thought you could escape me but
I called him up and I said Lawrence
let's write a paper about all those
discussions we had otherwise they're
going to remain in our email buffers and
no one's ever gonna read them so we did
that we wrote a paper we submitted it to
the transact workshop and it got
accepted and so now we have to polish it
because it's not very polished at this
point and it sort of it's not a here's
how to do it paper it's here many of the
biggest issues here are some of the
trade-offs involved here are our
opinions on some of the issues other
issues we think we need to get some more
experience before we decide what's the
right thing to do here and therefore we
think we should have an incremental
approach where we do sort of the basic
functionality first encourage people to
use it test out what they need what
works what doesn't and explore and go
that way and ideally do it in an
incremental fashion so that subsequent
prototypes don't break the code written
for earlier ones and so in several
places and the paper we say we prefer to
do it this way first even though that
might be the right decision because we
can make that we can change the decision
that way without breaking anyone's code
button not the opposite so it was fun
writing that paper with you Lawrence
a couple of the sort of more interesting
and thorny issues I mentioned here I'm
not going to go into any detail about
them one one is that you've been asking
about week versus strong atomicity how
do you integrate exceptions into
transactional memory that's a thorny
issue to say the least
how do you implement how do you
integrate transactional memory into
debuggers in some kind of meaningful way
like I said before software
transactional memory and by extension
hybrid and pH TM they fake atomicity
right so if the if the debugger is not
willing to go along with the story that
those things are atomic it's going to
expose the illusion and it'll probably
not be a very useful debugger so y'all
see Liv and I had a paper and transact
last year describing some ideas about
that now we think we've made really good
progress demonstrating the viability of
hybrid transactional memory showing that
you can support transactional
programming models where the programmer
doesn't need to sit and think about
architectural specific details in order
to write programs using transactions
however nonetheless and as sort of
illustrated by the fact that we're still
writing papers and thinking about what
the what the programming model should be
and how to support it it'll be some time
before transactional programming models
become mature enough to be really used
and and be adopted but we think that we
should not wait until then to start
building hardware transactional memory
best effort because best effort Hardware
transactional memory in addition to
helping advance the state of of
transactional program models it also
serves a bunch of other purposes so you
can use it for reducing LOC bottlenecks
turns out you can use Hardware
transactions to execute critical
sections protected by the same lock in
parallel if they don't conflict with
each other so you can eliminate
unnecessary synchronization in existing
lock based programs you can use Hardware
transactional memory perhaps with with
hybrid transactional memory down at some
level to improve the performance and
scalability and importantly simplicity
of various system software the operating
system virtual machine whatever so that
even without the world switching to
transactional programming models the
world can begin to benefit from
transactional memory there's really neat
tricks for using best-effort Hardware
transactional memory to optimize
non-blocking data structures so that you
can make the common case really fast
even though the when the hardware
transactional memory fails you've still
got to go and do tricky complicated
algorithms that require proofs and which
some people even do there's some really
neat optimizations for those kind of
things and there's dot dot here which
hides all manner of sins which I won't
get into so we've got a message for
Hardware people and message for software
people in here a message for Hardware
people is give us your best effort don't
just look at the unbounded Hardware
transactional memory proposals in the
literature and scratch your head and
figure out how to you know whether you
can address all of the issues that
remain unresolved in those things and
say oh this is just too complicated and
risky if you get yourself to that point
think about doing your best effort it
really simplifies your life if you're
allowed to just say err that one's too
hard I'm going to abort this transaction
on the previous side based if it
Hardware transactional memory supports a
bunch of other purposes beyond just
changing programming models and because
in our work we have assumed very little
we've sort of made the the most basic
assumptions about what the best if at
Hardware transactional memory looks like
we give maximum flexibility to hardware
designers having said that though there
are a bunch of things that we don't
require from the hardware transactional
memory implementation in order to make
hybrid and P HTM and things like that
work correctly but if they supported
some additional functionality or
features that would make life much
better for us and so perhaps there can
be a bit of a trade-off here we made
your life much more flexible how about
using some of that flexibility and
simplicity to give back a little bit to
make our lives better and so some
examples include feedback
why did my transaction my hardware
transaction just fail that's a really
critical question it turns out if you
fail because of a conflict with another
transaction there's a good chance just
retrying or perhaps backing off
a little bit in retrying is the right
thing to do but if you failed because
you had tried to use some functionality
not supported by the hardware or you had
an unlucky cache mapping or you had a
huge transaction that didn't fit into
the cache well whatever the reason is
you can retry it until the cows come
home it's not going to succeed you might
as well go to software and if you say
well I'm gonna retry enough that if
there's contention that's the right
thing to do then you waste a lot of time
doing that while when you're never going
to succeed so you'd really like to have
some feedback to give you a good
decisions about that and our simulator
doesn't give us any such feedback all we
know is we're boarded so we're planning
soon to improve our simulator to
demonstrate the value of this kind of
information in addition if you can give
some guarantees for some really simple
transactions let's say every transaction
that accesses at most two cache lines
can always eventually exceed so you
don't need us do you don't need a
software backup path for such
transactions that there's a lot of power
in that kind of guarantee that can for
example substantially improve the the
implementation of software transactional
memories because that guy who's left you
know he asked me how do you make those
things atomic well the truth is it's
worth quite complicated algorithms that
we've worked on really hard if we had
best if at Hardware transactional memory
that guaranteed just for little
transactions that you could always do it
and you don't need a backup path that
would you know I haven't quantified this
but I feel like it would make an order
of magnitude improvement in the
simplicity of software transactional
memory designs
okay so misses for software people is
that we think transactions can improve
scalability and substantially simplify
your life we don't claim to be there yet
we don't have all the functionality that
you might need we don't even claim to
understand exactly what functionality
you would need performance is still not
fantastic we're getting better and
better and better but we don't think
that people should just wait until
everything is solved better to get
involved earlier try it out let us know
how it works or doesn't work influence
the programming models and the
implementation if you're if your real
work load is the real
workload that everyone Tunes their
implementations for then you weren't in
the long run and the other reason for
doing that is that the more and the more
realistic transactional workloads we
have the more we can use our simulators
to show look if you went and built just
best effort Hardware transactional
memory you don't have to go and do the
whole thing look how much improvement
you could provide and also provide
guidance like you know this is how much
resources you should put on cache so
that 99% of the transactions so should
sit on chip but you know caches are
directly relevant of course how much
resources should we put there to make
sure we get almost all of the
performance that we could get from a
from a much more complicated unbounded
implementation so just to wrap up and
sort of repeat some of the things that I
said
hybrid transactional memory supports
transactional programs today and you can
use best if at Hardware transactional
memory in the future to improve
performance and better best effort than
the future beyond that to improve it
again even though the application code
doesn't change at all its performance
continues to improve because the
underlying hardware and software
transactional memory isn't proof
yeah we're improving the performance of
software and hybrid transactional memory
approaching the performance of an
unbounded Hardware transactional memory
I don't have a strong opinion whether we
will ever need unbounded Hardware
transactional memory but I think that's
an open question it may be that were the
best effort with a good best effort you
know round three of the best effort
hybrid transactional memory we might get
to that point and say that's enough you
know we're not going to buy anymore by
putting more complexity to get those
last 0.01% of transactions or whatever
and again best if at harbor
transactional memory supports a bunch of
other purposes beyond just transactional
programming models for improving the
performance of applications and systems
that exist today and and so the last
takeaway point just repeating what I
just said is that we argue for building
best effort Hardware transactional
memory sooner rather than later if
unbounded Hardware transactional memory
is not feasible or not consistent with
your hardware budget or your complexity
profile and so on and that's it I'll be
very happy to take and even try to
remember to repeat any more questions
yeah what is
Stano sectional memory together with
existing
code that's slowing that because the
code down so let's say it's there later
what these a string enough transaction
other uses of string outside of
transactions just because I use this to
my transaction site what this is though
everything else just circuit
okay I think the question is what level
of hardware support is necessary so that
we can support and did I catch you say
strong and yeah so we can support strong
atomicity meaning you don't have to
worry about which parts of your program
are transactional and which parts are
not and make sure that they don't touch
the same data at the same time let's
take that burden off the programmer and
and just as a footnote I am quite
sympathetic to that point of view
because again you know our primary goal
here is to improve life for the
programmers so it's my view that we
should resist putting burden on the
programmer to improve performance before
we've really wrung out every ounce of
performance so so then the question is
what support would be required for that
so the most generic answer is just just
the best effort right we can do all of
that with software transactional memory
with one or two small caveats but
putting some some overhead even on on
transactional code now that overhead
there are a lot of opportunities for
quite simple optimizations for those
things in fact there's a paper presented
by some Intel folks at PLD I just this
week describing how to do this and
describing their work on it that's not
zero overhead that's what you asked me
for
so the comment is you know if you're
using third-party libraries you don't
know their implementation you don't know
what's in there you've got to call them
and and so the if you want to support
strong atomicity you don't really know
if what those things are doing in those
libraries might be accessing data
concurrently with your transactional
code and you need to do something about
that to make sure that they interact
correctly and and I think the question
is what level of hardware support would
be required to make the overhead of that
zero I will hazard a guess that you
cannot make the overhead zero without
very complex unbounded Hardware
transactional memory but I also hazard a
guess that you can make it small enough
that it's not that it's acceptable but I
don't think we're there yet
let's make the rivers life simpler so
going back to your original example the
other two Q's suppose that one thing
that's reasonable to do with the queue
is to implement it to put a remote
machine and just use our pcs to
assertive things believe mixer IQ if I
were to make this message to my program
right so if you don't mind I'll
translate your question into a standard
TM talk question which is how do you
handle a oh right the question is what
if going back to the the FIFO queue
example what if I were implementing that
FIFO queue on another machine store RPC
calls I don't have the ability to send
out an RPC invocation and into say later
oh sorry didn't mean it take it back
well actually you kind of can okay so
the i/o question is a wise man once told
me it's either a solved problem or an
unsolvable problem depending on the type
of i/o and and what you consider an
adequate solution for things like
implementing for things that don't have
user visible external actions this stuff
you can do right so you can have for
example you could do some kind of i/o
like you could fire off that RPC call
and you could have a compensation action
that says oh I didn't mean to do it so
I'm gonna send off another thing that
says hey please don't do that now that
requires the RPC implementation and the
thing at the other end to be aware that
it's in transactions right so it's not
like it just plugs in and works for
other kinds of i/o that the favorite
example people like to use is fire the
missile it's kind of tricky to say oh
sorry missile it turns out that I
determined that I was under attack based
on an inconsistent read set and a bit of
brilliant massage back there you kind of
stuck so
thought so so put it this way for some
kinds of i/o it can be engineered into
transactions for other for other kinds
you know there's not much hope if you've
got transactions that have a mix of of
input and output visible outside of the
system you're you're stuck with
solutions more or less like sequential
eyes everything and don't let anything
happen and and but and in this case you
can't you can't support and explicit
abort but there's various techniques but
none of the solutions are you know in my
opinion ever going to allow someone to
say it just works don't worry about it
well so the the I guess the so the
question is what do you do you just use
locks the the approach of okay I'm gonna
sequential eyes everything because I
know I'm gonna do IO and only have a
single transaction yeah I guess you
could call that using locks right now so
this is kind of in my view so in our in
our paper that I mentioned before about
integrating transactional memory into
C++ we say don't allow IO in
transactions that's that's the first
thing to do now the immediate response
to don't support feature X and
transactions as oh well then you know
what you said about trans X
transactional memory solving all of the
world's problems is never gonna be true
well I didn't say that
yes and I believe that but it's it's not
I am NOT one of those people saying it's
going to make everything trivial and
cover all of the cases and you know I
don't claim that transactional memory is
the programming model of the future I
think it is something very promising for
supporting programming models of the
future but I'm not the one saying you
can do everything you want it's it's
it's a useful box in the toolbox I guess
I think it is other questions
okay go ahead
anything transactional memory predicted
into this the other canonical example I
have a database of shorts you think
there's actually say inside what's it
say
do a full scan of it
right so the question is I guess I'll
again translate it to a sort of more
canonical question what if I've got a
big long transaction and I've got a
bunch of short transactions that
conflict with it I basically got a
difficult trade-off right I can either
starve that long transaction forever or
I can make the those short apparently
simple transactions wait for a really
really long time because of this long
hardware transaction so this I would
argue is so first of all let me say that
there are techniques there's sort of
flexible mechanisms for incorporating
different contention management policies
so that you could implement either of
the things I said right make sure
everyone eventually completes possibly
at the expense of making a short
transaction take a really long time or
you know the priority is on those short
guys that need to get done it's possible
to implement both of those policies it's
my opinion that you absolutely should
not burn into the implementation either
one of those policies it's really if
you're an application programmer and you
wrote an application that has those kind
of characteristics one question is
what's in your mind what do you want to
happen right if you are it's almost like
you basically have unreasonable
expectations at this point right we
can't make those those small
transactions fast and predictable and
guarantee that the long transaction of
eventually completes and so
so the question is does the hardware
implementation affect the policies you
can choose I'll say yes and no it
affects the policies that you can use
fast right you've always got the ability
with hybrid TM to back off to software
and use whatever contention management
policies you can cook but but obviously
you're already slowing down to do that
what happens with contention between
hardware transactions yes the hardware
implementation affects that the the
simplest proposals would simply say I
bought the transaction upon conflict and
now you've got to go retry it and then
there are other proposals that say oh
let's do some kind of queuing or some
kind of time stamp based thing to try to
guarantee progress there you introduce
more complexity and perhaps you baked
into the hardware that policy and it
might be the wrong policy for a
particular application
so my viewers there are probably some
reasonably simple contention management
policies that you bake into hardware
that work well for most of the cases but
you definitely need the flexibility to
so stop and say oh boy this is this is a
tricky situation probably created by
somewhat naive programmer if the
expectations are you know I've got that
mix of transactions and I want
everything fast and predictable probably
that we didn't educate that programmer
well enough but the flexibility is there
it's just you know that there are
realities as an anything that you can't
sort of have everything at that once
yeah
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>