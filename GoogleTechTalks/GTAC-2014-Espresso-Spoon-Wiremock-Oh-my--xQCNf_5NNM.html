<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2014: Espresso, Spoon, Wiremock, Oh my! | Coder Coacher - Coaching Coders</title><meta content="GTAC 2014: Espresso, Spoon, Wiremock, Oh my! - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2014: Espresso, Spoon, Wiremock, Oh my!</b></h2><h5 class="post__date">2014-11-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-xQCNf_5NNM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">&amp;gt;&amp;gt;Michael Bailey: So I'm going to be talking
to you today about Android testing.
My name is Michael Bailey.
You can find me on Twitter @yogurtearl.
I'm an engineering director working on Android
at American Express.
And I'm going to go over one specific stack
that I've found very helpful in our effort
to automate the testing of our Android app.
So what I'm going to be talking about today
is the automation of just what's inside the
APK.
So the APK is an installable, on Android.
It's the piece that runs on the device.
And if you want to test just that part, not
your back-end services -- and this is a little
bit higher level, more of a UI test, functional
test, than a unit test -- I'm going to be
explaining a stack that we use to do that
level of testing today.
Lots of types of Android tests.
Many tools, many open source tools, many paid
tools.
I have just a handful listed here.
Each one has its pros and cons.
They target different types of tests.
Robolectric is very popular.
I'm not going to be talking about that really
today.
But that's great for unit testing where you
have a class that you want to be able to test
as a class, but it also happens to have some
dependencies on some Android-specific API,
so without something like Robolectric, you
can't test it in a regular JVM, even though
you're just testing Java logic.
Robolectric gives you sort of a pseudo Android
environment.
I have API question mark, because it's not
really Android.
It's just sort of android.
And you're not really testing your code against
any specific API.
It's useful for testing the logic in your
code.
There's a bunch of other frameworks and ways
to test actually on top of the Android platform,
everywhere from Espresso to Robotium, Selendroid.
And there's different ways even within the
Android platform to test on top of.
There's instrumentation tests, which I'll
be reviewing briefly today, which have been
there since API 1.
And there's a newer form of testing (UiAutmator)
that's been there since API 16.
So today I'm going to be talking specifically
about one stack.
And the reason we chose this stack and the
goals that we had are these goals.
The first four are fairly common to most testing,
mobile or otherwise.
But the last one is somewhat mobile-specific
in that you have a lot of mobile-specific
things that you want to be on a real device
and you want to test against the real API
versions and the real idiosyncrasies of OEM
skins and things that may be specific to those
devices.
Another one that was important to us was it
being easy to debug, meaning that if a test
fails, you can attach a debugger and step
through it fairly easily.
And the tests that I'm going to show you are
all written in Java.
They all run in the same VM process as your
app, which adds to the debugging and makes
it easier to dispatch a debugger using the
normal Android tools and debug your test when
something goes wrong or you get a flake and
try to triage that.
So, specifically, I'm going to be talking
about Espresso.
Espresso runs within instrumentation tests.
And I'm also going to touch briefly on UIAutomation,
which was a new thing added on to instrumentation
in API 18.
I also want to mention, there seems to be
a monkey theme in some other tools I'm not
going to talk about.
There's monkey, which is from Google, MonkeyRunner,
which is something entirely different but
also from Google for testing your apps.
There was a thing called FoneMonkey, got renamed
as MonkeyTalk.
There's a lot of tools that test your Android
Apps.
The reason I'm talking to you today about
Espresso, instrumentation tests, Wiremock,
Spoon, et cetera, is because, one, there's
good Gradle support.
So if you have a Gradle Android build, you
can run app:connectedCheck, and it will do
all the things you need to do to build those
and get them on a device and execute them.
You can also do this from Android Studio,
and it has good support for those, whereas
UIAutomator and some of the other things may
not run quite as well out of the box with
Android Studio.
The tool Spoon, which gives us some great
reporting, that I'm going to demo towards
the end, only supports instrumentation tests.
API-level support instrumentation tests run
across a wide level of APIs, as does Espresso.
And one of the themes you'll see across the
tools that I'm presenting today is fluent
APIs, which makes your tests readable.
You can do things like Gherkin, which do give
you readable tests.
But this allows you to write your tests in
Java while still having a level of readability
which adds to maintainability.
And these give you realistic tests.
So if you have a problem that something's
happening on, you know, a specific Samsung
device with a specific API, these tests can
be run on a real device, and you can use tests
to reproduce real issues on real devices.
So back to what we're talking about.
We're testing the APK.
So in a normal usage outside of automated
testing, you have a person touching the screen,
manipulating the UI.
In our automation, Espresso is taking the
place of that person.
And Espresso goes through the instrumentation
test infrastructure that comes with the Android
platform to get to the UI.
So what's an instrumentation test?
I'm going to go over this briefly.
If you've never done Android testing, it's
just to give you a background.
An instrumentation test is a JUnit 3 test
case.
It comes with the Android platform.
If you're doing a Gradle project, you put
your JUnit 3 test case in androidTest/source/java,
and Gradle plugin and Android Studio know
how to do the right thing.
It generally looks like this.
Your test case will extend either JUnit 3
TestCase directly or you will extend one of
the subclasses of the JUnit 3 TestCase that
comes with the Android framework.
If you're doing a UI test, generally, you'll
extend ActivityInstrumentationTestCase2.
You tell it which activity that you want to
start up with.
And this is another reason that this is a
useful way of doing tests, in that you can
-- depending on how your app is structured,
you can actually go five screens deep past
the login and start your test just at one
screen, bring up that screen, automate it,
and bring it down, which can lead to a much
faster test than trying to log in and go through
the whole process to get to that screen if
you just need to test something on that screen.
And it can be very useful in the development
process to be able to say I'm working on this
screen.
I want to bring it up, operate on it, and
bring it back down while you're developing.
I made a code change.
I just want to run this test.
And it takes you right to that activity and
allows you to test on it.
So this actually will either launch the activity
if it's not already launched.
The getActivity() call.
Or it will actually launch the activity the
first time it's called for that test case.
This last line here is a bit of Espresso code.
So you can see it's a fluent API.
And it does exactly what it sounds like it
does, on the view with ID foo_button, it will
perform a click.
That's a bit of Espresso code.
This is what an instrumentation test looks
like, you put it in that folder, Gradle will
do the right thing and deploy it.
Underneath the covers, you can do this somewhat
manually.
Gradle will help you with this.
You essentially have two APKs installed on
the phone, one for your test and one that's
the actual app.
They have different package IDs, which in
Android is the unique identifier of your application
on the system.
So the one in your test APK will be something
like com.example.test.
And it is targeting to instrument com.example,
which would be your app.
And you do this by setting this up in the
manifest of your test APK.
So the system knows this APK is instrumenting
this other APK.
Like I said before, Gradle has built-in support
to just execute it for you with the connected
check task.
Or -- and this is useful to know -- generally,
what it does is: it packages your APKs, which
you could do with ant or whatever else you
happen to be doing, does an ADB install of
both APKs, both the app APK and the test APK.
And then there's a command that you can use,
which is âadb shell am instrumentâ.
And this has a bunch of parameters that let
you execute the tests one at a time and things
like that.
And knowing how this actually works is very
useful, because you can -- you don't always
want to rebuild and redeploy the APK.
If you're debugging a flaky test, you may
just want to run the test a few times and
attach a debugger and not have to go through
the build and deploy process.
So by knowing âadb shell am instrumentâ
and the flags you can pass in there, you can
easily and quickly re-execute a test that's
already been installed if you don't need to
make changes to the test.
Or if you just make changes to the test APK
but not the actual APK, you can only reinstall
the test APK and then run âadb shell am
instrumentâ.
So, by default, if you don't pass arguments,
it's going to search your entire classpath
of your test APK and run every JUnit test
case it finds, which can be useful, but it
can also be slow, because it's scanning the
classpath.
So trying to get it to do that every time
during development is not the most efficient.
You can pass things in, like, just run this
class.
You can just run one method if you do hash
and method name.
You can run a series of things by putting
a comma in there, by passing in the method
name, and then maybe run a whole other class.
So you can run subsets of your test very quickly.
And this executes very quickly if everything's
already installed on the phone.
There's a lot more options.
You can see the documentation here.
It's on the JavaDoc for InstrumentationTestRunner.
So that was a brief introduction to instrumentation
tests.
Now, how does Espresso fit on top of instrumentation
tests?
So in a deployment point of view, you have
one process on the Android device.
Your APK under test has a UI.
It's probably making API calls out to a network
device.
And Espresso is in a test APK, but at run
time, the platform is going to combine the
classpath and the memory space of both, and
they're both running in the same VM, so that
they can access each other and talk to each
other like any Java -- two things running
in the same Java Virtual Machine can.
Espresso is available here.
If you're using Gradle in the current version,
there's a thing called Double-Espresso that
you might want to check out.
It's a Gradle-ized version of the exact same
code and it's posted on maven central so it's
easier to consume if you have a Gradle build.
It doesn't have 100% support for Lollipop
yet.
I hear it's coming very soon.
The progress can be tracked there.
So keep an eye on that.
So why Espresso?
As a fluent API, which I showed before, can
make the code readable which make your tests
readable which makes the tests more maintainable.
But really the thing that Espresso gets you
is there's not great ways built into the instrumentation
API to actually -- you can bring up the activity,
but there's not a whole lot of great ways
to manipulate it and do certain things.
And specifically, your tests run on a thread
called the instrumentation thread, and all
the app code by default runs on a thread called
the main UI thread, and Espresso has a lot
of things that synchronize between those two.
And it can remove a huge level of flakiness
from your tests.
So if you're doing UI test on Android, you
need something to synchronize between your
instrument tests and the main thread, and
Espresso is very effective at doing that.
It will also detect the active view hierarchy.
So in Android, you can have multiple windows.
Each window has its own view hierarchy.
And trying to make sure that you're manipulating
-- finding a view in the right hierarchy.
Dialogs have their own hierarchy.
PopupWindows or auto-complete text have their
own hierarchy.
Espresso has some code in there in a class
called view oracle -- RootOracle that will
manage that for you.
It has support for acting on AdapterViews.
So you have this problem of I have a list
of things.
I know the underlying data that's being shown,
and I want to click on the thing that's represented
by this Java object, but you have to scroll
the list into place before you can click on
it and there's a bunch of other things.
So there is an onData API in Espresso that
takes care of that for you and there's a number
of extension points.
So Espresso can't know everything about your
app but if it doesn't do what you want, through
a combination of ViewAssertions, ViewActions
and IdlingResources, these are kind of the
main three extension points.
You can tell Espresso a lot about your app
and what you need Espresso to do, and it can
be very extensible fairly easily.
So just a brief detour into one of the cool
parts of Espresso.
So as I mentioned, there are these two threads.
The instrumentation thread where your test
case is running and the main thread which
is a message queue processing animations,
activity launches and all these other things
that are going on.
In trying to get your test to observe that
main thread in the right state -- is the view
present yet?
Has it been loaded?
Has the activity transition happened.
There's just a lot of things that can lead
to flakiness.
Espresso has this trick where it actually
will assert itself onto the main thread and
block your test case until it can -- and block
the main thread while observing the future
using reflection on the main queue to observe
future messages, while looking for the conditions
it knows that your app is needed for.
So it can be very fast by taking this approach
because it's in the main message queue.
It's actually processing each message one
at a time while checking for conditions so
it doesn't need to sleep.
And sleep in your UI test on Android can be
a huge source of flakiness.
It also can really slow down your test.
A good rule of thumb for writing tests, especially
UI tests, is if you're doing something that
won't be faster when your hardware is faster
or your VM is faster, it's probably something
you want to try to avoid.
So if you say sleep for one second and you're
hoping that whatever is happening happens
in one second, that will never get faster.
That test will never get faster no matter
how fast of an emulator you put it on or whatever.
Whereas if you can have this approach of looking
for the condition that you want while processing
each message in turn, assuming you have a
faster VM, those messages will get processed
faster and your test will get faster over
time with faster emulators and faster hardware.
If you're using Espresso, you're going to
want to use GoogleInstrumentationTestRunner
which is an extension of InstrumentationTestRunner,
but you can also -- it's kind of akin to the
application class that comes in your application
in terms of it's a global object that gets
callbacks at specific points in the life cycle.
You can actually do some cool things by extending
GoogleInstrumentationTestRunner and hooking
into there.
I don't have time to get into a lot of it
but if you look at the JavaDoc for InstrumentationTestRunner
and GoogleInstrumentationTestRunner, there's
things like onCreate and various callbacks
that you can extend to add some interesting
functionality such as turning on the screen
before your test runs, making your app pop
in front of the keyguard in the lock screen
if that's on there, and disabling the key
guard.
And there's some examples in the Spoon sample
app of a custom test runner.
One thing that you can do is Espresso, by
default will -- it has analytics in there
that track the actual usage at runtime.
You can turn that off in your own custom test
runner if you want to, but I can understand
why they would want to track the usage to
understand how popular it is, too.
Another thing that's interesting about Espresso
is if you're familiar with Android development,
there's this thing called an intent, and it's
kind of a message passing interface which
allows you to say I want to launch this activity.
It can go through multiple processes and things
like that.
There's an interface that comes with Espresso
that's called IntentSpy and has things that
allow you to record intents that are issued
and also say whether you want them to proceed
or not.
So let's say you have a call button and you
don't actually want the dialer app to come
up but you want to make sure that the right
intent was issued, you can use this to say
don't allow the intent to proceed but record
that intent, and then do an assertion on that
intent.
Unfortunately, there's no open source implementation
of this interface.
The interface is included as part of Espresso,
but you can actually roll your own by just
simply using their package name and calling
it IntentSpyImpl.
It will automatically get loaded and you can
use those methods that were listed here.
I mentioned UIAutomation.
So this is a new API that came out in 18 plus.
It gives you a few extra things you can do.
You can take real screenshots, which means
you can take everything on the screen, if
there's a dialogue, another app, you'll get
the system bar.
UIAutomation will give you real screenshots.
It uses the accessibility framework so it
gives you access to any UI on any app.
So if you need to automate another app, you
can do that through UIAutomation on 18 plus.
For example, if you want to automate opening
the notification drawer and clicking on something
and making sure your app does the right state
after that, you can do that with UIAutomation
in 18 plus.
So you can actually test a flow of maybe a
push notification or something like that.
Unfortunately, there's no current integration
with Espresso, meaning that Espresso has this
built in logic to synchronize with the main
thread but doesn't synchronize with anything
in UIAutomation, so using UIAutomation can
actually introduce flakiness because there's
the lack of synchronization.
You can use the IdlingResource API in Espresso
which is the main way to tell Espresso to
add synchronization into Espresso and combine
that with the on accessibility event listener
that's in UIAutomation, and you can do a -- fairly
successfully you can tie the two together
to make Espresso aware of the stuff you're
doing with UIAutomation.
So that's Espresso.
You're replacing the person who would be touching
the screen with an automated tool that takes
care of a lot of the pitfalls that you may
fall into trying to do this.
So let's turn to the other side of the APK.
So if I'm trying to log in or do something
on the app, a lot of apps have calls out to
network services.
So if I want to not test my server code but
I only want to test my Android APK, how do
I -- how do I replace that end of it?
I'm going to talk to you today about a tool
called Wiremock.
So testing apps that rely on network resources
can definitely be a source of flakiness.
You can use real end points.
You can use your staging area.
You can use QA environment or dev environment,
but you have to worry about test accounts.
Did the test account change?
Does it have update transaction so if I make
a payment on something, is that now in the
payment history?
How do I reset?
You have network flakiness.
If you're going over a network, that server
may be down.
The API may have changed on that server.
So there are a lot of reasons why if you just
want to test the code that's inside the APK,
that going against a real service can cause
flakiness or cause your test to fail when
it's actually not a problem with your APK.
So in this we would replace -- use Wiremock
to kind of replace that level.
So Wiremock is an open source tool.
The things I'm talking about today are open
source.
And it can increase your reliability by being
very predictable in what it returns for specific
requests and responses.
You can reproduce real world conditions which
can sometimes be hard to reproduce.
A certain account status.
If your account is app based or certain network
faults that may be very hard to reproduce,
especially in an automated fashion.
And it can also handle stateful scenarios.
So I made a payment.
Now that should be in payment history and
things like that.
And Wiremock is not -- it's actually not specific
to Android.
It can be used in all sorts of technology
stacks.
So you can -- even if you're not doing Android
development, definitely check out Wiremock
and see if it fits the need that you have.
Essentially, Wiremock is an HTTP server, happens
to run on top of jetty, that can be configured
to return canned responses via a JSON API.
So what do I mean, configured via a JSON API?
So on a Wiremock server, when you have it
running, there's a thing called __admin/mappings/new
where you can post to Wiremock and say, when
you see a request like this that matches this
pattern, return a response like this.
So by default, Wiremock just returns 404.
It gets a request, if it doesn't have a mapping,
it just says 404.
But then you give it these pattern matching
and response things, and you can load multiple
of these, there's a lot of things you can
put into the matching and then you say return
this response when you see a request like
this.
So Wiremock only does exactly what you tell
it.
And then it can be reset if you need to clear
the state of Wiremock and start over.
So there's this JSON API that you can use
from any language.
You can post to Wiremock from any language,
whether it be iOS or PHP or whatever you're
using, to set up these mappings.
It does also have a fluent Java API.
So if your client and tests are in Java, your
job is a little bit easier in that you don't
have to use that JSON API directly.
This fluent API will make those JSON API calls
for you.
Here is the equivalent of what I had on the
previous slide using the fluent Java API client
for that API.
You're saying a stub for post on a URL matching
that regular expression will return a response
with status 404 in body.
Whoops.
So this is how it would fit into your test.
At the top of your test, assuming you have
Wiremock running, you would point your app
at Wiremock.
So you just need to replace the host name
and the port number.
The rest of the URL can be the same.
And presumably, you have that function in
your app to point to your staging or your
QA environments.
And then you can, at the beginning of your
test, tell Wiremock you're going to see requests
like this.
And when you see requests like this, return
responses like so.
Then you can launch your activity.
You can operate on the UI.
You can say click this button.
And this is using Espresso.
You can say on view whoops, check that it
is actually displayed on the screen.
So you're actually controlling the data that's
served so that it's all contained within one
test case that you have the text showing on
the screen, and you also have what was returned
from the server and make sure that they match.
The other nice thing you can do with Wiremock
is, it keeps track of what request it's served.
So at the end of your test, you can actually
say verify one post requested for a URL equal
to /q=foo.
So you can make sure that when you click this
button, your app didn't issue two requests
when it was only supposed to issue one request,
because Wiremock is tracking that state, which
may otherwise be very hard to track if you're
going against some other end point.
So a couple of Wiremock features.
I don't have time to get into everything.
But it is stateful, meaning that you can -- you
can add scenarios.
And one, it's kind of like a state machine,
one request coming in will transition to a
different set of mappings based on the state
of the state machine inside Wiremock.
So you can say if I'm in the scenario make
payment and the state is payment due, I will
set it to payment, or maybe payment made when
this request comes in.
So it allows you to do things that are stateful
on the server and have certain scenarios in
kind of a very simple state machine for the
request responses during your tests.
You can do errors.
You can say when you get this request, return
a response with this sort of fault.
And there's a couple different fault modes
that are supported.
So that allows you to more reliably automate
the testing of the various error paths and
fault conditions in your app.
You can also introduce delays and see how
your tests respond to that.
Although, you know, you need to be careful
about that.
That can really slow down your tests.
So where does Wiremock run?
So it's a jetty server.
It needs to be accessible from the device.
You can run a local server on your network,
which could be shared.
Maybe your iOS devices might talk to it, too.
You will probably need one Wiremock instance
per device, because Wiremock per instance
is stateful.
So if you have multiple devices running tests,
talking to the same Wiremock instance, and
you have stateful things going on, you're
probably going to run into problems.
You still have that network connection, even
if it's on a local host, between Wiremock
and the device, which is still a source, potentially,
of flakiness.
But it can be made to work.
And depending on your needs, and if you need
multiple devices talking to the same Wiremock
instance or same infrastructure, you may want
to do it this way.
You will have to have some infrastructure
to coordinate.
Okay.
I have five devices.
I need five Wiremock instances.
They're on these ports.
And things like that.
So it's a little bit of infrastructure you
need to set up to coordinate all that.
The other thing you can do is bundle it in
your test APK, where it sits next to Espresso
and it actually just runs on the same process.
You're still connecting to it over a localhost.
All your stack of HTTP client code is still
running.
Your app doesn't really know that it's just
going back through the loop back-end interface
to Wiremock.
But this can produce a whole 'nother level
of flakiness.
It's one per device by nature because it's
actually running on the device.
So it reduces the level of setup and coordination
you need.
And it also reduces the network problems,
because there's no real network between the
two.
The open -- One caveat I'll give you is, the
open source version doesn't support Wiremock
out of the box, or doesn't support Android
out of the box.
So there's a few things you have to do.
It's an active thing on the open source community
discussing how to get it to work.
I can tell you it can be made to work.
And it's not that hard.
So here's the first example I talked about,
where you're running it off device, and your
tests are talking to a Wiremock instance you've
spun up somewhere.
But here's the other way that can even reduce
flakiness more, is actually running it in
the test APK, which is in the same process.
And you talk to that directly.
And you have much more control over Wiremock
and starting it up and stopping it and resetting
it.
So the few things if you're going to attempt
to get Wiremock working inside your Android
APK that you need to think about, and some
of these may have changed.
There's some ongoing work on the open source
to manage some of these.
The logger implementation, I think it uses
log4J, which could cause problems on Android.
It has some JUnit 4 stuff in there which may
conflict with certain Android things.
It has -- uses a different version of Apache
HTTPClient, so you may need to use JarJar
to repackage that under a different package
name to remove the conflict.
The good thing about having it in the test
APK is, you get the 65000-method limit on
both APKs.
So even though Espresso includes Guava, which
is fairly big, but it's not going to hurt
you too much, because it's in the test APK,
which has its own 65,000-method limit.
And you can even go beyond and implement things
like there's a file source API in Wiremock
that is -- can load precanned mappings from
a file system.
You can implement that API and make it load
precanned mappings from the Android asset
manager.
So now you've invested all this time in your
test.
You've set up Espresso.
You've set up Wiremock.
You've got a pretty good test rig going.
You want to run these across lots of devices
and you want to maximize your investment that
you've made in writing this test, because
it's not always quick or easy or painless.
So there's a tool called Spoon, another open
source tool, that I'm going to talk to you
about today, that allows you to maximize that
investment that you've made.
It allows you to run your tests on multiple
devices in parallel.
So it will build and deploy.
And then you can grab screenshots using a
Spoon API and get a nice report of all of
these tests that you've written, run across
multiple devices, in if a way that allows
you to troubleshoot where was the flakiness?
Is it only on a certain type of device?
API 15?
API 16?
And I'm going to give a brief demo of a sample
report from Spoon.
So this is the sample report that actually
comes from a sample app built in Spoon.
So if you're interested in Spoon, you can
check it out.
It comes with an app that's instrumented with
tests.
And you can run the tests, and it will give
you the sample output.
So it's very easy to take a look at Spoon
and see if it's going to meet your needs.
So you can see here they ran their app on
seven devices.
Each device was running nine tests.
So it says 72 tests run across nine devices,
that's eight tests per device.
You can see it gives you this nice matrix
of which tests passed per device.
You can see there's two devices here that
had an additional failure.
So it could be something about just the devices,
the API version that they're running.
And you can kind of dig into that to try to
see why that test failed on that specific
subset of devices.
The other nice thing that Spoon does for you
is you can see which test it is by mousing
over it.
If you click on it, it will give you the list
of tests with the screenshots for each test
as it was going through.
And you decide when the screenshots need to
be taken by calling their screenshot API within
your test code.
So you can see that these two failed.
So the one good thing is, about Spoon as well,
is it collects the logs from every device
just from when that test case was running.
So if you have good logs in your app and you're
trying to troubleshoot flakiness, you can
also just view the logs for the ones that
failed.
So here is all the logs from that test case
on that device when that one failed, and again
for this test case.
The other thing you can do and the value that
you can get out of this is you can click view
on all devices.
So I'm viewing now -- before, I was viewing
all tests on this one HTC device.
If I click here, I'm viewing this one test
called blank username shows error, on all
devices, the HTC, the Droid, et cetera.
So you can see this one was in landscape mode.
This one is a Nexus 7, so it has a lot of
empty space on the screen in this layout.
So this can be a very effective way to see
how your layout is looking across a lot of
devices in a very automated way.
And you can share this with your designers
so that they can say, oh, on this type of
device, the spacing is not quite right, or
what have you.
So that can be very helpful and help you get
a lot out of the investment that you've made
in writing all these tests.
You can also turn on an option -- and it's
optional -- to view this as an animated GIF.
So it will actually take these screenshots
and play them over in an animated GIF so you
can actually kind of visualize the step-by-step
process of going through the app in that test
case.
So I'm going to switch back to the slides
now.
So I'm going to talk briefly about CI.
So there's a Spoon Gradle plug-in which allows
to you if you have a Gradle build, you can
execute spoonDebug on top of your instrumentation
tests, and it will do the right thing about
building it and deploying it to all the devices
in parallel, executing the tests on all the
devices in parallel, pulling the logs, and
generating this report.
So by using this plug-in, you get the Spoon
report fairly cheaply, and you can use the,
obviously, Jenkins Gradle plug-in or whatever
Gradle plug-in for your continuous integration
server to execute this on every check-in or
however you do your continuous integration.
So you can get this nice report on every code
change, with screenshots, across devices.
It works with any device that's attached to
ADB.
So you can use this with emulators as well.
You can also -- if you haven't done this,
you can also connect to devices over Wi-Fi
if they're not physically attached to a server,
using ADB connect.
Of course, that does add another level of
flakiness.
And one last thing that I'll just briefly
mention is, if you're doing all this and you
have Wiremock that has a nice, fluent API
and you have Espresso that operates on an
API that has a nice, fluent API, there's one
more tool that if you want to continue that
theme in your tests, it's called AssertJ Android.
And it's built on top of AssertJ, which gives
you a fluent API for asserting things at the
ends of your test, but it has support for
all sorts of Android APIs.
So, for instance, if you're using that tin
spy thing to block intents but make sure that
they were issued, you can do things with AssertJ
Android like assert that the intent spy intent
has the action view so you make sure the right
intent was issued.
And you can do all sorts of assertions on
various Android APIs.
So you can do that as well.
That brings me to the end of the presentation,
and I think I have a bit of time for questions.
[ Applause ]
&amp;gt;&amp;gt;Alan Myrvold: One of the questions from
the moderator.
What's the argument for these low-level test
libraries instead of a black box test approach
taken by Selendroid/Appium?
&amp;gt;&amp;gt;Michael Bailey: I mean, you can use this
in a -- you can use this in a -- you can be
more kind of black box or gray box with these
tools if you want.
I mean, you don't have to -- if you -- if
your concern is knowing about the ID of a
specific item, you can do more based on the
text that you see in the UI.
So you can use these tools a little bit more
abstracted.
But there is some -- there's some nice things
that it allows you to do in terms of asserting
the state inside of your app that you can't
just do.
And, really, from a debugging point of view,
it's tightly tied to the internals of your
app and having it all in one process and being
able to have the debugger step through your
test code and also be looking at your app
code in the same process can make debugging
a lot easier.
That's probably one of my favorite things
about doing it this way, is being able to
kind of debug the test and the app that's
being tested at once.
&amp;gt;&amp;gt;&amp;gt; So I'm looking for some good ways to test
other services, content providers, like non-UI
stuff, like content provider services, the
integration with them.
Is there a good mechanism for that in Espresso?
&amp;gt;&amp;gt;Michael Bailey: You're talking about Android
content providers?
&amp;gt;&amp;gt;&amp;gt; No, integration with them, just like you
have an intent spy, something like that.
&amp;gt;&amp;gt;Michael Bailey: That's a good question.
Not that I know of.
But I know there's an Espresso talk from the
Espresso guys later today.
And maybe they have an answer.
I don't know.
So it may be a question for that talk at the
end of the day.
&amp;gt;&amp;gt;&amp;gt; Okay.
So my second question was, can I test my business
logic without launching activities and so
on?
&amp;gt;&amp;gt;Michael Bailey: You can run just plain old
JUnit test cases in instrumentation.
Building an APK, deploying it onto a device
and all this may be -- it's going to slow
you down if you don't really need to test
-- if you're not really testing anything Android-specific,
you may want to try to get that outside of
testing in Android and do it just on a JVM,
either just a plain JVM if you're not calling
-- if you don't have any dependencies on Android
APIs or using something like Robolectric that
kind of gives you enough of the Android APIs
to test outside of an Android environment.
It will be much -- it can be much quicker.
&amp;gt;&amp;gt;&amp;gt; Okay.
Thank you.
&amp;gt;&amp;gt;Alan Myrvold: Another question from the
moderator.
With this stack, is it possible to automate
test cases where you have more than one device
involved?
So if you have two devices talking to another,
data synchronization, messaging between the
devices, can you make that happen?
&amp;gt;&amp;gt;Michael Bailey: Between devices.
It doesn't -- I don't -- I wouldn't say it
supports that out of the box.
Yeah, you may be able to do -- if you had
-- I mean, you have to have some -- if you
have some way of the devices talking to each
other, and I know this device is in this state
and this device is in that state, you may
be able to tie that piece of logic that you
would have to be specific to your app to something
like an idling resource in Espresso possibly
to get it to kind of pause at the right place.
Like I said, the -- the IdlingResource, the
ViewAssertions, and the ViewActions can help
you extend Espresso to meet your tests.
It probably wasn't meant, really, for that
use case, but, you know, you can give it a
shot.
Take a look at the idling resource API.
&amp;gt;&amp;gt;Sonal Shah: Any other questions?
All right.
Thank you, Michael.</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>