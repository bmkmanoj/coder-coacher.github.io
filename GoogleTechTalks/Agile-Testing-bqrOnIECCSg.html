<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Agile Testing | Coder Coacher - Coaching Coders</title><meta content="Agile Testing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Agile Testing</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bqrOnIECCSg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Harry my sponsor says it's time to start
so so we were just debating should Harry
get up and introduce me and I decided
that he didn't have to do that cuz he's
so comfortable there with his laptop
it seemed cruel to make him get up so
instead I'll introduce Harry this is
Harry in case you don't know Harry Harry
has been a Google for how long now eight
months Harry is the model-based testing
guy among other amazing things and and
collector of testing related lyrics up
on his website and is now blushing I
think just a little bit so I'm here
thanks to Harry and I'm here to talk
about agile testing which of course
makes me curious about what you guys are
up to so out of curiosity how many of
you are currently working on a project
that you would describe as agile
whatever flavor oh wow one were you all
just attracted by the title is this
flexible testing we're going to do yoga
and testing combined is okay um so gee
I'm seriously 1 wait a minute I know you
must be on an XP project cuz I know you
this is mark oh how many how many of you
are trying but not there yet on agile oh
okay okay not okay and we may have some
disagreement about how hard we're really
trying on that all right well I confess
I'm surprised because I do know a few
people at Google and everybody I know at
Google is an ex peer extreme programming
so how many of you have ever heard of
extreme programming oh good we're
getting better a few of you still
haven't so that's okay I'll explain a
little bit about what extreme
programming is and I need to explain a
little bit about how I came to be giving
this talk at this point I have given a
version of this talk several times and
it keeps evolving as my beliefs and
understanding and perspectives on agile
testing are evolving I first started
hearing about this agile stuff several
years ago and initially I was extremely
skeptical it sounded like yet another
buzzword yeah
another flavor of the month sad that was
gonna go away anybody remember
computer-aided software engineering that
had a real long life right so I figured
I could ignore this safely but then I
started reading and I became intrigued
because it seemed like these agile
people had answers for stuff that we've
been struggling with in software for a
really long time oh I better find out
more so then I attended a talk by Kent
Beck he's the guy who wrote extreme
programming explained embrace change
like the big industry changing book that
was published and I believe 1999 well in
2001 I heard him speak at quality week
and he basically said that QA people are
a throwback to Taylor istic scientific
time in motion management kinds of
things and that we are all irrelevant in
the brave new world of extreme
programming now I have to admire his
courage because he said this to a
standing-room-only audience of quality
professionals he survived the experience
I have seen him since now it was
actually kind of funny because about 45
minutes in he'd done with he was done
with his prepared talk and he looked at
his watch and he said well I'm done with
my prepared talk and I guess we're done
because my time is up and his track
chair the guy who's responsible for
managing the time and the talks stood up
and said well actually we scheduled you
for a double-track session so you've got
45 more minutes to answer questions yeah
yes he did well as somebody who I am in
fact test obsessed that there are a few
bracelets left for those of you who
might not have gotten yours they're all
in the front row this was in fact an
enticement to get people to sit in the
front row I am in fact test obsessed I'm
not just test infected I live eat
breathe and sleep testing I think it's
fun and I know that that makes me just a
little bit odd
it is difficult to explain to people who
don't understand you know why anybody
would think that software testing is fun
how I can find it so exciting and and so
as a test obsessed person I was
surprised to hear somebody who I thought
was test infected say that testers were
irrelevant so I figured I gotta go find
out for myself what life is like for a
tester on an XP project and I got lucky
enough to get a contract on an XP
project where I was a designated tester
working with the development team on
this XP project and I had a blast have
you ever gotten softer well first of all
how many of you would identify
yourselves as testers of some flavor or
another okay so those of you who are
testers of some flavor or another have
you ever gotten software delivered to
you to test and it wouldn't launch at
all this has happened right didn't
happen once on this extreme programming
project not once not only did I never
get a do a build I didn't even have to
wait for them to give me a build because
it was safe to check out whatever was
the latest thing checked into source
control and it would work Wow that was a
new experience for me I was used to
projects where it could take weeks to
integrate the software to get it to work
at all much less basically do what it's
supposed to do yeah there was stuff to
find though it wasn't perfect reports of
the demise of QA people were wildly
optimistic they needed me I felt loved
and appreciated now that's a weird
feeling for a tester yeah
how I do feel loved and appreciated to
do what I love to do I was hooked
never again was I going to go back to a
traditional project so since that time
that was about eighteen months ago I've
been working with extreme programming
teams now one of the reasons why my
beliefs and beliefs and feelings and
thinking about testing on extreme
programming projects are morphing
evolving is because my role is starting
to morph and evolve the project that I'm
on right now I've crossed over to what
some might say is the dark side I'm a
programmer on this project I'm just
another programmer with the development
team and let's face it I'm probably the
most junior programmer on this
development team but I'm the most senior
tester and what that means is that I
have a perspective on this project that
none of the other developers do I'm the
one who's most likely to say I think we
ought to write a test for this before we
move forward we're doing test-driven
development how many of you have heard
of test-driven development okay and
y'all know that it's not a testing
methodology it's a design methodology
right so I'm the one who's most likely
to have the little tester paranoia kick
in and say I think we ought to write a
test to drive this little tiny subtle
aspect of this functionality and I'm the
one who's going to say yes we can to
test that let's just figure out how
right so I have a different perspective
on that project and that's starting to
shift my perspective about how testers
can effectively collaborate with agile
developers on agile projects but in the
meantime here we've got this talk that
I'm going to give about agile testing
that represents what I think today and
what I think tomorrow might change if
you would like to get the slides I
didn't want to burn a bunch of paper to
give to you you can find them online on
my site at agile quality tree comm agile
testing 3.1 PDF so they're there and we
have to talk about traditional testing
before we can dig too deep into agile
testing so let's take a look at
traditional testing with great optimism
the project manager releases the project
plan there's a big daunted a Tom meeting
that
kickoff meeting 7-foot full color print
outs of the Gantt chart are distributed
to every executive and it looks like
this roughly we're going to spend an
analysis phase first we're gonna have an
analysis base we're going to spend time
analyzing the problem because we know
that if we don't think about it very
hard we know we can't get it right the
first time we've all been in this
meeting right where we're having this
discussion so we're going to analyze it
and then we're going to spend time
designing and about six months from now
we think we might understand enough
about the problem to begin coding so
then we're going to do a whole lot of
coding and then we're going to go into
the testing the bug fix phase stabilize
everything and then we're going to
release this sounds familiar
this never happens if we lived in a
perfect world this might happen we don't
live in a perfect world instead
inevitably this happens we spend a whole
lot of time analyzing and designing and
coding our hearts out and then all of a
sudden at the very end they hand it off
to somebody in an independent test group
and say test make sure that it's quality
it's you're responsible to a short
enough responsibility to assure the
quality and then we've got like three
days to test and then we're going to
release that looks kind of familiar
right okay now there's a whole body of
knowledge about how to do testing in
this environment that has been developed
over the last roughly three decades
maybe more and these practices have
worked in this context and I honor these
practices we've done things like become
the last defender of quality test
departments stand there and say it must
get by me before you can release it to
the poor hapless users I protect the
user does that stance sound kind of
familiar right so so we're the last
defender of quality we want to employ
strict change management you can't check
in that bug fix unless I ok it right so
we're going to be very strict we're
trying to control the chaos we're going
to make sure
we've done our homework we've got
detailed preparation planning test
design excuse me we're going to do a
whole ton of documentation because when
it comes to that end of that release we
know that we're going to have to bring
in outside contractors who don't have a
clue about what we've been doing for the
last eight months and they're going to
have to get up to speed very quickly so
they have to have very detailed test
scripts sound familiar right we have to
do these things strict entrance and exit
criteria it can't come in to test until
it passes the minimum acceptance tests
we will not accept it it's not in the
test phase until it is past our gate
have you weight test automation starting
with commercial tools that do lots of
record and playback kind of things we
attempt to enforce the process in some
cases that's where the whole QA title
comes in because QA is more than testing
right QA involves quality of the process
as well so we attempt to enforce the
process there's only one problem with
this it works in a traditional context
it helps control the chaos it's anti
agile this is why the agile is hate us
because we're trying to enforce process
we're trying to do strict change
management but agile is about embracing
change so if we are accustomed to a
traditional test environment how do we
adjust our practices to contribute
effectively in an agile context well for
starters the agile context is very
different from a traditional context
instead of releasing a big bang thing at
the very end we're releasing all
throughout each of these is a completed
releasable feature as or set of features
as we go through we've got short
iterations lots of deliverables and in
fact that's what agile means delivering
a continuous stream of business value
the implication of that for us testers
is that we have to deliver a continuous
stream of information we don't have the
opportunity to prepare for six months
before we start working on stuff we have
to be ready to start testing day one of
the project
fortunately the code is ready for us to
test as well it may be
baby code it doesn't do much but what it
does it does and we can test that of
course there is a warning here just
because some manager somewhere and you
know who you are says we're going agile
Duncan um
therefore I want you to revise all of
your test estimates to account for the
fact that we're going agile well that's
not enough to call it agile right just
because we dumped the documentation
compress the schedule and code up to the
last minute does not mean that we are
releasing a continuous stream of value
so we have to be careful about adopting
agile practices and make sure that it
really does fit the context typically
organizations achieve agility by
adopting one or more of the the agile
methods that are out there and here are
just four examples the most well-known
is typically extreme programming
followed by scrum extreme programming is
a set of very well defined practices and
I happen to know that mark is an expert
on XP you can raise your hand this is
Mark everybody and he's a he's a Googler
you have other experts on XP amongst you
I'm not an expert on XP I'm merely a
practitioner of XP the thing that that
has continued to amaze me is the
misunderstandings in the industry in
general about what extreme programming
is there's this myth that it's the
license to hack for Cowboys anybody
heard this extreme programming must be
this loosey goosey kind of thing it's
actually the most disciplined
development methodology I have ever
worked with developers write automated
unit tests before they write a line of
code so it's it's they've got a full
suite of 100% automated unit tests that
get run before they check in anything
continuous integration ensures that
everything not only compiles all
together but actually functions they
automate their acceptance tests and they
take responsibility for working with the
customer to automate acceptance tests so
as a result the unit tests become
executable specific
nations of what the code should do and
the automated acceptance tests become
executable requirements
that's pretty disciplined right now they
don't happen to love documentation a
whole lot and that's because
documentation it's overhead if stuff
doesn't get to the end user if it never
achieves if it's never intended for a
customer if it's a byproduct of the
process rather than the thing that you
sell or deliver then a lien terms its
waste
nobody likes waste right now some waste
is necessary it's not possible to
produce software with zero documentation
well I take that back I've seen groups
try it doesn't work real well you have
to have some but the question is how do
we minimize that so that we've got the
maximum value for the minimum cost and
that's what agile teams typically look
to do scrum now where XP is really
developer centric it's got some stuff
about how you manage projects but it's
real strength is in providing a set of
practices that a development team can
use to produce good software scrum is a
project management focused set of
practices that focuses around big
visible charts how do you demonstrate
progress how do you show your customer
that you're on track so each of the
different agile methodologies has its
own strengths it's got the audience that
it speaks to and a lot of organizations
have found that they've gotten a lot of
value out of wrapping extreme
programming with scrum so that they get
both the project management side and the
development side other methodologies
include Mary poppendieck stuff on lean
she's written a whole ton about how you
apply the principles of lean
manufacturing to software development
and what she wrote actually makes sense
see before I read her book if you'd said
you can apply lean manufacturing to
software development I would have said
no you can't it's different software is
different well she figured out how to do
it because she's got such a rich
background in both software development
and in lean manufacturing Crystal is
Alastair Coburn's a slightly less rigid
model for doing agile software
development very developer centric so
there's a whole bunch of stuff that's
been written
about how to do agile and how to do it
well now when us testers are working
with agile teams though instead of being
that last defender of quality instead of
having this stance we have to shift our
stance now we focus on supporting the
team typically from the perspective of
either supporting the developers in the
developer facing side of things moving
the project forward or in supporting the
customers in figuring out whether the
software was acceptable because
ultimately we're working for one of
those two groups of people and this is
one of the areas where traditionalists
don't really like the way that XP kind
of oversimplifies the world and says
look there's developers and there are
the customers who are the customers for
whatever the developers produce these
aren't necessarily the end user
customers customer in the XP sense of
the word has a special meaning its
capital C customer and that person or
set of people they speak with one voice
to say this is what the software should
do and then they get to say and I agree
that you've done it thank you very much
good job
so as testers we may be supporting the
developers in moving the project forward
we may be supporting the customers in
figuring out whether they got what they
were trying to pay for we want to focus
on shifting our practices with two key
ideas in mind one is let's increase the
feedback speed the speed of the feedback
loop and two is reducing waste let's
reduce the number of byproducts that we
have to create in order to get the
information that our stakeholders want
and we want to focus on testing provides
information so that we can reduce risk
because that's ultimately what we do
right no matter how we do it so let's
compare and contrast traditional versus
agile the traditional attitude towards
changes we've got to manage it and
control it the agile attitude is hate
change happens we might as well be ready
for it the traditional attitude towards
planning we'd better do comprehensive
upfront test design because if we don't
do it at the beginning we're just going
to get absolutely bulldozed at the end
whereas
the agile approaches yeah we got a plan
we got to plan a little but we're going
to plan as we go
documentation tends to be verbose it
serves a couple of purposes one is
communication and two is cover your
assets on a traditional project we want
to make sure that we can't possibly be
blamed when things go wrong on agile we
want to do as much as necessary but no
more handoffs well we've got formal
entrance and exit criteria on
traditional projects on agile projects
it's not a relay race we're going to
collaborate because we're all one team
test automation on traditional projects
tends to be very tool centric focused on
the commercial tools and it tends to be
built by specialists there'll be a
separate test automation department by
contrast on agile projects everybody is
testing and the developers are
continually automating their tests we
can leverage that so let's look at these
in just a wee bit more detail to embrace
change we have to be able to minimise
duplication and plan for per maintenance
right so at one point I was working with
one of my clients to help them assess
various testing tools and we were
meeting with all of the major vendors
and getting them to comment on our
project now our project was a somewhat
special context it was not an extreme
programming project but it was a very
early-stage project this was a product
that was expected to be released in
about three to four years in a medical
device company now the stuff that we
were working on early on we wanted to do
automated tests that were end-to-end
tested the whole system and the system
included stuff that a clinician would
use that connected to embedded stuff
that was the guts of the thing and then
that connected to proprietary hardware
that ultimately controlled treatment to
a patient so there's a whole lot of
moving parts in this thing and we wanted
to make sure at the earliest stages
possible that all this stuff was working
well together and that you could have a
whole lot of cycles through make sense a
good thing to test early on right the
way we were going to drive this was all
the way from the UI down to the hardware
and then back to the UI
we felt that that was a good way to find
this information out so one of the
questions that we had for every vendor
that we talked to was talk to us about
maintenance because we know that this
user interface that's here right now
it's just a quickly tossed up mock-up
and we know it's going to be changing
over the course of the next three years
so what's it going to look like to help
help us figure out what it's going to
look like to maintain tests in your
environment one of the vendors had the
gall to say to us oh well you should
nail down the user interface first can
you imagine a three year project and
they want us to nail down what the user
interface looks like first now the user
interface is important because it's the
thing that the clinician is going to use
but don't you think it's a little bit
more important to nail down how that
hardware is going to behave and how that
controller software is going to behave
and you know maybe the UI should wait
until closer to the end and we'll have a
professional UI designer figure out what
the UI should look like but they wanted
us to nail down the UI first and didn't
think it was worth us using their tool
to automate unless we were going to do
that we said thanks for playing we're
done and we went with another vendor
where we were able to more easily modify
our tests as we went along because they
had better support for maintainability
so as you are working through the
process of adopting strategies for
testing
you got to bear in mind that change is
going to happen it's going to happen
every month how can we make sure that
whatever it is that we're using is going
to support that change speaking of
change we want to plan ahead but not too
far ahead because any time we plan
farther ahead than then the project is
ready to go we risk wasting our time
because we're going to plan all this
stuff and then we're never going to have
those stories be implemented so on an
agile project we don't want to plan any
further ahead than the next iteration
because we don't know what's going to be
implemented after that right stuff that
was on the list today might come off the
list tomorrow
this is one of the reasons I tend to use
very informal mechanisms to do planning
and communication I prefer using
whiteboards sticky notes wiki's this the
kind of stuff you guys use yeah largely
okay as opposed to databases or big
Microsoft sorry I said the M word
charts and stuff yeah okay because the
more informal it is the easier it is to
change when the universe changes around
us when I do my test documentation I
want to keep it simple and capture the
essence there are folks out there who
say that the best practice is to detail
every single step well if you do that
and you've got thousands upon thousands
of test cases you end up producing
thousands upon thousands of pages of
documentation for any given project
documentation that no customer ever sees
the value of in the worst case I once
went into one organization where it was
the worst case I'd ever seen of over
documenting because nobody was using the
documentation I mean nobody not the
testers not the people who wrote it they
had a whole separate team set up for
designing the tests and those people
were tasked with documenting test cases
these people spent 90% of their time in
mercury test director documenting tests
they would then sign the sign-off form
to send those tests over to an entire
group of people whose job was to execute
the test cases I had the opportunity to
talk at length with the people who were
charged with executing the test cases I
said how's this process working they
kind of did the look around you know the
look around to make sure nobody's
listening in and closed the door and
they said we don't use them
the people who are tasked with designing
those test cases haven't actually run
the software in three years they don't
know what it does anymore this is an
organization that was spending millions
every year on documentation that no one
ever read that's that's that's waste so
I prefer first of all I prefer it when
my work gets used it's just you know
it's a quirk of mine I like the stuff
that I produce to have value so I want
to make it as lightweight as possible I
want to reuse as much of it as possible
if I come up with a checklist I'm going
to reuse that checklist in as many
places I possibly can and you all know
that I don't mean copy and paste it
everywhere right I mean that's a whole
other sin in tech document in test
documentation have you ever seen an
organization I know you guys don't do
this so I'm not afraid of stepping on
you know putting my foot in my mouth
have you ever seen a test organization
that takes the the requirement
specification you know that big formal
document that says the system shall blah
blah blah blah blah the system will blah
blah blah blah blah they copy that into
a new document and then they run a macro
to do a global search and replace on the
system shells to make it say the system
verify that the system does this is a
sin we now have an unmaintainable
document that nobody knows what it means
right okay so I don't ever want to do
that I don't want to copy and paste I
want to centralize you guys are the
knowledge repository of the Internet you
know about centralizing and distributing
as well by the way but you know
centralize that knowledge okay here is
one example of lightweight test
documentation that is sanitized but
essentially from a real project here
we've got a test number that parts
optional but you know if you want to be
able to say test number four blah blah
blah test number a category a test name
that was all the detail that I had for
those tests I didn't bother with any
detailed steps
there is a cost to this very few people
would have been able to run these tests
unless they'd already been on the
project but it was enough information
for us though they atlast executed
notice all of a sudden this document is
now serving two purposes oh I love
leverage this is good that we can make
one document serve two purposes the two
purposes are test design and test
results tracking last executed the
result in the configuration on which it
was run so this is one example of very
very lightweight documentation another
example is a mind map this is built in a
program called mind manager there's a
bunch of mind mapping software out there
pick your favorite flavor the reason I
like mind manager is that if you happen
to be working on a hybrid project where
on the one side you've got the agile is
and on the other side you've got the
traditionalists and the traditionalists
keep banging on the Angelus for more
documentation this is great because mind
manager will spit out the most formal
looking Word documents you've ever seen
you give it a template it takes
something that looks kind of free form
like this and turns it into something
that's good for military use very handy
so you can work in this and it can spit
out the formal stuff for you so this is
another example of lightweight Styles
all right the next thing we want to do
is reduce those handoffs this is not a
relay race we're all one big team that's
one of the basic agile concepts we're
all we're a team we're not a series of
independent departments we are all
responsible for the outcome one of the
biggest lessons I had to learn on XP
projects is that it's way too easy if
there is a designated tester on an XP
project to kind of almost do the
traditional thing sort of scary how easy
it is for this to happen and say oh
that's a test thing Elizabeth's going to
do that I don't have to think about it
and the next thing you know even though
this is an XP team and we're all test
infected I'm sitting over your
hopelessly behind in my testing tasks
because none of the stuff I'm doing is
being tracked with the rest of the
project so we have to guard against this
even with XP teams even with agile teams
and make sure that the testing tasks are
considered at the same weight of
priority as any other kind of
infrastructure development task
co-locating testers and programmers is
an excellent idea it does not by itself
guarantee communication there's this
bizarre social thing that happens on two
projects now I've been in a bull pen
environment now this is typical of agile
projects that you'll have this big room
that's kind of like a war room or the
bull pen and everybody's all seated in
there and on two projects I was part I
was in the bull pen
I was with everybody else except I had
this table that was kind of off to the
side I mean we're talking kinda like no
more than three feet off to the side and
entire days would go by without anybody
from development ever talking to me now
it is this bizarre social dynamic it's
too easy to become isolated so I became
aggressive about sitting outside my
designated area in the rest of the
bullpen and this is what is agile
testers we end up having to do just to
remind people that we're here and we're
here to help and really they saw me is
there to help they didn't see me as an
impediment to progress in fact I went on
one of the teams I had a couple of weeks
where I was out of town and then I came
back and the day that I came back one of
the developers heard the door closed
very small office and so everybody heard
everything heard the door closed did the
prairie dog saying of popping his head
up above the cubicle saw me and said
Elizabeth this back Elizabeth is back so
I mean I was I was loved and appreciated
and felt all warm and fuzzy and part of
the team and yet I still had to make
sure that I I reminded the team that I
was there have you ever been in the
meeting where somebody says okay now
everybody get out your razor blades
because we're gonna sign in blood on
this one
yeah some of you have heard this one one
of you back there has apparently been on
healthy projects your entire career
because you're back there going on ever
seeing that either that or you've got a
very sarcastic sense of humor um I've
been in that meeting too many times and
it's painful frankly cuz I mean I
understand the intent the intent is to
say really are we really sure
we're ready to go I understand the
intent but there's a flipside to that
intent isn't there because I'm going to
hold you to it because somebody is going
to come after me because my signature is
on the QA manager line and if there is a
failure in the field I know that it will
be my fault because my signature is on
that line well what this is just a
ritual with a compass and a dark side so
let's take the purpose and find other
ways to achieve the purpose without all
of that blame stuff that gets in the way
so the purpose is to get agreement that
we are actually done this is a
conversation between the people who
produce the software and the people who
are supposed to accept it the people who
produce the software saying we're done
we can't think of anything else that
we're supposed to do in order to meet
the criteria that we think that you have
given us we're done we've met the
criteria we've hit the bar on we go and
the other side is supposed to say either
yeah looks good okay I accept it I agree
with you you're done with this it's time
to move on or they say no this does not
meet what we thought we asked you to do
it's a very simple conversation that
results in either and accept or reject
well so let's make it a simple
conversation that results in an acceptor
or reject one of the things that you can
do to do that is have a ritual of
exploratory testing all together as a
team a whole team with the customers
there and the developers there and
everybody else who is involved and is
interested there at the end of every
iteration to go through the features and
see if you get agreement about whether
or not the features are ready to be
accepted right it's a lovely ritual and
it's one that makes people feel all warm
and fuzzy because they get to see stuff
working and by the way if your
iterations are a month or less in length
which they should be you get to have
that warm fuzzy feeling on a regular
basis how cool is that you could also
have I've seen it be very successful to
have the primary customer in the XP
sense of that
special capital C word do a demo once a
week for all of the interested parties
on the business stakeholder side of
things with the engineers all in the
room so everybody's one big happy family
gathering around the table all together
and there's a demo and there's a
projector and cool stuff is happening
and and they get to get that feedback
and some of the most of the feedback is
usually positive because after all these
agile teams are employing good
development practices so you don't have
embarrassing demos where the thing blue
screens in the middle of the demo it
basically works and there are some
nitpicks
and you get that feedback and you get it
live how cool is that so instead of
signing in blood let's find other
rituals that accomplish the same goal of
having the conversation yes I accept it
or no I don't without all of the blame
stuff thrown in now test automation on
agile projects is really interesting
because they start automating before
they even start coding coming from a
traditional background this was a shock
to me but I now practice test-driven
development
I love test-driven development I think
it's the coolest thing since forever I
don't know anyway typically what you'll
find is that developers on XP projects
anyway not all agile but XP projects are
using some flavor of X unit whether it's
J unit J s unit J web unit pick your
favorite unit depending on the
technology that you're working with
they're already doing automated tests in
that technology in the in the code in
the language that they're already
writing the code in typically agile
projects will then employ something like
fit Fitness domain-specific languages
some kind of acceptance level system
level test automation and this requires
a collaboration between the people who
understand the system from a business
standpoint who can specify what the test
cases should be in terms of business
rules or in terms of behavior that they
expect to see and then the people who
are able to write the fixtures that will
support the automation to make that
happen so typically that's what you see
on a Gillette's P projects and this
means that we as testers have the
opportunity to collaborate with the
developers to write the test
Automation we don't have to put up with
webpages that don't have IDs for
anything and we're trying to figure out
okay I can get an array of all the input
fields and then I can iterate down to
that you don't have to do that anymore
because the developers already had to
put in all the testability hooks to make
their unit tests work how cool yes okay
um you guys aren't as excited as I would
expect about that maybe that's because
you just never had to deal with
completely untestable code does anybody
ever had untestable code okay well those
you know five of you who have
experienced untestable code you should
be like excited about the prospect of
the testability hooks already being
built in okay and the other thing that
we can do is use that test automation to
help support early exploratory testing
so common wisdom has it that you can't
start testing until there is an
externally available interface against
which to test which means that if you're
doing a GUI based thing you can't
actually start testing until there's a
GUI right yeah yes you can now you can
do manual and I mean manual testing you
can do manual testing against something
that's completely not ready for external
interface interaction by using
automation to help drive the app to a
particular point deep with it manually
through whatever interfaces you've got
available to you in whatever creative
and let's face it we're all testers well
yes actually we are all testers no
matter what your title is you are a
tester we're all testers and we all
occasionally have that moment of
inspiration when we think hey I'll bet
if I do this it will break you can do
that before the code is from a
traditional standpoint ready but only
because there's already automation built
up that you can leverage to get the app
to the point where you can do that yeah
thing right and then you've got other
other automation in place to help reset
the app to another state so that you can
do more malicious horrible evil terrible
things by the way I didn't mention I did
tell you all that I am test obsessed
what I didn't tell you is
that I am in fact an evil person or at
least so I've been told just never to
people always to software all right so
this is my current view of agile testing
that there are three basic activities
that are happening and all of these are
happening within the iteration for the
the features that are being implemented
now whatever now means for you one is
automated acceptance or story test now
you may be wondering why is that all the
way on the left is though it's the first
thing that's happening because in some
organizations it actually is as weird as
that may sound some organizations do
story driven development which means
they define the acceptance criteria in
terms of stories I'm sorry in terms of
story tests so that they can run the
story test watch it fail so you watch
this thing fail you know that the story
isn't implemented yet then you create a
unit test an automated unit test that
would implement some little itty beat a
sliver of that story and you watch it
fail because if it passes you know the
test is bad if the test passes when
there was nothing written whatsoever
that should make it pass it's probably
not a good test just like if the test
automation passes when the software
under test is not installed that's a bad
sign okay so now you're doing the unit
two automated unit tests and typically
that's the developers I've had some
people say well we're doing agile stuff
because we're doing automated unit tests
but it's the testers who are doing the
automated unit tests and the developers
are developing the code I will submit to
you that that it well better than no
automated unit tests probably isn't the
most agile approach that they could be
taking so the developers are automating
unit tests and then we're augmenting
that with manual exploratory testing not
manual scripted testing see if we know
enough to script it manually so that we
could hand it to anybody who knows how
to operate a computer I will suggest to
you that's a test that should be
automated if it's that clear-cut which
leaves us free to do the exciting stuff
that we haven't thought about yet until
we put our hands on the keyboard and the
malicious side of our mind takes over
and we think of the evil things we could
do to this software okay so that brain
use us to the end of that that's my
current thinking on this that is shared
by the way amongst various people who
are part of the agile community there is
a huge agile community not now maybe
y'all are shy and you just all have been
very involved in the agile community but
just in case for those of you who didn't
raise your hand there's a huge community
out there there is an XP mailing list
there is a test driven development
mailing list there is an agile well now
one agile conference in the US other
agile conferences throughout the world
if this isn't an interesting thing to
you you have internal resources places
that you can go internally to find out
about the great broader world of people
who believe that this is a better way to
develop software then that slide I
showed you at the beginning with the
testing all compressed at the very end
okay further reading some books and and
this list is in the slides which again
are on my site some thank yous to some
folks who reviewed early versions of
this work and then once again you can
find the slides on my site at that
location so how far over my time slot
did I go we have time for questions how
marvelous any questions Harry two kinds
make it past or it kind of falls into
two big categories one is um end to end
or sequence related okay three big
categories see I'm gonna change my mind
even as I'm answering the question
all right I'll stick with three
categories end to end test so things
that involve multiple moving parts in
the system that you aren't likely to be
able to catch with a single unit test
because it involves dependencies but
multiple between multiple parts other
things so like integration test or
system level end to end test sequence
tests you go through it once this way
you go through it again this other way
and doing it the first time set
something in some weird state that
results in it failing the second time
through so that's a sequence oriented
test the thing you're tweaking is
sequence and then the third
is data related where we didn't
anticipate that the database could have
nulls for example because we thought
that we were going to put a not null
allowed on that column but we're dealing
with legacy data and it turns out that
and historically the nulls were allowed
so those are kind of the three big
categories of stuff yes because there's
stuff that's much easier to catch with
the unit tests than with end-to-end
tests so if there is a method way buried
down here it lives down here in its
little world and it takes input from
other stuff and every now and again
other stuff will throw it a null and
then it will barf because it doesn't
know how to handle nulls but from the
user interface which is about 17 layers
of abstraction away from that one little
method way down here all of those that
user interface it's really hard to get
that null down to that one little point
down here from all the way up here so
what we find is that each of the
different layers of testing represent
different questions that we want to
answer about the software the unit tests
answer the question does it do what I as
the developer expected it to do and and
has it changed see that's the other
thing the automated unit tests become
change detectors so let me give you an
example of a bug that was caught by
automated unit tests it was testing
regular expression stuff you ever done
regular expression stuff it's it's like
gnarly to get that stuff just right and
so we had a series of tests that tested
passing these strings make sure that we
get this response back from this method
that's doing regular expression
transformations we had to make a change
to implement a new feature we made that
change and all of a sudden three of our
automated unit tests broke because we
broke that regular expression so that
was a change detector for us if we
hadn't had the automated unit tests we
probably wouldn't have caught that until
it became a surprise in the field yes
yeah okay so the question was if agile
teams typically work in a bullpen kind
of area what about global teams I
confess this is one of those areas where
it is very difficult to have that same
level of camaraderie but some
organizations have had success one of
the ways that they get success is by
doing a whole lot of face time so that
they build up the camaraderie in the
trust now if you look at the open source
community although not all open source
projects practice agile you will find
that there's a fair amount of
camaraderie and trust within open source
projects and yet they're completely
distributed so somehow they achieve that
the key goal I think is that camaraderie
and Trust and you have to achieve that
one way of achieving it is by having
everybody in the same room but there are
other ways of achieving it sorry it's a
very general answer right video
conferencing helps who has the biggest
problem going agile testers or
developers yes it depends it depends on
your organization so in actually my
husband works for a company now he's a
product manager so he's on the marketing
side of things and he's trying to push
for agile so we're the push comes for
agile depends on your organization and
by the way both the testers and the
developers are resisting him in this
case as well as the managers because
they don't they don't see it yet they
don't they don't quite get the benefit
to them yet whereas he sees it very
clearly from a business standpoint so I
think that you just have to take each
individually and find out what their
concerns are with some in some cases
like let's take XP if you go into an
organization and want to do XP in some
cases the developers are very comfy in
their corner offices they've gotten a
whole they've worked really hard to get
a door and all of a sudden you're saying
that you're going to relocate them into
a bullpen environment and they're going
to have to pare that means that they're
going to have to have somebody looking
over their shoulder every minute that
they're coding well for some developers
that's a really scary thing now I can
tell you
as a developer who is in the middle of a
project right now where I'm pairing it's
also the best professional experience
that I've had because we're producing as
a team good code and it feels good to
write good stuff so anyway yes okay so
there's a principle that somebody
smarter than me put forth that I don't
and I don't remember who it was but on
the XP mailing list I remember seeing
this principle if it hurts do more of it
now that sounds counterintuitive right
because if it hurts we want to do less
of it because we don't want the pain but
if you do more of it
the fact is that you have to find ways
out of self-preservation you have to
find ways to reduce the pain unless you
just become numb from hitting your head
against the wall but most people I find
have enough self-interest that they're
not just going to go numb they're going
to find ways to address the pain so
where you've got these tests that are
incredibly fragile and you know I'm
guilty of writing fragile tests to in
fact anybody who's ever done system
level tests quickly discovers that it's
much easier to write fragile tests than
to write robust tests right run them
more often and every time they break fix
them don't let them languish in the
unfixed state the test should always be
green that well the test that you
believe should pass should always be
green and commenting out doesn't count
no fair putting the X in front of the
test keyword right so just the act of
fixing them more often is going to yield
even if it's only in one person's head
but hopefully it's a shared team
College base of what tends to make tests
fragile for our context at which point
you start to learn what not to do
because it's going to make things
fragile and can start applying mocks
better and using various techniques to
break the dependencies so that you do
end up with tests where when they fail
your first reaction isn't oh the test
broke as opposed to oh the code broke
hey so does the distinction between
testers and developers go away
maybe I realize that's heresy ok so
let's go back to the 1980s when the big
QA consultants I was not one of them
it's not my fault don't blame me but
they were all going around the quality
consultants saying tests should be
independent y'all remember that that
mantra test should be independent tests
must report up to a vice-president who
is completely independent from the
vice-president development because if
you don't do that you're being
irresponsible and you must not be
quality aware you've all heard that feel
right I bought into it for a long time I
don't buy into it anymore and the reason
is because test is never independent no
matter who they report to test reveals
information test yields information if
there is no audience for that
information they don't need us right so
it doesn't matter that we're there so
presumably there's an audience for that
information
now if the audience for that information
is development and I don't care who my
boss's boss's boss's boss's boss is I
work with development and if the
audience for that information is a
product manager I don't care who my
boss's boss's boss's boss is I'm an
agent for product management right so
does the distinction between developer
and tester go away maybe and maybe
that's not such a bad thing for the
developer centric testers I tend to be
one of those because I'm a tester new
codes and I confess on a geek now there
are also testers who specialized in
understanding the domain they support
the customers they come up with good
test cases typically this is one of the
hardest problems with XP is having the
customers write good acceptance tests
right John I'm picking out John hi John
because two years ago at
it was you invited me to speak at BAE XP
on how can we get customers to write
acceptance tests so this has been a
point of pain for XP teams for a long
time the answer is get somebody who
knows something about testing to help
the customer not be the substitute for
the customer and that's the key thing we
don't become a substitute we testers
don't become a substitute for anybody we
support the development effort and/or we
support the customer side of things
specifying and accepting the code so
yeah I think I'm starting to think and
this is heresy but I'm starting to think
that testing is a skill set and some
people love testing like me
I love testing and yet I'm finding that
the lines are blurring a little bit and
it's becoming just another big skill set
out of what I offer a team so yeah
ah if the responsibility is blurring
between the tester and the developer
who's ultimately responsible some of you
know what I'm going to say right let's
say it in unison the team see this is
one of the biggest mind shifts for agile
and one of the biggest areas that's
difficult for management to accept
because management typically wants to
know who do I blame at the end of the
day who do I come back to if it breaks
who's the buck stops here where is here
because I want to know whose desk bets
on so that I can blame them right okay
so how do we make sure that the quality
of the test was sufficiently good well
that's a slightly more complex answer
you can use code coverage analysis tools
to figure out what coverage you're
getting there is no one person who is
responsible for the quality of the unit
tests the responsibility belongs to that
altogether Newson but T and this is one
of the reasons why extreme programming
teams believe in shared code ownership
so it's not like this is my section of
the code and that is your section of the
code we all work on the code and the
code starts to look like any one of us
could have written it yeah this does not
surprise me that somebody would object
to the heresy that I have just committed
yes the team first I think I'm putting
the responsibility of the TV's sounds
very good but in the end you're
basically putting the responsibility of
no one I think it's very easy to and get
away as that waits because of the team's
not just me I think it's important to
name one person and another thing is
that you say the tests need to stay
green all the time never let tests go
red
that was supposed to be green okay but
in practice I'm sure awful nutty when
you
practicing right you know that just is
right in the morning oh sorry is right
in the morning it needs to be fixed I
don't have time because you have other
read tests that you need to fix first
you know this tests are going to stay
right for a couple of weeks Oh what kind
of testing framework do to help you keep
track of those tests make sure that they
don't sleep okay so am I allowed to
invoke the M word again Microsoft they
shipped with a product that according to
the popular press and we all know how
messed up the popular press gets reality
but according to the popular press they
shipped with 63,000 bugs and they were
vilified in the press for doing that and
they've gotten a whole lot of bad press
for having shipped stuff that's got
security flaws and you know there's a
whole debate that we could go into there
but that number sixty-three thousand
just fascinated me because I wondered
what kind of enterprise-class bug
tracking system you have to have to
manage 63,000 bugs at which point it
dawned on me that if you have to have
that much effort in tracking bugs maybe
you need fewer bugs instead of better
bug tracking systems so going back to
what you're saying about failed tests if
you've got that many failed tests you're
incurring technical debt now this is a
term that all of us have experienced
whether or not we put a label to it
anytime you're working with code that's
fragile where you know if somebody
changes that module bad things are going
to happen so we don't touch that module
unless it's absolutely necessary and if
it is absolutely necessary we get out
the full you know fire protection suits
because we're going to have to go into
the breach to get then to this code that
kind of bad scary code well let's let's
not find special ways of managing that
pain let's fix it right so anytime I
hear about tests having to stay red I'll
remind you that that's a choice now it
may be a choice that you're making with
a full perspective on all of the
business
that you're under but I'll suggest it's
a very expensive choice because that
means that you can't trust your test
runs they go red and the first thing
you're going to say to yourself is oh
that's just the test braking or we know
about that once upon a time on a project
I had a test suite that was kind of like
that I had a bunch of things that were
failing for reasons that we didn't care
about this is feedback we didn't care
about and I went through and looked at
we had 75 failures or something and I
looked at the first 38 of them and they
were all for this one reason that we
didn't care about so I didn't look at
the remaining ones and it turns out I
missed a horrible bug because I got
lulled into thinking that all of my bugs
were in that class so the test must
continue to reveal interesting feedback
and information otherwise you'll lose
the value of even the good tests right
so I'll suggest that if there's really
one that you're not going to fix for a
couple of weeks move it into a different
test suite with big red flags all over
it saying this is a known bug and we're
going to ship with this issue uh you
asked one so I'm going to go over here
and then I'll shoot oh okay yeah oh
thank you yes
so I'm so glad you said broken windows
so Malcolm Gladwell in the tipping point
wrote about the broken window phenomenon
where they found in was it New York City
that neighborhoods that had broken
windows tended to have worse violence
and worse crimes and they did simple
things like erasing graffiti and
preparing windows and the crime rate
went down just because it appeared that
people cared more so the pragmatic
programmers Andy Hunt and Dave Thomas
wrote about this in their book the
pragmatic programmer as drawing the
analogy with the little breakages in
code that we kind of say oh well that's
okay we'll we'll deal with that one
later right well it turns out it has the
same effect because then we say that's
okay two more things stuff that we
didn't have to say that's okay - yeah
and products that were really shy and
upper management doesn't need to know
about that because when you're
developing words in the past they'll
come back and say it works why are you
going to change it so refactoring just
in case you don't know the official
definition of refactoring refactoring is
changing the implementation without
changing the behavior essentially
cleaning up now it may seem to some and
some managers believe that this should
be unnecessary because if it works it
just works don't touch it
but the fact is that by refactoring you
get more maintainable code so the next
change is easier to implement so you
reduce your technical debt when you
refactor yeah okay so the question is
what if changes are coming every week or
two weeks how does this work with agile
well that is agile that change is
happening that frequently and I'm sorry
if I left you with the impression that
these were longer stretches of time for
the agile projects that I've been on our
iterations are typically two weeks so
they're they're very quick turnaround
kind of things and they should be it
should be small incremental changes so
you get that continuous stream of value
so it works very well with agile which
is why I was giving you the puzzle book
because because that's exactly why you
need agile hairy it is now time I thank
you all so much wow</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>