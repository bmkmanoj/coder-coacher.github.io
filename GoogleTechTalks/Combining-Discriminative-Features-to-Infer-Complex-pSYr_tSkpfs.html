<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Combining Discriminative Features to Infer Complex... | Coder Coacher - Coaching Coders</title><meta content="Combining Discriminative Features to Infer Complex... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Combining Discriminative Features to Infer Complex...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pSYr_tSkpfs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">ok so today we have with us David Ross
from the University of Toronto he's
going to be presenting some work on
tracking percentage of my CML thank you
so the work I'm going to talk about
today is called combining discriminant
features to infer complex trajectories
I'm currently a PhD student working with
rich saml at the University of Toronto
and the other codecollaborator was Simon
o sandero one of Jeff Hinton's postdocs
so the problem I'm going to address
today is that of fitting a probabilistic
model to a set of continuous state
variables and we're going to try to
estimate these state variables from a
sequence of observations so this is
stated kind of abstractly but a more
concrete example might be trying to
estimate the location of a basketball
which is a continuous variable that
evolves over time given high dimensional
observations which are the video
sequence you could imagine applying this
to some other settings like robot
localization in that case your state is
the true position of the robot over time
and you have various sorts of
observations for example information
from the odometry how far the legs or
wheels have moved locations of visual
features which might suggest where the
robot is or maybe audio cues so if you
notice that the radio has moved a
certain the sound of the radio has
changed then you might get some
indication of where you are based on
that so the trick to this approach we're
going to model this as a discriminative
conditional model which is a little
different from how people usually do it
and this has a couple of advantages over
the typical generative state space
models like common filters and HMS
basically this allows us to pile on
features so if we can come up with any
way any sort of feature that might
suggest where what this continuous state
variable is so the running example I'm
going to use is my friend Simon bouncing
a basketball and then we'll watch him
tracking the ball later so any features
which we have which might suggest where
the ball is in this video or then we can
add them to this model and any sort of
features that describe the dynamics so
our understanding about how the ball how
this continuous state sequence might
evolve over time we can throw all of
these in and then using labeled training
sequences we can learn which features
are relevant and more than that as we're
tracking so when we're using this at
runtime we can learn or decide which
features are useful and switch them on
or off dynamically so include all the
features you want learn which are
relevant in a training session and then
online you can switch them on or off
depending on whether or not they're
relevant at a given time so if you know
a lot about machine learning then you
might think this looks a lot like a
conditional random field except that we
have a continuous state variable instead
of discrete and we our features can
switch on and off and then if you know a
lot about the stuff that Jeff Hinton's
group does then you might say this is a
product of experts except that we're
training it conditionally so the
motivation here the standard way of
modeling continue with state sequences
give it observations is using a
generative state space model so here if
we have a sequence of observations why
and our state sequence X then we model
it in by using these two components
first we have an observation likelihood
that says what do the observations look
like given the state so what is an image
like if we know the position of the
basketball and then we set up a prior
distribution P of X which describes how
this state sequence of balls over time
so how do we imagine the ball flies
through the air and bounces then you
take these two probability distributions
you apply Bayes rule and out of it you
get the posterior distribution P of x
given Y which is your estimate of what
the state sequence is given your
observer
so this standard approach like a common
filter is the canonical example makes a
couple has a couple of quirks first to
make this computationally tractable you
have to assume conditional independence
of observations that means that given
the state sequence all of the
observations are independent and that is
generally not true because if you
imagine you know I know the position of
the ball then the two images out you
know nearby fractions of a second in
time should look very similar I mean
they'll have correlated features not
related to the position of the
basketball and such so this is more or
less implementing is computationally
tractable and works pretty well in the
real world and then the other quirk is
that you have to use a single likelihood
function to model the entire high
dimensional observation so your
generative process here you near p of y
given x is what does the image look like
given x's are our position of the
basketball and so it's very complicated
you have to basically learn some way of
modeling the entire generative process
of you know basketball at position 10 12
and then generate an image of my friend
simon holding the ball and bouncing it
and doing whatever it should be so it
can be very difficult to create these
likelihoods instead our approach which
have been taken by others but we're
applying it to continuous sequences is
to model this posterior distribution p
of x given y directly so this has a
couple of advantages first we don't have
to make the conditional independence
assumption because we're always
conditioning on the observations we
don't have to assume they're independent
and any features we use which might help
us determine where the ball is can look
at more than just the observations at
one time step so our features can look
at windows of five time steps of time
five video frames or can look at say the
whole image sequence when trying to
determine where the ball
so this allows us to use much more
complicated and interesting features and
the other advantage here is that
features can be discriminative so a way
to think about discriminative versus
generative if you had a generative
likelihood then that would be like me
I'm giving you a location of the ball
and saying I want you to draw a
photorealistic image of Simon bouncing
the basketball whereas if you had a
discriminative feature it would be more
like me handing you a picture of Simon
with the ball and saying give me a rough
idea where you think the ball is so I
mean in many cases the second
discriminative features could be a lot
more easy to to create and this
framework gives us the other advantage
of allowing us to include any sort of
features we might imagine and then we
can learn their relevance if there any
questions feel free to stop me if
there's anything that's fuzzy about the
math or statistics then and just let me
know okay so what are features in this
model I'm going to include two different
kinds of features dynamics features and
observation features dynamic features
consider the state at two adjacent time
steps at xt minus 1 + xt and they return
a value indicating how well do these two
states match so if we have some notion
about how the ball should move how
likely is it that these two adjacent
States fit say the ballistic trajectory
of a basketball this will return a large
value if they match well and a small
value if they don't match very well so
for example this could be if you knew
about linear or nonlinear dynamics it
could just be do these two states match
according to this dynamical model and
then the other sorts of features are
observation features so these ones take
the image sequence or observations and
I'm give a guess as to what the location
of the ball might be so yeah
so this in principle could be any sort
of appearance model or object detector
so if you had some black box that takes
an image and spits out a guess as to
where the ball may be based on color or
shade or any one of those things now one
novel aspect here that we're adding and
with these features is the ability to
robust to buy these features by
switching them on and off so if you're
throwing in features at any given time
they might be on the ball or they might
be you know giving spurious results and
to keep those from polluting our
estimates here we're going to introduce
hidden binary switch variables so you JT
is is binary and it's one if the
dynamics featured J is relevant it's on
at time T and 0 otherwise and v kt and
switches the observation features on and
off yes the descendants
how do you decide that when you want to
switch out of a picture well so for
example the observation features each
give a guess as to where the ball might
be and it's several of them agreed and
you imagine that there than there the
right so they're there they're all
firing at the same location they're all
saying that the ball is there so it's
sort of a weight of evidence we have two
sources of evidence there's some
agreement so if the dynamics agrees with
the observations then probably all those
features that agree are right and should
be on and then I'm going to get to it in
a little bit we include extra side
information that allows us to determine
based on the observations whether we
think certain features should be over so
we'll get to that and if you're still
uncertain as okay so probability model
if you're good at parsing factor graphs
this is what this looks like yeah I can
probably skip past it
so if you like probability instead I'm
going to build up the probabilistic
equation that we use here so if you're
just looking at the features then this
is just a standard log linear model
we're taking the exponent of the sum of
all of the dynamics features across all
features in time and all of the
observation features at all times in and
so you can think of this as a log linear
combination or as a product of all of
these features look at the product of
experts between those features is sort
of the pseudo probabilities right right
yeah so um we are making the Markov
assumption in time okay that in each
state is related to its neighbor and you
know we don't have a yeah and I think
that's the only independence assumption
we're making because we're conditioning
on the observations at all time so we're
not making any independence assumptions
for my observations and state yeah so if
you want to see my slides later this is
the factored wrap and you can figure out
all the independence assumptions of this
okay so this is the basic model and this
is without switching features so if we
include the switches here then we just
add an extra variable that multiplies by
each of these features and if it's one
it turns it on and we pay attention to
it and if it's zero then it switches it
up
and then the final edition is these side
information so basically if your
features are unreliable then switching
them on or off at the correct time will
dramatically affect your performance if
you know which features to pay attention
to even if there's only one that's right
and you know that that's the right one
then you can do well and if you're not
sure you pay attention to people who are
giving you bad suggestions and you'll do
very poorly so um to improve the ability
of our switches to turn features on and
off or including additional information
so these guys these calligraphic fng are
just saying we're going to look at the
observations and get to some indication
as to whether or not this feature should
be more you can think of this as some
sort of classifier that looks at the
observations and tries to guess whether
they should be on or off so in this one
in particular we're just using logistic
regression so like a linear classifier
that looks at certain information so for
this one the observations it's easier to
understand if you're using an appearance
model so for example a template of the
basketball and then you scan it all over
the image and you find the one location
that it matches best that you can
compute the error with which it matches
the the the template matches the image
and this error you can use it and
combine it in a linear classifier to
indicate whether or not this switch
should be on or off so if the template
matches well then that's strong evidence
that the switch should be on and if the
template matches poorly then we should
probably ignore this feature because it
just isn't very likely to be the
basketball so the switches are
determined by this information does it
agree with the state sequence does it
all fit and this side information
that we used it to get a little boost ok
so the features in more detail so
specifically in this model we're going
to use these sort of Gaussian energies
or Mahalanobis distance features so for
each let's start with the observation
features we're going to have a function
that looks at the images and that time T
tries to predict where the ball is and
then the feature is just the negative
sum of squared distances weighted by
this precision term or inference
covariance matrix beta K similarly with
the dynamics we have the state of the
previous time then some function here
that says how are we going to evolve
this how are we going to take it one
step forward according to dynamics and
in this particular instance of the
problem we're going to use linear
dynamics here so we're just going to
move it forward according to some notion
of linear dynamics and then we're just
going to compute the squared error
between the state of time T and if we
evolve it forward one step and then
again we've waited by this precision
matrix alpha so the Precision's alpha
and beta are the parameters that were
really interested in setting well when
we're learning there will indicate how
reliable a feature is you can think of
this as a covariance inner Gaussian if
its inverse covariance so if it's some
very large that when you have a great
deal of confidence in biased emits by
this feature and if it's very small then
we we don't really pay attention to this
feature much because it's very noisy so
in learning we're going to try and set
these alphas and betas and they say
whether feature J or K is reliable
side information so I mentioned this
before we need to include some extra
features to help decide if these
switches should be on or off and we're
going to use basic classifiers here so
logistic or softmax regression so in
particular for the observations we're
going to look at the the errors with our
observation models our appearance models
and that will give us some indication if
we should turn the motor off okay so
unfortunately in this model of what you
want when you're trying to estimate your
state sequence or track is on this
distribution P of x given Y the
continuous state series given the
observations and obtaining just this
distribution is actually quite hard the
reason for that is that we have all
these binary switches so Keith x given Y
is actually P of X UV given Y and then
we have to marginalize out over all the
different possible settings of our
switches and because of binary we have
exponentially many so doing inference is
difficult but unfortunately we have or
fortunately we have two things that we
can leverage to make a fairly easy
approximated for the scheme first of all
we know that p of x given the the
switches and the observations is easy so
if we know which features are on and off
and we have the image sequence then we
can estimate the state's very easily so
this essentially amounts to something
like calm and filtering you're just
going to do expectation so a forward
pass of a belief propagation what the
state should be and then a backward pass
and then you can come up with an exact
exact
version of this function P of X and then
similarly on P of UV give an XY is also
easy if you know the state sequence and
you know the observations then you can
tell which features were telling you the
right things you can tell it that
switches should have been on or off
because you already know where the ball
is so these two things are easy yeah so
how p of x given you me why you can
infer using belief propagation and these
switch probabilities you can sample or
compute their probabilities using these
simple things so this is just a a
sigmoid function of some linear terms
and it's just done so so these are both
easy now
to put this together our inference
scheme is going to be if we're given on
an observation we're going to come up
with some initial guess as to what the
switches should be so we can look at
these classifiers we had earlier that
will tell us whether these switches
should be on earth and they're just kind
of a week indication and then given
those switches we're going to do
inference to get the particular state C
so we're going to apply this guy and get
an estimate of X now given Y and X we're
going to re-estimate and resample on the
switches human being and then we're
going to take this new series of you
would be and get a new version of X by
sampling so this is sort of an iterative
Markov chain Monte Carlo scheme for
sampling from this distribution so we
can use this to compute expectations the
expected sequence
so learning the goal of learning here is
a supervised training of these precision
these inverse covariance terms that I
indicated before and this is to train
the Precision's of the features so how
reliable are certain features the
algorithm that we're going to use is
contrastive divergence by geoff hinton
which is basically an approximate
gradient descent scheme I'll skip the
details of that but I can refer you to
information if you're interested if you
know a lot about jeff's Boltzmann
machines then you can think of our state
sequence as its visible units and the
switches as hidden humans now in
addition to learning these Precision's
we can also improve the quality of our
side information features so these
classifiers which are suggesting it
switches should be on earth we can just
sort of wrap this learning into the
gradient descent and do it all at once
sorted from some initial guess as to
what these parameters should be a better
the fine
yeah if you want to see the great ansys
is what they look like they're kind of
messy
okay so a quick recap what are we doing
so we're building a probabilistic model
of the state given the observations and
we're posing it as a log linear
combination of dynamics and observation
features the way we set it up you can
include any features you'd like and
you're going to learn which features are
precise and which aren't during from
labelled training data and then when
we're tracking at runtime or doing
inference we're going to dynamically
switch features on or off depending on
whether or not they're useful so the
application I did pose this in general
setting but done tracking is the
application we've been aiming at here
our goal here is to estimate the
location of the ball based on some
unreliable observation and dynamics
features so here we're going our state
sequence is at each time a six
dimensional vector that it coats the
position velocity and acceleration of
the ball and our dynamics features are
going to be linear dynamics our
observation features are going to be
some sort of detectors that try and
guess the XY position of the ball only
so an interesting thing to note here is
that features don't have to say
everything about the state so this
observation features they're only going
to predict x and y position so they're
Precision's might be high for x and y
presume but they're not going to say
anything about velocity and acceleration
which is also part of the state so
they're going to have essentially zero
precision in those predictions so this
is a way of combining features that give
different source of information so they
don't have to all say everything about
our state vector
so we're going to train this model using
video labeled with ground truth so I
took some of the sequences and labeled
where the basketball is in each frame me
rather tedious but so we've got
sequences of video images and the ground
truth locations of where the ball is and
then in our ground truth I've just
filled in the velocity and acceleration
using finite differences so we trained
this model learn the Precision's and
need some switching features and then
run it on these sequences so what
observation features are we going to do
this my goal here was just some features
that I could code up quickly that give
up a rough indication where the ball is
and really aren't that reliable so these
ones that I threw together in like an
afternoon start with 6 templates so from
the training data I it k means to
k-means clustering on images to the
basketball and came up with five
templates of what the ball should comply
and then I also randomly picked one of
the frames and took up the image of the
basketball how did that as a template so
each of these features at every time
step we just scan this template over the
whole image and we find out where should
be and then the guests of that feature
is the one location in the image that
has the lowest error matching error
between the template and the image as a
somewhat more reliable model we train
principal components analysis using only
three components and this is again on
images of the basketball term for
training sequence and we use the same
deal here we scan it over the whole
image at each time frame and return the
the location that has the lowest
reconstruction error and then our final
feature of for the observations is local
background subtraction so this is the
only one that actually uses windows
larger than just a single frame of where
we're looking at adding more complicated
features right now so this one we take a
window of five observations and then we
so these are images and then we just
take the mean of it and then we subtract
that from the image of the current time
step just to get an indication of where
the most motion has occurred and so
we're going to come up with stump spot
on the image where it's changed a lot so
if only the basketball is moving you can
imagine that this might be a pretty
reliable indicator with balls but if
there are other things moving like the
player is moving or the cameras moving
in this feature is going to be a linear
dynamics we're going to include four
different dynamics features and these
are just the standard physics that you
get for a ball in flight a ball bouncing
off the ground ball bouncing off the
wall and just sort of a Brownian motion
sort of a random dynamics for when that
the player is holding the ball because
we don't have a good a priori notion of
how the ball cinnamon or side
information against reconstruction error
of the template how well did they match
okay so now it's time for videos
so in this one we use the first 500
frames labeled with ground truth to
train and they were tracking on the
remaining frames here the blue indicates
where the ball is and at each time step
we have a circle the diameter of the
circle is our uncertainty there it's
like a plot of the covariance or
estimate the red and yellow dots are
locations that the observation features
say are most likely to hold the ball so
yellow ones are observation features
that we think are relevant and we
switched on and read or observation
features that we think are terrible than
we've decided to switch off so you'll
notice that these features are at any
given time there's probably one or two
on the ball but a lot of them are
terrible and they're just giving us very
unreliable results so we're able to
track the ball through despite using
these very poor observation features
so in a video we do lose track of the
ball four times twice of them it's
because the ball is included Simon
halted behind himself and so onions a
legitimate loss of track here and then
twice it's because we incorrectly switch
teachers on or off when we should and
that screwed up our estimation of the
states and we compared it with two other
trackers one is the the previous work I
did on incremental learning PCH record
and it can track the sequence up to
frame 688 after which it fails and it
can't recover and then we also applied
on the mean shift algorithm and it
basically has no traction here because
it relies on color and with this low
contrast ball it can do anything so here
are some highlights from the video or
the lights of the case may be here's
where the ball is hidden behind
assignment and we incorrectly determined
that these features should be on when
really they're not indicating where the
ball is so we get lost there but as soon
as the ball reappears so this is just a
few frames later then we we notice it
and the state sequence estimation
corrects itself this frame is an
indication of the importance of the
dynamics features so we're not just
doing some sort of detection at each
time frame at this case um there are no
features on the ball the only ones that
are on are incorrect yet because they
don't agree with the dynamics so I guess
this estimate is worse than the dynamics
then we stay on the ball because we're
not
fooled by this misinformation so this is
just some Diagnostics about exactly what
we learned here this is a plot of the
standard deviation of each of the
features so I said before we learned a
precision matrix for a diagonal
precision matrix for each of these
features estimate of how reliable it is
and so I just inverted it took the
square root to get this standard
deviation its own this is units of
pixels in the image so we see through
that the principal components analysis
feature is the most reliable the k-means
templates are slightly more reliable the
single image that I just randomly picked
is is not too bad either but this
background subtraction is way up so it
it doesn't give a very reliable estimate
as to where the ball is so this other
graph over here is an indication of how
often the features are actually on the
ball so if you look at the ground truth
we can see how reliable is this feature
when was it right when was it wrong and
then these two lines are a true
indication of whether it was right or
wrong and this is our estimate so how
will rewrite at deciding if this should
be on or off so you see for most of
these were very good at deciding when
features should be on a mom but this one
feature here we are very that so this
background subtraction so are my measure
of whether this feature is right or
wrong it's just did it give a location
and estimate within five pixels of the
true location so this background
subtraction feature almost never gives a
location within five pixels so it should
be off all the time yet we're turning it
on almost all the time so if you put
these two prediction or two pictures
together you can figure out the reason
basically this feature is unreliable so
we've down weighted it so we're not
paying too
attention to it anyway and although we
have it on all the time its its its
predictions are very noisy so we're just
sort of we're keeping it around because
it's sometimes in the neighborhood but
we're not paying too much attention to
it so the first example was sort of
simple in that we were doing week
generalization we trained on a sequence
on the first part of the sequence and
then tested on the remaining part of the
sequence so as a further experiment
where we're going to train on two
different sorts of sequences and then a
train on a separate one of our tests on
them a separate one that we've never
said before so here we have two training
sequences one where Simon and my advisor
Ridge are rolling a basketball back and
forth and another where they're bouncing
it back and forth and then our test
sequence they're going to be either
rolling or bouncing at the same time so
in none of the training videos have you
seen both rolling it bounced
so this one's a little slower they're
just rolling the ball back and forth
again red features are ones that we're
switching off in yellow that we think
are on so the first 500 frames of this
was used for training as well as the
first 500 frames of the bouncing
sequence and then for the test sequence
of rolling and bouncing we didn't train
on that at all
as soon as this the other video that we
we trained on so trend on the first 500
frames and then this is just the result
of tracking the whole thing
I think the one yellow feature that's
giving a lot of spurious results is the
background subtraction or motion
detection feature and we're not paying
too much attention
ok the boss
okay so this is the test video that
we've never seen before it actually does
a little bit poorly at the beginning
here that this illustrates the main
failure mode of this algorithm if you
have unreliable features and you're not
able to tell that they're bad that they
shouldn't you shouldn't pay attention to
them at a time then we're going to make
mistakes so there are features here
firing on the back of this Toyota there
and where we're not able to to turn them
off so it just makes mistakes at the
beginning but then near the end is
smaller bus and here we're combining two
different sets of dynamics and we didn't
see both of them and it's the same video
before
so in terms of initialization in
conference with a lot of trackers where
you have to you know give the ground
with location the first frame you have
to click on or where to start this one
doesn't be initialization and because of
that it can recover when it gets lost
which is something that a lot of
crackers including my previous work
didn't do
okay so as a further experiment of this
we tried applying it to the problem of
occlusion or missing data so as a final
sequence we use the tracker that we
trained it on rolling and bouncing and
we applied it to the problem of tracking
the ball behind this recycling bin so as
you'll see Simon froze the ball goes
behind the bin and then it reappears on
the other side and for this short
segment we're able to track it through
both of these inclusions and we use our
knowledge of dynamics to estimate where
the ball should have been roughly as it
goes behind a bit
so you'll notice that it doesn't
perfectly follow the ball as it goes
behind the bin but I think that's
because we don't have it's hard to
estimate that the ball has bounced when
it secluded so one of our further pieces
of work is to try and be able to do that
so in terms of related work this is a
lot like many different methods out of
therapy the most closely related is work
on conditional random fields by Lafferty
and McCallum you can think of this as a
conditional random field with a
continuous state space and more
complicated features this is also
related to products of experts and to
exponential family harmoniums which is
work by mac swelling at UC irvine the
generative analog of it so that the
standard way of doing this would be
switching the near dynamical system to
chuck a lot of people using them
tracking such as people at Georgia Tech
and then there's also mixed state
continuous and discrete particle filters
I think this is worth by Andrew Blake I
think switching linear dynamical systems
and mixed state particle filters are
essentially the same thing except you're
using mcmc and the second one there have
been other people who've done
discriminative trackers related ours
like Christians in it and she said scoot
but his work is related to estimating
body joints and he he doesn't do the
same sort of learning framework that we
did another very similar thing would be
a common filter with input gating so
this is in standard computer vision
textbooks basically a common filter and
that each time step there's a classifier
that makes one of the observations and
says which what it's going to pay
attention to so what are we going to do
next in terms of the features that we're
using for tracking this is pretty much
just a prototype these features are very
simple through them together quickly so
we're interested in using better
features that are more reliable and use
more of the observations so one thing
we're considering is optic flow we can
use this in the framework because we
have all the observations so we can do
optic flow over more than just one time
step we can do it over larger time
windows and we can use that to
intimating which features should be on
or off in terms of observation features
we're thinking we could use sift
features or at the very extreme each
feature in our model could be the
prediction of another state of the art
tracker and we can learn which of these
state-of-the-art trackers are reliable
I've given scenarios and when we can
switch them on or off to to decide what
we're going to do another interesting
way
another direction that we're exploring
right now is including different
modalities so I just have observation
features here which are based on the
images but when the ball bounces behind
the bin a good indication of the fact
that it bounces the fact that you hear
the sound so we're looking at using
sound features to try and give us
indications about what the dynamics
should be important to moving this to
more interesting domains would be using
nonlinear dynamics and we're also
interested in applying this to other
data so my colleague things that we get
rich if we manage to apply this to
financial time series robot localization
might be a more realistic problem and
I'm open to any suggestions that anyone
might have has two problems be
compliance too okay so that concludes my
talk thank you all for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>