<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stationary Features and Cat Detection | Coder Coacher - Coaching Coders</title><meta content="Stationary Features and Cat Detection - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Stationary Features and Cat Detection</b></h2><h5 class="post__date">2008-12-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-w72_VwSj6A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is a work with done gman at
Johns Hopkins basically it's an
extension of something we have been
doing for years and which was a
missionary in phase detection on now we
try to extend this to LA complex object
so during my I did my PhD was done given
it was my advisor on we designed a new
phase detector which was based on an
idea of hierarchical decomposition of a
possible so this is typically so I don't
know how familiar you are with object
detection in general on vegetation more
specifically but the idea of object
detection is you want to design an
algorithm that if you give it a scene so
an image where an object is visible or
one instance or few instances of the
subject at the end you would get as a
note output locations of all the
instances of the object so four phases
you would expect to get usually a
location of the scale taking well aware
it is for everything so in that case we
were going a bit further because we are
go to estimate more accurately the
Margaret is a location of the face so
what precedes me for this algorithm the
output for every phase would be the
rotation of the eyes on here I just
display as more triangle to show roughly
where it is but it's not estimated
location of the mouse it justit was so
the usual way of doing object detection
consists of passing the scene so going
through a relocation on every scale on
at every location on every scale to have
a black box machine running able to
answer the question it is the object
there or not ok so you have this kind of
algorithmic group which is outside that
goes through locations on the scale one
for every single location scale you ask
your machine running same is our faith
is our faith is effectively so you have
this external loop we will scan on five
risqué going through locations ok and
for the approach we propose which we
call cost to fine the idea was to divide
what we call the po space so now the
task we need to solve is you give me a
small image for instance 32 by 32
greyscale let's say and I just start to
predict so the machine running belt has
to predict a boolean flag if there is a
face or not but in that case we need to
go just a bit further which is wanted to
know there was a face on where is the
location of the eyes so the approach we
proposed was to to build a sequence of
ocular family of math if I also hear you
this ellipse stands for the what we call
the ball space so in that case suppose
it's just location of the center between
Z is 0 this point to tilt so it's young
girl between the large gatherings with a
face on the Vatican the image on the
scale which is a distance between the
eye so suppose is the set of those four
parameters on here this stands for the
water pools we want to catch in this
morning age so we lets us on top of the
ice float into a small box eight by
eight bucks so it will be between news
21 plus 20 degree on the scale between
eight and 16 pixels on here you see the
dispersion ear I sample at Honda me
firmly in this post base roses and I
just deeply displays your eyes on a
mouse location and as you see is pretty
spread but so we will do classifier
which is suppose to say one to respond
that there is something as soon as there
is a face whatever its paws which is
still in this ellipse it's it's a pretty
challenging task because you expect a
lot of in violence from your classifier
but so we proposed another ID which is
we will discuss if I out an extremely
conservative threshold so it will react
so that it never misses the face of
course this detector would make you a
lot of false positives but then if this
guy's says there is a face then we have
a bunch of a family of four although
detectors which are dedicated to more
constrain poses so now every one of
these ellipse instead of being the same
constraint as before now we focus on top
of the ice to be in a small box of 4 by
flow instead of eight by eight so it's
why we have four detector we're going to
try is our face with the center here is
our faith with us on trial here
so here you see that it constrained
farmers or occasionally eyes on the
mouth when we go we go down like this so
we split location on scale on tilt etc
but so the global ID that we have this
ball space where the post can be get me
anywhere or we will split it the article
on build a family of classifiers
dedicated to sub set of targets of
phases which are getting more on more
complex so at the end of the CR key for
instance this ellipse you can see that
it's extremely highly constrained on now
of course you can see fire which is
specifically aiming at detecting faces
with this pose is far easier to build
because you don't expect the machine
learning part to learn on to guess on to
inventing variants which is in the data
now the only remaining in violence is
due to almost independent random stuff
you don't have any more strong long-term
correlation due to the fact that there
is this hidden by a bar which is open so
to summarize all this we have this yucky
of both cells or we build one classifier
which only to interact pretty well sorry
it worked pretty well but result strong
drawback which is that we need to build
one can see for every cell on the actual
implementation we we built we add more
than 100 classifiers on who you need to
feed those classifiers to train them
with training sets which very fee which
are actually consistent with your post
constraints so for the faces that was
easy because because there is just
translation scale on rotation if you
give me a name age of a face in a
certain pose I can sanitize anime tofu I
can for suppose to be in any cell just
by rotating it scaling it almost 80 but
in practice that would not be the case
you will need lot of data so maybe to
put this in context are there have been
a lot of work and object detection on
I'm going to
with them in two big families so one it
would be what I call path based which is
just that you would look for your object
by detecting individual discriminating
parts like arms or I or whatever and
then to have really Susan de la moda it
some kind of condition in Independence
of the part given certain reference
point but in practice algorithmically it
gives you an algorithm for which you
find parts on all the parts will do some
kind of have transformed so voting for
what is a Sumter consistent with me so
if you detect the arm here and you would
say okay there is the guys that are
either here or here now you did exist
this arm on the subs going safely the
guys is out here here you get two votes
here you see in case you break in here
on your a bunch of methods which are
getting more and more sophisticated on
the work usually pretty well based on
this this ID and then you have what I
would call monolithic model which is
just what I described before so you go
through the bodies on use brute force
machine learning on to ask again and
again the question so you have the
one of the first method for Phase
addiction which was based on whether the
density of face images with the on
the show equations then you have the
famous congressional networks which have
been existing for a Kino 20 years and
one works pretty well are you out the
four phases of famous cascade of Cassie
first bill by boosting okay so what I'm
going to my talking two big parts one is
the new idea of stationary features
which is a way to fix the main weakness
of the cost to find technique I talked
about on the second part is really cut
detection an application this technique
ok so to to formalize a bit I will
denote why the pore space so so so this
is hidden viable we want to associate to
every target to detect it's it's a
geometrical post but I'm going to split
it into K subsets which correspond to
the resolution I'm interested in I'm
going to be more precise then I will
denote big I any major so the thing I
have access to on to the image i will
associate as as many billion random
variables that as cells so for every sin
i have 1,000,000,000 run on weber that
tells me if truly there is not a target
in this image with suppose in this
subset so for instance if i'm interested
in phase detection on let's say there is
no scale so all phases are our same size
to make things simpler the image will be
something like this map of pixels the
pose of the targets archer is orange
cross to DC so the post pace is the
actual or 2d rectangle so two
coordinates between as you want on the
way your own wits all right i would
split it if I'm interested in for
instance or a resolution of i don't know
what 32 by 32 pixels i would speed my
post base into as many cells of that
size what I would have one more number
for every cell so for this scene for
instance all this one of our V 0
00 it's a trap but only two of them
would be equal to one and the other
locations for which over time okay so
four faces as i said in the front slide
we considered a 4d pose which is just
the coordinate of the center of the face
the sched size on the teeth but the
private that cats tend to be slightly
more complex so sorry mate she's taken
from the database we use and they tend
to have an extra me an extremely large
variation in in the pose goes from okay
you can see by yourself so what we
propose it just to add one more
parameter compared to the to the face to
explore this now we are in the process
of making it even more complex but for
now and bring the rest of the talk
suppose we'll be a 5d vector which is
just sometimes ahead yuhp H so this
point radius of the head so the diameter
or the rights of this circle and then
the location of this what like I would
cause a baby which is roughly the center
of mass of the body of the cat okay so
for every cat there is a wicked visible
in the image there is this ground crews
fight the most parameter yes yes yes
painfully annotating is that so now if
the steel abstractly so if we if we
forget precise example I'm i just
described if you are given a training
set which is a bunch of images and for
each of them this long boolean vector
that tells you where the targets are
what you are going to interested in is
to build for every K a predictor that
tells you is there in this image the
target whose pose is in YK yes or no so
predicting this number
right on the interesting point that if
you have no additional knowledge about
how the signal interact with the polls
in this complex interaction the best you
could do would be for every image you
would have to Train one classifier five
weekend and so forth so for every image
we'd have one sample which is a plus
zero is if there is no target with the
pose into YK one if there is a target
with my key but so to make it more
concrete if you of course this looks
stupid because you have a strong opinion
about the fact that the target is the
appearance of target is translation in
volumes which something looks like a
face at some point of the image if it
somewhere else and still look the same
it should you should see be able to say
so this is a target but you have to
rewrite that is because you have a
strong understanding of the relation
between the boot space so here the
reserve UK for phase between sir the
location on scared of the face on what
it means in term of pixels but if you
don't have this knowledge if you not
models is the best you could do is if
you want to Detective our faces here in
scenes you would take 1,000,000 see on
for every of them say ok if you have a
face here it's of class one if you don't
if there is a facebook so mice to be of
class 0 and then you would train one can
see one classifier for this location on
your way train your nose are conceived
on another occasion etc it looks stupid
to see it that way but it's actually
what you would do if suppose so relation
between the post base on the image space
is not up view so if for instance I I
have a bunch of images which are
extremely well scaled on sound third but
now you have only one remaining
parameter which is hunger out of the
plan usually what people do they reach
rain one classifier for small domain of
angles they they they don't they don't
do what they do for translation which is
to find a way to get rid of this problem
so in practice if you have K post-sales
and you have no idea of the relation
between the signal on the on the pole
what you can only do is basically to
have one sample for every scene on the
divide a number of positive examples by
the number of poor cells so
of course people don't do this for face
detection so if I denote see a feature
vector what usually people do that they
introduce a way to normalize the signal
which is if you give me a post an on an
image I can produce a new image so that
if now i compute my features in this new
image and there was a target initially
at suppose then it does not depend with
the pool okay practica what does this
mean it means that you are able if i if
i give you a bunch of images with faces
all over the place your eyeball to bring
them to a reference pose so that if you
compute now you feature after this
normalization it does not depend anymore
with well as the target before this
normalization so if we denote it that
way and it just mean you bring in the
reference pose in reference post sell
all your training examples okay so you
can do this if you have a way to
normalize the signal given a post cell
where there is a target you can bring
your target into a kind of reference
frame you can do it if you can do this
then what you can use to train when they
take tour with this new data set which
is for every scene on every pose I
normalize my signal so i'm going to
compute my features in the image after
normalization and i will associate the
labor the which depends with was their
target initially at least pose or not so
if we like I give you see you go to
every pose bring it back to a reference
frame on here if there was initially
faced blue of class one is a or it
reveals classy so this is nice because
now you keep when you're a lot of some
power on you keep especially all your
positive examples on now we will try one
guy with this one classifier on now if I
want to predict if there is a target in
email in scene I up with a pose in
poster k i will first dominate my signal
according to dispose on computer
response of my classify of them okay so
if I want quickly there's a face here I
first move my my email
h to normalize this both and then I
computer responds at my casa vary from
the train the brain is that evaluating
this size is normalization of the signal
is computationally intensive for any
non-trivial transformation so if if if
you are talking about translation you
would not really move the pixels it
would move your operator for scan or so
you can do something so if you are if
you are talking about how wavelets for
instance you you don't need to don't
skate a picture as a bitmap lever you
can just change your operator on compute
it analytically like if you had done the
transformation but now if you are
talking about rotations if you are
talking about nonlinear deformations if
you are talking about multi parts and
you want to take many things into
account you can do this that way and
actually it's it's even were than that
because you often side does not exist so
if you consider our cad for instance if
you look at a lot of cat picture if you
have a cat at home you will realize that
so statistic of the both head is pretty
independent with a statistic of the body
so the cat is always basically looking
at you on the body can be well so it's
because it is this kind of thing um so
if I'm normalizing the signal with
rotation translation whatever I have no
way to to put some parameters ready to
the body to fold them into a certain
reference frame without changing the
head so it's basically what i would like
to to do i would like to not touch the
head so not damage my feature that I
specific specific to the head location
instead I would like to maybe normalize
about educational extract features basic
to the body in this reference but in
practice fragmentation so this
phenomenon that I talked about which is
to split my training set into some subs
on parts of law homogeneous pose is the
norm to deal with any problem which is
not translation or scale even for in the
plant rotation of four phase detection
they tend to the usual ways to split
your training set into 20 training set
corresponding
sub Angela our domain and then you train
as many data file so to summarize all
this with a nice-looking computer
diagram this can be this can formalize
the normalization of the signal so you
give me the balls are both set on the
signal I first normalize the signals and
then extract the feature I end up there
and then from this I'm going to compute
a pacifier what we propose which is
pretty simple is to directly index of
features so instead of trying to find an
intermediate representation you give me
the ball you give me the signal I
directly compute my feature vector so
it's not really so extraordinary but
just to be conscious that it's what you
usually do so if you don't face
detection with haar wavelets you never
compute our efforts on an image you
always compute our wavelets Odin image
for certain pose it's it's what is in
all the phase detector algorithms you
were actually if you get the code you
will end up looking for how wavelets in
a certain for certain laws of the target
so in practice what we call a family of
booze index features is a mapping from
the family of post-sales times the image
space into a to the power and with the
full with the following property which
is that whatever the initial post Sam
whatever the value you are looking at
operating for your future to have this
value given that there was a diet
interpose so if you evaluate your
features at four southern post-sale
given that those d'Agata disposal does
not depend with the posture which again
is obvious if you think about
translational scale if if you take 1
million images with faces that with in
each of them a phaser disposed and you
compute your feature vector there for
this pose obtained a certain
distribution although you take another
million of images with faces with facing
you really single of the matter no
suppose and you compute your features on
this on these new images for this post
to Instagram should be exactly the same
usually if you are going to guess where
was the target initially
it means that you proceeding on adding
value to what you'd like me to violent
so we call stationery features a mapping
from both sale time image 2 n such that
the distribution on the certain pools
even though it was a targeted that pose
does not depend we support okay so for
instance if my objects were a pair of
scissors the polls could be for instance
26 points so the tips of the Santa and
if I index the way where is the location
we are on the schedule i'm going to
extract my for instance a linear
response with Zeus with this ball so
that when it moves around i'm going to
scale rotate translate according to the
bull its abused that if i give you the
response of the filter which is adapted
the way I just said on those three
locations you have no way to bring back
to Posy's where they were evaluated
because I this is designed to pose index
features so that sounds okay another
example of windex features which is more
formal but may help to understand
exactly what we mean imagine that I
built synthetic when the signal which is
opposed so I Wendy singer would be of
dimension 32 my the hidden pose is just
to two numbers to integral to integers
which are so theta 1 theta 2 Stalin
strictly smaller than tattoo on the
signal is between theta 1 and theta 2 a
normal own independent normal law which
is centered and one on everywhere else
on talent 0 and admitting that now I say
that my paws index features is to give
mr. Putin the on the signal is going to
be this 40 vector which is the value of
the signal just before the ones value
the Seanad see that one's values nights
that we want wherever the signal just
after a seat at this thing if you
commute is obviously of this
distribution so the value the value of
the first so first dimension of this
post index features which are vector
would be the oceans on 07 negotiations
on 1000 oceans and 11 on questions on 10
this thing does not depend with the pool
anymore so it's it's pretty trivial
stuff we propose index features
you will value ate it for certain
persons at an image on if there was a
target it does not depend with a boot so
now if you give me such a positive
negative set of paws index features
family of windex features now I can
build the training set which is for
every scene on every booth everybody
cell i'm going to have a sample which is
the victor of air and she's a response
of the proceedings features at that
booth come out the actual boolean labor
which is where there i get there on ok
and from this we can learn a single
classifier on do the trick as for the
normalization of the signal now if you
tell me is there a daggit was posing
supposed 7k in image i am going to first
extract my pod complete my next
videos of that building that signal and
then compute my classifying ok so
vertically all this is super template
matching i just everything i say is just
a way to do this ATM machine rulings
same on double feature that can be
dedicated on the fly to an abstract pose
ok and we keep in mind that all this
artillery is just just to do open all
the doors to all sophisticated poses
than just scare in rotation on ok so now
we are places to get the addiction which
was the original material original
motivation so yeah i'm just going to
describe first base features what do I
convey features as Charlotte bows
indexed which are basic signal
processing and then I which well we
parameterize them with the balls to have
to some extent the property of
environment i was talking about so the
first thing we do is to extract at every
point eight different edge detector so
we use extremely crude edge detectors
with for instance we would say that
there is no reason that hedge at this
point so the big dot if the difference
between the two pixels which are
connected by the thick line is greater
than those or six others that make sense
if you have a gap here if you have a
jump here on that here not here not
reality honor yeah then you would
sailors own so we just use this gridiron
oh that every point we have no 8 billion
flags and we do this at three scales so
to gain this image this is the response
of the things i showed so you have
tourism teletech thought we were
together with priority like to write I
to that on two diagonal then you have a
console scale even go Sasuke we did
right by with some supper by fact oft
okay so now at every point i have 24
flags corresponding to edge detector on
from this we define what we call base
features so base features are not post
indexed yet they are just functional
image so the first kind is the
proportion of a satin edge so
orientation is can take eight values on
skates can take three values in satin
window switch we like you amuse
grayscale image by my future is
parametrized by a window on the certain
orientation schedule i'll go through my
window and count how many pixels abscess
snatch the second kind of feature a
parameterized by two windows on the
scale on its just add one known between
the orientation instagrams is estimating
on the two rectangles so basically the
first kind of feature are able to catch
any recos way controls on silhouettes if
you have a big board or big vertical
line even extremely noisy the system
would be able to put a rectangle on
count where enough vodka edge so second
can by looking at the difference between
the orientation instagram is able to
compare textures is the texture they are
similar to stick to you on the sub can
compare the variables railroads two
graphs between two windows ok so this
just look for is able to catch super
edges this is able to compare texture
with strong environmental nation this is
able to compare texture or color with
with advanced me to skate but not mini
me yes
we come to this actually this is maybe
the central question so but it's the
next slide so the timing is perfect so
now if how do I index the windows with
respect to the polls to have this my
curious Posey next feature family so
this is the actual pose of the scat this
is a run throughs and from this we
defined three reference poses a
reference frame sorry so one of the
frame is a head frame it's a square
centered on scaling with a head on head
location and scale the second one is the
body frame which is some talent a very
that which is in the 12 so at this point
on left side twice so 4 times ahead
sighs on the third frame is centered on
the middle point between the head point
let's enter on the B what is oriented
according to the salutation so bottom
line is if I have a booth or if I
propose that I take the average from the
poster on from this i define three your
front frame on now what we do we simply
to let the features to make the future
stationary we associate with we window a
flag that tells us in which frame is
defined so every one of the windows
based features can can decide during
training if it if it wants to be
relative to the headframe very very
frame ahead Barry frame so for instance
here we see the first actually the first
picked in the running pose index
features which is comparing the
grayscale histogram between two windows
on both windows up attached to the head
frame ok so when to get in moving around
it's still attack to attach to the head
room is really similar to what we do
know for face detection so go on another
kind of booze index futures with this
one which is comparing the texture
between this part on this button goes
are attached to the body so it makes
sense is just looking if so the old
actually ok so the frames are polarized
correctly so if so head is on the left's
of reference frames are
yes
okay if you want to the detail so it's
three like you really so you have your
reference frame which is centered on the
very location on the size of size like
eight times or head reduce or now you
define a window by seeing this
coordinate minus 1 to plus 1 minus 1 to
plus 1 which is where is the center of
the window when we define both the Wits
on the ides of the window with respect
to the size of the square so is the
square move translate if it's kate's so
its case according exactly yes exactly
exactly and then you have the third
example which is maybe shows real
interest observe this is in that case
you are comparing the system is
comparing a grayscale Instagram or
actually edges to remain you know we
estimated on a window which is attached
to the head body frame on the windows we
attached to the bed frame which is
really interesting because you see that
when you cut is moving around this is a
kind of semantic you could attach to
this question which is is the fur or
whatever which is nearby so head on the
body is the same as right on the body
which makes a lot of sense is exactly
what you would like to see emerging from
your system which is to touch us there
is a cat with its head here and it's
very here it make sense to look for
continuity in the texture okay so so so
if there is only one message to take
form of this is we just parametrize
usual features with the post so that
means when the post moves around the
support of the features where we measure
them goes moves around consistent so now
we have this yep
I'm sorry yes okay so sorry oh yes yes
yes yes yes yes but no okay but now we
are facing taking care issues which is
to do this efficiently you have to use
integral image to enjoy image you have
to have any rectangles so rotated
rectangle is not the rectangle anymore
so yeah we are well I it's it's not how
we've led to its integral image to
compute to compute histograms but so to
minimize the effect of not rotating exam
when they are in a reference frame that
can rotate we for them to be square
because this I don't I have no way to
compute this efficiently yes yes yes yes
yes but what we do actually and that may
be of importance that we also let the
running decide if the edge detectors
themselves have to be rotated so if
we're feature is attached to the
heavenly frame the system can decide
okay and I want the edge detector to
rotate so the quantification in eight
would go around with but we force it to
be if it can rotate if it should rotate
if we if compositionally we're going to
rotate it on we can't we force it to be
square because a rotating square is
caused us to a square and relative
rectangles just wrecked on you okay so
now we have so now we have this way we
have this bunch of features that we can
evaluate on the ball and we have this
trainings set which is since with bows
on labels on we train so what's
interesting is now so the classifier G
has no idea for this mass is just a
usual classifier that takes this vector
of responses from the by features just
predict a value so what we do is to do
we are pretty heavy here so we do
okay and we put all these in the
interview framework of course to find so
we have which first constraint the head
pose and then we can change the Bugaboos
I will come back to this later but
basically the classifier we use have
2,500 times so it's a usual thresholding
of features that we train with a
occasionally when you're either was
battered abused and we introduced two
things which may help which is that
instead of doing the Cascade staff
review regions which is it seems I think
pretty hard to tune because you have to
choose our many weak learners in every
lever what a low threshold it's pretty
complex we just substitute these two we
do usual booting so unless you're
familiar with the Cascade thing but the
idea is to do good stopping so you build
a first classifier and then you you are
going to build the next stage by just
taking the false positive that goes
through the floor slaver it's a way to
concentrate okay if I lon lon the
difficult popula- populations when you
image space you have your small positive
population I get a lot of negative
examples on a negative rotation on the
real tricky ones are the ones which are
close to your positive population in
practice if you're somewhere you'll
never catch them so you train your first
classifier then you take the fourth
petit is for us to go to signal etc etc
what is unpleasant in this scheme in
that it's basically doing what boosting
is supposed to do which is to focus on
the difficult example so in that case we
avoid a cascade by doing boosting on to
under it to be able to under 1,000,000
negative examples what we do is waiting
by something which is extremely
efficient computation and so everyone to
give the etl details everyone what steps
of boosting wearisome per 10,000
negative examples according to the
boosting wait so we keep the response of
the classifier up-to-date on one mil
negative examples but when we pick a
weak learner we based our choice and
10,000 negative examples which are
sampled along
medium well do a suit yes it's just
yes okay so exactly yes yes yes exactly
so we we address this or so yeah but you
agree cesare to as all I want to sound
like I'm a citizen or die and I think
also the growing radiant are in the gas
k we are just like but so for the
competition I'll part we we put a
special every 100 stamps but soon we
keep the response and I think also it
makes a bit more sense instead of aving
classifier that don't talk to each other
we just have it's like we have one
pasiva with 2500 stamps but now we
choose one threshold everyone writes
down so that overall ever error rate is
targeting all right on one we have the
cascade effect basically we stopped on
an easy rejected examples we stop
wearing also for the exponent i'm going
to show we have a two ton of 2300 scenes
containing when 1700 cats and we use 75
for central training so we do 10 round
of presentation to have kind of through
significant results and we use actually
50 person to choose a week one hour 25
to pixel social and then 25 degrees okay
we have a bunch of experiments that i am
going to detail here that just show
because we wanted to motivate really
onto to back up a bit our claims about
this program of doing full exploration
without the cost to find or two too
fragmented at down we can show from easy
that if you don't if you fragment your
data so if you build a bunch of
classifiers dedicated two subpopulations
it's it's terrible it does not work on
if you do it lively brute force without
cause a cost of flying instructor it's
also attractive ok so the message is
that stationary features about
fragmentation as much as possible so as
long as if you i were to design feature
so if if it makes sense to put the
samples together which means that there
is a way to get rid of the pose
observable to normalize future response
with respect to the pose it's the best
you can do
so it made it imitates a fragmentation
as much as possible on then so on point
so these deals with the fragmentation
and it's at one point for the year for
the conventional cost of exploration in
the yard gal search concentrates
competition right is needed on even even
more than gasket in that case because
you can really if you want it to have
accuracy for the bows or if you want to
lose this whisk last game and you have a
program because you at the end you will
end up in yard yeah things okay we call
the resulting approach for the dr key of
classifiers why because during training
it's like we are falling although if you
remember this city are key the scheme of
the Iraqi all the cells of a certain
level are bringing together on the new
train one can see feel for this on
during test if I want to pass a scene I
do the opposite now I'm going to kind of
virtually every one classifier I expand
my classifieds an entity Kelly 15
minutes now so to connect with a goes to
fine we use or simply to leave earlier
key with you have a first level that so
oppo space is five day with three
dimension for the head two dimensions
for the body on what we do in the first
level of the Yaquis of cells are tiny
cells for the head so we explore the
scales within tava with 15 towers
between 25 reduced when T Phi to reduce
204 every interval on the scale we split
the scene into we split the location
into small pieces so in the first of all
of the Yaqui post-sale is a small pose
for the head dying with a full space for
the body when you go to second level you
keep your head cell but now you split
your body to space into 500 so the head
level is composed of 500 550 thousand
cells and then for every one of those we
have 500 body cells so maybe to make it
here this of course it's done certain
this because we are 5 50 thousands
headset but you can see that when we
first explore all the head locations so
we explore all those five hundred fifty
thousand cells run a classifier for
every cell that reacts we go to the sub
sales so for every cell at reactant that
gate
we have three of them we go to the
subsets of this of this headset which
practically for the guise of the for the
case of the cats correspond to explain
Pacific Valley locations and for
everybody occasion we have a three I
shows a centroid of the sales for every
body location we run again a second
never classified ok so for the results
to estimate your rates we have to define
our criterion so if the true cell is the
black one so this is this guy we would
say that when estimated cell is an
estimated pose is correct if the
estimated head location is at less than
the head reduce from the true education
and if the estimated bloody location is
at less than twice the head radius from
the true body location so this will be
pointed at skype this will be counted as
incorrect and correct incorrect this
pretty demanding because often even a
journey you would think that a detection
is correct mercury system can't eat
right 1 12 so again you kind of a
baseline to at least see what r is
opposed index features bringing the
story because we have all this artery
with one with lot of weak learners and
boosting LT we propose a baseline which
is composed also of two lever so Steve
the cost to fine approach but instead of
letting the second level use bows index
features that can look at the head as i
can only look at the bodies which means
this is the dick toss for Maddie
corresponds to first running a hand
adicto than running a body detector on
every time there is a core current
between the heat we would say ok there
is a cat there on the so it goes it's h
plus B because we have had detect
operates a very detector and then we
have a reason HB which is our staff so
it's the same but now the second level
can really exploit the fool our
interests of having this giant pose
because I handle mine so if we compare
the two so the result can be can loop
weaker than what you can get for phase
detection with frontal forfeit our faith
deaf in addiction but first we are
looking for the body and this is
extremely difficult compared to just
looking for the head around also
is this not front our cat head he's not
even registered in rotation so you can
be Oregon's okay so if we catch seventy
percent of the cat we have basically at
for sale 15 for signups be seen unless
you will see also for almost also for
signups we get on the CAD body so it
seems that the system add finely
designed all the way to tell you and
pretty well get texture detector and it
can be fooled by cat texture but not by
Capet on the underlings so if we compare
the performance so this is of average
number of false alarms bar scene on a
log scale this is a true positive rate
with a proton described as you can see
basically the poison X which was divided
of force around by three at a at any
choice I would say I have some I think I
think so yeah so I also tried i don't
have the recipe i tried classification
so instead of trying to get the location
on the result where r something nice if
mr. positive eighty percent there would
be five for some false positives so i
can show actually so here our results
picked uniformly i have two existences i
did not share we picked the result so I
just run run round pick one run so that
the threshold is fixed for 70 Poisson
true positive and just picked a bunch of
images that from them so as you can see
the post okay there is of course a
post-processing of the alarms but the
possibility is not too aggressive which
means that even if there is a strong
response we don't discard also report
the other arms which are inconsistent
with because this it's bit of usually to
give a talk to invisible best way to go
but then it hurts you for the rug
because you it happens often that's a
good one is weaker than a bit anyway so
this I think is kind of correct there is
no force negative and I don't know if
this is counted as was pretty I don't
think so this is correct this is correct
present force positive because the big
alarm
which is not incorrect this is correct
though I look at will you allow this
correct correct correct correct well
maybe you know maybe this county doesn't
right I know because I think so sort of
the body was here correct right etc but
as you can see we don't put any
constraint on the head orientation head
or attention than what the right ones
can be on Team get me not front Adam
and as you can see when you have images
empty image is even difficult once
because I don't know if you have about
an face detection but this kind of
images or this kind of this kind of
images is really difficult for object
detectors because you have plenty of
veggies with extreme easy to a false
positive okay so our conclusion so what
I just showed can be seen as a super
template matching which is we we are
exploring exhaustively in some sense
both space and for every possible pose
we are asking the system is the target
there on super on with matching in the
sense that the way we organize it allows
us to do it quickly because of the cost
to find organizations of computation on
allows us to bring the machine learning
methods of choice we could do this with
a gem decision trees whatever because at
some point we have a feature vector and
we just have to make prediction from
this so it has benefits it's not late
matching black box machine running and
you can search however he's achieved of
the expense of annotating the training
some parts with rich one truth we are
not doing this totally automatic way so
now we are thinking about either using
some p.m. procedure but more
specifically I'm working the student who
is trying to do this from videos so we
would have a fixed background show an
object and try to guess automatically
both supo space on the annotations image
mothers who you have to design the booze
index features which is which may be an
engineering challenge but I tend to
believe that this is far easier than
designing really in violence there is a
really it's it's pretty difficult if I
tell you ok I would like you to measure
something on this image so that if the
image move around your response remains
the same honesty is in format it's not
like a constant stuff this is far more
difficult then I I want to design a
piece of algorithm so that if there is a
target at the booth I know the process
to target I just need to build something
where when I measures see on the target
like know where it is then the response
is consistent this is far easier to do
so this because this marginalization
that
this some of us and then state that you
must have when you build an environment
you don't have to take care at this
river it's taken care of at the level of
the video are key so this exploration of
the Hidden Valley ok so the reference is
we have a paper I gmail our paper are
going out soon to sell the camera ID
like one month on I'm not only had four
goals which should go there on
everything i showed the also code on the
all the data are believer this website
so the coding under GPL 30 ok it's
pretty heavy because each round takes
something makes two days on the health
and a powerful pc only 20 rounds plus
the ROC curve i showed but you just have
to run one script on you out google so
you are not afraid of finding computers
and you just run one script and
everything should run without a bitch so
please if you're interested only if the
response on your vacuum not interested
under ok i would like to thank the
people from red.mike eaten so this is a
website where people can submit get
images or right so there are people cat
cuteness and those guys gave us 120,000
get images so we have a plenty of data
to work ok thanks for your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>