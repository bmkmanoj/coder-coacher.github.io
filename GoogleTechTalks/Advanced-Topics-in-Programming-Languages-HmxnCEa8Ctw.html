<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advanced Topics in Programming Languages:... | Coder Coacher - Coaching Coders</title><meta content="Advanced Topics in Programming Languages:... - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Advanced Topics in Programming Languages:...</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HmxnCEa8Ctw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody we're gonna get started
at roughly on time this time instead of
postponing it because we have to there's
another talk in here at 2:00 my name is
Jeremy Manson and welcome to the latest
in our series of programming languages
talks I like to take a minute before
every talk to try to inspire people a
little bit to give a talk of their own
so if you've got something that you
think might make a good talk and I see
several people in this audience who I
know would be great speakers then please
come up to me either
after the talk or email me later and
tell me that you'd like to give a talk
and we can set something up all right so
I've actually always been tempted to to
give an introduction by saying this man
needs no introduction and then just walk
away
but and I think it would be appropriate
in this case but I'm going to give an
introduction anyway our speaker for
today is Rob Pike who among his other
accomplishments is responsible for
things like utf-8 and plan 9 for Bell
Labs and one of the first bitmap systems
for the UNIX operating system and he's
here today to talk about a programming
language that he developed while I guess
he was working at Bell Labs called new
squeak which has some interesting
mechanisms for concurrency and message
passing so without further ado here he
is thank you
of course I could say I need no
introduction and walk away too but I'm
going to talk about some work I did
almost 20 years ago now so a lot of this
is going to be unfamiliar to you and
unfamiliar to me because I've had to
page it all back in but there's some
interesting ideas in here and I think a
lot of them have been forgotten and I
think I really deserve to be thought
about and they all stand from this
notion that we live in a concurrent
world but we use sequential computers to
to write programs and there's a really
profound mismatch between those two
models and there's two obvious ways you
can deal with this mismatch one is to
somehow make the world look synchronous
and sequential which is pretty much the
way most things are done now or you can
try to make yourself where concurrent
and this talk is about number two
now I want to start by saying what this
is not about because I think it's a
common misunderstanding about
concurrency a lot of books including
some that are very highly regarded that
I won't name start by telling you that
concurrency is one of these awful things
that you just have to deal with there's
all these parallel devices and parallel
interactions and it's awful and
computers have multi processors it's
horrible hard hard hard so you've got to
learn it and think about it as a
solution to a nasty gnarly problem I
think that's a really unfortunate way to
think about it because concurrency has
nothing to do with parallelism there are
actually separable ideas and that's
important and moreover there are
concurrent programs that have no
intrinsic parallelism that are actually
much cleaner and more beautiful than the
sequential versions of the same thing
I'm going to show you a few of them
later this talk is not about how to make
compare log computers run faster this
talk is about how to make programmers
more effective by thinking about some
problems with concurrent models on the
other hand once you've got that in your
head if parallelism comes along you've
got a great tool first this all comes
from the notion of what a state of a
program is and and the way computers
work as you know you get a program
counter in a stack and the state of your
program ignoring the sort of memory
that's underneath it can be represented
by a stack and a PC and you see that
when you're going to do debugger and ask
what just happened you get a stack trace
back and you see on here and here's how
I got there and you can consider
concurrent program as just having lots
of those things together so the state is
just a linear agglomeration of a set of
PCs and stacks and the thing is that the
the composition of those pcs and stacks
can become exponentially more powerful
in what it can do but conceptually it's
a very simple almost sort of linear kind
of thing now clearly there's a huge
layer of I just laid down but
bear with me so how are we gonna make a
concurrent program with a set of PCs and
stacks and actually have to do something
with it so the model is to think about
software as a set of things interacting
independently executing processes and
Tony Hoare blesses Oxonian Hart wrote a
paper in 1978 called communicating
sequential processes which really set
the ground the ground for all of this
work and and all the stuff that we
talking about is derived from that but
takes it in quite a bit further
one of the things to point out is that
we're missing a lot of the words people
expect you to talk about when you're
talking about concurrency I'm not going
to use phrases like threads shared
memory locks semaphores all those kinds
of things I'm pretty much taking Andrew
Barrels model he popularized a model for
thinking about concurrency and I'm just
ignoring it not because it's not correct
and not powerful or not good but because
it's too low-level for the way I want to
think about programming I want to work
at a higher level and not have to
concern myself with these low-level
concepts so the Barrell model is great
for writing operating systems not so
great when you want to just write an
interesting program like some of the
ones I'm going to show you very briefly
there's a fairly rich history in this
stuff and this is just my sort of slice
of it I'm leaving out a lot of work in
things like concurrent ml and all
command stuff like that but in 1978 hoar
wrote this absolutely brilliant paper on
CSP which introduces the concept of
communicating sequential processes but
it missed out something important that
was discovered by a bunch of people
later including hoar himself which was
this notion of a channel which I'll talk
about quite a bit
Lukic our Delia 9 1985 wrote a paper
about a little very very silly toy
language called squeak which used
concurrency to express graphical
interactive interfaces much more
concisely and it wasn't a real system
you would really want to use it but it
pointed out a lot of the issues that
come up when you try to write software
for a concurrent world and it scratched
a niche I had and got me thinking about
some stuff so about 1988 I did this
language called new squeak which was a
real language you could actually write
programs in which was not true for
squeak it's a full in language you can
write real programs in it it's
interpreted it's not particularly fast
but it's fast enough for what I want to
do with it and it's kind of odd because
I I don't know there's ever been done
before but actually wrote a programming
language in order to write a single
program and the program on to write was
a window system I'll talk a little bit
about that later but I had users for
Newsweek I went off and did all kinds of
interesting things which I'm going to
talk quite a bit about later and it also
inspired a few other languages phil
Winterbottom in 1995 may be offended by
me saying this but i think what he did
was basically build a compiled new
squeak which we used as a systems
language at Bell Labs for a few years to
build a lot of interesting tools in fact
a lot for a few years all essentially
all the big systems we built at the labs
were written in this concurrent language
which was see like but had full
concurrency and message-passing and then
a year or two later
so Winterbottom Shawn Dora and I did a
language called limbo which is still a
product that's sold by company called
Vita Nova as part of an infernal project
and it's very much like new squeaks so
essentially if you understand new skete
programs you can understand limbo
programs but new squeak is jetted I mean
sorry new squeezed interpreted but limbo
which has a JIT and it's reasonably
efficient so your view of this talk I'm
going to talk a little bit about new
squeak but I'm not gonna really
concentrate on the language as such
because there's a lot of things like if
we don't need to talk about so missing
all kinds of features of the language I
just want to present enough of it that
you can understand the examples I'm
going to talk about what processes are
or at least how you think about them in
this week what channels are how you
write programs this way and then the
really interesting part is towards the
end where we start building interfaces
with these ideas and eventually maybe
build some system software on top of
that stuff so an overview of new squeak
how many people in this room have used
sawzall or at least we're modeling for
them okay if you've used sawzall
the syntax can be very familiar it's not
the same but it's very familiar that's
not a coincidence
but Newsweek is a much richer language
it has a much more interesting semantics
and of course this whole concurrency and
communication stuff is absent from
sawzall but it's the whole point of new
squeak so if - a very rough
approximation it looks like C with
Pascal declarations but it's not C like
because it's got functions as lambdas so
you can actually have expressions as
functions and do all kinds of
interesting things with them it's
obviously got process management
software built into it and these
channels think these channel things
which are when I was doing it seemed to
be the good idea and I still think
probably our our first class citizens
and there's control structures that I'll
talk about that let you do things with
channels in interesting ways and then
perhaps the single most radical thing in
new squeek although it doesn't come up
much in the talk but it's relevant is
this notion that every memory cell is
value semantics that is everything is a
value there are no references anywhere
in the language sawzall has the same
property people when they start using
sawzall they're still sort of don't
believe that that could be true but it
is true and it has implications for how
you think about concurrency and shared
memory and stuff like that which are
important but I'm gonna just sort of
gloss over because it's not that
interesting to the model I want to talk
about but it's important to the way the
language actually works
so here's some really stupid little
snippets of code just to give you a
flavor what it looks like not so these
do anything interesting but say when you
see more interesting examples you'll
understand them so here's a declaration
with a type and initialization value in
the variables that says declare hello it
has this type and it's got this value
when it's created and for these next two
slides I put the keywords in blues just
to make a little easier to figure out
what the syntax looks like so this odd
little thing here is actually a
declaration it says declare variable
called I whose type and value is this
expression so increasing an integer
variable and gives an initial value of
47 this weird-looking thing here is
think of muc as the new operator here's
the type of the thing and it's an array
of arrays it's got an initialize value
and again this is just a value with a
type that initializes and creates a
variable called B and MUC gets used in
creating things like channels which is
why I had to show it to you here and
then just to show you it's not all that
weird here's a here's a loop it looks
very much like a C loop in a lot of a
lot of ways there's a built-in print
statement which is not very interesting
but you know you need something for this
so this should be pretty easy to
understand whose Ackerman's function
just issued a function looks like it's
starting to look a little weirder now
there's a keyword rec which means
recursive which allows you to define a
block in which the variables can refer
to one another so if you're gonna define
a recursive function you have to put a
rec keyword on the declaration it's just
an accident of the grammar it's not very
interesting but lets you normalize some
of the definitions of recursive things
without forward declarations which is
kind of nice this keyword probe think of
that as lambda and become think of that
as being like returned that it has very
different properties which I'll talk
about it's important so anyway here's
how you write act if you change become
to return and probe the function you can
read it as a regular old Ackerman's
function definition and of course
calling it looks the same as always
so these function things they're called
lambdas but lambda has too many
characters in it so we made it Prague we
like short key words so here's a program
which is an integer that an integer
value function that's the return type
and it just returns the sum of a and B
its arguments so that's actually a value
in this language you can pass it around
of value and once you have one of these
values there are four things you can do
with it you can treat it like a value
just assign it you can call it because
it's a function you can replace yourself
with this execution which is something
I'll talk about and you can also
obviously very important in this model
start a process running it let's go
through those so here's our here's our
value buried in here now and I've turned
it into a an initialized declaration so
this is how you define a function called
some that has that that lambda as its
value okay and then here's another one
difference which is the same thing
notice that's become here we're going to
come back to that but this should be
fairly obvious what's going on and then
this is not interesting in any way but
you could say sum equals difference the
functions are just functions there it's
very very simple stuff
so you've got lambdas you can assign
them you can you can treat them just
like lambdas of course you can call a
function any way you'd normally would so
here's our sum function again and we can
initialize the value a to be the result
of calculating sum of 24 and 23 and this
is exactly the same result but done
without actually creating this as this
sum as a function we just use the lambda
and then the call is done by just
invoking parenthesized parameters right
after the Kalama this again should be
very familiar to any anybody's
programmed in any kind of land the world
so it the reason I'm going through this
is we're going to use these things a lot
and I want to make sure you're
comfortable with them so is everybody
comfortable with the whole simple lambda
thing here okay now this is the we're
getting a little weird here there's no
return keyword in new squeek because
although you can do a return operation
with this this become word become
keyword represents a somewhat richer
idea of what execution means so the
notion is that in it for anytime when
you're doing a calculation you can
replace the calculation of doing by
saying become with another expression
whose value is the same type as the type
you're already executing for so that's a
funny way of saying you can return that
value so here's a simple expression
here's the some guy with that becoming
it so it says when you evaluate this
expression probe you do it by becoming
the expression A plus B now that just
means return
except here's a slightly emergency
example here's a difference function
which is defined as to become of sum of
a and minus B and the point about this
become here is that it truly is a become
it replaces everything about the
calculation including the stack frame so
although it's a recursive function it
doesn't grow the stack it actually and
the implementation of Newspeak actually
work hard to make sure it kept the stack
as small as possible and the reason was
I was thinking about interacting
processes and mutual recursion and stuff
with things actually pinging back and
forth between evaluators of state
machines without having to grow the
stack and I'm not going to show you much
of that today but it gets used a lot in
one of the examples that I'm gonna talk
about but not show you the code for
there was a question in the back
keyword that rip replaces the
calculation you're on it's it's like
it's isomorphic to return in the way you
can't say plus return you can just say
return sum expression you can say become
it has to be an expression a full
expression and there's some stuff in
denotational semantics if you like that
that flavor you can identify what's
going on here but anyway it's you won't
lose any understanding if you just think
of it as a return statement but it
actually is a little more powerful in
the implementation sense if not in the
computational sense finally the last
thing you can do with the probe is
invoke it as a process and set it
running on its way and to do that just
to be perverse the begin keyword I
borrowed from Algol but it means
something completely different
what this means is not begin some block
but start invoke this Prague as a
function but started on its way and
don't wait for it to finish I don't care
how long it takes just let me go so
after X can this begin the next
statement whatever it is there isn't one
here would begin executing immediately
so it's it's like fork or spawn or clone
or any of those things but defined it as
a fully typed function invocation and if
the function returns a value the value
is discarded
so you can in fact say become some here
even though some is a type function that
is just thrown away at the end but it's
not very interesting so here's a
slightly more typical kind of thing
here's a probe that with that loops and
does some complicated calculation this
guy's just prints a bunch of numbers but
here we are invoking it dynamically so
we're just launching a process and
laying the whole thing out at once we
say begin we write the spec for the the
probe we're going to run and we give it
as parameters and off it goes and you
see that kind of pattern quite a bit but
of course there's something missing from
this model which is we don't know when
it finishes and to do that we need some
way of having the begun probe informing
us that it's done something useful and
or there's a value to be recovered or
whatever also there's no join it's just
not in the language the concept instead
is you communicate to find out what's
going on so let's talk about that so in
the original CSP that whore did there's
a book he did later that has this stuff
in the original CSP it did not have the
notion of a channel you communicate with
a process you actually wrote out a
process and you talk to it and one way
to think about it is that it's the
difference between doing i/o to a file
versus doing out of a file descriptor
the channel is much more of a file
descriptor than a file it's a it's a
handle and you can use to communicate a
channel which is introduced by the
keyword Chan in News Creek is an
unbuffered synchronous communication
port unbuffered means that if you write
to it and you or you you have to have a
place to put it if you if there isn't a
place if the channels got a value in it
you block it's synchronous in the sense
that when you're when you write to it
you can't return from the write until
someone has read the value out again so
not only does it communicate it also
synchronizes which is very important and
it's fully typed you can have any value
want inside a channel including a pro go
to an int even another channel which
gets used more than you think it's half
duplex which is an interesting wrinkle
although it's fully typed there's no ND
endedness to it so once you have a
channel you can read or read or write or
send a receive on either guy it's
arguably a criticism it might it might
be better to make the channels have a
defined direction but they don't again
that's sort of CSP and there's these
operator they're actually one operator
which is the same operator depending how
you use it is a Santa Ana receive that
looks like this so here we are declaring
a channel so this is an uninitialized
channel and then
we can assign it by doing this muck
thing which is like new to create a new
one you could of course also say sea
call an equals monkey an event which is
the more typical usage and there's this
operator which is the left facing arrow
which is the communication operator and
the way you use it is if you put it to
the right of the channel
it's a send if you put to the left of
the channel it's a receive now there's a
mnemonic that makes it easy to think
about it if the arrow points into the
variable then you're sending if the
arrow points out a variable you're
receiving it's pretty simple and it
reduced the number of funny tokens I had
introduced so in order to make things
sort of regular I made send actually
have looked like an assignment so that
this is the like and you're assigning 23
to the channel and 2 and this this is
perfectly fine notation in practice
people tend to write it like this so
that the operator this says this is
really two operators in the language but
they glom in to one
it looks like an assignment send
assignment and the point about this
thing is that you can have this way of
communicating really simply with a
channel and the semantics there are just
taken straight out of CSV which means
when you're going to send on a channel
there has to be a receiver before the
send will complete when you're receiving
from a channel there has to be a value
available in the in the channel and that
means there as to be send are waiting
for you because it's synchronous that
the sender won't have left the value
behind you'll be sitting there too so
when the instant the communication
happens you're both at that same point
in the program wherever those two pieces
of the program line up and when they're
both there and ready the value is
transferred and then both the sender and
the receiver go on their way now it is
always synchronous and always unbuffered
it's easy to build buffered channels
using mechanisms in the language but the
fundamental primitive is a unbuffered
channel similarly it's synchronous you
can simulate a synchrony in practice you
rarely need it but a lot of people think
the thing is important so let me spend a
couple of slides talking about a
synchrony in this world it's pretty easy
to simulate any synchronous send all you
have to do is launch a process to do the
send for you and it'll just complete
when the value can actually be
transmitted and so you just launch it on
its way so to do that you could write
this let's say that you have a channel
that you want to send on called CH and a
value V you can just write the probe
that says accept the channel and an
integer and send it and then begin that
in the background so that will do the
asynchronous end for you because I'll do
the sand in that guy will hang around
until the sins actually done but that's
kind of clumsy so we can do something
which is a very common sort of pattern
in new squeek programs to wrap it up a
little bit what we do is we take this
this launching of the program and we
bury it inside a function and then the
function itself actually does the send
so you call a function with sand on my
channel 23 I guess that should be a CH
but anyway asynchronous sand this is
this function the channel and the value
and what the function does is it does it
buries the begin of the process within
so you think of it as a channel but
you've now essentially this is
isomorphic to it that asynchronous send
but done as a function call and so this
notion of launching processes inside one
line lambdas is very very common and and
you'll see a few more of them now
asynchronous receive is as you can guess
quite a bit trickier because you have to
know when to receive there's there's
some signalling involved and involves
multiple channels and thinking about it
so I leave it as an exercise for the
reader but it's not very hard the key
point though is that the channel that
you're using to do the communicate the
return value back is also a way to
signal that the value is ready and that
gives you a sort of handle on how to
build these things and you can use the
same kind of observations to build locks
and semaphores
and all those lower level primitives if
you want them that way there's nothing
wrong with doing that but that's we're
trying to avoid that in general the key
point is this one when you wanted what's
discover when a process is done that is
in effect the join you create the
process with a channel that you will
then read when you want to know that the
job is done and so you use channels as
first-class values all the time to
communicate states of things that are
happening so a few points of our
channels because they really are
important they're used for communication
obviously from the point of view of the
language and the way it's used as
opposed to what is implemented they
should be used for all communication you
don't have to use channels for
communication you could use memory and
whatever Eldar mechanisms you want but
that's not the way the idea the idea is
you don't use shared memory instead you
use channels to pass things around and
clean arbitrarily large things and you
know the language tries to make that
efficient so you don't
signal to say this data is ready you
just send the data and it's highs the
signaling the day together which is
actually an important idea that
clarifies a lot of stuff there are a lot
like capabilities or if you if you
Preserve prefer your UNIX thinking
they're a lot like file descriptors if I
give you a channel you have the ability
to use it to communicate if you don't
have the channel you can't
and so I fight I can use it as a way to
handoff communication I can also use it
away to handoff sort of security aspects
if I trust this channel to be used right
I can give it to you and you can go with
it
it has other interesting aspects like
that that are not there in the original
CSP which didn't have channels that only
had processes and of course they're
first-class values you see a surprising
amount of this kind of thing where you
have past channels around if you've got
a capability the first thing you want to
do with the capabilities give it to
somebody what better way to give it to
them than to send it over a channel so
you get these second order capabilities
which are kind of fun to play with I'm
not gonna use this stuff much but I want
to just mention it because it's
important to the way some of the
programs get written inside new squeek
there's an operator control structure
called select which replaces switch just
in the way that become replaces return
it's you can use a select statement as a
regular old switch statement but it's
more interesting when you have this kind
of structure what what it does is
instead of having these just be values
and these are actual potential
communications that could happen so you
reach some point in the program where
you're waiting for a bunch of stuff to
happen the way you ask you know what
should I do next is you write a select
statement that has a case for each of
the possible communications that might
proceed and just to be perverse here
you'll notice there's actually some
duplicate cases that's perfectly okay
what happens is you hit the Select
statement and your program your process
will block until one or more of the
communications in the Select statement
is able to proceed if if one is
available to proceed then that will
execute and the program will do whatever
that case statement says and off you go
now notice that it has to be
communication written in here and also
unlike a sort of C style case statement
there's an assign in here because
chances are if there's a receive you
want know what the value was and so you
can grab it and print it out if you or
whatever else you want to do with it you
can also send a value here and that also
blocks if there are multiple guys ready
to go when the Select statement begins
execution
the system chooses one at random so
another way to think about this for your
language mavens is that this is very
similar the Dijkstra's guarded commands
right but now with communication as the
primitive and again this comes out of
CSP but it's fairly important yes no it
is a strong random a random selection
there's actually a little there's a lot
of randomness in the implementation of
this system which is in the
implementation paper which you can look
up and it is there's totally
non-deterministic it's designed to be a
non-deterministic select you in other
words you can't depend on the system
properties to do something favor one
case over another okay there's a richer
version of select this is the same
statement but now these expressions are
no more complicated there's a thing
which I I don't know if I invent it or
not but anyway I hadn't seen it before
which is what I call an array select and
in these case the the cases actually
have an array value see I declared an
array of channels up here and then in
the Select statement there's actually
array expressions buried inside here and
these are all the same really but
they're four versions cuz you can
extract elements out this says any
element in the array can communicate
this says any m of any element of the
array can communicate but tell me what
their value I receive was this says any
element can communicate but I need to
know which one did it and this one is
any value needs to make it but I know
which one did it and tell me what the
value was so this thing inside the
brackets here this funny stubbed
assignment actually reports which index
of the array transferred so this
obviously is there for writing muxes and
of course a MUX is a one-line select
call I mean you wouldn't write a thing
like this you typically have one line
just like that that does the muxing for
you and so you can have n way muxing and
it's very very simple and you'll see in
a minute why that comes up so I think I
pretty much covers the language
so let's actually look at a program in
the language because what's the point of
having four lines you can't write a
program this is a trivial program but it
it's actually representative of the
kinds of things you see do going on so
here we have a probe called counter that
receives a channel as a parameter and
then in a for loop just prints out
sequential integers to that channel
so prints out the wrong word it sends
sequential images to the channel so to
invoke it we have to create a channel to
use for the communication and then we
begin that probe with that channel as a
parameter so when that happens the first
thing that program is going to do is hit
this send operator and block because
nobody's waiting for an answer and so we
we actually we actually execute you can
this is actually type script you can
type this into the system and it'll just
run you can type receive from C and the
system will print out - and the blue
means that that's text that the system
is printed out from we're in the program
you do it again you get three and so on
and so on and so on so I've created this
thing called C which will just give me
the integers starting from two now the
reason I picked two is that two is a
really good place to start when you're
doing this next program which is I think
one of those beautiful programs I've
ever seen in any language which is the
prime sieve written in Newsweek I didn't
know this program when I wrote Knuth
Greek but the guy crossed the hall did
and turns out Doug McIlroy is credited
with being the first person to write
this but Tom Cargill actually showed it
to me so the program actually ends here
this is actually running it and it
borrows counter from the previous slide
so the notion is to follow you want to
write a prime sieve which means we want
to find all the primes that come out of
this calculation so we have this stream
of all the integers going by and what we
want to do is filter out successively
all of the numbers that are divisible by
a given prime right that's the
definition of prime zip the way we do it
is we create a process for each prime
that filters out things that are none
that are 0 modulo that prime and that
process is called filter
so here's filter which is a probe that
takes a channel on which it receives the
integers a channel on which it sends the
integers and the prime it's going to be
filtering up and what it does is it just
sits in an infinite loop receives from
the receive channel of value if it's
nonzero mod the prime that is its it's
not divisible by that prime then we send
it on so it just filters copies
everything from receive to send but
throws on the floor everything that
divides by the prime ok now that gets
you get gets rid of one filter from the
stream the trick is how do we stitch
them all together and I have a diagram
let me go through the code now stare at
the diagram and shrill figure it out so
this is our actual sieve
and it starts again it's the same
concept you passing a channel this is
the channel that's going to deliver the
primes to us and by construction we have
created the channel so to is the first
one that comes along and so the first
number is always a prime and so that is
the invariant that we're going to run in
the loop we start we start the counter
and that means that the first one we
know is prime by construction that's two
so let me go into a loop receiving the
value from the channel by construction
the beginning of time two is the first
one save it in P so we have it in our
hand and send it on to the prime channel
which is the output of this whole
program so that delivers the first prime
to the caller of us then we make a new
channel because we're gonna be stitching
a bunch of filters together so we make a
new channel and start a filter process
that copies from the channel we're
currently holding onto into the new
channel it's filtering out by the prime
P and then overwrite C the channel so
we're holding onto the output of it so
to look at it looks like this so this is
the channel coming in from the counter
and it's to think of this as being
delivering all the integers down this
way so it delivers two three four five
six seven eight and so on we pick off
the first one and say oh that's a prime
we print it out and then we launch a
filter for two and he's gonna copy all
these values but he's gonna filter them
out so that only those that are nonzero
mod to go through the first one that
pops out there is three we launch a
filter for three he pops out of five we
launch a filter for five and so on and
so on and so on and so this channel
threading is essentially coming from the
right hand side filtering new pieces on
taking this out the output here and make
it the input to this guy starting a new
guy stitching them on like like pearls
on a string hello so here's that
sequence receive a prime remember it
delivered to our caller make a new
channel that we're gonna use as our new
receiver start a filter copying the old
receiver to this one and remember the
new receiver so that's the whole program
plus the counter which is the one line
thing from the previous base and you run
it like this you make a new channel
which is our prime Channel begin the
sieve this is a very common pattern you
you make a channel create a process with
that channel as its argument
run read the data so as you go and then
when you whenever you want the next
prime you just invoke this expression
and prints it out now this looks very
expensive if you think about all these
processes and complexity and so on but
I'd like to make two points about that
number one computationally from the cook
from the complexity model this is no
more complicated than the regular
algorithm it's exactly the same idea you
just have to do all the divisions this
does all the divisions that's all there
is to it
and moreover it's very hard to write a
prime sieve that's any shorter than this
there are languages that are
intrinsically more concise like you
probably a nice one in Haskell that's
but it would but the idea is that if you
try to write this this filter program
all the bookkeeping and the management
of data and all that state is quite
difficult here it's all sort of hidden
in the fact that you just start a
process for every prime so it's a
strange little program but it's actually
quite pretty and there's a lot of
different ways you can adjust it to to
do it different ways but this is
probably the most concise way I have to
write it so people understand this
example all right try this one
I wrote this system to do the right
window systems in and my office the
office next door was occupied by Doug
McIlroy who's there's people in the room
here and know him well the test is even
fiendishly clever and he realized that
you could use this system to manipulate
power series so a power series is just
an expression like this it's the
sequence of coefficients representing
you know successive powers of a variable
and common example is Taylor series so
here's the Taylor series for the
exponential function so you see it's
it's just algebraically X to the N over
N factorial but you can also think of
that just 1 plus 1 X plus 1/2 x squared
plus 1/6 X cubed and so on and Don said
let's represent since we know that the
X's are always there let's just ignore
them and think about the coefficients so
we're gonna represent the coefficients
of this power series which is 1 1 1/2 a
sixth and so on as a channel and the
idea is just like we use integers
sequentially in the prime example these
are just coefficients identified by the
sequence in which they arrive on that
channel when you go in problem so here's
our definition of power series but we
sort of weirdly invert it now the way
doug dated to make it pretty was he
defined a
I'll type so these would be really
rigorous mathematical power series
that's not very important it just means
the mathematics has to be a little
functional rather than operational but
it's still pretty easy to define so this
type power series here is a channel of
international numbers which have a
numerator and a denominator and then
there's a paper which I'll cite in
another slider to which you can read all
about this and I really recommend
reading the paper it's amazing but for
the point of this talk assume we have
ways of doing arithmetic on rationals
like maybe functions called rad add rad
mole-rat did that kind of thing so if
you if you have two power series F and G
and you want to sum them to make a new
power series ask you could do it like
this you make a probe that takes a F and
G that it's going to sum s which is the
return value and you just loop doing rat
at sending/receiving pardon me F and G's
values which are the leading terms of
their series and sending them on to the
sum so that sums to power series by
taking the two streams and merge them
into one sending them out it's almost
like a geometric operation it's very
simple to do right but it's kind of
clunky to have to functionalize it all
like that so the next step we do which
is really where things start to get
interesting is instead of having a
function that takes the sum channel as
an argument we actually created as a
return value and so again it's this
thing where you put the probe inside the
process inside the probe and invoke it
so we make a new channel which is the
summer we're going to send the values on
and then we launch a begin procure that
does that loop notice the invocation
there and then the return value for this
function is the stream that we created
that is the addition of those two power
series and this pattern is very again
very common I keep pounding on it so
there you go there's a way that you can
take two power series and turn them into
another one by just calling psi of F and
G and now you got a new Parris's in your
hand you can sum them now something is
trivial but in the paper you'll see you
want to do derivatives well you drop the
zeroth term and then send forever rat
model of the next value times I which is
the index in the in the sequence you
want to integrate a power series you
emit a constant for the leading constant
integration and then send forever
divided the next value by
the index so there's integrated and that
that's I mean you've obviously need a
little boilerplate for that but that
really is integrate and differentiate
our series and the paper
Doug works out how to multiply divide
very splitting operators it's really
kind of amazing and when he's done he's
able to do things like this this is kind
of a don't worry about all the details
here it's kind of a lot of explanation I
want to go into but that expression from
his little library will calculate the
power series for the tangent function
which is notoriously difficult to
express in computer code and he got it
down to a expert hell of an expression
but an expression nonetheless it's very
concise and the implementation of all of
this is actually only a few hundred
lines of code that's the entire
implementation of this thing in this
language and it's all made possible in
concise by the stream notation that
makes it easy to manipulate these
variables as power series as actual
values I highly recommend reading this
paper I'll have a slide at the end with
all the papers on it it's one of the
most amazing papers I've ever read so
once you saw in that last example and to
a lesser extent in the prime example was
this notion that you have a channel that
represents some sort of contract this
contract is a sequence of primes or or
the you know addition of two power
series and it's important to think about
that contract idea because that
maintains its really an interface I mean
the entire interface to a power series
in Doug's program is this channel it's
trivial but it's also seemingly powerful
you can express quite interesting
programs with it but of course this is a
real programming language let's build
data structures out of this stuff right
so what you can do is take a set of
channels together that represent a more
complicated interaction with a more
complicated process and that can become
a much richer kind of interface which i
think is isomorphic but interestingly
different from say an object-oriented
interface to a class so here you see
this sort of sketchy version of it you
have some type called interface which is
just a structure with a couple of
channels in it I'm not saying what those
channels do or what they mean but here
I've now got this interface which is a
set of channels that have some property
that individually implement their
contracts but because their channels too
independently executing things may
actually execute independently and have
other interesting properties and I'll
show you some examples that make this a
lot clearer
and then to use such an interface you
you you make a type that holds these
channels in it and then you start that
program which has some use of that
variable in it and invoke it with that
interface as a variable so you the
instance of the interface is actually
just the represent of the channel and
somewhat independently there's a probe
that uses that interface and operates on
the channels that it embeds and it's
probably very confusing so let's look at
an example this was the motivating
example for a new squeak in the first
place actually it's almost a motivating
example for squeak in the first place
but new speaker is the one where you
could really write the program I wanted
to write so there's a paper again I'll
cite the paper later that goes into a
lot more detail about this I'm glossing
over a tremendous amount of not only how
it works but also why it works really
well because I don't have a lot of time
but here's our here's our idea when
you're looking at a program running in a
Windows system or graphical environment
it's it's some you know some box here
and it's got things it needs to talk to
in the outside world in order to run and
I've represented very schematically as
the mouse the keyboard and the graphics
model right and so we represent those as
channels and exactly what these mean
don't worry about for now it's it's you
know we don't have time to go into it
but the idea is there so you have this
type which we call the environment for
that for the client of the window system
and it consists of at least a channel
for doing graphics on a channel for
getting most activity on and a channel
for reading keyboard characters on and
that's pretty much all you need to know
if if you believe that this represents
the environment and modulo a few missing
details it is enough then a client of
this system is just a program that
operates on that environment and
implements the protocol that that
interface requires so you can actually
define a type and then invoke things of
that type with this model and you have a
graphics program
well that's itself not very far but you
can get pretty far by thinking about
what you do then when you have a Window
System all you have to do if that model
works to build a Windows system is MUX
it and so given this okay so here's our
here's our shell window that's inside
this box doing god-knows-what we don't
care
all we know is that there's these three
channels we used to interact with it and
then use it to interact with us and I
arrows point different ways to stress
the point that it can be a
bi-directional kind of thing okay and
here's another client which is an editor
and then and there's another one down
here and from this guy's point of view
he's just using this interface and he's
getting something that honors the
protocol of graphics keyboard and mouse
and it just works and he runs and all
his sweetness and light okay and this
guy's got his own little world and all
he sees is keyboard graphics and mouse
and everything's wonderful and then the
window system itself what it does of
course is what's its world well its
world views is running on a computer
it's got a keyboard of graphics and
mouse operations looks exactly like an
end guess what it is the same exact
interface and so if you ignore what's to
the right here this isn't one of those
client things but it implements a MUX to
other ones depending on for instance
where the mouse is on the screen it
might direct events here or here or here
and the key point of this is that this
interface is exactly this interface that
it's muxing which allows this to work
you can actually run the Windows system
as a client of itself and it's not that
magic happens in order to make that
happen it's that the model makes it hard
to make this not just work it just falls
right out of the design and it's kind of
a powerful concept and very different
from the way that event oriented
programming would think about doing this
right you this interface model with
concurrent programming makes this thing
actually not only easy to write but the
whole concept very simple to understand
and also very powerful there's all kinds
of wonderful things you can do with it
running the Windows system as a window
is one you can do things like let's say
that someone's left-handed you want to
flip the mouse buttons over you can just
interpose a little process right there
that inverts the mouse buttons and
neither side even knows about it it's
all transparent because the interface
handles it the whole program here this
thing is less than 300 lines of new
squeak and in fact the part that really
matters the non boilerplate part is a 60
line array select statement with some
interesting operations in it it's very
very simple code and it took me an
evening to write you know it took me six
months to write the language then and
even to write the program I wrote in it
which is not usually the order of doing
these things
and this paper which is almost 20 years
old now talks about this in a lot more
detail and if you're interested I think
it explains a lot of why it works well
and also explains many of the
interesting examples that you can do
with this system that aren't so obvious
one of the things I wanted to do and
explored but as associate me I moved on
to other things was the idea that you
could take this Window System and stick
it here so that for instance a multi
window text editor could use the window
system code as its own window manager
internally and that also falls out very
naturally from the model now this went
on it worked so well that we I just said
you know this is great let's just do it
and so having learned what we learned we
went when plan 9 started which was
roughly the same time the window systems
for that operating system were built in
exactly the same way but not in new
squeek it because better rather than a
systems language for a lot of obvious
reasons and in fact there are three
window systems now they've been written
this way that ran on plan nine eight and
a half REO and Acme and it just works
great and REO which is still a living
program still works is I think three or
four thousand lines of code but it's and
that includes the terminal emulator but
it's a full must interacting thing that
by the way also implements a file system
because that's the way plan nine is but
I don't believe it would have been
possible to write that program if I
hadn't gone through the whole new squeak
thinking about concurrency model program
was just a lot easier to write because
of that there's a couple of papers that
talked about this this eight and a half
one talks about the window system that
was first written for plan nine that
looks like this slightly the second one
Acme is a little bit richer system it's
still a window system but it does a lot
of other things but it's interesting
because it has I think a particularly
clear section in it about how the system
model applies to building this kind of
window system and in fact in the end
essentially all the major planning
services user level services ended up
being written with this kind of approach
which I'm now going to talk about in
more detail so what is the system model
here I mean I said we're gonna build
systems this way what does that mean
well first of all what you want to do is
define your components as interfaces
that cap
capture the communication that your to a
thing that's going to do the whatever it
is is going to do it's going to interact
with a client's gonna interact with a
back-end server whatever is going to do
and all of the data flow and
communication that's needed to manage
that thing is done with communication
over channels now it doesn't need to be
shared memory it doesn't have to not be
shared memory but the notion is there's
an interface with communication and
channels that exchange stuff the
interface itself is a type that has in
it all of the elements of that of that
communication stuff and you can
implement various versions of the
interface just by writing anything that
operates on that type because the type
is just a channel it's not an interface
in the object-oriented sense it's just a
set of channels and you anything that
honors the protocol for those channels
will implement that interface so it's
very easy to do so in the Windows system
example the shell the editor of the
window system itself those are all
implementations of that interface and
then the what where it starts to really
matter is that the composition of things
when you start building systems that
connect together lots of components like
this the composition of their execution
tends to be linear in the complexity of
the design adding another thing just
incrementally increases the complexity
but you get this super linear express
ability you can start to do much more
complicated interactions like I
mentioned with Windows System the editor
and the Windows system are all
interacting in interesting ways and it's
worth thinking a bit about how that
compares to state machines which is
almost exactly the opposite in state
machines you have exponentially
difficult complexity trying to write the
composition but when you're done you get
this really piddly inexpressive result
and this this model I think is a real
counterpoint to the way people think
about state machine and building things
or state machines because the and also
when you actually do this the
interleaving of execution falls out for
free which is a really powerful idea
when you're starting to think about
systems and large-scale performance and
you know hundreds of clients talking to
you and that kind of thing you don't
have to worry about a bookkeeping it's
all taken care of by the model so as a
sort of bullet item to think about think
of it this is composing interfaces
themselves not the state machines I'd
like to stress that the point of all
this is not that it's parallel I don't
really for the point of view this side
of things don't care that it's parallel
but it's nice that the parallelism falls
out if you build systems like this they
will run in parallel well you won't have
shoes with locking and things that tend
to be devil stuff that works at a lower
level the same is almost true for things
like networking your remote execution it
doesn't follow up quite so neatly but
it's easy to imagine if you have a an
interface that defined as a channel how
to turn that into some that works across
a network it's not you have to think
about a little bit but it's a lot easier
than think about how you do shared
memory across the network for instance
so let me give you leave you with this
kind of thing I printings talk to you in
the last few days I realized that I
should probably resurrect new squeek and
try to out a web server in it because I
think it's pretty nice idea for how to
do this and it's very similar diagram to
the window system diagram right here
you've got these client stubs which are
this is your program this is the wind
web server and he's got a little stub
process that's interacting you know
dealing with the HTTP stuff come from
the browser and doing various I go to
the web server which is muxing all these
clients together these things are really
cheap so we can have hundreds of
thousands of hundreds or thousands of
them lots of browsers are all
interacting independently it's all taken
care of but on the flip side somewhat
the window system touches us a little
bit in things I didn't go into but you
can imagine the backends for the web
server
you know implementing various services
that the web server is providing the
same kind of model would work over this
side too and so this whole thing can
become a composition of interfaces and
when I think about doing that versus
doing state machines there's some very
interesting possibilities for how it
work and in fact there was a plan nine
web server that you could probably draw
this diagram for but I didn't write it
but I'm sure if you squint it a bit this
is what you would see
so in conclusion I'm surprised ntid's
model which has been around for a long
time but I think has been forgotten by a
lot of people I still miss it and
thinking about maybe doing resurrecting
some of its ideas again the thing is
that when you have message passing and
concurrent processes you have this very
powerful mount model for thinking about
programming that doesn't really have
anything to do with parallelism per se
there's nothing parallel in the power
series example and you get the express
ability of the model for writing that
program is really powerful sometimes
though the problem you're working on is
intrinsically parallel like you're
building a server and then it's obvious
that you get benefits but there's
benefits even when it's not you need
both concurrency and communication this
is sort of my criticism of the low-level
semaphore a lot kind of thinking where
you you think a lot about the the
locking and control but you don't buy
that any kind of data model and you
really want to have a higher level thing
that unifies communication as a
synchronization plus a data transfer
because then you can really think about
data flow as a way of internally doing
things and and the fact that the
notation is fairly concise is important
you can obviously do this as the
functional notation or just function
call notation with send and receive and
stuff in fact that's how we did it in
plan 9 in the C programs but you want to
have the thinking in your head to make
it very easy to write these things down
so you understand it and if you get your
head around the stuff you find it really
clarifies how you think about interfaces
and sharing and communication and
composing systems and it's a very
powerful model that's quite different
from the way most systems get built now
it is so I'll just leave this slide up
to finish these papers are all online
there's the original squeak paper which
is weird you probably don't wanna read
that one this is the new squeak document
which is quite short and easy to
understand this is Doug's amazing paper
on power series this is sort of the
window system paper which is actually
written before the plan 9 window system
is just about the new squeak window
system and how I got there and how it
works and there's some a lot more talk
in there about what it really means
the Acme paper has probably not into
most of you except this this one page in
there about how the system model is used
to MUX together this composition of
services actually very much like that
diagram is kind of interesting and
actually I resurrected the binary so in
my bin directory on the net app there's
a squeak interpreter called squint the
code is from 1988 a lot of the libraries
for graphics and some one just aren't
there because I couldn't resurrect them
but all the examples I've shown you say
have been tested inside this thing and
the power series example and others are
available under this directory to play
with if you're interested so you have a
few minutes left for questions I guess
that
there were recently around weekend
I think it's a very s I understand I I
think it's a really good idea to think
about implementing this kind of
communication channel model on top of
mutexes in C++ and I'm certainly
thinking about why that isn't there and
maybe trying to fix it a lot I'm
thinking about it a lot John what's the
robin cost of a channel versus a
callback and I think if you were doing
reasonable implementation of channels
they'd be modestly more expensive but
not punitive ly so the payback in terms
of the complexity of the program itself
and the bookkeeping it needs to do in
order manages callbacks might more than
offset the extra complexity of the
channel itself if you just use your
channel for signaling it's very cheap
it's equipment its just a lock and a
data transfer which will typically just
you know an integer or something or a
pointer and so it can be very very cheap
it depends on a lot on what the
callbacks doing and how you compare
specifically but intrinsically I don't
think it's it's it's significantly more
expensive and the simplification how you
use it may mean that your whole overall
program becomes actually more efficient
but obviously that depends very much on
the details Jeremy
the question is basically what's the
implementation overhead for all this
communication stuff and the in this
particular squeak itself where I wasn't
really too worried about parallelism it
was all in one process it was fairly
simple implantation there is an
implementation paper which I didn't list
here but you can find it that talks
about what the algorithm is for LF which
was truly parallel and worked on a
shared memory machine phil spent a lot
of time tuning the algorithms to give
the same semantics but with efficient
communication and there's a lot of
optimization you can make when you're in
a language like this to recognize simple
cases and the trick for making this work
well is often to have the compiler
generate different code for different
forms of select where you can actually
generate more compact less locky setups
for some of them in the most general
case it can be quite expensive obviously
but you work hard to make sure that you
don't have to pull the channels and
things like that and construct data
structures that will suitably manage the
arrival of data so that things stay
expensive in the amount of communication
going on rather than the number of
channels involved in the operation which
can be quite a bit well almost always be
very much smaller yes there's a lot of
there's a lot of stuff about how to do
that and obviously we've thought about
that a lot
yes there are there are CSP like
libraries for a lot of languages there's
something about having a notation there
and the Select operator is hard to do as
a library and things like that yes
mm-hmm
how do i D bug my programs I knew that
was going to come up that's why I put a
slide after my finally everyone obsesses
about debugging concurrent programs like
it's some sort of plague and you know
what deadlocks just a bug you fix it
right and moreover when your program
does deadlock you run the debugger you
look at the stack traces of all the
processes you can see what's going on
it's just like any other bug how did I
get here what happened what do I fix it
but there's actually that's pretty glib
but I think it there's a lot of truth to
it but there's more to it which is
really important in a port understand
about deadlock one is unlike almost any
other kind of bug I can think of
there are amazingly good tools for
preemptively discovering deadlock in
your program there's things like foreign
called trace there's a drawer Holtzman
program whose name you lose me for a
moment there's others where you can writ
you can represent the program model to
this tool and the tool will tell you're
going to deadlock if you do this so you
can actually automatically find programs
bugs in your program in fact Gerard's
stuff more recently he extended so that
he could actually look at our C programs
that use this model the kernel source in
some cases and identify deadlocks or
more importantly lack thereof in certain
of our more difficult algorithms so
having automatic tools to solve it is an
interesting thing and the final thing
which is experimental I never actually
did it but I thought about it quite a
bit is when you have an interface it's
so clean you defined like this and
you're doing something like the Window
System where you going to plug in a new
client you might not trust a client if
you're going to get a dead log it's
probably because that client is
misbehaving but you could imagine
because the interface is so well defined
sliding a little shim interface in here
that guarantees that this side is
deadlock free even if this one screws up
and not only report when there's a
deadlock and isolate the rest of the
system from the problem but kill this
thing off if it's different and I think
I've never done it it's it's
hypothetical but I think between the
point of having the ability to identify
them before they happen and the ability
to perhaps even solve them dynamically
there's a really interesting power of
things that's often forgotten but
fundamentally they're just bugs
you look at the stack trace you see how
you got there and you fix it I think
we're almost out of time here by the way
how are you synchrony doesn't avoid
deadlock no no you think asynchronous
means you don't wait it doesn't mean you
don't have bugs so I think if there's a
two o'clock talk we probably need to
stop now
right well I'll put this back</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>