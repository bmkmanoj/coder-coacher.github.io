<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>PhotoTechEDU Day 11: Document Image Analysis with Leptonica | Coder Coacher - Coaching Coders</title><meta content="PhotoTechEDU Day 11: Document Image Analysis with Leptonica - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>PhotoTechEDU Day 11: Document Image Analysis with Leptonica</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pCZtGRUa_7s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay people thanks for coming today we
have Dan Bloomberg from the google book
search team to talk to us about document
image analysis damn take it away okay
thank you yep see if this work okay so
this is a photo tech course so what are
we doing what are we doing talking about
image analysis well I don't know but but
there was a lot more is the is the
description actually actually a lot of
we can now capture documents for example
with cameras and so it actually makes it
makes sense to talk about this a little
bit now image analysis in the what I was
just going to mention in the last
century image analysis was tended to be
a sort of a I like affair where where
people tried to reason about images and
you know from my experience it was it
was sort of funny because when I started
in this field everybody else was working
on 256 x 256 pixel images and it didn't
matter if it took him took him a few
minutes to find out to reason about the
image and get some result I wanted to
use document images which were typically
eight million pixels and I wanted a
result in in a few seconds and i was i
was actually impressed by douglas
hofstadter statement that a human being
can recognize a person in about a
hundred milliseconds and so why can't we
do why can't we use processing image
processing or some kind of processing
things rather than reasoning about about
an image and there are other reasons too
but basically virtually everything I do
deals with with the image so the image
is the primary representation we don't
don't don't really build up a lot of
other things there's there's always a
trade-off between speed and accuracy it
turns out that for image analysis you
can you can sort of you can well in a
way you can get rid of the
you can have both so you can have you
can do some things very very quickly and
get good results because an image
analysis that you have to make decisions
about about pixels and that's a and
that's a nonlinear process so for
example in image processing you you can
scale and you can have you can do
Splinter pilation or even higher order
interpolation to try to get the most
accurate rendition of the scaled image
or say in a color image for image
analysis very often and you're working
on binary images and you want to do
something for recruiting very fast and
so I'll mention this later a rancor
cascade of power of two reductions is is
actually very useful for doing such
things so and why are we talk about
document image analysis basically i'll
be talking about well it basically it's
easier to the natural scenes because
there's more structure to it and it's
very useful because we have a lot of
paper and it's useful and we live in a
digital age it's also an interesting
problem because unlike the graphics
problem where you you have a
representation and you turn into a
raster in this case the input is not
well defined the fact the input can be
just about anything even though it's
it's supposed to have some kind of
structure so it's actually an
interesting problem so road map I'll
talk a little bit about the goals what
we try to do with with image analysis
and then the approach that I take which
is use non linear operations work of its
shape and texture and always use the
image talk a bit about the primary tools
now give you some example applications
the primary tools are image morphology a
fine transforms counting connected
components and seed fill and I'll just
be showing you some some set of
applications here
so so the goals okay so first of all
we're trying to extract information from
the page and you just kind of imagine
what that is you you want some kind of
global information about for example the
sku of the image text orientation or if
there's some kind of warping with with a
camera you can get warping you want to
know what's on the page so what are the
components what's the hierarchical
arrangement where are they specifically
and sometimes you want to know what the
equivalence classes are that's useful
for compression and you want to know
things about the photometry to you
actually want to know a lot I've just
mentioned you know like what's the
background color is your color so you
you will typically want to do some
improvement or restoration of the image
or you may you may not but if you do
there are geometrical operations that
you can do in terms of D skewing and D
warping their various color mapping
things you can do to restore the image
because of non-uniform lighting for
example you may want to improve the
readability so you want to increase the
contrast of the text you may want to
improve the way it images look but by
increasing the dynamic range for example
of the images if you see if the image
has been scanned at two little
resolution below the Nyquist limit
you're going to get more a with with
digital cameras with with the bayer
pattern this often leads to color either
coming so and and that's it's useful to
detect that if you do detect it you
probably don't want to do a normal D
mosaicing you probably just want to too
well depending on if the image has color
or not if the image doesn't have color
and you have the color more a you just
want to do mosaic you want to just
basically remove effectively remove the
filters over the over the sensors
and then there are whole bunch of other
things that you may want to do so if you
have binary scans you may want to remove
noise I'll show you a kind of a weird
way of doing that little later typically
you have some bleed through that's
that's good to get rid of if you can if
you're going to display something in its
binary it's useful to to crunch it down
and and and into a gray image so that it
looks good on a great scale display if
you're going to print something and you
have a great input you typically want to
expand it up and do that in a way that
preserves some of the anti some of the
gray information around the edges of the
characters for example and you may want
to do quantization for compression so so
in in in these images if you have jpg
for example you I'm sure you've all seen
it you have artifacts around the text
the the eight byte block artifacts as I
mentioned before you can have more a on
half tones and on grab your that looks
very different but it's it's it's still
kind of ugly and Anna court and if you
have threshold Incanto if you if you do
binary threshold you can destroy images
and okay so there are various techniques
for avoiding these problems so the the
JPEG artifacts if you if you can get a
uniform background you can get rid of
that those those ugly things yeah well
so let me just let me just go on
and talk about how we're going to how
we're going to do this excuse me and
please please stop me if you have any
questions at all so as I said the
approach requires nonlinear operations
because you need to make decisions on
each pixel if you have linear operations
you basically don't make decisions what
you're going to be doing is you're going
to be assigning labels to pixels will be
implicit but it any pixel could have a
multiplicity of labels and one way to
think of assigning labels to pixels is
to have to have mass and so you're going
to you can imagine a binary mask we're
set of mass where each mass represents a
particular kind of label and then and
then that mass gives tells you which
pixels have that label and typically the
approaches bottom-up aggregation of
information that is pixels telling other
pixels what's around them and and what
they should do so the approaches is
basically working with shape and texture
shape and textures ill-defined shape is
everybody knows but you can think of
texture texture at at a particular scale
so for example if you have a line of
text if you're up close you can see the
characters if you get very far away it
just looks like sort of a fuzzy line so
so and it looks like a set of fuzzy line
so the texture of the characters blurs
into into something that's uniform but
then you've got you have the you have
the line separated so that's a texture
so depending on the scale you want to
look at things that are the texture at a
at a higher res a higher resolution look
more like shapes at a coarser resolution
so we're going to use binary morphology
to to sieve to to basically extract
texture or shape components out
and as I mentioned we the rank
reductions are very interesting because
they allow you to modify the texture at
the same time you change the scale and
seed phil is a witch the French call
binary reconstruction is a very
interesting way to make a robust kind of
segmentation you basically have a
situation where you have you have a seat
in a mask the seed pixels you're pretty
sure that those seed pixels are correct
like this seed pixel is inside a
halftone image part ok the mask the mask
pixels you don't really you don't really
know what they are the only thing that
you can pretty pretty carefully assert
is that pixels of different types are
not touching each other and therefore if
you start with a seed you can fill into
them into this mask so if you start with
halftone seeds you can just get the
halftone reasons that's a it's a useful
way to do and it's a very typical way of
doing segmentation the image is primary
representation ok that's where the
information is just just use it and and
so in fact you know my view is use use
image processing to do just about
everything if you want to use other
representations things get complicated
and and it's relatively limiting because
because how much can you how much can
you do on some representation that
you've made up to describe the image
like a level set the level set for
example whereas if you use the the image
things are relatively simple and their
and their generalizable and it's easy to
visualize so that's the approach the
tools ok so I'm going to go through the
the tools kind of fast how many of you
are familiar with image morphology ok ok
I'll I'll just I'll just sort of say a
bit about it there are a lot of
references that that are available here
that you can get more details so
basically morphology is a way of
extracting as I said shape and texture
sitting for exam
people the basic operations are dilation
and erosion the analogy is with
convolution which which are all familiar
with in convolution you have a kernel
and you basically do a an averaging with
a with the colonel the averaging of the
pixels under the colonel it's really
accomplished you're multiplying by the
kernel value for every single pixel in
the image in morphology what you do is
you got a kernel which is called a
structuring element and instead of doing
an average thing you do a nonlinear
operation you take a min or a max so
it's basically a rank order filter with
the rank is either at the minimum or the
maximum and that's all it is and you
have to it's an image processing
operations over every pixel so every
pixel in the image you're going to
compute a pixel in the source you can
compute a pixel in the destination and
the structuring element is composed of
hits don't cares also misses you can
specify so so let's let's think of this
as on a binary image you can say these
pixels must be in the foreground hits
these these pixels in the image must be
in the background so there mrs. and
there's also an origin to the
structuring element the origin says says
where you put the pixel in the
destination when you've made your
decision on the source opening and
closing our item potent operations so
they're pure filters and opening is an
erosion followed by a by a violation and
closing is vice versa these are dual
operations just as the erosion and
dilation or duals which is
Yeah right uh it was not going to do
that next all right sorry yes so so an
erosion is is what you do is you got
this kernel and you put it on the image
you have to place it at every point on
the image and you just you just ask
what's the minimum of all the pixels
that it's sitting over at each place so
if it's a binary image and you just have
hits than the minimum if every every
pixel in the in the structuring element
is over a foreground pixel then the
minimum is is the foreground which is in
binary images it's a 1 so however if any
of the pixels is over a background in
the minimum is a 0 okay so so if if the
thing fits entirely over the foreground
you're going to get a pixel in the
destination a 1 in destination otherwise
you get a 0 in the destination so if you
have a structuring element that's a line
for example and you're putting it on any
where it fits you get something anywhere
it doesn't you don't so if you have if
you have a thin line in the image that's
narrower than the size of the
structuring element that line is going
to disappear because there's no place
you can put it on ok the dilation is the
is the dual of the erosion in that case
you place the structuring element on the
image and effectively you can place it
on the work so that the origin is is on
the on the foreground pixels and what it
will do is a little draw into the end of
the destination image it'll draw itself
it draws itself in there so it
effectively widens there will widen be
the any structure that's in the source
image by its width and that's why it's
called a dilation the so for example the
opening is an erosion followed by
dilation if you think about what happens
is the erosion brings it down right so
you let's say you've got a line that's
free why'd you put it in the image now
you've got now you just have a single
point for every point that was in that
line ok when you do the dilation it
you've been
tically open the result back up again
and so the aunt of the the net effect is
that when you do an opening you place
the any place that you can place the
structuring element within the
foreground you get you paint that
structuring element exactly as it is
exactly where it was in the source into
the destination okay so anywhere it can
fit you get it and that's kind of nice
because what it means is that it leaves
things that are smaller than the
structuring element pretty much
invariant and think a larger pretty much
invariant and things that are smaller it
removes them so that's why it's a filter
that's why you can think of it as a
filter in fact it was invented by the
French we're doing filtering on on
images that had particles it was ok and
the the hit miss as I said is a general
pattern match so these are these are
examples of hit miss structuring
elements that are used to identify
character ace enders and descenders so
what you have here so these are hits the
blacks are hits the lights are don't
cares and the the things with circles in
them are mrs. the origin is that guy
right there with a little dot ok so
anywhere that this whole thing fits that
is these are all hits but don't care if
you don't ask questions about and these
these six or mrs. you're going to get in
the destination you get one pixel right
there ok so what happens is it turns out
they're more ascenders and descenders in
text and roman alphabets generally so if
you do this and then you count up you do
this on the image and actually there's
some there's some filtering that you can
do to make it a little more robust
before you actually count you know apply
this operation to the image to count the
ascenders and descenders so you do this
and you just count up how much you get
when you use these two for the ace
enders and these two for the descenders
and basically based on that difference
you can decide if the text is up or down
if there's enough of it so that's that's
enough that's what the hit miss
structuring element does so how is it
implemented well so efficiently in order
to implement efficiently you have to use
packed words so that so you're if you're
dealing with binary images they're
packed 32 pixels 32 bits in in a 32-bit
word or 64 if you've got that
conceptually what you're going to do is
I as I mentioned you just test the
structuring element each point you make
a and you write it out over there that's
that's not the way you want to do it
obviously right because you want to do
it on a word word parallel basis so in
fact what you can do is you can just use
raster ops how many of you are familiar
with are familiar with raster ops ok the
raster Rob is a basic operation which is
which takes a block a rectangular block
of an image and it does it does an
operation with another rectangular block
of another with a with a rectangular
block of another image let's say in
place on this other image and the
operation can be let's say any logical
operation there are 14 different logical
operations that you can do between these
blocks so it's a it's if you want to
paint characters on the screen user ass
drops in fact that was I possibly the
first application that I knew of where
it was where it was implemented so with
a raster op basically what you're going
to do is you're going to take the whole
image and depending it the structuring
element tells you tells you what you're
going to do with it so suppose you want
to do a with a with a three by one so
what it says is you take the image you
start out with the image paint it to the
destination ok then you take the same
image and see the structural element has
it says let's say the origin is in the
center so that you've got one on one
side and one hit right one pixel
to the other side so you just paint it
again shifted over by one the left for
your left and then paint it again
shifted over by one to the right okay
and each time you paint it when i say
paint it i mean you or it so so the the
or is basically this max operation in on
a binary image this boolean max if
you're if you're doing an erosion you
would you would paint it and then you
would do and we would shift in and shift
at an end you gotta be careful which way
you shipped in order to make them tool
but basically that's that's all that you
do so it's just answer it's just logical
logic and and so the raster op is
implemented 32 bits at a time so it's
relatively fast okay what what else what
else can you do for the typically
ninety-five percent of the time that you
ever use this thing you're going to be
using what I call brick structuring
elements so it's just solid you know
solid horizontal solid vertical solid
rectangular okay so for those it's their
separable in x and y so so that's good
so you can do you do the x and then the
y after you've done the X right and then
and there also composable as sequences
at different scales so if you can do a
two-way composable things suppose you
have something that's a hundred what you
can do first you do 10 and then you do
another one where you have a comb where
you have a hit at every 10 and so it
takes this thing that you've already
dilated by 10 and it just moves it over
10 10 10 so you've only got so it's only
20 so it's like two times a square root
of the size is the number and you can go
on with this thing right you could do it
three way and then it's going to be
three times the cube root and you can
take it you know until until you until
it becomes ridiculous but so so there
are various ways of speeding up now you
can also implement it faster than raster
ops by unrolling the loops and what you
do the destination word method you
basically you write codes
specific for that structuring element
that says for each destination 32-bit
word or 64-bit word the structuring
element tells me that if I'm doing an
erosion I have to take pixels from these
these other these words ship them in
mass them appropriately and then I get
the result so you unroll the loop and
it's about four times as fast and it's
really really ugly to write the code and
to get it right so you don't have to
with with lept annika it will auto auto
general the code for you so that that
makes it a bit easier and let tonika
also lets you invoke these these bricks
with an interpreter so you can vote them
as a sequence of operations I think
you'll see an example of that later okay
so any questions about that so that's
that's how it's implemented now more
toolkit so we have a fine transforms
you're familiar with this in graphics
that finds our translations shears
rotations and scaling the rotation can
be done on a digital image either with
two or three shares and it can all stand
so for example and that can be that's
that's depth independent and that's done
by raster out and one of the nice things
about raster up I described it in the
context of binary images raster up
obviously works on images of all debts
so that's an it's a nice feature that
you don't need to worry about the depth
if you have a let's say grace kill em
into a color image and you want to do a
nice job then you have to then you can
use area mapping or you can even get
more fancy and use cubic splines and
things like that generally not necessary
to go anything beyond beyond linear
interpolation which is equivalent area
mapping for for for the rotation scaling
scaling is quite complicated because
there are so many cases in so many
different ways of doing it and again
there's references for a huge set of
different things that you can do with it
now the useful for many things so
they're useful for rendering in
rendering you will you know typically if
you're going up in resolution your gut
you want to do some kind of
interpolation if you're going down you
want to use some kind of smoothing and
sub sampling some anti aliased operation
for going down you you may want to
combine it with depth change so skill
too great for example if you have a
binary image and you want to display it
on a con on a screen you do not want to
display this binary image you want to
display this color or grayscale image
and in likewise if you're if you're
going to print something and you have it
as a great image printing is typically a
binary operation so you would scale it
up with linear interpolation and then
get an accurate a more accurate binary
rendition using the the anti alias
information on the edge of the
characters and you can combine
morphology with subsampling and there
are a couple of ways to do that you can
do it in the binary regime you can also
do it in the grayscale regime in the in
the binary regime in particular you get
this textural filtering effect which
which we'll see an example of and this
these are just examples i won't i won't
go through this in detail but but you
know in terms of of the kinds of scaling
i will do want to mention the binary to
binary with this rank order so in other
words what happens is you may you may
want to work at a lower resolution
question is how do you get there you may
want to work say 8x down because you're
the scale of what you're looking at how
do you get there you can subsample but
what you might in fact want to do is you
might want to do it let's say a
morphological erosion and then and then
do the subsampling afterwards that's a
huge that's a wasteful effort even
though morphology is now pretty fast
what you what you can however do is you
can combine the two together and that's
by doing a cascade of two
2x reduction so you each two by two what
can have anywhere between one and four
foreground pixels in it and so you can
just basically say I'm going to I'm
going to do a rank order reduction if
it's got n or more pixels in the
foreground I want a pixel on that
reduced image okay and you can do that
essentially the same speed that you
would do straight subsampling you can do
that in a parallel parallel way across
the thing so we're talking in that case
we're talking about what about 1
millisecond to take a full eight million
pixel image and generate and generate
the the the reduced image at any scale
that you want at any scale that you want
with any sequence of these of these
ranks so it's actually a very useful
technique it was useful quite a few
years ago and it's still useful so let's
go on another piece in the toolkit is
counting yeah just county program pixels
also computing connected components I'm
i said something about how you should
stay in the image well every once in a
while you have to leave the image and
get gather some information about the
image so this is this is the exception
that i make the main exception counting
pixels you might want to test for
foreground pixels and for sku detection
and and measurement you basically you
need to sum the pixels on raster raster
lines connected components are useful
for labeling components and okay another
counting thing is histograms right so
you may want to take histograms of 88
bit per pixel images so okay
alright so another another tool the seed
Phil I mentioned seed Phil right you got
you have a seat and am asking you just
fill it in ok slow method would be a
morphological and and you don't want to
do that because that takes the number of
iterations equal the size of the
component that you're trying to fill
much faster is to use a sequential
method first I first saw Luke Vincent
who's here came up with this thing
raster raster anti raster on again on
forward 32-bit words and you just have
to do some number of them until it until
it converges so so you can do seed Phil
very very quickly and and yeah the other
thing to mention is that that in lab
tonika actually uses a seed fill method
by heck Bert which is which is
relatively efficient tool able to find
the connected components to identify the
connected components find where the
bounding boxes are for them to actually
find the images of the separate
connecting components and there's also a
grayscale version of seed fill its it's
a little weird to think about how did
how you what it means if you have a
grayscale image which is think of it as
some sort of arbitrary topology some
height in two dimensions but what you're
what you're essentially doing is you're
you've got you've got some seed at some
point now the seed itself is also a gray
image and it just kind of fills out
until it hits the boundaries to tell
can't get any further right it fills out
until it so it's clipped by this by the
the mask the mask is typically higher ok
and then it just kind of follows the
contour and when it's able gets under
you know there's a little saddle or
something it's able that's and it just
sort of sneaks out and goes on like that
it keeps going back it's actually very
useful there's something called an H
dome operation where you can I'll tell
you exactly what you do you take it you
take a an image what you want to do is
find out tell me all the peaks all the
peaks in the image that are that are
that are not larger than a certain
height so you take the image you
subtract that height from the image and
the thing you subtracted is the seed
then you do this seed fill operation and
after you fill the seed basically you
don't fill into the end of these hype
the height parts right you don't fill
into the parts that are higher and then
you just subtract the see the seed after
it's been filled from what you had
before and you end up with with these
with the peaks so it's a way of
normalizing out background and it's a
different way from grayscale morphology
which the grayscale closing which I will
show you in a minute all right and I'm
going to just run right through this
it's a left Annika library it just has a
whole bunch of stuff that's all you need
to know but it's available in a in a
variety of places it's open source it
has a very small number of structs and
it's so the these operations we've
already mentioned it also has has a
bunch of other things it has io4 in the
standard formats so that you can
actually do something useful and it has
a whole bunch of applications and we're
going to look at a few just a few today
okay so the things that you can do it's
basically a low-level pixel grinding
library but you know there are a few
simple up applications that you can make
from them okay and so let's get right
into that so the first one page
segmentation and this is this image is
from the University of Washington data
set thanks to is that right UNL sorry
UNLV what data set thanks to Ray so so
there's an image and what you want to do
is you want to find the half-tones the
text lines etc okay so you just you just
do a bunch operations right and so you
do that and you do that and you're done
okay well alright so I'll show you a
little more detail what you're actually
doing first the first one is
that's that's the image you start out
with this is the seed image for the for
the Half Dome so these are the pixels
that you're pretty sure and halftone
part right this is a is the mass that
you're going to fill this this thing is
basically a dilated version of that okay
you want to make sure that you that that
in the halftone regions if they exist
the pixels are going to be touching so
that any seed you have is going to fill
out all of them so you have to do a
little bit dilation okay and then when
you do the seed fill you get this that's
nice and you can take it out and get
that and then what you want to do is you
want to find the text lines let's say so
you can do this you can do a basically a
closing a horizontal closing operation
which is going to smear them out but if
you do that then you're going to join
the columns so before you do that you do
a very large vertical opening to get rid
of the 22 on the you do a large vertical
opening on the inverse image to get the
white space the vertical white space and
then that this thing right here is you
actually remove some more pixels and
I'll show you that in a minute so you
actually use this on that to get this
right there and then you can join up the
text blocks and and see the different
parts so let's let's let's look at just
do not just so you can see you know
there's nothing there's nothing really
terribly hidden or difficult about this
this is this this cascade of reductions
we're going to do it at 8x reduction we
don't need to know about these seeds at
a very high resolution so we do this
cascade those that's the level that when
it says it's a for what that's saying is
for every two by two all four of them
have to be honor it's gone well what
that does that that thins things out
that's an erosion and a rotating process
so when you do this cascade you're
basically it's like you were doing a big
morphological erosion and then you were
doing a subsampling and then then
there's a small a small opening to get
rid of
of some noise just accidental noise and
you know you could have something
elsewhere and and then that's it okay
that's the result hey yeah this was this
was expanding it back up that this
operations took place at about 150
pixels per inch I mean sorry the input
was 150 pixels per inch the 8x reduction
is 8x below that alright so that was
that's the seed this to get this
actually used to close a closing
operation to get the mask the seed phil
is just seed Phil okay and and again
there's a little bit of an opening to
get rid of small lines and things like
that but basically this is what you end
up with so this is the half this is the
halftone mass then then the rest of it
you just subtract that off right it's
just set subtraction and so that's
that's the rest of it to get the text
line oh this is this is so now we do the
inversion we take the inverse of that
thing and then we do this this basically
a vertical as there's a little right
there you do a little horizontal opening
and then a very large vertical opening
it's 200 that means you have to do if
you did this if you did this with just
with a block thing you'd have to do 200
of them you can do it in a composite
fashion and it's about about 40
operations 35 operations so it doesn't
take much time so then but here's the
problem the problem is if you do this
you can have white space above text and
and so you'll have you'll have something
that's 200 long and it'll go right
through and it'll go right through into
into a space between texts so it'll
actually break up something that you
don't want it to break up right we
really want this to break up things
between columns we don't want it to come
shooting down from the from the top or
up from the bottom and and just
fortuitously sneak through a whole bunch
of stuff so what we do is we do
we remove some of these pixels and the
ones that we remove we basically take a
we start out with that that that inverse
image and we say where are the things
that are at least 80 x 60 black pixels
right so all the things that are 80 x 60
that's going to be this stuff at the top
and the bottom anything that's that big
let's find it and let's subtract it out
let's remove it and so when we do that
we get this so it went from this to that
okay so this is now a reasonable thing
to use oh this is now a reasonable thing
to use so now we close this well that's
a 30-30 whip closing and then we and
then we remove it right we just subtract
that that thing off okay so now we've
opened it back up and the rest of it you
can just label the the colors that just
shows you you have to do a few more
lines of code in order to label the
colors but it's not much okay so here's
here's a here's a different example and
this is this is a is kind of funny you
probably all received a photocopy of
something that's that where the the
copiers just got really weird with a
threshold in it it gives you a lot of
really dark stuff so let me like that
over there this is Chuck's one of us
shucks favorite papers actually I bought
it but but the problem is it's really
hope so how do you get rid of you we get
rid of all that noise right well you
could scan it in binary and try to clean
it but you can also scan it in in
grayscale and try to clean it as a
grayscale image and one simple way of
cleaning is gray scale image is to try
to figure out what the background is
well so there's the background how do we
get the background we got the background
just by taking that foreground that I
show that no yeah
and we just do a closing we do
morphological closing not even not even
a particularly large one just big enough
big enough to get rid of the text what
does the closing do the closing gives
you a remember the closing gives you a
max so the closing is going to and and
in grayscale images black is low black
is 0 right so the background is the
higher is the higher stuff so you're
just going to run this thing over and
get the max and so that's all you do you
just pick something this big enough to
get rid of the text and you get that now
there's one other thing you have to if
you do that the result you get is not
quite as smooth as what you would see
there what you actually get you'll see
the blocks where the where the the
structuring element was sort of stuck
you know i mean it it the noise in the
image there's various noises in the
image that that gives it a blocky so
what what you can do is just do a
convolution just do a regular
convolution that's actually a 30 x 30
convolution it looks like 15 but it's
really 30 x 30 so about three times the
size of that net and that's what gives
you this nice smooth great curve which
is the background once you have the
background it's relatively simple to
figure out how to how to threshold a
plea threshold that that image and i
just want to mention this little guy
right here scale gray min max so this is
a this is an el cheapo way of doing the
same thing as the closing basically
since since the background is you don't
need to have the background at every
single pixel when you do the
morphological closing you're getting the
background at every pixel you don't need
that you just need it sort of i need to
know it you know every ten twenty pixels
so but why not do that why not just tile
the thing up and do a do a min in this
case do a max over each of those those
things and you get roughly the same
result and it's probably about 20 times
faster it's 20 times faster than the
closing and the closing itself is very
fast
due to an algorithm by Gil vermin and
van Herrick from from 1991 surprisingly
late where they figured out how to do
this operation how to do a closing or an
opening or an emotion or a dilation and
gray scale in a time that's independent
of the size of the structuring element
for a structuring element that's a break
ok so anyway they're one of the one of
the lessons is there always these these
faster things that you can do that give
you the information that you need almost
always ok so ok sku how are we doing
well I'm running out of time ok let me
just I'll talk really fast d skewing and
images is a useful thing to do there are
hundreds of papers on this maybe
thousands of papers ok now when there
are hundreds of thousands of papers you
can either say the problem is not solved
and keep working on it or the problem is
so easy that people can just find new
ways of doing it and they're just
writing you know printing stuff on paper
so it's really the latter the most
robust method that's known was was found
nearly 20 years ago about guy named
postal and basically what you do is you
just okay here's the naive idea is well
if the thing is is properly dispute and
I some i some the pixels on each
scanline some scan lines will have lots
of pixels and some will have very few ok
that's the naive idea so what I I just
do vertical shear until I get this until
I get the the biggest difference between
them right so it's like it's some of
them have few some of them and many
that's a variance you just basically
it's you can it's equivalent to the to
the sum of the squares of the pixels on
the on the scan line there's a constant
difference which is independent of the
school so so that's that's the that's
the and that and that kind of works
sometimes but it fails in the following
situation when you have multiple columns
and the text is not aligned on the
multiple columns and the fact that Texas
kind of arbitrarily aligned then this
whole thing washes out and it doesn't
work but the thing that postal realized
worked was even if you have multiple
columns what what what you instead of
getting all that energy from little scan
line itself get the energy just from the
transition at the bottom and the top of
the of the baseline and the top of the
Exide so so take the difference in the
number of pixels on adjacent scan lines
and take the variance of that okay so
here's so that's basically it and you
can typically compute this at a
resolution of about 100 pixels per inch
which gives you an accuracy of roughly
the theoretical accuracy is roughly 1
pixel vertical out of the width of the
image which is about a twentieth of a
degree and which is much better than
what people would notice that's fine you
don't need to go any further than that
this operation on a computer today takes
you know probably it takes less than a
tenth of a second to to figure that out
now on this image right here so I
purposely picked a nasty one as this one
has two columns in there and they're all
different and what you get you this so
this is the this is the score function
as a function of angle so there's the
angle and the thing is is that is that
where it is I guess it's there yeah so
it's a max that it's not really peaked
okay if you have if you have a single
column this thing is extremely extremely
narrowly p this is this is kind of wide
the width is about point five point zero
five but it doesn't matter what you
choose in there so this is that's
basically what happens okay now if you
take a picture with a camera a little
camera you're going to get some key
stoning right if you're close to it so
you have this this non 8f fine
transformation you can actually in a
very simple way of
fix fix that so basically what you do is
you have to you have to deskew it use
the same method I just showed you break
it up and do into slices compute the the
skew in each slice okay so there's this
skew fit a line to it and that gives you
that gives you proximal that gives you
your best approximation to what the what
the projective transformation is that
you need in order to to dispute it let's
see oh yeah and so so then you so you'd
SQ it and then the the second thing that
this shows you is once you've got it d
skewed you can find the baselines it's
relatively simple to find baselines and
well there's an example where the
baselines are you can see them there so
you would you would actually had a lot
of trouble if you tried to do that
operation on this Keystone dimage but
what's nice is once you've got once
you've got the the thing properly d
warped then each effectively each line
is giving information to the others
about about where it is because you you
don't have to you don't have to fit both
the the position and the slope right you
all you have to do is fit the light
position to each one huh
in what way do you break this into
flocks oh ok the question is in what way
to do it break them into blocks you just
know just yeah just do something
arbitrary have you have some rule that
you're going to take 20 20 pixel high
200 pixel high blocks and they're going
to be overlapping of a certain size and
just do it yeah something something like
that full with ya take take the phone
take take the data you've got when you
when you've got yeah yeah in fact yeah
in this you want you want to use all the
data you probably you don't want to do
this at a reduced resolution because you
don't have that many lines in each
poster ah yeah ok right so so the
question is is is can you take out a
general Keystone with this with this
operation and the answer is the answer
is you can take out the the horizontal
the part that you can make the parts
horizontal hope they're not to deal with
the parts that are the vertical key
stoning right no you can't do that
that's right so you can only get rid of
it you can only do part of it you have
yeah that's that's completely right
if it's just so yeah you can you could
you get if you think it's justified then
you can then you can do another
projective transformation to to get rid
of that so here's another application I
won't go into this but basically if you
can find the connected components you
can do an unsupervised classification of
those components and in fact Adam
Langley wrote AJ big to encoder which a
shock mentioned is how you how you can
compress binary images very very well
because you're using it's a lossy
compression with a with a representative
for each of the equivalence classes it
I'll just run through this thing in one
minute to have one minute so color
quantization color segmentation well
they can kind of go together and you
know why color conversation because it's
it because it's fun actually there are
good things you can do with it but what
I'm going to just going to show you is
is I'm going to talk about a cube way of
doing the quantization this is i I just
I just mentioned unsupervised
classification of shape components so
here in this case we're doing a
essentially a clustering in a
three-dimensional space of the of the
colors that appear in an image a natural
image okay and how you do that
clustering either many ways of doing it
I cubed is really nice because it has
depth so you can you can choose at what
level you're going to select to go down
to for any particular cluster it turns
out you don't have to get too fancy
though dithering dithering gives you
better accuracy or it makes the mean
squared error or worse but it looks
looks better and you may also want to
use quantization if you for example if
you have to scale something that's got a
color map you have to remove the color
map to do a decent scaling they want to
use the same color map at the end so so
we take that image so these are these
are examples you can have fixed levels
you can say I'm going to go down to
levels in the out cube a 64
Thanks and and what we find with this
thing is they're twenty seven colors
that doesn't look great if you go down
three you get this one still doesn't
look great okay well another thing you
can do is you can have you can just say
okay I'm used 256 cells I'm going to go
3322 for the blue because we don't see
blue that well and I'm just going to
find the the closest ones in that case
you get 56 colors there but if you did
it so the ending is just an error
diffusion tillering where you add the
the residual to the to the next one and
then quantize it to its nearest guy and
then you just go on like that so it's in
a raster order you get something like
this get a hold of the the the notes and
take a look at it because in fact that
that looks quite good but it's not as
good as that there's some there's noise
that you can see in there now you can do
better you can that you can do a two
pass where the first pass you figure out
which sells you want to actually use at
a variety of different depths and
without dithering it actually looks
pretty good there on this side with is
earning it looks really good and and we
can also apply similar techniques to do
segmentation so you can do color
segmentation by just in this case you
don't want fidelity you want you want to
trash the image right and you wanted to
sort of get an idea what's what is in
there so this is one where we just said
okay let's let's use two colors in that
case three there's five there's six so
this just
that may be the best the two may be the
best one for the segmentation there but
anyways okay and they're all a bunch of
extras in the left Annika library that
that there's just a few of the extras
that in case you're not interested
anything you saw there okay so thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>