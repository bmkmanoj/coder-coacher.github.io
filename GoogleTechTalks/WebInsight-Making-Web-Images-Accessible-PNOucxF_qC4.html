<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>WebInsight Making Web Images Accessible | Coder Coacher - Coaching Coders</title><meta content="WebInsight Making Web Images Accessible - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>WebInsight Making Web Images Accessible</b></h2><h5 class="post__date">2007-10-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PNOucxF_qC4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">maybe if you know him really from his
password you walk around even birth with
head but he's actually been doing
something missing work in accessibility
space that he wanted to come give it
back on yeah he's got the students
working on cases loud I won't say much
more other than some of the other / done
Thank You TV for inviting me it's a it's
a great pleasure to see all you know my
former students and former UW students
and former colleagues here I do remember
and Taylor and Pablo Pablo so today my
time making web pages accessible this
talk is adapted from a talk that Jeff
Bingham gape at the assets conference in
portland in the fall so browsing while
blind i guess with some experts here on
that but most blind people use screen
readers they're really blind low vision
there's like window-eyes and jaws are
they are the two most popular now these
are nice but they can't good enough to
read images yet an image is a very
complex thing and then it's much more
difficult than text for example that WCC
accessibility standards I think they
can't require anything but they can sort
of suggest or say something like that
that every image should have some non
some some textual equivalent as an
alternative text and that can be done in
a number of ways I'll talk about that a
moment if there is no alternative text
what does it scream well it may do
nothing because that there's nothing no
option for it to do it may return
filename because most images have a
filename and this one here says 0630
0060 315 underscore the
nner banner underscore and some
something that ends in Jeff I read that
out for TV Raman sake would that be
satisfactory probably not as an
alternative text or maybe better would
be a link address if it's an active
element and it has a link associated
with the edge so this one would be HTTP
colon slash slash wwc Washington you and
that might not be as good as something
that said you know link to university of
washington or something like that or to
the computer science department of
university of washington so here's a
have a beautiful page from a Yale it's
the Yale alumni association page and it
looks wonderful that there's lots of
paca sets of navigation stuff on the
left and articles about Yale Esau
realize whatever they call themselves
but what somebody with a screen reader
would sort of see is what I'm going to
show next is well actually all that text
for images on the left so just about the
only thing left are the articles there's
no navigation anymore so all you get a
screen reader would tell you if you are
on the left side they're doing the tab
key it would tell you some punch of URLs
that hopefully might have some meaning
but the text it's gone no alternative
text for those images so I'm going to be
nice to insert those somehow to
automatically do that for somebody using
a screen reader so here's an example of
one of those images nav underscore svcs
gif which is not very helpful so I'm
going to start with some web studies
that we've done and I will talk about
different ways that you can provide
labels and one of the exciting ways to
provide labels or alternate text is
through something like the image the
google image a blur or formally call i
guess the ESP game and then we'll talk a
little bit about the web inside system
and what we built so far
I think I can actually give a demo of
that a little bit about the evaluation
and some future work and also i'm going
to talk just very briefly one slide each
about some other projects that I'm
working on so our web studies well not
all images are equal so some images are
significant that is they're informative
they have information in them they have
a link associated with them so in this
example here you would hope that they
would have some alternative text so for
example a an image that had as its
filename graph jiff an alternative text
might be sales graph that would be a
decent one and or I'd be in the title
sales graph or in this long description
they might have something else so this
actually is something will be found on
on the web now in significant images
well there's lots of those on the web
their little decorative items spacing
some of them most of them are one color
or very few colors they're usually quite
small those we call insignificant images
and activation of alt text to according
to the w3c standard it should be it
should just have an empty alternative
text I believe it or not there are some
people that actually put in things like
spacer Spitzer spacer and a blind person
I have to listen to that all those
spacers but the screen readers won't
read out those empty ones
so we had this automatic determination
of significance that we're actually in
the process of sort of testing its
validity right now before we wrote this
paper we did not but we had a pretty
good feeling that worked well so I have
a couple of undergraduates working on
this so for our automatic significance
determination we said if it's if it's
more than one color and both dimensions
are greater than 10 pixels then it's
significant or it has an Associated
action it's clickable or has a link or
something like that then it's
significant so that's just a non
subjective way of determining
significance and we're testing its
validity this spring so first web study
well talk about previous web studies and
I have to admit that that everybody does
it slightly differently so it's kind of
hard to compare numbers and so you can
see that these numbers are quite
different so in three different two
different studies they looked at all
images in determine whether they were
significant or not the numbers that they
came up with were twenty seven point
nine percent were labeled or forty seven
point seven percent were labeled or
forty nine point four percent were
labeled so that was kind of tough so
these studies some ignore significant
sum includes significance some ignore
image frequency but I think most of
these do that is some images actually
come up a lot but they discounted it
once so the the actual studies are
listed below there and then we saw we
what outland did kind of a sort of a
similar study but we tried to determine
which of the significant images actually
did not have or had alternative text and
it depended on which group you went to
so we looked at five groups and here we
didn't look at frequencies again we just
look at these groups of webpages some
some 500 high traffic web pages from
thick it was from the Nielsen rating so
I'm sure Google was up there near the
top computer science departments from
the CRA list there 100
d eight departments in the CR a list of
the top 100 universities in the world
the 137 US federal agencies and all 51
states so we looked at these five groups
and again we came up with different
numbers for the significant images and
also in this table we show what
percentage of these groups had at least
ninety percent of their images labeled
correctly with the significant level
image of the total number of inches very
large the high traffic was over almost
thirty-three thousand images yes that's
not a percent hundred percent I don't
think any of these I think there might
have been one or two computer science
departments that that didn't have any
images so so there's a difference
between you can sit as a difference
between the sort of sites like I traffic
computer science and universities they
were thirty nine point six percent 52.5
percent in sixty 1.5% respectively so
they were well they were kind of number
similar to those other studies that we
should and but if you went to the US
federal agencies seventy four point
eight percent of those images were
labeled by law they shall be labeled
because there's a section 508 that
requires federal agencies to be have
their webpages accessible of course that
seems to be moving over toward a little
bit not that particular law but the ad a
seems to be affecting groups like target
that the
current law of the current
interpretation of the law is that in a
recent case is that the webpage and
extension of the company of the of the
store and so it's supposed to be
accessible so the webpage should be
accessible so the National Federation of
the blind representing somebody what a
lawsuit against target because of that
and then if we go to the US states even
better it's 82.5 percent of those images
are f correct label so and almost all
the states have as part of their
requirements to follow the same
requirements as a federal government so
you can see there's a big difference so
it does seem that these requirements
make a difference but also it shows you
that the numbers are pretty small but
these studies are a little
unsatisfactory because they don't
include frequency so we did another
study rope web traffic study so we're
fortunate the University of Washington
that they've already done a bunch of web
traffic studies for other purposes so we
adopted that technology we have to be
very careful that everything has to be
anonymised and we can't really look at
the data we could measure significance
they let us do that and things like that
so we looked at that one week of web
pages arriving at our department in at
the University of Washington and there
were about 12 million images that were
brought to the department and of that
group 40.8 percent were significant and
although 63.2 had alternative text so
the 62 point 63.2 I feel is at least for
academic institution and probably I
would Google did the same study I
believe you would come up with a number
similar to 63.2 so I think you know
sixty-five percent of significant images
on the web that are downloaded by
intelligent people or whatever AB
alternate text so that's actually you
know better than expected and this
number is bigger than those numbers on
those previous studies and bigger than
most of the numbers on our earlier
studies so this one I really includes
frequency
yes much harder thing to measure that is
is there any sort of sense of useless
alternate text versus useful yes the
group two things one if something is
really truly insignificant it's just
decorative and it does have alternative
taste text like I said space that space
that's not useful if you have a
significant if you have a significant
image that has alternative text it might
not be appropriate and my student Jick
and did a study of that and you know i'd
say its preliminary but it seemed like
ninety-five percent was appropriate so
the large fraction stands so thats name
is throwing it's very hard to measure
how see you i would say sales graph is
appropriate but not fully informational
so that's there's levels of this i don't
know that's a good point and we have
really look at that so what about
providing labels well we have three ways
that we thought about what is context
labeling if we know something about the
image nearby or the image is clickable
and we can go to another page a title
that page is probably good alternative
text so important images
certainly any image with lake is
important and it's often often described
by by the title of the page so that's
one way to do it so we call that context
labeling so here's an example of an
image and it has excuse me for images on
a page and if you just follow the links
you get good titles so in this case a
good title for one of these images
people of UW that turned out to be the
title of the page that this image went
to and it did not have alternative text
and so you can insert that as
alternative text in a in a transfer in a
like a transformation proxy another one
we've used is OCR labeling and we spent
a little bit of time on this I'm sure
there's better ways to do it so in this
picture here we have a button that says
register now ! and the button is very
stylistic it's it has multiple colors
and you know black white and red so we
did a basic color segmentation and
formed like six images from it of the
different colors and we pass each
through the OCR each of these images in
and turns out that one of these colors
is good it's white and so the white
image gets turned into black and then
the OCR can understand it and we get
something so we'll go through all this
text produced and many cases no text
proofs but sometimes garbage is produced
like in one of these and then registered
Alice boots and we can look it up in a
dictionary and then say ok that looks
like it might be a good alternative text
so they're very important buttons
register now maybe might be important
because right next to it is canceled you
know or something like that so that's
kind of and we'll talk about some
studies we did on this on this
methodology OCR labeling optical
character recognition ok so what I went
through this
oh here's the result actually let me
just finish the slide and so we were
able to improve recognition of a setup
like a hundred buttons by twenty-five
percent yes what was asking the question
yeah I over simplify this we do color
clustering and color fust-rate we try to
reduce it we don't look all the colors
but we'll just do some quas a shin to to
get a smaller number color maybe 20
colors or 15 colors and then do this
technique that seemed to work fairly
well well this one here is on a black
and white they all started so we're
using my high quality OCR as well now
the word I forgot how many in our study
now maybe half the buttons did go
through OCR give you reasonable text
without anything any change without
doing this color segmentation the google
logo would be a problem if we did that
one but i think google is very good they
always have alternative text saw yeah
yeah make more harm I think we started
to study that one University of web page
would look that more carefully now let's
give me the department web pages we
looked at more carefully because I gave
a report to CRA about their about that
and there were only about 150 there were
only a few maybe two or three the news
flash well I'm doing that same study
again and then June last year I'm do it
again and find out how many more have
flash so it is growing and you're right
it probably a year ago didn't matter but
it's mattering
that's again that's it as some
accessibility by Crytek some previews
this is the word Google comes in it's
that it's the human labeling and I put
up there the logo for google imaged
labeler i know if that bait is still
there is that still a beta it still has
a beta on there which is the the
grandchild I guess of the ESP game from
luis von ahn and fetch it's another
labeling game but it needs more data
than just the image to get so seated and
these are sort of take the idea that
while humans are best at lately if we
can do it these recent games you know
they tend to compel accurate labeling
although at our meeting just a few
months ago with the image label or
people they told me that there is a lot
of you know Evan call it spamming but
tricking the game so that if you kind of
agree that good word is you know man for
every single image and half the people
that play the game agree that then they
start getting more points at all getting
his points you know so it's not like
money but I think most labels are fairly
accurate when I played the game and see
what for example the taboo words are
taboo words are always pretty good words
for the
image in fact it's kind of hard to come
up with a new word after you see the
tabloids I'll show you a screenshot of
the other of the game in a moment so
this web incite we have a ten thousand
images that we stole from from ESP game
because we did have cooperation with
Louie by on for that and we use that but
this is a very tiny subset of of what
people would actually use and the
interesting thing is that you could do
this on demand that if a blind person
was at a page and an image was not
labeled we could send that we could send
that image to the image labeler and I
would get a label pretty quickly and you
know what i mean by the end of that
section on that page it might have a
label on I brought that up today and
roll some eyes in my group oh here's a
picture of the image label if you
haven't played I think everybody at
Google probably has played by now but
this I pretty well on this one I had a
pretty good partner 800 is like that's
the best much as I can get in this in
this game but it just it shows you that
there's an image there there's place to
put in some text here are some things
that are off-limits I guess taboo words
and there's labels I did I took this
greenlight eight seconds left in this
game so I did the screenshot before i
typed anything in you can see some
previous things that we agree on there
was a image that we both agreed on that
it's a planet airplane it looks like an
airplane wreck actually a bug and a
mountain and I think all of those are
pretty good labels you know they're not
like telling you everything what kind of
bug that is actually one of the things I
put in there was wasp because it looked
like a wasp but and then there's two
more at the bottom of the page one of
these here I just put in the word text
and that was we agreed I put in here
handwriting and we agreed you know so I
can't remember what these other ones or
we got these eight correct and that one
we got correct two and i actually had
900 points in this game because i would
type in something i think pretty quickly
after taking that screenshot pretty
shadow it takes a moment to do
let me talk briefly about this web
incite before I do it we've discovered
that we're not the inventors of this
idea it's been around for a while
there's something called the Alta fire
have you ever heard of that um TV Raman
yeah so it came out of university of
toronto it was a from a w3c initiative
and it started in 1998 and finished in
1999 and and and the webpage is dated
1999 so it's like dead and i had this
concept of a registry of alternative XO
be a database with alternative text in
it and you can imagine that database
being seated in many different ways like
OCR with human labeling with you know
this context labeling we talked about
they the only way they seeded it was
with the with the context type labeling
and then it automatically suggest
alternative text for images via a proxy
so our system it's going to you know
there's different ways you can engineer
and i'll describe some of those in a
moment but it's going to coordinate
multiple labeling sources it's going to
insert alternative text in the web pages
via proxy or via an extension like a
firefox extension it'll add code to
insert the alternate pics later if need
be so some of the features are the
browsing speed is preserved we're trying
to make just not gonna ruin the browsing
experience the alternative text
available will be will be able once
formulated so its immediate and and then
it will be stored in a database so the
next time you just look it up and the
database is indexed by md5 of the image
itself so if it's compressed image
whatever the file is just md5 it and you
got a name board and that's the in the
index so two images are slightly
different they were compressed on
different jpg compressors or something
like that then they would be different
in the database but that's probably okay
so this is our initial design so we have
our blind user using a browser that
blind user makes a web request it goes
out to proxy the proxy then sends it off
on into the back into the internet and
retrieves it from wherever it's coming
from and it analyzes it for any images
that it has on it and then looks up at
its database what images it should
insert and puts those in to insert those
into the web page transforms a web page
is something that has alternative
alternative text for for the images and
that is returned to the black user and
you want this to be fast and actually
can give a demo of I don't think I give
a tip of this i'll give it dumb or
something something similar a little bit
later so that's one organization so it's
a big box around the the context
labeling the OCR labeling the human
labeling all those would be on press on
this you know they might be in separate
places but they'll be controlled by the
same organization and the database by
another organization so you could
imagine Google owning that old piece in
the middle for example and you could
call that you could call that thing oh I
don't know google image proxy or
something like that so that's one
possible thing so another organization
that we've built is something like this
we have a Firefox extension it's local
and so all the context labeling doesn't
really need a database you can just do
that on the fly and so that's done
through the extension so there's no
database local so those things are not
even fed into the database the request
and go through a proxy at all but the
extension contacts this what it does
have an image that a kid doesn't for
example have contacts labeling for that
it will contact some server some
labeling service which could have OCR on
it could have a human labor has a
database and just gets those uses the
md5 s and gets those
alternative text and also the extension
could make requests to get things done
like to get something OCR to put on a
database or to get something human
labeled going out to some other service
like Google Google a blur so these are
two alternatives and we built both of
these both of these two except for the
human label apart we don't have a hero
but we do have a primitive human labeler
that we built that it that you have to
trust the person to do the labeling it's
not probably in its label so here's some
basic issues a distribution of task
there's this database who takes care of
that 0 CR how is that done is that that
in a separate site the human labeling
where's that done so the distribution of
all these labeling services
authorization who should be allowed to
even use this system because you can
imagine for example that somebody's
developed a very large database of
labels for images well you don't make
that accessible to the world you want to
have some limited access to it because
they could copy that for example and use
it to improve search which might not be
a good idea ever see concerns copyright
concerns and accuracy are these labels
that are being provided actually
accurate so a little bit about
evaluation so I measuring the assistant
performance we tested the web pages from
the site study so the study of all those
web pages that we did not not the pages
we're coming to the what we call the aam
I had the two studies the one with the
sites and the one with the UW all the
one papers come to you of it we didn't
do that one because we didn't have
permission to do that so we use just
context and OCR labeling because we
didn't have any human labeling power and
we labeled with just that 43.2 percent
of unlabeled significant images and this
is where we're evaluating and we haven't
done that these are good labels
but preliminary studies are ninety-five
percent so actually did sample 2500 of
these and 94.1 percent were correct we
have a bigger study do you have a chance
to look at the ones that weren't
correcting see what the readies clears
you know Jeff knows that and I don't so
I don't think there probably are some
systematic ones but I don't know what
they are so this does seem to be pretty
good you know we got 40 three-point-two
percent it does seem to be a benefit but
there's still about half of those
significant images still aren't labeled
so the conclusion is that lack of
alternative text is pervasive maybe
forty percent of images that should have
labels don't web inside calculates
alternative text so it does the web
incite inserts alternative text
automatically and it has pretty good
accuracy so here's some future work
we're in the process we believe we're in
the process of the building a user study
a user observation study to figure out
what blind users actually do on their
screen readers and we have a pool of
blind people that are willing to help us
with that I have to admit that they're
all really really sharp there at least
college students and above so it might
not be a balanced or unbalanced but
there I power I call high-power blind
users and we're going to test you know
the interventions we're going to find
out what they do would kind of pass they
want to do and see if this image
labeling actually helps them finish
their tasks more quickly we're also
interested in the content producers in
this sort of built this sort of new
direction for this research so we're
going to do some user studies on on web
developers to find out what they're
doing about accessibility and how they
insert alternative text and how
difficult or I'll easy that is and what
processes think
we use and then we're going to redevelop
are in the process developing this web
incite developer and we're just
finishing a paper now for the W the W
for a conference which suits this summer
it's a big web accessibility conference
in BAM so you know if you think about
these labels they weren't they were you
know we didn't get a lot of them without
the human labeling we got that forty
three percent or something like that so
there's a lot of empty space there that
somebody should put some labels in and
maybe web developers could do it well if
we've made it really easy to put it in
there like we made the suggestions and
half the suggestions were actually good
suggestions they wouldn't have to type
anything they just say yes or no yeah
that's good so that forty three percent
of labels would be done and they just
have to do the rest and if we had that
human labeling in it might be better so
it's just like can we use the very same
idea to aid web developers to put an
alternative text into their program so
that's the thing I can demonstrate in a
few minutes so just the fact that you
know you've been labeling by the google
image labelers not going to give you the
greatest labels necessarily but there
might be good suggestions and help that
web developer put something in that's
better so this is actually a screenshot
but I can give you a demo later so the
screenshot shows the homepage of the
Department of Computer Science and very
top is a banner and in there is
something a web developer could could
use it would just go through the images
and right now it's on this image at the
bottom of the page that has CRA in it
and and then so it knows where its
context is and then it it gives the
suggestions while the original text was
computing research association what it
deemed is good the link went to a page
which titled computing research
association parentheses CRA which seems
good as well maybe that's even better
and OCR didn't do anything we weren't
able to get anything out of CR and so
maybe we'll use computing research
association as kind of the the
intersection or a good balance between
the things that came out and that would
be the suggestion so actually in this
case there is some alternative text and
you're satisfied with it so you just go
on to the next one generally
unfortunately University of Washington
Department pure science has good lickles
so we'd have to go to another page and
they people do that in in try another
page that doesn't have one this is more
challenges here that we're considering
working on like we've written an NSF
proposal to work on these additional
problems besides images there's also the
content structure and I saw some
beautiful stuff today of the TV remotes
were more aware he's able to sort of
parse a web page and sort of get down to
the nitty-gritty of what the text is on
the page and organize it in pretty good
way so trying to do this for pretty
complicated web pages I don't know if
that works all the time TV but it worked
well in the stop line person does not
use the mouse yeah they use a tab key to
go from say link to link or feel the
field or whatever so in a form a web
form but if something requires the mouse
over then goodness what do you do so
we're trying to figure out ways to
handle that as well and a proxy could do
that it could do sort of a virtual mouse
over of everything to see what's on the
page that this dynamic and analyzes has
it really needed to be dynamic if it's
not needed to be dynamic than it can
make it not dynamic and deliver
something that is not as dynamic as
original page but has the same content
and then web applications web
applications because of Google and other
companies are growing I'm word
processing email texting spreadsheets
you know it's just about everything that
we have in Microsoft Office will be a
service and I think for sort of the
general masses it might be the preferred
service it probably wouldn't be
preferred service for a company for
example like IBM but so making sure
these web applications are accessible
not just web pages so that's sort of
work that we're going to do in the
future so what can google do I don't
know probably should have been a new
list after our meeting today but provide
access to image label or database for
experimental purposes actually suggested
that today and I could get some pushback
on that idea I think it's actually
pretty good idea because we don't know
how good those labels are for blind
people and and we could do a a study at
the University of Washington to do that
now we wouldn't have to have access to
the entire database but maybe just
selected subset of it that you're
willing to give up on and also we could
suggest things to be labeled by the
image labeler and to make a more
realistic set for black people to use so
that it'd be a nice collaborative
project I think there's probably some
belief among some people that those
labels aren't good labels but they
argued labels why are you collecting
them you want to do better search
they're probably good for other things
as well and this might be a very good
use for them generally just develop some
collaborative projects I mentioned this
today Google for screen readers like
Google mobile so that might be something
and just to basically help fund
accessibility project the UW that makes
sense to to to do but I think we're
doing good work we have smart people
there's going to be some future hires
and accessibility of the web is a huge
topic it's it's not just a good thing
it's in some cases becoming kind of the
law and so if you want to sell anything
to the government both some of these
beautiful web applications are supposed
to be on maybe the US government should
use a web application you have a way to
make it nice and secure for them or
whatever well they're not going to touch
it unless it's 508 compatible
so I thought I'd mentioned a couple more
projects real quickly that I'm working
on and this one is actually what fairly
mature it's the tactile graphics project
so i thought i'd give a little example
so this is a little picture in the left
here is a is an image from a precalculus
book and this particular book has about
1100 images in it and a problem is
making this whole textbook accessible to
blind students who want to advance and
become TB ramens or want to get a degree
in chemistry or whatever it is they're
going to have to take precalculus that's
all I thought somebody the room was
asking me what's too I heard about this
room it's the non room room I guess so
how can we do this fast right now it's
done by hand basically so to do this
entire book would take months and we'd
like to do this in a few weeks rather
than months so that's the technology we
developed so let me describe it a little
bit by sort of an animation so we have
our original image which has so it's a
graph it looks like it's some there's a
line x equals 15 and that a line I can't
read it up exports y equals 20 and then
you're looking at the region so this is
a linear programming problem so you're
looking at the region that bound the two
axes in these lines and that's some kind
of like solution space or something like
that and this is going to precalculus
book you talked about linear programming
and precalculus book they've been in my
precalculus book many years ago so
somehow this thing didn't come out it I
don't see everything here but there
actually is supposed to be a clean image
right next to that dirty the original
scanned image was dirty when to clean it
up and then we extract all that text
using OCR actually not directly OCR we
extract the text using our own machine
learning technology and then we take
that text and notice that X plus y
equals 20 was rotated rotate the text so
it's all horizontal and then we put it
through OCR and then we can put it
through a Braille translation program
and then we have the Braille and we take
the pier graphing plus we know where
everything is in that xml file at the
top and then we merge those three in
Adobe Illustrator and out comes a
tactile graphic which you can print on a
embosser pardon lsi okay so i should say
that this particular book we did this
1,100 images in in-person time one
person it took them 10 minutes per
figure so this is like remarkable and in
in April this year we're going to do a
training workshop for a bunch of people
and do this kind of work in Colorado and
hopefully this they can learn this
workflow yes actually has the manual
because OCR is not perfect you have to
do corrections of going and extracting
the text is not exactly perfect but it's
like ninety-nine percent so you have a
little work to do there the conversion
from the OCR to Braille is not perfect
so you did real specialist that's the
only place you're Elina bro specialist
and then going from the the final layout
also needs work in fact that's the most
unkind consuming part is when you lay it
out you might have to move that texture
a little bit so that fits in the right
place nothing overlaps the image and
stuff like that and that's we've been a
quite a bit of work on that already for
example the text on the
on the y-axis should be right justified
it unless justified so we determined
that and we right justified in the in
the image because the Braille will be a
different size than the original text
there's also the question and mentioned
it is look up an XML there's some scale
factors so you get a lot of scale up to
be bigger so Braille will fit and if
this image is only about this big you
have to make it about this big to be
readable
okay so the other project is kind of
exciting is this is the / dotted project
that TV was mentioning earlier this
mobile ASL project so we're trying to
enable american sign language
communication using video phones using
video cell phones and in the current US
network which is a low bandwidth network
and actually the low bandwidth is not as
much of a problem as the low power of
the cell phone they don't have very good
processors on them so this limited
bandwidth limited the network bandwidth
and limited processing power on the cell
phones are the two main limitations and
if anybody wants to talk about this
afterwards I'd be happy to tell you more
this project so this is kind of in its
first year and we've been quite a bit on
the data compression part but not on
some of the other parts i can describe
that pool with anybody's interested so
that's the end of my talk if there any
questions on the app to answer them yeah
when I was your very your two going
uh-oh something interesting about the
PSP game which was that friend just
showing showing images showing it is
contact would often be much more useful
than just showing the event so for
example you could just showing an image
out of contest
like man woman long and but in contacts
in the article that appeared in person
yogi game could say ah Monica Lewinsky
you know whatever and try to figure out
if there's any way of doing this ah for
more general that works in these but
this is their way to rob to bring I
guess I should be asking Google Image
folks this but Sir what you bring in the
context of the image blip looking for
the old I know the one they only show at
the end of the game that you show the
name of the edge wow that's the thing I
not dirty game sound economy
I usually play with you to have a bad
that agency like you can have a game in
a way where you don't have the context
first you run about years and you can
push a button and then some more stuff
comes up but we only have a minute
probably pass before you do that
anything like the bug my feet you see
that uh I in the context you be a page
out of force awful on the way I gas a
fossil found wherever and you say okay
you know that's by looking at the
wedding time it's a ha you know I can
tell you more than that this is a but
until you this is amber you can also
have you know you can have a gain for
entomologists etymologists and somebody
else's and then you know yeah yeah sup
specialist yeah I do the other
so using the same is it makes more
relevant information by father thing I
do know is that a lot of these images
are capable and these different areas of
the images will have different URLs and
so I think doing context labeling for
those would not be too difficult because
that's why they're that's why they're
sprite baby is in 10 15 10 and then you
CSS 74
the URL active the image 4 SPD then this
whole mount is me all information is so
parsing it love it do the right side so
uh so we're not even about
the current standard for doing at
graphics is the process I just tried to
scan the image forget copyright / visual
you can do that Stan image and then my
hand if it was so some computer systems
transform it into an image that's gonna
be useful for last that's sort of white
stuff one other thing that one day pace
we did have it we didn't start with was
it was a bunch of you eps and for that
one said well why don't we go and there
are texts extractors 440s already out
there public domain stuff so we put our
text extractor into all these images and
we got almost enough and we found out
later that the the copies that all these
de esas people are how should they have
their own proprietary fonts and it just
happened now so that's what's inside VSS
text isn't even it but you actually I'll
get no effect on you get to design a
shrinkage of all the court finds that
they use thing bc is equal parts
more faces out there yeah
Oh</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>