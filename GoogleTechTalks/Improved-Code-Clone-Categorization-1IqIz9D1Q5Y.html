<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Improved Code Clone Categorization | Coder Coacher - Coaching Coders</title><meta content="Improved Code Clone Categorization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Improved Code Clone Categorization</b></h2><h5 class="post__date">2010-11-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1IqIz9D1Q5Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello I'm Nicolas craft from the
University of Alabama in Tuscaloosa and
I'm actually accompanied here today by
15 students that are performing research
this summer three are actually students
at UA and twelve are research
participants from across the country
primarily the southeast although we have
someone from the Bronx hey alright so
today I'm going to talk about the title
of the talk is improved code clone
categorization but really the the bulk
of the talk is just kind of an overview
of research going on in code clones
across the world and then towards the
end I will get into some of the work
that we're doing at Alabama migraines
one of the students in the crowd is
actually helping me out on this for very
little pay so that line the talk
basically a brief introduction some
motivation and then we'll get into
remarks and I included some reference
slides in case anyone's interested in
learning more so start out introduction
and acknowledgments here I actually have
two collaborators Lee that's Lauren from
UAH Alabama in Huntsville and Jeff
Carter who's also a faculty my
department and my cranes of course our
sponsors the National Science Foundation
stimulus package and Department of
Education so kocoum research you know
the purpose behind it is software
maintenance problem and software
maintenance is costly so we always like
to find big numbers that we can put up
to get people's attention like up to 90
percent of software cost is spent in
software maintenance of course it's up
to 90
projects but as of 1995 is the most
recent estimate I could find them
related to actual dollars the estimate
was about 1% of the GDP which of course
the GDP is grown very since then and I
don't know if yes software maintenance
is kept pace but again these are just
big numbers meant to get your attention
to say software maintenance is important
and that's why we're studying this
problem as most people do the size and
complexity of modern software systems is
actually spent trying to comprehend the
system that you are maintaining so of
course we have the developer mobility
issues in general the software industry
so we have new people joining the team
and they need to learn a piece of
software so they can begin making
changes whether they be bug fixes or
future additions and you know if you've
not worked on something for a month or
if it's a perl if you've got a
to come back and you no longer to
comprehend the code you're looking at
that's the problem so this makes ombre
making it's difficult and it's a lot of
research on comprehension space and
finally supper made it's a risky you
can't to maintain internal consistency
within these systems and systems are
interrelated so we can't just make the
change to a software system assume that
change occurs in isolation we have to
worry about how that change will
propagate throughout the system and so
today the clone research primarily is
it's on these points so trying to reduce
the overall cost of software by reducing
the effort that people have to spend
maintain software the way in which were
trying to address software developer
effort is to reduce the time and effort
spent comprehending a program and with
clones were specifically worried about
internal consistency and this one to
make sense as we learn about
you are and what people have found
related to clumps so moving right along
some terminology so a code fragment when
I say code fragment I just mean any
sequence of source lines and that could
include comments just statements any any
sequence of source lines contiguous and
we could be talking about different
granularity levels we can be talking
about two statements within a method we
can talk about method itself a class a
file a package its variable but we're
just being thumbs snippet of code so
Copeland's are actually similar code
fragments and similar is a metric which
we get to define so similar could be
exactly the same character for character
or it could be similar in relation to
some metric that we can compute and
we'll get into this a bit more when we
talk about clones so we're talking about
similar code fragments began to similar
fragments so fragment a and dragon B and
they're similar
that's called a flowing pair or if we
have say three fragments that are
similar that's a plumbing route or
sometimes called clone class so three or
more segments or fragments of code
similar
we have different types of clones
these can be clones based on the syntax
similar so the form of the code
fragments are similar that is you know
we have C++ and we have two for loops
the syntax is similar it might say
or clothes or we could talk about and
this is a little less common at this
point semantics clothes where we have
the syntax is not related but we're
performing the same action and we'll
look at some examples on these slides so
researchers have divided code clones up
into what they call four types types one
through three are related to syntactic
clones and then we throw all of semantic
clones in to type four and these are
somewhat loosely defined you know in
general we agree on what these things
mean but you know different tools that
detect these components implement these
things in different ways so there's
certainly some variability but in
general a type one clone is when we have
the exact same code except some white
space and possibly comments have changed
so on the top here we see the original
code fragment or code fragment a and
comb fragment B is identical character
for character except for we removed two
new lines and replaced them with a
single x
and so this would be called a type 1
clone any change of MySpace any change
in comments type to clone builds on type
1 so we can have differences of
whitespace and comments but additionally
we have names that have been changed so
any identifiers in the program whether
it be a tightening or variable name so
on and so forth they can be changed and
you consider these two code fragments to
be tight to close so here you see the
class thing is different and we've
changed a regular name and thus all the
uses of that parameter have changed just
any identifier could change and this
as this
it says it all
the fact that the battery life is not on
me it's dead or mean that
I'll see what I can do so type 2
questions to be several differences and
names type three clones again we're
building on type 2 we can have
differences of whitespace comments and
identifiers and now we can also add or
remove statements so this is where we
start to get some variability in the
definitions because how many statements
can be add to remove and still consider
it a clone this is currently just a
parameter to the various different tools
or algorithms that are out there and
there's no there's no set definition but
here you see we simply added a statement
an if statement wrapping one of the
existing expressions and this is a type
3 clump and as you can see it builds on
this type 2 we've still got a different
name so now type 4 clone is deals with
semantics not syntax our syntax and here
you see that we have the same algorithm
expressed in two different ways one the
original code fragment above uses an
iterator and the code fragment below
uses you know the accessor the
overloaded a square bracket operator and
you know we're doing the same thing but
the syntax is not completely different
but significantly different okay and the
detection of these clones is still in
its infancy
compared to syntactic clones because
there are a number of different issues
here as you can imagine so code clone
detection how do we actually detect
these code clones in our software there
are a number of different techniques you
can basically partition them into four
categories text based techniques which
just consider a program to be a sequence
of characters and we're comparing you
know the raw text in the program without
regard to the specific language
constructs an example of that is doop
which Brenda Baker I believe she's at
IBM research
came up with this in the mid-90s token
based techniques much like a lexical
analyzer break the program up into
tokens and then you move a sliding
window across the token stream looking
for similar similar sequences CC Finder
is actually probably the most commonly
used and well-known code clone detection
tool out there it's actually a fairly
mature for a research tool it's from a
research group in Japan they have not
only you know the the core you know code
clone detection but they have a GUI that
does various kinds of analysis and it's
it's a reasonable tool syntax based
methods work similar to a parser so we
parse the source build a tree
representation and then we're comparing
sub trees an advantage of the syntax
based techniques over the token based is
now we don't get weird clones that
include the end of one method and the
first two lines of another method you
know they break you know across a method
boundaries that doesn't make much sense
in terms of you know the actual program
structure and meaning so with syntax
base we can only try to compare sub
trees that represent an entire method or
an entire for loop or whatever the
granularity we're looking at so there
are some advantages here but of course
when we're dealing with sub tree
matching as opposed to a token stream
matching we get slower semantics based
tools are primarily used to detect
semantic clones the most well known I
don't think it's the only but it's one
of very few tools out there's duplic and
it builds a program dependence graph
which is a typical compiler internal
representation and the disadvantage here
for detecting syntactic clones is that
you abstract away a lot of the program
structure you're just maintaining the
meaning and so it's obviously difficult
to detect similarities in structure if
you've abstracted that away but of
course you are maintaining the meaning
and so we have a better chance of
detecting these similar you know similar
meaning different different syntax with
these techniques and again these are
even slower than this index based
because now we're looking at sub graph
matching as opposed to sub tree matching
so with any of these different
techniques we can use different
similarity measures to determine whether
two code fragments are in fact similar
and again we can use a very basic are
they exactly the same then yes they're
clones we can do for syntax based for
example we can do hash values for the
subtree and compare the hash values and
if the hash values are within some
threshold of each other then we say
they're clones
and these similarity measures are often
actually they're all basically always
parameterize in these tools so you can
you know set the threshold and change
the type and amount of clones that are
actually detected
so for token-based you commonly set the
minimum minimum window size so how many
tokens what's the minimum number of
tokens that can constitute a clone 30
might be a typical value if you bump
that up to a hundred you're going to
detect less clones which may be a good
thing and if you push that down too far
you're going to attack lots and lots of
clones and all of a sudden every for
loop you know the header of every for
loop begins to be a clone because you
know they're extremely similar in terms
of the tokens so you know
parameterization of these there's been a
lot of anecdotal evidence that one
parameter you know one token window size
is better than another or one threshold
between comparing hash values for these
sub trees is better than another but
there hasn't been a lot of study here
basically we tend to follow each other's
lead which we could be propagating good
or bad information it's hard to say so
that's future work obviously but again
there are lots of different detection
techniques and tools out there that
allow you to make various trade-offs so
some empirical results to show that
these clones exist in the
while which perhaps it's intuitive but
you know some experiments have looked at
for example the Linux kernel and
determined that 15% of the code the four
million lines is actually duplicated in
some way now this may be the most
obvious of all these examples because
when you think about the drivers
subdirectory all drivers have a basic
framework and in particular if we look
at all printer drivers they're gonna
look fairly similar and especially if
you know how these developers you know
create new drivers they take a driver
for a device that's similar to the one
they're writing the new driver for and
make some changes so nevertheless 15% is
not a small number so it might be a bit
surprising other studies have looked at
different versions of the JDK and J hat
draw which is an open source drawing
toolkit for Java and you see varying
levels of cloning people have actually
looked as well at some COBOL systems and
found numbers closer to 50% which you
know I don't know that much about COBOL
but hearing that it comes out the worst
is maybe not surprising to me from what
I do know
I think 50 percent cloning is it's
probably undesirable so anyhow these are
just results that people have you know
come up with as they're testing their
tools and techniques and to show that
you know these clones do exist in the
wild and they are a real issue if you're
maintaining a code base where 15% of the
code is duplicated in some way or
another you should know about that if
you're going to be making changes so a
clone comprehension so first of all what
is it it's knowledge of the existence of
clones first of all do you know that
there are clones in the system if you
don't know that you can't comprehend
them knowing where they are in terms of
you know in the broadest sense you know
we have clones you know high
concentration ones the drivers directory
of the Linux source tree you know that's
you know some kind of coarse-grained
comprehension knowing that a particular
subsystem whether it's split across
multiple packages if it's cross-cutting
concerns knowing that that concern has
lots of clones involved maybe that's
valuable knowledge it's kind of context
dependent and then finally understanding
the relationships between the clones and
this is what we'll we'll focus on a
little more through the following slides
so first of all some motivation the kind
of canonical example here is that a bug
report is filed and we identify a change
that needs to be made to address that
bug and we're going to go apply that fix
and the question is after applying that
fix have we actually resolved the bug
okay if the bug effects a cloned piece
of software then maybe maybe not we
should at least be aware that there are
clones and inspect those different
clones to be sure that this bug does not
affect those clones so here is some data
from our NGO UML which is a open source
UML modeling tool available from was at
Tigris org and here are some activities
so the first activity was inserting a
new statement so you can see in March
2002 the developers inserted a new
statement and class diagram model and
they came back in August 2002 and
realized they should have added that
statement and a related class deployment
diagram model so there was a clone there
they didn't realize and so the change
that should have been made in two places
was actually we create an inconsistency
there for about five months which we
presume is a bad thing
similarly we're fixing a bug make the
first change in October 2002 takes us
five months or four months I guess to
realize you know we should have made
this in a separate place as well so we
didn't actually resolve that bug until
four months later so you know these are
just two examples of yes you need to
know that clones exist because it can't
affect the quality of your system
so current approaches to actually
comprehending these clones as you can
imagine going back to the Linux example
four million lines of code 15 percent of
it is cloned okay that's an interesting
fact but that's not really actionable
you're not going to go through a
database a 15 percent of our code
looking for every single clone every
time we make a change that's not not
reasonable so you know one approach to
helping people comprehend these things
is to provide a visualization so when
you're making a change allows you to
quickly kind of get a feel for am i
working in a piece of the system that
has clones and has a high concentration
or low concentration of clones and you
can see here a typical visualization
which your milage certainly may vary
with the scatter plot you know the tool
actually does allow you to kind of zoom
in and click on things but regardless
you're getting a very coarse
coarse-grained view a system-level view
you're not getting an actual well here's
a piece of source code I'm working on
and here is another piece of source code
that's related and I can look at the
relationship all I can take away from
this really is trends and
characteristics of the system in general
and it's hard for me to even say what
that means I know that a diagonal line
of dots means there's some clones but
that's about all I can tell you about
that so a different approach is to
categorize these things and try to take
that again going back to the Linux
example take that 15 percent of code
clone and our flowed cloned code and
abstract that even further such that we
can actually have actionable information
that is usable in our day-to-day
activities so people have looked at
three basic ways to categorize these
things and let's take a look at the
image first here we see clone classes or
clone groups so for example clone class
one there is four code fragments that
are clones of one another and what we're
done here is you know we're grouping
these different flow
or categorizing these different clone
groups kind of clustering them together
and trying to say that the clones in
clone class 1 and class 2 and class 3
share some property and you know so
we're just trying to abstract
information at a higher level view and
one way to do this is lexical properties
and I'm gonna stretch the definition of
lexical here and say that you know we
might categorize these things based on
these clone clones and clone class 1 are
found in the same directory as those in
clone class 2 and 3 in the same file
things like that people have also looked
at syntactic properties all of these
clones in a particular category as shown
here might have involved a for loop or
involve some other program structure and
finally semantic properties and here
we're talking about a different kind of
semantics we're talking about human
semantics so that is all of the clones
in one category might have the same
identifier name present and that
identifier name right might represent a
type or a method you know but the idea
is that if the same identifier appears
we're referring to the same concept and
it may be useful to know that that
concept appears in clone code and in
different places throughout our system
so the semantic properties is actually I
think the most promising research in
that you know other than finding that
you know this particular directory has a
lot of cloning people have actually
found some interesting interesting
relationships using semantic properties
so for example in a study of the Windows
NT kernel some researchers who were
actually now at my institution they
weren't at the time they did the study
they discovered that you know there's
different I think 3 or 4 distinct ways
to allocate a particular memory for a
particular purpose in the Windows NT
kernel and so because of the you know
the use of the same identifier name in
the different methods they actually
found that okay we have clones of this
allocation method in clones of this Alec
ocation method and clones of that
allocation method but actually they're
all doing the same thing and we
discovered that via simply the use of
the same identifier I'm in the different
sets of clones and you know the
advantage of this is other than that it
kind of you know identifier is very easy
for humans to comprehend easier than say
program dependence graphs it's also
fairly lightweight computationally
particularly in comparison to some of
the some of the other techniques so any
questions is this is this pretty
straightforward okay so now I'm going to
talk a little bit about what we're doing
currently at Tuscaloosa this is a
National Science Foundation sponsored
project we're actually in the first
really in earnest we're in the first six
months of the project its three-year
project so this is just kind of where
we're going what we've been doing and
what our plans are so what we want to do
is create an analysis process that's
automated first of all so I mentioned
those results in the Windows NT kernel
the clustering was automated but the
discovering what the cluster was telling
us that there were three different
allocation methods that was done
manually so just by inspection so we
would like to automate some or all of
this and we want to use structural
properties as opposed to simply lexical
syntactic and semantic and on the next
slide I'll show you exactly what I mean
by structural properties um but we also
want to use these semantic properties
because there is some promise there and
in particular we want to combine the two
using structural and semantic and we
think that'll actually help us do some
of this analysis an automated way that
was previously done manually so the
major tasks we have are figuring out how
to structurally categorize different
classes or groups of clones improving on
current techniques that do semantic
class or categorization and actually
combining those two and then doing
empirical validation of all of this and
empirical here in the
so actually studying humans using these
different techniques within their normal
workflow and seeing if we're having a
positive impact it's easy to say that
you know what we're doing is better
because you know we have a bunch of
numbers but that's that's different from
actually being useful so task 1 the
structural categorization is actually
something that I'm leading
Mike and I are currently working on and
here we want to use static basically
static program representations that that
okay that uh sorry static program
representations that have to do with the
the structure of the program three basic
types of program representations that
we're going to look at our flow graphs
so things like call graphs which encode
caller Kali relationships control flow
graphs which again they're just what
they sound like they kind of represent
the flow of control through the program
will look at dependence graphs including
data dependence graphs and control
dependence graphs program dependence
graphs as I mentioned earlier and class
graphs and this could be you know we'll
start with class diagrams you know what
are the relationships among classes and
how can we you know use those to
discover interesting properties of our
clones and we actually want to to help
automate this process if we want to
define metrics for these different
program representations that capture how
they're similar you know how an instance
of this call graph is similar to an
instance you know separate instance of a
call graph and how they're different and
you know a lot of the research for
example on call graphs has allowed us to
compare to call graphs and say you know
do they contain the same information but
that's different from actually capturing
to what extent and in what ways they're
similar and in what ways into what
extent they're different so that's
actually you know a reasonable
reasonably difficult challenge that
we're going to be dealing with
this just shows some of the different
program representations we'll be looking
at I mentioned call graphs control flow
graphs different dependence graphs which
are along the bottom you know
interprocedural control flow graphs
which you take a control flow graph for
a method or a function and link them
together using the calls you find in the
call graph so on and so forth
okay task two is primarily being carried
out at UA Huntsville although I'm
participating in this and I think this
is actually pretty interesting stuff if
you've not if you're not familiar with
this so this is kind of really kind of
creating a search engine a clustering
engine for or sort our source code so
I'll go over the process in a moment but
basically the first thing we're going to
do is is take the the study of the
Windows NT kernel and replicate it using
a different information retrieval
technique some preliminary research
recently has discovered that latent
semantic indexing which is a very kind
of lightweight information retrieval
technique is is effective at capturing a
certain dimension of your data but
latent darish lay allocation which is a
probabilistic method is a little more
advanced a little more heavyweight
actually captures a separate dimension
of the data so first of all comparing
yeah so just comparing the performance
of these two techniques as well as
looking at combinations of these two
techniques to try to capture you know
both distinct dimensions that that we
believe these techniques are capable of
capturing and we want to augment the
structural categorization using these
information people techniques and the
semantic properties so again we want to
integrate these techniques in both a
serial and an integrated manner so we do
structural categorization then semantic
vice-versa and then integrate them in
such a way that every time we
we have a decision we were going to make
in the structural categorization we also
consider some of the semantic
information and that's pretty far down
the line we don't really have concrete
ideas if some concrete ideas but not
many about how we're actually going to
do that that's actually a hard problem
but the process here the generic process
for kind of clustering source code based
on the identifier ziz it's simple but
it's it's actually been found to be very
effective so we take our source code and
in our case we'll run it through a clone
detector to get our clone groups and
then we will do semantic extraction on
this clone group so we'll get you know
documents that represent each clone
group where a documents just a list of
words you know a list of identifiers
that appear in those different clones
and those identifiers could come from
again type names variable names string
literals comments etc so we're gonna
create these documents one for each
clone group and put them through an
analyzer that implements the particular
information retrieval technique again
LSI is a pretty common lightweight one
the way that works is you create a term
document matrix so you have your
documents along the top of a matrix and
each term that appears in any document
as the rows and you put some weight in
each cell it could be 0 or 1 if the term
does or doesn't appear in the document
it could be you know for if this term
appears four times in this document or
it could be called a it could be term
frequency inverse document frequency
which tries to weight you know the
number of times the term appears by how
common it is across all documents in any
case this is pretty simple we just
create the matrix run singular value
decomposition over it and we basically
have a bunch of vectors and we can take
the angle between the vectors the
smaller the angle the more similar two
documents are so to clone groups are
most similar if the angle between them
is 0 after we've done this LSI process
the LDA process is probabilistic it's a
it's a bit more complex and expensive to
compute and a bit harder for
me to relay because not a math person
there's lots of Sigma's and pies and
various at one time I could have
understood it but maybe not anymore
anyhow it's just an alternative method
for coming away with a model that we can
use to compare two documents or in this
case clone groups to say you know how
similarly similar they are in terms of
the identifiers that are used and that's
really the clustering part is going
through comparing all our documents
pairwise and determining which ones are
similar within some threshold and again
the threshold is something that you know
you have to determine at this point
basically ad hoc and then see if it it
holds across different software systems
that's kind of where we are with this
research we being the general community
so this is semantic categorization this
has been done to some extent but we're
looking to improve it by using different
combinations of information retrieval
techniques challenges for these first
two tasks one kind of mundane challenge
is actually mapping these code clone
results to that back to the original
source code these Koplin results for
example token-based they give you ranges
of tokens in a particular file and then
you have to go figure out well what did
they consider tokens and on what lines
do they appear and it's not a difficult
problem it's just annoying more than
anything else and then when you move to
okay well let's look at a different tool
and now we have to analyze its results
and try to map that back to the source
code it it's a challenge in that it's a
lot of work not in that it's terribly
difficult a difficult problem here is
how do we handle code fragments so in
particular we're building a static
program representation for a code
fragment most of these analyses that we
use to create these representations are
designed for whole programs so do we
create the whole program representation
then try to extract the piece for the
code fragment
or do we try to compete it directly on
the code fragment and then once we look
at you know you know computing a metric
do we compute that metric on the whole
program graph and extract that I mean it
seems like it would lose meaning without
that context how do we alter it to to be
more meaningful in a code fragment
context these are actually fairly
difficult problems and finally
integrating these distinct strategies
combining structural and semantic
categorization again it's not entirely
clear how you do this for example if
you're looking at call graphs and you're
categorizing based on call graphs you
know one obvious thing to do would be
say well all these clones in this group
and all these clones in this group call
the same method or they call a method
that calls a common method and how do
identifiers fit into that or do they
and how do our results differ across
different software systems and can we
kind of characterize different software
systems to say that yes this combination
will or won't be effective based on
again some metric so these are fairly
difficult problems numbers two and three
here and then of course we have to
evaluate these things so once we get
these presumably different categories
than we did with a with an existing
technique how do we actually show that
our categories are better in some way
more meaningful more useful and and
that's where the human studies come in
so so far we've actually done some
preliminary studies with students
graduate students at both UA and UA
Huntsville we've also done the study
with professionals we have a Research
Center affiliated with our department in
Tuscaloosa that has about 30 full-time
staff and in Huntsville a lot of the
students are actually professionals
working on you know for defense
contractors and such so basically been
studying them in terms of you know how
do they use clone information and what
can we distill from the clone
information that would be useful to them
and perform
various tasks we're actually Beverly is
in the process of analyzing some of this
data from the study we did in the spring
at the moment she's loving it so the
goal here is to go beyond anecdotal
evidence and actually get some you know
observing developers in the context of
performing a task and being able to you
know qualitatively or quantitatively say
that yes this did or didn't help in to
what extent so finally progress where we
are we've been working on structural
categorization based on call graphs
initially the next step will be control
flow graphs which might be the first
time Mike's heard this that that's the
next step and we've been doing some
comparisons with LSI and Lda and in
combinations of those and we'll also be
looking at combining those in a serial
process with the the call graph
structural categorization and we did a
preliminary study a human study it was a
bug localization task and we provided
some clone information and trying to see
how people used it or if they used it
and we actually have a related project
going on with my other PhD students is
looking at coke load management
techniques and this is actually pretty
interesting stuff so people have come up
with okay we detect the clones and maybe
we analyzed them and have some way to
make that information more useful but
now day to day I know about the clones I
can comprehend them but you know how am
i managing those am i doing it
interactively such as you know I'm in my
IDE I add a clone you know does it
detect that and pop up something I mean
stored in a database I don't know you
know if I change some code and I no
longer have a clone because of that
change or you know the type it was a
type 2 clone now it's a type 3 clone you
know how can we you know people are
looking at how all this information can
be used in an interactive fashion other
people are focused on what we're calling
reactive
techniques so that is every time we have
a code review or every six months we run
a clone detection tool and we you know
make some adjustment based on the fact
that we do have clones or we don't have
clones we have this many and then we go
back to presumably you know not caring
about the clones until the next time we
react and run a code clone detection
tool and finally proactive and this is
where this could be a reactive or an
interactive technique can be proactive
and this is where we find clones and we
we kill them we refactor them away and
this used to be originally this was the
idea we find clones and they must be bad
so we removed them and lately that's
been called into question I mean the
most obvious case is we had a clone but
it was necessary for performance reasons
you know we can't afford that that
function call an embedded device so
that's led to people thinking more and
more about when is a clone good and when
is it bad and that's a that's a hard
question to answer it depends on context
it depends on the particular system and
the properties of that system but people
are looking at this and trying to build
evidence for you know how we can look at
a clone and say yes it's good or bad or
even can we do that so my PhD students
actually he did a big review of all the
literature came up with these this kind
of taxonomy and he's actually gonna look
into interactive code clone management
techniques because he thinks that's the
most promising so thank you for your
attention and if you have any questions
or comments I'd be happy to address
those or talk about those at this time
yes
sure
okay so first of all let me give proper
attribution I didn't do that someone
else did in the literature just to make
that clear in case this comes up but you
know that the tool they used was CC
finder and it's token-based and actually
you know token based techniques are
pretty quick because there's not a lot
of pre-processing we're just tokenizing
and then we're just moving we you know
we take a token stream that represents
one code fragment and all the token
streams that represent the other code
fragments and we just kind of move the
window and say yes or no
still costly you know probably talking
about hours rather than minutes there
but they have implemented this
distributed version of it and that
obviously runs a lot faster you know
because we're doing a lot of pairwise
comparison we can parallel lies a lot of
this you know it tends not to be the
case because these are academic
prototypes but but you know some people
have looked at that it is it is possible
now when you get into tree based
techniques depending on how you're
comparing the trees you can get you know
in terms of days there although again
people have looked at some work at UC
Davis they actually take the sub trees
and they compute a hash value you know
that's unique for each subtree and then
they do comparison of hash values and
that you know still slower perhaps than
token-based because we are parsing the
source code to begin with but you know
not the worst
sure I think a bigger issue is at least
to me is okay yes we can go out and
detect all these things and now if we're
looking at interactively managing these
things we have to have something that's
reactive in an IDE and you know these
data sets at least to me can be pretty
you know pretty unwieldy
sure
yeah you know it to be perfectly honest
you know I've done a lot of work with
with front-end systems for doing various
static analyses and it to some extent
amazes me how quickly eclipse or
Microsoft Visual Studio can work you
know a local manner you know having to
constantly recompute these syntax trees
and an update so anyway that's it's not
that much harder of a problem I don't
think are much more computationally
expensive than what they're already
doing yeah sure the other yes
sure yeah and you know yeah I think that
you know the goal here obviously is to
get this this stuff integrated into you
know all these development tools and you
know every people's everyday processes
you know the reason I decided to present
some of this today rather than my work
on grammar engineering which has to do
with refactoring context-free grammars
based on metrics is is that I think this
is more you know this is more mediate in
terms of this is stuff that can be
integrated kind of now if we have the
tools as opposed to some esoteric
research thing that it's kind of
interesting but not particularly useful
in day-to-day context
well thank you very much for coming I
appreciate your attention</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>