<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GTAC 2010: What Testability Tells Us About the Software Performance Envelope | Coder Coacher - Coaching Coders</title><meta content="GTAC 2010: What Testability Tells Us About the Software Performance Envelope - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GTAC 2010: What Testability Tells Us About the Software Performance Envelope</b></h2><h5 class="post__date">2010-12-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1keyEiJHqPw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">boarding everybody
my name is Bob bender I want to talk to
you this morning about testability the
title of the talk and the general
structure of it have changed a little
bit from the what's in the announcement
so but don't be worried it will be
pretty much the same content just the
story's going to be told in a somewhat
different manner so what I'd like to do
is to talk a little bit first about why
testability matters or at least why I
think it matters look at two dimensions
of testability from a kind of high level
perspective it's i'm going to call them
white box and black box talk a little
bit about the role of test automation
and what it plays in terms of
testability and then try to draw some
conclusions about strategy and how we go
about the process of doing testing
designing tells running them and then I
think we'll have some time at the end
for questions and answers so why does
testability matter basically I look at
the testability from an economic
perspective let's start with a few
assumptions and software sooner is
better than later buggy escapes are bad
fewer tests again other things being
equal means more escapes and in testing
we have a fixed budget so the question
is given a fixed and finite amount of
resources of course I don't know maybe
Google maybe things are different here
this is the perhaps but but seriously I
think that in most circumstances we have
a project with a deadline and a finite
amount of time and resources ability
hours of the day people etc and so the
question becomes how can we put that to
best use and in terms of testing the
issue with testing is we want to
contribute value by improving removing a
defects from the system and perhaps some
of the knock-on effects the secondary
effects of that that it often happened
doing good testing so for me testability
is basically the thing that
limits on our ability to produce a
complex system that has an acceptable
risk of costly or dangerous defects
there are two dimensions of testability
effectiveness and efficiency which I'll
come back to later on it towards the end
of this but this basically if you look
at the total cost of doing the test
that's all the resources that are
consumed in doing testing you divide
that by the number of tests for me
that's the average efficiency and when I
look at this it's not just the time that
you might spend first writing a test
object that a mock for your your source
code it's everything that you have to do
afterwards and that somebody else might
have to do or can't do because of the
way things have been done an
effectiveness is the average probability
that when you run that test you'll find
a bug hopefully that's low but not zero
at least starting up so you know other
things being equal higher testability
means more better tests at the same cost
lower testability means fewer weaker
tests at the same cost what makes a
system under test testable and
classically there are two dimensions to
this controllability and observability
this goes back to hardware engineering
digital logic design hardware guy
started working on the testability
issues a long time ago especially the
sort of this was driven by increasing
miniaturization so when you went from
LSI large scale integration to vlsi very
large scale integration several order of
magnitude more circuits on a piece of
silicon and then now today's sort of you
know nano scale wires that are in the
computers were all using you know you
couldn't just stick a probe in it right
the wires are too small it wasn't like
you know the old breadboard where you
had everything exposed and hanging out
so in order to determine what was going
on within a circuit you had to have a
way in which you could controllably
observe what was going on inside of a
system and to make a long story short
about this there's a whole standard for
this it's called the jet or jade
standard is on every basically every
chip that's made there are four
additional wires that come in and out of
it that allow you to do testing so the
idea of controllability observability at
least my perspective they have this kind
of roots in hardware engineering
controllability readings what do we have
to do to run a test case how hard is it
how expensive is it does the system
under test make it impractical to run
some kinds of tests there may be
questions that we'd like to ask might be
a scenario we'd like to evaluate because
it's likely to occur in the real world
but it may be that in our test
environment that's prohibitively
expensive we're just technologically
infeasible I'll give you some examples
of this later on given a testing goal do
we know enough about the system its
behavior in it's likely environment to
produce a test which is realistic and
meaningful now you might say well well
sure how is it how hard can that be well
if you think about it let's say our
testing goal is we would like to cover
all the requirements of our system at
one test for each well sort of that
presupposes that you actually have
requirements how many of you've ever
worked in a system where you had a full
set of requirements yeah so the
knowledge that we have what we begin to
approach our testing with and what we
drive our design of test cases is really
a factor in testability and how much too
late by the way can we afford to achieve
controllability so these are all kind of
factors that influences observability
has kind of a symmetric relationship
what do we have to do to determine
whether a test has passed or failed
again this may seem simple and when
you're talking about you know
straightforward unit testing where
everything is kind of on your desktop
and under your control and it's a nice
well-organized sandbox you know it's not
so hard to do but the testing that I'm
sure that many of you are involved in
large distributed systems it's not quite
so simple and again the questions are
how hard or expensive is it to achieve a
particular kind of testing and does the
system under test such as the way it's
structured or
designed make it hard or easy to do this
can we easily find the information we
need to determine whether a particular
situation has occurred or not do we know
enough to determine pass/fail or did not
finish here's a fishbone chart that I
first produced about 15 years ago I got
interested in the subject testability
for a number of different reasons the
story is not terribly important anyhow
so I looked at all the factors in this
and this is kind of what i came up with
now for those of you that don't have you
know 1000 x 1000 vision here's the short
form testability at least in that
initial analysis for me had six basic
factors each of them had a lot of
separate individual things that were
drivers today I'm going to focus on
basically on a representation
implementation into a certain extent
test tools I'm not going to talk a whole
lot about process how the test suites
are organized I'm also going to talk a
little bit about built-in chest this is
there's an article in this you can read
it at your leisure if you like the
reason that I put this up to take away
there is to say that testability is not
a sort of single at least in my mind is
not a single dimensional issue it's it's
really there's a whole web of forces and
factors that influence whether or not a
system in your particular context is
testable let me give you some examples
from personal experience of systems that
I've worked on and the issues and
controllability and reserve ability that
I've had to wrestle with and trying to
create tests for these systems well
buoys everybody deals with GUI sooner or
later it's basically impossible to test
the GUI other than manually interacting
with it without some abstract widgets
set get if you do by having a blonde you
have a commercial tools such as you know
HP's winrunner or something of that
nature or a selenium if you're using a
a web interface it's great it does a lot
for you but it's also brittle this is
the curse of capturing replay we all
know what the headaches are involved
there latency is another interesting
problem latency in terms of the
responsible system and also the think
time that users input impose in terms of
doing real interaction our testings
usually isn't very good at capturing
that so it's a controllability issue we
have a hard time actually dealing with
the variations in response and think
time dynamic widgets by that I mean
widgets which tended to find themselves
on the fly and then things that are very
specialized for which our abstract
setters and getters don't really can't
really deal with observability not
everything is as simple as a text the
text box where you can set and get a
string and figure out whether the string
says what you want there's structured
content there's lists in all sorts of
things and you know this needs to imply
some kind of notion of a cursor that's
not just the tester it's a position
within the data structure so can that be
established can it be manipulated to get
something out of interest there's a lot
of noise and non determinism not text
output graphical output is notoriously
difficult to parse you can't parse it as
text there's some very interesting and
successful attempts to extract
information meaningfully from you know
basically a bunch of bits that represent
a picture but it's still a hard problem
I think image recognition as a testing I
looked at this and a few years ago it's
a lot of interesting research proposals
but nothing was immediately a takeaway
at least as far as them and then there's
plenty of proprietary lockouts so
testing gooeys you know its
controllability observability even with
the tooling set that we have is a fairly
large industry that supports this you
know it used to be close to a billion
dollars a year it's still not that great
one system i worked on we had to
basically
drive a lot of exceptions out of the
operating system this is a UNIX platform
there were hundreds of exceptions that
the system under test could throw and
the the issue for us was whether or not
the application that we were testing
could actually catch them and do
something reasonable with them well we
had to generate them first so how the
heck do you do that you know how do you
force exceptions there are certain
things we're kind of difficult to get to
and then another interesting issue and
observability in this case was silent
failures so if you could force the
exception often time you know the
applications just say yeah I don't care
so we really had no way of knowing
perhaps other than just the absence of a
response whether or not something had
actually occurred that was as expected
my first exposure to object-oriented
programming was back in the objective-c
world so-called next world a very
interesting experience objective-c is a
highly dynamic language in which it was
it was common programming practice the
to define objects on the flight
two-footed to find the classes for those
objects on the fly so programs had this
is sort of feeling of writing themselves
well that's that's very interesting and
it also creates a lot of headaches in
terms of testing because you don't know
what you're testing what the testing
target is how to evaluate it and whether
you know it's remotely close to what you
want and then these things tended to
sprawl out of control so the source code
that you looked at was nothing like what
the actual implementation was there was
a problem trying to instrument objects
on the fly how many of you worked in
mock objects in a system that has a DBMS
or it's a database or large data store
behind it okay so you know as they say
how is that working out for you this
sometimes can be quite challenging we
may just want to take a little bit of a
piece of functionality away from a
database for our particular application
it may turn out that you know right in
the mock object in some senses as a
project similar complexity to
constructing the database management
system itself system I worked on a
number of years ago was a multi-tier
core by appliqu
patient and we had a real challenge
getting all the distributed objects to a
particular desired desired state to
achieve a particular test so this was
this was what I referred to as I tried
to describe the problem to people in my
family who were not software you know I
really didn't know much about it who
didn't want to I said well it's like
this suppose you were you know you had a
dog act you had six different dogs you
wanted to get them all up on the stage
at the same time perched on a little
chair and you know balancing a ball on
their nose and then barking out you know
Merry Christmas or something like that
it was comparable to that so there were
lots of issues in controllability there
and then we had some other interesting
things that went on in that and tracing
message propagation so when you have
distributed systems message propagation
and figuring out what happened and all
the points in the path is quite a task
another system i worked on with a
cellular base station and this is kind
of the ultimate non testability base
station is essentially it's a big radio
tower and the physics of radio
transmission are very hard to emulate so
you can't easily you can kind of fake it
out but there are certain things that
happen that are not easily emulated so
basically the best place to test the
cellular base station is to take it out
in the field and have you know 10,000
people pick up their cell phone and try
to make a call well that gets to be
ridiculously expensive and by the way
the customers are paying for the base
stations want the people make the calls
and not get them disrupted in the
process there are also lots of
proprietary lockouts in this and sorts
of other interesting things going on the
systems are never offline so the point
here is a controllability observability
you have some very real dimensions in
lots of different kinds of systems I'll
talk a little bit about some of the
dimensions that would come to us from
the implementation things that drive
complexity or drive the testability in
the
implementation our complexity and non
deterministic dependencies what I call
ND DS things that help us our points of
control and observation built-in test
state helpers in good structure by the
way I'm not going to claim that this is
an exhaustive list but it is what I'm
going to touch on today and just to give
you some sense of what what things you
have to pay attention to before we do
that mud go much further into this when
I introduce just a little bit of theory
about testability and I hope I'm not
taking away from what another speaker
later who basically helped to define
this theory some years ago Jeff often
will say but to reveal a bug a test has
to do several things several things have
to happen have to line up you have to
get the the buggy code to execute you
have to trigger their bug in that code
location and executing a picture piece
of cody but if it has a defect than it
is not necessarily mean that it fails
when it does fail we have to propagate
the incorrect result is something that's
observable there has to be an observer
of the incorrect result and the
incorrect result must be recognized as
such by the observer so you say well
yeah gee that's all kind of obvious well
in a sense it is but it's there's some
kind of interesting takeaways from this
here's a trivial fragment of code this
is an example devised by Geoff Bowes
many years ago and here in the bug in
this is that you know it's the kind of
thing that I used to do all the time you
know I am wrong operator so I should
have an addition instead of subtraction
but I did anybody want to guess what the
test cases would reveal this bug suppose
you didn't know that so no cheating
what tests would you have chosen to
exercise this method well it turns out
that we could do exhaustive testing on
this there are about 65,000 possible
inputs and those are the only three or
six six yeah six test cases which would
reveal this bug out of those 65,000 and
if you chosen one the number one which
is kind of an obvious choice and a lot
of testers soon well it's no we should
at least do that sorry you wouldn't find
the bug show zero well you're better
lucky you have you better luck there so
this is a kind of very low level a
notion of testability but it's an
important one it's where basically the
idea is what is the sort of propensity
of code to hide bugs others wanted when
it's wrong how easy is it for us to
determine or write a test that shows
that it's wrong and this example is
somewhat contrived but it's one that
indicates that there are plenty of very
simple circumstances where the answer
that it's pretty darn hard to get those
to find those those problems so what can
we do about this well we'll come to that
later here's another one I couldn't find
any good dancing dog pictures but I did
find this one of these dancing hamsters
somebody really got busy with Photoshop
on this it wasn't me this kind of
suggests to me what is these sort of non
deterministic M&amp;amp;C czar race conditions
these are classic ones message latency
threading all the wonderful things that
can happen when you use threading in
your applications and create replace
update delete the typical operations
unshared and unprotected data sort of
all the stuff that used to happen before
we had databases sometimes still does so
these are basically things that we have
that are hard to control in an
environment an application may allow or
rely even rely on them they tend to be
things that can cause failures
intermittently
another kind of key element of
testability is the extent to which our
systems are complex Oh software
complexity is a subject which has lots
of people have said lots and lots of
things about I'm not going to get into
too much detail today other than to say
it is kind of critically important for
testability because the harder it is to
get to that each of those points in the
code the less likely you are to get
there and the less likely you are
therefore to see the bug there are two
kinds of basic complexity essential and
accidental essential complexity is it's
basically you have a big job you have a
big system so you can't get away from
that accidental complexity is what kind
of gets dragged in usually kind of
coincidentally because of technical
decisions and commitments there's a
great analysis of this called essential
systems analysis that was published in a
long time ago and made the same kind of
distinction usually we see some kind of
graph diagram or other other way of
representing complexity I thought today
you might like to see a somewhat
different one well
this is a well-known modern artist
Jackson Pollock who did some very
interesting things I find in looking at
this picture I don't know what your
experience is but as I look at it
there's something about it that draws
you in and that my experience in kind of
looking at it being drawn in is that I
can't quite figure out what it is and
then there's a sort of an echo to that
somehow well without getting too much
further down that path by the way the
music that I chose is one that
illustrates kind of complexity and
compositional structure in a similar
vein so I thought the this might suggest
the complexity is it's kind of a
psychological phenomenon testability in
our our ability to understand things and
then construct tests from that so think
about Jackson Pollock the next time you
think about complexity what improves
testability points of control and
observation state based test helpers
built-in test well-structured code I'll
talk a little bit about each of these
what's a pcl if you're familiar with
something called TTC n 3 this is a
notation and abstract notation for test
strategies and test harnesses for
protocol verification and basically
within it it has this notion of point of
control and abstraction and that's an
abstraction for any kind of interface of
interest so what we do have to do is
testers basically to activate component
and an aspect you know what components
are what's an aspect well you may have
heard of this it's a notion that says
there's some slice of functionality
within a system that may not be it may
not map cleanly onto a component that's
an aspect these are things actually the
quite often we're interested in testing
aspects usually are more interesting but
are usually not directly control
so for example performance the ability
an assistant to respond or its its rate
of consumption of resources is an aspect
they're typically is one interface that
you need to touch to evaluate
performance what do you have to do is a
test or creating your test harness to
inspect the resulting state traces are
one way of doing this but they're often
not sufficient or noisy at least traces
that are designed for other purposes
besides testing embedded state observers
which will spend a little bit of time
kind of sketching for you in this
morning are often effective but they can
be kind of expensive to do and some
people complain that they're polluting
so aspects are often critical but
typically not directly observable so our
design for testability this is like
going back to that large scale
integration where I can't put a probe
into a you know a way for a silicon that
has a nanometer wires in it design for
testability is to determine requirements
for asking aspect-oriented points of
control and observation and build those
into your system so ask yourself in
advance as you're doing the system what
are the aspects that I care about my
customers care about and how can I
observe those and how can I put
something into my design which allows me
to easily evaluate those one thing along
that vein might be state-based test
helpers I was very interested in this
subject the number of years ago and and
and wrote some collected some patterns
about doing this now basically to do
state-based testing you need to do
several things you need to be able to
set the state get the current state of
whatever it is you're testing and then
use something that I've called the
logical state and variant function or an
else if you also typically find it to be
useful to do a reset which means to take
the system under test back to some
starting state all the actions and
events should be controllable and
observable what does this look like why
are we interested here is a
implementation model of a
part of a system that supports a
three-player game two player game 3
player game of a racket racquet game
similar to racquetball or tennis or
squash the bottom is the state chart
that might result then when we show what
to do for three-player game as an
extension of the two-player game the
test model is somewhat different the
test model is we want to test
three-player game we need to consider
the aggregate behavior not just this
individual unit but of the the entire
unit so that takes us to producing a
test model that's called a flattening
machine so flat state machine looks like
this and it takes into account all the
interactions now we can then produce a
test plan for this there are many
strategies for doing this this is one
that I like and what this does is
basically it traces out all of the round
trips within the state machine which
will take you from one state and then to
another back to the same luck if we have
K events and end states with logical
state and Varian functions that's
basically K times n tests on the order
so it doesn't explode which is good
right if we don't have any logical state
invariant functions and you really want
to know what the resultant state is so
that is at the end of the test you say
ok I did this I did this I did that and
then is that what happened did I get to
the player two states served is that
actually what would occurred the
scheduling of processes and management
of resources to check all those things
so they had a real controllability
observability problem the strategy was
to add prayer into every class in the
system and invariant function they call
it sanity checking the invariant
function would basically call another
function which is globally allocated to
determine whether or not the state
the conditions the invariant conditions
of that particular object were met and
very a check could be had some very
simple global settings one of which was
that it could be the number of times
that it actually fired and spent the CPU
cycles do there to do its checking could
be scaled from basically once in every
256 times it was called to always so you
can have a way of kind of randomly
sampling as a system stabilized you
wanted to dial that down you wouldn't
have to check everything perhaps an
earlier earlier releases when the things
are still unstable you do relatively
more checking then there is a kind of
clever trick John some of you may may
use it's a combination of constant in
line this is a C++ City I'm idiom which
basically causes no object code to be
generated without any changes to source
code so because this is a ship product
and they didn't want to lead the
instrumentation in and they ship the
actual operating system but they didn't
want to futz or the source code because
the risk of reducing or introducing
regressions this is a very clever
strategy we actually took the same
strategy and built it into the system I
most recently worked on was a test
automation system will use this and it
was quite effective the percolation
pattern basically is designed by
contract for class hierarchies and this
is a way of enforcing compliance with
something called Liskov substitutability
that simply means that anything a base
class does that subclasses should do
only less up if you implement this kind
of with a no code left behind you have a
way in which you can be sure that with
these additional functions that the it's
kind of a check a runtime check on the
consistency of the extensions to the
class hard work so you can do some
pretty sophisticated things with
built-in test the issue here is of
course you know is it
worth it when you put the effort into
built-in test you put it in once and
that it's there and it works so i would
say that when you have the opportunity
to do things like this is it's at least
worth thinking about well structured
code this is a subject which you know
there's there's a lot been said about
this the many well-established
principles i won't delve into that there
are several that turn out to be fairly
significant in particular for
testability here's one no cyclic
dependencies this is a cyclic dependency
is where a calls be be call see see
calls a that's a cycle those are bad
don't do that y in terms of testing it
means we have to basically take all
three of those parts everything within
the scope of the cycle and test it as a
unit and then doing state said and get
on that to bring the something that
participates into a cycle to a
particular state may be difficult
there's an idea called level ization
john lycos has a great book about this i
recommend that too if you're doing c++
development basically one of the
takeaways from that is to not allow
static dependencies to leak across
functional or package boundaries so
something that is performs a a a
function at let's say one level the
stack should not reach up through
another level of the stack through a
static compile time dependency and make
it do something else and then this this
is one which is kind of general but
really very powerful for testability is
to partition classes and packages to
minimize interface complexity so as your
dive designing deciding what goes into
where and what the facade is and what it
looks like and you have several
alternatives for that choose the one
which minimizes class complexity
alright so that's a lot let me ask you I
could maybe I'll just take a moment here
and take if there are any questions at
this point on what we talked about so
far Sam that's right I happen I'm
curious how you increase control and
observability without increasing attack
surface from a security standpoint I
think this is a trade off any my I don't
have a good answer for that I think you
necessarily increase it so it is like
putting in a back door and if somebody
else you know the bad guys find out
about it they'll probably break it in
and do something so it's definitely a
concern that's one of the trade-offs
that's involved in doing this yes sir
hey did I miss you so at least in my
experience in terms of testability there
are very good points and thoughts most
of the time when we do when we think
that we have done quite a lot of like
you know improvement in the testability
the time we measure we always realize
that like no still there is a long way
to go I'm just wondering whether is
there anything covered in the slicer is
going to be there in terms of how do you
say for example you talked about the
states right I'm sure we all would
design a test assuming that most of this
are covered but some of the transitions
which you would have not thought about
it later on you realize that you have
not covered at all so is that a way of
finding these because the challenge
itself is like no we always assume that
we have done a better job but then we
realized that there is a there is
something new to it we have never even
thought about it so how do we
find these well if I understand your
question you're you're saying you know
how can we have confidence that our test
Suites your test strategies are complete
yeah and also is there any measurements
which you could always suggest as saying
like you know these are the we generally
talk about the code coverage the
condition coverage and some of these is
that in and sometimes we always say the
code coverage is fine but we are not
able to achieve like you know a better
condition coverage and things like that
so do you have you have anything which
would which would add more value to the
basics what we are talking about
something we could we could also explore
more well yeah so this the question is
what what kinds of additional criteria
might we consider beyond code coverage
metrics to help us have confidence that
our test suites are complete there's
there's no end of coverages so you know
if you want to go and invent some new
ones you know a bit be my guest the
whole point of coverage is to take up
with with respect to a particular
testing goal and say how much of it have
we done how far how close we've gotten
to that and what why do we have testing
goals well because we have some
intuition or a suspicion at least that
that is related to finding bugs so
underneath every testing goal is a
sumption that says i think if i look
under this particular rock there's more
likely to find we're more likely to find
bugs so I would say it depends on the
particular kind of system that you're
looking at if you want to develop more
specialized the kinds of criteria you
should look to that system itself and
things in it that you are uncomfortable
with or that you're not certain about or
where you know you said we're putting
this thing together we'll do the best
that we can we had the punt on this one
we don't know you know so if there are
areas where
you have a either subjective or proven
risk known risk of higher subjective
assessment of likelihood of a problem I
would then ask a question how what can
we do to try to identify problems given
that assumption and then go after that
so make up your own coverage criteria
all right I'm going to get back into
this I wanted to just kind of change the
pacing a little bit here it's a lot a
lot of stuff one last question yes sir
so I think you started out the
definition of testing as a economics
definition I think what you just alluded
to is it's all risk assessment and how
much time you have there's no magic
thing to that I'm sorry to say again
what's the question oh good comment okay
all right just supporting your test
ability as a economics right it's it's
just in engineering but you're an
engineer and you don't like talking
about money because money is dirty then
you can just say it's trade-offs so
you've been gotten an absolution there
okay black box testability factors that
decrease is this is looking at a system
from an external perspective sizes nodes
variance in weather weather what the
heck is that to tell you in a minute
test model Oracle and automation again I
don't don't claim that this is the
complete inventory of the things to
think about but it'sit's ones i think
that illustrate some of the things to
think about system size so in terms of
the kind of all the technical
interesting technical things about
systems we can talk about the drive
testability one that often i think is
not often mentioned is how big is it it
is a huge system obviously it's going to
take more work to test and my economic
perspective of what testability is that
means if i assume i have a fixed amount
of resources to do it other things being
equal i'm going to be able to do less
testing so the larger the system
more complex it is the less that
basically intrinsically lowers its
testability my perspective all right so
how can we scale systems there's there's
many again many many metrics you know
choose to choose the one that you like
best here are some fairly common ones
that are well understood use cases
single Ian vocal menu items a command
sub command structure another one is
computational strategy some systems have
you know most of what they do is sort of
visible at the the boundaries some
systems most of what they do is is
hidden away so if you look at
transaction processing system that's
mostly visible at the boundaries if you
look at something like simulation I
worked on a for large oil company a
reservoir simulation system which
created huge finite element models and
did lots of mathematics on that to
basically simulate the behavior of
underground oil and gas water reservoirs
it just chugged away for weeks and weeks
and weeks you got maybe a hundred two
parameters that started the simulation
going and then I ran and you know
several weeks later you got either a
report or in some cases a picture of
what the things look like the
underground or at least what their best
guest was most of the work of that was
in what was going on in those
computations video games are another
interesting area where it's kind of the
surface of that and how you sighs those
is has its own unique dimensions another
way of sizing a system is storage how
many tables how many views what are
those what are the things that we put
into it and look at what about the
extent of the network how many
independent nodes do you have to get
going so that's how many dogs do I have
to line up on the stage and make them
bark out you know jingle bells client
server systems it's simple it's too okay
at least two maybe a lot more depending
on what I want to accomplish n tiered
systems of course we could have division
of labor across different kinds
servers and computers and then we have
peer-to-peer systems this example is
from one that I've worked on recently
it's the basically explanation of the
Microsoft implementation for two-phase
commit and it takes five computers do
two-phase commit so in our test lab this
is actually fact not fiction in the test
lab we actually had five computers that
each perform those roles if you want to
get a little more formal about this and
you like my like modeling and
mathematics you want to find the minimum
spanning tree or at least one minimum
spanning or one you want to find the
minimum spanning tree and you must have
at least one of those online so if
you're devising a large network system
and you have lots of nodes that have to
participate and you have allocated
functionality across those nodes what
does that imply for testing it means
that you're going to have to have a lab
where you have each one of each at least
variants this is another dimension of
the test problem that often does not
paid a lot of attention tool until until
you know several weeks before you have
to ship how many configuration options
are there configuration options
something usually you set once user sets
and set it and forget it but there's you
know lots and lots of them and there are
many possible interactions many things
that can go wrong how many platforms are
supported how many versions of Windows
will this run out does it run on the Mac
does it run on the you know which which
flavor of linux etc etc how many local
is a localization variants do we support
how many editions for commercial or
competitive marketing purposes each of
those is the combination and each of
those going to have interaction effects
and what has been at the commercial
software world knows that if you don't
test this stuff you will you will pay
dearly combination coverage one way one
strategy for picking the
combinations just do what's called
pairwise testing that basically means
tried to be sure that you do each one
with the other at least once it's not a
bad strategy actually it's very powerful
in terms of finding bugs worst case
would pairwise is basically a product of
the size of the number of options so if
you have five options of five that's
basically 25 tests at least there are a
lot of very sophisticated pairwise
selection strategies that try to
compress that without going into that
the number can be reduced with some good
tools for choosing the pair's but this
is another element of system testability
in size whether what I meant by weather
was environmental stuff stuff that is
the real world you know what your system
has to operate in and you have all you
can do is complain about it but you
can't control it the cellular example I
mentioned earlier cellular base station
we really had to struggle in that
circumstance to find ways to adequately
load the system without basically
fielding it by the time it got filled in
to customer had paid for it because each
of those cellular service stations was
about 10 million bucks each at least the
customers wanted to use them they didn't
want us to test them what about an
expensive server for I think Google is
an organization knows a lot about big
expensive server farms let's say you
have one that's going to support a
certain kind of demand a certain kind of
computing are you going to basically
have a second one that you dedicate for
testing or do you share it somehow
suppose there are competitor or
aggressor capabilities which are part of
the real world that you in your system
is to be deployed in how easily can you
replicate those in your lab we're trying
to do anything in cyber warfare this is
an interesting problem the internet of
course the way that I think of this is
like you can never step into the same
over twice in other words it's a little
bit hard to get recreated to recreate
circumstances when you're dependent upon
variable all the vagaries of the network
communication and suppose of course that
you have you made the main out of
experience perience this I have a few
times where there is no test environment
I worked in an early version that they
was then called the Chicago Stock
Exchange and putting in one of the early
for trading systems and there was only
one computer basically at the exchange
and during the day that ran the existing
stuff we couldn't shut it down and run
our apps on it because there were
literally billions of dollars are riding
on this machine and if it hiccup you
know there was there was a lot of grief
so we had the test from basically and
then by the time everything was wrapped
up after the end of the trading day it
was ten o'clock so we got the test from
about 10 to four a.m. in the morning you
know and just like Cinderella's coachman
and mice we had to be out of there and
had to have the system clean so it could
be rebooted for the production run in
the in the next day and there were
actually some times when surprisingly
the test system did something bad and
you know there was some some very tense
moments in getting that system brought
up the next morning so there are
circumstances where the production or
field test partner field system must be
used for tests and the kinds of things
that you can do are limited you can't
stress it one of the things I wanted to
do in mobile testing early on we went to
some of the tests under says look we've
got this great tool for you we're going
to put it on on the air and it's going
to saturate your cell tower he said no
you aren't going to do that so this is
what i mean by environmental factors and
the sperrys of course from one system to
another but it is part of the dimension
of testability so other things being
being equal a larger system is less
testable
you spread the same budget more you get
in it becomes thinner so here let's say
here's some hypothetical case 10,000
featured points6 network nodes 20
options 5 variables each it only can run
from 9am to 3pm in the afternoon how big
is that
well it's big I don't know if the
correlation here is exactly i did some
this is the m-66 galaxy and one pixel in
this picture is about 400 light years
and the distance across the solar system
the best estimate is is about 14
hundredth of a Lightyear so it's big but
you know if you start to think about the
number of states in a complex system and
the number of combinations of things
that we have to test pretty soon you get
up to astronomical numbers so while the
comparison is is somewhat for dramatic
effect it's not entirely specious the
other element of black box testability
is understanding what do we know how
much do we know about a system what's
our primary source of knowledge of the
system we are testing is it documented
is it validated or is intuited or guest
or perhaps it doesn't even exist yet if
you want a good place to start in terms
of requirements at least there are many
standards and guidelines for this i
triple e 8 30 is a good one it's kind of
old it's fairly simple but i still think
it provides a lot of useful guidance so
how do we know what we're going to test
how do we know what our system is
supposed to do besides just guessing it
have you ever had the circumstance where
you go into a room of other developers
and you think that you know what the
system is supposed to do and so do they
and after talking for 5-10 minutes you
get this kind of queasy uneasy feeling
like what the hell did they just say or
something that effect and then after
about a half an hour later everybody
leaves the meeting and you know
something something dramatic may happen
but we've known for a long time that
getting this shared vision of a complex
system is essentially the biggest
challenge in software engineering get a
room full of people 20 people working on
something extraordinarily complex and
difficult and they all have a picture in
their mind
I can guarantee it's not the same
picture it may be mostly the same but
it's not the same and then as Wiz
testers we try to say well which picture
is right which one should I believe the
tester then takes that and produces a
test model from that there are many
different kinds of test models you know
different strokes for different folks I
think having a test model of any kind is
better than having none test models may
be formal they may be informal etc etc
one distinction I like to make is are
they test ready or they kind of hints a
test ready model is one in which you can
commit to code or is already in code and
you can produce tests from or you can
evaluate tests against and then finally
do we have an oracle and i don't mean
the database company and oracle is a is
basically something which allows us to
determine whether or not a test result
is as expected or not in model-based
testing which is something that i like
and i do a lot of its it's relatively
easy to produce tens of thousands
millions of tests automatically in a
matter of minutes now the question then
becomes but if I run those tests what
happens can I decide whether the results
of running them or actually as I want or
not and if I can't the tests are not
very meaningful so do we have an Oracle
is it computable or as a judgment
sometimes the best that we can do and
oftentimes in circumstances it's a good
strategy they have a person interact
with the system and then judge decide
whether or not the system makes sense
finally let me say a few things about
test automation I'm a big believer in
automation I know there are other people
in the testing world who are big
believers in people I believe in people
that I believe in computers for certain
things the people are computers are
better than people in certain kinds of
testing tasks in particular in bigger
systems we need more tests automation
properly
used of course it can be misused gives
us intellectual leverage it allows us to
kind of extend our vision and
understanding across a very large and
complex space it's repeatable we can
scale up functional tests for load tests
than many other kinds of things there's
lots and lots of different kinds of
automation I'm sure that you'll hear
about different strategies in this
conference today and tomorrow I
mentioned just a few here is as far from
an exhaustive list model-based testing
again an area of my etre particular
interest does two things generates tests
and good model-based testing systems
also choose their models carefully so
that they can serve the purpose of
evaluation also finally why does test
automation matter this is a kind of
notional slide I don't claim that this
has any deep research behind it but it's
kind of the way that I look at the wall
if we look at effectiveness our ability
to create a system which is reliable
let's suppose that we categorize this
according to you no liability or
availability statistics 59 s from 195
miles basically means a system which has
about five minutes of downtime a year
one night as the boom a minute that is a
system that has about five minutes of
downtime a day we look at our other
factor of efficiency so if I can produce
a system that is 59 verses one that is
19 with the same with the testing
strategy I would say my testing strategy
is more effective if I can achieve
higher reliability at the same cost
productivity this is kind of the total
cost of tests per hour how many tests
per hour or per cost or whatever your
unit of measure is can I do and my
experience in manual testing we're in
this region where we can get probably
about two nines so a system that will
run for several weeks without burping
seriously and we're going to get on
average about one test and hell and I
take into this my experience in total
cost of testing not just the first time
that you write the test but when you
come back to it later and you have to
maintain it and Faye
or throw it out and start over so it's
kind of the total cost that along with
everything else so if you took all the
inputs economic and otherwise that's
what I'm talking about here of course
any any reasonable tester can do more
than one test an hour and I'm saying
that on average that's about what it
ranges with scripting both of the kind
of gooey capture replay as well as unit
based testing with the various test
frameworks we can get about an order of
magnitude better productivity and in my
experience this this helps us find other
things being equal about another notch
up and bugs my own experience in
creating model-based testing systems for
specialized purposes puts this up I
claim hey I do have some data to back
this up that we're able to achieve two
orders of magnitude better productivity
in terms of number of test generated per
or economic cost of producing them and
at the same time the tests were much
more intensive fraud and reached into
parts of the system that we could not
have done or imagined as kind of doing a
simply manual or let's say traditional
kinds of testing I worked on for the
last several years in model-based
testing vision which unfortunately is
incomplete but my intent was to take
this because this had a lot of whoops a
lot of kind of hokey limitations I did
what customers wanted so I you know was
on their nickel and didn't do all the
things that I want it but I believe that
model-based testing properly understood
can get us to some what might seem to be
kind of fantastic levels of efficiency
as well as effectiveness so the kind of
test automation that you have is a
factor in your testability what this is
the takeaway from this chart for me is
that a system scale and complexity and
difficulty of testing you're getting
bigger they're not getting smaller all
right nobody's systems are getting
smaller it's
you've got an expanding universe if we
stick with strategies like this
basically you're going to run into more
problems than you want you're going to
run out of you can run out of resources
or you're going to produce systems that
are unnecessarily bugging we're
unacceptably bugging you won't be able
to keep up talk a little bit about
strategy so what's the bottom line how
do we improve testability well for white
box testing we've seen that there are
several things that we can try to
improve built into us state helpers PCOS
we'd like to try to maximize those and
minimize the corresponding blockers of
testability with black box the same
thing we'd like to maximize our ability
to produce meaningful models evaluate
the results and have a harness that
helps us do that and we'd like to
minimize all that other stuff okay so
that's not very profound the thing
that's event of interest to me is that
who owns these factors in most
organizations now this may not be true
in yours so if and if it's not that you
should think yourself lucky but in most
organizations that I worked with the
fact is that testers don't typically
control or own the work that drives
testability the things that drive
testability are basically dictated or
handed to them by the architects with
people who are managing the system and
the developers testers are basically
working on the test parts and this is
determined by someone else so the things
that kind of set the bounds on how
effective you can be often are outside
your control so this is kind of a whole
process an organizational issue it's a
whole other subject I'm not going to
attempt to discuss that but it's
something I think you may want to
reflect on and if your circumstance it's
not like this again I say consider
yourself lucky so here's a strategy box
finally at the end let's suppose we're
in a circumstance where we have high
black box testability and low white box
testing my argument is
we should emphasize functional testing
black a black box approach because we
can't really do much on the white box
side so the implementation might be this
might be a legacy system which is all
hard to test what should we do okay
let's not kill ourselves let's go for
the low-hanging fruit will pardon the
expression emphasize functional testing
when that is the thing to do because if
you think about the ultra strategy to
try to dig into the code it's a losing
battle you can burn a lot of cycles
learn a lot of time and money and not
get very far symmetrically kind of the
other thing is true when you have high
white box testing you have a system that
is cooperative well structured but you
might not know much about its behavior
for example a system is relatively new
something has just been through
developments and beta test first time
now you might want to emphasize
implementation specific aspects of it
getting bigger the question of the
gentleman asks there what kind of things
might we know might we be should we pay
more attention to it depends on what you
expect to go wrong here in a
circumstance where you have low
testability on both both counts I think
your best attack is to learn how to
manage expectations and then finally if
you are in a circumstance where you have
produced system which is you know works
kind of high has achieves high
testability both in the implementation
and representation sides I think you
want to try to figure out how to do it
again because the news here is that
you've done a tremendously good job
you've done something that's unusual
unique and you ought to try to figure
out what what the magic was it made it
happen and put it in the bottom okay so
that basically is my story and take
questions I think we might have a little
bit of time and will run over too much
yes sir
hello my name is risen you mentioned
something about the testing the
production environment so how do you
manage the strategy for testability in
terms of performance in terms of load or
stress testing do you do some like
capacity planning or estimation you do a
prediction everything based on your
knowledge in the white box testing and
black box testing how to do that in
advance it's a little hard that's it's a
kind of general question it's sort of
hard to answer in general without
knowing the specifics yeah I think you
just have to look to the trade-offs and
decide what makes sense and what's
doable there that's it's negotiable
other questions
alright so I have a question for you
when i played the messer the m-66 galaxy
slide I actually I had an internal
debate about what kind of music to play
along with it and this is something
estriol piece which has some very very
dramatic grass in it I thought that the
other thing that might work in that was
Jimi Hendrix's Purple Haze so I don't
know would you prefer to hear Purple
Haze this morning or not okay well
another question over here see one thing
that you didn't mention is about the
test data it's a lot of times when we
are doing the performance tests and load
testing here am ah ok yeah so I was
going through the Lord of open questions
you're posing in the talk and then one
thing I thought it's relevant is the
test data especially when we are doing
the performance load and stress stress
when we actually load the databases you
know when we are required to do that for
about forty percent of the production
data so my question is like don't you
think Oh test data is a challenge when
we are actually handling the testability
in the kind of time it takes for us to
set the stage yeah it certainly is and
that that's a very good point how do you
populate and instantiate that's set up
yes I didn't get in that but in a data
intensive system which has a large
database getting that just to some
initial usable state which is consistent
can be quite a lot of work and so it's
something that it's worthwhile paying
attention to and I think automating as
well
if you have a model-based estimates a
that if you have a model for which you
can generate some kind of assume certain
scenarios and then generate a database
snapshot that corresponds to those
scenarios unload the database reloaded
with that scenario I found that to be a
very useful kind of tool to have in this
situation you described other questions
okay well thank you very much for your
attention this morning</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>