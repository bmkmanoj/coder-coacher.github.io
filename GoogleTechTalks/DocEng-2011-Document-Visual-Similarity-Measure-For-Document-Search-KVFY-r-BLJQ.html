<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>DocEng 2011: Document Visual Similarity Measure For Document Search | Coder Coacher - Coaching Coders</title><meta content="DocEng 2011: Document Visual Similarity Measure For Document Search - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>DocEng 2011: Document Visual Similarity Measure For Document Search</b></h2><h5 class="post__date">2011-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KVFY-r-BLJQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">without everyone I'm going I'm going to
talk about today about document visual
similarity measures for document search
so as for problem statement we can say
that we want to may have means to
compare documents with respect to their
visual similarity we do not consider the
content of the document what the
document talks about we would rather
like to compare layouts on images in the
document such that similar documents
would be and have some means have some
algorithm that would be enabled that
would enable us to find similar
documents in a very large document data
set so as a possible application is
would be something like an entrepreneur
would like to advertise his business and
he would like to come up with the
brochure and he would have an idea about
what would he would like to have a nice
be sure and he would be provided a large
data set of brochures that are designed
that are prepared by the professional
designers and he would have means to
visually find documents brochures that
are similar to what he has in his mind
but created created by a professional
designer so this is a screenshot of
snapfish web page where the where the
services greeting cards so as an
additional application would be
organizing documents or greeting cards
with respect to their visual
similarities such that users might be
might find green cards of their specific
interest rather by searching by their
visual similarity rather than by the
keyword or newspaper catalog searches
another application so our approach to
these problem is basically comparing
documents with us back to three
different components there's component
for background text and saliency
background component is basically the
component where we are where we have the
background without text we erase all the
text from the background and then we use
the document we extract our feature
vectors from every pixel of the document
so it's five dimensional first of all
it's XY which is the position of a pixel
and la be color values so
from every pixel of the background
component we extract one feature vector
and then we run am algorithm to find out
to learn a gaussian mixture model and
then we compare and then we are the
number of mixture models is basically
calculated by the MDL minimum
description length cost function so we
learn a gaussian mixture model that
basically represents a pixel position of
a pixel given the the color of this
pixel at the background here what we can
mention here as the visa visualization
of the gaussians is can be as follows so
since the Gaussian since the feature
vectors are five dimensional they're
impossible to show on a plane so the
best thing we can do is actually we can
show each Gaussian as an ellipsoid and
give its mean color since we got the
feature vectors each have a color then
the mean color would actually can be
given to the whole Gaussian and here you
can see a document next to its
background component and next to the
ellipsoids that represents the whole
gaussian mixture model or the dog for
the background component another
visualization of this approach would be
as follows so by the maximum likelihood
function we can assign every pixel it
its color of its closest Gaussian so if
we have five gallons for example here
then the corresponding segmentation
where we have five colors to assign to
each pixel would be as follows and we
can run this experiment for as many
gaussians like a we can have and you can
see that there is a big difference in
the number of gaussians between third 13
and 28 gaussians but in terms of
segmentation there is not a lot
different so we actually end up with a
number with number of gaussians in
between 10 and 15 so we don't have more
than 15 gaussians in our mixture model
for this application for text component
we do similar algorithm we extract
gaussian mixture model but then
in this case we only consider pixel
pixels of text boxes so basically we
take pixels XY the only the address of
the coordinates of pixel at every text
box and we disregard everything else so
we learn Gaussian and these are the
actual gaussians since there are two
dimensions we can show them on the
screen to this is the presentation of
the gaussian mixture model and then for
the saliency component we extract this
alien see is basically given as the
clarion distance between leb color
values of every pixel well and the
average la be color of the whole
document so it is basically given by
this formula so it is three dimensions
now are three dimensionals that are
given by the position of a pixel X Y
values the coordinates and the third
Gordon would be the saliency value so
salen see why do we pay attention to the
seven SI salen sees basically would
represent the areas or the regions in
the documents that are significantly
more visual in a way so they would stand
out with respect to its neighborhood so
for example this one comparing documents
we would like to find documents that
would be similar to this one where the
instead of the dancing persons here it
would have some other salient portion
maybe some some inscription or some text
that would have also this selling
selling properties at the same player
place and so once we have learned the
Gaussian mixture models for every
component we now would like to have some
means to compare gaussians so we compare
gaussians by the Hellinger distance
which is basically the distance that we
can calculate whether we can find
comparing two different probability
distributions so for probability
distributions F and G the Hellinger
distance would be the scales square root
of the one-half norm between these two
distribution discovery square so these
two distributions which can be
simplified into this single form
where it is basically discord square
root of 1-3 bhattacharjee officiants in
between two different distributions F
and G and if we expanded but the Cherica
efficient we basically see that this is
nothing else but the expectation of this
square root of the ratio between the two
distributions under one of them and it
is also symmetric so we can actually
play around with exchanging distribution
p by q m we can have another form of
expressing but the cherokee efficient
but in terms of expectation of another
distribution the butter churn rate
coefficients in order to compare the
distribution we basically use we
approximate by the Cherica efficient by
the unscented transform uncertain
transform is used to approximate
expectation of a non-linear function H
of X under probability distribution well
in this case f of X so this is basically
done in the following way we
specifically choose points at certain
locations for the distribution F and we
evaluate our other evaluate the function
H at the specific points and then we
take the scale some of the obtained
values and this would be the
approximation of the expectation now in
terms of Gaussian it would be best
actually if we just take these points
points that are certain that would
capture the true mean and variance of
the distribution so for example if you
want to find brock's expectation under
some specific function h of x where the
probability distribution kim is given by
this ellipsoid then the points that we
choose actually would be on the two
sides are of the mean and that would be
the square root of a column of the
covariance matrix away from from from
they are from the mean and so by taking
the mean of these points we would have
an approximation of the expectation of
this of the nonlinear function h and so
once this is the ways to calculate
distances between galaxies and mixtures
and since i mention
before we have three components now that
will know how to compare these three
components the question is how do we
come up with an ultimate measure in
between the documents so to do that we
basically come up we research for
weights w be standing for the wait for
background component WT which is the
wait for the text component in the wait
for the saliency component and then we
wait the distances a week i'll we search
for the way that some of these distances
to come up with the ultimate measure
between document similarities and to do
that we define a probability function
which is expressed in this way and this
is the probability function that a
document J is the neighbor of document I
and then if we have classes of similar
documents in our data set then we can
set probability P I which would be a
probability that document I a is
correctly classified that all of its
neighbors that are in Class C I are
close to it and then we can some them
some this API with respect to all of the
classes that we have in our data set and
we can come up with the cost function
that would basically be the probability
that all of the documents are correctly
classified yeah the good thing about
this function is that it is
differentiable and we can run gradient
as an algorithm all sorts of
optimization algorithms on this function
to find the optimal waits for our
application and so for our testing
components testing and training we use
the 410 documents from five different
classes you can see example samples from
our data set and we ran a three-fold
cross-validation technique and here are
the results of our three runs for our
cross-validation so the cross relation
basically works in the way that we
divide every class into three parts we
train in two parts and test on another
and then we switch them and then we do
that three times and these are the
results and as for small oh
demo I would like to show you the
following so here for the demo we have a
data set of approximately 2020 documents
here there are very different in their
style eating stylistic features and what
we can do is simplest them and will be
basically to find a document here an
index of a document and run and find for
the most similar ones for example then
the query doc would be on the road on
the left and the four that are most
similar documents to this one with
respect the visual similarity would be
shown next to it and the same way we can
run this experiment imes fro let me just
choose very different example something
of this sort and the algorithm basically
produce gives me this so all these
documents are considered to be similar
with the specter a similarity measure in
their stylistic features ah this is it
thank you very much
I'm just curious and if I had the answer
to this question I would ask it more
specifically at Chi this year Scott
clamors group got did a style matching
based on a sort of a visual feature
model that kind of reminded me a little
bit of the last paper but not exactly at
all but sort of in this same vein and I
just wondered if you so you're familiar
with are you referred to bring collage
paper yeah yeah I guess they have a
whist paper in a few weeks yeah i was i
was just wondering if you would could
compare and contrast the two approaches
yeah this right well that's a very good
question actually all we had i've been
invited to a few seminars to their group
actually and what they do is they
compare layouts of web pages and whereas
we basically concentrate and are on the
actual PDF document so but apart from
that our approach is a similar yes but
the thing is they're using three based
algorithm so they compared trees which
is a different proper problem well but
the thing is the comparing tree
algorithms might be and pick complete so
they might run into some difficulties
whereas this is not very bust but well
more robust but a little bit more simple
Oh approach to this problem said so I'm
sorry think the implications are of that
are for how useful the two approaches
are in on what kinds of problems well
applications would be totally different
actually are the first their approach
would be just to come up with a website
that has the layout of a certain layer
that is similar to the website so that
the user has chosen whereas in our case
we have actual brochures and we would be
basically comparing the documents single
page documents in here we do not
consider web web pages because they can
be very different actually but here we
have certain our margins and certain
limitations to the PDF documents that we
use I'm not sure if I education but we
can talk later Cassie phone
we have other questions I don't I don't
really have a question but I thought
that it was nice i like the work it was
interesting to see your success nice
demo thank you okay let's thank our
speaker</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>