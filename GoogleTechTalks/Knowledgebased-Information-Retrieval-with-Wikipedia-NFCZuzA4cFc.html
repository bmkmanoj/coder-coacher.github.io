<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Knowledge-based Information Retrieval with Wikipedia. | Coder Coacher - Coaching Coders</title><meta content="Knowledge-based Information Retrieval with Wikipedia. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Knowledge-based Information Retrieval with Wikipedia.</b></h2><h5 class="post__date">2008-11-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NFCZuzA4cFc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone welcome my name is
Michael McNally I'm about to introduce
our guest speaker David Milne is
connected to Google through Ian Witten
who is the professor who is David's
advisor he was also the PhD advisor for
Craig Newhall Manning and so that's a
the connection by which he was
introduced to us and help you presenting
some of the research results and ideas
from the paper that he just presented in
Napa Valley
at the CI kam conference the conference
for information and knowledge management
and this just won the best paper of the
conference so congratulations to David
Melanie for that if you'd come up and
welcome to Google
thanks for the name dropping okay so I'm
here to talk about knowledge based
information retrieval with Wikipedia I
don't mean going to Wikipedia and
finding the information you need that's
not all that interesting what I'm
talking about is using Wikipedia as an
intermediary between queries and
documents and trying to have a search
engine or a digital library consult that
to try and help things along
also my abstracts might have been a
little bit misleading I'm not going to
be talking just about Wikipedia and how
good is and how bad it is I'll be more
talking about the specific things I've
been working on with it so I've been
creating a system called kuru and
working on some related problems such as
semantic relatedness and Wicca fication
is going to be pretty cryptic at the
moment but as I go through the talk I'll
talk about four more and I'll actually
demonstrate a live system for each of
these problems okay but first I need to
motivate my talk and this is the bit
where I need to criticize Google
criticized search engines not the best
we need to try and do this but we all
know search has not solved there's
improvements we can make and the main
limitation that I'm interested in here
is that current search engines don't
understand us really they they deal and
characters and word patterns they don't
deal in people or places or events or
concepts so yes we do lots of really
cool stuff with link analysis or
statistical analysis of what words fit
with what other words or click-through
behavior but really fundamentally
queries and the webpages we're looking
over them with may as well look like
this right they may as well just be
plain characters so what I'm going to be
talking about is an idea of how can we
how can we move from these just
characters and patterns of characters to
actual concepts and ideas and people the
idea is called knowledge based
information retrieval where we just have
some kind of external ontology or
knowledge base or thesaurus that we
consult
whenever we encounter a document or
encounter a query to try and find out a
bit more about what it means it's
definitely not a new idea it's been
around for a long time and it's not one
that's really worked out so far I have
to admit there's been lots of research
on it but yet as I said before the
things people use the search engines
that people use don't really work with
us curricula if I'm wrong because I
don't know exactly what goes on inside
Google but the things I keep hearing
about have nothing to do with consulting
knowledge basis and actually finding out
what these things mean
and there's pretty obvious reason why
this hasn't worked so far and that is
we've never had the right knowledge base
so you think of what we would need to
support this on a web scale google scale
we need something that knows about
everything and can connect everything
together and knows about all the
different ways that we're talking about
these things and simply computers aren't
accurate enough we don't have the NLP
sort of technology together as
automatically and humans aren't quick
enough to deal with all the information
that could possibly be coming in except
that last bit might have just changed
with the advent of web 2.0 we can now
throw millions of people with the
problem and it's actually quite possible
that not only could they make this
knowledge base but it's quite possible
that they already have of course from
the talk oh the title of the talk I'm
obviously talking about Wikipedia so
let's think of specifically how it could
be considered a knowledge base I'll talk
about this quickly what we need from a
knowledge base fundamentally is a thing
that tells us what topics and concepts
are out there how those topics are
referred to like how can we connect them
up from the documents and from the
queries and also how do those topics
relate to each other so how can we
usefully negative navigate from a topic
to another topic or identify useful
relations between topics Wikipedia
covers all these bases so as an example
I'm going to talk about rugby because
I'm a New Zealander which fundamentally
means I'm fanatical about this sport
does anybody else to know what the sport
is it's basically it's gridiron without
the padding and without the rules pretty
much so last time I checked I did a
crawl on Wikipedia like a year ago to
find out how many articles are about
rugby and it's like several thousand of
them for this obscure pop sport which at
least is not very interesting to
Americans so overall and all of
Wikipedia there's more than two million
articles and categories describing
different concepts that are out there
and they cover things like the sport
itself different events that are going
around on the sport
different teams all the way down to
individual players and tactics and
referees and things like that how those
topics are referred to Wikipedia
maintains a network of redirects which
connects alternative titles or synonyms
to to the concepts and also there will
be lots of links going in on from one
piece of text that might mention sort of
a bezoar the New Zealand rugby team
things like that to this article so we
can tell from those sort of things how
people are referring to these concepts
and also how those topics relate to each
other
well we've got all these massive network
of links between these concepts so here
the All Blacks is linking to New Zealand
and rugby union and other teams like the
Wallabies so we can draw a network
between these concepts and also we can
get a bit more structured information
from things like the categories there's
a big hierarchical structure which
organizes Wikipedia and you know tell
more logical things like rugby union as
a type of rugby which is again in turn a
type of sport and there's so huge
network I have to be careful saying huge
at a Google crowd but there's a very
large network of connections between
these concepts so if we take a knowledge
base from Wikipedia in this sort of way
of mining the concepts and all the
relations between them we get a very
very large one so here's a comparison of
other things that people have used in
academia as wouldnít which weighs in at
about 120,000 concepts research psyche
weighs in at about 300 thousand concepts
and here's Wikipedia drawn to scale
right not only that but it's got far
more potential for growth in the future
so research stock has been getting
developed over the last 20 years or more
whereas Wikipedia is only developed over
seven years and it's accelerating
I have to point this out because I'm a
cheap student but who knows how how much
research site cost to produce you know
I'm playing professional ontology than
philosophers for 20 years it's not cheap
whereas Wikipedia was negligible cost
also
sike exists in one language whereas
Wikipedia with some caveats you know
there's very big differences between the
amount of information that's contained
within different languages but it exists
in 250 languages anybody who's involved
in research like would be crying foul
now because there's a very big
difference between Wikipedia and site
fundamentally psyche and other
anthologies are very formally defined
carefully defined they're designed so
that you can do inference we can tell
things like George Bush as a head of
state he's a president of the United
States United States is a democracy
therefore President Bush must have been
voted on at some point we can do things
like that with the formal structure but
with Wikipedia in comparison it's a
complete mess
right anybody can connect to different
topics up and any way they want they can
refer to these topics in any way they
want sometimes not particularly
complimentary you can see there so a lot
of researchers have seen this as a big
opportunity Wikipedia is huge could have
so many potential applications but we
need to tidy it up and turn it into an
ontology there's a lot of research going
on on that that's not my field my field
my hypothesis is that Wikipedia will
provide significantly significantly
improved retrieval if we allow search
engines or digital libraries to consult
it as it is without making it tidy we
don't need to make it tidy it's not a
question of sophisticated NLP or AI
artificial intelligence it's more a
question of HCI my reason for this
intuition is that
people are using Wikipedia to find
information all the time and the way all
of its relations developed was through
people thinking this link is going to be
useful to someone else or this link was
useful to me so if we have a second look
at the structure what would you rather
have on hand if you're investigating
George Bush would you rather have
something that dryly labels him as a
prisoner in the United States heads of
state person therefore has two legs or
something like that or would you rather
have something that can connect them up
to any topic that someone thinks if
you're looking at this you'll also be
interested in this or this or this which
would you rather have on hand okay so my
methodology is pretty obvious it's going
to make a search engine that uses
Wikipedia as it is and find out the
search engine is called Cora and because
I'm just a mere student the search
engine is not web-scale it just works on
a finite set of documents it's designed
to be used on digital libraries so we
start with with a set of documents and
we cross-reference those documents with
Wikipedia to try and find out what sort
of topics and concepts are relevant to
it and so we extracts basically a
thesaurus or an ontology that is
relevant to these documents I call that
at wikisource so from this structure the
search engine knows what topics and
concepts are relevant to these documents
not just what patterns of characters and
that means anytime someone issues a
query which is relevant to these
documents
it will also be relevant to this
thesaurus and therefore we can find out
what query topics people are talking
about and so there's a lot of
opportunities for improving recall and
precision and that sort of thing by
doing query expansion opportunities to
match up these query topics with the
document topics an interesting ways but
more interestingly I think is that these
opportunities for exploratory search for
making suggestions you start
off with this query what are the related
things that you could be looking at okay
this is a little reminder to make me do
my the system because I keep forgetting
to do that okay so this is a search
engine let's try the George Bush example
okay so on this side we just have the
normal document lists that we'd see on
any search engine but on the other side
we see a set of topics that we could be
talking about and so that by consulting
Wikipedia we've figured out that this
thing is ambiguous we could be talking
about George Bush junior or senior and
we're also talking about controversy and
you can see the sorts of things I'm
trying to do with query expansion like
we've added synonyms to the query
basically the actual query that was
issued over these documents is a big
combination of all of these synonyms and
also we can use this as a starting point
for looking at related concepts firstly
you know just to show that that send
another thing works we get exactly the
same results no matter what we type and
we can also use us as a base for
exploratory search for finding out
related concepts that we could be
looking at so for example what is George
Bush been saying about a abortion
initially we don't get any results but
we can easily pick and choose what
topics were interested in and so we can
have a look at actual documents this is
sort of a stay tuned thing I haven't
done much with this year but you can
also see the documents and the search
engine itself and the idea here is later
you'll see how we can pick up topics in
the documents and
allow people to feed that back into the
query and so because documents are a
great place to figure out what you're
actually searching for and refine your
search okay
so I conducted an evaluation on the
system we're basically rennet on tricked
documents there's a documents for which
relevant judgments and different topics
that people could be looking over have
already been calculated and from that I
could tell that on this fairly random
set of documents that belonged to no
domain in particular Wikipedia was able
to match the Kreutz terminology
extremely well so whenever someone typed
a query
95% of the time it recognized all of the
topics that were in that query and then
was able to do something to expand the
query and the recognition and the
expansion of topics significantly
improved retrieval statistically
significantly but it's it's there would
be a lot of work I could do to try and
improve that and so the way it can
improve recall obviously is we were
searching through synonyms and the way I
can risk and precision is that it
recognizes multi-word topics and can
ensure that I need the right documents
are getting returned one positive thing
we found from again an HDI perspective
is that the recognition of topics
significantly modified people's query
behavior so we're seeing things like
people issuing really long queries like
this is an example of someone searching
for documents about email abuse and the
workplace like spanning and using it too
much and things like that or looking for
the wrong stuff and you can see
someone's issued a really long query
which is initially completely useless
because it's too specific but it gives
them a base for picking and choosing
different permutations different
combinations of what they could be
looking at so people issued a lot of
queries and overall those queries were
able to give them better documents in
the end
a negative thing we found was that the
Related Topics needed a lot more further
investigation so here's an example of
someone searching for the email abuse
problem and here are the related topics
I presented for abuse there are not
particularly helpful they are a very
dire really so we need a lot more
intelligence of what is actually
relevant to the query what's irrelevant
to the task what's relevant to the
documents behind them and another thing
is the extraction of the source terms
was inaccurate this was basically a
prototype system my first test of the
hypothesis and so there are lots of
problems like say in this example every
time this documents were getting indexed
and we encountered the topic security it
always thought it was security the
finance like security on a loan and so
it didn't know what security you know
security guards checkpoints and things
like that it didn't know about that
concept so those are the two main
problems extracting the concepts and
disambiguating and finding the relevant
concepts and also finding the relevant
relations between these concepts the
useful relations so that's what I'm
going to tackle next that's why they did
tackle next
first one looking at how topics relate
to each other and how to recommend good
topics I did a lot of experiments and
semantic relatedness and this is the
idea of you have two concepts or two
terms how do you measure how strong the
relation is between them so you think of
like money and cash pretty much 100%
related because they're the same thing
they're synonyms
whereas money and bank that's a bit less
related and money and graduate study is
pretty much unrelated so how can we get
a system that can produce those same
judgments this stuff was highly useful
for things like AI data mining I so the
advantage
of investigating this as I can produce
something that will be used by other
people but it's sort of a weird task
it's completely subjective
like for example that's completely
ignore the giant carbon footprint I put
on the planet getting here from New
Zealand and look at the relationship
between cars and global warming you're
gonna get different responses if you ask
the guy rides a bicycle and the guy
drives a Hummer right it's all
completely subjective so what we have
instead of ground truth for this task is
we have data sets which look like this
they have term pairs and they just get
people to just tell me how much do you
think tiger and cat relate to each other
give me a number and they average the
number over normally 1020 people and we
get an a value of how much we think
these concepts relate to each other and
we want to produce those numbers
automatically Wikipedia is a great way
to do this because for this problem we
need scale we need structure we need to
be able to provide measures between
watts of different concepts but we also
need structure to be able to do it we
need to be able to tell identify the
actual concepts we need to tell how much
they relate to each other so as I've
said before Wikipedia covers us pretty
well and naturally that means it's not
going to be a new idea if I use this for
semantic relatedness two other people
had tried it before me there was a
system called wiki relate which works on
Wikipedia's category structure mostly so
a concept is related to another concept
if there is some sort of common ancestor
and there come in their category
structure and the further up you have to
go basically the list related at us and
there's another one called explicit
semantic analysis which works on the
text in Wikipedia so you can look at
textual overlap it's a lot more
complicated than that but I could have
used either of these two systems but I
decided to try something on my own and
that is I felt both of these resources
were ignoring so
thing important they're ignoring that
massive interconnected structure of
hyperlinks that I showed earlier
so I created a system which uses these
links to calculate relatedness so here's
an example of how it works we want to
compare Bank and globalization here's
the Wikipedia article on globalization
and you can see it has links to things
that are related like trade foreign
direct investment human migration but it
will also have links to quite odd things
for some reason I haven't got an odd
example there but normally there is is
is random links as well so what we do is
we gather all of the links that are
coming out of the article globalization
and we can do the same for Bank and we'd
get some overlap and so the overlapping
concepts indicate that they're related
but the ones off on either side indicate
that they're not related we can do
exactly the same for the links coming
into the articles and we can turn this
into a number of how much they relate to
each other demo
okay
I'll give some URLs at the end of the
talk but this is my site for the code
I'm sharing for working with Wikipedia
and mining stuff from it and it's got
some demos and I'm going to search for
how much Google relates to Yahoo okay so
with 75% related and that's because
there's a bunch of things that they have
in common but there's a bunch of things
that they don't have in common right
exactly
okay what do we expect to happen here
well it'll still be kind of related cuz
you know Microsoft does search but
they're doing a lot of other stuff as
well so it should be a bit less related
how's that is that too much or I get and
then we try another company which okay
this will still be a little bit related
because it's a company yeah but 4015
related it's probably a bit too much I
don't know all right and let's do
something interesting what's the motto
here don't be evil
let's compare Google and evil what do we
expect how are you guys going whoo
that's a bit too much
okay the other important thing is that
this is working with you can probably
tell it works with any any type of
semantic relation it doesn't matter what
type of relation it is so it works with
location as well I spelled it wrong
right and it's also doing disambiguation
so we aware that Google quite possibly
picked the wrong Mountain View to set up
business on you could all be hanging out
in Hawaii actually there's a Hawaii
there's a mountain view on Hawaii so
before we're looking at not in view on
San Francisco but here we're looking at
Mountain View in Hawaii
okay
how well did it work well there are
standard data sets like this word
similarity 353 I showed the start of
that data set yes sorry can you try it
try it with case folding because it's
you know
yeah
there's a different search mode you can
do it on K spotting sorry I keep saying
I'm in HT over I make terrible mistakes
that's interesting it's getting
evaluated as I see as I speak okay okay
so when I ran it on evaluation data
basically what I found out it was quite
obvious really it works better than
doing it on the category structure
because we have a lot more information
available and it doesn't work as well as
using it on full text at Wikipedia
because again they have more information
available but the really good thing is
so yeah the really good thing is we can
do this very very cheaply it's only
using structured information and
actually all of the structure that it
uses Wikipedia's link structure can fit
on memory so later on I'll show you some
experiments which are doing this is
doing the semantic relatedness stuff
literally millions of times so this is
important sorry it's it's this one
Wikipedia link based measure okay
the next problem was okay now we can
tell when concepts relate to each other
pretty accurately and we can do that
with multiple concepts so we could do
things like pick the query the thing
that's related not just to the query but
to all of your query concepts and also
to the TOC relevant relevant documents
that are getting returned and things
like that the other problem was being
able to identify what topics are being
talked about in the documents so that we
can index them properly and this is a
task that's been coined as Wicca
fication and the idea is that wikipedia
contains millions of examples of how to
connect documents to wikipedia every
single wikipedia article has been as as
an article that's been cross-referenced
as and it's got all these links telling
you what other wikipedia articles are
relevant so Wicca fication means
basically you take a Wikipedia article
and you strip out all the links and you
try and put them back in and you can
evaluate it on how well it does this
there's a few problems involved separate
steps sorry one is which terms relate to
concepts and which ones they just prose
zippering out stop words but there's
more than just stop words that we need
to ignore another one is how do we
resolve ambiguous terms because terms
can potentially relate to multiple
concepts like bank could relate to the
financial institution but it could also
relate to the site of a river and
another problem is how do we select the
concepts that are actually relevant as
we'll see later we could be picking up a
lot everything in the document but it's
not always going to be helpful so look
at the first one identify in concept
terms and we're Kapadia links if we just
gather them up that would provide a huge
vocabulary of which terms can link to
which concepts if anything
this vocab there is too comprehensive
if we wanted to we could link to even
the stop words in this document such as
the we have an article about that or the
concept of six or half of something
luckily we can easily separate out these
sorts of things by looking at how often
these terms appear and Wikipedia and how
often they're actually used as a link so
very small percentage of the time that
is actually used as a link where as
global economy 15% at a time that's when
that's encountered it's used as a link
so that's how we separate out the chaff
from the potential concepts the other
problem is resolving ambiguity like some
concepts are ambiguous okay I've created
a system which is machine learned that's
because in a sense in this example we
have millions of training examples of
how to identify a correct sense for a
concept every single link in Wikipedia
has been manually disambiguated it's
been manually decided which concept that
should link to and so that provides one
good example obviously but also all the
bad examples all the things that could
potentially ever link to but didn't so
my machine learned approach uses two
basic features the first one is prior
probability your cominis which is trying
to identify what are the sensors that
people actually know about and what are
the obscure things that people are not
likely to be interested in because
wikipedia has got a lot of that so for
example when people want to add a link
to global economy
they could be linking to the global
economy but sometimes this is it
technically ambiguous and Wikipedia
because sometimes they link to the
concept of globalization the phenomenon
of governments working together in
countries working together
but again we can look at the probability
of each of these things being a
destination for this term and we can
identify what is the obvious one and
what is the least common one so that's a
feature obviously we wouldn't want to
rely on this all the time because there
are other terms which are more genuinely
ambiguous so as I said before banks we
could be talking about financial
institution at the edge of a river or
stream and under what a hill like a sand
Bank that people run aground on or of
movement and flight like he Bank a plane
and here are the prior probabilities of
each of these sensors and in this case
would be fine but we changed the
document and we're not we actually need
to pick this one in this case right so
the other feature is how much it relates
to the context surrounding it what we do
is we gather unambiguous concepts from
the entire document in which this link
is found and we look at how much our
different sense concepts like each of
these sense concepts relates to each of
these context concepts and I showed you
before how we do that and so we can
easily see that the edge of a river or
stream relates much more closely to
these things you know because these are
rivers and streams okay
I'm sorry I made a mistake here that
figure is completely wrong the figure
for resolving ambiguity is more like 98%
and 97% recall and precision so I'm
sorry about that
believe me the stuff was competitive
with the state of the art I can point
you to a paper I can't believe I make
that mistake okay
the next problem is selecting relevant
concepts so the thing is Wikipedians do
not link to every single article they
make interesting like quite complex
decisions about what to link and what
not to link so in this example here we
have the article on financial crisis and
we're not linking to vague things like
situations we're not looking to things
that everybody knows about
like value or 20th century when linking
to things that are really relevant to
the story like banking panics recessions
stock market crashes so as I said before
Wikipedia contains millions of examples
of what is a relevant topic to link to
and what is not given the context of the
article and we want to learn from that
so I've made a machine learning approach
which first we just did that thing I
showed earlier of just trying to
separate out the chaff from potential
concepts just by looking at the prior
probabilities so things like 6 and 1/2
and they're going to have very low
probability so we just ignored in that
we gather these other concepts like
central bank's Bank of England interest
rates and also overlap doesn't matter so
we're picking up central banks at all so
banks and we run the disambiguation
classifier which i described earlier
with those two features communists and
relatedness to try and identify to get a
one-to-one mapping between each of these
different engrams
and the relevant concept and the next
step is we need to learn which ones to
throw away and which ones to keep so in
training we would do this to a Wikipedia
article we'd take the text detect all of
the possible concepts that could link to
and then our good examples are the ones
that were linked to and the bad examples
are the ones that weren't and also
because we're dealing with not just
engrams
and but also ticks we can gather
features that are not just like where
it's found in the document or how long
it is or things like that we can deal
with things like how much it relates to
the central thread of the document or
how general and specific it is like the
intuition being that so we wouldn't want
to link to general topics like Bank
because you'll know about them but we
would want to link to central bank's
because you might not know about them
you need to click on them and find out
so we do a diver training on Wikipedia
articles but we went if we go and do the
same thing in testing on things that are
not on Wikipedia then we can use the
same classifier that was trained to make
the decision to actually pick out the
ones that are useful the ones that are
interesting and that is the actual
accurate figure for this thing so what
that means is we took a bunch of
Wikipedia articles completely removed
all of the links on them and then tried
to put them back in automatically and
only 26% of the links there new links
were not found in the old document and
only 26% of the old links were not found
in the new document which is pretty good
really because this is a completely
subjective task you and I would argue
about what should and should not be
linked and a Wikipedia article we also
tested it on news documents that are
nothing to do with Wikipedia and had
human evaluators who use Mechanical Turk
to get people to look carefully at each
every single link and tell us where it
was good or not and also the document as
a whole tell us which links are missing
and we got the same sort of figures
okay so demoed us so here's an OL about
San Francisco and I am going to try and
Wicca Phi it bear in mind this is just
running on my little research machine
back at home so it's not going to be
very fast and also for some reason it
messes up some so via scripts but here
we have its link to San Francisco and
Alcatraz Island San Francisco Bay Area
San Francisco Peninsula everything
that's about San Francisco and also its
history like calm boom and
counterculture and things notice it
hasn't linked to everything that it
could possibly have identified for
instance has decided that where is it
it's decided that Victorian is not
relevant here it's not a central part of
the story whereas here we have another
web page to work if I
and we can see it has actually decided
that the Victorian area and things like
that are worth linking to because
someone reading this story would be
interested in investigating this topic
okay one limitation of this whole thing
is it's been trained on Wikipedia
articles so it expects to be making
links to something that's like Wikipedia
so whoops let me just here's a Google
blog and I can try and rectify this but
this is a little bit different it
doesn't work quite so well because a lot
of the features are about having a
central thread and this documents a bit
short maybe doesn't have so much of a
central thread so it's only been able to
pick up Google and human-rights here but
the whole thing is the machine mode
approach so we could just train it on
what we want it to pick up or we could
just tell it to be a little bit less
exact about what it picks up so here we
have a lot more stuff like bloggers and
free speech and privacy things like that
okay so to summarize with that last bit
we can add explanatory links to any
document so we could do this to news
stories blogs educational materials
Knowles possibly and also we could
assist the creation of new Wikipedia
articles like you can imagine you create
a new word a computer article maybe
there's a button that says just look if
I this and then after that's done I'll
go through and only change the ones that
are wrong that would be cool but that's
I should say this is the work that won
the award
it doesn't quite seem worth it at this
stage because all we're doing is adding
a few links to the pages what's the big
deal there but this has some interesting
implications what we're really doing is
we're cross-referencing any document
with the largest knowledge base in the
world so we can pick up the concepts
that are in these documents so for
example I ran it on the paper that was
about this and here's a sample of the
concepts that I was picking up so before
we just had some words we didn't know
what they mean but now we have a bunch
of concepts that this document is
actually about and we're doing things
like we're resolving ambiguity we know
exactly what type of ontology I was
talking about
it's resolving policy me so it doesn't
matter if the document was talking about
data mining or knowledge discovery or
kdd it would show this same thing and
also it's not a bag anymore it's
actually a graph we know how these
concepts relate to each other we could
cluster them and also as I said before
there's a lot of research going on than
turning Wikipedia in Toronto G so if we
tap into that we could start reasoning
about this stuff as well we could tell
that Hamilton as a city in New Zealand
and it's the home of the University of
Waikato so
we can improve how documents are
represented I'm going to be trying this
sort of stuff for information retrieval
obviously searching but also exploratory
search making suggestions about what
people can investigate luckily some
other people are gonna be using it for
other things as well so Alyona my
colleague from university is currently
working at Google and New York and she's
working on topic indexing which means
finding out here's a document trying to
basically trying to tag it what are the
most important things that you could
file this under or organize it and so
work if occasion is sort of just a
starting point for this problem and the
relatedness stuff provides some
interesting features for the problem
another thing is document clustering so
another colleague of mine Anna from
University she's currently doing an
internship and EML which is a company in
Heidelberg and Germany she's using it
for document clustering so the idea is
we're representing documents by the
concepts they that are within them and
we can tell not the normal way of just
text overlap to tell whether they should
be grouped together or not but we can
compare the concepts in them we could
have a blog article about Google and a
blog article about Yahoo that even if
they didn't mention anything in common
with each other we could group them
together and I've just came back from a
very short internship at the same
company in Heidelberg where I was
working with Vivi anastasi on multi
document summarization so we have a
query and we have a bunch of documents
that we know are relevant we want to
summarize those documents as succinctly
as possible in relation to the query and
so the stuff is useful there as well and
that's basically it that's the end of my
talk here are some references of
different things if you want to read
more so the top one is a description of
it's a comparison of Wikipedia
and other potential knowledge bases
specifically at the source the second
one is all about curve and it's
evaluation third one is about the
semantic relatedness measure and the
last one is what I just presented about
rectification and detecting the topics
and texts and there's some webpages for
DMS as well okay
so feel free to ask any questions if you
want sure
have you done any work in characterizing
nature of relationships
yeah yeah so this is the problem of
turning Wikipedia into a structured
ontology I haven't been doing that a
research but it's definitely something
that's getting addressed there's a lot
of people looking at it so pulling out
is and not as relationships from the
category structure or we're using info
boxes to sell to tell is this location
within this other location or things
like that not yet I'd like to suggest
this using this stuff to suggest new
lengths or to find missing links would
be cool but I haven't started that sorry
okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>