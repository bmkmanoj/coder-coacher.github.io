<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Google NYC Tech Talk: Breaking the Matrix - Android Testing at Scale | Coder Coacher - Coaching Coders</title><meta content="Google NYC Tech Talk: Breaking the Matrix - Android Testing at Scale - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Google NYC Tech Talk: Breaking the Matrix - Android Testing at Scale</b></h2><h5 class="post__date">2013-10-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IGavGSOSAoM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to welcome you to meet Ivan
even Shiva ch he's a senior software
engineer in test and he's passionate
about building Android development and
test infrastructure he joined google in
2006 and has worked on a few teams
including the Google Checkout team he
also helped Google Wallet Android
engineering team by building an internal
development and build release systems
he's lived in San Francisco just got
back to New York about three weeks ago
and today he's working on mobile
infrastructure for ads here in New York
so let's give a warm welcome hello
everybody my name is even in each ear
and i'm a senior a city here in New York
office first I want to welcome you to
this amazing office there's so many cool
so many cool projects here in this
office there's so many cool people you
can work with there's so many cool
things to play with and the food is just
amazing okay so what can I ask you a
question how many of you are Android
developers how many of you actually test
your applications do you find it painful
good so my team were responsible to make
the Android testing easier at Google we
about the tools and infrastructure to
make the building Android developing
Android and testing android easier at
Google and today's talk is going to be
focusing on Android automation testing
and we can be talking how to break the
manual testing matrix the set of stage
for my presentation I'm going to play
this dramatic video
I imagine that right now you're feeling
a bit like Alice tumbling down the
rabbit hole mmm you could say that I can
see it in your eyes you have a look of a
man who is executing all these tests by
hand now ironically that's not far from
the truth do you believe in manual
testing you know why not cuz I don't
like the idea that people should do the
same thing over and over I know exactly
what you mean let me tell you why you're
here you're here because you know
something what you know you can't
explain but you feel it you've felt it
since 2006 that there's something wrong
with mobile you don't know what it is
but it's there like a splinter in your
mind driving you mad it's this feeling
that has brought you to me do you know
what I'm talking about the manual
testing matrix do you want to know what
it is
the testing matrix covers everything it
means testing on all phones on every API
level now even it means testing on your
glasses soon you'll have to test on your
watch you already need to test on TV you
need to test on cars you need to test on
different networks it's the spreadsheet
that has been pulled over your eyes to
blind you on the truth what truth that
you are a slave neo like everyone else
your manual tests are catching bugs that
could have been caught with automation
or emulation immediately a prison for
your mind
your life is being wasted installing out
on a hundred different bones you know
you'll never prevent a regression this
is your last chance after this there is
no turning back you take the blue tablet
the story ends you go home test however
you want you take the red tablet you
stay at gtech and I show you how deep
the automation goes
okay hope you enjoyed the video so going
to ask you to make a choice would you
like to take the blue tablet or the red
tablet good I have no slides for the
blue tablet so why ultimate let me put
this in terms that everybody can
understand just look at this function
this could actually be a Google into
your question can somebody tell you what
is the computational complexity of this
function entry yeah yes so let's look
into this we have tests that's running
on different devices these devices could
be nexus one nexus s nexus 7 10 razer
droid many different devices that they
keep adding new ones every day now these
devices might have different API levels
by API level I mean different android OS
it can be Froyo gingerbread Gingerbread
mr1 ICS jelly bean and so on so you can
see there's combinatorial explosion here
we have full matrix of different devices
running different API levels this is how
developer desktop might look like
android developer desktop you can see
there's a bunch of phones lying around
lots of cables generating lots of heat
but way there's something wrong with
this picture for each of the phones we
need to have different API levels so for
next 27 we need to have one which runs
gingerbread froyo jellybean ICS so this
pile is even actually bigger luckily
typical developer uses only one or two
phones on their desk and they develop
the test on it and there's some point
where they need to test in a different
point which they don't have then they're
just going to scramble around run round
office and scream does anybody have
reason droid does anybody have nexus 10
so they can test my
picture on a different one so automation
is actually easy to paralyze you just
have tests running on different phones
it's the same test running on different
phones using different deeper levels but
why aren't we automating what's the
problem well we have several problems to
deal with first you need to have a place
very going to run your tests so you also
need to have a device is the accessible
under your fingertips you might need to
test it in a tablet or on a phone which
has different density and you have it
easily accessible and also we need to
make it fun and easy to write tests
otherwise you're going to meet lots of
resistance people just going to give up
and not write any tests so this is
written in developers to the android com
and it states when building mobile
application it is important that you
always test your application on a real
device before releasing into users this
somehow gets twisted and turn around and
become suppose down to two this we only
do testing on real devices otherwise we
don't catch any bugs oh this is not
necessarily true so to do testing we
need to have a device lab you need to
have a place to run tests so we have a
choice we can choose a data center
hardware which is gray and boring but
it's reliable stable it's standardized
it has a published data about mean time
before failure so you exactly know the
time when to replace your hardware and
you have a good vendor support 24 7
another hand you have a consumer
hardware you have the scale kitty phone
which is very cute very desirable but
that that's not really a reliable when
especially when you run continuously
24-7 you bombarded with lots of tests
non-stop they just going to give up at
some point it's it's meant to be used
for about six months and then replaced
with a newer model and the support for
it interests in your local mall where
you actually bought a phone it's a
little kiosk
it's not very good support for it so you
would think that Google has amazing
device labs but something that looks
like this maybe so I'll show you the
actual real lab which I encountered
about a couple years ago so here you see
bunch of nexus s phones they're actually
glued to the wall with a pill velcro and
they use USB cables to connect to the
USB hub which is in turn connected to a
desktop workstation so this was great it
actually ran tests it was actually
mesmerizing sometimes their encounter
people sitting there for hours looking
at tests running but then problems start
happening the USB cable gave up the hub
is having problems the desktop just
rebooted sometimes and then in a remote
week or two because you continuously
running tests the CPU heated up and
melted the glue and the phone started
falling down one by one suddenly sudden
you get test failures people start
pulling their they're here you know
what's going on which keeps failing yeah
when it's really hard to manage this lab
this you fight against gravity here it's
it's really tough well the lesson is put
them on the table yes so managing the
physical lab has lots of problems I mean
there's security somebody can just waltz
in and steal your phone there's
maintenance you have to replace the
phones there's new points being issued
the phones died or because things happen
to them then you have to upgrade the
software on the phones so you have
hundreds of folks sitting there how
you're not reading how I'm going to
manage it how you're going to connect it
to the proper hub this the hardware is
also consumer grade hardware it's not a
server hardware which is very stable you
have to wreck it you have to arrange it
in small spaces and they're all
different sizes and shapes
then they give up lots of heat and we
had lots of problems with signal
interference when you have Wi-Fi radio
of hundred phones sitting in a small
space they keep disconnecting all the
time and you have this post failures so
it's automation dead on arrival how can
you even test when you don't have
anywhere to run their tests well where
we still hung up on her on a real phones
what are the most common bugs the unit
conjure the class of bugs that you
mostly encounter are concurrency and
buffer overflows and off by one errors
do they care which divides the run no
this device this bugs are going to
reproducible Renee device they do run in
addition to that if you replicate the OS
version the screen size the cash and the
memory constraints deep will probably
catch 99 percent of the bugs and we have
the full matrix setup there's still a
chance there's a small set of bugs that
you can slip through and they're usually
very hardware-specific like Bluetooth or
secure element but we can work around it
by insulating the code around it and
then testing it in insulation this is
actually a real google data center it's
quite pretty and we can run emulators
and data centers that means they run on
a cloud we can scale without any limits
well there's some limits but it's quite
large these servers and handle lots of
emulators can somebody tell me how many
seconds are there in mono March this 2.6
seconds in in march in the month of
march we managed to run about 82 million
tests in march so we can scale pretty
good we also have reproducible test
environment we start fresh emulators
during clean state so there's nothing to
contaminate from the previous run and
and in we have fully controlled test in
mark
but it's ridiculous you're going to test
on emulators that's not the real device
actually it's just another Android
device it emily is the real phone
hardware and the system images are
almost identical this is called Android
Android system architecture looks like
i'm not going to go deep into this i
just want to point out what is device
specific can somebody tell me where to
usually find bugs in this diagram well
you don't find any bugs in this diagram
you find bugs in your application
actually so we optimize the emulator we
create a device specifically specific
device specifications for all the
emulators or all the device they're
going to try to emulate the tube the ram
the screen resolution the screen density
and we also take the operating system
Android emulators come with a rooted
system so you can easily change the
product model to reflect the real device
name and we install some tests friendly
services this services allow you to
create an account take screenshots
dismiss the NRS and system pop-ups that
usually causing the they're usually
causing the flakiness for UI testing and
will log everything not just the log
kehte belong to a system dump in vogue
everything that is laudable that makes
it easier when you debug the test
failure you can just go drill down look
at the logs see the whole state of the
emulator and find drill find the root
cause of the bug so how do I find the
device that I want to use I'm developing
something I want to test my feature I
have to dig it down in this pile and
connect the right cable to the right
phone
is there a better way to do this well it
would look something like this this is
actually the elevators that was talking
about we developed a tool that you can
launch any emitter that you want by just
specifying in a command line line saying
launch next to stand using jelly bean
and boom in like three seconds you would
get them later there you can install
your apk going to tell your tests you
can run tests you can do whatever you
want with your emulator emulators just
too slow so this is the Android boot
sequence I remember the first time i
installed android sdk I started running
the emulator it's blinking and said it's
booting I lost my patience after a
couple of minutes and I just kill the
process I tried it again the same thing
happens after several minutes i got my
android running cool you know it took
some time this is not very friendly so
if you look at this boot cygnus it's
very similar to desktop and that's to be
have something called hibernate then
Droid we have something similar golden
snapshot so what we did we just took a
snapshot and then we use that to boot so
we boot directly into Android and that
takes about three to four seconds so
what happens under the hood on the phone
the phone on the left side you have the
phone on the right side you have the
emulator emulator runs on the on the
host hardware can somebody tell me what
is the bottleneck here or somebody draw
the yellow rectangle to help you out so
in this case encasement we demoed it
runs on host hardware and we are
emulating the arm CPU the CPU
instructions are interpreted and that's
really slow it's a software emulation
so what we did we removed that
bottleneck we compiled android x86 and
be running that directly on the host
hardware the host card where you need to
turn on the virtual virtual machine to
be able to to emulate directly and run
and we directly on host hardware using
them later and this runs much faster the
host hardware is a bit much beefier
machine than any Android device this
problem is solved we reduce the boot
time by using snapshots and we are
speeding up using virtual machine so i
created a little video that demonstrates
the race between the real device and the
emulator using running the same set of
tests like a little loud ok same problem
and we have a winner so we solved
several pieces of the puzzle we have a
place where to run tests we have a any
device we can bring up under your
fingertips at any time that you need to
do your development and testing cool
there's lots of work you're done it can
go home have a beer it's only this don't
be this guy listen to Jackie Chan is a
wise guy so in testing on Android is
different than typical web testing the
web testing we have it down pretty good
we have we use design patterns either
Model View controller or Model View
presenter we put most of the business
logic in a presenter and we tested
installation well view doesn't have much
logic it's pretty lightweight in Android
we have something called activity is
activity a view or a presenter well it's
actually both activity contains both the
view logic and the business logic of the
presenter so you're a little bit of
disadvantage there for testing android
sdk provides really nice to call android
instrumentation and it's a nice layer on
top of android that allows you to to do
all kinds of wonderful things like
clicking on the screen in an invocation
sending key events sending text and also
inspecting the state of your application
and is inspected verifying what's going
on the screen however it's very
complicated to to use the API is not
very friendly so there are some efforts
outside of Google open source efforts I
have experienced with robotium that
try to solve this problem by providing a
simple API we start using that and start
running tests using robotium but after a
while our tests became very flaky and
they looked something like this our
continuous build which runs the test
continuously started to look something
like this fail fail fail pass/fail pass
and these failures are not genuine
failures those are the fake failures
their failures because the flakiness
matrix Vince Vince you view testing is
too hard let's just give up and go to
the beach that's it why are the tests of
flaky well then really we have you I
tried which runs the business logic and
then we have a test read which we
request a clique which translates is a
motion down in the UI thread then motion
up so some side effect happens meanwhile
and if you don't assert in the right
time we get a failure we solve this by
putting asleep okay that works but then
in the future something changes in the
code and our side effect changes the
location and then we again have a
failure so that's causing flakiness so
what if we could but if you could put
all this concurrency handling and
synchronization under the hood and come
up with something like this to help us
run testing we can only focus they can
then only focus on procedural testing we
can say click on this view and then
verify if this text appeared well
earlier this year my team got together
and we did a deep dive into android OS
and we came up with a framework to go to
to give us something like like this the
code espresso fortunately it's not yet
open sourced and we are working on that
so hopeful it's going to become
available sometime soon
so I would let go to show you how this
automated testing look like for us of
course that's right
so we're not going to go into QA yet I
wanted to talk about I want to show one
more video later on and remember earlier
we mentioned there is some set of bugs
that we cannot catch with emulators and
I get a chance to work on a Google
Wallet project where we had a secure
element which was stored on the phone
and one of the main features robot is to
be able to come down on the reader going
a range of the reader and then tap and
pay and then get out of it so that was
really hard to emulate and I was
thinking how to solve this problem I
came to India to go and buy a little
robot arm I thought it was cool so did
in my free time kind of thing I went to
local store about this arm which was
about $35 and he had a USB connector I
wrote a little driver for it and it was
very simple we were just saying turn
this motor on for one second and turn
this out a motor for two seconds and
that was it it was a great joy mean I
can solve this problem so I tried it out
he was going down and up and it was
actually working but if I did it like 20
times it went out of alignment so start
hitting the desk I like crap you know it
was a great idea it's not going to work
I went home I was taking a shower like
hey the phone actually has the gyroscope
it's a very precise instrument I can use
that to tell me what is the angle or the
phone there's like cool i'm going to try
to doubt so I wrote a little app to tell
me what is my angle and then I cooked it
up and I made it work so i'm going to
show you the video of that
that's a duct tape this is going but
this for the phone
do one more okay now we can move into
questions yes so the rums are we are
testing on in a Google Experience phones
and they cannot get a manufacturer
specific runs but I think most again
most of the boxwood should be covered by
testing the google sprint phones unless
something drastically change in the
manufacturer roms it's possible yes
although it can also be available on
eclipse or is the only specific boohoo
so those I motors are available on
Eclipse there's the same address we use
the same images there you have x 8x six
images that you can use from eclipse
what we did we did some additional
modifications to the others to make it
more friendly for Google developers and
it's like installing a setting up the
counts changing the memory taking the
memory RAM size density that's all
available we can just go and do it
yourself
hey how's it going so we actually moved
away from emulators back in 15 because
we saw it problem with him crashing your
try to run our tests in the near and
they would crash so we this became a
problem how do you guys deal with that
sort of flakiness or has that stopped
becoming a problem he's we never
actually used snapshots so we vehicle
optimized our emulators if we made sure
that they're not crash and we didn't
have any problems with crashing do you
know any reason why why they were
crashing we have no idea have you been
using x86 emulators or yeah we're using
x86 on a bunch of boxes so not sure why
yeah so maybe it's the hardware that
you're running on I'm not sure try try
using different hard right everyone
ordering sounds you it's a very specific
question it's hard to tell that was the
reason for the crash so much you're
curious so how much manual testing do
you guys do if any that's a good
question I think mango testers are very
precious and you should use them
preciously right we should do most of
our testing using emulators you're doing
unit testing and try to automate as much
as possible and just let our manual
testers do real testing exploratory
testing creative testing versus trying
to go and execute big matrix of list of
things I'm checking the boxes because
they're going to be testing it as a real
users and that adds real value then
would you walk up to the microphone
please one of your remarks it sounds
like you expected developers to test
them so is that how you work or do you
have a separate Q a group or separate
testing group that's a good question and
Google be a part of you your job as a
developer is to write tests so it's your
job it's test-driven development so you
have to write test before submitting you
shouldn't be submitting your code and
repository before you didn't without
writing any tests and this test have to
pass before submitting submitting it in
that baby ensure we have quality at head
revision we have somebody in the back
there give us an idea of what a typical
test suite would look like for any
arbitrary project you're a piece of code
that you're about to test what's what's
the lifecycle of developing the tests
and and and then the effort that it
actually is involved given the
supporting a good question we have was
go to Google which is distributing test
into a small medium and large and that's
the rule is about 70 2010 the seventy
percent of your tests should be unit
test small very very small tests which
executes really fast and they're not
dependent on any UI or anything large we
shouldn't be talking to the network this
should be focusing only a new function
then you have medium test which exercise
testing between different components and
you have large tests which are
end-to-end tests which the exercise the
whole system so that's pretty much the
philosophy that we go by when we design
tests most of them are very small and
then only ten percent should be large
oh the complexity hasn't changed them we
still multiply the number of tests by
the number of platforms to get the full
coverage right yes and yes you can get
more tests running at the same time on a
host than you can on a consumer
electronics device yes okay but as you
keep adding more devices and you keep
adding more tests how rapidly or the
respective size is growing the amount of
work you have to do and the power you
have to do the tests yes so we can scale
very well in our data centers so right
now there's no concern about running out
of you know processor time or space in
our data centers but you're right you
know the matrix is expanding its growing
but we also look at the usage of
different older operating systems for
example donut is not really used that
much anymore so we might decide at one
point to drop it and reduce the tests
that they yes of course own perception
you don't expect progress be as fast on
Android as other platforms know if you
agree lot but that it's skeptics and
expectations so you try to test this as
possible an Android for the performance
so you know you imagine about it for you
past is hailing the program does
something unexpected right yeah but this
you know the perceptional parts that are
not really part of the discussion but to
the testers that is problem especially
it'd be something really intense
correctly but even if it's a business
application you know if it's like
jerking around you know you're behind
your condition that and you don't
know it until you test on that device
know that it brings back the problem of
testing on an emulator sometimes it's
faster than the real device on press it
slower there's no you can't predict this
well okay but suppose you do say okay I
want to test on my emulator zone but
still have you test the performance
aspect of that program IT that's a very
good question performance is
you mostly test the logic on emulators
that's the primary goal performance you
can put in some instrumentation and try
to test the performance and optimize it
to an ammeter itself but it's not going
to guarantee that it's going to run the
same way on the device and it's a whole
different set of problems that you have
to deal with and you really comes to the
performance testing I guess you can
still improve your application using
emulators and make sure it's optimized
there and it has a good chance running
better on the real device but it doesn't
really help you much running on a murder
it's not going to give you the real
information that's true you guys have
plans to provide that also something
like cloud service maybe in the future
and we definitely play with this idea
it's honestly it's a it's lots of work
and it might be possible in the future
we're discussing this I I can tell you
it's going to happen anytime soon but
it's possible I think it's a wonderful
idea the application that we're testing
uses metod YouTube videos and in the
past the emulator hasn't done so well
playing video in automation has it
improved and how do you handle a video
testing in house yes very good question
the did enable OpenGL emulation on
emulators so if you have the coast
machine which has GPU it's possible to
run OpenGL and actually have the GPU
acceleration in that case the videos
will work fine if you have the set of
hardware that a standard we have set up
servers which don't have a GPU then you
can have troubles but you can still go
around it by using a mess up drivers
which is a software video driver
emulation it's going to be slower but
it's still going to achieve the effect
of testing your video
yes so think of it as emulator being the
real device so it actually operates as a
real device there have any specifics on
which oh yeah you can run anything is
you can run a real device as far as the
OS is concerned it's the same it's
running on device it doesn't know it's
running an emulator oh we're just trying
to pretend that we're that specific
device let's say Nexus S has a I don't
know exact number but 64k cash and he
has a 512 memory so we make sure that
our emulator has the same constraints
ramco straight so to read if your
application runs on the memory in the
next success it will also run out of
memory on the emulator yeah that's
that's a good question that probably
falls in a category of this one percent
that we can test and emulators the way
to go around it is to take your code
which interfaces with sensors insulated
and then test it thoroughly in
insulation and then probably have some
kind of a menu addition on the end of
the day but most of the bugs you're
going to catch in the software emulation
so you're going to have to do minimal
work with a real hardware that point yes
you can borrow one of the features of
our test services we also added ability
to change the orientation which has the
effect of redrawing the application yes
yes if because you're not a microphone
I'm going to repeat the question do
diameters reflect the sense UI the third
party actually the rum producers
modifications no we just use the Google
Google Experience bones so we don't and
there's a slight possibility that
something might not work as as expected
there because we don't have the images
their proprietary yes again you should
use emulators so there's something
called webdriver that you commonly use
these tests the web applications and you
can use the same webdriver implantations
for there's a webdriver implementation
for Android native browser that happens
to be the same as a webview webview is
using Android native driver
implementation and also other browsers
for Android like chrome and I don't know
maybe opera they should have their own
implementation for webdriver they might
not but they it's there is possible to
implement the webdriver spec and they
can use the webdriver API to drive your
testing on the web page of the Android
yes I have another question so we
actually use your podium in our project
a little bit ago and we had some
experiences in terms of the flakiness
and we recently switched to the UI
Automator which was released by Google
for my jelly bean um do you have any
comments about it because you mentioned
that you are working on your own big
espresso so is any particular reason
so it's not the different UI tomaters
you oughta mater's try to approach the
problem from different angle they're
using the accessibility framework and
they don't actually have the access to
the context of their application so they
can just click around but they don't you
don't actually know what happened
underneath if you can't query you can
change the state of the application and
it's not using instrumentation right the
approach we took is to use the
instrumentation to drive the testing so
I mean there's overlap but again you
know you can use both to solve different
problems and it's it's less flaky
definitely good more questions okay oh
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>