<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Google Faculty Summit 2009: Book Search | Coder Coacher - Coaching Coders</title><meta content="Google Faculty Summit 2009: Book Search - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/GoogleTechTalks/">GoogleTechTalks</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Google Faculty Summit 2009: Book Search</b></h2><h5 class="post__date">2009-10-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2D3BZTJZyQY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm Dan Clancy I'm the engineering
director for google book search some of
y'all I know from a previous life where
I used to be at NASA where I ran the
information scientist Directorate and
i'm going to give you like for talks
today in one so i'm going to try to jump
through this and part of this is you
know feel free to start asking me
questions because again they're like 12
directions that i can go in this and i'm
going to try to kind of touch on a
number of things okay so i'm just going
to start i assume a quick question how
many of you have used book search okay
so i was going to assume that Y all
pretty much know what's happening there
so I'm going to just give the requisite
couple minute kind of background to make
sure we're all on the same page so we
all know that we started this project
really because there's this vast amount
of information that's not accessible
Larry and Sergey had a deep belief which
I share that information retrieval and
search has really transformed the way we
interact with information but the bulk
of our cultural and historical heritage
actually was not accessible in the
internet so let's digitize it all let's
make it all searchable got books from
two sources we get books from publishers
that's what you see a lot on there where
we actually get copyrighted works we get
permission and you can preview up to
twenty percent of the works sometimes
more we get books from libraries for the
public domain books we let you see the
entire thing we give it away for free
pdf download etc etc for the in
copyright we only show three snippets
because we believe it's fair use to scan
in index and f snippets so that's the
let me just think I think this now goes
to doesn't go to lawsuit yet but so
that's the subject of the lawsuit little
thing and I'm going to talk a little bit
about the settlement first I'm going to
talk some about the challenge of how to
find books and how we integrate books
into Google okay and break down how we
think about it so broadly I think of
queries in the following different ways
what I'll call on information query
usually with an information query the
result is some content match okay we're
really without the content you couldn't
have matched that okay so an example
might be PageRank algorithm there's
somewhere in some book on page 178
something that describes the PageRank
algorithm
them so that's what i call a Content
match and that's where we usually blend
stuff into google so it's just like a
web page no difference okay another
class of matches you know what i'll call
topical i'm looking for something on
this subject and there are a number of
books that might be relevant on this
subject so information retrieval an
example of a topical you don't want to
land in the middle of a book now of
course they're interesting interplays
here because for some topics there may
be good chapters which are parts of a
book right you can have a good summary
chapter on information retrieval and
that's actually a great result sometimes
in fact it may even be better than the
whole textbook okay then you have
navigational and sometimes navigational
or author navigational or our title
navigational where you want to be able
to find a specific book okay each of
those we handle a little differently one
comment i'll say that as you think of
these things you know remember that
often d and i'll talk a little bit about
some of the search challenges you don't
just want to take the text that is on
the book that in fact for title you know
if you're looking for Bill Clinton's
autobiography you might not know it's
called my life but you may search on
Bill Clinton's autobiography that's
still a navigational query so the way we
present this is we presented differently
depending upon the type of query where
we've seen the biggest benefit and where
the focus of the project really was on
was predominantly on the information
content there are lots of ways that if
you know what book you want where you
can find that book but we found a lot of
serendipitous discovery from the fact
that we text the whole book so i'm going
to talk about this a little later when i
talk technically about some stuff one
thing i wanted to let you all aware that
in terms of the value of uncovering all
this information the data here is
actually about a year old i haven't
rerun it yet site and i think it's
actually a little lower now but what
this is showing is that this is over a
30 day period the and this one is the
number of the number of viewer books
public domain books which is visits line
where users have seen at least 10 pages
okay and it's fifty percent of our
public domain books at least 10 pages
are viewed every month okay for our
partner program books it's over eighty
percent okay look this is a
demonstration
is really the value of serendipitous
discovery from full text search and just
integrating it into google because for
much of this stuff people may not have
checked it out from the library for
years in fact at Harvard none of the
pages it either been cut so we know
nobody ever read that book so you know
in kind of these questions of the long
tail they're just countless examples
will people find stuff and I'm not going
to go through all the testimonials where
people find something about their
grandfather were all they knew was he
was in war war one and here they find a
book that explains the division in the
infantry who is on and their blah blah
blah now they know all this about their
grandfather that they never would have
known and those examples just go on and
on so I really think it's a
demonstration about the value of long
tail search serendipitous discovery and
I think there's still a lot of not so
much computer science research I keep
trying to get a lot of the library
science folks I think there's a lot of
interesting research about finding how
the internet and full-text search helps
this stuff much more so than where it
had been before you know in other words
and how much more usage do we see it as
stuff I think there's good longitudinal
research that's interesting to do so now
part of the thing I'm going to talk a
little bit about is our scanning okay
and now this in and of itself can be
five talks okay and I'm not going to go
in and show all sorts of all the details
but I'm going to give you a little bit
of background in terms of how we
approach to this problem and i'm going
to talk maybe a little more than some of
y'all have heard us talk publicly before
um so we approach this problem in much
the same way that we approach our
large-scale deployments of our serving
centers it's really kind of saying let's
let's take into account that there'll be
errors and then let's write soft smart
software and also use people to find
those hours and account for those errors
and the analogy I like to make in terms
of our approach to scanning and this
group will understand it well is a
comparison of progressive jpg versus
what used to happen where the JPEG image
would just slowly inch up the screen and
the waist getting used to occur was you
know you would scan a tiny bit and you'd
make absolutely sure it was true it was
right but we would we were walking in
tiny
any steps and really the way we
approached the the mass digitization
issue is saying how can you do this
scale except that there are problems and
so that when you consider over time the
quality of the corpus that it really
fills in in terms of the quality of what
you get and where you can invest your
resources proportional in some fashion
to the usage that that's going to
receive so there's certain books where
you should spend a hundred dollars to
scan and some books are you maybe you
should spend fifteen dollars to scan and
we shouldn't just act like everything's
the same okay so the way we do this is
sort of with these progressive circles
here okay so um I'm not going to go
through the logistics obviously we
developed our own scanning technology
I've actually I know Larry was here
earlier if you all see him at any of the
reception's you can go tell him Larry
why don't you let them talk about their
books get anymore okay because actually
the patent is out and I tried to push
her but you know I said look Larry the
patents out okay it's not like it's a
secret anymore so if you want to figure
out how we do the scanning go read the
Pat okay but this is a little bit
broader in scope in terms of what we're
thinking so part of it is the actual
scanning and there's one thing which is
how good is your picture that you
require okay then we do a ton of
processing after the scanning ok we have
2d warp the image we have to clean the
image we do OCR so there is a lot you
know there's a significant amount when
you look at the computational resources
required to do all the processing it's a
lot now part of our approach to this was
saying we can keep making our software
smarter and reprocess all the image so
we've actually reprocessed all of our
books I think we're going on it the
second time now okay and we're going to
do it again in a year because we've made
our processing software smarter and so
many of the problems that people might
see are actually software problems that
we can fix okay now this comes the thing
you have to be able to do is when you
take the actual picture say is this a
good picture so we actually have site
what I call it's not really real time QA
in terms of real time systems but it's
kind of while we're scanning the book we
have some degree of automated to
detectors to try to figure out if an
error has occurred and we do have humans
turning the pages everyone knows that
from seeing the hands so we have ways to
say did they make a mistake and then
possibly get them to turn back if they
did okay so that while the book is still
they are we fix it okay but that's not
perfect okay sometimes it screws up now
we have the processing and storage now
in our processing sometimes it's our
processing software that screws up okay
sometimes it's the scanning bit screwed
up so there's a time lag here between
when we realize there's a problem here
versus when we realize there's a problem
there okay and part of this allows us if
we think it's an acquisition problem
where we still have that book and we can
scan it again before we return the book
okay so a lot of our books we scanned
twice okay because if somebody made a
mistake the first time we scan it again
now you still have the challenge of
putting those two scans together to
create a combined product which is
itself a very challenging problem
especially if you have multiple pages
within each scan because you not only
need to detect that there's an error
which can be very challenging you know
but then you also need to pick which is
the right page and what's the right
order of the page so that's where we
spent a lot of time and in this we
always take this kind of combined
automated human approach where we have a
robust QA process where we can ask human
simple questions so we don't think of
the world as it's all software or it's
all people the way we've brought the
costs down is saying let software be as
smart as you can and one of the mistakes
that I think we made early on and for
other folks doing this I encourage you
to think this is we we overestimated how
smart we could make the software so in
fact what happened was as opposed to the
quality of what you see being constant
and the costs going down as our software
got smarter the cost remained constant
and the quality was the thing that
suffered okay and then over time the
quality came up okay and later on we
sort of rethought this and realize hey
maybe the right way to approach that is
a little different you know in other
words don't assume
let your software get smarter and make
it so it's cheaper don't always assume
that you can write as smart a software
that you're always going to overestimate
how smart you think you are in terms of
the software you can write so lean on
humans a little bit earlier more than
not now so we have another stage at the
QA here and then really the big thing is
as people use this stuff well well now
that's the glory that we don't have to
look at every single page to detect
every single error because people will
look at this and we can get humans that
are using it to tell us where there's an
error and then we can feed back and
sometimes we may have a better scan of
that page sometimes we may need to scan
that page again so again it's sort of
approaching this combined human
automation along with different time
cycles in terms of the feedback loops so
that when you look over a five-year
period the question is where is the
quality that you end up on 30 or 40 or
50 million books and not how quickly do
I where is the quality on a small subset
at this point in time which is for one
of the things I find very interesting
and working with a lot of people from
the library's is well they've preserved
these books for decades or centuries
they also a very impatient lot and so
try to get them to realize that it all
doesn't happen right away has been fun
um so now I'm going to talk about
another big challenge that we're facing
so we spend a lot of effort on OCR so we
right now OCR over 100 languages all
Greek Roman Cyrillic we now do thi frock
der McGlone inch Arabic so we've
invested a lot we have an OCR team and
we also licensed software the project
that we're really emphasizing a lot now
is automated structure extraction which
there's been a lot of good work on
luckily parked in other places but
really the kind of grand challenge that
I think is in front of us is the way I
like to describe it is suppose someone
gave you an xml version of a book today
and then they gave you the same book to
scan can you scan that book and
transform that book so it's an
equivalent object as the xml thing that
they gave you and if you really want to
make the books that have been published
over the last 200 years as vibrant in a
digital economy as the books published
today
need to be robust digital objects
because you can't just be dealing with
page images okay and so there's lots of
issues here obviously in terms of
extracting you know structure and
captions and images mathematics
equations is a great thing right that
right now we just say oh this is an
image and take it as an image but
there's all sorts of interesting
challenges about you know how to
actually extract the structure of the
mathematical equation but and I don't
think and I'm going to come to this in a
second this isn't just a google thing I
think you know broadly you know this is
there tons of nice research challenges
here that I think people can dig their
hands into so I'm going to touch base it
because I want you all to be aware of
this as we talk about some of the
research another thing we're doing is
digitizing old newspapers which again
offers a host of research challenging
we're doing it from the microfilm okay
so this is the google news archive
search um one of the big challenges in
newspapers which I find particularly
which I don't know what the answer is so
I'll throw this out so that people can
be you know thinking through it for
books it's pretty straightforward how to
I think mine the value of that because a
book as you think through a newspaper a
magazine and a book newspapers tell you
what's happening right now there's not
much of synthesis over time but for
someone who's deeply researching that's
really useful magazines a little more
synthesis books even more synthesis okay
so when you're looking for certain
things you'd prefer the Wikipedia
article which gives you a nice synthesis
but really what's in the newspaper is
actually a chronicle of what's happened
across the world in terms of daily life
and also perspectives that people had on
events at different points in time okay
so i think there's lots of interesting
social research that moves beyond just
how we look back on what happened but
actually how people view the work as
they're going on okay there's also tons
of interesting research in terms of how
to parse the newspaper how to clean the
paper some of these things or total crap
so this is some of the cleaning that
we've done on this and so I wanted to
mention again part of this is in terms
of corpuses you know one thing i'm going
to talk to about is somewhat the
settlement allows
but as people have research ideas that
can build upon some of this I can't tell
you yes we'll give you everything right
now but I'd like to hear the ideas and
let's see where we can kind of act as a
resource for some of the ideas that
people might have in this area so now
what I'm going to do is take very
quickly give you an overview of the
settlement agreement and then I'm going
to talk about one part of it that I
think is important to this group which
is the research corpus um so in the
agreement and this is suddenly two
lawsuits class action settlement and as
that the class is basically in fact many
of you are class members how many of you
are authors okay how many of you have
out of print books okay how many of you
know whether or not you own the rights
to your out of print books okay probably
many of you said I don't know okay um so
part of the way the settlement works is
for any in print book all we can do a
scanning index and we can't show any
content unless the right shoulder comes
forward and says you can show content
for out of print books we can scan in
index and there are a number of access
models we start making by default okay
i'll talk about them in a second and
part of it is designed where rights
holders always have choice so they can
opt out of the settlement which says i
don't want to be part of it they can
remove their book from the settlement
which says I don't want you to scan scan
at Google so they say in the settlement
but they tell us not to scan it and
that's legally binding and we can't scan
it and we've already scanned it we have
to delete it or more importantly they
can turn on and off the different models
at any point in time they can pull it
out they can put it back in lots of lots
of flexibility in terms of on what
they're doing so in fact you don't have
to stay with Google there's no oh if you
don't do it by this date you know you've
missed the boat okay with the outer
print stuff by default we're going to
start making excess the the services are
a consumer purchase ability for users to
buy it preview ability for users to
preview up to twenty percent to
determine if they want to buy it when I
say consumer purchase what they're
buying is electronic access to the book
in the cloud okay it'll be there five
years ten years and they can always get
it when they're online
so preview see up to twenty percent of
book for free and they decide if you
want to purchase it and then an
institutional subscription you build a
license to universities and colleges and
whatnot right solder is supposed to come
forward and claim their books since many
of you are class members I'm not
communicating to you as class members
you're represented by counsel blah blah
blah but note you should go and claim
your books even if they're in print
because you still have rights and you
should be aware of what those rights in
the the URL is I think google book
settlement com if you just search on
bing for google book settlement I'm sure
you'll find it okay so so in terms of
the access models any money that's
collected is given to this group called
the books rights registry which is
independent from google and it's run by
authors and publishers and they're
supposed to hold the money on behalf of
the rights holder and try to find the
rights holder for books that have not
been cleaned and so over time what
you'll do is see them more and more
finding out who are the rights rights
holders the database they build of what
books have been cleaned and who claimed
the books has to be public so that means
one of the big questions is does this
give you a monopoly on all this stuff
well the as people come forward if they
want the registry to represent them the
registry can in fact will and the
information about who are the rights
holder has to be public so people don't
have to work with the registry they can
just go right to the right shoulder okay
so that's a very quick outline of the
settlement for those of you that are
interested actually there is an event
tonight at the computer history museum
which is just
you
before that for them you could feel free
and I assume there's some event with
this as well but your history museum is
just right down the road and that's a
good forum to kind of hear about that
but that wasn't what I want to focus on
here so what I want to focus on so there
are two things that I want to focus on
and i'm going to take go off the
settlement for a second one of the
challenges we've run in in the
settlement is people think that that's
our vision for the future of how books
will be bought and sold and it's
actually not it's our vision for what to
do with all these out of print books
which is not the future of the book
market okay the future of the book
market are the imprint books in the
books that are yet to be published okay
so one of the things we're developing
here is we're trying to figure out
what's the right role for Google because
this isn't our core business but it just
so happens we've scanned millions of
books okay and in particular we want to
know how can we engage in this market in
a manner that keeps it kind of more
competitive and more open so our
strategy is we're going to have a
heavily focus on retail syndication so
that you should be able to buy books
from anywhere okay they'll be stored in
the cloud and then you should be able to
read them on any device so if you buy a
sony reader if you buy your laptop if
you buy your whatever okay for those
people using general purpose devices
we're going to rely heavily on HTML or
and or Google gears and the browser is
really going to be the app that we're
going to Center this heavily around the
browser as opposed to dedicated clients
and kind of work to make sure that the
security works there because we think
from a user perspective you don't want
to be loading this app or this app
really the browser is becoming the app
and you should be able to access it from
any device that's a computing device
that has a browser and it should be the
same so it's very much trying to focus
on how can the browser be the app what
can you do with html5 offline
capabilities and also then how to
support other reading devices okay I'm
so and I think for those of you this
isn't a computer science question per se
but I think there are a lot of
interesting questions and y'all can feel
free to grab me I think I should be able
to make the reception later about what
happens with copyrighted content in the
cloud and how do you deal with this
becomes your expectance of the
dependence on the cloud and also the
challenges of how to make sure the cloud
doesn't lead to
one dominant player which is one reason
why we're focusing a lot on retail
syndication and I'm not going to go
through this we're doing some other
things to make sure the clouds can
interoperate because we think it really
needs to be open now what I'm going to
talk about is one important part of the
settlement agreement in particular with
this audience so one of the things that
the settlement agreement does is it
gives us the right with our library
partners to create to what are called
research corpuses and they're really
research centers okay and what this is
is we're taking all of the books we
scanned and our library partners can
make up to two centers that will have
all of these books for research okay now
today one of the problems that we have
is since many of these books are
copyrighted and we don't have
authorization so Google currently we've
scanned over 10 million books okay all
sorts of research you can do on 10
million books I can't let most of you
ask I can't give you those 10 million
books because to the extent i give you
the books some copyright holder might
sue me and you and to the extent that
somehow gets out then we've got all
sorts of problems ok so in here this is
actually a fully if the settlement is
approved ok we get full authorization
from the copyright holders the class to
give all these books to create to
research centers ok for what is called
and I apologize I'm the one who made up
this name and I still haven't come up
with a better name if any of you can
come up with a better name please tell
me in the settlement agreement it's
called non-consumptive research it
doesn't mean it doesn't have a disease
ok it's trying to capture the idea that
these this is not for reading all the
books which is the idea of consuming the
intellectual content for which the book
was written but rather it's for
computational analysis and other large
scale analysis over the whole corpus ok
and so it basically there's kind of
clear authorization for people do
anything that's called non-consumptive
and it has a definition in there if your
goal is I really want to read John
Grisham's latest book that's not
non-consumptive research okay but
there's countless other things that
people will want to do ok so it really
range is quite diverse Lee so certainly
new search technology is a few
area of non-consumptive research okay a
linguistic analysis image analysis
information extraction better OCR better
automated translation because we have a
you know a huge parallel corpus here
because there are lots of books that
have been translated into multiple
languages and now you have the text of
these books so this is just scratching
you know scratching the surface of the
type of research that can be done on
this on these resources okay and the way
it works is our library partners of
which now there are 30 that I expect
will eventually become partners they all
are responsible for building these
centers we're putting up 5 million
dollars for them to build the centers
but it's their jobs to do this it was
really important a lot of times they
said Google why don't you do it although
one of the challenges as you're talking
about doing lots of research that in
fact may be competing with Google ok
saying you have to come and do it on a
computer you know even though we might
sail but we promise we will look I mean
it's some level there's some
apprehension if you say yes you do all
your research on my computer ok and I
thought it was important to make sure
this was independent in terms of Google
that in terms of running these things ok
and any of the IP is of course retained
to be yours blah blah blah ok that and
Google is not involved in deciding who
gets to access this well universities I
say libraries but it's really the
university's I suspect since of the 30
University which has includes all the UC
schools CIC Michigan Stanford Princeton
Cornell Columbia they all came on I
suspect many of you are professors at
those schools and in fact we are also
talking to many other schools and we're
very interested in adding other partners
so I suspect for almost everyone in this
room there's a reasonable chance that
your your university could be would be a
partner and you can be part of trying to
figure out how this is run and anyone
else can still access it but it's just
their responsibility to figure out the
deals with the university's figure out
how people access it ok now let me now
what I'm going to do is I'm going to
talk through a few examples of research
that either we have done or other people
have done and then i'm going to talk
through what i think are some of the
research problems that face us okay and
this is just to get you thinking of some
of the different things that you can do
so this is something that we have in
book search today it's called popular
passages okay and in here and this was
done by okin colic and i'm bill shill it
and the problem they said they wanted to
look at was let's figure out those sort
of seminal or popular passages that
actually are referred to a lot in this
corpus now if you already know what
those popular things are it's easy it's
just search the problem is you don't
know what actually is the things that
happen over and over again and one of
the challenges us to distinguish between
strings that are actually important
quotes and seminal in strings that just
happen either do serendipity or do two
things that aren't really that important
you know so I'll be back is everywhere
that's not a popular passage okay and
there's also you're doing this in the
face of OCR errors and Miss quotations
because in fact people frequently
misquote these popular passages and so
this is part one way to think of this
and this is I will put this in the
context of what I think I need to
characterize what is one of the grand
challenges okay one of the grand
challenges and this is going to touch on
search and many other things is we all
know that on today's web they're all
sorts of things we can do because of the
rich hyper linking structure that exists
between all of the documents okay in
fact in search it you know people have
been slaving away at search for a long
time and most people think oh the search
doesn't work very well the world wide
web came along suddenly Oh google solved
search okay of course it hasn't but of
course part of the thing is is that
people in this room realized that many
other people don't realize is that one
reason it works so well is because you
have fairly short documents along with
rich metadata from people creating links
and hyperlinks all over the place and
now it becomes much easier than what
information retrieval had been doing for
many years when it just had the
documents
ok so these books are not there are all
sorts of implicit links in all these
books both within the books and within
the web ok some of them are more
explicit than others obviously a
citation is a link it's explicit in a
text but there isn't a hyperlink ok
there are all sorts of quotes and
references and all sorts of other things
that really are connecting these books
together so the question is in a world
10 years from now 20 years from now how
do all these books just kind of
disappear into what i will call is the
rich fabric of information that is the
world wide web ok some of this is
through automated techniques right so
this is an example of a set of
relationships between these books they
may be strong they may be weak but its
defining relationships that exist
between these books because of these
seminal passages they're talking about
the same thing ok some other things
actually maybe humans making these links
in fact one of the things that we've
launched in our public domain stuff that
has gotten very little use and I think
it's because the tool doesn't quite work
yet very well we have this clipping
facility so you can actually identify a
portion of a page and clip and put it in
your blog and get a link that goes not
just to the book but to a region of the
page so you can imagine hyper linking
into and out of books ok just like you
do anything else on the web ok now one
of the interesting questions I think as
you think about not just hyper linking
into and out of books let's take the
example of an annotation ok an
annotation well it an annotation is just
basically identifying something with
some comment on top of it it doesn't
actually have a link to another thing
right and all a hyperlink is is an
annotated relationship between two
objects but as you annotate a book you
would like those annotations to be
persistent across different copies of a
book in different versions of a book so
you should be able to annotate Tom
Sawyer and while sometimes you might be
annotating a specific edition of Tom
Sawyer you're probably annotating Tom
Sawyer as a con as
a literary work and it should be that
your annotations of the research that
you're doing should be applied to
anything any version of Tom Sawyer not
just the version that I'm looking at so
as you think of a way to create these
these hyperlinks this is one thing we've
run into because we rescan books we
rescan pages we have different copies of
book we have different just having a
persistent link that says oh you're
looking at this page at this XYZ
coordinate this XY coordinate is
actually not a very robust
characterization of what this comment
and what this link and what this thing
is about okay and so that's an example
of one of the you know but i think is
really an interesting problem of how do
you create this kind of metal linking
and it also relates i think in the world
wide web because here this is a case
where somebody creating the linking
doesn't own the page they don't own the
book of course the same thing happens on
the web where you want to be making
comments and all that and sometimes they
may be going out sometimes they may be
going different directions where you
don't own the the document okay and in
fact that document they think these
things have some degree of persistence
but we know will often morph and move in
different places so how do some of these
things become persistent so another area
so this is actually work done by our as
Lieberman yuan Chen and jean-baptiste
Michelle at Harvard and they haven't
published this work yet but and this is
something that we're probably going to
release sometime next year an n-gram
corpus I'm a five gram corpus over all
the books okay and so those that are
interested in this type you know come
contact me so they were working on this
five gram corpus and so this is just one
tiny example of some of the stuff
they're doing is this is actually
looking at how isms have grown and
shrunk over time over this corpus okay
there are countless other things that
they've looked that because of these
books they're able to characterize how
things have evolved over time this is an
area where actually find in particular
with newspapers you could do all sorts
of interesting work because they're you
get Geographic and daily variation and
so you can see
how people view things in the deep south
versus the northeast vs etc etc okay so
another thing that we can pick up
historical epidemics this is an example
where they kind of can pick up the
various different flu epidemics from the
books corpus from looking at the
occurrence of influenza and then HIV
okay so there's a lot that we can find
and this is fairly simple analysis okay
so in the linguistic analysis I think
there's a whole bunch of stuff to do so
this is and I'm a dis table an hour and
a half ago when I was like oh let me
just make at least one table so I'm not
waving my hands for this um in the
research corpus one of the challenges
and and I'll say this and this is why
especially for those of you in the
computer science department from some of
the schools that are partners one of the
challenges the negotiation over the
ability to create this corpus was with
the libraries the challenge is I don't
think the libraries fully understand
what it means to build such a thing okay
because this is really a computing
research center okay not dissimilar from
other computing research centers that
you know NSF and other folks have funded
okay and thinking about how do you
control access how do you control cycles
when we give all these books which when
they include the images you're offering
talking about 10 20 petabytes that
actually the computer they're building
is a supercomputer in terms of the
number of cycles and that in fact you
often are going to need robust cycles to
go hand in hand with the data to
effectively use this okay so there are a
lot of you know research questions about
how to build such a facility and they're
not all we I think I think actually
people know how to do this it's just
getting the right people that know how
to do it and so conceptually and this is
my idea of what it might look like you
know obviously you're going to have
certain services that are important for
computing its scale and as I know many
of you will know and I'm sure they're
talking about it you know we've done
some of this work already and Hadoop and
some of the other open-source version so
that you can do MapReduce you can do big
table and many of the other things a big
part is how do you store the books so in
fact we spent a lot of time figuring out
how what are the underlying data
structures we use so that it's easy
to do a MapReduce over every single page
and every single word of every single
book and if you don't store it right
that can be a ridiculously expensive
operation okay so when you build this
underlying data layer about how to
access you really need to start with
some understanding of the type of uses
you're going to want to make a bit so
that you structure it in a manner that
it will be efficient okay now my view of
this research center is that ultimately
there will be lots of different types of
people using it okay there'll be
computer scientists that will be working
heavily deeply within the data layer but
then there may be humanists and
linguists and other folks that may not
have those skills so I think of this as
its own sort of open source world where
hopefully what researchers do is they
come to work they leave much of their
code they build services and
applications that other types of
researchers so in fact you might you
might have a computer scientist working
with a historian and they're going to
build if we take for example this Engram
model this is an example of a derived
data product okay that in fact you know
there was processing of this and you get
an n-gram model and you'd like that
engram model to reside within here okay
and then you could imagine in a search
front end on the Ngram model so that
people with really no computer science
skills whatsoever can sit here and think
of all sorts of different words and
different combinations and get different
graphs and reports okay so one of the
big questions is how is this going to
operate as sort of an open source world
where people as they come and use it can
build upon each other's research okay um
and the other thing is luckily the
agreement allows lots of exporting of
information including of course all
research publications products are all
owned by the person during the research
it also allows data to be extracted and
distributed more broadly as long as it's
not like competing with something's
Google's doing or where something that
one of the publishers is doing so if you
wanted to take out an index of all the
world's books to make a competing
product or google book search well that
might be a problem but ninety-nine point
nine percent of what people will do
there's a fair amount of flexibility in
terms of distributing stuff um so now
I'm going to transition to where we can
ask some questions and I'm just
highlight what I think are some of the
kind of research questions and
opportunities that exists 11 i talked
about seamless integration with the web
I think there's all sorts of stuff to do
there so I'm going to tie this to
somewhere in your I don't know if it
talks about search / search I think
there's a lot of work in search / dense
textual content and one of the things to
think of is what is the granularity and
how do you segment and how do you parse
the documents that are in here some
books chapters are really unique objects
in first order objects some books
they're just kind of arbitrary
separations okay so you need to treat
those things differently sometimes you
want to do deep segmentation into
different semantic chunks sometimes you
don't okay and this goes exactly to
since we don't have the rich hyper
linking structure that the web has how
do you infer some of the other meta
choices and you know metal relationships
and semantic information that exists
between these things so I think in terms
of search it's a very interesting corpus
OCR if we want to go from this you know
scanned book tour robust XML part of it
is actually perfect OCR and OCR
correction part of its structure
extraction segmentation disaggregation
of books talked about that linguistic
analysis information extraction and
linking I think I've touched on many of
that all right so with that I don't need
to talk to this let's go through so
questions and it can be either about the
settlement it can be about book search
it can be about the research it can be
about any
are you considering or doing a similar
project for sheet music ah so now you've
got no actually I always I always wonder
if managers get twenty percent time cuz
in fact fact we're actually sheet music
sometimes are part of these libraries ok
so we've scanned sheet music ok we don't
do anything special with it ok the
settlement doesn't cover sheet music ok
I'll just tell you my own personal
things although I haven't had the time
to find engineers with twenty percent
project as someone who plays the piano
so I actually think that if someone goes
and just scans it in segments all the
sheet music and people could go online
and buy it for a dollar ninety-nine it
would be kind of the same thing with
itunes as with music because right now
what people do is they go on and they
get the tab you know stuff that people
put on there it's generally pretty
crappy and that's because they only sell
the stuff sometimes in these big books
and you can't buy individual songs in
the big book is fifteen dollar so i
actually would love to kind of do a
project where you actually segment you
have songs and you basically make an
itunes for sheet music but i haven't MIT
it hasn't been at the top of the
priority stack so if you have any your
students who want to come over and start
getting everyone else talk to me because
i would love to kind of talk to some of
the sheet music sand do that and part of
the platform we built makes it fairly
easy to do that ok so we have the
underlying platform it's just you know
some of the work to do and i noticed in
your diagrams and said well outgoing
arrows but not incoming girls who seem
to assume of you know immovable database
so no no no so so their outgoing that's
just again i did it an hour ago it is
the fact that this is copyrighted
material and for the public domain stuff
we should talk about how you know we do
have certain requirements about
protecting it so you can't again this
will have all in print books you can't
take all the books and say i just want
to run it over on my computer and trust
me i'm not going to do anything bad you
know the universities have to think
about how to protect the content because
to the extent this is a leaky sieve
then we have problems with sustaining
the resource for research and so there's
this balance so certainly there'd be
lots of incoming arrows because other
people should be adding stuff to the
research center it shouldn't just to be
about books we've scanned and in fact
much of the stuff that doesn't have the
protection it's it's very different but
but you know that's one of the
challenges that the libraries need you
as equivalent of hyperlinks it's going
to be using so effectively yeah yeah
that you should be any back in a ton
environment yes yes agree completely and
let's say I think he has a question back
there solution so when you talk about
this non-consumptive research have you
been thinking of any way of implementing
the interface in such a way that it can
only be accessed for non conservators so
it doesn't have to be controlled by the
agreement but it will be the user
interface that allow you only this type
of access yes so I think and again I
have fun ultimately the universities
that run it have to think about this I
know I've thought about it where I think
the agreement is I think as opposed to
creating a hard lock so there is no way
you can do it what you do is it's some
simple lightweight monitoring because I
think most everyone that accesses this
will do it for the right purposes okay
and so I think that you don't have to be
too rigid and that that you can do that
I have thought about more rigid ways but
I think you can do it fairly loosely yes
yes so in fact agreed it if you will yes
I think that's a good question that in
fact luckily we've gotten fair this
isn't overly rigid but you can imagine
about the same problem with other folks
that are very apprehensive about giving
you the data how can you have this
another layer in the same Center because
in fact this may be what about books
published in the future how can you get
it where publishers put it in and feel
that it's secured because people can
only get it to Assyria
ap I think that's a good question um
we're gonna make this the last question
but Dan's I'm joining us at the
reception later right so what is a
reception 5 30 to 6 30 okay okay Oh lots
of your books will have pictures and
sketches and so on so are you already in
your scanning considering storing them
for subsequent queering yeah so in fact
and I assume that you're you're relating
to the fact that for those who don't
know the settlement doesn't give us
authorization to display hold on to
display images or drawings that aren't
by the same copyright holder of the book
okay so it's the same copyright so most
of you that have written books I suspect
you put your figures and images and all
that in there okay so in fact this isn't
an issue because in fact you I know I as
a computer scientist I build my own
crafts and images and all that for some
of you that might license pictures then
the image holders were not class members
now we're still scanning the whole thing
okay because we still think it's fair
use but we only get authorization from
the class and the class doesn't include
those image holders that are the authors
of the books I mean for most of computer
science I don't think this is a huge
issue but in other cases I think it does
so although we're hoping to solve that
um let me mention a couple things to
this group that that I didn't mention
that I've thought of first of all for
those of you that you know have out of
print books okay um Google is very
supportive of well actually even for in
print books but usually your publisher
might have a problem here for
distributing those for free to the
extent that's what you want to do okay
and in fact we're going to announce this
soon we're even going to allow
distribution through a CC license if
that's what people want to do don't go
and you know spread that around but
we've talked about it we've talked we're
coming up so any of you that have books
that maybe we've scanned that you're
like oh I own the rights I'd like to
distribute through CC Google would be
supportive of that and for those of you
you know that have out of print books
that you know do or don't own the rights
you know under the settlement you can
you don't have to sell them you can give
them away 40 which you know I know for
if I add another print book I don't have
print book either uh I would that's what
I would do by the way dissertations okay
are in many cases probably included so
in fact actually everyone in this room
is a class member and it creates certain
opportunities with your school's about
how to open up some of these
dissertations because I think many
students would say yes please let my
dissertation be fully searchable and
broadly on the web and accessible in an
integrated fashion okay so that's one
thing for you all to think about you
know that in terms of your school's feel
free to reach out to me so that was one
point for those of you so let me mention
my email address is d clancy at google
feel free to reach out to me if you have
questions if you don't come tonight you
have questions about the settlement etc
etc one of the things that's happening
as you all know there's been a fair
amount of press about the settlement
having talked to lots of people I find
you know the vast majority of people
when they understand the agreement gets
very excited okay because they realize
the potential of unlocking this okay
there are folks that have some concerns
there is a very vocal of what I think is
a small minority as people become
informed ed Feigenbaum is going to be as
putting together a letter from a number
of scholars to kind of make a statement
of support for the agreement and for any
of you that are interested in learning
more are participating in that reach out
to me because you know in some of you
add may reach out to directly because
it's the type of thing where if this
doesn't happen you know we probably are
left where people are watching looking
snippets okay cuz that's we assume we
would win the case but even if we win
the case all you would do is get three
little snippets of much of this stuff
and while for computer science much of
the stuff you want to read is actually
still in print in fact some of the out
of print stuff maybe it's not the best
thing to read but I do think there's a
societal and a you know in terms of
comprehensive if there's a lot of useful
value and making sure this content is
accessible okay so feel free to reach
out to me okay thanks
music</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>