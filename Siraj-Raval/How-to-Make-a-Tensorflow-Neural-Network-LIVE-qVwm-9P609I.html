<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Make a Tensorflow Neural Network (LIVE) | Coder Coacher - Coaching Coders</title><meta content="How to Make a Tensorflow Neural Network (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Make a Tensorflow Neural Network (LIVE)</b></h2><h5 class="post__date">2016-12-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qVwm-9P609I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">everybody let's see I mean we make this
work
oh we're all did Suraj hi guys
good to see you let me mute myself okay
there we go alright we've got people
coming in the room everybody hi Preston
hi Trey Leandro I've been uh
Nico Vishal Nishant
Sebastian alright gotta kill it with
that fresh tensorflow uh Shuba deep it
is MN ist this time um but I will get
fresher stuff later alright so ok um in
this live stream we are going to uh we
are going to create a classifier in
tensorflow for MN ist ok what does that
mean we're going to create a classifier
in tensorflow no TF learn just
tensorflow straight up tensorflow and we
are going to do this for a handwritten
character digits like images so we're
going to give it an image of like the
number 6 and our arm our model is gonna
be able to look at that and say oh this
is a six so it's going to be able to
read the image the number that is in the
image and we're going to instance
straighten up tensorflow
alright um so that's we're gonna do and
we're going to start off with five
minutes of QA and then I'll get right
into the code
alright so five minutes starts now um
that's a cool map right yeah I love that
map because it's really colorful um okay
um open AI universe that is a question
did Google contact you they did actually
I'm meeting them next week um we'll see
what happens - I mean I'm sure there's
something we can do together ah this is
my part
it yep how to study chemistry uh watch
chemistry videos on YouTube oh uh that's
not my line - why are you so awesome I
just believe in myself how does this
differ from the example in the docs uh I
mean this is kind of like a custom
version how many layers will your model
have it's going to have four layers it's
going to be a convolutional neural
network with four layers uh what is it
opus way to build AI to detect fake
articles on the internet that's actually
a hard problem that we are working on
right now detecting if something is fake
or not like a validity test is actually
like um I mean what does that even look
like like if you had a supervised if you
had a set of articles that were labeled
as real and a set the relatable is false
I mean it's fake you could you could do
it that way but even then like if a fake
article was good enough like it would
just pass so we need when you had a vet
we need a very very very strong robust
model for that and like you know Google
auto-reply level amount of data that
it's it's trained on will you use LS TM
yes I will um
MacBook or Windows PC Mac book will
Scala P Python no um did you lift your
job why I used to work at Twilio um but
I want to do this full-time
why don't you make a video about NLP in
particular the entity type recognition
problem I have several videos on NLP I'm
gonna make more though what is your
laptop specs I just got the new MacBook
you
I got lost in the neural network um okay
so let's let's go ahead and do this you
guys can see me right um no no I'm still
here just someone say that they can see
me I just had I just had a problem for a
second um all right let's see I'm still
broadcasting okay I'm still broadcasting
audio is back no no they they can't see
me okay all right there we go all right
okay there we go
Plus code and so now you guys can see me
okay here we go okay so we've got people
watching and we're going to screen share
okay so screen sharing time um sure okay
boom um alright so here we go
and all right you guys can see
everything dropped out for a bit I'm
gonna make this bigger okay so now we've
got a hundred sixty-one people watching
and the tour okay so here we go you guys
can see alright beautiful right alright
so let's do this
so we're going to import our first
library which is the future library why
um future is going to let us but we're
going so future is going to let us
there's lag right okay
is there still lag um yeah I'm gonna I'm
gonna get a I'm gonna I'm gonna get a
better connection next time I'm lagging
okay hold on ah hold on damn it
PS
too much audio is good okay bad video
quality um hold on okay so um it's still
lagging okay so the video is lagging um
I'm not sure and too much lag okay
so there's too much lag and video lags a
lot okay
so just try to restart it okay um let's
see let's see let's see let's see
restart I can restart restart the what
actually lit box is a little I'm not
sure okay
about um 123 okay so 123 so so everybody
it's lagging right that's what's
happening right now it's lagging that's
what's happening right now the stream is
lagging all right so I'm just gonna keep
going um because I can't help but the
lag so I'm just gonna keep on going and
uh it's still lagging okay um
sound is okay but the video is lagging
uh it's breaking I'm just gonna keep
going I don't give up okay so so for
future we're going to import the print
print function um okay
all right great we're gonna import the
print function and we're gonna import
tensorflow
yes those are a two library that were
going to important and future is going
so that we can have the print function
from Python too and we could do it for
Python three okay so so there's that and
uh so now we're going to AH so we had
that now we're gonna import our data set
okay um it's fine alright no lag close
your browser tabs all right good good
call actually close that boom boom boom
so uh so okay so we're going to import
our data set right so the first thing
we're going to do is we're going to
import the exec our example data set of
the MST and I'm going to talk about what
format we're going to we're going to
import this ass okay so we're going to
import this is our helper class input
data and what input data is going to do
is it's going to pull our data from the
web our MN I STR handwritten character
digits are images it's going to pull
that from the web and it's going to
store it in our folder and it's going to
format it's going to format it so that's
so that we can use it in our code okay
so good finally there's no lag all right
and I'm sorry about the lag guys um I'm
going to not have this ever happen again
all right I'm going to work it out of a
place where there's no lag so we're
going to create a variable called a man
is t using our input data help a helper
class and we're going to we're going to
use the
data sets method we're going to read it
from wherever it's saved so it's going
to save it to the temp folder our data
folder in our temp folder and we're
going to and we're going to say one hot
equals true what is one hot equals true
me that means that let's talk let's talk
about it for a second what what is one
hot encoding okay so this shows up a lot
one hot encoding one hundred coding is a
way of of of formatting data of
representing data so that it so that it
uh so that it's more machine readable so
what would be an example if I had an
array like car car if I encoded this
normally I could just say like I could
represent this as one zero two one
okay I could I could say that but um
what is this this looks like tooth is
the greatest value like it looks like
tooth is greater than one because the
value that I'm representing it as is is
greater but this is wrong like tooth
isn't actually greater I just need a way
to differentiate between different data
right so a better way of representing
these would be as binary digits so that
I could represent house is one zero zero
zero and then I could represent car as 0
1 0 0 and then I could represent to that
you know we don't think so
they're different ways of representing
of representing data and and it's using
this kind of binary format so it's a way
that lets us encode data so it's more
machine readable and it's good for
regression and classification but
no it doesn't say that one is greater
than the other so that's what we call it
that's what we say one hot okay it's a
way of encoding it but there's not like
it's it's it's not greater than the
other okay so that's one hunters okay so
that's us getting our data set import
data alright so next step is to uh get
the love you too Michael
next step is to get the hyper parameters
alright so hyper parameters these are
our tuning knobs and I'm going to talk
about each of them so okay so the first
one when the import is called a learning
rate let me explain what I'm doing with
here um so why am i setting it to point
zero one okay so as data flows through
our neural network we're gonna apply an
activation function at each layer so
what this function is going to do is
it's going to transform our data in some
way and we're later going to use we're
later going to use um that transform
data to update the weighted connections
between the layers and to what the
learning rate does is it's it's what we
apply to that weight updating process so
the greater the learning rate the faster
our network trains but the lower the
learning rate the more accurate our
neural network trains okay so it's that
trade-off between time like speed and
accuracy speed and accuracy um and one
hot is used in word representations as
well and that's what kind of what all
hyper parameters are they're they're
they're kind of trade-off between speed
and accuracy so that's our learning rate
and now um now we're going to have our
training iteration so how much do we
want to Train and so we're gonna say
200,000 iterations okay so generally the
more iterations the better it's going to
the more iterations that the better our
model is gonna train okay so that's that
for our training iterations now we want
our high he but hey guys say hi to kevo
she's my friend IRL so for batch size we
want to say bad guys is gonna be 128
what does that mean that means we have a
hundred and twenty eight samples that's
the size of our batch the batch is what
we train okay um and uh alright so um
there's that and we're gonna set our
display step to ten what does that mean
well how often do we want to
hey what's happening while we're
training let's say every every 10
iterations so it's so that's what we're
gonna say reset every 10 iterations okay
so there's that and now we want to
create our network parameters our
network parameters alright so for
network parameters we want to say how
many uh uh what is the size of our our
image let's say 784 what does that mean
I keep doing this minus sign let's say
784 um so that means our image shape is
going to be a 28 by 28 image right a 28
pixel by 28 pixel image that's our
that's our affair the size of our image
so so there's that and then our number
of classes um is going to be 10 what
does that mean well we have 10 digits
right the digits 0 through 9 there are
10 digits now we're gonna are our last
Network parameter is called drop L oh I
cannot wait to explain dropout I love
dropout okay okay here we go
dropped out okay is this awesome thing
so drop out is a technique created by
Hinton Landon I'm gonna do it I'm do it
I'm gonna do another Q&amp;amp;A at the end of
this session all right so what dropout
is is it's this awesome method invented
by Judge Geoffrey Hinton and his team
that prevents overfitting by randomly
turning off some neurons during training
so data is what is forced to find new
paths between the layers to allow for a
more generalized model okay so what does
that mean so um I think the best analogy
I can think of is like old-people okay
so generally they say like the older you
get the more set in your ways you are
you are and there's a kind of scientific
truth to this because there are these
neural pathways in our brain kind of
like grooves that we kind of carve into
our brain that we kind of get used to
thinking about right and so that's kind
of what it is with dropout if you train
your neural network a certain way and
you don't use dropout then those
pathways are going to continually be the
same way so it's going to be to train on
the data yeah it's gonna be to fit on
the data you train it on it's not going
to be able to generalize well it's not
going to be able to predict new data
sets but what you can do with dropout is
while you're training
what dropout does is it randomly
turns off neurons while while the data
is flowing through right while the data
is flowing through it's randomly turning
off neurons randomly and so that the
data is forced to find new pathways and
what this does is it creates a more
generalized model so the model is then
able to train and test on all sorts of
data ok and dropout is a very very
successful technique ok so that's what
dropout is there's a little bit long but
that's what we're gonna use for dropout
and drains a probability it's a
probability value okay and like
everything else it's a trade off and
it's all about to Nate's about trying
and testing what works best okay so um
so that so that's that okay so now we're
going to create our guitar placeholders
how we're going to uh how we're going to
get the data in there so what we're
gonna say is everybody say hi to Brian
he's also my friend IRL um so we're
going to take our placeholder variable
our tensorflow placeholder variable and
we're going to say none and then the
number of inputs what does this mean
this is our gateway this is our Gateway
dropout is not like shrimp kind of it is
actually it actually it is that is a
great point so we're gonna we're gonna
create I'm gonna let me just type this
out and then I'm gonna explain what is
happening what is happening today okay
so none and then the number of classes
what is this well we've created two
gateways we've created two gateways for
our data one gateway is for the image it
are for the images the other gateway are
for the labels so we're gonna have an
image like the number like an image of
the number zero and then the actual
label zero um and so both of those are
going to be fed in at the same time so
our short convolutional network is
seeing our labels and it's saying our
images at the same time okay we now we
need one more thing it's called keep
probability which is going and so test
flows placeholder opt of a tensor flows
placeholder object is what is what
represents those gateways it's a gateway
into our computation graph so that's how
the data flows into our computation
breath we have our placeholders okay so
I need one more placeholder and that's
going to be a float 32 so it's a 32 bit
float and that's that's what that's what
what are they our drop out at our drop
out is going to flow into
network so we have three gateways
actually one is for our our image one is
for our label and then one is for our
drop out okay so there's that um and now
what we want to do is create our
convolutional layers so let's create our
convolutional layers and I'm going to
explain what's happening here first and
so what we're going to do is I'm going
to create a function for this so it's
gonna be a 2d convolutional layer it's
going to take a set of four parameters
okay what are these parameters that I'm
that I'm importing here so what we're
going to do is we're going to have these
four parameters and uh we're going to
define our convolutional layer here so
I'm going to type this out and
tensorflow has a built-in convolutional
function right and uh so we're going to
say whatever our men are very our
parameters for this well we we already
imported them in the main method that we
just called here and we have something
called strides that I'm going to explain
in a second but stride states in these
strides that I've defined previously 1 1
1 and then padding is going to equal
same and then right and so then X is so
let me explain this okay so look so this
is so this is why I this is why I have
arm into a its own function I quit
because there are two there's actually
three things I want to do here I want
two years ago here I go I'm about two
clicks so what's happening here okay so
here's what's happening here's what's
happening okay okay
so a convolution is so so when we're
feeding these images into our network a
convolution is basically taking a part
of that taking that image and
transforming it in some way so that's
what convolutional layers do they take
the image and they process it they
transform it in some way so each layer
is going to have some um some
representation of that image and it's
going to get hierarchically more
abstract the higher you go in your
network so the first layer is going to
be a 2d layer right and we're going to
add our bias to it and what is the bias
- it's like all other hyper parameters a
bias is going to it's going it's a
tuning knob it's going to the you know I
can make it go one way or the other but
generally what biases
it makes our model more accurate okay
and uh so so there's that and so so what
is convolution is a fancy word for
transform okay for for image transforms
and we're going to return the riilu
function riilu is an activation function
rectified linear unit is the full name
of it but basically it is an activation
function and we're gonna and we're gonna
use it in our convolutional layer okay
so that's what that's that's what's
happening here
and then strides are bit so then strides
are the UH it's a list of integers and
it's gonna be a a tensor right so so
strides are are tensors and tensors just
means that those just mean data tensor
is equal data all right um so that's
that's one convolutional layer okay that
i've created that as a function um okay
thank you Eva okay so that's our
convolutional layer and so now I want to
create another function called a max
pooling layer alright so the max pooling
layer is what is pooling well let me
talk about what pooling is we've created
a convolutional layer but let's talk
about pooling because this has happened
all the time in convolutional nets it's
like your car is a great um that's a
great explanation convolution is like
putting filters on an image it's a it's
an increasingly abstract set of of
filters okay so what pooling is is a
pooling layer takes small rectangular
blocks okay from the convolutional layer
and it sub-samples them to produce a
single output from that block so it's
taking samples of an image is taking
little samples pools okay like little
pools from an image okay
and it's so they're they're going to be
max pooling because we want to take the
average or the maximum of the of the
learned linear combination of the
neurons in the block okay um so that's
what so that's what max pooling is so
regular we're just going to do one thing
we're going to say we're going to return
the max pooling function so tensorflow
has a built in max pooling function and
we're going to that's what we're going
to return okay
so it's going to be the size um 1k k one
so that and so that is that that is a
Ford V tensor that the four D tensor
okay so there are four variables there
and and the same thing about our strides
that's going to be another four D tensor
1 K k1 and padding is going to equal
same I'm going to fast
I will slow down I will slow down um all
right but don't so that is our that is
our cooling layer arm and so now let's
create our model ok we've created our
definitions here now let's create our
model ok so create model and um so we're
going to say convolutional net x weights
biases so let me let me type out these
parameters and what is what's going to
happen here
some model we're going to take our X
which is our input our weights which are
the other connections or synapses
between our layers our biases that work
that's going to affect each of our layer
our layers in some way and then our
dropout okay so first before we do
anything we want to reshape our input
data so it so it is uh we want to
reshape our input data so is a formatted
for our computation graph that we're
about to create okay um a screen shot
went off video is down for you hold on
hold on hold on what just happened all
done here we go
um camera off turn camera on alright
back video is back great video is back
man it is we are on an adventure today
okay video is back right guys okay so
I'm going to say uh I want to reshape my
input okay great and uh this is the one
time I'm going to have video issues guys
I'm just recording out of my place today
I usually record out of my studio but
it's closed today but I'm never gonna
let this happen again all right and
thank you all for showing up for this
livestream I'm gonna I do this for you
guys I'm going to keep on doing all
right so um so um where were we right so
we're gonna we're going to reshape our
input data right and what is the shape
that we want it to be well we can define
that as our parameter here we can define
what our shape is going to be and we
want our shape to be a it's going to be
28 what was our dimension was 28 by 28
pixels and then our width and height we
have here I set to one right so that's
how we're going to reshape our input now
we can call our combinational layer um
uh so now um we're going to create our
convolutional a convolutional layer and
uh what is it so we defined our
convolutional function up there right so
now we're going to actually use it and
guess what we haven't actually defined
our weights yet I'm going to define our
weight in a second right now we're
defining this function without defining
our weight um uh so now
we can we can set our biases and our
biases are going to be what our bias is
going to be we haven't defined those
either so we're going to we're just
going to use these as placeholder uh
first um and we're going to let's see so
that's our convolutional layer as their
biases and weights so now we have our
max pooling layer alright so so we've
created our convolution layer and then
we're going to add to that convolution
max pooling um so then our max pooling
layer is going to take that convolution
that we just had so it's going to take
that max full 2d function that we just
created it's going to add another set of
weights and um uh and then
we're going to have our biases as it's
going to be BC - boom boom boom all
right so that's our convolutional layer
and I'm active cooling layer okay and uh
so so what happened here so we have our
convolution layer and a maximum so now
that's our first layer that's our first
layer um and now we're going to do our
next layer okay so our neck later is
going to be convolutional 2d um right so
that was our one one of our layers and
now we're going to uh now we're going to
create our next layer and it's going to
take our previous layer that we just
created as an input and we're going to
say weights are going to be WC - and
then so again we're going to define our
weights in a second we haven't really
defined all of them but we're going to
define them in a second and that's going
to be our list of weights and one more
thing we need to match pull this layer
to right we want to maximal each of our
layers um
um alright so let me let me do that
uh max pulled Judy convolutional 2d k
equals two and then okay so so that's
what we got so that's our max pulling
layers all right so now we have our
layers and now we want to create a fully
connected layer okay so we've got our
both of our convolutional layers and now
we can create a fully connected with why
do we create a fully connected layer a
fully connected layer is a generic layer
that means like all the layers are
connected to every so every neuron in
this slit in the fully connected layer
is connected to every neuron in the
previous layer so the previous layers
are two convolutional layers so the
convolutional layers are taking or
creating convolutions or transformations
or filters of the image right and then a
fully connected layer isn't it's just
representing that that image the image
data it's just a representation of image
data without it transforming it in a
convolutional way so the first thing we
want to do is we're going to reshape it
right we're going to reshape the data
for our a for our convolutional layer
and then we want to get the shape
and it's going to be as a list it's
going to be as a list of inputs
um and so okay so that is our first
connected layer um
and so now um I am I am doing the next
one okay so so the net one is going to
be we're going to add uh so so this is
where the actual matrix multiplication
happens okay we're gonna we're gonna
take this is what the actress actual
matrix multiplication happens um this is
where that right so per car said this is
where the actual classification happens
this is whether this is where the matrix
multiplied happens so all that data that
we've been transforming this is work
this is where we kind of combine it
together okay so what we're going to do
is we're going to perform matrix
multiplication using tensorflow so
testicle has a built in matrix
multiplication function and for our
weights we want to use the same weights
that we had um uh and then we're going
to use our biases as well okay so we're
going to our weights and we're going to
use our biases right so there's that and
now now okay now that we've done that
we're going to apply dropout okay we
believe we've created our convolutional
layers are fully connected layers and
now we can apply dropout oh you know
what I guess what I forgot something I
forgot to at our activation function
what is our activation function it is
real oh and we're gonna apply it to that
that uh that layer okay so now we're
going to apply dropout so we're gonna
take so guess what tensorflow has a
built-in dropout function and we define
dropout earlier um okay
line 45 check the parameters arm
let's see convolutional one weights and
biases be - yeah that works right um so
there's that and so now we're going to
say for our output um line 45 what's
what's going on line 45 line 45 we have
max pooling um max pooling convolutional
one
max cool 2d what is happening over here
just um trying to figure this out I
thought 146 uh
max cool 2d anyway line 40 is missing
brackets oh there it is okay crow thank
you okay cool okay so anyway so we
applied drop out and now we're going to
have our output and so what is our
output gonna do output is going to
predict our class so output is going to
predict our class okay so we're going to
say so now that we've corrected there
our matrix multiplication on everything
that we calculated beforehand everything
I would calculate beforehand because
we're going to say our weights it's
going to be out and then our biases um
we're going to be out and now we're
going to return out 947 convolution - ah
thank you that's thank you um Pepa I
appreciate that
biases out and then we return hell okay
and that good and whatever we're
returning here that is our class
classification okay that is our class
classification all right um and hold on
hold on matrix multiplication to the
death Oh dr. 47 so 47 convolutional 2d
what's what's happening on 47 okay 47 is
convolutional too - yes right um okay so
now we return how i'm luciene on this
TFW alright so anyway I'm just
gonna keep going here so now uh now
let's create our weights let's create
our weights um yeah let me make my
editor a little wider um I'm not gonna
be able to see the comments fully okay
anyway so let's create our weights
um weights um are going to be so we're
going to create these weights as a
dictionary right but it's time for us to
create our weights and so our weights
are going to be a list of four
tensorflow variables okay so our weights
gonna be a list of four tension flow
variables and uh we're going to say DF
variable get that random I will yeah I
can use centreboard why don't I use
can't afford for this okay I'll you sent
your board when I'm done
uh right
okay I'm gonna okay so it's going to be
kind of hard for me to write this out
and explain at the same time to what I'm
going to do is I'm going to just say um
I'm going to write to sell and then I'm
going to explain what these weights are
so these are a list of the list of
values and um but what is this so we're
going to say our variable is a TF that
random normal it's going to be the same
kind of thing right we're just going to
have four tensorflow variables and each
of these uh variables is okay each of
these variables is going to be a
different value um ah okay and so it's
going to be 64 so there's that and then
wd1 ah skip that variable so here I go
I'm about to finish writing these like
this I'm on my third of four and Kiev
top random normal seven times seven
times 64 uh 124 let my doing here so
that's not an actual and 24 one more
variable guys no no one more variable uh
don't worry about it one more variable
and we're good to go
alright so TF got variable um yep got
random normal right it's the same thing
all of our weights we want and then
we're gonna say and I'm gonna explain
what's happening here in a second okay
okay so here's what's happening here's
what's happening okay here's what's
happening we have our first set of
weights um uh it's a five bytes so
here's our first set of weight this is a
five by five convolution with one input
and thirty-two outputs so it's a five by
five that's it width and height and then
of our input and then it's just going to
be one input that's gonna be an image
and um
thirty two outputs that that's the bit
that that's a number of bits another one
5x5 thirty two inputs sixty four outputs
what a thirty to me there's thirty
thirty two different connections going
thirty two different ways and sixty four
right so it's taking one image and it's
splitting it as splitting it like
increasingly through our network
these are synaptic connections okay and
so then it's going to be our fully
connected layer that's a way for a fully
connected layer seven by seven by sixty
four inputs ten hundred twenty four
outputs okay um lastly it's going to
take ten twenty four inputs at the last
layer and then this is where we actually
predict our class the number of classes
is gonna be ten so those are our weights
okay now let's go ahead and construct
our model
okay so let's construct our model truck
model and let me know if it's laggy or
not like if it's let me know if it's not
laggy cuz okay so I would appreciate
that
so let's construct our model well guess
what we already define our uh Anthony
Johnson that was a thug life moment
right there thanks for saying that uh I
should go a little slower though yeah uh
so uh the weights are massive aren't
they they've weights or mass so now
we're going to construct our model what
are we going to strut constructed with
we're going to construct it with our
input data X our weights that will be
justifying our biases and our key prom
which is our drop out okay so that's
what we're constructing our model now
now let's define our optimizer and our
loss and once we do that we can start
training so what is our loss we can call
it loss or you call it cost let's call
it cost we're going to use tensor flows
reduce mean function which is which is
kind of synonymous with reducing the
loss okay um and what is the type of
loss function that we want to use well
pension pose neural network class has a
loss function that is good for image
classification called softmax
cross-entropy with logits okay and let
me explain what the f this is okay this
is a big fancy word right here a big
fancy mathematical work so what is this
doing this is measuring the probability
error and a classification
tasks okay it's measuring it's measuring
the probability error in a
classification task and it's when the
classes are mutually exclusive so that
means that an image that is at zero and
enemies either one are exclusive okay so
that's our that's our that's our loss or
cost let me just call it costs for
simplistic and now let's define our
optimizer what is our optimizer and why
do we even need an optimizer
well what whenever we are creating a
neural network we want to create a an
optimizer and we're going to use an
optimizer called Adam and what Adam does
is it reduces the loss over time through
a gradient descent process a gradient
descent process
okay I'm using the latest version of
tensorflow um and what what is our
learning rate well it's gonna take our
learning rate as a parameter which we
already define okay and what is it going
to do well it's going to and guess what
there's a there's a function for
this minimize our cost that's why the
optimizer does it minimizes our cost and
the more we minimize our cost the more
accurate our model gets and and why are
we using the Adam optimizer adam has
become really popular recently there are
other types of optimizers we can use
like a degrade okay um but for this case
we want
see the set I'm going to use tensorflow
to visualize these weights at the end
yes so now that we've created our
optimizer in-app cost now we can
evaluate our model so what does this
look like you're a model evaluation we
want to say well what is our correct
prediction what does that look like we
want to make sure our correct prediction
we want to see okay so I'm going a
little too fast let me calm down
everybody take a deep breath with me
ready a deep laggy breath with me okay
we're calm everybody it's all good it's
all good okay so now what are we doing
we are evaluating a model and we're
using tension flows equal function um -
man uh we are going to use tense of
flows equal function if the difference
between the predicted value and um uh
and uh well uh but the test data is so
we have test data and then we have our
predicted value and we want to see the
difference between that okay so that's
what we're doing here and security what
is our accuracy are C is going to be a
difference between or correct are
correct prediction and whatever we
predict and and so we're going to see if
I ask the correct prediction and uh that
value is going to be a float float 32
okay so now we can initialize our
variable so let's initialize our
tentacle bears and guess what we always
want to do this intentionally always
want to uh we always want to UM know
video hold on hold on oh there's nobody
hold on let me fix that boom boom there
we go bitty
is back okay so we're getting through
this guys we're getting through this
we're almost there
now arrange a trainer graph and we're
good to go so we're going to initialize
the variables and the variables are
going to be so how what are we doing
here
every time we initialize our potential
flow graph graph we want to initialize
our variables okay every time we wanted
we want to do that so now we've
initialize our variables we can launch
the graph the graph is our neural
network but we intention for we call it
the computation graph okay so with and
so how do we do that well we create a
tensorflow session and a graph is
encapsulated by a session okay and so
we're going to say run the session and
we're going to initialize a session uh
we're going to initialize a session um
uh okay and we're going to say equals 1
and so we're going to keep training
until we reach max federation's all
right so let's go ahead and do that so
so while um the step so now in this
while loop we're going to say we're
going to take the batch size I'm going
to say it's less than their training
iterations um let's see what is what's
happening here we're going to we're
going to run our optimization and we're
going to feed it uh the values I have
from our batch and our uh both of our
batches and our what's the last thing
our dropout our dropout okay
so papa and our dropout all right um so
okay so
is that and then we want to print out
what's happening here want to print out
the iteration step and uh iteration step
oh okay it's old on so now it just going
to be a bunch of print statements and
and it is really laggy this time and I'm
like okay so anyway uh so okay so we
have that we've our model and so all
right so let's see what this looks like
so python hold on hello hello like
maximize so what's happening here
python Jenica hi right so this is what
it looks like um I'm gonna have to close
that quote in the end
okay so here's I'm not going to Train it
right now so that's going to add more
lag because it's computation but what
it's doing is going to Train on our
label data set and it's going to test on
the on the label onda on the data so we
we have as testing data and let me um
let me show you guys what I mean by uh
hold on by MN is key a browser
visualization I mean I have a little
buzzer if you want um here's what it
looks like um hold on Shh God nothing's
working
all right um hold on okay guys uh um we
have there's a lot of lag this time and
so what I'm doing right now is I'm going
to close out the stream I'm going to
post a code on github and I'm gonna do a
last hold on get that camera turn camera
off turn camera on make sure it's there
hold on hold on hold on come on camera
all right there we go
so okay I'm going to do a five-minute
Q&amp;amp;A now okay and then we're going to
close out the session and then next time
there's going to definitely be no lag
all right so go ahead ask 5-minute
questions Q&amp;amp;A I'm gonna get those I'm
gonna get those I'm gonna get the code
and get help later um ah let's see my
parents are from India I was born in
Houston Texas we need a video on LS TM
for audio when uh that's happening on
Friday uh Rob I have video on Ellis
eum's for audio happening what graphics
card you use to train models an NVIDIA
Titan X would be ideal um what color
scheme are you using in sublime text
it's the default one what schools used
up what school you study I excited at
Columbia heard about Amazon go I think
it's a great idea well which will be a
great force for CV computer vision um
the self-driving car course on Udacity
can you help me write a neural network
to predict if a girl is into me how
would that work you'd have to have a
label data set of girls that are into
you and then some kind of set of
features of why they are into you or
maybe maybe unrelated that's actually a
great quite maybe that could be an
unsupervised problem girls that are into
you versus not well you have to have a
set of girls that you know are into you
for sure and then a set of features so
you could learn those features or you
could just hard code those feature that
would be better um maybe the hair type
what they look like
um one of the important features what
type of girl is into you
maybe there
personality and then based on that you
could kind of predict what other girls
would be into you um if you had if you
were able to extract those features
Facebook data would actually work for
this um outreach in San Francisco one
day great how should i started as a
nubian AI watch my videos uh
what company do you want to work for uh
no company but i wanna i love open AI I
love them and I and maybe Google um age
sex height I'm 25 I'm male I'm six feet
video on string classification I have
one
I have several actually but I'm gonna
I'm gonna do more um speak something for
school
ah yeah and start downloading code for
all of my videos and start running them
locally on your machine whenever you
have spare time and try to get your
professors to learn to do more machine
learning stuff in all of your computer
science class but she wanted can be
applied to almost every field of
computer science
no not almost every field of computer
science C++ or Python Python and um no
video um how long you sit on the PC and
do research I'm on my computer all day
caris is a great thing is a great
library for starters but I would prefer
TF learn for starters ok um alright so
what type of music you like mostly
hip-hop uh - pod Kanye West uh a lot of
electro and yeah what's your favorite
project in ml I like um man uh I like
the synthetic radiance paper that deep
mine came out with that was really like
mind-blowing to me okay uh sex or Python
oh man that's a hard one ah sex is so
like it just happens then it's gone so I
would say Python if I had to pick I know
that so anyway I love terminal I love
seeing into directories and making
directories I just love being in a UNIX
shell it's so awesome
and anyway what is my motivation to
continue learning machine learning
machine learning is the solution to all
profit is going to help us solve
everything it is the most important
thing in the entire world okay um we
have to solve intelligence guys uh okay
where should I start learning neural
networks intensive let's start with my
videos and then also tensorflow has some
great tutorials on their website um do I
have a girlfriend no I am newly single
man I get this question a lot uh but I'm
not actually looking for a girlfriend so
I'm my girlfriend is Python alright so
opening eye is how I found you alright
anyway thank you please do a video on a
live video on recruit nights ok that's
it ok cool I will I love you guys
next time there is not going to be less
as much lag I promise you I'm gonna I
want to do these live sessions every
week ok
I am going to alright and thank you guys
so much for showing up freestyle a song
I will freestyle okay here I go
um here we go what is the topic coffee I
love coffee I do it back every
I'm not me I'm somebody else my mind is
so free I see machine learning cuz I
want to be something more than me I want
to go and flow and so high in the sky
that my mind is so fried from doing this
lives ok so that's my that's my
freestyle I love you guys I've got to go
for now I've got a not have a laggy
connection so thanks for watching love
you guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>