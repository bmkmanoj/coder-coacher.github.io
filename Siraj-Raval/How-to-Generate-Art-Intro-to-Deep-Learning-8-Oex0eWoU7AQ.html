<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Generate Art - Intro to Deep Learning #8 | Coder Coacher - Coaching Coders</title><meta content="How to Generate Art - Intro to Deep Learning #8 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Generate Art - Intro to Deep Learning #8</b></h2><h5 class="post__date">2017-03-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Oex0eWoU7AQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">how does a computer make art the great
artists of our time have all had their
own distinct style event she could
devote wonder and layer hidden messages
in his work Khoya was able to create an
unmatched sense of direct ally blurred
the line between reality and dreams the
lone artist even the right medium is
able to create beauty when the film
camera was first invented it wasn't
thought of as an artistic tool just
weren't able to capture reality when
artists got their hands on it it was the
birth of a new era in fact every time
we've created a technology artists have
found a way to use it as a creative tool
whether it was meant to track our hands
or does it take all recently advances in
machine learning have allowed us to
generate amazing art pieces with a few
lines of code what if you could
prototype an art piece a hundred times
faster
having your medium actually collaborate
with you if we can extend these
biologically learned patterns with
machine learning patterns it will become
much more clear that it's not that
machines are our artistic competitors
it's that we've upgraded our own
creativity hello world it's Suraj and
let's write a Python script to transform
any image into the style of an artist
that we choose one of the first attempts
at computational artistry was by a
British artist named Harold Cohen in
1973 inspired by his wife the prominent
Japanese poet Hiromi Ito he created a
program called Aron which created
abstract drawings Cohen hand coded a
structures into it that were used to
arrive out of four it was a tree like
structure and using heuristics the
program was able to take encoded rules
and generate new combinations of what it
knew incredibly the paintings that
generated ended up being displayed at
museums across the world from London's
Tate Modern to San Francisco soma fast
forward to 2015 when Google released
deep cream the internet went crazy
all glories in hypnotoad they kind of
convolutional net to classify images
then use an optimization technique to
enhance patterns in the input image
rather than its own weight based on what
it had learned soon afterwards
three German researchers use a CNN to
transfer the style of a given painting
to any image they later created a
website called D part that lets anyone
do this easily since that initial paper
the AI community has started to think
about the possibilities for artistry
using machine learning even Kristen
Stewart from Twilight published a paper
on artistic style transfer as part of
her new movie come twin music yeah also
I'm a werewolf so let's understand how
this style transfer process works by
writing our own script and carrots with
a tensorflow back-end we're going to use
a base image which is this extremely
attractive photo of me and a style
reference image our script will take the
style of this image and apply it to the
base image so we're going to eat these
images into a neural net by first
converting them into the de facto data
format for all neural nets tensors the
variable function from tear-offs is back
in tensorflow is equivalent to TF
variable the parameter will be the image
converted to an array then we'll do the
same for the style image and we'll
create a combination image where we can
later store our end result we'll use a
placeholder to initialize it with a
given width and height let's see if we
successfully loaded our images yep this
checks out now we want to combine these
three images into a single tensor that
we can feed into our model we'll use the
concatenate function to do this in just
one line the next step will be to
download our pre trained model called
GGG 16 that Kaos has wrapped for us
beautifully setting our input to our
newly created tensor and the weights to
the image net weights will set include
top two Falls since we don't want to
include the fully connected layer at the
top of the network
ggggg 16 is a 16 layer convolutional net
created by the visual geometry group at
oxford that one the image net
competition in 2014 the idea here is
that a convolutional net pre-trained or
image classification on thousands of
different images already knows how to
encode the information contained in an
image it's learn filters at each layer
that can detect certain generalized
features
we're going to use these filters to help
us perform style transfer and the reason
we don't need the convolutional block at
the top is because it's fully connected
layers and softmax function help
classify images by squashing the
dimensionality feature map and
outputting a probability we're not going
to classify just transform our input
we'll frame this style transfer task as
an optimization problem where we have
some loss function that measures an
error value that we want to minimize our
loss function in this case can be
decomposed into two parts content loss
and style loss we'll initialize a total
loss to zero and add each of them to it
first the content loss we can think of
an image as having both a style
component and a content one we know that
the feature that a CNN learns are
arranged in order of progressively more
abstract compositions since the higher
level features are more abstract
detecting things like faces and the
meaning of the universe actually not
that abstract we can associate them with
content they detect the objects that
make up an image when we run our output
image in our reference image through the
network respectively
we'll get a set of feature
representations for both from a hidden
layer that we choose then we'll measure
the Euclidean distance between them to
calculate our loss named after the
ancient Greek mathematician Euclid of
Alexandria the idea of distance is very
useful in machine learning we can use it
to find rankings recommendations
similarities it's a mathematical way of
comparing data the second loss we'll
calculate is style loss this is still a
function of our networks hidden layer
outputs but it's slightly more complex
let's do this
we still pass both images through the
net to observe their activations but
instead of comparing the raw activations
directly like for content we'll add an
extra set to measure the correlation of
the activations for both of our images
we'll take what's called the gram matrix
of the activations at a given layer in
the network this will measure which
features tend to activate together this
is calculated by taking the inner
product of all the activations at a
given layer which are a bunch of vectors
one for each feature so this resulting
matrix contains the correlations between
every pair of feature maps at a given
layer it represents the tendency of
features to co-occur in different parts
of the image once we have this we can
define this file law as a Euclidean
distance between the graham matrices for
the reference image and output image
and we'll compute the total sidewalks as
a weighted sum of the style off at each
layer we choose it turns out that for
style using just a single layer like we
did for content Locke doesn't get great
results but when using several layers
result in group but get content and
style from cars and get in
No
oh yeah
now that we have our losses we need to
define gradients of the output image
with respect to the loss and then use
those gradients to iteratively improve
our output image to minimize the loss so
we'll calculate the derivative of our
loss with respect to the activations in
a given layer to get our gradients and
use them to update our output image not
our weight like we usually would the
gradients give us a direction on how to
update our output image such that the
difference between the base image and
the file image becomes smaller we can
call our helper classes combination loss
function giving it the model and the
output image as parameters so we'll
combine the loss functions into one and
get the gradients of the output image
with regard to the loss using the
gradient function of tear-off which
translates to TF that gradients under
the hood
this gives the symbolic gradient of one
tensor with respect to one or more other
tensors next we'll run our optimization
algorithm call l-bfgs over the pixels of
our output image to minimize this loss
which is very similar to stochastic
gradient descent but quicker to converge
will feed our minimize our function the
gradients we calculated and it'll output
the result image let's see what this
looks like dope I'm going to submit this
to GQ there are mobile apps that do this
as well Prisma lets you pick filters on
your mobile device and RT so even lets
you apply filters to video we're still
in the early stages of using machine
learning to create art so there's a lot
of opportunity in this space so to break
it down convolutional neural nets allow
us to transfer the style of any given
image onto another to do this will
compute loss functions for style and
content using help foots from hidden
layers we choose and we can minimize our
loss using an optimization scheme
similar to stochastic gradient descent
call l-bfgs
the winner of the coding challenge from
last week a tied vote of Gorsky he used
several features to model Google stock
data and artfully use rmsprop as his
optimization technique Wizard of the
week and the runner-up is Andre of swine
Zach love your plot the coding challenge
for this video is to apply style
transfer that combines a base image with
two different style images poster gave a
blink in the comments and I'll announce
the winner next video please subscribe
for more videos like this check out this
related video and for now I've got to
minimize my losses
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>