<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keras Explained | Coder Coacher - Coaching Coders</title><meta content="Keras Explained - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Keras Explained</b></h2><h5 class="post__date">2018-01-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/j_pJmXJwMLA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and the question
I get asked the most by far is how do I
get started with deep learning and it
makes sense to ask that there are so
many different learning paths and tools
you could use it's hard to just pick one
and roll with it in this video I'm gonna
explain why you should use a deep
learning library called Karos to build
your first deep neural networks and
compare it to other options then we'll
use Karos to build an app that generates
text in the style of any given author
deep learning only started getting
really popular a couple years ago when
Hinton's team submitted a model that
blew away the competition for the large
scale visual recognition challenge their
deep neural network was significantly
better than all benchmarks Illuminati
confirmed because it used lots of GPU
computation and data others began to
take notice and implemented their own
deep neural networks for different tasks
resulting in a deep learning Renaissance
deep learning played a huge part in the
biggest a I success story of 2017
alphago
Google's algorithm that mastered the
game of Go previously thought near
impossible similar improvements were
made in fields like vision text and
speech recognition
wavenet for example was a model that
massively sped up improvements to speech
to text and text-to-speech resulting in
lifelike generated audio Giotto was
really the first widely adopted deep
learning library it was maintained by
the University of Montreal but in
September of last year they announced
that they would stop developing for
Theano in 2018 yes different open-source
Python deep learning frameworks have
been introduced the past couple of years
and some got lots of traction as of now
tensorflow seems to be the most used
deep learning library based on the
number of github stars and forks as well
as Stack Overflow activity but there are
other libraries that are growing
passionate user bases as well pi torch
is a great example it was introduced in
January 2017 by Facebook
they basically ported the popular torch
framework which was written in Lua to
Python the main driver behind pipe
torches popularity was the fact that it
used dynamic computation graphs that
means they are defined by run instead of
the traditional define and run when
inputs can vary like if we're using
unstructured data with text this is
super useful and efficient when it comes
to static graphs we first draw the graph
then inject the data to run it that's
defined aedra for dynamic graphs the
graph is defined on the fly via the
forward computation of the data that's
defined by run but in addition to tensor
flows main framework several companions
libraries were released including the
tensorflow fold for dynamic computation
graphs and tensorflow transform for data
input pipelines the temperature flow
team also announced a new eager
execution mode which works similar to pi
torches dynamic computation graphs but
wait other tech giants have also been
getting in on the game Microsoft
launched its cognitive toolkit last year
Facebook launched cafe to Amazon
launched MX net deepmind released sonnet
there's also deep learning for j-d libe
h2o AI and spark oh and Facebook and
Microsoft announced the Onix open format
to share deep learning models across
frameworks for example you can train
your model in one framework but then
serve it in production in another one I
know I know I know deep AF overload but
look the best way to learn how some AI
concept works is to start building it
and figure it out as you go and the best
way to do that is by first using a
high-level library called chaos chaos is
effectively an interface that wraps
multiple frameworks you can use it as an
interface tensorflow Theano or CNT k it
works the same no matter what back-end
you use Francois chalette a deep
learning researcher at google created it
and
maintains it last year Google announced
it was chosen as the official high level
API of tensorflow
when it comes to writing and debugging
custom modules and layers pi torch is
the faster option while Karros is
definitely the fastest track when you
need to quickly train and test a model
built from standard layers using chaos
the pipeline for building a deep network
looks like this you define it compile it
fit it evaluate it and then use it to
make predictions consider a simple three
layer neural network with an input layer
hidden layer and output layer each of
these layers is just a matrix operation
input times await a Tobias and activate
the results repeat that twice and get a
prediction deep networks have multiple
layers they can have three four five
whatever that's why they're called deep
and these layers don't have to use just
one type of operation there are all
sorts of layers out there for different
types of networks convolutional layers
drop out layers or current layers the
list goes on but the basic idea of a
deep neural network is applying a series
of math operations in order to some
input data each layer represents a
different operation that then passes the
result on to the next layer so in a way
we can think of these layers as building
blocks if we can list out all the
different types of layers we can wrap
them into their own classes and then
reuse them as modular building blocks
that's exactly what Kerris does it also
abstract away a lot of the magic numbers
you'd have to input into a deep Network
written in say pure tensorflow
when we define a network they're defined
as a sequence of layers using the
sequential class once we create an
instance of the sequential class we can
add new layers where each new line is a
new layer we could do this in just two
steps or we could do this in one step by
creating an array of layers beforehand
and pasting it to the constructor of the
sequential model the first layer in the
network must define the number of
puts to expect the way that this is
specified can defer depending on the
network type think of a sequential model
as a pipeline with your raw data fed in
at the bottom and predictions that come
out at the top this is helpful in Cara's
as concept that were traditionally
associated with the layer can also be
split out and added as separate layers
clearly showing the role in the
transform of data from input to
prediction for example activation
functions that transform a some signal
from each neuron in a layer can be
extracted and added to the sequential
class as a layer like object called
activation the choice of activation
function is most important for the
output layer as it will define the
format that predictions will take once
we defined our network we'll compile it
that means it transforms a simple
sequence of layers into a highly
efficient series of matrix transforms
intended to be executed on a GPU or CPU
depending on our configuration setting
it's a pre compute step for the network
it's required after defining a model
compilation requires a number of
parameters to be specified specifically
tailored to training our network the
optimization algorithm we use to Train
the network and the loss function used
to evaluate it are things that we can
decide this is the art of deep learning
once the network is compiled it can be
fit which means adapting the weights on
a training data set fitting the network
requires a training data to be specified
both a matrix of input patterns X and an
array of matching output patterns why
the network is trained using the back
propagation algorithm and optimized
according to the optimization algorithm
and loss function specified when
compiling the model
finally once we are satisfied with the
performance of our fit model we can use
it to make predictions on new data this
is as easy as calling the predict
function on the model with an array of
new input patterns for our text
generation sample well see that it
generates text in the style of our
favorite author
just as we fed it in three points to
remember there are lots of new
competitors that showed up in 2017 for
deep learning libraries but Karos is
still the easiest way to get started pi
torch is getting really popular and is
best way to build models next to Karros
and deep networks are a series of math
operations in the form of layers just
mix and match them to get different
results every time the coding challenge
winner from the war robots video is
Alberto Garces
he used a proximal policy optimization
algorithm to train an AI to balance a
pendulum using the open AI gym
environment top-notch work Alberto and
the runner up is Sven near der Berger
who landed a simulated space X rocket
using PP o such a cool use case this
week's coding challenge is to use chaos
to build your own deep neural network
github links go in the description and
coding challenge winners will be
announced next week please subscribe for
more programming videos and for now I've
gotta not use anything made by Microsoft
so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>