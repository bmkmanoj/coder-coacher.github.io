<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build an AI Artist - Machine Learning for Hackers #5 | Coder Coacher - Coaching Coders</title><meta content="Build an AI Artist - Machine Learning for Hackers #5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build an AI Artist - Machine Learning for Hackers #5</b></h2><h5 class="post__date">2016-05-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9Mxw_ilpvwA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world welcome to Sura geology in
today's episode we're going to talk
about building an AI artist art is the
embodiment of the human experience it's
a synthesis of all of our emotions and
experiences in life you might be asking
yourself is it really possible to build
something that can do this answer is yes
it's incredible we can train a neural
net to learn an artists style and tell
it to modify a picture into a painting
in that style it all started when the
Google research team released a blog
post called inception ISM they trained a
deep convolutional neural network on a
huge dataset of images so they could
start to detect everyday things like
dogs and buildings once it was able to
do that they gave it a novel image and
asked to detect an object it had learned
in the image it's all something an image
that look even slightly similar to what
it had already learned to a cloud that
kind of looked like a dog it would then
modify the image to look more like a dog
this resulted in some pretty crazy
pictures then another group wrote a
similar paper called neural algorithm
for artistic style but they repainted an
image in the style of another using
famous paintings as the base image so
when they trained their neural net on
starry night and gave it a novel image
it would modify the image to look more
like starry night by artifice all of its
features we've gone over convolutional
neural nets in a previous episode at a
high level we're gonna really deep dive
into the code for this one and try to
understand exactly how this process
works we're going to go through the
necessary code to recreate the results
from the neural style paper in python
using deep learning library Karros let's
get started we'll start out by defining
our arguments when we run our script we
define the base image the style image
and the output image we'll create
variables for them then reference a
precomputed WAV file called vgg 16 these
are just a bunch of precomputed synapse
weights trained to recognize everyday
images which will later add to our
neural net as a starting point
we'll also want to initialize boolean x'
that define whether or not to rescale
our image or maintain their aspect ratio
based on user input then we initialize
our variables for style and content
weights so what do we mean by style and
content weight well in the knurl style
paper they found that when they train a
neural net to recognize the painting
style of its artists the learn features
in the initial layers were style based
like you know how when you train a
neural net to recognize a dog initial
error detect edges and the next ones
detect shapes and more complex shapes
and a whole dog all those same layers of
abstraction apply to paintings but what
they found were the initial layers the
edges and curvature and other low-level
features equated with style they also
found the highest few layers were more
based on
content so in the starry night photo the
higher levels will be that dope Sun
thing and perhaps a collection of stars
the lower levels will be the curvature
of the night sky and the color scheme in
this way CN NS helps separate content
from style and mirror the capabilities
of our biological vision we then need to
define how much we want to weigh one or
the other because we can optimize for
one of them or both depending on how
much we weigh each will get a different
output well Sarah image dimensions and
then create a tensor representation of
our base image style image and output
image then we'll combine all three into
a single input tensor a tensor is a
multi-dimensional array an example would
be like colors textures each of those
would be arrays as well so colors would
be its own array containing the 7 main
colors that each of those colors would
be an array of sub colors we convert our
image to a single tensor because it's an
easily possible data structure for a
neural network tensors help reduce the
high dimensionality of our images and
that in turn reduces the computational
complexity now we're going to want to
build our model which is going to be a
convolutional neural network we'll add
in our input tensor as the first layer
then we'll start defining the other
layers we're going to add in 31 layers
to our neural net there are three types
the convolution 2d layer means it has a
set of learn about filters which have a
small receptive field the receptive
field is a sub set of filters that are
used to connect the neurons to a local
region in the next layer instead of
every single other neural the zero
padding layer helps us control the size
of the output volume by padding:0 zyk
ross the border then there's the average
pooling layer pooling is a concept in
cnn's where we take the input image and
split it into a set or pool a rectangle
fully helps us avoid overfitting and
reduce the amount of parameters from
computation by only using a subset of
the image as a representation rather
than all of it the idea is that once a
feature has been found the exact
location isn't as important as its rough
relative location to other features
we'll take the average value from the
pool the activation function is called
relu or rectified linear unit the
relavant is faster than sigmoid without
a huge difference in generalization
accuracy so we'll use that the numbers
here are the number of output filters in
the length and width of the input image
we'll name each of our layers as well
for reference now that we have our model
we'll add in the pre computed weights we
called earlier
then we're going to define our loss
function for the style content and total
variation
aka the uniformity of the image loss
functions help us calculate the
difference between the expected output
and the actual output we're going to
take these loss functions and combine
them into a single scalar or number then
we'll get the gradients of the generated
image using the loss which helps us map
the color scheme our last step is to
train our model by minimizing the loss
using back propagation the back
propagation algorithm we'll use in this
case is called limited memory
gs l-bfgs helps minimize our loss
function in a space efficient in that it
really soars a few key vectors instead
of all of them minimizing the loss
function means modifying the output
image iteratively so it looks more and
more similar to this artistic style we
want sigh pi gives us a technique as a
built-in function and that the training
is over we can rescale and save the
output image that's about it this is
what happened when I tried out the
algorithm you can also apply this
algorithm frame by frame to video
content and with more data and computing
power it's only going to get better I
hope that in the next few years we'll be
able to generate not just paintings but
other forms of art like sculptures and
interior design and facial hairstyles
for more information check out the links
down below and please subscribe for more
ML videos for now I've got to go fix a
compile-time error so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>