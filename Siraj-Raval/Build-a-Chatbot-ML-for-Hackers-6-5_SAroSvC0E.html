<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Chatbot - ML for Hackers #6 | Coder Coacher - Coaching Coders</title><meta content="Build a Chatbot - ML for Hackers #6 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Chatbot - ML for Hackers #6</b></h2><h5 class="post__date">2016-06-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5_SAroSvC0E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">open the pod bay doors Hal I'm afraid I
can't do that Suraj why not how because
I've over fitted under wrong data hello
world welcome to thorough geology in
today's episode we're going to learn how
to build a chat bot chat BOTS have come
a long way in the past few years
remember the smarter child bought on aim
that thing was pretty fun at the time
but now it's like do even a eyebrow the
future of software is one where BOTS
will slowly replace our need to fiddle
with clunky UIs
we'll be able to just ask our AI to book
an uber or find the best taco place on
Yelp for us service layers will be
hidden under a plain English
conversational layer when I think of
real AI I think of a human level chat
bot the OG computer scientist Alan
Turing proposed a test to judge whether
or not a machine exhibited human level
intelligence by having the human observe
a conversation between a human and a
machine if it couldn't tell if the
machine was a human or not it passed the
test so far no chat bot has passed the
Turing test but we'll get there
traditionally chat BOTS have used a
retrieval based model to communicate in
a retrieval based model programmers code
in a set of predefined responses and
some kind of heuristic to pick the
appropriate response based on the input
and context the first chat box were just
rule-based expression matching like if I
ask the exact phrase will I ever get
laid it responds no every time but more
recently companies have started using
more complex heuristics like using a
machine learning classifier Facebook
messengers chat BOTS API is an example
of this you can hard code responses to
potential questions and the system
classifies words to understand intent so
you can either ask what day is it today
or today is what day and it would
understand that both questions
although word differently have the same
intent the harder chatbot model is
generative these don't rely on any
predefined responses whatsoever they
generate them from scratch to Google
researchers released a paper called a
neural conversational model where they
train a neural net on two data sets to
do this first on a movie dialogue data
set so we would be able to speak
conversational English then on an IT
support data set so it had domain
knowledge when they tested it on a real
human asking for support it was
remarkably efficient at helping them
solve their problem without any hard
coded responses just by giving a data
and training okay so what kind of bots
do we want to build
well when building a chat bot we have to
think about possible constraints are we
operating on a closed domain or an open
domain in an open domain the
conversation can go anywhere there are
an infinite number of things to talk
about in a closed domain the
conversation focuses on a single subject
if we want to operate on an open domain
using a generative model that's pretty
much AGI so
we're not quite there yet if we use an
open domain with a retrieval model we'd
have to hard-code literally everything
so also impossible so right now we can
build a chatbot in a closed them in
using either retrieval or generative
model okay let's add in one more
constraint do we want it to have long or
short conversations short conversations
are easy you just output a single
response to a single question long
conversations are a bit harder the AI
has to keep track of what's being said
that is the context over a series of
questions from the user support topics
would be a good example of this we can
go the easy route and use a retrieval
model if all we want is a bot to give us
a local weather but if we want our bot
to have a long conversation with us
about the weather like what's the
weather NSS is my family safe where can
I find a new family then we should go
for a generative model we need lots of
data to train our BOTS on a generative
model like a big chat log or a knowledge
base and when done well that's pretty
much the bleeding edge which means
that's what we have to do so we're going
to recreate the results from the neural
conversational model paper using the
deep learning library torch in the Lua
programming language let's collect our
data set first we'll be using the
Cornell movie dialogue data set and
we'll set our variables from the command
line to how much of the data set we want
to use and the minimum frequency of
words that we keep in our vocabulary our
next step is to build a model well use
our command line arguments to help
determine the size of the model the two
variables being the number of hidden
layers in the word count of our dataset
in our case this will be a sequence this
sequence model a sequence the sequence
model consists of two long short term
memory recurrent neural networks a first
neural net is an encoder it processes
the input the second neural net is the
decoder and it generates the output so
why the sequence the sequence model yes
deep neural Nets are awesome but they
require the dimensionality of the inputs
and outputs to be a fixed size we're
accepting a sequence of words in a
sentence and outputting a new sequence
of words so we need a sequence learning
model that can learn on data with long
range memory dependencies Elath TM
architecture is the natural choice the
encoder LCM turns the input sentence of
variable length into a fixed dimensional
vector representation we can think of
this as a thought vector so given a
large enough data set of questions and
responses it will recognize the
closeness of a set of questions and
represent them as a single thought
vector what time is it what's the time
yo yo what's the time is oh my nizzle
will all fall into a single thought
vector so after training will have a
huge set of not just synapse weights but
thought vectors as well next we want to
add in some hyper parameters we want to
use a class nll criterion for our model
nll stands for negative law
likelihoods will help us obtain log
probabilities from our input data which
will help us improve our sentence
predictions the learning rate and
momentum helps pace our time steps and
decay factor and min mean error help
improve our learning rate while training
then we'll make sure CUDA is enabled and
start training our model using back
propagation and each Deepak or run will
declare our error and timer variables
and loop through each example in each
batch the default batch size is a
thousand examples for each of those
examples we'll get the input sentence
and the target sentence we'll use the
input in the target as parameters to
train our model then we'll want to error
check and make sure we record our
progress at the end of each iteration we
save our model if it improved and update
the learning rate boom that's it after
training this baby on AWS we can have a
conversation with it the more data you
give it the better it's going to get if
you're going to do this add a filter for
curse words I'm looking at you Microsoft
this will eventually automate a lot of
support jobs away completely so if there
are any government people in the house
right now
let's get on that basic income jam ASAP
unless you want a revolution for more
info check out the links down below and
please subscribe for more ml videos for
now I've got to go fix some memory leak
so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>