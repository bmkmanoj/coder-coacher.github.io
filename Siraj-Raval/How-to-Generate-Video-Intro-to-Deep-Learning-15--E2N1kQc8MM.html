<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Generate Video - Intro to Deep Learning #15 | Coder Coacher - Coaching Coders</title><meta content="How to Generate Video - Intro to Deep Learning #15 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>How to Generate Video - Intro to Deep Learning #15</b></h2><h5 class="post__date">2017-04-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-E2N1kQc8MM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and today we're
going to learn how to generate videos
using the hottest type of model in
machine learning right now
the generative adversarial Network will
train our model to generate the alien
language from the movie arrival that we
can later animate in 2014 everyone was
drenching themselves in ice water for
the ALS challenge but meanwhile in
Canada a researcher named Ian Goodfellow
published a paper introducing the world
to dance and the AI community loved it
down lagoon the director of AI at
Facebook called it the most interesting
idea in the last two decades in machine
learning I recently interviewed yen and
asked him a bit about its history how
did you come up with this idea for again
the short story is that I was arguing
with my friends in a bar the thing that
clicked there in the bar was this idea
of having the discriminator continually
learn at the same time that the
generator is learning
if both models learn they're driven to
this equilibrium where it becomes
impossible to fool the discriminator
Dan's are a type of generative model
given some input data X and some labels
Y it learns the joint probability
distribution of this data with the joint
probability distribution function given
a Y you can calculate or generate its
respective X and since this is
unsupervised learning
we have no labels handed to us we use
the training data as Y and the generated
data as X so given say a set of three
models of major cities from across the
world from Google Earth there are
thousands of different features or
dimensions to this data can we generate
an entirely new city from it Atlantis is
waiting and what constitutes a good City
sometimes a single input corresponds to
many different correct answers each of
which is acceptable generative models
help us work with multimodal outputs
like this there's been so much activity
centered around Ganz lately they've been
used to convert low res images into
crisp high res images convert hand-drawn
sketches into photorealistic images and
to generate everything from fashion
styles to new product categories Apple
you should probably take a look into
that last one
by Ganz cycle Ganz w dad's there's a lot
so the basic idea here is that we have
two neural nets one is called a
generator G and the other is called the
discriminator D we've got some data set
let's say it's a collection of Pokemon
images and we want to generate new
images from this data set that means
entirely new pokémon that have similar
attributes to those in our training data
the generators job is to try to create
fake pokemons that look really similar
to our training Pokemon the
discriminators job is to classify the
generated Pokemon has either real or
fake
think of G as a magician and D has his
audience the magician is constantly
trying to make the audience believe that
his illusions are real magic the
audience boos when it can tell that his
tricks are fake and applauds when it
can't tell the difference they both
improve and in the ideal case the
magician gets so good that no matter
what he is able to fool his audience
every time the type of game will use in
this video is called a deep
convolutional Gann or DC gear this is
because both D and G are deep
convolutional neural nets so the
discriminator has several layers of
what's called convolution and the
generators got several layers of
deconvolution
convolution is literally impossible to
understand in a parallel universe but in
this one it's pretty easy
normally neural net layers are fully
connected so all inputs are connected to
all outputs with many types of data this
makes sense we want all parts of the
input data to be able to contribute to
all parts of the output prediction but
images are considered spatially locally
correlated that means if there's a
banana in an image it doesn't matter
where it is in the image it's still a
banana
so we exploit that instead of connecting
all of the input data or pixels to all
output values we use a much smaller
filter that we slide across the picture
like a flashlight so that means that
much fewer parameters in a convolutional
layer as opposed to a fully connected
one let's look at our code we're only
going to use Kaos to build our model
pillo helps us do image processing and
numpy will help us perform some
valuable reshaping operations on our
images let's get started by first
defining our discriminator we'll give it
its own function it's going to be a
linear stack of layers so we'll define
it as sequential and we'll start off
with two convolutional blocks that means
a convolution to extract the feature map
followed by the 10h activation function
to squash real numbers into a range
between negative 1 and 1 which lets our
model learn more complex functions than
just linear regression then a pooling
letter pooling reduces the
dimensionality of each feature map but
retains the most relevant information
will flatten the feature map into one
dimension then apply to fully connected
layers to it
the last dense layer outputs an
n-dimensional vector where n is the
number of classes we have so it would be
2 in our case and by applying a sigmoid
to it it will convert the data into
probability values for each one commands
got a Traynham PNG let's use
cross-entropy ingenious gradient to this
and is it real or just pretend next
we'll define our generator which
performs similar operations but in the
reverse order since it's fed random
numbers as its input it converts them
into an image by first going through two
fully connected layers with their own
Associated activation functions batch
normalization will apply a
transformation that maintains the mean
activation close to zero and the
activation standard deviation close to
one this allows for faster learning and
higher overall accuracy then we apply
two convolutional blocks that will
eventually output an image up sampler
will convert our image into a higher
resolution now that we've defined models
for both D and G we can combine them to
make again pretty easily with care us we
can just reuse the same Network objects
we've already instantiated and they'll
conveniently maintain the same shared
weights with the previously compiled
models we're going to want to freeze
waits in the discriminator part of the
gaen when we back propagate the joint
models so we'll first have the Kaos
trainable flag to false for each element
in this part of the network
we'll also define a load data function
which will form our images into
actors that we can feed to our model by
making use of the image and numpy
libraries okay so how do we train this
thing the goal of training our
discriminator is to maximize D of X for
every image from the true data
distribution and minimize G of X for
every image not from the true data
distribution the goal of cleaning the
generator G of Z is to create samples
that boldi we train both B and G by
taking the gradients of this expression
with respect to their parameters because
each player's cost depends on the other
players parameters but each player
cannot control the other players
parameters this scenario is most
straightforward to describe as a game
rather than an optimization problem
specifically a minimax game minimax is a
strategy of always minimizing the
maximum possible loss which can result
from a choice that a player makes and
the Nash equilibrium is where the
optimal outcome of a game is one where
no player has an incentive to deviate
from his chosen strategy after
considering an opponent's choice so the
way we train Ganz is to find a Nash
equilibrium of a minimax game between G
and D we'll load our data and initialize
both of our models in our Train function
then we'll combine them both and
initialize stochastic gradient descent
optimizers for both of them
will define a loss function binary
cross-entropy
then perform the set of steps outlined
in the paper for every time step we
sample data from both distributions then
update D using our gradients then we
update G using our gradients once we're
done training we can generate some
images from G and will see that they do
indeed look pretty similar to our other
images we can even stitch a bunch of
these images together to make a video
this can be applied to any image or
video data set since videos are just
collections of images we just feed them
in one at a time all right so what are
the main takeaways here generative
adversarial networks are a framework for
generating realistic samples from random
noise they consist of two neural nets a
generator that creates state samples and
a discriminator that tries to judge if
those samples are real or fake and we
optimize them through back propagation
which helps find the
Nash equilibrium of the minimax game
between both G and D first place for
last week's coding challenge goes to
pneumonia Tomek pneumonia used a
convolutional variational auto encoder
to generate videos by training on my own
videos he also added a recurrent Network
to this architecture which I haven't
seen done before
very cool results in the jupiter
notebook definitely check it out
wizard of the week and the runner-up is
me oz muhammad neons used a bae to
generate pokemon and wrote up a really
cool blog post on his whole process you
guys inspire me and i bow to you this
week's coding challenge is to use again
to generate some video details are in
the readme github links go in the
comments and winners are going to be
announced next week can subscribe for
more programming videos and for now I've
got to discriminate between data so
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>