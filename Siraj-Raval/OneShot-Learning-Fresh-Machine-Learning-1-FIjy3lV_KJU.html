<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>One-Shot Learning - Fresh Machine Learning #1 | Coder Coacher - Coaching Coders</title><meta content="One-Shot Learning - Fresh Machine Learning #1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>One-Shot Learning - Fresh Machine Learning #1</b></h2><h5 class="post__date">2016-07-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FIjy3lV_KJU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it actually takes more than a one-shot
to train a model hello world it's Suraj
and welcome to fresh machine learning
this course is all about making
bleeding-edge machine learning
accessible to developers the field is
moving faster than Steve Ballmer at a
developer conference we're going to
learn to apply some of the latest
machine learning techniques to practical
examples that you can integrate into
your own apps neural networks have been
around since the 50s but we've just
never had as much data and computing
power as we do now we call it deep
learning these days and it deserves the
press it's gotten but so many articles
claim it replicates the human brain some
even make it sound like if we give a
deep neural net enough data and compute
it'll suddenly become self-aware mm-hmm
the brain is indeed a neural network but
do we really learn the way a deep neural
net does well let's think about it in
order for deep neural net to learn to
say recognize an image of a banana you
first have to feed it hundreds of
thousands of banana images but think
about the way you and I learn if I were
to show you an image of a banana for the
first time you'd probably be able to
recognize a novel banana instantly even
if it was a different shape or color we
humans don't seem to need thousands of
examples just to generalize just a few
and we learn richer representations than
machines do as well we can use the
concepts we learn in other ways like
creating new examples if we could create
an algorithm to do this to learn
concepts with few examples wouldn't that
be incredible it would further
democratize the fields so that not just
the big companies like Google and Amazon
with huge private internal datasets are
able to train their models but anyone
can so is there an algorithm that does
this well there was a recent paper that
came out called
human level concept learning through
probabilistic program induction the
authors said let's build a model capable
of what's called one-shot learning
one-shot learning is a type of ml that
learns an object category for just one
or a few examples oh they used something
called Bayesian program learning or EPL
to do this Bayesian refers to Bayes
theorem which attempts to use simple
stochastic programs to represent
concepts the word stochastic referring
to the theory of probability is what
Bayes theorem loosely revolves around so
by using simple stochastic
programs or probability algorithms BPL
can represent concepts BPL builds these
simple stochastic programs
compositionally from parts sub parts and
spatial relations all these things exist
in a hierarchy of knowledge which a
machine has gained too little experience
so they trained it on a data set of
handwriting characters and it was able
to recognize characters with a better
error rate and deep learning or even
humans so does that mean that BPL is a
way to go well it does have its flaws it
lacks explicit knowledge of certain
things like parallel lines symmetry and
connections between ends of strokes and
other strokes and the learning isn't
really transferable to other things so
it's not better than deep learning in
every way a few months later though
demine challenged the paper by releasing
their own called one-shot learning with
memory augmented neural networks the
basic idea they had was that deep
learning is very data-intensive but
perhaps there's a way to build a deep
neural net that only needs a few
examples to learn deep learning without
the huge datasets so they built what's
called a memory augmented neural network
a man has two parts a controller which
is either a feed-forward neural net or
lsdm neural net and an external memory
module the controller interacts with the
external memory module with a number of
read/write heads it's capable of
long-term storage via slow updates of
the weights and short-term storage B the
external memory module they fed it a few
examples of handwritten characters and
continuously trained it thousands of
times on just those examples and guess
what it outperformed humans as well so
they proved that one-shot learning can
be accomplished by using a neural
network architecture which is pretty
dope so there are lots of methodologies
to implement one-shot learning and in
this episode we're going to implement
our own we're going to build a one-shot
handwritten character classifier in
Python using the size library so we're
going to import our dependencies first
we're going to want three libraries
numpy sy pi and copy once we have those
we can define two variables the number
of runs we want to complete in a
reference bar for where we store our
class labels then in our main method we
can create an array of the size of runs
which is 20 we'll use this array to
store all of our classification error
rates one every run then we'll write a
for loop to train our algorithm 20 times
for each run we'll run a classification
function which will attempt to classify
a small sample set of images and store
the error rate in the array then we'll
print out the error rate to terminal and
when we are done with all of our runs
we'll go ahead and get the mean error
rate from the array and print it out as
the last statement in terminal so how
does this classification step work
before we answer that we need to
understand these two methods load images
points and modified house torque
distance the load images points function
loads an image file in our case this
will be a character image it then
converts the image to an array and finds
all the nonzero values that is all the
inked pixels and stores that in an array
then it creates an array of all the
coordinates of those pixels and returns
that the modified hausdorff distance is
a metric that computes the similarity
between two images by comparing their
pixel coordinate arrays that comes from
the load images points function it
calculates the mean difference between
both images and returns it the last
parameter of the classification function
cost just notifies a function that small
values from the modified hausdorff
distance mean more similar lastly let's
take a look at the classification
function itself in this function we
retrieve both our training and testing
images and load their image point
matrices into memory then we compute the
cost matrix using the modified house
torque distance after that we compute
the error rate and return it that's all
we do this for every run and then
average them all and get the average
error rate which is in state-of-the-art
like deepmind or BPO but it does make
for a good baseline demo of one-shot
learning one-shot learning will only get
more popular over time bunch of cool
links down below check them out and
please subscribe for more ML videos for
now I've got to go fix an index out of
bounds error so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>