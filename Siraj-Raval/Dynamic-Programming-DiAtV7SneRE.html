<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dynamic Programming | Coder Coacher - Coaching Coders</title><meta content="Dynamic Programming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dynamic Programming</b></h2><h5 class="post__date">2018-01-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DiAtV7SneRE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and dynamic
programming it's one of the most
important concepts in computer science
it's used all over the place in
artificial intelligence it's used in
security it's used in distributed
systems it's used everywhere and in this
video I'm gonna teach you how it works
by going through several examples but
before I go through those examples
before I go over the abstract before I
go over the theory let's look at this
demo I've got here and what this demo is
is it's a visual way for you to see
dynamic programming in action what it's
doing is it's aligning DNA sequences
into this matrix and it's a table right
with rows and width columns and what we
can do is we can type in a sequence like
a let's say let's say sequence 1 is
gonna be a C G and they're all some
variants of a CGG CA right those are the
3 letters and then we excite AGC AGC and
then for sequence 2 we could say you
know G a CG a AC AC and so forth so on
and so forth so notice how as I'm
constructing these sequences the table
and the values in that table are getting
filled in what it's using is what's
what's called a top-down approach
there's two types of techniques we can
use in dynamic programming a top-down
approach and a bottom-up approach I'm
going to talk about each of these in
detail so what I wanted to do was just
kind of show you this this visual demo
before we go into the code you can find
the github link in the description of
this video if you want to look at the
code but it's a good way to visually see
what's happening here and it's all
written in JavaScript ok so what is I
name it programming right what is this
well there's this really famous quote by
I don't know who it's not by dynamic
programming the concept because concepts
can't speak yet those who cannot
remember the past are condemned to
repeat it that's some sage advice for
you and for me as well geez oh my god
anyway anyway so bellman bellman was the
dude
bellman made the bellman equation which
is used all over the place in
reinforcement learning it's used for the
Markov decision processes responsible
for some of the famous wins
alphago for example in AI last year but
he had this very famous quote in the 50s
when he created the concept of dynamic
program
and I'll quote him he said dynamic
programming amounts to breaking down an
optimization problem the in conveying AI
into simpler subproblems and storing the
solution to each subproblem so that each
sub problem is only solved once right so
it's taking a big optimization problem
what is an optimization problem it's a
problem that looks to minimize or
maximize some value iteratively right
all of machine learning is an
optimization problem right all of
machine learning is trying to optimize
to fit a curve it's glorified curve
fitting to some data in dynamic
programming is taking that optimization
problem and breaking it down into
simpler subproblems okay so that each
sub problem is only solved once once we
solve all of those subproblems we can
concatenate them or put them together to
find the optimal solution for the larger
initial problem so what I've got here is
this funny little it's like an xkcd but
it's not it's just a clip but what I'm
gonna do is I'm going to just animate
the dialogue here just just to give you
some you know a little bit of fun before
we get into the harder stuff so there's
a woman and a man okay so here's how it
goes Oh what to wear what to wear such a
vast wardrobe how will I ever find the
right combination perhaps I can help
who are you I'm here to tell you about
dynamics the new selection optimization
software from algorithmic anomaly how
does it work well we use dynamic
programming to recursively create an
outfit that you'll look just stunning in
now if we want to do this in n squared
time we'll have to hurry let's begin
that shirt and those pants that you're
holding how good they look together how
would you rate them on a scale of one to
ten and so she says seven he says
excellent I'll enter that into our array
and then he keeps asking her these
questions how about those shoes with
that necklace she says three how about
those other shoes with that shirt she
says six he keeps asking her these
questions this necklace with those pants
that shirt with those pants - six right
three hours later there I've told you
everything and now in a few seconds the
paradigm will have worked it's magic
voila all done so what you want to wear
are these exact pants this shirt those
shoes and that and
later that night darling you look
absolutely dynamic somehow I knew he was
gonna say that right so what's happening
here is we took this larger problem
which is what is the optimal outfit to
wear that's gonna impress this dude at
the end right and what this what this a
programmer did was he broke it down into
subproblems what's the optimal shoe and
necklace to wear together what's the
uploads optimal pants and shirt to wear
together and then he combine all those
solutions to form the perfect larger
problem which is that larger outfit
right so dynamic programming can be used
to solve problems that would take
exponential time and it can solve them
an N squared time or n cubed time it's
so it's very similar to the divide and
conquer approach recall that in divide
and conquer or taking a problem
we're subdividing it into smaller
problems right we're dividing it and
conquering each of them but the
difference between divide and conquer
and dynamic programming is that in
dynamic programming some of these
subproblems can overlap and what I mean
is let's say this you know shirt
necklace dressing example we can have
one of the subproblems be what is the
optimal combination of a necklace and a
shirt and another one could be what is
the optimal combination of a necklace
shirt and shoes
notice how the necklace shirt and shoes
is kind of a subproblem of this other
size or a not a subproblem but a super
sect problem of this subproblem but
they're both subproblems in the larger
scale of things right but they overlap
is what I'm saying so the basic idea is
that in dynamic programming we're
breaking the problem up into subproblems
and we use the optimal solutions to
those subproblems to give us the optimal
solution to the larger ones it's ok if
they overlap that's that's ok
and it's basically recursion plus using
some common sense
so recursion allows you to express the
value of a function in terms of other
values of that function where common
sense tells you that if you implement
your function in a way that the
recursive calls are done and stored for
easy access it will make your program
faster so what we're doing with dynamic
programming is we're essentially trading
or trading space for time right so
instead of calculating all the states
taking a lot of time but no space we do
take up space to store the results of
all those subproblems to save time later
right so it's it's a trade-off
we're storing some values so we don't
have to recompute everything all over
again so it's faster but the trade-off
is we're saving more data so we're
taking up more space complexity a good
time to use this is check out this well
here's a here's an example by the way so
the the algorithm here is repeat the
others word add your word and pass it on
to the next one and if you're wrong then
you have to drink one beer and we start
over again so this is called dynamic
drinking it's just a joke but it's like
another way of understanding this the
first guy says wild drinks or the first
guy says while the next guy says wild
Bob the next I says wild Bob eight so at
every iteration we've saved the previous
state right while while Bob think of it
as an array right so we're storing all
these previous States rather than having
to recompute everything all over again
and eventually this guy at the end he's
so drunk he forgets what the other said
and so we start over again so all of
these dynamic programming problems have
four steps first we show that the
problem can be broken down into optimal
subproblems right so you have to think
about it like right within the case of
dressing someone up or in the case of
some larger problem that we can
subdivide into subproblems like
designing the optimal layout of a room
right we could just we could split the
room up into subsections right and they
all have their you know individual and
unique features right the wall is kind
of curved at this end but it's like this
and hey this sofa would fit perfectly
into this subsection of the room right
so we divide it into subproblems then we
recursively define the value of the
solution by expressing it in terms of
optimal solutions of the smaller
subproblems so the optimal solution to
this room design problem would be such
that each of these spaces in terms of
square meters or square feet are filled
at the at their maximum value because
the optimal solution for the larger
problem is to fill as as many square
meters or feet as we can such that the
room is completely fit full right we
compute the value of the optimal
solution in a bottom-up fashion I'll
talk about that in a second and then
lastly we construct an optimal solution
from the computed information right so
okay so here we go with this there are
two key
attributes that we must have for any
problem in order to apply dynamic
programming to it the first is it has to
have an optimal substructure what that
means is an optimal solution to a
problem an instance contains optimal
solutions to subproblems and then we
have to have overlapping subproblems
meaning a recursive solution contains a
small number of distinct subproblems
repeated many times so let's let's talk
about this right so we have so every
problem has to have two of these
features it's got to have an optimal
substructure such that for each of these
subproblems
if we find the optimal solutions to them
we can combine them and then find the
optimal solution to the larger problem
that's the first the second is it's got
to have overlapping subproblems right
like shirts you tie and then shirt tie
for it right for example those are
overlapping so how do we solve this
problem so we've identified a problem
that has those two key features how do
we solve it well we have two approaches
the first and these are fancy words is
the tabulation approach the second is a
memoization approach and what these
really means are a bottom-up approach
and a top-down approach so here's the
bottom-up approach let's say I want to
become an amazing coder right that's
that's the goal so the bottom-up
approach would be step one I'm going to
learn a programming step two then I'll
start practicing step three I'll take
part in contests step four I'll practice
even more and try to improve step five
after working hard like crazy
step six I'll be an amazing coder that's
bottom-up right we're starting at the
very bottom started from the bottom now
we're here right we're starting with the
very bottom like Drake and we're going
to the top now top down is the opposite
we start with that final solution I will
be an amazing coder how I'll work hard
like crazy how I'll price is more and
more and more how I'll take part in
contests all the way down to the bottom
I'm gonna learn how to program okay now
I've got this table that shows some of
the you know key differences and
similarities between these two which I'm
not gonna go into right now because
there's a lot let's just get into an
example shall we okay so for overlapping
subproblems let's take the Fibonacci
sequence as an example you've heard of
the fibonacci sequence right it's it's a
sequence of
numbers where where every number in the
sequence is the sum of the previous two
numbers right so the first one will be
one there's nothing before it so it's
zero the next one is one so 1 plus 1 or
1 plus 0 is 1 the third one is 2 because
1 plus 1 is 2 the fourth one is 3
because 1 plus 2 is 3 right it's just
that this just that chain right it's a
recursive chain we can solve it
recursively so that's the Fibonacci
sequence so how do we solve this how do
we write how do we write a programmatic
algorithm for this well one solution is
to do it recursively right so doing it
recursively does not mean doing it the
dynamic programming way there's a
distinction here so let's look at the
recursive solution the recursive
solution looks like this in Python now
let's go over this function here the
functions is in fib with the parameter
int n right so we we input the amount of
numbers in the sequence we wanted to
compute and then we have a base case the
base case is if n is less than or equal
to 1 return that return what n is and
then return fib n minus 1 plus fib n
minus 2 which are both the the sum of
the previous two numbers so what this
looks like is if F is 1 then we're just
going to return 1 so then it would
construct 1 if F is 0 then we're going
to turn 0 right but then if F is 2 it's
going to be this it's gonna be look at
this look at this recursive tree that's
gonna be computed it's gonna be F of 1
plus F of 0 which is 2 if F of 3 if it's
F of 3 it's gonna be F of 3 is going to
be F of 2 plus F of 1 and then for F of
2 we have to then compute recursively
the solution for F of 1 and F of 0 now
if we do it like this we'll totally
solve Fibonacci however we're going to
have to call F of 3/2 times if we do F
of 3 we could have stored the value of F
of 3 instead of computing it again and
we could have reused that old stored
value we're not storing anything in
memory here we're recomputing this
entire tree so notice if F if it was F
when I say F I'm talking about fib if F
was like let's say 200 we would have to
continually recompute all the branches
of this tree of execution where
if we saved some of these values
iteratively then we wouldn't have to do
that so right it's a trade-off between
time complexity and space complexity so
how can we do this in a dynamic
programming way
well the dynamic programming way looks
very similar to the recursive version
with the small modification in that it
uses what's called a lookup table before
computing solutions how do we do this
first we initialize that lookup table as
nil there's no values in here whenever
we need a solution to a subproblem we
first look into this lookup table if the
pre computed value is there then we
return that value otherwise we calculate
the value and put the result in the
lookup table so that it can be reused
later this is the dynamic version of
it's the memo eyes version for this
function we have our base case which is
the lookup table initialize as nil if
the value is not calculated previously
then calculate it notice that here is
the recursive part fib and one with the
lookup as its parameter and in fib and
two with the lookup as this parameter
again we only add those up if the value
in the lookup table is empty and then at
the very end we return the lookup table
so notice how it is recursive however
we're adding in this extra lookup table
which acts as a store for the pre
computed values in that fibonacci
sequence and it's still a top-down
approach right memo eyes approach
because we're starting at the top the
top is what is the last value in that
Fibonacci sequence and then let's go to
the smaller sub values right now now
instead of doing top down let's do
bottom up so the tabulated or bottom-up
approach is building a table in a
bottom-up fashion and returning the last
entry from that table so for the same
fibonacci number we calculate first fill
up zero then fib 1 then fib 2 then fib 3
and so on instead of the opposite way
right it's like 53 52 51 50 row we're
doing it bottom up we are literally
building the solutions of subproblems
bottom up so in this example for the
tabulated version we are starting with F
of 0 right F 0 times n plus 1 and we are
adding not subtracting from n because n
starts at that at that minimum value and
then we have our base case
and then well n is gonna be how many
numbers we want that the parameter is
the same however the way we're computing
it is different we're starting at the
we're starting at the smallest value and
we're adding them up iteratively
like in this for loop we're calculating
the Fibonacci and storing those values
inside of this array that we declared or
earlier so both of these solutions store
the subproblems write them in the
memorized version the top-down version
the table is filled on demand while in
the tabulated version we start from the
first entry and all entries are filled
one by one
but unlike the tabulated version all
entries in the lookup table are not
necessarily filled in the memorized
version right so that is the overlapping
subproblems feature that each of these
dynamic programming problems can have
now here's the other feature the optimal
substructure feature now this also
applies to the Fibonacci problem we just
looked at but I'm gonna look at a
different problem now
which really exemplifies this feature of
dynamic programs so the problem here is
the shortest path algorithm right we
know about shortest path Dijkstra
there's a bunch of the traveling
salesmen problem there's a bunch of
shortest path algorithms out there but
we're gonna talk about one in particular
that's called the bellman-ford algorithm
so let's say we have a graph right we
have some graph right a graph with with
nodes with edges and we want to find the
shortest path between two two nodes
right so how do we do this so this is an
example of have a problem that has an
optimal substructure check this out I'm
gonna read this out all right here we go
if a node X all right we've got a node X
lies in the shortest path from a source
node you right we have node X source
source node u and a destination node V
that's it that's all you have to
remember three nodes node X node U and
then node V then then the shortest path
from u to V is a combination of the
shortest path from u to X and X to V
makes sense right
we have three nodes X is in the middle u
X V the short what all it's saying is
the shortest path from u to X and X to V
is equal to the shortest path from u to
V so if we solve these two up sub
optimally we will get the optimal
solution to the larger problem what's
the shortest path from u to V right so
that's an example and we can use the
bellman-ford algorithm to find that
shortest path so here's how it works so
we're given a graph and a source vertex
I start see in that graph we want to
find the shortest path here's how we do
it first we calculate the shortest
distances which have at most one edge in
the path then we calculate the shortest
path with at most two edges and so on
three edges four edges five edges etc
after the ice iteration of the outer
loop the shortest path with that most I
edges are calculated and there can be a
maximum V minus one where V is the
highest threshold edges in any simple
path and that is why the outer loop runs
V minus one times right so here's an
example where basically we're computing
all of these sub sub paths and then
we're finding the optimal solutions to
those then when we find them we can just
add them together and that gives us the
optimal path from A to B which are going
to be our parameters to this model so
here's the code version of this these
are our initialization steps we don't
have to look at these
but here's really really the meat of the
code where this is happening the
bellman-ford equation finds the shortest
distances from source to the initial
node that we're at that were we were at
so step one is to initialize the
distances from the source to all the
other vertices then we relax all the
edges v minus one times a simple
shortest path from source to any other
vertex can have at most that many edges
so we have this nested loop where we're
updating the distance values in the
parent index of the adjacent vertices of
the picked vertex so consider only those
vertices which are still in the queue
and then we check for negative weight
cycles and remove them so then we are
left with the optimal solutions to that
larger sub-problem and then we have you
know us constructing the graph with all
of its edges and vertices and then we
print the solution but what I put what I
mean there's there's a ton there's
literally a ton of dynamic programming
problems out there there's like 40 50 60
on these sites out there you know like
dynamic programming problems
problems there's a million in one of
these which I was looking at gigs for
geeks calm checkout geeks for geeks calm
we've got so many of these dynamic
programming problems but anyway we're
worried okay so what do we know about
dynamic programming it's well any
problem that dynamic programming can be
applied to has two key features it's got
an optimal substructure meaning if we
can find the optimal solutions to the
subproblems we can find the optimal
solution to the larger problem and it's
got overlapping subproblems meaning some
of those problems will overlap sure
choose tie tie shoes right they overlap
and now where do we apply this well in
deep learning the workhorse of deep
learning is the back propagation
algorithm this is how supervised
learning works ok let's take a look at
some some code here for this alright so
here it's a series of code for a simple
feed-forward neural network that's
trying to predict the pattern match
between these inputs and outputs right
we have 0 0 1 1 1 1 1 0 1 1 0 0 and then
we have its associated labels 0 1 0 0 0
we want to find the pattern here such
that we give this network some input
like 1 0 1 arbitrarily and it will know
exactly
oh the label is going to be 0 or 1 after
training on this very small four point
data set so how do we do this well in
this training step we say we first we
initialize our weights as a matrix right
we only have one sets of weights this is
a perceptron a very simple neural
network we have our activation function
which allows us to learn nonlinearities
and then I'm not going to go through the
total details of back propagation now
I've done this many many times
look at my intro deep learning series in
fact I could just you know rap about it
a little bit right now my ones and nose
mapped two O's and once inputs add
weights update get sums past that
to my sigmoid function get that error
what's real in prediction and that's why
I use gradient descent
it gives predictions and it doesn't
pretend update weights and repeat 10,000
times
outputs are lit I'll be doing just fine
if you want to see that actual rap check
out my intro to deep learning playlist
and I think it's number two how to make
a neural network where I actually rap
that but anyway what we're doing here is
we are calculating a gradient value
right we're calculating a gradient value
which is which is also called a partial
derivative with respect to our weight
values it's one single value and we are
doing that recursively for every way to
going backwards so we feed forward we
calculate some input data apply an
operation write input times weight
activate we send it to the next layer
input times weigh activate sends the
next layer we get an output we
recalculate the difference between the
expected output in the actual output the
label that's our error we use that error
to then compute a gradient with respect
to the weights going backward right
backward we compute a gradient we get
that gradient update the well we update
the weights at the very end and then we
use that gradient to compute the
gradient for the next layer and
recursively for the next layer that is
dynamic programming because we are
storing that gradient value to update
our weights later on okay that is
dynamic programming in principle we
could calculate the partial derivative
of the function with respect to any
weight simply by tracing out the nodes
downstream from it and calculating the
longer derivative chains manually but
we're not doing that we're using the
chain rule and dynamic programming to do
it in a much more efficient way and that
is back propagation it would be very
tedious to do it the other way the key
idea is that we can reuse results for an
efficiency increase just as we do for
dynamic programming in general so it's
used in deep learning where else is it
used it's also used in reinforcement
learning in reinforcement learning I've
got a whole playlist on reinforcement
learning as well just search
reinforcement learning playlist
Siraj on youtube but dynamic programming
solved for the optimal Follis policy or
value function by recursion so if we
look at the landscape of reinforcement
learning algorithms we've got policy
optimization and we've got dynamic
programming and two of the most
important techniques in Markov decision
process optimization or policy iteration
and value iteration and from them spring
queue learning
and actor credit mythic methods so
dynamic programming is used heavily to
find the optimal Markov decision process
and this if you if you don't you know if
you want to know what a Markov decision
process is it's a way of framing an
environment where an agent can learn
from right we have a set of states we
have a set of actions that the agent can
take we have some transition function we
have some starting state distribution a
discount factor if we want to get fancy
and then some reward for completing the
correct action whatever that objective
is lastly let's go over some runtime
analysis how do we analyze the runtime
of a dynamic programming problem well it
always takes this kind of formula the
pre-processing runtime plus the loop
times a recurrence plus a proce
processing so it's a runtime of all
these pre-processing or any of the
initial steps you have to take just find
a time complexity of that for the loop
is how many times is a loop run instead
of is it a single loop is that a nested
loop is it an S&amp;amp;S and that's a loop and
then recurrence how much time does it
take the recurrence to run in one four
loop iteration we multiply those two
together add the post-processing and
that's going to be our overall runtime
analysis for a dynamic programming
problem I hope that video helped you and
if you want to learn more please
subscribe for more programming videos
for now I've got to find 99 sub problems
so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>