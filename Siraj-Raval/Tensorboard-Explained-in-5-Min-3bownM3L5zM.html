<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tensorboard Explained in 5 Min | Coder Coacher - Coaching Coders</title><meta content="Tensorboard Explained in 5 Min - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tensorboard Explained in 5 Min</b></h2><h5 class="post__date">2016-09-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3bownM3L5zM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and in this
episode we're going to talk about tensor
board tensor board is a data
visualization tool that comes packaged
with tensorflow
tensor flow programs can range from
super simple like an addition problem to
super complex using thousands of
computations and they all have two basic
components operations and tensors the
idea is that you create a model that
consists of a set of operations feed
data or tensors into the model and the
tensions will flow between operations
until you get an output tensor which is
your result tensor board was created as
a way to help you understand the flow of
tensors in your model so that you can
debug and optimize it we're going to
visualize a classifier that can
recognize handwritten digits in tensor
board we'll use two examples of the
classifier one is a simple version in 60
lines of Python and the other is a more
complex version Python I love you don't
worry if you don't understand every line
of code we just want to get a general
sense of what's happening under the hood
so that we can later understand the
tensor board visualizations here we go
we'll start by importing tensorflow in
our input data class which pulls our
training data from the web then we'll
define two helper functions and it waits
will return a variable that contains
randomly generated weight values along a
normal distribution
our second helper function will create
our model a three-layer feed-forward
neural network we're going to create
three layers and define them via the
name scope function the name scope
function creates high-level namespaces
for operations in the tensor flow graph
that we will later visualize and each
layer will run a drop out function and
an activation function drop out is a
function that forces our neural network
to learn several different
representations of patterns so that
generalization improves the activation
function creates probabilities out of
numbers so now that we have our two
helper functions we can create variables
to store our training and testing images
as well as our training and testing
labels next we can create input and
output placeholders for our data then
we'll initialize our weights between
each of the three layers using the
function we defined earlier we'll define
histogram summaries for each of our
weights so we can visualize the
distribution of weights later in tensor
board the next step is to add drop out
placeholders to our hidden and input
layers we can then create our model
using the variables we've created now
that we have our model will create our
cost function the cost function is a
measure of how good a neural net is with
respect to its given training sample
index
output we wanted to decrease over time
we'll also measure the accuracy of the
network we want that to increase over
time well later visualize book next
we'll create a session to run our graph
computation intercession will save our
model using the summary right lastly
we'll initialize our variables for
training and train our model that's it I
know that was really fast
unlike series comprehension you heard me
Apple let's visualize that code in
tensor board and I'll explain it more
summary operations are how attentive
board acquires data from our tensor flow
runs they are functions like TF matrix
multiply we created a number of them in
our code here in the events tab we can
view our scalar summaries accuracy and
cost the x-axis shows a time steps and
the y-axis shows the accuracy measure or
the percentage of correct predictions
over time we can blow up our graph for a
closer look or view a wider range of
data points by expanding the y-axis we
can also drag a rectangle on our graph
to zoom in on a certain region if we
like and double click to zoom out as we
mouse over the chart it will produce
crosshairs with data values we can
change how smooth our line is by
adjusting the slider the step option
shows time steps the relative option
shows the time relative to the first
data point that means the number of
minutes or hours since the training run
was started and the wall option shows
the actual time the runs happen we can
create more tags as well in this sidebar
it can either be an entirely new tag or
a tag that will group a bunch of
existing summaries together into a new
category let's switch to a more complex
version of our handwritten character
classifier example with even more scalar
summaries we can type in it's over 9000
and since no summary contains those
terms it becomes a new category but if
we look under max and mean they both
contain summaries for biases so if we
type in biases it will create a new
category that contains both biases from
these two existing categories we can
also download our graphs in CSV or JSON
format for this more complex example we
have lines for both training and testing
data that way we can compare our runs
let's move on to images we created an
image summary this lets us view the
images in both the training and testing
folder ok let's switch back to our
simple classifier and move on to the
graphs tab which lets us inspect our TF
model we can see each of the three
layers we created via the name scope
function let's double click on one of
our layer namespaces to expand it the
first thing that pops out is the drop
out function which we declared inside of
the scope as well as our riilu and
matrix-multiply functions notice the
arrows from both nodes pointing to the
cost operation the direction of the
arrows shows the direction that the
tensors are flowing our two plates
holder operation nodes X and P keep
input hidden which is used for the drop
out function serve as entry points for
our tensors they move through each of
the three layers through the weights
into the
cost function everytime eventually to
the accuracy function and finally to the
output placeholder that gives us our
prediction to reduce clutter tensorflow
automatically shows nodes with many
connections to other nodes in their own
area to view in detail if we wanted to
we can add them back to the main graph
by clicking the Add to main graph button
in the detail car
Yoh bringing it back let's take a look
at the sidebar we can choose which run
we want to display trainer test and show
the graph at each time step the color
option lets us see at each time step
what structures are being used which
device each operation is running on
compute time along a scale and memory
usage we can also manually upload a
saved tensor flow graph right from the
UI if we like let's move on to
distributions we created histogram
summaries for all three of our weights
between layers and we can view the
distribution of each weight here let's
switch to our complex classifier the
live part shows all the weights across
time and the shaded part shows those
weights that are actually activated
during training these curves represent
percentiles like the max and mean and
median the histogram plot allows us to
plot any variables we like from our
graph it's showing how the values of our
weights change with training isn't it
beautiful
tensor board lets you visualize your
data so you can debug and optimize it
you can create summary operations in
your tensor flow program which takes
tensors as inputs and produces output
tension board reads these summaries and
displays them visually the challenge for
this video is to create a tensor flow
program that visualizes audio data in
some way a winner gets a shout out for
me in two episodes more info and links
in the description please subscribe for
more ml videos and for now I've got to
go get some sunlight so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>