<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Simulate a Self-Driving Car | Coder Coacher - Coaching Coders</title><meta content="How to Simulate a Self-Driving Car - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Simulate a Self-Driving Car</b></h2><h5 class="post__date">2017-05-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EaY5QiZwSP4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and today I'm
going to show you how to build your own
self-driving car in a simulated
environment and it's actually much
simpler than what we've been doing like
so recall we've been talking about
generative adversarial networks and
variational autoencoders and all sorts
of stochastic models this comparatively
is actually surprisingly simple which is
crazy if you think about it a
self-driving car is simple no but it
actually is it's nine lines of chaos I
mean the model itself is and then the
helper code but we're going to talk
about how you can build this and I'm
going to show you step by step the
entire process ok so here's an example
of what it looks like when it's when
it's fully trained and it's running in
the simulated environment so I'm super
excited I hope you are and at the end
I'm going to answer some questions just
straight up from YouTube comments so I'm
excited for this let's get started so
the first thing we want to do I'm going
to stop this demo this is what's
eventually going to look like and now
the car is going to crash into the water
because I turned off the autonomous
feature uh-oh let me just turn off the
simulator ok simulator is gone ok so
let's first go ahead and talk about what
this is and what the whole deal is
behind all this a little bit of theory
and then we'll get back into the code ok
so where are we where are we
there we are ok so how to simulate a
self-driving car is the name of this
tutorial
and so Udacity recently open source
their simulated so they built a
simulator specifically for self-driving
cars so cool right it's just for
self-driving cars and it was it was
built for their self-driving car an
inner degree students and they recently
open sourced it so it was built with
unity which is if you haven't used unity
before I would definitely recommend at
least checking it out if I had more time
I would definitely be diving into unity
and building all sorts of cool 3d models
that I could play with and you know
maybe even generating 3d models with
generative models but yeah it's a great
tool it's very much using in virtual
reality and more and more in machine
learning or for modeling and things like
that but everyone check it out but yeah
they built this thing in unity and they
added a bunch of pre-built scripts they
added a bunch of scripts and these
scripts control things like
Appetit and momentum and acceleration
and all sorts of things that you would
think would be in a self-driving car
simulation and you can modify these
things as well as they're just values
that you've just change in code but you
can find the actual simulator itself
right here on github and I'll also have
a link to it in the description and in
the github readme but it's a binary file
you don't have to compile it from source
that is like an exe you know you just
download it it's like a dot app file and
you can just download it for Linux Mac
and Windows and then boom you're good to
go
and it's got two modes it's got a
training mode in an autonomous mode and
I'll talk about what each of those modes
is but the high level is you just
download it and it just works no
dependencies to install or anything so
it's super super simple ok so that's
what they built and so let's talk about
the three step process and how this
works ok there's a data generation part
then there's a training part and then
there's a testing part so the first part
is the data generation part and so what
happens is we are going to first look at
what Nvidia did so to generate the data
what Nvidia did was they took their bit
to the car and they did the same exact
thing that we're going to do we're going
to replicate what Nvidia and Udacity did
it's the same thing
they built a nine layer convolutional
Network and they attach three cameras to
the head of a car ok so they attached
three cameras to the head of the car and
they had a human driver drive the car
while the cameras were attached and all
the car has to do was collect data and
buy data I mean the steering up let me
turn off the sound here the Sirian
commands that the human driver was
inputting as well as the camera feed so
the three sets of camera images coming
from from all three cameras okay at the
same time and that was the data
generation part okay and so there were
there were images from the center left
and right cameras with the associated
steering angle speed throttle and brake
so there were four of physics variables
as well as the static images that were
coming in and it saved it also a CSV
which is what we're going to do and
ideally ideally you have a joystick for
this thing but I don't have a joystick
ain't nobody got time for that and just
because it's like it's
easier it's smoother with the
transitions and stuff using a keyboard
the WASD Keys is kind of erratic but
whatever I mean it works it works what
you saw was based off of a keyboard
training so whatever it works so yeah so
that's for the data generation part and
then there's the training part okay so
what the idea is that we have a human
driver okay so the human driver is just
driving around and we're recording all
that data and then we're going to get a
machine to clone that behavior so we
call this process behavioral cloning ok
behavioral cloning and to do this we're
going to build a nine layer
convolutional Network nine layers in
chaos that's just literally nine lines
of code and it would based off of
Nvidia's and to end learning for
self-driving car paper and yeah so they
trained on model for 72 hours on the
whole in a whole bunch of different
driving conditions sleet rain hail all
all sorts of things wet rain you know
everything so here's the hardware design
so the hardware design was it's
obviously a steering wheel but the
steering wheel is attached to a
controller those that was the so many
acronyms here because the controller
area network bus and so it's feeding in
those four variables that I talked about
right and you also have your three
cameras and the three cameras are all
feeding in continuous streams like just
frame by frame of all the images that
the car is seeing and it's fed into this
Drive px computer which is essentially
like a motherboard with a cluster of
jeep on-board GPUs attached to it and
then and then assaults a store it would
just store the results that's it okay so
that's the that's the high-level idea
behind the hardware behind it and then
the software behind it oh and also
interesting little tidbit I just
recorded from the paper instead of
inputting the steering command are
directly they inputted one over R and
they found that this may turn smoother
and it maybe it made the autonomous
angle that the car moved independent of
the geometry of the car so the car was
facing left
it didn't matter or the car was facing
right it's all about what the cameras
with the camera see and then using that
as the signal to then move the steering
angle so it's it's independent of the
directions the car is facing it sounds
counterintuitive like wait you want that
but you actually wouldn't and we'll
learn more about why that is as we get
into this code okay so the software
design for this code and it's so you
know it's crazy because going from
generative adversarial networks to this
is like that's it that's all it takes
for self trying to guard like what but
that's that is actually how it is check
this out so we here's here's what
happens we have we have two inputs right
we have our steering angle and then we
have our sets of cameras right which is
so three sets of images those are our
inputs and so we can think of the
problem as a supervised learning problem
right we have our input data which is
which are the images and then our output
labels which are the if we could just
abstract all of these steering angles
into one value you know like one binary
value that would be our label like based
on what you see how should you move the
car that's it right so we have a CSV
just listed of all of those things right
and at the same time we have what the
car is trying to do so during the
training process assuming we've
generated data 72 plus a 72 hours of
human generated driving data we can then
compare the both of those results
together so we can compute the error or
loss between the two right so if we have
let's just say we have the camera angles
and the steering wheel from the
autonomous car and then the camera
angles in the steering wheel variable
from the human generated data and then
we just vectorize both of those values
into one value and then we find a
difference between those values and that
difference is our error and then we use
that propagation to them update our
weights based on that error value okay
so it's taking that that weight value or
that back that error value and then back
propagating it in our weights okay so
images of images are fed into the CNN
and then it computes a proposed during
commit okay and that is the predicted
steering command and we want to find the
difference between the predicted
steering command and what the actual
steering command would be from the
training data okay and then the proposed
command expects the desired command
right label the target
versus the actual output and then the
weights of the CNN are adjusted to bring
the CNN output closer to the desired
output and the weight adjustment is
accomplished via backpropagation so
eventually you want it strained then all
you're going to need is the center
camera one camera you feed it to CNN and
it outputs a prediction when the
prediction is the angle of the steering
with just one output right so that's it
for training and then for testing right
so once once we once we train this
autonomous model for testing we could
think of it in terms of a simulator as a
server client architecture right the
server is going to be the simulator
itself that is our you know the app that
we downloaded that little 3d game and
the client is going to be our Python
program but what we write and what it's
going to do is it's going to just be a
feedback loop it's going to be a
feedback loop so we can consider it as
just so this is how we can consider it
it's just the client is piping in
steering angles and throttles to the
server and the server is typing back up
images from the car and steering angles
so that it can train it right it's just
it's just it's just a feedback loop so
that's that's the basic idea behind you
know how this works high-level NVIDIA
has a paper on it and then Udacity you
know was inspired by it and now I'm
bringing it to you guys so it's just the
chain of a chain of whatever
okay so let's build this thing right
enough talk let's build this thing so
the first step is to install our
dependencies and you can do this really
easily with just one line of code
there's an environment dot of yml file
and you can use anaconda to do this okay
so if we look in the environments fall
we've got like 20 dependencies here but
you don't have to you know as long as
you run this one line of code it's going
to install all of these dependencies and
make this bigger
all of these dependencies super easily
okay so yeah you got OpenCV which we all
know is a pain to install so luckily for
us anaconda is going to make it super
easy to install okay so that's the first
step now I would do this myself but I've
already installed the dependency here
but what I can do right
just paste that in and once you paste
that in then you're going to type in I
can show you the command you say source
activate both the command I'll put it in
the output in the github readme but you
then you activate your content by
ernment
and it's going to be called behavioral
cloning source activate behavioral
cloning and then that activates the
environment so it's you install your
dependencies in this container this
anaconda container and then you activate
it so then all those dependencies are
then active in that shell in that
session in terminal ok so once we have
that then we can generate our data ok
where we've got our dependencies now
step two is to generate our data so this
is a five step process we're going to
install dependencies which we assume
I've done step two is to generate the
data so we're going to drive ourselves
but we're going to write to replicate
with it with Nvidia did with the human
drivers step three is to write the
training script step four is to Train it
then have our agents learn or clone the
behavior of us the human and step five
is to write the testing script and then
let it run okay so let's go ahead and
generate our data so to generate our
data we're going to have to actually
drive this baby which is going to be a
lot of fun
now you just double-click on the app you
know I downloaded it you can double
click on it and then you notice it's got
a couple of settings I said it's
fantastic because why not
of course the choice but you know
fastest you know depending on your
processor you would want to change this
so I'm going to go ahead and run it at
800 by 600 and it's going to going to
pop up just like that and I'm going to
go into training mode okay so for
training for training mode I'll just
click on training mode and the controls
are going to be WASD okay so just like
this see this is me driving right now I
am driving the car okay and now I'm
going to stop the car and now I'm
driving it again okay so this is human
driving so what we're going to do is
we're going to generate data so that we
can train our our car on that data okay
so to do this we just have to type in
just type our right to record our and so
then it's going to ask well where do you
want to save this data to and I'm going
to say let's save it to the desktop okay
let's save it to the desktop and
start recording and now what it's doing
it is recording three sets of images
from three virtual cameras of the car
okay
assume that the cameras are on top but
what it's doing is its capturing frames
from this game from three different
angles and it's also recording the my
the four variables I talked about speed
throttle and the other two steering
angle there's one more to look at
but basically what you want to do as you
train this thing is you want to complete
either up one between one and five laps
okay ideally five but and look I'm off
track but let me just stop recording and
so then once you're done you know
driving between one and five laps then
hit R again and it's going to capture
that data so it's going to replay what
you've just done and it's going to go up
to a hundred percent and when it's done
it's going to save it all to a CSV file
that we're going to look at and see
what's inside of there so we could
observe it so we've got fifty two
percent and in the meantime let me go to
the CSV file and show you guys that what
else we're also going to show you all
this captures well is actually fun to
just watch this let me see what else I
can talk about the training and testing
script yeah we're going to be using cars
95% here we go done okay let's check it
out what if what did we save here so if
I go to open and then I go to my desktop
there's my driving log just just like we
thought it would be okay so let's take a
look at what this is let's take a look
at what this is what we've got here are
three images right and it's the first
three columns are images they're
pointing to images and these are the
images that it's pointing to right here
image folder okay their point their
absolute directory values it shows us
exactly where they are so see these are
the images that they're pointing to just
like that and these are frames that were
captured from the game and we've got
three sets of images for the C Center
for the left and these are labeled with
the direction and the right so we've got
three sets of images and then we've got
four values here and these four values
are those values that I talked about up
here which are the
which ones are they the steering angle
to speed the throttle and the brake all
four values and these are what I input
it and see how at the start I wasn't
moving so these are these are zero
values but then as I start moving
they're going to change okay so that's
it that's it for our data so what you
want to do is right train it between one
run one full lap and five laps
okay so somewhere in between there so
yeah that's that's it for our a data
generation part where were we in our
process we were at step two so assume
that I've generated data okay just like
that it would take a while but I
generated data so the next step is for
us to write our training scripts so
let's write this training script okay so
where were we for our training scripts
I'm going to say okay so we've got two
files here we've got a training script
which is modeled up PI and then we've
got a testing script called drive dot pi
let's write our training script right
we've generated our data and we saved it
to the desktop and now we want to build
a model that will see a convolutional
network that will read from this data
and then it will output output steering
command so we've got pandas 10 is going
to be our data analysis 2 toolkits numpy
is going to help us do matrix math we're
going to import scikit-learn just so we
can split our training and testing data
in two sets in two sets and then we're
going to use Kaos as our machine
learning model sequential because it's
going to be a linear stack of layers
very simple model and then add them for
gradient descent model checkpoints so we
could save our model and then we've got
a layer types that we're going to use
then our helper class utils it's going
to define our input shape and generate
training images and then our arc parts
for command line arguments and lastly
our OS module for reading files so what
I'm going to do is I'm going to write
the code for building the model itself
but all of all the rest of it is pretty
written right so the data loading parts
are pre-written we're going to load that
CSV file that we just created write that
driving log and make it bigger make it
bigger the driving log we're going to
we're going to generate that data or
we're going to read from that data using
pandas and then we're going to say okay
so now we have that in a data frame
variable very easily parsable variable
thank you pandas
then we're going to say for the center
left and right columns get those values
and that is going to be our input data
that's going to be our X right and then
our output data is going to be our
steering command so we can concatenate
that into one variable right so then we
have our input data and our input in our
output labels and we want to find the
mapping between the two this is a
supervised learning problem and once we
find the mapping between the two then
given novel input data which is novel
camera images of what a car sees we can
then output the predicted label which
will be the herring command see very
intuitive right okay so we've got our
input data in our output labels and then
we can split the data into training and
testing data so it's 80% training 20%
testing and we can define the size of
that in our command line argument and
test size okay which is going to be
point two oh this is going to be this
value so yeah so we're gonna have a
training our training data and our
testing data and our validation data and
we returned back okay so and then we've
got the code for building our model and
then training the model and then the
main function right so let's forget
about these command line arguments so
let's just go straight to the main
function and let's say that for our main
function after printing you know
whatever our parameters are we're going
to load our data using that funk that
function that we just talked about then
we're going to take that data and use it
to train our model but first we'll build
our model and then once we built our
model and loaded our data we'll train
our model right using those two
parameters as well as any command-line
arguments so this commit this helper
function just is for converting a string
to a boolean value for a command line
argument but this training model
function is really interesting
let's first build the model and then
we'll talk about the the training model
function okay so for this first part
we're going to build this model and it's
going to be a sequential model right
it's going to be a sequential model very
simple model and we can just pull this
straight from the paper serve in a paper
write the paper told us the parameters
with which we could build our network so
we'll use those parameters we'll use
those parameters build our network so
the first step is for us to say okay we
want our first layer to be an image
normalization layer okay we can totally
do that
image normalization layer using a lambda
function and the land of function is
going to help us do so really easily and
we'll say okay it's going to be from e
type of cell and then I'll talk about it
input shape okay so what's the deal here
so X yeah so this is going to avoid
saturation and nicker gradients work
better now notice that these are magic
numbers right here but we but the
authors sound that you know after
training and testing out different
values these are the ones that work that
for normalizing the images right when we
input it to avoid saturation and make
the gradient work better what do what do
we mean exactly by that something you
know the images can be shadowy they can
you know any on the lighting it can be
certain things could be obstructed or
the hue of it you know all of these
color correction values could be off and
they could give us results that are bad
so we want to avoid that right so that's
that's when we when we say image
normalization what we really mean is we
want to format or reshape these image
tensor values into values that would
give us good predictions in the end
right so that's it for our first model
and then we've got a bunch of
convolutional layers that we did
essentially copy copy and paste once
we've written out the first one because
they're very similar and so the first
one is going to have a filter size of 24
okay I got you and instead it's going to
be a 5x5 convolution okay I can do that
as well and then it's going to have an
activation function which is going to be
e Lu which means exponential linear
units so okay we've got earu here okay
which is more suited for this task than
rectified linear units and we're going
to subsample with two by two because
that's the length of our strides and
then we'll add our closing parenthesis
okay so that's it and so why do we use
Alou it's because it takes care of the
vanishing gradient problem that's why so
okay so we've got five of these layers
let me just paste that one two three
four how many of these five I think
that's five that's well okay so then we
want to make sure okay so what's the
difference here the filter size here is
thirty six this
now you can just read from a paper and
just write out the model directly right
it's not that hard they have the
parameters and with you know a simple
library like Kara's you can you can
build a model pretty easily
so we've got 36 we've got 48 64 64 okay
and so then we can remove the
subsampling for this for these last two
layers since the simplest right size is
one by one respectively for each of
these for each of them so they'll just
end in the activation and then we're
going to add a drop out layer okay so
it's asking for a 50% drop out we can do
that so we'll say okay drop out we'll
add it based on what the user says it's
going to be and we're going to it's
going to we're going to input 50% later
and then we're going to say okay so now
that it's dropped out we're going to
flatten the data and so why we talk
flatten it because we're going to start
feeding in a series of fully connected
layers and why why why a series of fully
connected layers because the
convolutional layers are meant to handle
feature engineering so that means that
the image processing parts or the
filters right so we feed in a set of
images and what the convolutional layers
will do is each of them respectively is
going to create a set of filters and
these filters are going to be you know
increasingly abstract right so they're
going to start off with low-level
features and they're going to get
increasingly more abstract so they're
going to be able to detect images but
what we want to output is not an image
but we want to what it is that we want
to output is a value and that value is a
single value and that is the steering
command right it's a direction how do
you want to move this this wheel so to
do that to get a single value from these
high dimensional image tensors we have
to want we have to squash that data and
the way to do that is by applying a
series of fully connected layers okay
and so it's going to happen is each of
these fully connected layers is going to
progressively get smaller and smaller in
terms of the number of neurons they have
and you'll see what I mean here so it
says the first one should have a hundred
neurons so we'll say okay so this is a
dense which means fully connected layer
and it's activation function like all
the other layers is going to be blue and
so then what we can do is we can just
copy
and paste this will say one two three so
there's going to be four of them in
total each of them is going to be
smaller so 100 neurons 50 neurons 10
neurons and then just a single neuron
and this one won't have an activation
function because it's the last layer and
that's going to output our driving value
our steering down and say okay so it's a
summary so all of those some are all
those values to get the summary and in
return the model okay and so then we'll
say how much we have here that there
there we go and then return the model
okay cool
so right so for our fully connected
layers we start off with a big layer and
then we want to get progressively
smaller and so the way to do that is by
using a model summary or but by using a
series of fully connected layers that
get smaller and smaller and one of what
that's going to do is going to squash
our data so it's going to basically be
like a triangle in terms of the number
of values in that in that and those
matrices that are being propagated
forward in our network so it's gonna be
like you know at n matrices a matrix
with ten indices and then like a matrix
C matrix with five indices and make sure
it's with two indices eventually one
single scalar value and that is our
output and that's what this is going to
do right and the line in the paper they
noted this but I didn't actually
document this they noted that it's not
sure where the image part and the end
the steering part begin and end because
it's all kind of connected right in
terms of what the what the like neural
network looks like but that's part of
the black box magic of neural networks
we don't know exactly where one feature
starts and one feature ends in terms of
where it lies in these in this
abstraction hierarchy but we know that
all as a as a whole as a sum total there
is some there there is some
connectedness right so anyway so that's
it for our model and then once we have
this model we're going to train the
model and so let me talk about this last
training function so for the training
function we're going to say okay take
the model and then the the training data
and the validation data to model and
data and train it right so to do this
we're going to run the model checkpoint
function and what this does is
it saves our model at a in a check point
that we bear that we that we say that we
want and it's gonna be modeled h5 and
then we're going to say well what is the
loss function that we want to monitor
which we're going to call the validation
loss not yet but we're going to call it
that and we only want to save the best
model okay
and then we're going to say the mode is
going to be auto and auto mode the
direction is automatically inferred from
the name of the monitored quantity okay
so that's it for our checkpoint and then
we want to compile our model so what are
we going to do here we're going to say
okay what is our last function going to
be well there's several log functions
that we can use and we're going to do a
really simple one called mean squared
error what does that mean so our model
is going to output a predicted a
steering angle and then we have an
actual steering angle from with a human
driver given those camera angles and
then we want to find a difference
between those angles and do that for all
of the data points that we have okay and
then sum up the differences and then
hold on we want to find the difference
square the difference add up all the
differences and then divide by the
number of them and that's going to be
the mean squared error the sum of the
squared errors okay or the mean of the
squared errors right and so then we're
going to use the atom optimizer which is
gradient descent yeah and so that's how
we compile our model and then we're
going to generate some data so what
we're doing here is we're running the
fit generator okay and so what the fit
generator does is it lets you do
real-time data augmentation on images on
the CPU in parallel to training our
model on the GPU what do we mean by that
well we are generating batches of data
okay while we are generating those
batches of data from from our training
data like the the buckets or the
containers from which we train our model
in from the from the huge set at the
same time where after we're training our
model right so what this fit generator
function does is it does both
simultaneously okay so it's super
valuable and then cool okay so then we
can train this model right which will
run Python models up high and it will
start raining on our driving they'll
start training on our drive
and we want to then once it's training
what's done training we're going to
write our testing scripts so training
can take a while it depends on whether
you're using it on the CPU or the GPU if
you're running on the cloud or on your
local machine but training can take a
while and we can definitely speed it up
by running it on the GPU I ran this
thing on my macbook and it took about
eight hours to train so yeah it all
depends on what kind of specification
you have right
so once we've so assume that we've
trained it it's going to take hours an
hour to train so we're not going to
train it right now but assume we've
trained it then we can write our testing
script okay so let's go to our testing
code let's check this out so let's just
let's check out our testing code so for
our testing code remember is a server
client model that's what you think we're
using a server client model and that
means that the that the simulator is the
server and then our clients is then the
script that we're writing so we want to
think of it like a think of it like a
server client models we're going to use
flask to do this the web app framework
so let me talk about these dependencies
and then we'll talk about the code so
the first thing we want to do is define
our command line arguments a 64 is going
to help us the code camera images
daytime 4 for timestamps of what else
we've got
high-level file operations socket IO is
going to help us work with this as a
real time server in terms of typing
commands through event handlers we're
going to use event lit for concurrent
networking and then we have more web
framework dependencies and then image
manipulation with pillo flask is our web
framework and then bio to deal with
input/output and of course chaos just to
load our model and our helpful class
okay so we'll start off by initializing
our server ok it's going to be a socket
IO server and it's going to use flask to
do this and we'll initialize our model
and image rate as empty because we're
going to fill those as we later on and
then we're going to set a Max and min
speed for our autonomous car so it can't
go faster than 25 miles an hour and it
can't go less than 10 miles an hour and
then it's we're going to define a speed
limit as well what you're going to be at
max speed ok so then let me skip this
function because we're going to write it
and let me talk about that the other
functions so let's go into this main
function so these are the command line
arguments that define you know what
we're
the model and where are the images that
we want to wear the images from the run
are going to be saved so we'll load the
model using our load function and then
we will tell it via command line where
that model is and it's going to create
an image folder and then it can either
record the run or not depending on how
we what we say and then it's going to
launch this flat middleware which is
going to let our client communicate with
the server and then we're going to
deploy it as a WSGI server right and
that acronym what was it again it was
WSGI let me brush up on my web my web
stuff here WSGI it's not crud create
read update web server gateway interface
right we have 101 acronyms okay so what
these functions are are these are event
handlers and this is why we're using
socket IO in the server because behind
under the hood for the stimulator it's
got the it's got the architecture
necessary to send commands that we need
we just need to create event handler
student accept those commands right so
we don't have to code the server part we
just have to code the client part so
this is really the easiest way to get
started with building a self-driving car
this simulator that Udacity release is
the easiest way
obviously there's Brent depth Auto which
is awesome and stuff but you can only
want that to appear on Windows and then
also you know there it's got a whole
bunch of extra features that we don't
necessarily need but yeah we could also
do it in Grand Theft Auto but right now
this would be easiest if you're looking
for the easiest way to get started with
building self-driving cars this is the
way okay so so we have event handlers
for Connect which is going to just send
it the s ID the session ID and then we
gotta send control which is going to
send the actual commands that our model
emits but then we have the telemetry
function and so that is going to be the
that's going to be the big the meet of
our code and that's what we're going to
write out here okay so we're going to
write out this part right here so we're
going to say okay so what this does is
it's going to make the prediction and
then send it it's going to make the
prediction of what the steering angle is
going to be and then we're going to send
it to the server okay so let's go ahead
and write this out so if data so we're
going to feed this in our data and then
we're going to create an if statement
says if data so once
got our data as our as our focus we're
going to say let's get the current angle
of the car so we'll say the steering
angle we want the steering angle of the
car okay so that's the first variable
that we want and it's going we're going
to retrieve it from our data data frame
okay and then we want the throttle okay
so remember we want these variables want
these values so that we can manipulate
them and turn them into one single
scalar value that will tell our car
where to go and then we want the speed
and the speed is going to be a float
it's gonna be a float value and just
like the rest it's going we're going to
pull it from this data frame using the B
key which is going to speed human
readable key and then we're going to get
the current image from the center of the
camera from the center camera of the car
using pillow right so is the image open
so and then we'll use this work lights
IO comes into play it's what we use it
because we want to convert it from
basics before this image into what we
can read directly into our model so say
864 decode data and then image okay and
so then we'll say okay so once we have
those things we'll go ahead and and do
some tensor processing on this image so
we need to feed this image into our
network right so to do that to do that
we're going to say image
let's see what else we need here image
and then so we're going to convert it
the image to an array and then we're
going to apply the pre-processing step
to it and then the model is going to
expect a 4d array so that's what that's
what this image is going to be and so
once we have that then we can say then
we can say a predictive steering angle
for the car given that image so we're
going to say okay so let's predict the
steering angle using our model let's say
model that predicts just one line given
the image and the batch size would share
which is whatever it's going to be also
say one for the simple example and then
once we have that we're going to say
okay so then given the speed limit that
global value that we initialized it's
greater than if the speed of the car is
greater than what we set as our speed
limit then change it say okay well the
new speed limit is going to be the min
speed so then that means slowdown right
so else if it's not then well then we
can say the speed limit is going to be
the max speed right so we don't want it
to go faster than the speed limit is
what we're saying here and once we've
done that then we can say okay the
throttle is going to be 1.0 - the
steering angle so this is a magic number
territory this is where guessing and
checking comes in but we'll say - speed
over speed limits times two tours
squared okay and then we can spend the
control using that helper function that
we defined before using the steering
angle and throttle cool that's it for
this code right so that's it we properly
pre process the image and then we fed it
into our model and that is outputs the
the steering angle and then we can use
that to then send that control directly
to the server via the send control
function okay and it's going to admit
that as a as a as a packet to the server
and then the server will read that in so
the actual event the event handling
logic is is written by the is under the
hood for the simulator and we can just
send it via our client that's it okay so
then once we have that then we can
compile it and it's going to run the
script just like I did right at the
beginning all right so to end this I'm
going to answer three questions randomly
from the YouTube
comment and then we're out of here okay
so the first question is let's see what
kind of questions we got here how to
work with multiple data sets this is a
great question and it's worthy of a
video but essentially there are several
ways of thinking about this one way is
you can just combine all your data sets
into one big data set using pandas and
that's what I would do that's probably
the best way that's the cleanest way but
another way you can do it is think about
it serially so you'll once you train
your model on one data set and then
train your model in the next data set
but I would I would just combine all
your data sets into one two more
questions I'm going to read from the
comments what else we got here how can I
discover a foreign language like Russian
you tell me so this is for the language
translation video so discovering a
language is quite a challenging task but
think of it has associations so as long
as you have some kind of labels and the
labels could be a different language but
maybe you're trying to discover an
ancient language or discover the rules
of some language you don't know then as
long as you have some kind of
associations you can treat it as a
supervised learning problem okay and
I've got two language translation videos
and links to those in the description of
that video and one more question once
you have this neural net trained can be
optimized to run locally or does it have
to be run as is every time yeah you can
react amaizing network you can use the
pre trained model or you can use your
code you can retrain it again it all
depends you can retrain on your data or
you can use it or you can use a pre
trained model of someone else's train
that's it for this session please
subscribe for more programming videos
then for now I've got to go clean my
kitchen oh thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>