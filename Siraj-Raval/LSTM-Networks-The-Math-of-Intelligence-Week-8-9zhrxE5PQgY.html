<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>LSTM Networks - The Math of Intelligence (Week 8) | Coder Coacher - Coaching Coders</title><meta content="LSTM Networks - The Math of Intelligence (Week 8) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>LSTM Networks - The Math of Intelligence (Week 8)</b></h2><h5 class="post__date">2017-08-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9zhrxE5PQgY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world is Suraj and our task today
is to build a recurrent Network a type
of recurrent network called an LS TM or
a long short-term memory network to
generate Eminem lyrics that's our task
and we're going to build this without
using any libraries just numpy which is
for matrix math because we want to learn
about the math behind LS TM networks
we've talked about recurrent networks
earlier on in the series and LS TMS are
the next logical step in that
progression of neural network learnings
so that's what we're going to do today
and we're going to first talk about
recurrent networks we're going to do a
little refresher on what recurrent
networks are how we can improve them and
then we'll talk about LS TM networks and
how they are improvements and the
mathematics behind them then we'll build
all of this build ads and we're going to
look we're going to I'm going to explain
the code because there's quite a lot of
code to go over here there's a lot of
code but we're going to look at all the
code and then I'm going to code out
manually the forward propagation parts
for both the greater recurrent Network
and then the LF TM cell itself so
strapped on with every math hat you have
because this is going to be so hard we
might as well just give up let's just
forget this no no I'm just kidding no
this is actually going to be this is
going to be pretty easy it's going to be
pretty easy if you got the recurrent
that video this is going to be pretty
easy stuff although it's a little more
complicated but you will get this okay
get ready for this I'm going to make
sure you get this okay so here we go
what is recurrent Network can you tell
me what a recurrent Network is in one
sentence I'll give you 10 seconds go
okay that's all the time you get I'm not
gonna wait a full 10 seconds for current
networks are cool they're useful for
learning sequential data we know this we
know this they're useful for learning
sequential data a series of video frames
text music anything that is a sequence
of data that's where recurrent networks
do really well that's what they're made
for
they're very simple you have your input
your input data and then you have your
hidden state and then you have an output
and so the difference between recurrent
Nets
feed-forward nets are that recurrent
Nets have something different here so in
a normal feed forward in that we would
have our input or a hidden layer and
then our output layer and that's it and
then we would have two weight matrices
between each of these layers that are
those are matrices right that we
multiply right input times weight add a
bias activate hopefully you said
activate because that is a wrap /
mnemonic device but input times way add
a bias activate repeat over and over for
feed-forward Network the difference
though for recurrent networks is that we
had another weight matrix and this other
weight matrix called synapse H in this
diagram connects the hidden States back
to itself so just a third weight matrix
and what if the reason we add that is so
whenever we whenever we are training our
network we're not just feeding in new
data points so if the data is always
we're trying to train a recurrent net to
remember the next to learn to predict
the next number in a series whether and
the series is 1 through 10 right we want
to predict the 10 we would say ok 1 2 3
4 5 6 7 8 9 10 we wouldn't just give it
the numbers we would also feed in the
hidden state right so we would say okay
so given a 1 predict the two okay now
given the 1 to predict the 3 okay given
the 1 2 &amp;amp; 3 predict the 4 and that's how
we would try in every iteration but
that's not all we would give it we
wouldn't just give it the input data we
would also give it the hidden state we
would give it both and so that's why we
have a recurrent matrix that's
connecting the hidden state to itself
because we are not just giving it giving
it every new data point the ones and the
twos and threes we're also giving it the
hidden state which is basically a which
is a matrix and we're multiplying it by
the hidden state and the new input data
where we are feeding in the hidden state
and the input data at every time step
and so that's why we have a hidden
matrix and so you could think of this as
unrolled as this a series of people or
networks right or we give it in an input
data points and then we get a hidden
state and then in the next time step we
don't just give it this new data point
x1 but we also give it the hit
they from the previous time step so we
just continue to do that set that's one
way of looking at a recurrent Network as
just a big chain of B for networks of
chain right a block chain no not block
chain although I did want to talk about
block chain it's coming don't worry I'm
coming for you block chain but not yet
we're still talking about recurrent
networks amazing stuff amazing stuff
block chains coming though oh I don't
want to give away too much I just did
anyway ok you guys can tell I'm very
excited about block chain anyway so we
give it the hidden state and the input
at every time step and we just keep
repeating that and that is a recurring
network but there is a problem here the
problem is that there are 99 of these
problems and no I'm just kidding the
problem is that one whenever okay so
here's the problem the problem is
actually really interesting it's called
the vanishing gradient problem okay so
it's called a vanishing gradient problem
so let's say you're like what is this so
let's say we we are trying to predict
the next word in a sequence of texts
which is actually what we are trying to
do right now duh but let's say that's
what we're trying to do and let's say
we're trying to predict the last word in
this sentence the grass is green right
so all we're given so we know that the
word is you know green but let's say
we're trying to predict it so all we're
giving is given it the grass is and
we're trying to predict that last word
we're current networks can do this right
they can easily do this because the
distance between what the word we're
trying to predict the distance between
that data point in the sequence and the
previous data points is pretty small
right the difference the distance
between grass which is the context we
need and green it's pretty small the
only difference is that the word is is
between those two words and so that's
easy to predict because that's the only
context that we need let's say it has
some sentences before that said you know
the lawn is rain or the grass is let's
say you already said the grass is
greener this is already like the
previous sentence but so we've already
made that that distinct connection
between grass and green and you know
those two things are related so of
course it's very easy to do that but but
let's also say and you but let's also
say that we want to predict the next
word in this sentence so let's say we
have a huge
paragraph look not even a parent let's
say we have a 30 page essay and the
beginning of the essay it is a first
person essay and it is about a guy named
Jean okay it's French dude he's got a
moustache unnecessary detail but a guy
named Jean and it starts off with I am
French as it should be I am French and
then there's 2000 plus other words and
we're trying to predict the last
sentence the last word after 2,000 words
and that is the word French I speak
fluent what and let's say between I am
French and I see fluent French there's
all these other languages like and so
this guy is Spanish and I heard some
German on the subway and all of that is
actually irrelevant to what he speaks
fluently which is French we've got to
know that context we got to know that he
is French so of course he's going to
speak fluent French so you've got to
find a way for our network to be able to
remember long term dependencies and so
the whole idea behind recurrent networks
the whole reason that we feed in the
hidden state from the previous time step
for every new iteration so that we can
have a form of neural memory right
that's why we don't just feed in the the
previous input but we feed it in the
previous hidden state because the hidden
state is that matrix that represents the
learnings at the learnings of the
network so that we can give it a form of
memory like what is remember before and
the new data points but the problem and
you would think ok so that's all you
need right of course the hidden state is
going to be updated more and more and
the whole idea of recurrence is made so
that we have a form of neural memory for
sequences specifically but the problem
is that whenever we are back propagating
the gradient tends to vanish so it's
called a vanishing gradient problem so
let me close so whenever we're forward
propagating we have our input data right
and we are trying to predict the next
word or character or musical note in the
sequence and so what we do is we say
input times wait a Tobias activate
repeat over and over and then you know
recurring over and over and over again
and you get the output which is the
prediction
the prediction is the next word or
whatever and so once you have that
prediction value then you're going to
say okay doctor I'd the prediction into
a number and say prediction minus the
expected be the expected output which is
the actual label or next word or
character because we know it and because
it's a supervised and so then we have
the error value or loss value and then
we use that error value to compute the
partial derivative with respect to our
weights going backwards in our network
recursively work performing gradient
descent or in the context of neural
networks back propagation because we are
back propagating an error gradient
across every layer but what happens is
that as the gradient remember this is a
chain of operations the chain rule what
happens is as we are as we are
propagating this gradient value
backwards across every layer or
computing the partial derivative with
respect to the error or the partial
derivative of the error with respect to
our weight as we are doing that for
every layer recursively the gradient
value gets smaller and smaller and
smaller for the reason for linear
algebraic reasons the gradient the
gradient just gets smaller and smaller
and smaller and so what this means is
that the magnitude of the whole point of
that propagation of gradient descent is
to improve our weight values such that
our expected output is closer to such
that our actions so that our predicted
output is closer to our expected output
right we're trying to minimize the error
value and so the whole point of gradient
descent is to give our weight values a
direction in which to update such that
the error is going to be minimized
through a forward pass and so by
direction I'm talking about what what
values in this weight matrix the set of
numbers is optimal such that if we were
to multiply this by the input and then
you know do that over and over again
it's going to give us the right output
value and so that's the whole reason
we're computing partial derivatives or
gradients which we also call them
because calculus is a study of change
right chain
whether it be in moving bodies or change
in terms of how to update a set of
values and when I say direction it
doesn't mean like a literal direction
like up-down left-right it means a
direction in that the numbers are closer
to the ideal optimal numbers that they
should be in the weight matrix so when
we multiply the input by them the output
is going to be closer to the actual
output that we want I probably repeated
that several times but you know it's
good it's good it's good for us and so
so that's that's the whole point of
performing gradient descent aka back
propagation and so the gradient gets
smaller and so what it means is that the
magnitude of change in the first layers
of the network is going to be smaller
than the magnitude of change in the
tail-end of the network the last layers
right so the last layers are going to be
more affected by the change but the the
first layers are going to be not as
effective because the gradient update is
smaller because because the gradient
itself is smaller and so right and there
are two factors that affect the
magnitude of these gradients the weights
and the activation functions and a P of
these factors is smaller than one the
brain is made vanish in time if larger
than one and exploding might happen so
that's called the exploding gradient
problem the gray itself is too big so it
can go either direction usually it's
vanishing gradient but yeah this is a
problem right we want to somehow
maintain that gradient value as we are
back propagating we want to maintain
that error gradient value so that it is
at the full magnitude that it should be
to update our weight values for every
layer recursively in the correct wig we
want to maintain that gradient value we
want to remember that gradient value as
we back propagate and so how do we
remember a gradient value how do we
remember remember is a word you know
maintain remember you know whatever you
want to call it and so the solution for
this it's called using an L FTM cell or
a long short term memory cell and if you
think about it the knowledge of our
recurrent network it's pretty chaotic
let's say we're trying to you know
caption a video a set of
frames a video right and it's he's a guy
and he's eating a burger and the Statue
of Liberty is behind them so then there
were the network things okay
he must be in the United States but then
he's eating sushi and it thinks oh he
must be in Japan just because it's
seeing sushi but it forgot that he was
just behind the Statue of Liberty there
exist sushi sushi places in New York
City - right and then you know he's
writing a boat and he thinks oh he must
be in you know the Odyssey or something
but he's still in New York
so we need the information to update
less chaotically to account for all the
learnings the memories that it's learned
over a vast period of time a vast
sequence to be more accurate and so the
solution for this is called the LST M
cell and it replaces the RN n cell and
so the RN n cell is input times wait a
Tobias activates right and with that
weight matrix that is connecting to
itself and so the difference is an LST M
cell basically just you just replace it
with in lsdm cell you just take that out
and you replace it with an Alice key M
cell and what it is it is a more
complicated or more extensive series of
matrix operations so let me let me talk
about what is it okay let me let me give
this go so LS t M cells consist of three
gates you've got an input gate right
here give your output gate right here
your your projected right here and then
you have a cell state now you also see
this input modulation gates so that's
actually only you sometimes but let's
just forget about that that's let's just
forget that exists you have an input
gates an output gate and a forget gate
and so there's many there are many
variants of LST ends and that's why you
see this input modulation gate but the
most used ones are just input/output
forget and cell states so just forget
about the input modulation gate for now
okay so you've got three gates values
and then we have a cell fate so you
might be thinking okay so what are these
gates like like what what is a gate and
so a gate is just like a layer a gate is
a series of matrix operations and it is
input times weight out of bias active
so in a way you could think of an LST
emcell it's kind of like am a neural
network these gays all have weight
themselves so they all have their own
set of weight matrices that means that
an LST M cell is fully differentiable
that means that we can compute the
derivative of each of these components
or days which means that we can update
them over time we can learn we can have
them learn over time and so so these are
the equations for each of these right so
far forget gate or info gate or an
applique its input times weight added
buys activate where the input consists
of the input and the hidden state from
the previous time step so in each of
these ways these gates have their own
set of weight values and so what we want
is we want a way for our model to know
what to forget and what to remember and
what to pay attention to in what it's
learned right what is the relevant and
that's all the attention mechanism what
is the relevant data everything that
it's learned what is the relevant part
of what it's being fed and this time
step to remember and what should forget
the cell States is the long term memory
it represents what all of the learnings
across all of time the hidden state is
akin to working memory so it's kind of
like a current memory the forget days
also called the remember vector learns
what to forget and what to remember
right one or zero binary outcome the
info gate determines how much the input
to let into the cell state also called a
save vector what to save and what not to
and the output gate is akin to an
attention mechanism what part of that
data should it focus on and so you might
be thinking well how is like I see you
might be thinking like okay so I see
these equations
I see how like input times wait a device
activate is akin to forgetting an input
and output I see how there's an ordering
to this right we have we have an
ordering to this we first you know go
through an input we learn with the we
learn what to forget and
you compute that cell state and then we
and then we send it to the output
ultimate but and then ultimately we
compute the cell and the hidden state
and these are the two key value that we
output so you might see these and you
might think okay like I see the ordering
I see how they represent for getting and
remembering but I don't like make the
connection between still like how it
knows what to forget and what to
remember and that's again that's the
amazing thing about neural networks like
these these gates are essentially
perceptrons they're like many networks
right with with a single node the node
is the gate itself right it's a single
node with a single activation function
all of these dates are perceptrons
they're like many neural network like
single layer neural networks and it
learns what to forget what to remember
uh based on gradient descent again it's
the magic of gradient descent it learns
what is necessary over time and so these
these components represent mechanisms
for forgetting remembering and what to
pay attention to or attention and so
that's what the L etting provides us so
instead of so this equation would be for
a normal recurrent network so you would
have your input times your weights plus
the hidden state times its own hidden
state the hidden state matrix you'd
activate that and that would give you
the hidden state at the current time
step the difference is that it would
look like this instead it's a more
extensive series of operations right so
that's what it is and yeah and so yeah
so that's kind of the high level of how
that works and now we're going to look
at it in code as well which is going to
help you know your retention but what
are some use cases of this like I said
it's all sorts of sequential data any
kind of text any kind of sequence data
it's going to it's going to be able to
learn what the next values in that
sequence are which means it will be able
to both it generates and discriminate
that type of data that you've trained it
on right in this case it's hand it's
characters that I can draw it can draw
so
this is very popular in NLP Andre
karpati the famous AI researcher he has
a great blog post on this the
unreasonable effectiveness of her
current networks I assume you've read
that if not check it out I'll also link
to it probably I'll link to it in the
description and so it's used for
translation and sentiment analysis and
all sorts of NLP tasks it's also used
for image classification like if you
think of a picture as a sequence where
each pixel is a sequence predict the
next sequence so there's a lot of
different ways that we can frame our our
problem and you know Ellis hands can be
applied to almost any problem very
useful and so what are some other great
examples where I've got two one is for
automatic speech recognition with
tensorflow so yes it's a little
extracted with tensorflow but it's a
really cool use case and definitely
coming to check out so check out that
demo and then also this this repository
which is just a visualization of Alice
TM which is going to definitely help
with your understanding to check out
this visualization very cool very cool
demo it's in JavaScript I think yes in
JavaScript no it's in Python great so
yeah so there's that definitely check
that out and so our steps are going to
be to look at the recurrent Network
class so we'll have a recurrent Network
class plain old recurrent Network and
we're going to use an LS PM cell instead
so we're going to replace it and then
we'll build that LS TM class and then
our data loading functions for our text
and then we'll train our model okay so
what is this right here this just jumble
of numbers with no explanation
this represents the forward pass the
series of matrix operations that we were
computing to get our output our
predicted output okay so and we'll look
at this in code so okay so our recurrent
neural network is going to remember so
what we're going to do is give in our mm
text we're going to predict the input
the next word in the sequence given the
previous words so what that means is the
input is going to be all of those words
that we have just every word and our
output will be the same thing but just
moved over one that means that you know
it'll look like this like you know
during training we have a series of you
know
iterations right so we'll say you know
like let's say you know my name is slim
shadey would be like the text so we
would say my and we were trying to
predict name okay we've got that compute
the error back propagated next iteration
weights are updated my name and now
we're going to try to predict is right
and so then we say try to predict is we
have a actual output we have a predicted
output compute the error back propagate
repeat my name is I'm trying to predict
slim you see what I'm saying so we just
keep doing that and so that's why it's
moved over by one so our inputs and our
outputs are going to be our words we
have the number of recurrences that we
want to do which is the number of words
total right because we're going to we're
going to we're going to perform
recurrence in our network for as many
times as necessary until we get a rate
through all those words up until we get
to that predicted word that we need to
be at and then we have an array of
expected outputs and then we have our
learning rate which is our tuning knob
or you know too low and it's never going
to converge to high and it will converge
it will overshoot and so we will never
converge as well so that's where our
learning rate is so now let's look at
this so we're going to do a bunch of
initialization so remember the
difference between LS TM and Plano recur
nets are that we have more parameters
those gate values and we have new
operations for those parameter values so
we're going to initialize all of those
right at the beginning and look you
might look at it and think well this is
very complicated and difficult but
remember with tensorflow
with care off you can you can do this in
ten lines of code 20 30 40 lines of code
we're looking at the at the details here
that's why it looks so long okay so
that's why it looks so long so now let's
look at this so we're going to
initialize our first word the size of it
there our next word the size of that and
then our weight matrix this is the
weight matrix between the input and the
hidden state which we're going to
initialize randomly of the size of our
predicted output we'll initialize this
variable G that's going to use for our
MS
which is a technique for gradient
descent that decays the learning rates
I'll talk about why we're using g8 later
on we're not ready for that right now
but then we're going to compete we're
going to say when it relies the length
of the recurrent network right that's
the number of words that we have the
number of occurrences our learning rates
these are all parameters and now we're
going to have arrays for storing or
input that every time step an array for
storing our cell states on a ray for
storing our output values our hidden
States and then our date values right
our for gate values well one of them is
actually a cell state these are lsdm
values so before that these were the
network the recurrent Network values and
now these are the lsdm cell values and
then we have our array of expected
output values and finally we have our LF
p.m. cell which we initialize right here
giving it our inputs or outputs the
amount of occurrence and the learning
rate just like we did for the recurrent
Network remember it's like a mini
network it's like a network in a network
and if you think of the gates as
networks and it's a network in a network
inside of a network or no it's three
networks inside of a network inside of a
network okay so yeah talk about
inception inception recurrence inception
so back to this those are our
initializations
and now we have our sigmoid which is our
activation function it's a simple
non-linearity right and then we have our
derivative of the sigmoid function which
is used to compute gradients that's why
we have the derivative right we'll talk
about that in back propagation and then
we have forward propagation which is our
series of matrix operations which I'm
going to code okay so for forward
propagation we're going to do this in a
loop right because if they're recurrent
network for the number of loops that we
want right so we're going to say okay so
for the number of loops that we want
that we defined in our L we're going to
set the input for the lsdm cell that's
input for the LCM cell which is a
combination of inputs so we'll set which
we can do with the H step
of numpy and we'll say I minus 1 or I
minus 1 and then the CELTA x LS cm x
equals NP South Dakota and so this is so
this is how we set inputs with the LCM
sell-by is a combination of inputs from
the previous output and the previous
hayden States right here right so that's
that's that's us initializing our lsdm
cell and now we can run forward
propagation through the LS TM cell
itself so it's going to return our cell
States our hidden States our forget
gates or so we can you know sort in our
array of values see which is the cell
States and then the output and so we can
compute that using the forward prop
function of the lsdm cell and so then
we're going to say let's store the
computed cell state right so then we've
got all these values and now we can
store them locally in this in this
recurrent networks memory these are all
values that were computed from the
forward propagation of the lsdm cell and
so we can just you know set the hidden
state we've got our what else we have we
have our forget gates of course the
forget gate is going to be set as well
these are all values that we computed in
our forward propagation States we have
our input gates which we're going to
stuff like that we have our cell States
and then we have our output gate where
these are all values we compute there
now we can calculate the output by
multiplying the hidden states with the
weight matrix so you know input times
weight a device activates so we'll say
okay we'll compute that output by saying
self dot sigmoids will use a sigmoid
function to activate the weight times
the input input times weight how to bias
activate right yep and then we'll set
our inputs because we've computed an
output we want to set our input to the
next word in the sequence right because
we're going to we're going to keep going
and then when we're done with that we
can return the output prediction right
so that's forward propagation that's
forward propagation now for backward
propagation we're going to look at this
so we're going to update our weight
matrices that's that's what that's the
point of back propagation to update our
weight matrices our learnings so we
computed a predicted next word and we
have our actual next word and we
represent these words as numbers as
vectors so we can compute the difference
between words like how do you compute
the difference between words
well you convert them to numbers or
vectors then we can compute the
difference to get the error value so
we'll initialize the error of zero and
then we'll initialize two empty
arrays to empty vectors for the cell
state in the hidden state remember the
cell state in the hidden state were
those two values right here which
ultimately these forget input output
gates are used to help compute the value
of right
notice how forget input and output are
used here the forget gate is multiplied
by the working memory State and then we
add the input gate which is multiplied
by the working memory state as well to
remember what to forget to to learn what
the
get and what to remember and that's
what's stored in our self state the
learnings of the forget and the input
gates and we then we then activates the
cell state and multiply it by the output
to get our hidden state and so if our
outer level where the weight matrix
between the input and the hidden states
we have our hidden state itself and in
the cell state and those are the key
like outer level parameters and then our
inner level parameters are those lsdm
level gradients right so we want the
gradient values for our forget gate or
input gate or sell yourself unit or
state and then our output gate the
internal ones and so we're going to fill
these out so we're going to loop
backwards or back propagate through time
through our recurrence so we're going to
say we have our calculated output let's
compute the error between that and the
expected output and then we're going to
say okay we're going to compute the
partial derivative is computing the
error times a derivative of the output
times the hidden state and so once we
have that then we can say ok it's time
to propagate the error back to the to
the exit of the LCM cell or the the
weight out to to the output of their
recurrent network in general so the way
we do that it's three steps we do we
compute the error times the recurrent
network weight matrix and then we set
the input values of the LLVM cell for
recurrence we set the input values of
the LCM cell for recurrence and then
finally we set the cell state of the
lsdm cell for recurrence pre like that's
pre updates and then we recursively call
this back propagation using these newly
computed values right so for our four
this is going to compute gradient
updates for our forget input cell unit
and helpful gates and the higher-level
cell state and the hidden state goes to
higher level their parameters and so
these are all of our gradients and now
we can this is just for error logging
now we can accumulate those gradient
updates by adding them to our existing
empty value that we initialize right at
the start
and then we can update our lsdm matrices
with the average of the accumulated
gradient updates and then update our
wave matrix with the average of the
accumulated gradient updates and return
the total error of this iteration and
that's back propagation in general so
then so then so notice it's update step
with this update step is is rmsprop it's
a way of decaying our learning rate over
time and this improves convergence
there's a lot of different methodologies
for improving on gradient descent
there's Adam there's rmsprop there's a
de Grasse there's a bunch of these and
rmsprop is one of them but here's the
formula I'll just put it up there okay
so that's what this is so now we will so
this sample function is the same thing
as a forward propagation function it's
just it's what we're going to use once
we've trained our model to predict or to
generate new words so the same thing
right we have our input and for a number
of words that we define will say you
know generate words or predict words for
as many iterations as we define so it's
the same thing so we can just get that
now for LST emcell so for our lsdm cell
we've given it the same parameters as we
did for our recurrent network it is
after all a mini network in and of
itself so again with the inputs the
output the amount of recurrence and the
learning rate and so what we'll do is
very similar at the start to what we did
for our recurrent Network well in it
will initialize our inputs the size of
it our output the size of it and then
our cell state is going to be empty how
often should we perform our currents
will initialize that variable our
learning rate as well and now we're
going to create weight matrices we'll
initialize these weight matrices
randomly just like we would for a any
kind of neural network will utilize the
weight matrices for our three gate
values for our forget our info gate and
our output gate as well as our cell
States so the cell state itself let me
go up here has a set of weight matrices
right just like all recurring that all
neural networks
and so the node has its own set of
weight matrices that that we multiply to
get that output value right it's a part
of a series of operations and the weight
matrix is that learning part it's the
non-static it's the dynamic part of that
equation that would essentially you can
think of these as gates using them as
layers even but they're called gates but
layers are very similar Union I'm saying
layers are very similar input times wait
a Tobias activate but we call them gates
to differentiate not to be confused with
so many terms here not to can be
confused with the actual mathematical
term differentiate but to discriminate
right okay so back to this so now where
were we
we initialize our gates we and then
we've initialize our dates and now empty
values for gradients that we're going to
compute for all of these remember all of
these gates are differentiable so that's
where these gradient values will go then
we can update them through back
propagation because we back propagate
through that the cell itself
we don't just back propagate through the
recurrent network at a high level we are
back propagating that is we are
computing great values for each of these
gates so we are updating waits for the
input forget cell state the output gate
where and the outer level weight matrix
as well for the recurrent network so our
computing grades for everything
so we're updating everything it's
learning what to forget what to remember
what to pay attention to the attention
mechanism the output and the outer level
weight matrix as well so right so then
we have our activation function sigmoid
just like before and our derivative just
like before and so what we do is we add
another activation function here this is
good practice in lsdm networks you
usually see the 10h function applied
pretty much all the time and the you
might be asking well why do we use 10 h
over other activation functions I've got
a great video on this it's called which
activation function should I use search
which activation function should I use
great video on this
and you'll you'll know it very fast
within seven minutes if you watch that
video but at high level it prevents the
vanishing gradient problem the tan age
function gives us stronger gradient
since the data is centered around zero
as opposed to the sigmoid which is not
and so we use that and then we also are
going to import the derivative function
of it because we want to compute
gradients where everything is
differentiable so just like before we'll
compute the for propagation for an L STM
cell and so remember the for propagation
for an L STM cell is drumroll please
this set of operations ultimately we
want to compute the output right we want
to compute the output so that's what
we'll do back to this so we'll say the
forget gate is going to equal the input
time of the forgetten so we're going to
activate the dot product of the forget
gates and the input input times forget
did and then activate that's going to
give us our forget gates and then we're
going to compute this the cell state
we're going to we're going to we're
going to update the cell States by
multiplying it by that for decades so it
knows what to forget and then we're
going to compute the input which is
going to be again the activated version
of the input times the previous input
the current input times the previous
input and so that's going to tell us
that and so then once we've got that
we can compute the cell state which
we're going to apply this new activation
function for the cell States to prevent
the vanishing gradient which is the self
de times the input and then we activate
ride that series of operations and then
we're going to update the cell States by
adding the input times the cell state a
cell and put times a cell and then for
our predicted outputs we're going to
take those we're going to say let's
compute the dot product between the
output gates and the cell States or know
the output eight and the inputs and
that's going to us our predicted output
and so what we can do is we can say but
no that's going to give us our output
gate and to get our actual help put our
predicted output we'll multiply our
output gate times the activated version
of our cell states and that's going to
give us our predicted output we can then
return our cell States our predicted
output for gets gates input gates cell
and then our outputs gates as well
that's forward propagation all right and
that's the equation that I showed up
there so now we've got a forward
propagation now we're going to look at
the backward propagation remember we
back propagate through the cell state as
well not just the high-level recurrent
Network so what this is is we're going
to compute these the first errors right
so that's the error plus the hidden
States derivative and we'll put those
values so it's not too big we want to
prevent the gradient from vanishing so
clipping it helps that and we'll
multiply the error by the activated cell
state to compute the output derivative
and then we'll compute the output
updates which is the output derivative
times the activated output times the
input and then we'll compute the
derivative of the cell States which is
error times output times derivative of
cell state plus the derivative cell so
we're computing derivatives of all of
these components in the backwards order
that before which means that forget the
forget date computation or update will
happen near the end instead of near the
beginning and so then we're computing
the derivative of a cell and then the
cell update the derivative of the input
the input update the derivative of the
forget the forget update so you do want
to thank for your computing gradients
and then we're updating them right and
then derivative of the cell state and
then the derivative of the hidden states
and then finally we can we can return
all of those gradients out these those
updated gradient values for the forgets
the inputs to sell the output the cell
states and the hidden state so many
different parameters that we have
computed gradients for and that
propagation is going to let us compute
all of those right recursively computing
the error with respect to our weights
for every single component we have in
that network in the reverse order that
we did forward propagation and so yeah
it's just you know it's more matrix math
than we did before it's like it's like
six or seven more steps than a recurrent
network maybe it's more like eight or
nine more steps but yeah and then our
our update step is going to just be
updating our forgets input cell and
alpha gradients and then we can update
our gates using those gradient values
and there are our gradient value x' then
that's it for our LCM cell or recurrent
Network and now we can look at our load
text and our export text function which
are not as interesting but what we do is
we load up our MN text file of lyrics
right just like that and then we compute
those unique words for for all of them
and so we have a sequence right we have
a sequence or input and an output
sequence and then we have this export
text so whenever we've sampled new words
we can write them from memory to disk
that's all and so for our program we'll
say ok so for five thousand iterations
with a learning rate of 0.001 let's load
the input in our output data and then
we'll initialize a recurrent Network
using our hyper programs that we've
initialized before and then for training
time for that given number of iterations
five thousand
say compute the predicted next word so
that's the forward propagation then
perform back propagation to update all
our weight values using our error and
then if our error and then just keep
doing them and then this this catch or
this this baton will say if our error is
small enough that it's between this
range here then we can go ahead and
sample which means predict new words
generate new words our network is
trained or error is smallest let's go
ahead and announce predict new words
without having to compute back
propagation to update our weights our
weights are already updated enough so
then we can go ahead and define a seed
word and then predict some new text by
calling that sample function which is
the for propagation that's all and then
we can write it all to disk all right so
let's run this beginning it's going to
take a while and then once it's done I
actually have a zip copy
it's spitting out some pretty dope
lyrics right these are some pretty dope
lyrics right that's it for this lesson
definitely look at this Jupiter notebook
afterwards look at those links that I
have sent you in the description as well
inside of the Jupiter notebook and make
sure that you understand why at least
why to use lsdm cells the reason is
because it's to remember long-term
dependencies that's at least a high
level that you should have got from this
video it learns what to forget what to
remember and what to pay attention to
those are the three things that an LS PM
sell as opposed to a regular recurrent
Network let's you do okay so yeah please
subscribe for more programming videos
and for now I've got to learn to forget
so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>