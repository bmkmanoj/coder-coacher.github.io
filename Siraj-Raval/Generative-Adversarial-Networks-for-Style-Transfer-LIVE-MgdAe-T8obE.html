<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Generative Adversarial Networks for Style Transfer (LIVE) | Coder Coacher - Coaching Coders</title><meta content="Generative Adversarial Networks for Style Transfer (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Generative Adversarial Networks for Style Transfer (LIVE)</b></h2><h5 class="post__date">2017-05-03</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MgdAe-T8obE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and welcome to
this live stream of my new 100k youtube
channel livestream I'm very excited for
this thank you guys for hundred K
subscribers by the way I am very happy
and we are the fastest growing
artificial intelligence community in the
world okay so today we are going to be
talking about disco Gans and the name is
pretty interesting right but it has
nothing to do with disco balls but cue
the disco mutant no I'm just kidding now
we're not going to do that we're going
to be building a model that is that
consists of six different neural
networks now so it sounds complicated
and it is but but it's going to be
really easy because I'm building a very
bare-bones version of it and it's gonna
be in tensorflow
okay and you might be asking why should
we be doing this Suraj what is the point
of this
I see purses and I see shoes uh-uh now
here's here's here's the cool thing
about this okay using disco Dan this is
a new type of generative adversarial
network I mean this paper literally just
came out last month like last month and
it's very exciting because I was just
going over this paper and trying to make
sure that I understood all the details
before I did this stream and now I've
got a good I've dropped it pretty well
so I'm excited to share with you what
I've learned so this paper came out not
last month but - two months ago but it
was called learning to discover
cross-domain relations with generative
adversarial networks okay and I'm going
to answer questions in a second let me
just explain this first but the idea
behind the paper was so the word disco
comes from discover so right it's like
disco discover cross-domain relations so
the idea was we have two different image
datasets one of them is let's say purses
and the other one is a set of let's say
shoes and what we can do using disco
gang is we can generate images from one
data set in the style of another so here
you see exactly what it can do like
here's two sets of examples the first
set of examples is saying in a fully
trained disco disco gann on these two
data sets purses and shoes given some
novel purse you can say generate this
purse in the style generate a shoe in
the style of this purr
right since this is really interesting
right
so it's style transfer essentially but
it's not like the style transfer that
we've seen before so recall that we've
we've talked about style transfer before
but it was more like you know Mona Lisa
you know starry night style transfer the
style transfer that we did before was
basic okay
basic AF it was essentially like a like
an Instagram image filter what we just
have if we consider two images to be two
matrices of pixel values and of course
you know it's got to be bad results but
you know what I'm talking about right we
have a starry night picture and then we
have some image and we just overlay that
style onto that other picture like van
Gogh or whatever it is and that's that
that was a naive approach right we why
is it naive why is it naive because
we're not we're not focusing on some
subject we're not saying like it
the Machine doesn't actually know like
this exact Mona Lisa is all we want to
transfer the style to let's just
transfer everything right
so what disco Gann does it is it is a
set is like smart or style transfer
right because what it's generating isn't
like a purse and it's kind of like
molded into a shoe no it's an actual
it's an actual shoe it looks like a shoe
it it looks like it would be something
that just wasn't generated right it
looks very realistic like a style in and
of itself and gans are really good at
this they're really good at this like
insanely good this is a cycle Gann video
right notice how we've transferred the
style of a zebra to a horse but it's not
like we're making everything black and
white we're just making the horse black
and white which is incredible it's just
incredible this technology is incredible
and it's just moving so fast so I'm
really excited to talk about this and
what I found is that it's actually very
intuitive to to understand
okay so let's and here's the other thing
so we humans we do this very well right
cross-domain relations if I have a you
know if I've got a black suit I know
that what goes well with it
the
cross domain the domain of suits what's
the cross domain relation what's the
other domain that's related to this
domain I could say you know some dope
like you know leather boots would go
well with it or something like we're
just able to do a well or like burger
and fries like this type of burger goes
well with this type of fries but can
machines do it and the answer is yes
they can because we are able to make
them do it so we can frame it as a
conditional image generation problem
right given one image purse you can
generate a new image condition on a
different data set that would be like
shoes right so we've just we've talked
about conditional probability
distribution before right probability of
x given Y rather than the probability of
X alone so that's essentially what it is
that's one way for us to frame it and in
terms of use cases games design science
engineering anytime you want any kind of
visual feedback of what you're thinking
just imagine just imagine a text or
voice interface where you say I want to
take this 3d model that I have is CAD
model and I want to apply all of these
features to it and a disk again that's
been general that's been trained on all
these different data sets will be able
to say ok here it is just like that
because it's already been trained right
so the the actual generation process
doesn't take forever it's a training
process that takes forever so there's a
lot of possibilities for pretty much any
science engineering or art especially
any field where there is some kind of
creation or discovery involved perfect
for it and games of course well any kind
of virtual world there is so much
possibility they think beyond the purse
and the shoe ok that's just the example
that we're using think big ok think big
ok and that that is that is where the
money is that's where the opportunity is
that's where that's where it's that's
where it's that's what's that that's
what I would be doing if I was doing you
know startup or whatever I would be
looking at ways of taking this
technology and applying it to real world
problems that people encounter ok so
that's the high level so let me um
answer two questions and then we'll get
started with the
okay so the first question that is going
to I'm going to answer once I pull up my
question window is just logging in this
is pretty cool let me make this bigger
the font definitely needs to be bigger
above a but we no longer support this
version of your browser that's what
happens when it happens okay so we've
got 324 people watching let me see who
is in the room why do you use
particularly tensorflow that's a great
question why do you use tensorflow
so the reason I use tensorflow and then
you're right because the authors of the
paper did this in PI torch Pi torch is
getting really cool it's getting really
used by a lot of cool people
remember that PI torch in five minutes
video that i just made Yamla kun share
that on Facebook I got like a ha I was
like oh my god yahwah kun do that guy's
so cool anyway ok cheese status so yeah
so why did I do an intention for siz in
tensorflow and I didn't want to just you
know drop PI torch on you guys all of a
sudden we get we got to stick to
tensorflow for now but I promise you
pi/2 or just coming attention flow is
great ok it's not it's not a bad it's
not a bad framework it's just you know
it's what we're used to and we want to
focus on the algorithms right now
instead of syntax so that's what I'm
going to keep using tensorflow
let me answer one more question and then
we'll get started with the code the
other question is
the other question is how do you select
oh no this is a great question what is
the best way and resource to learn
algorithms what is the best systematic
way to learn machine learning the best
resource I know it's your videos and I'm
already following them so okay those are
two separate questions the first
algorithms is the best way so I have a
great video on this it's called how to
succeed in any programming interview I
give you a great study guide to get your
data structures and algorithms skills on
point so check that out in terms of
machine learning yes my videos this
playlist I have you know several courses
on it
Udacity has several great machine
learning courses but yeah that's what I
was at Udacity my courses you know just
together great resources and if you want
really in-depth and you have the time
and you've got the you've got the
motivation to not to to to learn without
needing to be entertained whatsoever
which I need to be entertained
I just entertain myself with music and
stuff then probably the deep learning
book by Ian good fellow and Joshua Benji
oh okay uh but more than that you know I
I'm beginning to you know it's something
that I believed in my head for a while
but I've never actually said it because
it's so radical but textbooks are just
no stop stop reading textbooks it's not
about the textbooks we live in the age
of you know the internet and Twitter and
all this stuff
we don't need to we don't have to have
we don't we don't need to read books
books should read themselves to us right
right we need an easier way up is it's
just data and algorithms right learning
is just a process of data and algorithms
and we need to get it into our head and
what's a great medium for that video and
all sorts of you know very condensed you
know stuff anyway okay let's get started
with this I'm going to talk about most
of the code and I'm going to code the
parts that really matter okay so the
first part is okay the first part of
this is going to be us defining our
dependencies let me make sure the text
is big enough big like a boughs big like
a boss okay oh there's there's a one
more thing I want to talk about so how
should we structure this architecture
let's do a thought exercise for a second
right we want we have
to image datasets okay we have to image
data sets and we want to generate an
image in this style of another okay so
conditional image generation
well one naive way we can think about
this is an encoder decoder architecture
right so we have some image and we
encode it into a latent space right we
have some latent space encoding and then
we decode it again but when we decode it
we take that latent space and we
condition it on the other image data set
so that that image is the one that's
decoded is exactly like a reconstruction
of the original but it's conditioned on
that other data set that's a naive way
of doing it because what that would do
is like the original style transfer
paper it would it would just make
everything styled but it wouldn't be
that you wouldn't be that specific
transfer that we're doing right now so
that's that's the naive way it's like a
camera filter on Instagram a better way
is what if we had two encoder decoders
right one for each image data set and
they're both conditioned on each other
that would be good and now it would make
it backwards compatible but it's still
naive backwards compatible in that we
could generate us Chu in the solve a
purse and a person in style the shoe but
the dope way of doing this and that's
the one that we're going to do is doing
two encoder decoders in an adversarial
Tom context let me talk about what this
looks like but before we show I show you
the architecture let's define our
dependencies and our data sets okay so
those are some questions that I wanted
to answer and I'll answer questions
later but let's start off with this so
we first bridge the gap between Python
two and three with the future which is
totally necessary a lot of the time okay
so that's for things like the print
function whatever and then we're going
to use OS for saving files and then
numpy for matrix math matplotlib is our
handy dandy visualization library for
data or using tensor flow for machine
learning and this is a custom class
these two are custom classes for
generating data using what's called a
Gaussian mixture model which is a really
cool idea that I haven't talked about in
this course and I'm excited to talk
about that and then we have a progress
bar for for training and then we're also
going to be using the TF slim library
which I haven't also used before but
don't worry it's just it's just tension
flow just tensorflow neatly wrapped
neatly wrapped similar to chaos I'll
talk about the differences and then we
have our
this distributions class that's going to
represent batches of statistical
distributions that's going to help us
generate our data and then lastly this
graph replace method which is going to
let a function which is going to let us
to regenerate a network with replaced
tensors and I'll talk about why that's
that that is okay so those are our
dependencies and let's start defining
our hyper parameters right so what are
our hyper parameters well before we
define our hyper parameters we need to
know how many networks we're going to
use right we're going to use one two
three four five six six different
networks this is what our architecture
it looks like right here by the way just
like that so this is what our
architecture looks like okay it's kind
of confusing if you if it's your first
glance like I've been looking at this
for a while it's actually not confusing
so here's how it works we have four
generators each of these boxes is a
generator this one this one this one and
this one and then we have two
discriminators discriminator one
discriminator two okay and then what is
going on here well each of these
generators let's let's just look at
these two on top here right like right
here okay this one is an encoder and
this one is a decoder we can just think
of it that way that's that's how we're
framing these generators okay so it's an
encoder and a decoder and it's the same
for this one it's an encoder and a
decoder and then we have two
discriminators so these generators are
both encoders and decoders okay so what
am I talking about here so we'll give it
an image let's say it's this this blonde
woman and then we will encode it and so
what do I mean by encoding so when we
normally think about encoding we're
thinking about taking some image and
converting it into a latent space so
write some representation of that image
and so that's exactly what we're doing
here
but we are conditioning it when we
encode it on the separate the other
image data set so let's say we had the
blonde woman but then the other image
data set was dark haired women so this
would be a mix of the two
right what encode is going to be a mix
of the two and then when we decode we're
taking that conditioned image that's
generated and we're reconstructing the
original we're trying to best
reconstruct the original and
what happens here is then we can measure
the loss between the reconstructed image
and the original image and we'll use
that loss and feed that to the
discriminator
so the same thing is happening for this
encoder decoder pair but it's the
opposite so we so for this one it's
image let's say it's like data set 1 to
data set 2 for this one it's from data
set 2 or data set 1 as in instead of
generate a shoe from the purse it
generate a purse from a shoe so it's
like the backwards version of it it's
like vice versa you know like the
opposite we do the same exact thing but
but the opposite and what this does and
the reason we have this is so that we
can do it both ways we can generate
images in both cross hook in both
domains just as well and we feed both of
those losses to our discriminators okay
and so we have two separate
discriminators for each of them so these
are both generative networks so you
might be thinking wait a second
generators they're just they're just
going to be continuously upsampling
right well when we decode you're
normally thing about doing the opposite
of what you just did before so for an
encoder decoder with a with two
convolutional networks you would think
that for encoding with convolutional
nets you're you're down sampling and
then for the decoding you're up sampling
but in this case because they're both
generators were essentially continuously
up sampling so that is we're generating
an image right and then we're going to
continue we're going to generate again
from that image so it's just like one
big huge generator pair just
continuously generating okay and so
that's that's how that that's how that
is and we can use different thing we can
use convolutional nets for images and we
can use all sorts of things like that so
that is that and now what I want to do
is I want to talk about the data
generation part okay so let's get to the
data generation part okay so for the
data generation part I'm going to talk
about how we're going to do this okay so
the first step is the hyper parameters
so those are our models right so these
are our hyper parameters for those
models the first and I'm going to answer
questions in five minutes so the first
set of hyper parameters standard hyper
parameters and they apply to our
generators and our discriminators these
are general use cases right because
we're going to have some weight sharing
happening between these models some of
these some of these models like the two
first generators share weights and what
this does is just a lot it just improves
the cross-domain generation so then we
have discriminator you know hyper
parameters and then generator hyper
parameters and then I have this
inference network so the reason we call
it an inference network is just a
generator it's just a generator but
we're calling it an inference Network
just for like having that difference so
we don't get confused right so we could
just call it generator again but we want
to call it something different just so
we don't get super confused because
there are a lot of terms right
encoder/decoder generator adversary
discriminator so there's like a lot of
terms but it's - Chu - generator pairs
like general generator generator
generator - discriminators that's it
okay
so these are our hyper parameters and
these are the high parameters that were
implemented in the original paper okay
so then the next step is first to save
our results to our folder our disco game
folder or whenever whenever we're done
so we'll create a directory for that
okay so then how are we going to
generate this data are we going to use
images no we're going to use a more
simple data set because it's yeah and
I'll show you the results from the image
generation and stuff but for this you
know just to get a rocking of the
architecture we're going to do some
really simple data sets and that's what
we're going to generate it okay let me
show you what it looks like when we
generate it but we're going to do
something called a Gaussian mixture
model to generate this data okay so one
what we're going to do is to jet is
we're going to generate data using a
Gaussian mixture model okay and these
there are two data sets right there are
two data sets there's the red data set
and there's the green data set and we
want to generate that using Gaussian
mixture model so what is this what is a
Gaussian mixture model well recall that
Gaussian is it is the bell curve right
it's a distribution between two numbers
it's a distribution in two in an
interval pair a mixture model uses
several gaussians
okay uses several Gaussian to generate
data and some of that data might be it
uses those distributions several
distributions to generate data and why
do we use God
- mixture models and so like this this
data right here was generated using a
Gaussian mixture model and we saved it
from a previous training session this is
what our data set will look like and
then what we want to do is we can
consider these two different domains and
we want to find the intersection so
whenever we're going to generate new
images that are intersected between
these two domains so where would they be
they would end up being like right here
so here's what it would look like once
we're done with this test data set it
would look like this just pull up this
PDF you see these red values these red
values that's what we're going to
generate and what this shows is it is a
proof is it proof that we can generate
new images that are cross domain that is
they apply to both different both data
sets and then we literally just replace
the data sets with something more
interesting and we can do all sorts of
cool things but let's focus on the
architecture right now okay so yeah so
the weight that's that's how we generate
this using Gaussian mixture model and
you might be wondering well is there
another way for us to generate this
without using Gaussian mixture models
sure you could just use a you know a
gaussian alone
but what this does is it's it's better
for clustering it's better for finding
relationships between the two data
points if we're using a mixture model
there's already an inherent relationship
between the two data points and what
this does is it it gives us some ground
truth from which we can generate data
from okay so this is the formula for a
gaussian mixture model and here's what
it looks like we say the probability of
x that is some data set of elements what
we're going to generate depends on these
three variables right here the mean okay
the the mixing weight and then the
t-wolves this one alpha which is the
church no so the variance the I wrote
these down so this is going to be the
variance the mixing weight and then and
then this the Sigma which is the density
function that's what it is okay
so this okay so what we say is we say
and we're going to write this top
programmatically what we say is Sigma
notation for K we're
kay is a number of elements in our data
set we first apply this alpha this alpha
value which is which is a mixing weight
which we can decide beforehand and then
this end looking thing means the
Gaussian distribution so it's a Gaussian
distribution of X which is the our data
set of elements given our mean and our
variance okay or the square of our
variance and so we need these three
values and meaning the barians and the
mixing weights to be able to generate
data points in this distribution okay so
that's what we're going to we're going
to do here but let me first answer some
questions here okay so how to determine
the number of hidden layers required for
a particular deep neural net question
okay so that's a great question how to
determine the number of layers in a deep
net the way we do that is by looking at
what has been done before in papers and
then reimplemented that because hyper
parameter optimization is still a field
of discovery we need more algorithms to
learn how to learn hyper parameters
right one way to do this manually is to
just have the same model and each model
has different set of hyper parameters
and we run them on the same data set and
see which one works best right in
parallel distributed training right and
then see what which one works best and
that's essentially what a lot of machine
learning is it's just like different
people trying out different sets of
hyper parameters and there's not like
one true way of doing it right it's use
case dependent and I think and it
definitely needs to be better right it
needs to be more efficient it needs to
be something that we learn to learn and
that's actually you know I'm my video is
coming out on this so it's literally in
a few days which is really cool and then
two more questions
looks like I lost my connection here so
it's saying well but I saved these two
older questions so can we use tensorflow
for research you can absolutely I mean a
lot of great researchers use tensorflow
for research and it's uh it's been used
a lot but although pi torch is being
used a lot more now for research by
serious researchers so cool so that's it
for the questions let me get back to the
code okay so for the Gaussian mixture
model we're going to we're so we're so
good right guys where's a lot of hungry
brain so let's go ahead and do this so
the first step is for us to generate our
intervals right so defining our
intervals that we're going to generate
this Gaussian mixture model from so each
of these sets of intervals is a is we
can consider them components right we
call them components all right so from 0
to 0 from 2 to 2 from negative 1 to
negative 1 from 1 to 91 right so when we
define that using the lambda or
anonymous function given X so we say we
want to create a numpy array from these
intervals okay and then we're going to
store that in means so that's our set up
means we convert that to a list and it's
just and why do we convert it to a list
because we can perform a lot of
interesting operations with the list a
list is a great data type in in Python
and then we say well here's going to
here's our standard deviation that we
define we want it to be point point 1
and then our variances or we're going to
say so the so the I function of numpy
returns an identity matrix which is a 2d
array with with ones on the diagonal and
then 0 everywhere else and so why do we
need that identity matrices are
necessary to generate variance ease
variances so we take that identity
matrix and we multiply it by the
standard deviation for every value in
the means so for all of those components
and that's going to give us our our
variances right then we're going to
we're going to use our program generate
our prior which is this value right up
here which is our prior belief so when
it comes to probability theory we have a
prior which is your belief before you
come into a problem so before you
examine a problem it's a bayesian
approach right bayesian is believe in
priors frequentists don't
it's a huge debate it's an ongoing
debate so it's a holy war but yes the
Bayesian Bayesian logic okay so for
priors we're going to say one divided by
the means for all of the means is going
to give us our prior value okay
and so then we're going to use those
values that we just computed to generate
or generate our gaussian mixture model
okay and then once we have our gaussian
mixture model we're going to sample from
it
okay so we've defined what this model
looks like this this architecture this
structure from which we can now generate
data from we've defined our parameters
for it and we can generate data from it
and so this is our helper function to do
that and we'll get our data set okay and
then we will save the data set and I
which I visualized and we showed you
guys and then we're going to plot it
showed you guys and then we're going to
store the samples and the labels so this
is interesting so is we have samples and
the labels but we're not going to use
the samples they're just there so we
have just and so we can think of this as
x and y points right the samples are the
x points and the labels are the Y points
okay and so we'll do that twice for two
different data sets we have one data set
that we call X and we have the other
that we call Z right two different data
sets and so we all have both of those
data sets we just repeat the process
twice and then we can sample from them
right so we have eventually we'll take
both numpy arrays for both sets of data
and we'll have our X data set and our Z
data set okay so that's our data and now
we can start defining our networks or
model okay so they looked at this
problem right and so they were
considering like what type of model
should we use and we had this we just
had this interesting thought exercise
earlier on in this live stream where I
talked about oh sure we use an encoder
decoder should we use two in color D
colors to use two encoder decoders with
an adversarial approach they had this
same thought process right and so this
happens a lot in research where we are
like thinking well what if this would be
the way oh no what if this would be the
way well let's just try out all the ways
and see what works best that's exactly
what they did so they so they tried out
one very simple model another model and
then they came to this model that we're
going to implement and they found that
this far
outperformed the other models and this
is just a thing in machine learning and
in deep learning where it seems like the
more complexity we add to a model the
better the results are generally
obviously there are going to be
anomalies no pun intended when it comes
to anomaly detection but they're going
to be anomalies but generally the more
complexity we add the more we chain
these models together the more
interesting the results are wavenet is a
great example a pixel RNN pixel CNN and
a path knit they're a bunch of examples
but that's what our brain is right we
don't just have a convolutional Network
we have a convolutional net for our eyes
and we have a recurrent net in our
hippocampus and we have feed-forward
nets happening probably in our somewhere
else but we have all sorts of networks
that are happening right as we when we
combine them we get an interesting
result and when the network observes
itself and it goes through this loop of
self observation and just leave the loop
just keep going faster and faster that's
what we get consciousness but that's a
whole different thing go to lecture Bach
lots of philosophy there okay so where
were we
consciousness no yeah okay this is disco
again disco again okay so here we are
okay where were we so this is another
image that they had in the paper when
they said okay we have our data sets and
so let's talk about the failure cases
what we don't want so if we look here at
this make this bigger and then I'll
answer questions I know I haven't
answered questions in a while so so
sometimes sometimes the internet doesn't
work so that's okay so where was I what
we don't want is we don't want the
images the same image to generate uh
different images we want a straight
image to image mapping what do I mean by
that something that is predictable so we
know that that there is no failure case
where we give it two different types of
images and it will generate the same
image even though these are two
different images right we want variety
we want novel image
to be generated no matter what kind of
image we give it right we don't want the
same mapping so those are failure cases
that it's a good practice to think about
before you're building models what are
possible failure cases what what do we
don't want to happen okay it's good to
just as a thought exercise to map those
out to to to put those down on paper
okay so that's what that is
and so now what we're going to do is
we're going to define these networks
okay so let's define these networks so
remember we have six networks okay and
the way that I'm going to define these
is we're going to use tensorflow Slim
now this is just beautiful right so I've
never actually used tensorflow Slim in a
in a video before but it's actually you
know it's a very beautiful library of
tension flow because because there are
it's very compact and dense so let me
let me answer two questions before start
starting to build this ah let's see one
great question is how can we make money
with this okay I mean yeah there's
there's a lot of potential here what are
some problems where people right now
need to visualize something but they
they can't they it takes a lot of effort
the barrier to entry is very high how
can you reduce the barrier to entry for
say designing or visualization CAD
engineers are very well paid experts and
they're very few of them and it takes a
lot of time and energy and skill and
practice to be able to generate images
with CAD what if you use a generative
adversarial network to let anyone
generate images with a text query okay
with a simple description boom
billion-dollar idea
one more billion-dollar idea what can I
think of on the spot here when it comes
to special effects oh no here's here's a
great one when it comes to video effects
when it comes to After Effects or
Photoshop or editor an editing program
so much of effects right but none of
them really use generative adversarial
networks imagine the effects that you
could create with this
blow whatever they have that's like you
know some kind of linear combination
under the hood out of the water you
would just dazzle people okay so that's
where we are right now okay so anyway
Harris style transfer is not happening
today
I know but eventually it will happen by
the way if you want to here's here's
what it is uh dye your hair with a
silver stripe here
send me the picture on Twitter I will
retweet it okay just do it it's gonna be
dope
oh cool - are we everything about me is
open-source guys my hair all about
everything it's all open-source take
take what you need take what you need
okay so the first thing is the generator
so we have two generators here and
remember we're calling one generator
we're calling one inference Network just
for the just for a difference we could
call a generator - but they're both
generators okay so in this case we don't
have images right we don't have images
so we're not going to use convolutional
blocks we're going to use fully
connected layers because these are just
numbers right this is these are just
numbers so they are this is this is a
set of feed-forward networks with a set
of fully connected layers okay so how
many layers do we want what we define
that right here with number of layers so
the great thing about tension flows limb
is that we can define a set of layers by
one line of code what do I mean by that
we can say slim repeat so given some
data set Z and then the parameters for
what we want the network to look like we
could say okay so Z equals H okay so H
is now it's our data stored in H so
let's say slimmed our repeat take the
data set take the data that we input the
input data and then we want this many
number of layers type of layer fully
connected with this many hidden nodes
and then this is the activation function
we want to apply to a tree Lu and it
does that that number of times and then
we had at the very end
one last fully connected layer and
that's when the output of that and that
is our prediction or in this case our
generation what we've generated and it's
going to be a set of numbers in this
case right because these are numbers
that we're inputting and so that's the
great thing about touch flow slim and if
that doesn't make sense
then just like
I forgot this donor so so that's what
that is okay so that's the first step
and we're going to do this twice right
so we're going to get for a generator
and we're getting this for our inference
Network we do it twice to set two fully
connected networks and that's going to
eventually generate our data right so
that's it for our generators and then
for our discriminators our
discriminators we're going to use a
fully connected layers as well okay so
both of these are going to use fully
connected layers and we're going to look
for the reason we concatenate X which is
our input data with one is to
approximate the log data density and why
do we want that well we are just
outputting a we're outputting a binary
value right whether it's whether it's
real or fake what the image is real or
fake and in this case real or fake is if
it is a but the if the generated image
image is from the true data distribution
which is the original image data set or
it's from the not true data distribution
which is something that's a a mix of the
two so we want to optimize for the mix
of the two right so we'll minimize the
opposite that's what our discriminator
does it tries to judge if something is
real but real in this case is you can't
tell that it is a mix of the two it just
looks like it's an image of its own and
it comes from both distributions and you
would think that it comes thinks that it
comes from both distributions but it's
actually a novel distribution a mixed
distribution so if it's a bad if it's if
our model is bad it's going to be able
to detect that this sloppy purse looking
shoe thing is actually fake right it's
from a novel distribution it's not as
intertwined with the other two
distribution sets so it's a little thick
but if it's really well generated and
that it is balanced in terms of the
distributions that it's generated from
that you can you can't even tell then
it's real okay so that's what that's
what we mean by real in this case real
versus fake
okay so then yeah there for the
discriminator there also a set of fully
connected layers are both feed-forward
and then we're going to output a tff
squeeze for the generated data
then we say the reason we're using
squeeze is because it removes the
dimensions of size one from the shape of
a of a tensor cool so that's it for our
generator okay
and our discriminator is plural okay so
then I could code these out but let me
answer some questions
to see what the deal is here who else we
got Q and QA all right so we have some
people ask for a two-night so here's
what the Q&amp;amp;A is how can you use deep
learning how can you use deep learning
for detecting a spoofed Frank
fingerprint a spoofed fingerprint so you
would have to have a data set of oh
interesting that's an interesting
problem so it depends on who's the who's
the spoofing that we are trying to
predict right if it's one person it's
very easy right because you just have a
bunch of samples of that real
fingerprint right so it's a supervised
learning problem a supervised
classification problem right so we have
a supervised classification problem of
one person's fingerprint and then you
would just say these are all the real
ones so you train it on the real ones
where they're labelled real remember
real and then ideally you could here's
what I would do I would take those real
images and then I'd apply some kind of
some distribution on those images so
that it would create some very version
of them some you know so maybe even use
a generative adversarial Network to
generate fake but realistic looking
images of that data set but then label
them fake so then you you've tried it on
what's real and what's fake and given a
fake one you could just say that that's
fake okay okay so then two more
questions up can I use a can for anime
related purposes yes you can
so literally literally my Internet's not
working right now but literally just
search anime again like one word and you
will find a I swear to god a result on
github for this I was actually looking
at this but it generates anime
characters using using a generative
adversarial Network and then one more
question is what approach should I
follow to get a job in this so that's a
good question as well that's a good
question as well so a good approach to
follow if you want to get a job
this is whether you're in college or
whether you are you have a full-time job
you need to find the time to learn this
stuff so that's step one find the time
to learn this stuff so dedicate some set
amount of time every day to just study
this whether it be papers whether it be
code here's the here's the best way
besides consuming content my videos
besides consuming content you need to
try to re-implement papers that's going
to be really hard at first but
eventually like anything you're going to
get better at it whatever you keep doing
you get better at whether it's
kickboxing whether it's machine learning
whatever you keep repeating you get
better at that's how our brain works so
just keep looking at code keep writing
out code keep trying to read them in
papers and eventually before you know it
you won't even realize it you're like oh
now I'm an expert it happens really fast
but you have to put in the time and the
effort that's all you need with the
internet okay I might free saw at the
end depending on how I feel okay cool
back to this so I was going to code this
but honestly there is a lot like the
Internet's not working so I'm just going
to look at this and it's all good so
here's how it is for our loss functions
and our networks we define the functions
for our networks right we've defined
them they're done now we can actually
start implementing our functions so
check this out okay so check this out
first we're going to define placeholders
for both of our data sets right we have
X and we have Z remember we generated
both using a Gaussian mixture model
those are those are both of our data
sets we've got our data sets not let's
feed them into our model that's the next
step so now we'll define both of our
generators and remember we define them
both respectively one is the generative
Network and what is the inference
network okay these are in colors right
so these are in colors they are where
are they where are they they are right
here one the blue one right here and
this yellow orange one right here that's
what we just defined okay those are our
encoders encoder generators okay and
then now I'll talk about more use cases
after this we've got both of our
encoders and now we're going to define
our discriminators which were the two
discriminators on the
side here okay so and to generate these
we gave it the two respective datasets
right Z and X and then our height and
then our hyper parameters that we
defined for head then we have our
discriminators and we're going to use
data network x and then data network z
right we have two different
discriminators and we'll just what we're
going to feed it what we're going to do
is we're going to feed it are the
outputs of our generators right we want
to we want to feed it the output right
what have we generated and let's see if
it's real or fake let's criminais if
it's either real or fake so that's what
we feed both of these and the reason we
use graph replace here on our
discriminators is because it is going to
help us calculate our loss function
because we need two of these we need
it's essentially a copy in the
computation graph so that we can do this
next step and you'll see why we create
two discriminators and then two copies
of them so then we can then compute the
soft plus function on all four of them
it's just two discriminators they're
copies of each and the soft plus
function is taking the log probability
of the exponential
our features plus one which is an
activation function okay so we and
that's what the soft plus function up
tensorflow does so we have four sigmoids
that we've calculated okay and then
we'll take those values and we'll use
those see in this lobby we'll just add
them together for the original and then
the copy to compute our D color loss and
then our encoder loss for both
discriminators so we have the loss for
both discriminators and then we will
combine them to have one big huge
discriminator loss and we say is that
the average of the encoder loss minus
the average of the decoder loss so we
take the difference between the two what
is the difference what is the difference
here okay between what is the original
image and what is the generated image
original data distribution generated
data distribution find the difference
minimize it we want there to be no
difference so it looks very similar
statistically speaking to it to the
discriminator and that's going to be our
discriminator loss okay and then we've
define our loss function we define our
discriminators and then two of our
generators now when we have to do we
define our generator loss and then our
two next generators right so that's what
we're going to do now so now we have two
more generators and these same deal
we've got our inference Network and our
generative Network and what do we feed
it in the output of the previous
generators the encoders px + qz you
remember these were right up where were
they right up here see peak px + 2 Z
weed if we feed those right into our
next set our decoders and what does that
look like that looks like that looks
like this decoder one decoder - that's
it we define all six of them see how
simple that was we define all six of
them now where was I where was I
lots of TF warnings warning warning okay
we've got our generated through got our
discriminators and now we want to
compute the generator law so we have our
discriminated loss it's computer
generate a loss so what do we do we
compute the sum of squared errors all
right so we have generator one the
computer computed that generated of the
ultimate generated product right
that's what Rex Z the reconstruction of
Z and reconstruction of X are those are
the ultimate outputs of our network the
ultimate outputs what that mixture of
both image data sets and we want to
compute the loss and that is our
predicted output the generated output
minus the original data set to the
difference squared and the average so
the sum of squared errors for both data
sets cause II and then cost X and then
we compute the advantage loss which
basically ties in the discriminator loss
into the generators loss by finding the
average of those all the points in that
vector the average of all those and we
use that to compute the generator loss
which is 1 times e advantage loss plus 1
times the cost four plus one times the
cost of the other image so two two costs
for two image datasets and that's going
to us our final generator loss and I'll
answer questions right after this
but after I get done with this block
right here so then we're going to want
to update our our weights right four we
want to use our gradients to update our
weights so that's what we do we say
we'll use the get collection method to
say with intention floats computation
graph I want you to get these values
that are that have the trainable
variable and we define what that
variable is inference generative
discriminator and we defined those up
here we define those up here see the
Scopes that's how we call the scopes
really easily we're very very good
programming syntax syntactic sugar is
the official term for a very very cool
term Thank You Francois chalet for
continuously using that term okay so a
creator of careless so so now let's
optimize we've got our we've got we
define our networks we define our loss
functions let's optimize well use
Adam for gradient descent to optimize it
and then we can minimize both losses
that minimize the loss for the generator
and minimize the loss for the
discriminator using the generators loss
and the discriminators loss and then
what are those values that we want to
update when we can't compute our
gradients what do we want to back
propagate to our network well these are
the these are the variables that will
that will point our point tensorflow
to the memory location of where we these
networks are okay so that's that part
and let me talk about the training part
now we're done with that part now we're
the last part is the training part but
let me answer some questions let's see
okay so can can be used for audio
generation yes
ganz can be used for audio generation
that is a novel field and not many
people have attempted that before
wavenet was it was a great attempt at
generating audio in the style of someone
else it didn't use a generative
adversarial Network though so there's a
lot of possible
to hear that there's so much you could
do with audio generation generating
speech of the style somebody else
generating music and the song that's a
great one as well generated adversarial
networks for music generation how cool
would that be
Hans Zimmer Hans Zimmer music okay two
more question questions Suraj is wrong
about textbooks here's the thing people
have different learning styles
people have different learning styles in
the age of the internet where our
attention is split 300x right we paid we
split our attention I saw some statistic
recently where I was like even ten years
ago ours our attention was split across
maybe two or three different domains
across the entire day but now it's split
across three hundred different domains
Twitter Facebook snapchat life
girlfriend-boyfriend this there's so
many things right so a textbook requires
a lot of attention and a lot of focus
but we live in an age of instant
gratification let's be real right so we
want that instant gratification we get
that from everywhere else we get that
from you know mindless entertainment we
can get that from education too that's
all I'm saying
but if a textbook works for you it works
for you right but I'm just saying that
if you are trying out the textbook for
learning it's just not clicking there
are other ways it's not like D way to
learn two more questions can we detect
movement in video with gann yes you can
detecting movement is a vague term but
detecting the direction that someone is
moving sure you can you can generate
different possibilities of given some
set of frames one is going to be the
possible next frames that possible next
frames and then and then take those
generated frames across all the
generated frames like he moves this way
it was this way it moves this way
vectorize all those vector vector vector
vector and then compute the distance
between those vectors
perhaps a cosine the cosine distance or
you know one of one of the distance
functions and then
and then multiply those by some distance
vector and you can see a set of possible
distances and also get the most likely
distance that's never been done before I
just I just made that can you suggest me
an NLP book Suraj uh NLP Stanford has a
great course Michael Collins is a great
my favorite NLP professor he's a
professor at Columbia who had now has an
online course on Coursera and a textbook
NLP textbook Bishop if you okay if you
want a textbook then bishop's
pattern-recognition book is great great
section on NLP in there one more
question this is via I know it's via
what is the can you show us how to do
facial recognition next yeah I will
eventually what happens when none of the
Gans generated images can be classified
as a positive match within one of the
initial data sets
what uh what happens if none of the
generated images from again can be
classified as a positive match within
one of the initial data sets oh yeah so
if your gaen is bad like it's not
predicting well then you tooth out me
there's several things that could be
happening but it's usually going to be
two things one you got to change your
loss function try out a different loss
function right your loss function is
just not working it's a very common
thing with Gans
although Wasserstein Gans definitely
improve on this so that's one
possibility change or loss function but
the other is change your data set add
more data add more data okay so that's
it for that and so now let's look at the
training and for training we're going to
say let's begin our session and then
inside of our session we're going to say
stable from both data sets so from our X
data set for Z two data set will use our
shuffle function to sample some random
values from them and then we're going to
say okay so for each of those values for
each of those values so we're going to
do we train this six Network model
simultaneously so it's happening all at
once
right it's not like we have some session
and we have another session women no no
it's one session and we train them
simultaneously so we say for uh for each
of those data sets let's compute the
let's compute the let's minimize the
loss for both our discriminator so this
is for our discriminator feeding in both
both sets of data x and z and then for
our generator feeding in again both sets
of data and so you might be thinking
well shouldn't it be generator loss
these three components make up the
generator lost the advantage loss the
cost of X and the cost of Z recall up
here see these are the three components
we could just say generator loss as well
but this is how they implement it in the
paper when in PI torch interestingly I
mean but you could say two generator
loss as well there's no reason to do
this specifically so let's let me just
compile this whole thing and and see see
what's good see what happens but but but
compile compile compile compile and then
we get to the end
boom training just like that training
training training 2% through did now to
see it's going to take a while so I want
to stop it before my computer gets crazy
crazy like Charles Barkley no wait
Charles gnarly no Gnarls Barkley that's
a great song
where was I okay so open this let's look
at our results the results are gonna be
saved
we're not showing them in the tension
flow graph they're gonna be saved and so
check out this check out our loss
function it's like not doing that thing
where it has to go down it's like going
it's like going wildly crazy for both
the generator and the discriminator so
that's just that's generative
adversarial networks for you although
I'm going to talk about Wall Street in
Ganz and show how they improve on this
but like check to sell right so we have
our true samples and then we have our
inferred samples so the inferred samples
right here showed that the combination
of the two and so it just plots that it
just creates those novel red points in
from from the two initial data
distributions and yeah more or less
simple simple idea there but that's what
the paper was all about and remember
like when reading papers it's really
like let me just I'm just like I think
this will provide guy
this will provide value to you guys to
just kind of go over like how I read
papers really quickly so the first thing
I do is I definitely read the abstract
in the introduction because those are
super simple right it's just it's just
like you know motivations and why
they're doing it look at the image
usually like 90 percent of the time I'll
be able to you'll be able to grok what
the entire paper does just by reading
the first page and a good paper should
be like that you should be able to
understand at a high level what is
happening without having to look at the
entire thing right that's what the
abstract is meant to do okay and some
people say you read the abstract at the
end rather than at the beginning but
until it depends
if you are trying to just get a quick
idea quick and dirty idea of what the
paper is then I really read the abstract
at the beginning but some people say
wait at the end you know all around I
would say that's a bad idea I just this
is how I read papers and it's worked
what very well for me so I'm going to
speak on my own experience here so so
that's the first step and then so then
they'll talk about their methodologies
and they'll talk about usually a
different like many different
methodologies and many different ideas
that they're talking about but what you
can do is you can go right to the meat
of what it is and if you read a lot of
papers you'll get better at this because
right here they're talking about
notation and architecture talking about
a single Gann with reconstruction laws
this is irrelevant to the actual the
model that they built but if you keep
going you'll find our proposed model
this is the actual model so you can just
if you wanted to you could skip the rest
and then just read this and which is
what I did at first
so the first pass like oh this is that
this is what they built and then they'll
talk about their experiments and they'll
have many many different steps for the
experiment and you just kind of like go
through it and you just want to get to
the results you want to know why did it
why they made the paper what's the model
they used and what are the results and
once so that's how I look at it in our
first pass I was good so I go all the
way down here and I see the results I
see that I see that well they got state
of the art you know in these areas and
and then conclusions like how they would
improve once you've got that first pass
and the first passion take you like
maybe I don't know it takes me it took
me like 25 minutes 30 minutes first pass
then if you want to then go back and
really like read through all the details
and want to be through all the details
then look at the code there's an a good
paper always has associated code if you
if you were writing papers you need to
be publishing code okay because you have
to help other people out this stuff so
that's how I read the paper for this
okay so it's a very new stuff it's very
new paper and the next live stream is
going to be the last live stream and it
will be for for this course and it's
going to be on not deep learning it's a
surprise okay so let me answer some
ending questions here before we're done
I'm Hagar's oh love the show we have an
eight-year-old that's awesome
that's awesome thanks for being here is
it the code in the paper how do I begin
reading source code from a paper so
source code is usually not in the paper
but it's on github so what I do is when
I want to find source code is I will
copy and paste the name of the paper
like this into Google or github
sometimes github and it's going to show
up if they publish code if it doesn't
show up on Google's first page they
haven't published the code and so that's
that's that's not good okay two more
questions
what's the source of papers you're
mentioning a great source for the papers
is archive sanity check this out make
that bigger is the word archive sanity
let me paste that right here
where is it
checked out this is the link right here
archives sanity calm you can you know
what it does it's a web app that looks
at the best papers for you and it just
picks and you can just it just lists
them chronologically and you can look at
what the top high papers are great great
tool okay so one more question can we
use our n n based architecture in an
adversarial setting for realistic text
generation tasks mainly are recurrent
net architecture in an adversarial
setting for text generation tasks
absolutely absolutely
so first of all recurrent Nets for text
generation it's been used before
Shakespearean text all sorts of texts
well-documented problem well-defined
solutions you can do this in 10 lines of
chaos
Andre Carpathia is the king of this lots
of 10 line snippets on the web to do
this very easy to do using lsdm
recurrent networks in an adversarial
setting I haven't seen it but you could
I would bet you could beat the state of
the art if you tried I would bet you
could because I haven't seen it before
and overall ganzar just blowing to say
of the are on many and it many different
peels so that'll be in like that okay so
enough of that let me uh let me let me
wrap so I'm going to freestyle so
someone shout out to be and let me
answer one question in the meantime
because it takes a while for the
question to come in one more question
and guys shout out topics for the
freestyle by the way okay uh can we
train a net to configure a good again
that's irrelevant
what was your uni I went to Columbia but
look don't think like oh you know
he went to Columbia like he's a he's a
genius I can't be like that guys I am
just like you I am NOT some God as much
as I would like to say that I am I'm
really not I'm just like you I'm a human
i'ma come a guy you know
I'm not some I'm not I don't have a PhD
I have you know I'm not like sitting
there you know I'm just a guy who's
really interested in this stuff and
that's all it takes is an interest okay
and had a desire to learn okay so all
right so we've got some some okay all
right enter all right so I'm gonna
freestyle about ten sir hit it there we
go
jazzy tensors it's going to go down in a
second what I want to hear that I'm
gonna hear the beat drop it's on for ten
sir huh it's gonna come in a second
here we go ten sir oh here we up it with
it we doing that we I love tensors try
to give up and give you some big
lectures every day I come out it's like
I'm a section leader of a person every
time I give it you don't even know I'm
reading I see these different variables
every single day I see you like one two
three four okay I think I can define a
tensor out of that my way are using
vector class analysis okay there are
different ways of putting this out there
anyway I'm going to talk about demo one
two and three all right hey drop the
beat drop it back like if you take a
seat not while I'm rapping man I'm not
your enemy I see Jupiter notebooks can't
you see that's the only way to do this
you gotta be on top
whenever you release it whenever you
show it to the world you want to make
sure it is creasing creasing like paper
you fold it you show it to professor's
like your
the man okay that's it for this that's
it for the right that's different it
would be the beat didn't drop but I just
rolled with it you know the B in life
will drop when you ask it to okay so
that's it for the live stream thank you
everybody for watching and for now I've
got to go create the finale and don't
worry I have so much more to come this
this is nothing I'm just getting started
okay so I am just getting started don't
be worried like oh no the course is over
strut I don't know I'm just getting
started okay so for now I've got to
write the finale so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>