<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TensorFlow in 5 Minutes | Coder Coacher - Coaching Coders</title><meta content="TensorFlow in 5 Minutes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TensorFlow in 5 Minutes</b></h2><h5 class="post__date">2016-08-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2FmcHiLCwTU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj the most popular
machine learning library in the world
right now is Google's tensorflow
we're going to use it to build a
classifier that can look at an image of
a handwritten digit and classify what
digit it is in under 40 lines of code
basic is she pretty much every single
Google product uses machine learning in
some way whether it's image search image
captioning translation recommendations
Google needs machine learning to take
advantage of their godlike data sets to
give users the dopest experience there
are three different crowds that use
machine learning researchers data
scientists and wizards
I mean developers ideally they can all
use the same tool set to collaborate
with each other and improve their
efficiency tensorflow was a solution
they created to help solve this problem
Google doesn't just have a lot of data
they have the world's largest computer
so the library was built to scale it was
made to run on multiple CPUs or GPUs and
even mobile operating systems and it has
several wrappers in several languages my
favorite one is Python objective-c you
broke my heart we have to install
tensorflow first we're going to use pip
the Python package manager to install it
once we have pip we can create an
environment variable that points to the
download URL for tensorflow
once we set the environment variable we
can download tensorflow via pip install
with the upgrade flag in the name of our
environment variable dope now that we
have our dependencies installed let's
get to the code we'll start off by
importing our handwritten digit data set
the input data class is a standard
Python class I've download the data set
splits it into training and testing data
and formats it for our use later on
and of course we'll import tensorflow
now we can set our hyper parameters or
tuning knobs for our model the first one
is the learning rate which defines how
fast we want to update our weights if
the learning rate is too big our model
might skip the optimal solution if it's
too small we might need too many
iterations to converge on the best
results so we'll set it to 0.01 because
it's a known decent learning rate for
this problem definitely faster than
little wayne's now we want to create our
model in tensorflow a model is
represented as a data flow graph the
graph contains a set of nodes called
operations these are units of
computation they can be as simple as
addition or multiplication and can be
complicated at some multivariate
equation each operation takes in as
input a tensor and outputs a tensor as
well a tensor is how data is represented
in tensor flow they are
multi-dimensional arrays of numbers and
they flow between operations hence the
name tensor flow it all makes sense
we'll start by building our model by
creating two operations both our
placeholder operations a placeholder is
just a variable that we will assign data
to at a later date it's never
initialized and contains no data well
define the type and shape of our data as
the parameters the input images X will
be represented by a 2d tensor of numbers
784 is a dimensionality of a single
flattened MN IST image finding an image
means converting a 2d array to a 1d
array by unstacking the rows in lining
them up this is more efficient
formatting the output class is why will
consist of a 2d tensor as well where
each row is a one hot 10 dimensional
vector showing which digit class the
corresponding MN is T image belongs to
then we'll define our weights W and
biases B for our model the weights are
the probabilities that affect how data
flows in the graph and they will be
updated continuously during training so
that our results get closer and closer
to the right solution the bias lets a
shift our regression line to better fit
the data well then create a named scope
scopes help us organize nodes in the
graph visualizer called tensor board
which will view at the end will create
three scopes in the first scope we'll
implement our model logistic regression
by matrix multiplying the input images X
by the weight matrix W and adding the
bias B well then create summary
operations to help us later visualize
the distribution of our weights and
biases in the second scope will create
our cost function the cost function
helps us minimize our error during
training and we'll use the popular
cross-entropy function as it then we'll
create a scalar summary to monitor it
during training so we can visualize it
later our last scope is called Train and
it will create our optimization function
that makes our model improve during
training we'll use the popular gradient
descent algorithm which takes our
learning rate as a parameter for pacing
and our cost function as a parameter to
help minimize the error now that we have
our graph built will initialize all of
our variables then we'll merge all of
our summaries into a single operator
because we are extremely lazy now we're
ready to launch our graph by
initializing a session which lets us
execute our data flow graph well then
set our summary write or folder location
which will later load data
to visualize in tensor board training
time let's set our for loop for our
specified number of iterations and
initialize our average cost which will
print out every so often to make sure
our model is improving during training
we'll compute our batch size and start
training over each example in our
training data next we'll fit our model
using the batch data in the gradient
descent algorithm for back propagation
we'll compute the average loss and write
logs for each iteration via the summary
writer for each display step we'll
display error logs to terminal that's it
for training we can then test the model
by comparing our model values to our
output values will calculate the
accuracy and print it out for test data
the accuracy gets better with training
and once we've trained and tested our
model it'll be able to classify novel MN
is T digits pretty well we can then
visualize our graph in tensor board yo
pretty colors and stuff in our browser
we'll be able to view the output of our
cost function over time under the events
tab under histograms we'll be able to
see the variance in our biases and
weights over time under graphs we can
view the actual graph we created as well
as the variables for weights and bias we
can see the flow of tensors in the form
of edges connecting our nodes or
operations we can see each of the three
scopes we named in our code earlier and
by double clicking on each we can see a
more detailed view of how tensors are
flowing through each lots of cool links
in the description and please hit that
subscribe button if you want to see more
ml videos for now I've got to go doc as
my environment so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>