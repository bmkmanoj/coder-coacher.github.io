<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Convolutional Neural Networks - The Math of Intelligence (Week 4) | Coder Coacher - Coaching Coders</title><meta content="Convolutional Neural Networks - The Math of Intelligence (Week 4) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Convolutional Neural Networks - The Math of Intelligence (Week 4)</b></h2><h5 class="post__date">2017-07-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FTr3n7uBIuE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world its garage and we're going
to build a convolutional network using
no libraries I mean just numpy but no
libraries no tensorflow no pi torch none
of it
we're going to look at the math behind
it and we're going to build it with just
numpy for matrix math in Python okay and
what it's going to be able to do let me
just start off with this demo to start
off with what it's going to be able to
do is recognize any character that you
type in or not type in but draw in with
your mouse so you could draw a six like
that and then hit submit it'll start
working and then it will say it's a six
and then if you don't want you to six
you could say a letter like a any number
or letter it's going to be able to
detect slash predict so it's gonna be
really cool because we basically we're
wrapping it into a web app using the
flask web framework so it's going to be
super awesome okay so that's what we're
going to do today and this is our first
neural network that we're building in
this course from scratch I mean we made
one in the weekly video but this is the
real you know hardcore convolutional
network with all the layers all the
functions everything okay so let's start
off with what it's inspired by well it's
inspired by Yann Laocoon the genius no
it's not so Jung laocoön is a director
of AI at Facebook he's the total ji he
is awesome because he was inspired by
these original two guys right here who
published a paper and I think 68 or
early 60s or 70s but the paper was on
the mammalian visual cortex and the idea
they had was and so here's a great image
of it let me make it a lot bigger this
has to be a lot bigger so the idea they
had was that mammals all see in a very
similar way and that way is hierarchical
so you have a collection of cells and
these cells or neurons and b-cells
cluster and and these clusters represent
different features that are learned okay
so here in terms of neuroscience they
call these clusters v1 v2 you know have
names for all these clusters in the
brain these clusters of neurons before I
see posterior all the neuroscience
terminology but what we need to know is
that at a high level what's happening is
every time you see something a series of
clusters or
layers of neurons are being activated
whenever you see something whenever you
detect something to be more accurate if
I detect a dog or if you know face or
whatever it's going to be a series of
layers or clusters of neurons that fire
and each of these clusters are going to
detect a set of features ok any features
are going to be more abstract the the
higher up the hierarchy of clusters you
can think of it as a vertical hierarchy
or even a horizontal hierarchy what it
doesn't matter but the idea is that
there is a hierarchy of features and at
the start these features are very simple
they're lines and edges but then they
get more abstract and they become shapes
and then they become more complex shapes
and eventually at the highest level at
the highest cluster level exist the
entire face or the entire dog or
whatever it is and this is how the
mammalian visual cortex work and so what
yawn laocoön said and his team in 98
when they published probably the
landmark paper of convolutional nets
which is kind of arguable I guess
because her jetskis imagenet paper was
pretty good and and I think 2012 but
anyway y'all look who's a gee I just
want to say that he had the idea to be
inspired by three things three features
of the human or the mammalian visual
cortex local connections and that means
the clusters between neurons how each
neuron each set of neurons in a cluster
klux are connected to each other and
they represent some set of features and
then the idea of layering how these
there's a hierarchy of features that are
learned and spatial invariants what does
this mean this word spatial invariance
it means that whenever you or I detect
something whether it's let's say we
reciting a shoe right we see a shoe you
know it's a shoe right if it's a Yeezy
if it's a you know adidas whatever it is
you know it's a shoe it could be shaped
this way or this way it could be rotated
or transformed no matter how it varies
we still can detect that it's a shoe we
know it's a shoe so we are it is the way
its position is it's spatially invariant
we can still detect what it is and so
those three concepts were what inspired
first of convolutional neural networks
programatic neural networks designed to
mimic the mammalian visual cortex how
cool is that it's so cool so how does
this thing work let's look at how this
works so we have a set of layers okay
and we'll talk about what these layers
mean right what is layer a layer in each
case is a series it's a series of
operations that we're applying okay so
let's let's talk about this right so we
have some input image so let's say this
is the orange that's the image and
you'll notice by the way that this image
this is a convolutional network by the
way this is what we're building okay
you'll notice that this image right here
or this image of the convolutional
network isn't what you normally look at
when you think of neural network right
you always see that image of the circles
and everything connected so why is it
different for convolutional networks
because every layer in a convolutional
network isn't connected to every so
every neuron in every layer isn't
connected to every other neuron in the
next layer why because that would be too
computationally expensive I'll go over
that in a second but the idea is that if
you if you see here there is a part of
the image that is connected this little
square of that orange and that is called
the receptive field okay I'm going to go
over all this it's going to make more
and more sense you're going to be more
confused it's going to it's going to
make more and more sense as I go further
and further and depth here so so so stay
with me here so we have a receptive
field okay that is some part of the
image that we are focused on we are by
focused I mean that is the part of the
image that we apply a convolution
operation to okay and we take that
receptive field and we slide it across
the image okay you're going to do
exactly what I'm talking about in a
second I'm just going it over at a high
level we slide over the image we are
applying a dot product between our
weight matrix at a layer and every part
of that image iteratively okay and so
that the reason that they look different
the convolutional networks look
different is two reasons really the
first reason is that not every neuron in
each layer is connected to every other
neuron in the next layer it's only a
part of that because it would be a to
borrow from discrete math a
combinatorial explode
to connect every single pixel value in
an image to every single pixel value in
the next layer of features right it'll
be just a huge amount so what we do
instead is we take a part of that image
and we iteratively slide over it okay so
at a high level you understand the
sliding part right think of it as a
flashlight okay think of it think of the
the filter at each layer that shines
over the receptive field that box as a
flashlight and you're shining over the
image and you're and you're applying dot
products to all of these numbers okay
just like that okay I'm going to keep
going into this that was just a high so
you're not supposed to understand it all
yet okay that was that's very high level
we're still going deeper we're going B
we're going deep okay so check out this
beautiful image right here isn't it
beautiful it's very beautiful also
you're beautiful for watching this so
thank you for watching this okay so I
love my pen so much seriously you guys
are amazing seriously you guys are the
reason I do this every week okay so I by
the way I want to say one more thing to
go on a tangent the people who subscribe
to my channel no one thought they
existed
we are programmers who are smart and we
are also cool no one thought these
people existed but we exist okay we are
smart and we are cool so you are amazing
okay anyway back to this what this is is
another way of looking at the network
right we're just looking at different
ways we're looking at different ways so
we can build a spatially invariant image
in our head of what a convolutional
network is like right no matter what
that image is we're going to learn to
recognize a convolutional network when
we see one I'm just trying to you know
Metta applying this logic to what we're
learning so what happens that each layer
we are applying a series of dot products
between the weight matrices and the
input matrix okay and so what happens is
let's we'll get a third image okay so
there's a third image what happens is we
perform a series of operations okay at
each layer and so we could think of
different we could think of splitting up
a convolutional Network into two
separate categories the first category
is feature learning and that's what's
happening at the at
head of the head to the middle to almost
a tail end of the network and at the
very tail end is classification so
there's two parts there's the feature
learning part and then there's the
classification part and to put a feature
learning part what happens are three
operations over and over and over again
and we can call them convolutional
blocks let's just call them
convolutional blocks i'm coining the
term so what happens is we first apply
convolution then we apply riilu or any
kind of activation and then we apply
pooling and we repeat that that's that's
a single block three operations in a
single convolutional block
okay so convolution reroute Pooley
repeat convolution reroute pooling
repeat convolution remove pooling okay
and usually you know you have three
blocks at least I literally building
inception by Google then you have 15 15
of these but you you know you have these
convolutional blocks and at the very end
then you flatten that output into a
smaller dimensional vector and then you
apply a fully connected layer to it so
that means that you then connect all the
neurons and one layer to the next one
just because we want to then harness all
of the learnings that we've learned so
far that's why we fully connect at the
end and then we take those learnings and
we squash it into a set of probability
values with our last softmax function
and then we take the max value all those
probabilities and each of these
probabilities is a probability for
specific class that it could be and we
take the max value let's say 72% as and
we'll say okay well 72% for banana and
now we know it's a banana okay so
hopefully you get some of it but it's
very confusing so I know we're about to
go even deeper okay so get ready for
this I haven't even started yet so I
haven't even started yet okay so anyway
step one so for step one we are
preparing a data set of images right so
when you think of an image you think of
a matrix hopefully a matrix of pixel
values if you don't think of it that way
think of it think of it that way now
you're thinking of an image as a matrix
of pixels rows by columns and each of
these each of these points in the matrix
represent a pixel right between zero
and 255 but it's actually better in
terms of convolutional networks to think
of an image as a three-dimensional
matrix and you're like what no well it's
good enough so it's three dimensions so
the first dimension is the length of the
image the second dimension is the width
and the third dimension is the depth so
wait what is the depth because the depth
represents the channels and there are
three channels for images red green and
blue unless you're talking about
grayscale then there's black then
there's you know black and white but
we're talking about color images okay so
there are three channels and you have
these dimensions for each of the
channels so these values in each of
these in each of these 2d matrices for
and there are three of them represent
the the amount of redness or the amount
of greenness or the amount of blueness
between 0 and 255 so in terms of
convolutional nets we think of images as
three-dimensional pixels okay so I
wanted to say that part ok so that's
that's that's what we think of our image
as our input image and it has an
Associated label right we're talking
about supervised learning learning the
mapping between the input data and the
output label dog image dog label learn
the mapping given a new dog image what
is a label well you just learned it
right so and we learn it through back
propagation back propagate to update
weights remember the rhyme you know what
it is hey I haven't wrapped yet in the
series but I will don't worry it's
coming anyway so every image is a matrix
of pixel values we know this we know
that they're between 0 and 255 and we
can use several training data sets
they're two really popular ones there's
c4 and there's cocoa and there's a bunch
of other ones as well but basically
these are huge data sets and you can
find smaller versions of them and each
of these images their dogs their cars or
airplanes their people whatever they all
have labels for them handmade labels by
humans which is great for us ok so
that's that's it that's step one step
one is to get your training data which
is your images which are your images
step two is to perform convolution now
you might be asking what is convolution
well I'm here to tell you that
convolution is an operation that is dope
as
here's white stove because it's not just
used in computer science and machine
learning it's used in almost every field
of engineering think of convolution as
two paint buckets you have one paint
bucket which is red another one which is
blue and what you do is just smear it
all over yourself no you don't do that
what you do is you take these two paint
buckets and you combine them into one
paint bucket and that new paint bucket
is going to be a new color whatever that
combination of colors is that's
convolution convolution is taking two
separate types of data or two matrices
and then applying and it's an operation
that combines them so you can think of
convolution as synonymous to combination
okay then why do we apply it why do we
say that for convolutional networks
because what we're doing is we are
combining the values for each of these
layers with the input matrix so think of
the input as that matrix right and so
well it's a three dimensional it's a
three D tensor right but we're applying
it to each of these dimensions right so
three of them so just think of it as a
matrix for right now and so what we do
is we take this so at each layer at each
layer there is a weight so by the way
okay so there's a lot of interchangeable
terms in machine learning and it's easy
to get confused here but I want to set
the record straight for a second weight
is the same as feature matrix is the
same as feature map is the same as a
filter in this case in for convolutional
networks so you'll see these or even
kernel kernel is a different one there's
actually five interchangeable terms I
can see how it's going to be confusing
but if you get the basic idea of you
have an input matrix which is your image
and then you have a set of matrices
which are your features that are learned
you know edges shapes more abstract
shapes that's it that's that's all it is
matrix dot product matrices that are
being multiplied by matrices all the way
through that's that's all it is matrices
that are being multiplied by matrices
always are just a chain of them okay so
what happens for convolution is we take
a matrix and we multiply it by all the
values in this matrix at a certain
region right and so this is what I was
talking about when I was saying we have
a receptive
field because we don't just multiply it
all at once we multiply by a little part
of it okay the receptive field and we
slide it and we can define what that
interval is that sliding-window I know
I'm talking about without coding the
coding is coming believe me the coding
is coming but just check this out for a
second we got it learned
conceptually first so we are multiplying
the feature matrix by that input image
just for every row and every column or
just multiply multiply multiply and what
happens is we have this new matrix that
results the output and that output is
considered the convolve feature okay and
so what we do is we use that output as
the input for them to the next layer and
we repeat the process over and over and
over again
obviously there's two more parts here
there's the activation the riilu and
then there's the pooling which I'll talk
about as well but that's the basic idea
between convolution and that's what we
call it convolution because we are
combining or convolving the wave matrix
or filter or kernel whatever you want to
call it feature map by that input we're
combining it using the help and using
that output as the input for the next
layer after activating it and pulling it
okay so that's convolution and also
right so we apply through all of those
dimensions for that for that input
matrix okay and that gives us our
activation map or feature map or filter
right so many different interchangeable
terms here so anyway so it's computed
using the dot product so you might be
thinking well okay I see how there is a
dot product
I see how there's matrix multiplication
but how does that really tell us what
features there are I see you're still
making the connection probably why
understandably why these series of major
operations help us detect features well
here's what happens what happens is this
and here's the great thing about
matrices and having several of them when
we learn a filter or weight whatever you
want to call it you know what moving
forward let's just call it filter okay
I'm just saying let's just call it
filter moving forward for the rest of
this video when we learn a filter over
time by training it on mouth mouth
pictures for example a filter is going
to look like this at let's say at the
first layer we we learn a filter for
detecting a
that looks like this right this curve
right here and so what's what the
filters going to look like for detecting
the specific type of curve it's going to
be a very sparse filter that means
there's a lot of zeros except so there's
all these zeros except for right here
you see this 30 30 30 30 and notice that
these values represent the shake they go
in this direction of a shape and so what
happens is when we take this filter and
perform the dot product you know we
convolve it with whatever part of the
mouse if it's over a part of the mouse
that matches that feature exactly
then we when we multiply all of those
when we when we perform the dot product
between all those values and sum them up
that's the convolution operation right
there okay just it's going to be a big
number okay so then we know that we've
detected a feature because we've we've
multiplied it sum it up and there's a
large number and if there's not if we
multiply it loads let's say we have that
receptive field over a different part of
the mouse and that that curve doesn't
exist then it's going to be zero right
because if you look between these 30 30
30 values and that the equivalent
locations on this pixel representation
of the mouse image these are zeros and
so what happens when you multiply zero
bi 30u get zero right so that's why it's
important to make the rest of the so the
data that's irrelevant we want it to be
zero right in the in the feature maps
are in the filters that we learn in the
filters that we learn we want the
irrelevant parts to be 0 and in the
images okay and N in the input images so
I so I can actually go even more into
convolution but it's not really
necessary but it is super dope it is
super dope though this is a great blog
post by the way I definitely encourage
you to read this blog post it's linked
in the notebook but this dude Tim Tim he
goes into this idea of convolution and
he talks about how it's applied to all
these different engineering fields and
he goes into the formula the formula for
the convolutional theorem is what he
called it is what it's called okay and
I'm just going to go over this at a high
level but the convolution theorem
is this general theorem for discrete
well there's a discrete version and a
continuous version right discrete is if
there's you know 1 or 0 black or white
you know definite classes that something
could be or is continuous is if it could
be an infinite amount of values between
0 &amp;amp; 1 point 5 0.25 you know 0.7 infinity
in that direction but here's the here's
the formula for it and so let me make it
bigger just really quickly and we'll get
back to it because it's really cool but
the convolution theorem states that we
and so in it's a general theorem that
can be applied to any any any set of
problems but in terms of what's relevant
to us is called is the convolutional
theorem apply to matrix operations so
what we can do is we can say what it
what it says is it's the input times the
kernel and it's the dot product it's a
dot product between two different
matrices and we perform that for every
value in all of those matrices and we do
that for all of the values that we have
and we sum them up together and that's
what the Sigma term represents and we
and we actually express that right here
right this operation right here this
multiplication in summation is the same
thing but it's a more complex way of
looking at it or more mathematically
accurate way and also the fast Fourier
transform is is brought up by this and
the fat Fourier transform take some
spatial data and it converts it into
Fourier space which is like a waveform
and you see this a lot in your day to
day life whenever you're looking at some
sound you know you're listening to some
sound and you look at your mp3 player
and you see the wave that's at the
Fourier transform happening but I won't
go into that that's that's for sound in
audio but anyway it's really cool a blog
post definitely check it out ok so back
to this until we talked about
convolution now we're going to talk
about pooling right so what is pooling
so whenever we apply convolution to some
image what's going to happen at every
layer is we're going to get a series of
feature of so each of the weights are
going to consist of multiple images and
each of these images are going to be at
every layer there's going to be more and
smaller images so the first few layers
are going to be
huge images right and then at the next
few layers are going to be more of those
but they're going to be smaller and it's
going to get just like that okay and
then we squash it with some fully
connected layer so we get some
probability values with a soft max but
anyway what pooling does is it word is
it dense is it makes the matrix the
major seeds that we learn more dense
here's what I mean
so if you if you perform convolution
between an input and a feature matrix or
a weight matrix or filter it's going to
result in a matrix right but this matrix
is going to be pretty big it's going to
be a pretty big matrix what we can do is
we can take the most important parts of
that matrix and pass that on and what
that's going to do is it's going to
reduce the computational complexity of
our model okay so that's what pooling is
all about to pooling tester there's
different types of pooling max pooling
is the most used type of pooling by the
way
it'll basically multiply so what happens
is we strive we have some we define some
windows size and then construed size so
how what are the intervals that we look
at and we say okay so for each of these
windows let's take the max value so for
so for this one right here for 6 0 8 the
max value would be 8 and so for 1 3 12 9
OB 12 right so we just take the biggest
number it's really simple actually we
just take the biggest number and we just
do that for all of them and that that's
what pooling is all about and so it's
going to just give us that the most
relevant parts of the image if you think
of these these verities values in the ND
matrix as pixel intensities by taking
the maximum intense the the pixel with
the most intensity or the the highest
intensity we're getting that feature
that is the most relevant you see what
I'm saying it's a least opaque feature
to use the term from image math anyway
so we talked about pooling and we talked
about we talked about activation and so
now now we talked about convolution and
we talked about pooling and so now the
third part is normalization or
activation so remember how I said how it
would be it's so important that
have these values that are not related
to our image b0 we want them to be zero
so the result is zero if the if the
feature is not detected well the way we
do that is using riilu and to relive
stands for rectified linear unit it's an
activation function
it's an activation function okay we use
activation functions throughout new york
neural networks and we use them because
it is you can also call them
nonlinearities because they make our
model able to learn non-linear functions
not just linear functions but non-linear
functions so any kind of function right
the universal function approximation
theorem we talked about that activation
functions helped make this happen and so
riilu is a specific special kind of
activation function that turns all
negative numbers into zero so that's why
it's going to make the math easier it
won't make the math break for our
convolutional networks will apply reloop
so basically what we do is for every
single pixel value in the in the input
to this riilu activation function we
turn it if it's a negative we just say
make a zero it's super simple it will be
one line of code you'll see exactly what
I'm talking about okay so that's that's
those are our blocks so that's how our
convolutional blocks work however there
is another step that I didn't talk about
that is a nice-to-have and
state-of-the-art convolutional networks
always use it and that's called dropout
so Geoffrey Hinton the guy who invented
neural networks invented a feature
invented a technique called dropout and
what dropout is is a good analogy is old
people or not old people but people who
are stuck in their ways let me let me
okay so what dropout does is it turns
neurons on and off randomly what do I
mean by that that I mean the matrices
for each weight value is converted to
zero randomly at some layer of the
network and so what happens is by doing
this our network is forced to learn new
representations for the data new
pathways that that data has to flow
through it can't always flow through
this neuron and the reason we use it is
to prevent overfitting right we want to
prevent overfitting we've born
preventing to fit to the data
think of it as you know the older you
get the more
and your ways of thinking you're you are
right and so it's harder to think of new
ways of thinking right because you're so
set in some ways so a way to prevent
that is to have a novel crazy experience
whether it's skydiving or taking
psychedelics or whatever it is and what
that does is it creates new pathways so
you're not so you're kind of forced your
brain is forced to make new pathways and
this increases your generalization
ability and you're not so over fit
that's a very rough abstract analogy but
basically dropout is not as complexify
sounds dropped out can be done in three
lines of code so definitely check out
this blog post as well that I've linked
but what it does is it just randomly
pick some neurons in a layer to set to
zero right so it's just it's just three
lines okay and you can look at it in
this notebook right so that's and then
our last step is probability conversion
so we've got this huge set of values
right all these little small images that
are represented by this huge output
matrix and we want to take this huge set
of values and make some sense out of it
we want to make probabilities out of it
and the way we do that is using a soft
max at the end a soft max is the type of
function and it looks like this this is
a soft max function right here but what
we do is we plug these values into the
soft max function and it's going to
output a set of probability values
discrete probability values for each of
the classes that we're trying to predict
okay and then what we'll do is given all
those probability values we'll pick the
biggest one using our max the Arg max
function in numpy and that's going to
give us the most likely class okay those
are the seven steps of a feat a
full-forward task through a
convolutional network looks like that
and so now you might be wondering well
okay so how do we train this thing well
using gradient descent right and one
apply to neural networks gradient
gradient descent is called back
propagation exactly I hope you got that
right anyway okay so how do we learn
these magic numbers right how do we
learn what these weight values should be
what the feature should be back
propagation is how we do it right and so
we've talked quite a bit about back
propagation and gradient descent but
I'll do a little
over it again but the idea is that we
have some error that we're computing
right this is super supervised learning
we have a we have a human label right
for some data so we put in a dog image
or a bicycle image to look at this image
to look to relate to this image here we
put in a bicycle image in the bike label
we pass it through the each layer dot
product dot product up you know dot
product activation function pool dot
product repeat repeat softmax or squash
into probability values pick the biggest
one and we have some prediction value
and what we do is we compare the
prediction value to the out the actual
value and we get an error and we take
our error and we compute the partial
derivative of the error with respect to
each weight value going backwards in the
network okay like this okay and so for
regression we use the mean squared error
if we're using linear regression
regression and for classification we use
the softmax function so remember how in
the first neural network we built an in
there linear regression example we use a
we use mean squared error to compute the
error and now we're using the softmax so
we'll take the so we'll take the partial
derivative of the error with respect to
our weights and then that's going to
give us the gradient value that we then
update each of those weight values
recursively going backward in the
network and that's how it learns what
those features what the ideal feature
the weight matrix value should be but
what about the other what about the
other magic numbers what about the
number of neurons and the number of
features and the size of those features
in the pooling window side and the
windows tried well those that is an
active area of research there are best
practices for values that you should use
for those for those hyper parameters
right the tuning knobs of our network
and andrey karpati had some great
material on this he's probably the
leading source for convolutional
networks right now in terms of written
content and yeah I mean this is an
active area of research finding out what
the ideal hyper parameters for our
neural network should be and we're still
learning what it should be what what
what how we can get them rather than
just guessing and checking which is what
we do right now which is kind of like
you know not is not as optimal right so
anyway last two things now we're going
to
with the code when is it the time to use
this well we know it to classify images
we've talked about that but you can also
use them to generate images and that's
for later on that's a little more
advanced but to give you a little
spoiler or a little teaser in fact this
is a my entra deep learning playlist you
take a convolutional Network you flip it
and then you call it a d-- convolutional
network and then you can take some text
and create an image out of text how
crazy is that okay
there's also generative models where you
have two networks fighting each other
and you can generate new images a whole
bunch of really cool crazies and stuff
you can do but anyway when should you
use a convolutional Network anytime you
have spatial 2d or 3d data what do I
mean well obviously images are spatial
the word spatial implies that the space
the positioning of the data matters so
sound you can apply to sound images or
text where the the the position of the
text matters right because we have a
flashlight or filter and we're
convolving over an image right but if
you have some data like say customer
data or if you were to just flip the
rows and columns it doesn't matter what
order they're in they're still you know
they're still features so a good rule of
thumb is if you swap out the rows and
columns of your data set and it's just
as useful like the space doesn't matter
then you don't want to use a CNN it
helps you do okay and a great and last
thing the great example of using CNN's
are for robot learning you can use a CNN
for object detection and you can use a
CNN for grasp learning and combine the
two and then you can get a robot that
cooks which is really cool I've got a
great tensorflow example and a great
adversarial networks example okay let's
go into the code now and so what I'm
going to do is I'm going to look at the
class for the convolutional network in
dump i as well as the prediction class
there's two classes here okay so these
are our three inputs pickle is for
saving and loading our serialized model
what do I mean
pickle is pythons way of having a
platform or language agnostic way of
saving data so you can load it up later
tentacle uses it a bunch of other
libraries use it as well num pies or
matrix math and we've got our own little
custom class for pre-processing the data
because we don't care about that part we
care about the machine learning part
okay so
let's talk about our light OCR or object
optical character recognition class in
our initialize function we're going to
load the weights from the pickle file
and then store it and then store all the
labels that we've loaded we'll define
how many rows and columns in an image
load up our convolutional networks using
the light CNN function with our saved
weights so assuming we've already
trained our network we load it with the
saved weights from the pickle file and
then we defined a number of pooling
letters okay so once we have that then
we can use this predict function so
given some new image we'll reshape the
image so it's in the correct size to
perform the dot product between that
image and the first layer of our
convolutional Network and will it will
we'll put it we'll feed it into our
network and it's going to output a
prediction probability for a class and
we'll return it okay super-high level we
haven't even coated our CNN that's
that's our first class that's a
prediction class now now we're going to
look at the convolutional Network class
and what I'm going to do is I'm going to
I'm going to go over the code and I'm
going to code some parts of it so now
we'll look at our convolutional Network
class okay so in our initialize function
will initialize two lists one to store
the layers that we've learned the the
weights of each layer and then the size
of the pooling area for max pooling okay
we'll load up our weights from our
pickle file just like this and then we
have our predict function know in our
predict function that's where the real
magic is happening right let's code what
this looks like so given some input X
we're going to feed it through all of
these layers right and so what happens
is we will say okay so the first layer
is going to be a convolutional layer
okay we're going to define what all of
these functions look like look like but
the first layer is going to be that
convolutional layer will feed in that
first image and we'll say okay well this
is the first layers with a zeroth layer
will say border mode equals full and
I'll talk about that part later on but
that's it for that and so what happens
is X equals this layer okay so that's
our first layer and then our next layer
is going to be real ooh
so we'll say okay now let's apply an
activation to the outputs of the
previous layer okay and then we'll say
equal to that okay so we'll set the
output from the previous letter equal to
the input of this player and then we
keep going we'd say okay so we've got
another CNN we have another
convolutional layer and we do the same
thing here we say okay take the in
output from the previous layer we'll
define what the name of this layer is as
well as a border mode which I'll talk
about the very end of this we have a
border mode which is valid and then we
say okay well we'll set the output of
that equal to the input of this and just
keep repeating now it's time for us to
apply a nother non-linearity so we'll
just go ahead and apply our
non-linearity again remember these are
convolutional blocks oh and we also want
to pool so also the order with which you
can do this varies right you can do this
in different ways and yeah so I'm doing
in a certain way right now you know we
could change it around it would change
our result but the order map the
ordering within the block it can be can
be different okay so right so we're
going to pool it's we're going to pick
the most relevant features from from
that from that output and then we're
going to perform dropout to prevent
overfitting and we're going to say
there's going to be 0.25 percent chance
that a neuron is going to be deactivated
that will turn it off set it to zero and
that's our dropout probability value and
then now we're getting into our our the
second category of our network not the
feature learning part for the
classification part and we'll say ok so
let's flatten this layer let's reduce
the dimensionality of all that that data
so it's something that we can then learn
from and say well let's put 7 equal to 7
and then we'll say once again turn that
output into our inputs here okay and so
then we have another dense layer we just
we just keep going with our first dense
layer and that means we're going to it's
a fully connected layer so we're
combining everything that we've learned
because we're getting really close to
squashing these values into a set of
probability values so we want to take
all of our learnings and combine them
with a fully connected layer
and so we'll combine them with a fully
connect layer and then we'll squash it
now with our sigmoid or no not our
sigmoid our softmax function okay and
then that's going to give us our output
probability and then we're going to say
well which of the probabilities do we
want we want them max one right we want
the max probability and we'll classify
it just like that and return that value
okay that's the highest level and so if
you're using Kaos or one of these high
level libraries this is all your code
would look like but we're going to do is
we're going to look at these functions
as well okay so let's look at these
functions you'll start off with the
convolutional layer function and have
your notebook open with me as well so
you could go over this the link is in
the description if you don't know now
you know if you don't know now you know
so for our convolutional layer given
some input image we're going to say well
we'll store our feature maps and the
bias value in these two variables
features and bias will define how big
our filter or patch is going to be how
many features do we want how big is our
image how many channels RGB so 3 and
then how many images do we have so given
those values we'll define a border mode
so a border mode so is so when you apply
full to border mode in this case it
means that the filter has to go outside
the bounds of the input by filter size
divided by 2 the area outside of the
input is normally padded with zeros and
the border mode valid is when you get an
output that it's smaller than the input
because the convolution is only computed
where the input and the filter fully
overlap ok and they'll give us different
they'll give us different classification
results accuracy results and it's good
to test both options so what we'll do is
we'll initialize our feature matrix for
this layer as convolve zeros it's going
to be a bunch of zeros and then we'll
say ok so for every image that we have
for every feature in that image let's
initialize a convolve image as empty and
then for each channels or doing it for
each of the 3 channels let's extract the
feature from our feature map define a
channel specific part of our image and
then perform convolution on our image
using that given feature filter so
notice this convolve 2d function it's
where
actual convolution operation is
happening this is more of a wrapper for
that actual mathematical operation so
once we have that we'll add a bias and a
bias
acts as our anchor for our network it's
kind of at the y-intercept it's kind of
like a starting point for our model to
exist and then we'll add it to our list
of convolve features for this for this
layer okay and it will return that as
our feature map our set of filter values
our weight matrices and so let's look at
this convolve to the function so in our
convolve 2d function will define the
tensor dimension of the image and the
feature will get a target dimension and
then these two lines perform this this
operation this convolution theorem that
we defined right here or performing a
dot product between the input and the
kernel or feature for for all of those
weight values and then we're summing
them all up and that's going to be our
output and so the fast Fourier function
in numpy does this very well and so we
can just use that as FFT to but that's
it's a multiplication and a summation
operation okay and so then we have our
target value and then once we have our
target value we could say okay let's
have a starting point and an ending
point and our target value is going to
be within that range of what we want to
return as the convolve feature right so
we have some bounding box that we want
to apply this to okay so then so we have
that so what else do we have so we start
off with our convolutional layer and
then we had our riilu so what is really
really super simple riilu riilu is just
forgiving so for for some matrix of
zeros it will go through every single
pixel value in the input matrix and if
it's a negative number we just turn it
into zero that's it that's real ooh okay
and then so we have we had talked about
real ooh we've talked about convolution
we have to talk about pooling so what
does max pooling look like so given our
learned features and our images let's
initialize our more dense feature lists
as empty and so here's what we do we're
going to we're going to take the max
values of all of those parts of the
input image right so we can say we're
going to say for each image and for each
feature map the
by the RO the finest starting an ending
point okay which we define with our pool
size hyper parameter and so for each
columns we've got a set of rows and
columns for each image there's a notice
a lot of nesting happening here we're
going to define start and end points for
the columns as well and then we're going
to say define a patch given our define
starting and ending points there's some
some bounding box and then take the max
value from that patch using NP dot max
and that patch is what moves around
right for all parts of that image and
then we return that and we're going to
store all of that in our pooled features
of matrix right here and we return that
as the output and that's what we pass on
in the convolutional Network okay so
that's what max pooling is okay so we
talked about convolution riilu max
pooling and then drop out so for
dropouts right we have our probability
value that we define is 0.25 and we just
multiply it by the input okay and that
what that's going to do is going to turn
on or off some part of the matrix into
so on and off I mean 0 will make it
either 0 or not 0 so it will so then our
data will have to learn to either be
multiplied by it or find a different
pathway that's where dropout and then we
talked about drop valve and convolution
flattening dense and softmax so for
flattening it's just it's a tensor
transformation we just reduce the
dimensionality of the input okay and
then for our dense layer our dent is our
fully connected layer now this is the
generic layer that you would see in a
fee for network input times weight and
then you add a bias right which is the
dot product right here this is this is a
dense layer we just take our inputs and
away at a bias that means we just
perform the dot product between the full
weight matrix and the full weight matrix
instead of doing it at all the layers
because that would be way to computation
computationally expensive for image data
we perform it as one fully one fully
connected or dense layer at the end and
that's a way for us to combine all of
our learnings together so we can then
promptly squash it with a soft max
function
okay so then for our a softmax layer and
then we have classify so for our softmax
layer we will so this is the this is the
formula for softmax programmatically
speaking but what it does is going to
output a set of probability values and
then we'll classify those values by
taking the R max the largest probability
and that is our output okay so that is
our forward pass through the network
okay
and so yes that is our forward pass
through the network so back so back
propagation works pretty much the same
way as I've talked about before several
times graded send back propagation works
the same way we take the partial
derivative of our error with respect to
our waste and then recursively update
our weights using that gradient value
that we gradient equals partial
derivative equals Delta interchangeable
words but here's a great simple example
right here where we after the forward
pass we do the same thing in reverse
order so we calculate the gradient of
those weights and then back and then
multiply them by the previous layer and
then for our JavaScript portion we are
taking the drawing from the user here's
the main code for that paint window in a
canvas and we are going to say capture
the mouse's positions capture all those
points in that image with an event
listener and we're going to say on paint
so whenever the user actually starts
moving that painting whenever that mouse
stops clicking and then the user hits
the submit button will save that
snapshot of that image and then feed
that into the network and that's our
flask app we'll define two routes one
for our home and then one for that image
for the network we can deploy to the web
there's a Heroku app you could
definitely check out the link link is in
the description as well check out the
notebook and yeah that's it please
subscribe for more programming videos
and for now I've got to do a Fourier
transform so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>