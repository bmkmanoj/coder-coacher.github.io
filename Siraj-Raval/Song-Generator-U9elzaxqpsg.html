<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Song Generator | Coder Coacher - Coaching Coders</title><meta content="Song Generator - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Song Generator</b></h2><h5 class="post__date">2017-12-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/U9elzaxqpsg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and have you ever
wanted to create songs using AI it's
totally possible and I've got my friend
Taryn here to help me explain how it all
works thank you for having me time I've
been watching your videos for a while
and very excited about this moment in
time thank you
hey everybody I'm Taryn southern and
I've been a youtuber for quite a long
time got my start making music videos on
YouTube about 10 years ago and recently
released my first single off of my
upcoming album which is composed
entirely with artificial intelligence as
Suraj said so really been exciting to
work with this new medium totally it's
super cool you guys got to check it out
links are gonna be in the description
okay so why did you want to create songs
using AI I think it it seemed like a
great challenge you know I just I like
doing things that I haven't done before
music creation has always been a little
bit of a mystery to me because I don't
play instruments
I grew up trying to learn how to play
guitar but my hands were so small and
not very nimble across the guitar that I
basically gave up I played a little bit
of piano but I had this narcoleptic
piano teacher who would fall asleep
halfway through the lesson so that
didn't work out so well either so for me
writing music in my in my 20s in
adulthood really just became about
writing by ear and so when I found the
first pieces a few pieces of software
that could actually write music using
code I got really excited because I
thought now finally someone like me that
doesn't play instruments could
potentially make the music that I hear
in my head with this new collaboration
partner so it was an exciting challenge
and it's like crossing new frontier yeah
I mean who does that I mean and this new
partner being AI yep and they never get
tired or hungry I don't need to have
Doritos anyway and if you don't like
their song you just throw it out you
throw it out the window
it's gone it's gone it's out of here
okay so so tell us about the process you
used to do this what
yeah so it's different depending on the
software and there are now a number of
different AI software companies out
there that can compose music from Google
magenta to ampere to AI music I've IBM
Watson like I'm forgetting some of the
main ones I'm collaborating so the all
function differently depending on the
neural network and how the how the
engineer has actually created the
interface so I will say that the easiest
one to use if you just want to get
started and understand what kinds of
things say I can actually create
musically damper and that's the one that
I used for the single that I released in
September called break free the cool
thing about ampere is it actually
produces all of the music so what I mean
by that is all the instrumentation that
you hear in that song is actually put
together using AI it wasn't it was not a
musical track composed by AI performed
by humans so it gives you a sense of
what's possible because it's actually
really hard to take random musical
sounds and put them together into
something cohesive that sounds good
so I would start with ampere that's
that's my cut Tiggy
that's a Suraj's backpack oh don't do
that
she's destroying your backpack I'll just
have an AI make one with generative
adversarial networks right okay perfect
perfect so if you're looking to do the
most basic kind of introductory lesson
in AI music creation I would go to
ampere if you are familiar with code and
you want to get your hands a little bit
dirty I would say Google magenta or IBM
Watson are great places to go google
magenta their software and I have a
number of different programs available
for AI music writing but two different
things it's all available on github I
believe I think and IBM Watson is
actually releasing their software open
source in January and I've been using
that the last month to write stuff and I
love it it's cool so you do need to have
knowledge coding knowledge you'll be
using terminal to write most of your
songs
yeah I had to like for the first couple
weeks on it I was calling their
developers being like wait how do I do
this thing so basically with a program
like Watson or magenta you're going to
set different musical parameters like
what type of song you want the AI to
create is it pop is it reggae is it a
mixture of reggae and pop what's the
tempo what's the you know what's the BPM
what are the instruments that you want
embedded into the track and in some
cases you can also give the AI a track
or a multitude of tracks to teach it
basic rules based on those tracks that
you like so if you want to make a song
that sounds like the Beatles you
basically just feed it a whole catalog
of Beatles songs it'll do its thing and
then you say I want the song that it
creates to be a reggae track so now
you've got a reggae track inspired by
the Beatles right so so there are a lot
of depending on how skilled you are at
coding there are a lot of ways that you
can take these these software's to do
really cool things there's a program in
Google called incent which allows you to
actually take two disparate sounds and
combine them together so I could
actually record my cat Iggy scratching
on Suraj's backpack and then combine
that with the sound of nails on a
chalkboard
to create a truly delightful he decided
to say hi this is the little runt that's
ruining the video what I can't even fake
you I don't really like cat stuff but
essentially I mean you even you can
create a whole an entirely new sound
using some of these tools and inject
that into your musical work so this all
goes to say that they function
differently depending on what you choose
to use and your coding knowledge and
your musical knowledge but it is
absolutely untrue that using AI is not a
creative process it's so creative
because there are so many different
avenues that you can take in creating a
song and creating new sounds and I
actually think that it has the ability
to bring out the super composer in all
of us
totally awesome so how does amber make
this all happen
well it's proprietary technology so
we're out of luck see you next time just
kidding
we can totally reverse-engineer how it's
very likely done looking at some of the
latest research in deep learning we know
that one popular way to class machine
learning algorithms is in two categories
of generative and discriminative models
discriminative models classify data in
two sets of categories they allow us to
differentiate between different types of
data generative models on the other hand
offer even more exciting possibilities
creating new data after going through a
training phase one type of generative
model are called the audio synthesis
models these are useful across a range
of applications that we use day-to-day
including text speech systems the kind
that Google Translate uses to help
dictate what you've just translated or
the kind that voice assistants use to
respond to our requests generic
synthesizers have been used in music
extensively and have a long history in
that field for DJ's - terrible hip-hop
producers like t-pain they're usually
hand designed in-house that gets
acceptable signals like pitch and
velocity to shake the tone and dynamic
of a sound synthesizers have had a huge
impact on culture and music the past few
decades as some of the most popular
sounds out there have used them so the
traditional way of doing this will so
use some sort of arrangement of
oscillators or an algorithm for sampling
playback but a newer way to do this is
by using a data-driven approach that is
letting an algorithm learn from musical
data it's possible to create new types
of expressive and realistic instrumental
sounds using deep learning
we know that deep learning allows us to
learn features from data and in the case
of music these features can represent
tone timbre dynamics Krunk ness all of
these can be tunable knobs for music
generator google has been at the
forefront of a lot of progress in AI
generated music and they have an open
source project call
magenta magenta embodies a lot of the
recent models that have been published
in that field
a more recent model just published a few
months ago used two concepts together
the first was a wavenet style auto
encoder that learns temporal hidden
nodes to capture longer-term structure
exactly and the second was called incent
which is an enormous data set of music
that can be used to explore neural audio
synthesis of musical notes just like I
mentioned earlier so incense contains
about 300,000 four-second annotated
notes from about a thousand musical
instruments an order of a magnitude more
than any other similar data set so it's
pretty powerful I'm like I said you can
combine sounds of your cat with I don't
know anything anything which is pretty
cool deep neck criticism call wavenet it
generated raw audio waveforms and
Weidman models the conditional
probability of two of a waveform to
generate new music it uses all previous
samples and other parameters to do this
the authors of our audio synthesis paper
were inspired by that model to create
something similar to weight net there
were two motivations here the first was
to be able to create music that had a
consistent long-term structure so that
the theme would carry out through the
end of the piece unlike anything off of
eases the second was to use the learned
features for applications by using
meaningful audio interpolations like
between different instruments for
example like what what turned it in the
original wavenet architecture and each
step of training a stack of dilated
convolutions predicted the next sample
of audio from a fixed size input a prior
sample values the joint probability of
some audio was factorized as a product
of conditional probabilities between the
different ways but these researchers
remove the need for external
conditioning instead it works as an
autoencoder a generic one taking in raw
audio waveform as input from which the
encoder produces an embedded then they
shifted the same input and fed it back
to the D color which reproduce the wait
input waveform so using the joint
probability they could parameter eyes a
feature as a latent variable to train
the model they use gradient descent the
most popular optimization scheme out
there shoutout to grade a descent and it
uses the difference between the
predicted output and the actual output
as an error value then using that error
it calculates a gradient and using that
gradient it subsequently updates the
weight values of the network over time
to give it better predictions it was
trained over eighteen hundred thousand
iterations a really long time for the
training data even though ensign
annotated every single note using its
unique pitch and timbre and dynamics
they decide to further annotate it
giving each sound a source a family of
instruments and a sonic quality even
though training this type of deep
learning model requires a massive amount
of computing power you could just
download a model from github and run it
on google cloud or AWS this stuff is
democratized so you have access to
computing power if you use the cloud or
you could just pull model off of the
magenta github page or use experiments
google.com and play with it in your
browser so three things to remember here
generative machine learning models that
can learn latent variables from a data
set can be used to generate new data
similar to the training set you can use
a wavenet style auto encoder and the end
synth data set if you'd like to
experiment with state-of-the-art machine
learning from music generation and
wavenet is perhaps the most powerful
model out there to perform audio
generation you have a really smart
audience all about them they're very
smart if you want to see more AI music
you can follow me at youtube.com slash
Teheran there we go
please subscribe for more programming
videos and I think we gotta go we gotta
go make some AI music that's true so
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>