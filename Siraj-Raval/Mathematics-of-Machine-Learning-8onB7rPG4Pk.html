<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Mathematics of Machine Learning | Coder Coacher - Coaching Coders</title><meta content="Mathematics of Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Mathematics of Machine Learning</b></h2><h5 class="post__date">2018-03-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8onB7rPG4Pk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and the
mathematics of machine learning is it
necessary to know math for machine
learning absolutely machine learning is
math it's all math in this video I'm
gonna help you understand why we use
math in machine learning by example
machine learning is all about creating
an algorithm that can learn from data to
make a prediction that prediction could
be what an object in a picture looks
like or what the next price for gasoline
might be in a certain country or what
the best combination of drugs to cure a
certain disease might be machine
learning is built on mathematical
prerequisites and sometimes it feels
like learning them might be a bit
overwhelming but it isn't or is it no
it's not as long as you understand why
they're used
it'll make machine learning a lot more
fun you can have a full time job doing
machine learning and not know a single
thing about the math behind the
functions you're using but that's no fun
is it you want to know why something
works and why one model is better than
another machine learning is powered by
the diamond of statistics calculus
linear algebra and probability
statistics is at the core of everything
calculus tells us how to learn and
optimize our model linear algebra makes
running these algorithms feasible on
massive data sets and probability helps
predict the likelihood of an event
occurring so let's start from scratch
with an interesting problem the problem
is to predict the price of an apartment
in an up-and-coming neighborhood in New
York City let's say Harlem shout-out to
Harlem yo Westside represent okay let's
say that all we'll know when we
eventually make a prediction is the
price per square foot of a given
apartment that's the only marker we'll
use to predict the price of the
apartment as a whole and love
for us we've got a data set of
apartments with two columns in the first
column we've got the price per square
foot of an apartment in the second
column we've got the price of the
apartment as a whole there's got to be
some kind of correlation here and if we
build a predictive model we can learn
what that correlation is so that in the
future if all we're given is the price
per square foot of a house we can
predict the price of it if we were to
graph out this data let's graph this out
with the x-axis measuring the price per
square foot and the y-axis measuring the
price of a house it would be a scatter
plot ideally we could find a line that
intersects as many data points as
possible and then we could just plug in
some input data into our line and out
comes the prediction poof in mathematics
the field of statistics acts as a
collection of techniques that extract
useful information from data it's a tool
for creating an understanding from a set
of numbers statistical inference is the
process of making a prediction about a
larger population of data based on a
smaller sample as in what can we infer
about a populations parameters based on
a sample statistic sounds pretty similar
to what we're trying to do right now
right since we're trying to create a
line we'll use a statistical inference
technique called linear regression this
allows us to summarize and study the
relationship between two variables a
lemma one variable X is regarded as the
independent variable the other variable
Y is regarded as the dependent variable
the way we can represent linear
regression is by using the equation y
equals MX plus B Y is the prediction X
is the input B is the point where the
line intersects the y-axis and M is the
slope of the line we already know what
the x value would be and why is our
prediction if we had M and B we would
have a full equation plug and play easy
prediction but the question is how do we
get these variables
naive way would be for us to just try
out a bunch of different values over and
over and over again and plot the line
over time using our eyes we could try
and estimate just how well fit the line
we draw is but that doesn't seem
efficient does it we do know there
exists some ideal values for M and B
such that the line when drawn using
those values would be the best fit for
our data set let's say we did have a
bunch of time on our hands and we
decided to try out a bunch of predicted
values for M and B we need some way of
measuring how good our predicted values
are we'll need to use what's called an
error function an error function will
tell us how far off the actual Y value
is from our predicted value there are
lots of different types of statistical
error functions out there but let's just
try a simple one called least squares
this is what it looks like we'll make an
apartment price prediction for each of
our data points based on our own
intuition we can use this function to
double check against the actual
apartment price value it will subtract
each predicted value from the actual
value and then it will square each of
those differences the Sigma that little
a looking thing denotes that we are
doing this not just for one data point
but for every single data point we have
M data points to be specific this is our
total error value we can create a three
dimensional graph now we know the x axis
and the y axis they will be all the
potential m and B values respectively
but let's add another axis the z axis
and on the z axis would be all the
potential error values for every single
combination of M and B if we were to
actually graph this out it would look
just like this this kind of bowl like
shape Cup it firmly in your hand like a
nice bowl if we find that data point at
the bottom of the bowl the smallest
error value that would be our ideal m
and B values that would give us the line
of best fit but how do we actually do
that
now we need to borrow from the math
discipline
as calculus the study of change it's got
an optimization technique called
gradient descent that will help us
discover the minimum value iteratively
it will use the error for a given data
point to compute what's called the
gradient of our unknown variable and we
can use the gradient to update our two
variables then we'll move on to the next
data point and repeat the process over
and over and over again slowly like a
ball rolling down a bowl we'll find what
our minimum value is see calculus helps
us find the direction of change in what
direction should we change the unknown
variables MMB in our function such that
its prediction is more optimal aka the
error is smallest
but apartment prices don't just depend
on the price per square foot right
also included are different features
like the number of bedrooms and the
number of bathrooms as well as the
average price of homes within a mile if
we factored in those features as well
our regression line would look more like
this
there are now multiple variables to
consider so we can call it a
multivariate regression problem the
branch of math concerned with the study
of multivariate spaces and the linear
transformations between them is called
linear algebra it gives us a set of
operations that we can perform on groups
of numbers known as matrices our
training set now becomes an M by I
matrix of M samples that have I feature
x' instead of a single variable with a
weight each of the features has a weight
so that's an example of how three of the
four main branches of math dealing with
machine learning are used but what about
the fourth probability all right so
let's just scratch this example what if
instead of predicting the price of an
apartment we want to predict whether or
not it's in prime condition or not we
want to be able to classify a house with
the probability of it being prime or not
prime
probability is the measure of likelihood
of something we can use a probabilistic
technique called logistic regression to
help us do this since this time our data
is categorical as in it has different
categories or classes instead of
predicting a value or predicting the
probability of an occurrence since the
probability goes between 0 and 100 we
can't use an infinitely stretching line
we're left with some threshold passed
some point X we are more likely than not
looking at a prime house we'll use an
s-shaped curve given by the sigmoid
function to do this once we optimize our
function will plug in input data and get
a probabilistic class value just like
that
so to summarize machine learning
consists mainly of statistics calculus
linear algebra and probability theory
calculus tells us how to optimize linear
algebra makes executing algorithms
feasible on massive data sets
probability helps predict the likelihood
of a certain outcome and statistics
tells us what our goal is
this week's coding challenge is to
create a logistic regression model from
scratch in Python on an interesting data
set
github links go in the comment section
and winners will be announced in a week
please subscribe for more programming
videos and for now I've got to build
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>