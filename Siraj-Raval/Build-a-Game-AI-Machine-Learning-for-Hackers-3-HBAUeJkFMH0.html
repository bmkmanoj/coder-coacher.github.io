<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Game AI - Machine Learning for Hackers #3 | Coder Coacher - Coaching Coders</title><meta content="Build a Game AI - Machine Learning for Hackers #3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Game AI - Machine Learning for Hackers #3</b></h2><h5 class="post__date">2016-05-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HBAUeJkFMH0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yes I beat it did that impress you if I
built an AI of beat this for me would
that impress you hello world welcome to
serology in this episode we're going to
build an AI to beat a bunch of Atari
games games have had a long history of
being a testbed for AI ever since the
days of pong traditionally game
programmers have taken a reductionist
approach to building AI they've reduced
the simulated wall to a model and had
the AI act on prior knowledge of that
model and it worked out for the most
part I guess not really but what if we
want to build an AI that can be used in
several different types of game world
all the world models are different so we
couldn't just feed it in one world model
instead of modeling the world we need to
model the mind we want to create an AI
that can become a pro at any game we
throw at it so in thinking about this
problem we have to ask ourselves what is
the dopest way of doing this well the
london-based startup deep mind already
did this in 2015 the minds goal is to
create a GI that's one algorithm that
can solve any problem with human level
thinking or greater they reach an
important milestone by creating an
algorithm that was able to master 49
different Atari games with no game
specific tuning whatsoever the algorithm
is called the DQ learner and it was
recently made open source on github it
only takes two inputs the raw pixels of
the game and the game's core that's it
based on just that it has to complete
its objective maximize a score let's
dive into how this works since we'll
want to recreate the results first it
uses a deep convolutional neural network
to interpret the pixels this is a type
of neural network inspired by how our
visual cortex operates and expects
images as inputs images are high
dimensional data so we need to reduce
number of connections each neuron has to
avoid overfitting overfitting by the way
is when your model is too complex there
are too many parameters and so it's
overly tuned to the data you've given it
and won't generalize well for any new
data set so unlike a regular neural
network CNN's layers are stacked in
three dimensions and this makes it easy
to connect each neuron only two neurons
in its local region instead of every
single other neuron each layer acts as a
detection filter for the presence of
specific features in an image and the
layers get increasingly abstract with
feature representation so the first
layer could be a simple feature like
edges and then the next I would use
those edges to the text and shapes and
the next one would use those shape to
detect something even more complex like
kanye these hierarchical layers of
distraction are what neural nets do
really well like really well so once
it's interpreted the pixels it needs to
act on that knowledge in some way in a
previous episode we talked about
supervised and unsupervised learning but
wait
Ares ago
name is Johnson it's called
reinforcement learning reinforcement
learning is all about trial and error
it's about teaching an AI to select
actions to maximize future rewards it's
similar to how you would train a dog if
the dog fetches the ball you give it a
treat if it doesn't then you withhold
the tree so while the game is running at
each time step the AI execute an action
based on what it observes and may or may
not receive a reward if it doesn't
receive a reward well just our weights
so that the AI will be likely to do a
similar action in the future Q learning
is a type of reinforcement learning that
learns the optimal action selections
behavior for the AI without having a
prior model of the environment so based
on the current game state like an enemy
space shipping and shooting distance the
AI will eventually know to take the
action of shooting it this mapping of
state to action is its policy and it
gets better and better with training DQ
also uses something called experience
replay which means the AI learns from
the data set of its past policies as
well so we're going to build our game
bot in just 10 lines of Python using a
combination of tensorflow
and gin tensorflow is Google's ML
library which we'll use to create our
CNN and Jim is open AIS ml library which
we'll use to create our reinforcement
learning algorithm and set up our
environment oh if you haven't heard
opening eye is a nonprofit AI research
lab focused on creating AGI in an
open-source way they've got a billion
bucks supplied from people like Elon
Musk
good luck much' to get the busted let's
start off by importing our dependencies
environment is our helper class that
will help initialize our game
environment in our case this would be
space invaders but we can easily switch
that out to a whole host of different
environments Jim is very modular opening
I wants it to be a gym for AI agents a
training and get better you can submit
your algorithms their site for an
evaluation they'll score it against a
set of server-side metrics I approve
we'll also want to import our deep Q
Network helper class to help observe the
game in our training class to initialize
a reinforcement learning
once we've imported our dependencies we
can go ahead and initialize our
environment we'll set the parameters to
space invaders and then initialize our
agent using our dqn helper class with
the environment and environment type at
the parameters once we have that we can
start training by running the trainer
class with the agent as the parameter
first this will populate our initial
replayed memory with 50,000 plays so we
have a little experience to train with
then it will initialize our CNN to start
reading in pixels and our cue learning
algorithm to start updating our agents
decisions based on the pixels it
receives this is an implementation of
the classic agent environment loop each
time set the agent chooses an action and
the environment returns an officer
raishin and a reward the observation is
raw pixel data which we can feed into
our CNN and the reward is a number we
can use to help improve our next actions
Jim neatly returns these parameters to
use via the step function which we
brought in the environment helper class
since we started training we can start
the game with the play function of our
Asian object we can go ahead and run
this in terminal and the space invaders
window should pop up and will start
seeing the AI start attempting to play
the game
it'll be hilariously bad at first but
will slowly get better with time the AI
will get more difficult to defeat the
longer you train it and ideally you can
apply to any game you create but more
info check out the links down below and
please subscribe for more machine
learning videos for now I've got to go
fix a runtime error so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>