<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Predict Music You Love (LIVE) | Coder Coacher - Coaching Coders</title><meta content="How to Predict Music You Love (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>How to Predict Music You Love (LIVE)</b></h2><h5 class="post__date">2017-02-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/18adykNGhHU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay
ok it's working ok guys oh my god it was
open broadcaster software I can you guys
bring everyone over here so if you still
had that other lesson you just paste the
link to this in that in that chat
because I am never going to use open
broadcaster software again I'm only
using Google hangout alright okay so
it's fine now note everything is working
everything's better I'm live good to go
we got everybody in here great works
much better hi guys okay so we just
start off with a five-minute Q&amp;amp;A and
then we're going to start building a
recommender system okay we're going to
talk about several types of recommender
systems in this episode and we're going
to do it in the in an ipython notebook
okay
OBS sucks totally so let's start with a
five-minute ETA and then we get started
all right so come on give it to a Google
Hangouts right right I'm using Google
hey I've been using the whole hangouts
for since forever I just tried to do
something different because I wanted to
do up the quality of my stream but that
was just never again what projects are
you programming for fun right now I am
just making content I really wish I had
the time to just do some research make
some publications
but join a research group online but I
love making content even more so that's
what I'm doing right now if I wasn't the
project that would be working on is
probably trying to push the field
forward in terms of Bayesian like
probabilistic programming like trying to
move past the pointing to something that
requires less data in computation how
are you going to use are you can use
central and not this session Oh what do
you think of tensorflow fold I've never
heard of that
Lag came back um okay Tennant one
question isn't someone okay
you want at Google I don't apart from
your videos what do you recommend to
learn machine learning from uh Udacity
has great courses of udemy and also and
ruins course lag is not back lag is good
videos okay okay okay no lag thank you
okay so we're going to answer three more
questions then we're going to get right
into it because we've been lagging in
and doing some dumb things okay can you
suggest a math book for machine learning
I would recommend Khan Academy I would
actually not recommend a textbook
because every time I read a textbook it
just I don't absorb it you know like
I'll read it and I'll get it for a while
but after like a few months I'll forget
everything so the way to do it is not
just practice makes perfect but practice
makes retention you have to continuously
practice this stuff and the way to do
that is a cheat sheets and Khan Academy
like short bits of information as you go
in your journey okay rather than just
sit there read an entire textbook and
then forget it after a few months okay
how can I student get involved in
machine wedding research join a research
group online uh there are several if you
go to the machine learning subreddit
they have a they have a weekly reading
group so that would be a good place to
find people what do you think of data
camp data quest and similar of all great
projects I don't know about them in
Ithaca how many years have you been
studying on an offer like four years uh
what are your thoughts on C++ for ml and
D morning uh C++ is great I don't have
time to deal with deadlocks and like
syntax and the STD library or focus on
algorithms and that's why I use Python
can you recommend research topic for CS
student uh focused on unsupervised
learning and generative models can you
recomment how they go hand-in-hand
management like management for a company
uh-hmm
well you can try to find the if you if
you if you model your company as a
machine learning problem you can find
what tasks are most profitable for your
objective and your objective could be to
maximize profit for your company so if
you were to if you were to look at the
data of what people are doing in your
company you would put that in an Excel
spreadsheet and then you could find
those features that are most relevant
and then improve efficiency in those
areas okay so one more question and then
we're going to get started which is
reading books for anything in Harrison
Kinsley sent that YouTube channel yes in
Texas great he's
apparently the most you died on YouTube
but uh yeah he's a great guy okay so so
we're gonna start it up but but it's
wrong what you away Jay except from will
you make some time to make a video about
hyperforin or tuning yes Jake that is
coming up I remember shooting that is
coming up for sure because that's
something I need to talk about practice
makes permanent exactly so let's get
started uh but one thing is every time I
do this life starting to run out for me
to of freestyle so I'm just going to
freak saw off the dome right now on some
things if someone to say a topic and
then I'm just going to freestyle without
music I felt like last time was good but
it wasn't amazing so I want to make this
one amazing uh how do you get control
system with tensorflow that github link
what if Suraj is regenerated my machine
learning human learning robots okay
robots when I was in seventh grade I
made my first robot it float on the
floor like it was a little flow bot
I see the desk green enemies looking at
me telling me you can't make that no not
I said no I'm gonna make it anyway so I
went that and went my fiddle in place yo
I put meteors and other things together
and it made a little contraption man it
was against the weather it went out in
the rain it got no full short-circuits
it came back man it was my lurking back
okay so that was it okay so now we're
gonna get started with this and I didn't
build a robot in tenth grade it was more
like 10th grade okay so that was a
storytelling wrap and now we're going to
get started so let me start screen
sharing and then we're gonna do this so
guys let me give you the link to this by
the way so I have the link and we're
going to review this together and I'm
going to put it in the description so
okay so here's a link to the code let me
send you this the link to the code and I
want to give a shout out to some people
because I forgot about that nester Dan
siddhart Sidhant cup he'll uh Dan David
okay alpha okay so that was it 417
people here are watching I'm so excited
for recommender systems okay because
there's so much cool we can do with
this there's so much to talk about if I
recommend
okay so guys let me add this to the
description in real-time it boom link is
there in real-time now we're gonna start
screen sharing okay here we go what do I
want to screen sure I want it and share
my screen okay so now that we have that
let me minimize this Google hangout and
we are going to do this okay here we go
so let start the very beginning of this
let's look at the very very beginning
and I'm going to minimize my screen so
let's get started with this okay and let
me see here let me see here let me see
here let me see here okay great so I
mean maximize what we've got here we're
going to build a song recommender okay
so the data set we're gonna use is uh
also let me show myself because I need
to go mental new screen recording not
screen recording what is it was movie
recording okay there I am in the corner
hi okay all right so great so I'm there
like always so we're going to build a
song recommender and now how are we
going to do that how are we gonna build
a song recommender a recommender this is
a prop this is a problem that amazon has
Netflix has Hulu has every website has
this problem how do we personalize
content for users and how do we feed it
to them okay so that's what we're going
to try to that's what we're going to
think about this slice trick how do we
personalize content for users and feed
it to that okay and a dating recommender
we're going to do that too in the in the
next weekly video not not this video so
before we even if before me even think
about this let's talk about the goal of
recommender systems that you identify
relevant data for it users whether
that's articles movies games people
places in fact let me just let's just
look at what Amazon recommend it for me
okay let's see what it what is amazon
recommend for Suraj what do we got here
Valentine's Day that's not personalized
uh what do we got here
recommend inspired by your browsing
history okay
okay so if you look at this you would
think you know something's weird is
going on here I swear I needed costumes
for a video that I'm making but what it
did was it looked at what I've looked at
in the past and it recommended items
based on my past history okay and books
on machine learning so it's looking at
my past history but it's not just my
past its what other similar users have
looked at as well we're going to talk
about these different types of systems
in a second okay so I was looking at a
video I'm looking at making a video and
idea to costumes for that were anyway
I'm like a whole choir singing my name
anyway that's for the system so there
are three types of recommender systems
okay that we're going to talk about the
first one is content-based the second
one is collaborative and the third one
is popularity okay so we're going to go
through these step by step okay but
before we talk about any of these and
we're going to talk about them in depth
we're going to first load our music data
so let's look at our music data okay
what do we have for our music data uh
for our music data we are going to look
at two two files okay so the first one
is let's see what this is this is a lot
of songs okay there's a lot of songs
here and then the next one is the the
next database of songs so let's just
let's just look at the website for this
like what is this what is this data we
always want to analyze what that data is
that we have first before we do anything
what is that data that we have so this
is the data set and it's a mixture of
songs from a bunch of music websites and
user ratings okay so it's a collection
of songs and the ratings that user gives
users give data songs so last.fm is a
website first this is my jam second hand
songs it's a bunch of different uh
ratings by users of their favorite songs
that's what we're going to train our
model on okay now we have two different
data sets our job is to integrate this
data okay this is a very important part
of the tip data processing pipeline it
is we want to integrate this data okay
so to integrate this data we're going to
use pandas okay so what we first do is
we say okay here here are two files okay
and let me make this a little bigger
these are our two files once a CSD
one is uh is tripling okay these these
are these are triplets right up here the
triplet is user ID song ID and listen
town okay so we want to integrate these
two together so the first thing we'll do
is we will read the table out using
pandas and we'll store it in this
variable and then we'll say okay let's
define those three columns user ID song
ID and listen Cal then we're going to
read the metadata which is that other
file that we had and we're going to
store it in this variable song DF 2 so
DF means data frame so we have two data
frame uh two data frames and uh we're
going to combine them with pandas merge
function we're going to combine both
there and it's actually uh one one of
those up so whenever we whenever we're
integrating two datasets together
sometimes they're duplicate columns and
we can we can drop those duplicates and
replace them okay and the way we do that
is what we we specify uh what that
column is that's a duplicate so that we
can then replace it so in our case song
ID is the one duplicate across these two
datasets we'll replace it and that's how
we merge it and the final result the
integrates in the integrated a a data
frame variable is called song DF and we
can look at what this what this now
looks like okay so once we um once we
have that done let me let me give you
guys the full file as well uh yeah let
me give you a full file hold on a second
so you guys have everything so check
this out so here's the full file which I
haven't tasted I was just here that
travel with you so each other okay so
sure here is that here's the data okay
so let's see what this is we have an
index we have a user ID a song ID
listen count title release artist name
and you what do we want to do we want
you it is very similar to an inner join
in SQL exactly what it's using handles
it
it's the same conceptual idea it's not
SQL but it's conceptually the same
exactly well so someone asked what
feature should we be using and that's a
great question
so with deep learning architecture
engineering is the new feature engineer
okay if there's anything you guys
remember from this session
remember that architecture engineering
is the new feature engineer that means
that all of that engineering complexity
that we have to do thinking about what
features are relevant and what features
aren't doesn't matter because with deep
learning it learns the high-level
features from whatever features we give
it more or less there are some caveats
okay more or less but it learns those
and so the complexity that moves to the
architecture rather than hand tuning
features for hand tuning models what are
the hybrid parameters what are the you
know uh types what is a type of neural
network we want to use for the specific
data set okay so in our case what we
want to do is we want to predict a song
for a user the songs sorry plural songs
that uh this user will like we don't
want to predict artists we just want to
predict songs so what is something we
could do that could just make it easier
for us to look at and just make it
easier for our model in general well why
don't we just why don't we do so the
first part of this is why don't we do
we're going to be doing the data
transformation step we've already
integrated our data into one file the
next step would be to clean our data but
we our data is relatively clean I mean
there's not any really it's a relatively
clean data set so let's just move right
on to transformation and the the
transformation we're going to do here is
we're going to combine the song and the
artist columns together because we don't
care about the artists we just care
about the song
so just for simplicity sake let's just
go and combine these two columns so
what's happening here is the first thing
is doing is it is um it is going to
queer going to create a subset of the
data so that first 10,000 songs that's
what we're going to focus on the first
10,000 songs we're going to merge the
song top of the song and the artist
title into one column okay so it's one
column that we're going to focus on
now we're going to show the most popular
songs in the data set so what does that
look like we're going to group them by
the listen count in the percentage so
there are four lines here let's let's
let's quantum really appreciate it
michail really appreciate okay so we're
going to show these most popular songs
okay so we're going to start off with
this is what it looks like but let's
let's talk about these four lines of
code in detail so would you so let's
check out this four lines put in detail
so what we're going to do is we're going
to say just what this does is it groups
so the first line is it groups them in
order of listen count descending okay
for the listen count then it gets a
total sum of listen counts to calculate
the percentage and that is what's on
this right hand column then it's going
to add a new column call percentage to
calculate that percentage it's summed up
all those listen talents and it has to
calculate the percentage and it does
this by dividing by the listen count
times 100 and that's going to give us
this point four or five point three two
and then finally it's going to list them
in a the most popular songs at the top
okay so now we have this subset of data
and just now this is what we're talking
about right we wanted we wanted
something really simple for us to look
at for us to understand now if we really
wanted to we did and have to do this
step we didn't have to but it's simpler
to look at okay and our model will
likely be more accurate and just because
and another thing just because a feature
engineering isn't as relevant with deep
learning that doesn't mean that we
shouldn't engineer our features at all
you know like for simplicity sake having
this is just simpler to look at and it
talks now it's not a necessity but it
helps okay and then whatever you do can
have the difference can get that last
mile difference between you know your
model being 98 percent in 99 for 10
accurate if you're trying to get there
then yeah go ahead and make it more
simple okay so that can we do to that
when do we get get to hear the choir of
Frederic we'll talk about that later uh
okay so so that's that now let's keep on
going we haven't actually done any
recommendations here we're just we're
just doing some data pre-processing what
do I mean by listen count listen count
is the number of times each song was
listened
in general but all of users okay because
we're going to start off with a very
naive approach for recommendations a
very naive approach
okay so let's count the number of unique
users in the data set okay to do this
we'll say okay what is the number of
unique values really handy a method
right here unique okay and then we say
okay well those 365 users in this data
set great just so we know how many users
there are and whenever you're looking at
it is that be sure to look at these
things okay use ipython notebooks look
at all of your columns analyze your data
see what count of users are what count
of everything there is what is a
percentage shouldn't it sum to one um no
no so the percent it's not it's not
percentage in relation to all songs its
percentage in relation to a whole um
actually hold on a second you are right
this code needs to be recompiled this
this needs to be recompiled
it so the percentage here it needs to be
the altered so so good good good call
Tina good call yeah okay so but anyway
so let's keep going that's the basic
idea okay so we're going to count up a
number of unique songs of days at 5,000
about 5,000 and now we're going to
create our song recommender okay so the
first thing we'll do is we're going to
split it into training and testing data
and we're going to use a train test flip
function from scikit-learn okay that's
what scikit-learn gives us whenever we
do any machine learning before we train
our model anything we always want to
split our data into training and testing
data okay that's what we want to do and
we're going to and we're saying
arbitrarily let's pick 20% as our
testing size and then it'll know that
80% is our training size okay so there's
that
now let's it says okay so simp so the
first thing it's doing here is it's
saying simple popularity recommender
class can be used as a black box
well we're not going to look at it as a
black box we're going to look at this
code in a second okay
but what it does it says okay based on
the popularity of each song create a
create a recommender based on this
training data and then print out for
user five given this user ID what are
the recommended songs and it's going to
print out so what does this look like in
code so to look at this in code let's
let's look at this class okay so we're
going to look at this class actually so
let me go right into this this class so
let me just recommenders file right so
what is this what is this method that
it's loop looking at let's look at this
together it's this recommenders
popularity recommender ha okay let's
look at what that that is here so this
is a recommenders file and now we want
to look at the popularity recommenders a
class so where is that okay here it is
popularity recommend elite let me
increase the size of this so let's just
look at this create function okay so
what is it doing here and but this is
what it's doing okay so this is a very
naive approach it's not personalized
what it does is it says okay based on
your training data and a user ID we want
to get a count of the user IDs for each
unique song as a recommendations for
okay so basically what it's saying is
how many times have had each song has
each song been listened to and then sort
the songs based on a recommendation
score now what is that recommendations
for it the recommendations for is this
given by the the score that the user
that the scores that user gave it and we
can find that alone the score that the
user gave it home I'm sorry so we're
calculating the score by the number of
times that a song has been listened to
in general and that is that metric that
were using for the score that's it then
we rank those so we so we rank those in
order so all it's doing all this is
doing is it is giving you for any user
the top ten recommended songs in general
and it doesn't focus on the user okay
it's not focused on you it doesn't care
about it doesn't care I care about you
but it doesn't care about you okay I'm
sorry
uh but that's just like okay but it's
saying what are those top ten songs that
are going to be recommended to you and
those top ten songs are just in general
they're just the most popular songs
there's no there's no personalization
happening here this is the naive
approach so if we give it user five it's
going to say okay here's the top ten
songs
Harmonia undo and then dog dates okay
well what about for user eight Harmonia
undo and Dog Days it doesn't care about
the user that's a naive approach okay
and this is before machine learning so
we wanted to show that I want to show
the most trivial case before we do
machine learning okay that was the most
trivial case now we're going to focus on
exactly Kevin it's the top cabin it's
the top ten songs based on the listened
count okay so the now we're going to
focus on the personalization kit okay
this is that now we're going to talk
about some machine learner okay you guys
ready for this so to talk about some
machine learning okay now we're going to
do a different type of recommender
system it is called an item similarity
the top songs are based on just listen
town that's it so far hacker
HECO or kora listen cow okay so just on
item similarity based recommender
systems what the hell is this let's talk
about this so here is a great website so
there are two types of so there are two
types of recommender systems okay there
are content-based and collaborative base
content-based predict what you like
based on what you like in the past
collaborative systems predict what you
like based on what other users liked now
most major services like Netflix and
Hulu use a hybrid approach so it's not
just what you like it's what you liked
in the past and what other users liked
and it combines those approaches in a
way but right now we're going to focus
on collaborative some so I'm wrong
you're not too late right now we're
going to focus on a collaborative
approach and we can split the
collaborative approach into two
different approaches
item item collaborative and user item
collaborative like to talk about each
okay so let's talk about um let's see
which one do we want to talk about first
we want to talk about item item okay so
let's talk about this
so use your item so what is user item
collaborative approach look like whoa
look at this we're creating a matrix of
values so for each user here we we list
their rating for each item so you know
this this user right here would let me
show you this link as well okay check
out that link so this user all the items
that they like okay all you hi tons up
this next use your like all these items
this next is the like from this matrix
we're going to calculate similarity now
that is a user item okay and we're going
to talk about that now this is item idle
collaborative tilting filtering so this
is what item item looks like so let's
just look into the code because that's
what we're about to do item item so it's
saying okay so create this item
similarity recommender initialize this
class and then create it for a user and
then print out the recommendations so
let's look at this code okay what is
this code doing so okay so here we are
in item a in item similarity recommender
okay so let's look at what it's doing
here there's there's a bunch of these
helper methods but what is it what is
that main method that we're looking at
okay what is that main method the main
method is okay right here generate the
top recommendations okay so here we go
so the first thing it's doing is it's
going to create a co-occurrence matrix
okay that's what it's doing it's create
a co-occurrence matrix let's talk about
what a co-occurrence matrix is a
co-occurrence matrix here's an example
let's assume that someone a bunch of
users bought a bunch of different
products so what we would say is let's
see uh this is this is the one right
here so for so for each product what is
the likelihood that a user also brought
that bought this not the likelihood for
each user
how many top four let me repeat it one
more time I'm down for each product what
is the number of times that a user who
bought that said product bought another
product okay so for product 1001 that
user bought Weber the number of times
have brought 1001 they bought a thousand
to one time they bought one thousand
three three times where we are creating
a co-occurrence matrix okay so a
co-occurrence matrix in our case would
be for item items soap but for songs
songs or items in our case songs are
items okay so we are creating a matrix
of songs okay so we want to calculate
the weighted average of the scores in a
co-occurrence matrix for all user songs
then we're going to sort the indices
based up on their value and maintain the
corresponding score so they so we prayed
a co-occurrence matrix of songs that
users like okay so basically based on
what songs you've lights in the past we
can see those those top songs that
you've liked and then based on those top
songs what are the users that like
that's those songs the most and then
what are those songs that they like the
most so it's kind of like a second order
uh where it's like a second order
function how is a co-occurrence matrix
different from a normal matrix white
great question well I mean a normal
matrix is just a matrix of users and
songs and a bunch of other features a
co-occurrence matrix is we are taking
the same the same value for both our our
rows and columns so it would be songs
and songs okay so based on this song how
many sometimes if you like what other
set of songs okay so we're pretty a
co-occurrence matrix and based on what
you've liked in the past other users uh
what you liked in the past what are most
likely other songs you'll like based on
what other similar users have left okay
so that is what we did for the
personalized song okay and they tend to
be sparse matrices Kyle
great insight these coke these
co-occurrence matrices tend to be sparse
because not all that because because why
is that
because the face the space of possible
possible songs is so vast that you can't
just say that whatever likes this song
is gonna like every other song right
there are millions of songs out there so
we whenever we're dealing with
recommender systems we have we tend to
have a lot of sparsity more so than I've
seen in a lot of other applications so
this is one of those fields we're
dealing with sparsity is very important
here's what the result of doing that
gave us here's what the result tables it
gave us this list of scores now we can
rank these okay and we rank these up to
ten and that's going to be our
recommendations so that is one is it
feasible to have a matrix with such huge
dimensions yes and we routinely do in
data science we routinely have huge-ass
matrices okay we routinely have huge as
matrices that we load into memory I'm
sure there are better ways just like
there are there must be better ways of
um sampling data than uniformly random
but we just you know we're moving fast
and we need people to be focusing on
these things but right now yes we just
load the entire bucking matrix into
memory okay so that is that now we've
got a personalized model and this is
just repeating the same thing for a
different user okay let's keep on going
here let's keep on going okay and we
could use the same matrix for swaps so
based on a song what is it similar song
Allah what why because the well the
first one you say you know second order
it looked at not just a song use the
co-occurrence major to see based on
these songs let's see what users like
now this it just looks looks like the
raw song matrix and gives us course for
that now this is not using deep learning
I want to say that right out front right
up front this is not using deep learning
it's just using a linear algebra B M
matrices okay that's all it's using and
we can get good results from this okay
okay so some people are saying that they
prefer it when I code and I got feedback
last time that they prefer it when I
don't code so we're gonna see we're
gonna see it it's the first live stream
I've ever done where I'm not doing any
code I'm just having it there so I'm
gonna see feedback based on this and
then overall I'll decide how to move
forward like I already decided this live
stream not to ever use OBS ever again so
that was one thing and then based on the
feedback in general from here I'm gonna
decide if I'm going to code next time or
just look at it like this
okay so we'll see so so make sure to
give me your feedback brutal honest
feedback you know you know me guys you
know how I love it okay I'm here waiting
for you to code okay okay we are going
to you we're going to get to deep
learning okay clone yourself and do both
I wish that was possible
coding is better okay I'm gonna post a
notebook all right
coding is you yeah yeah okay okay so
okay so I'm gonna coat a mix a mix
coding all right
it's getting difficult to follow okay
okay so okay so everybody wants code
okay okay clearly okay okay guys okay
okay okay you guys miss people I promise
that next live stream I will code okay
but it's just that this one I've set up
so that I don't code because that was
the feedback that I got overwhelming
feedback okay so but now I'm promise I'm
gonna code from now on moving forward
but let's just keep going with this okay
um god damn people are just uh going
back and forth yeah okay we'll have a
poll we'll have a poll that's a good
idea attached great idea we'll have a
poll
let's keep going so okay what are we
doing here okay so we've we've done our
a personalized item based collaborative
filtering okay
now we're going to do what's called
calculate deep we want to measure the
performance of our to model what was our
first model the first model was we want
we the first model was a not based on
you at all remember it was just based on
the popularity of a song the next model
was based on you using a co-occurrence
matrix right it was a collaborative
filtering model now how are we going to
measure the performance of these two
models okay
the poll will be 50/50 great how are we
going to measure the performance of
these two models we're going to use
something called precision recall now
what this precision recall look like
let's look at this precision recall is a
good way of of measuring the value of
our recommender system now I have got a
great link for this that I'm going to
throw up on the screen here let me let
me find this link it's an awesome link
okay here it is
and let me let me paste it for you guys
too okay so check out this link I'm
going to throw it up okay so what is
precision recall let me let me blow up
this this image this is weightless so
there are two metrics here precision and
recall
okay so precision and recall precision
is the based on some so let me know mean
alongside precision is the proportion of
top results that are relevant
considering some definition of relevant
to our problem domain what is that
definition of relevant to our problem
domain it could be the number of times a
song has been listened to it could be
the number of users that have all liked
a song some value of relevancy okay that
we're going to define and and recall is
that would measure the proportion of all
relevance all results included in the
top result okay so they're measuring the
relevancy of songs in relation to to
precision is relation to the top 10
results and then recall is how good are
they in relation to all of the songs so
there are two different measures okay
there are two different measures okay so
I promise next livestream I'm going to
code every single bit okay I promise
because you know me I every livestream I
have coded everything okay so I will
continue to do that that's right feel
most at home I'm just going to do it
this way this one time all right so
we're going to use precision and recall
to calculate this now we've got a class
that does this
okay first and when we get to the graph
we're going to plot the graph is
what it looks like this is what it looks
like so precision is the y-axis and
recall is the x-axis and what it looks
like is let me make this bigger it looks
like is it looks pretty much like the
item similarity model has higher values
for recall and precision up up to a
certain point so basically this tells us
that our item similarity model is better
than our popularity law it's more
accurate now FML I'm it made a great
point uh f1 score is also a good measure
okay they're there several precision is
one recall is another f1 score there's a
lot of ways we could measure how good a
oh good or sorry how good a model is in
relation to another mom okay so that was
it for our item base now we have one
more type of recommender system that
we're going to look at now this is a
matrix factorization based recommending
recommender system okay so what so what
am i top well I say okay so what am I
hello okay DMV following okay so now
what we're going to do is we're going to
create this recommender system okay and
we're going to talk about Janzen ganz in
a second but okay so let's my phone is
in my ear right now can you learn you
just shrug to say okay so let's focus on
our recommender system
to do this okay and
finally all these things are out of my
year so we're going to use we're going
to compute SVD to calculate or
recommenders recommendation so let's
talk about what this is doing okay so uh
so this so the singular value
decomposition okay so what is this it is
a matrix a with so let me let me throw
up a so the SVD is a way that we can
perform matrix factorization which is a
technique that is used to build
recommender systems okay so the SVD is
basically it's a matrix and it's a
factorize matrix of the original
similarity matrix so we'll create some
similarity matrix and then we'll perform
this process right here in this method
call singular value decomposition now
what this does is it ultimately outputs
three values okay what are these three
values so us and V T u represents user
vectors okay s represents the item
vectors and and then V T is points in a
two dimensional space so so what we are
doing is we're going to use SVD to
compute rate so it's going to in vector
space it's going to create user vectors
it's going to create item vectors and
it's going to create a joint embedding
vector for both of them in a two
dimensional space and we're going to use
these vectors to measure the distance
from one users up one users preferences
and another users preferences and
whoever has the smallest distance what
between users we're going to use their
songs as recommenders okay that's that's
that's that's kind of an explanation
that we're talking about so it's it's a
little like this yeah yeah it's a little
like principal component analysis
exactly
we are vectorizing matrices or
vectorizing matrices and then we're
computing the distance between matrices
okay so it's it's not clustering it's um
okay all that okay so so let's see what
we have here do I have any links for
STDs so so so this this whole this whole
method here of computing the SVD and
then using it to estimate ratings is how
matrix factorization is used to
recommend products for users so we can
look at I mean let me show you guys this
so it's check check check that's not
protect so this is the input that we're
going to give it it's a it's a user item
matrix okay and this is what we perform
singular value decomposition on so the
items are going to be songs and the
users are the users okay once we perform
SVD on this it's going to give us a set
of vectors and once we have those
vectors we're going to measure the
distance between vectors to give us
recommend recommendations that's the
most simple way of putting where it's
going to measure the distance between
vectors to give us recommendations okay
and and down here it's got a little bit
of the intuition behind it but um so and
we have plot those and net for this code
ends but I want to talk about deep
learning right now for a second okay
because we haven't done deep pointing
yet this is just this is just um this is
without he pointing so let's let's talk
about deep learning right now okay so
let me pull this up let me pull this up
so what is it good so this code doesn't
have deep money because I think a good
one it's like Hulu has a great so I
think who has said they are yet Hulu has
state of the art right now in
recommender system so what is what is
Lulu doing here
so so right now I think hulu has state
of the art that they discussed state of
the art and recommender system so let's
look at what they're doing for deepening
now there are a lot of ways to apply D
pointing to this problem set right so if
we
so here's one way okay so their method
is called
CF Nate okay that's had to take all
their method they definitely need to
marketing to help with that that Nate
but so what they did was they said okay
let's take an example now here's an
example that they're using and let's say
user rated for movies transformers
Sponge Bob up Ninja Turtles and
interstellar with the scores for two
three and five on a five-star scale
they're going to create a joint
probability of that vector factorize it
as a product of conditionals by chain
rule now what the heck did I just say so
this is what it looks like it's going to
have a the probability of you that the
user gets transformers at four star
rating conditioned on nothing that's
really the probability a user gets
spongebob a Rick arrayed in a two-star
rating conditioned on what happened just
happened and then the probability of
Teenage Mutant Ninja Turtles position on
that condition on that concern on that
so you see what I'm saying this is a
chain rule it's a chain of probabilities
based on what previous previously has
occurred so it's a chain of
probabilities and each conditional is
modeled by its own separate neural
network and the parameters for all of
these neural networks are shared amongst
all models so it's got several neural
networks for all of these conditionals
can you imagine how many neural networks
can you imagine how many neural networks
are using for this okay so they've got a
lot of neural networks and they're going
to minimize the negative log likelihood
of the probability of the vector among
all users okay so that's one that is
like the state-of-the-art way of doing
it okay so we did it black box all of
this right obviously it's a ten lines of
code but we're just looking at it
theoretically in detail like what is
what is the cutting edge right now in
the field okay so and then let me let me
show you guys it's linked as well so
leading edge right here okay so so let's
go back to where we were and
yeah so I think we went through all of
it actually yeah okay so cool we went
through all that code and yeah we're
going to talk more about recommender
systems this was nearly not enough to
talk about it we're going to do a lot
more this was a good high-level overi
this was good but we're going to do a
better high level overview or sorry an
additional high level overview later on
okay stop screen sharing okay back to me
guys okay so that was it for the code
and we're gonna end with another five in
akyuu a okay so what else is on guys
we're going to I will link to code for a
deepening based recommender right now we
want to learn the concepts okay deep one
there's a lot of there's a lot of
conceptual um things we have to learn
about recommenders before we get too
deep learning because I think that deep
learning for recommender systems is the
most complex uh task right now in in
deep learning to me there it's actually
more complex than generative adversarial
networks uh so we're going to talk about
it more this was clearly not enough I'm
not satisfied but I'm satisfied I'm
satisfied with this lie scream I'm not
satisfied I've talked about it enough
okay so rap about music recommenders I
wrapped already guys okay um okay uh
rock about music recommend okay so those
are fourth person so uh here we go huh
yo rap about music recommenders I'll see
his girl up there she's like a sender
she trying to give me some mail so get
out of here but I'm not going back I got
a drink my beer not really I don't drink
beer I'm more a coffee drinker man this
is crazy
you could call me Sean speaker I go out
every day on the streets telling people
hey I'm like this song they're like man
you need to drink up people baffled
Snapple all these drinks but I'm bored
man I got songs man I'm done with that
so I okay is it possible to write a
collaborative filtering algorithm with
out deep learning yes absolutely yes yes
that's that's that what we that will be
just it okay then I should have
clarified that okay what do you think
about trying to group possible actions
and optimize paths taking in this group
in reinforcement learning to reduce size
size of state space okay reinforcement
learning in general should be applied
everywhere it is going to be applied
everywhere because no path net okay path
net by deep mind okay path net let me
let me link to Pat them but this is this
is todo because because they apply they
applied reinforcement learning to a
neural net architecture check this out
check out that link I'm gonna link it in
the description for people watching this
but it used a reinforcement
reinforcement learning agent inside of a
neural network to find the optimal
parameters so get this for a second it
is looking inside of it is using an AI
inside of an AI which is a neural
network to find the octal hyper
parameters how joke is that okay and so
that's that so yes we can use
reinforcement learning everywhere
including recommender systems two more
questions and then we are out of here
okay um how much usage data is typically
required to make a good performing
recommender system rocío wait great
question you definitely need a lot of
data like a hundred thousand-plus
sets there's a lot of of recommender
system libraries I mean sorry datasets
out there publicly available I'll link
to them in the description but you need
a lot you need a lot okay if you want it
to be happier you need a lot and and
don't be intimidated by that because
it's everywhere
okay well I'll thank you more favorite
entrepreneur my favorite entrepreneur is
probably my favorite entrepreneur is
Tupac sugar because Tupac faced so much
oppression
he faced so much suffering and in the
face of all of that too Punk believed in
himself enough to broadcast himself to
the world and say hey I'm Tupac Shakur I
don't care how many haters I have I'm
gonna be myself and I'm going to be
essentially a messiah for a bunch of
people and so yeah Tupac is my favorite
entrepreneur I also have a book of
Tupac's poetry called the rosette grew
through concrete one more question that
we're going to talk about let's make it
a good one
okay when are you making a robot with
machine learning next video okay I just
said it so now it has to happen so the
next weekly video we're going to make a
robot okay so detach if you want to do
research post in the slack channel guys
we need our own research group ok we
need our own research group I want
publications coming out of this
community okay you guys are so smart we
need to build a research community okay
we are going to build a research
community okay we are going to publish
we're going to build a brand that
publishes world-class machine learning
research okay so that's what we're going
to do all right all right so so that's
it for the live stream okay and next
time I'm going to coat everything this
time I didn't I love you guys and for
now I've got to edit this next video i I
just have to edit it myself like Udacity
has offered me an editor but I just
cannot do it I just have to do it myself
right now okay so that's what I got to
do and thank your watching bye</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>