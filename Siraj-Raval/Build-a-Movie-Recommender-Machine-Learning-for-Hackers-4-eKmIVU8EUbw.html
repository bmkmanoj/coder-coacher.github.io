<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Movie Recommender - Machine Learning for Hackers #4 | Coder Coacher - Coaching Coders</title><meta content="Build a Movie Recommender - Machine Learning for Hackers #4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Movie Recommender - Machine Learning for Hackers #4</b></h2><h5 class="post__date">2016-05-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eKmIVU8EUbw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey Siri any songs you'd recommend good
lacquer at the barre by Kendrick Lamar
good pic why that one because the police
hello world welcome to serology in this
episode we're gonna build a movie
recommender system recommender systems
are all around us almost every single
major service on the internet uses them
to show you things you like based on
your interests sometimes it's so subtle
you don't even notice they help
personalize content on the web which
makes users happy which makes companies
money the two most ubiquitous types of
recommender systems are content based
and collaborative content based systems
focus on each user individually it looks
at the items you've already expressed
interest in do lights and ratings and
records their keywords attributes and
tags then your profile is gradually
built with these attributes once your
profile is built the system will start
recommending items you like with similar
attributes to the ones you've already
expressed interest in so if you're on an
e-commerce site and you buy a bunch of
Nickelback t-shirts those items will
have tags like worst band ever and
stupid based on that content the system
will suggest similarly tag items for you
like curry t-shirts and Walmart brand
guitar then there are collaborative
systems these are the most ubiquitous
types of recommender systems a
collaborative system recommends you
items based on what other similar users
have expressed interest in you really
like base-jumping and constantly buy
base-jumping gear online the system will
find users who have similar purchase
history it can recommend other items
they bought that you haven't it's likely
that you'll be into those products as
well so we're going to build an app that
can recommend movies you'd like in 10
lines of C++ using Amazon's newly
released ml library called deep scalable
sparse tensor network engine or destiny
we've got to think of a better name our
model will be a neural network because
depending on how deep we make it and how
much data we feed it it's just going to
outperform everything else let's be real
then we're going to train it in the
cloud using AWS because I got time to
Train this on my macbook destiny is what
amazon billed for production used
specifically to recommend products to
customers that they might like it's
optimized for sparse data and multi-gpu
computation data is sparse if it
contains a lot of zeros as not a whole
lot of valuable information Rex
usually operate on sparse data not
everything is connected but you can
manage to find some valuable links
between people ain't items mostly
elaborates implement data parallel
training as in it splits training data
across multiple GPUs this works but
there's definitely a trade-off between
speed and accuracy destiny uses model
parallel training so instead of
splitting the data across multiple GPUs
it flits the model across multiple GPUs
so all the layers are spread out across
multiple GPUs on the same server
automatically for you Amazon had to do
this because the weight matrices it had
4x that is all the mappings of users and
attributes just didn't fit in the memory
a single GPU when it comes to ML
libraries destiny isn't as general
purposes tensorflow but it is twice as
fast when it comes to dealing with
sparse data so we'll follow our
methodology can collect our data set
build the model train the model and test
the model will call the retrieved data
set method but the parameter as a URL to
our downloadable model in our case we're
going to use a sample movie lens data
set which contains user ratings for a
lot of different movies and their
associated tags once we have that we
want to convert it to a format our ml
library can read in this case is the
netcdf format netcdf is designed for
efficient serialization of a large array
of numbers what destiny expects will
generate it for both the input and
output layer of our neural network and
will use the name of the downloaded data
set as our parameter both of these
functions generate and netcdf file an
index file for neurons and an index file
for features also generated our model
it's time to train our neural network in
destiny you build your model in a JSON
file instead of programmatically we can
see in the config dot JSON file the
structure of the neural network this is
where we set our hyper parameters the
most important takeaway here is that we
are creating a three-layer
a forward neural network I mean Zeta
just flows one way with one 128 node
hidden layer in our activation function
at each node is the classic sigmoid
which turns values into probabilities we
can go ahead and run our train function
with the batch size and number of epochs
add the parameters will set the batch
size or number of examples to 56 and the
number of epochs our runs at 10 once we
run this it will create a newly trained
model file called GNC which we can then
use to predict recommendations our last
step is to predict recommendations so we
can just call the predict method and set
the number of recommendations parameter
to 10 this will place two newly created
predictions in the Rex book now that we
have our code ready to be compiled and
run we want to upload it to AWS to start
off we'll click on the ec2 button which
will take us to Amazon's cloud computing
service then we want to make sure when
the US East North Virginia region since
Amazon create a pre-configured image
with dependencies like CUDA and open MPI
already set up for us in that region
will click on ami under the images
directory of the Left sidebar and the
search for the instance called ami d 6 -
6 BC it should pop up and then we click
the blue launch button to spin up an
instance using that image then it'll
show us a list of instance types since
we want to speed up training time let's
go ahead and choose a GPU option here
then we'll click review and launch and
see the final page before we can launch
our instance everything looks good to go
so let's click Launch it'll prompt you
to create a new key pair go ahead and
download it so you have it locally this
will have authorized your machine to
connect to AWS now that we've
successfully launched a GPU instance we
need to upload our code to it and train
it I'm a fan of using FileZilla to
upload files so let's use that we'll
click the site manager icon then paste
in the host name we got to be sure to
set the protocol to SFTP then set the
login type to normal and the user is
called Ubuntu once we set the field we
can click connect
show us all the current files in our
instance let's go ahead and drag and
drop our project into the root folder
now that our code is in our ec2 instance
we can open up terminal and SSH into it
we can find the SSH snippet for terminal
under the instances section once we
click the connect button perfect let's
just paste this baby right into terminal
boom we're in let's CD into our
directory before we run our code we'll
need to do two things at the MPI CC and
nvcc compilers to our path and make the
library we can export MPI CC and then
run make and we'll export nvcc
now we can run our script and once
that's done we'll have Rex and our Rex
folder that's pretty much it you can
scale your neural net accordingly
depending on the size of your data check
out the links down below and please
subscribe for more machine learning
videos I've gotta go fix a runtime error
so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>