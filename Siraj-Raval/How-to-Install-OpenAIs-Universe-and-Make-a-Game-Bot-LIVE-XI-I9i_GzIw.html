<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Install OpenAI's Universe and Make a Game Bot [LIVE] | Coder Coacher - Coaching Coders</title><meta content="How to Install OpenAI's Universe and Make a Game Bot [LIVE] - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Install OpenAI's Universe and Make a Game Bot [LIVE]</b></h2><h5 class="post__date">2017-01-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XI-I9i_GzIw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody
let me load up the chatroom livestream
is starting soon alright let's get into
that room with all the live people
loading loading loading oh all the
loading live streaming events boom I'm
in the room there I am alright cool
alright hey all the world it's Suraj
good to see everybody I'm gonna list
some names up uh psych Colin's psych cut
ricardo spencer daniel preston no all
happy new year sagar Shazahn lance
savior how's it going guys okay so today
it's good to see you guys good to be
here i'm excited for this livestream
today we're going to build uh well first
of all we're gonna install open the eyes
universe and then we're going to build a
game bot to get better at it and it's
our own custom game bot um it's gonna be
about 70 lines of code in Python and
then uh I'm gonna along the way then
explain how it works okay so first of
all as always I'm going to start off
with my five-minute Q&amp;amp;A and then we're
gonna get started all right all right
here we go
um how much math you know behind all
this ai and ml uh i i've studied linear
algebra I've studied statistics and
calculus um in terms of how much do you
need uh I think I I mean it depends on
the level that you're trying to you know
what you're trying to do if you're
trying to research you definitely need
some math it's no question if you're a
developer and you're just trying to
implement some machine learning into
your app or use an API you don't
obviously don't need math and if you
want to do something in the middle where
it's like your developer but you're also
you know you're doing some innovations
in AI having some math is good
I'm gonna start teaching more math in my
on my channel all right uh hi uh uh
Alexander and massive Macedonia what do
you do for a living I do this channel
full-time uh how do you get started with
tensorflow and say my name please
Rashad uh with started with tensorflow I
have an intro to tension flow series on
my channel uh what is opening a universe
capable of other than games a great
question so there are environments uh so
uh there are environments for doing
tasks like sending an email or uh you
know uh doing some kind of mouse
clicking keyboard e event so there's a
lot of different set objectives and
they're adding more over time because
it's open source
can we get tension flow working with
golang there's got to be a rapper on
github just search tensor flow and then
click on go tell me if something shows
up I actually been searched for that I
don't even thought of that you're doing
a great job sir thank you thanks thanks
Bartos which is the best tutorial to
learn Python to be efficient at ml I
have a series called learn Python for
data science check it out when will the
basic deep learning video series come
out and will it also feature the math uh
yes it's coming out on Friday it's
something really big something really
big is coming out on Friday guys so it's
a lot of pressure but this is going to
be something really big on Friday how
long will it take this video is going to
take about 45 minutes um hi Suraj our
Google not releasing their best
tensorflow library uh no I mean I mean
Google does have a lot of internal code
that they're not going to share with us
but tensorflow is is you know that I
mean it's that's a good portion of what
they have are you going to make a game
live tutorial that's a great idea David
I ganz are really really really cool and
I made one video called generative
adversarial networks but I'm gonna do
more um all right so three more
questions uh where are you now Suraj I'm
in my room in San Francisco what do you
think about Mark Zuckerberg ai I talked
about that and like two streams ago I
thought of all right are you gonna write
code with you yes what do you think
about Pandora BOTS I have
heard of that all right um will you do
something with videos I guess you
talking about machine learning with
videos yes is a nano degree worth it
I yes I think it's worth it and speaking
of nano degrees
uh something cool is coming out so just
I can't I'm not gonna I'm not going to
say what it what it is what college did
you go to Columbia you smoke marijuana
yes and no apologies so um
anything with d3.js and AI I have a live
stream called uh well that's a
visualization without AI anyway um cool
I'll or Deus all right so um that's it
for the five minute Q&amp;amp;A uh let's get
started with this we're going to install
open the eyes universe and then we're
going to UM build our game bot with it
alright so let's get started with this
I'm going to go ahead and start screen
sharing so obviously it depends on your
environment like what you're running but
in this demo um we're going to uh let me
just start screen sharing here we go
screen share desktop okay so so okay so
here we see the actual repo right this
is the repo for opening eyes universe
they've got to read me here and they're
explaining that it is a software
platform for basically training an AI in
thousands of different environments
they've got flash games they've got
browser tasks as you can see here um
like you know sending emails and you
know more you know trivial things like
that uh and even like you know things
like Grand Theft Auto 5 which isn't
included yet but it's coming very soon
and more games like that 3d games are
going to come soon so so there's that
and then it's got the install
instruction so look what I'm going to do
is I'm just going to go through these
install instructions with you guys yeah
and I'm going to do it for Mac because
obviously I'm on Mac but this also
applies to Linux uh and if you're on a
Windows machine uh you know uh so the
the intersection here for Windows
machine is when we talk about docker
okay well so we'll get there so let's
start off by installing universe let me
check what you guys are up to
um cool all right cool so here's what
we're going to do the first thing you
want to do is clone the environment so
what I did is I went ahead and um I'm
going to open up terminal okay uh and
I'm gonna say ah let's see I'm gonna
create my let me make this bigger let
make it way bigger fun 5cd fun fun okay
so I'm in my directory right now a
little bit okay so let me make a super
big okay I'm gonna make it super big for
everybody everybody can see that all
right here we go
so is what we're gonna do I'm gonna put
this over here let me see what you guys
up to
alright cool alright so let's install
this baby alright so we're gonna start
off by cloning this thing let's go ahead
and get clone get clone alright so
that's gonna download it boom that was
fast
alright so next epic this CD and the
universe alright little CD in alright
we're in our let's look let's look at
what it looks like this this uh font
sizes alright right guys this font sizes
are all right cool uh right okay so um
we seeded into universe and now we're
going to install our dependencies so
what is this line it's the - a variable
means in editable mode all right so
we're doing this an editable mode which
makes installed packages editable and
it's reading which packages to download
from setup I so you see this set up that
PI file here let's let's like nano into
this for a second I just like see what
this looks like set up that pi is a list
of B dependencies and you can see them
right here like pillow and Jim and
docker PI things like that
alright so that's what that is so we're
going to go ahead and run our install
line pip install e so that's going to
install it's gonna it's gonna download
this dependency - oh Sh
all right yes I need to be in sudo mode
right permission denied
always just denied access that always
happens to me alright so we got our
dependencies right all right arm pillow
gives you nightmares
well yeah anyway okay so we've got our
dependencies and so then it then it kind
of you know splits off into whatever
platform you're running on Ubuntu you
want to install numpy arm and just in
general you should just have numpy on
your system because pretty much
everything machine learning is using
numpy these days um so and then you're
using app to get to install go laying
and you know we on uh go and you're
going to need golang because we're using
that for our VNC driver which i'm going
to talk about in a second so for us we
are sorry so us as in OS X users we
don't have a package manager like
apt-get so we had to so we have to use
something called homebrew which by the
way the inventor got rejected from
Google for not being able to do I don't
know if you guys heard about that there
the red black tree this was like a year
ago but like I just thought that was
hilarious and a and a good commentary on
the state of programming interviews
which I still have to make a video on
how to ace the programming interview I
know you guys want that so that's going
to come soon I just have a lot of my
Play right now so that's coming soon
anyway so up so for OS X it's gonna say
you're going to need command-line tools
which I already have so I'm not going to
run that but um so there's that and then
ah right so and I have these
dependencies uh right so I'm just gonna
go ahead and just install them anyway so
I'm gonna overwrite what I already have
boom I've got that and then I'm gonna
use homebrew to install golang and live
JPEG turbo which is which is going to
help with uh like image processing right
so it's gonna update homebrew it's gonna
download these packages okay um alright
so right so for Windows to um alright so
now we're on so we've got those
dependencies and now we're gonna install
docker so let's talk about docker for a
second here okay
people need to understand how awesome
docker is so so this is the docker
website okay this is how we install
docker and depending on what operating
system you are there are different
install processes I recommend the binary
whether you're on Windows or Linux or
Mac you should use the binary um because
it's just easier it's like a one-click
install but there's also you know you
can install from source but I would
prefer you know my preferences binary
okay see I've installed a binary docker
and so I've seen like right up here you
see docker is running it's just running
up there I've got you know I can get my
diagnostics and preferences and I can
update them so
pretty GUI and that's fine uh but so
let's talk about docker for a second
right so docker is so let me explain
with docker so ok so what's a good
analogy docker is kind of like a TV
dinner ok
it's it comes in a box it's got
everything you need right there in the
box and when you're done you just toss
it away
ok so that's so docker is like it tries
to make apps like TV dinners and so
virtual machines are kind of like that
but they're not quite the same so it's
like let me write this down so like what
is docker ocker Asami let me make this
bigger oh ok so I'm a pig docker is like
a TV dinner ok it's got everything you
need
loaded it in a meal all-in-one
right so doctor it's kind of like a
virtual machine except it's less bloated
than a virtual machine so like a virtual
machine but but thinner so it's it
doesn't have the bloat of a virtual
machine so virtual machines typically
include an entire operating system but a
docker ecosystem has a central engine
that can run multiple docker containers
so it cuts out the bloat of having
multiple operating system and just
simply it just packages the runtime
elements that you need ok so it's just a
run ten elements that your program needs
and Dockers awesome because it you know
it removes like all the dependency hell
that comes with every app someone
suggested I'd authorize literally
everything I do from now on
which I will seriously consider I need
to get better at so that's that's a
short a primer on docker ok so so in
terms of docker we're going to install
docker and a TV dinner is done okay so
we're so we've installed so we're gonna
install docker and we remember run the
binary for docker uh and so once you've
installed the binary um I'm not gonna
reinstall the binary for docker it's
just it's literally just like a
three-step process like next next finish
uh but once once you've installed a
binary it should be linked to your
terminal ok so you'll be able to call it
from terminal ok so um so and that's it
that's it so docker was the last step
for that
and uh once we have that we're going to
go ahead and create our agent so they've
got it they've got a sample agent here
uh but we're gonna go ahead and just
create our own okay so we're gonna write
up um so we're gonna we're gonna go
ahead and write up our script that's
where it's gonna go go right into it
okay so um let's let's go ahead and get
started with this okay so the first
thing I want to do so let me talk about
what this agent is going to do it's
going to do two things well first of all
the first thing is going to do is our HR
body's going to do our bot will do two
things well the first thing is going to
do is determine uh should should should
I turn right and then then the next step
is going to be um where to turn
that's a it's a two-step process where
to turn okay and this is going to be for
the coaster racer game
okay which you can see right here okay
this is the coaster Reigate racer game
it's not going to be this default agent
right here we're gonna build our own
thing but it's going to be right so you
know and by turning I'm talking about
which direction right left or right
which one which direction do we want to
go left right and that's what our bot
will do it's gonna be about 70 lines of
code and it's gonna it's gonna decide
where to turn
okay all right and um yes it's
reinforcement learning um and I'm using
sublime text uh you guys are all awesome
as well thank you okay so let's get
started with this so um the first step
as always is to import our dependencies
so the first one is going to be Jim why
are we importing Jim if we're using
universe well Jim is universes based off
of Jim Jim was opening eyes original um
attempt at creating an environment to
run BOTS in and they had games like kart
poll you know they had things like that
but universe basically expanded on it
like way more so we're gonna import both
okay and so we've got both of those
dependencies and then we're going to
import random because we're going to
implement a random policy here but it
would be a smart random policy that's
using reinforcement learning
okay so I'll talk about that in a second
but those are our only three
dependencies all right those are our
only three dependencies and now we can
go ahead and straight our main function
all right
our main function the first step is
going to be to initialize our
environments okay um so we'll say what
is our environment going to be like what
is the game that we want to play so Jim
has a make method that lets us define
what the environment is going to be and
I'm going to define it right here I'm
going to say this is calling a beta it's
gonna be a flash game called coaster
racer it's a flash game called coaster
racer and I think this might be a little
too big I'm going to just go down a
little bit okay so that's what it's
doing its initializing our environment
um it's going to be coaster racer okay
um so that's what that is and let me sow
a little primer on what's happening here
so uh so this is this is going to
initialize our universe environment um
and initializes universe environment and
what does that mean there are two things
happening when we're initializing our
environment there's a client and there's
a remote so the client is a VNC
environment that's where the agent lives
a VNC is a virtual net is stands for
virtual network computing so you know
when I was 16 I liked a little script
Kitty I used to hack into these just for
fun but basically it's a way to share
desktop screens with you know two people
so you can you know if you're using the
bein so VNC is kind of like a protocol
it lets you see what's happening in
another computer right and so the reason
they're using VNC is because these games
are running inside of it this is
essentially a virtual machine but it's a
docker container right it's like an
operating system inside of a docker
container which we're going to see in a
second so BNC is the way it communicates
and so it's a client and a server and so
the client is the agent sorry not a
client server a client or remote the
client is the agent that's that's what's
running all of the that's what's
deciding what the keyboard and mouse
actions are going to be and then the
remote is the environment and the remote
is going to be local I know it's weird
that it's called remote but it's
actually but it's local it's our local
docker container now if we wanted to we
could upload this to a server and then
have it all run there and in fact we can
actually say we want multiple docker
containers so we can have multiple games
running right so one agent that's
playing multiple games at once but for
this demo we're going to have this front
low cailli and it's gonna be
a local doctor container right so that's
a primer on what we're doing with the
environment so now the next so the next
step is to get our initial set of
observations right so right when the
game stops start let's get that let's
get that by run let's get the initial
set of observations by running the reset
method okay which will initialize our
environment ok so that's that that's
four that's the steps for initializing
our environment now we're going to
initialize our variables okay
so we're going to initialize our
variables and the answer to life
congratulations um okay so Illuminati
confirmed
always so we're going to insure eyes are
starting variables what are these
starting variables well there's a number
of game iterations and we're going to
define these later but we're going to
start off with 0 both of these define
the number of game iterations so num of
game iterations ok so that's what those
two do um and then this one is going to
sum uh it's going to calculate the sum
of our observations so how many
observations do we have and we'll store
that in the total sum variable which
will we'll initialize a zero
ok so that's four total sum of
observations um the next one we want to
create is the private the previous total
sum right well and why do we want to do
that well we're going to compare both of
those we're going to compare the total
sum of observations to the previous one
when we implement our policy uh and now
and this is probably the most important
variable the fault the current variable
and we're going to based on whether or
not this is true or false we're going to
turn okay because remember there's only
the this is a driving game and there's
only three moves to make turn left turn
right or go forward okay so speaking of
turns let's define our turns define our
terms or keyboard actions okay so let's
define our turns or keyboard actions
we'll start off with left okay so this
is this is going to be a left turn so a
left turn is we're going to say our key
event is
up um true and let me explain this in a
second but let me just write this out so
that's our first key event um and then
our next so let me just copy and paste
that because I'm going to be reusing
this right so our next one is key event
arrow left uh which is going to be true
and then our last one is going to be key
event arrow uh right which is going to
be false
okay so there's that so let me just copy
this whole thing let me make it a little
smaller so we can see what what's going
on here a little bit more um event or
left or right Club up up up up all right
so um right to the central left and I
want one for right so that's our left
so arrow up is true arrow left is false
for this right one and then it's going
to be true for going right and then the
last one is going to be forward those
are our three key positions left right
and forward and so for forward it's
going to be true false false okay so let
me talk about what what this is okay so
we've got three key events that we
define here left right and forward and
so why are we defining three different
key events for one direction like left
well we want these two so these are
gonna um these are a set of actions
right and we want them to be like this
because uh they're gonna happen
synchronously they're gonna happen
synchronously so whenever up this is
true we want this to be false so
whenever this is false we want this to
be true so it's a format that we want to
specify everything in right so we're
just standardizing this format we could
easily just say well key left is just
going to be you know key left and none
of the other two but we want to
standardize these so they're all in the
same format okay as we iterate through
them for a game okay so just it's for
formatting purposes in a nutshell it's
for formatting purposes okay let me see
what everybody's saying up here
aerial bun - you don't - cool okay so
how do we interact with the pixels
characters of the game great question so
the pixel data and the pixel data is
returned via the observation variable
when you run the environments step
method which we're going to talk about
in a second
but right now let's go ahead and um go
ahead and run our main logic okay so we
define our terms
I so we guys make a while loop here so
while true um we're going to run this
thing so this is your criminal just
gonna run continuously so that's the
that's for the that's for the while loop
so now we're going to increment a
counter for the number of iterations
okay so this is our counter so that so n
we've already defined but we're gonna
add 1 to it because well we're iterating
right we just started the game and now
we implement we've iterated it by one so
um if at least one iteration then check
if a turn is needed okay so now comes
our the fun part so let's check in our
observation um a variable and we want to
so we want the only the first
observation from this observation
variable which is essentially a list but
we we only want the first one because we
don't we say zero because we don't have
multiple games running right we only
have one so that's gonna be the first
and only item in that in that list okay
so if there's something there as in
we've observed something then it's time
to check if we want to make a turn or
not so we've got some feedback from the
game and now we're going to store a the
we're going to store the reward in a
previous score so in the previous score
but we're going to say okay we've got
this variable called previous score
which we define previously right and
it's just going to serve as a way for us
to compare what we have now to what we
had before and we're going to use that
later that comparison okay um
so okay so we've got something from the
game right we're still in this if
statement we've observed something right
so now we're going to check ok is it
time to turn remember turn was initially
set to false but if it's true and we're
going to determine whether or not we
want to turn in a second we're going to
create a bit we're gonna create a
function for that called determine
whether or not we want to turn but if if
assuming it's true that we want to pick
a random event okay so the event
is going to be um hold on the event is
going to be it's going to use that and
remember we employ in point that random
uh library up there which is going to
help us with this so random choice
pretty a Polina apt wheel int aptly
named right so um so random choice is
going to be an array of left and so
we're going to choose between going left
or right and that's going to be the
event so based on whether or not we turn
so remember there are two things
happening here so they're you know
should we turn so that's what should we
turn and then where to turn where to
turn and so this this is this answer the
question where to turn but we still have
an answer the question should we turn
and that's where the that's where the
reinforcement learning comes into play
and I'm going to talk about that in a
second but let me check if everybody's
following everybody is every I so
volatile um everybody's same seems
everybody's cool alright cool so so
where to turn is the next thing okay so
um now we're going to perform an action
let's perform an action so we're going
to perform an action so the action is
going to be we're going to call it n
right so um so for the event so okay so
let me just set this up event or op in
observation and okay and then we're
gonna so so uh right so should we sit so
we ask should we turn and then where to
turn we got that event it's gonna be
either left or right and and then we're
gonna perform an action based on that
event so based on whatever we see
perform that random event and that's
going to be encapsulated in this action
variable right so whether or not whether
or not we want to turn right is going to
encapsulate it in this action variable
which we're gonna which is going to be
the input to our step method we haven't
actually we haven't actually implemented
this action of our choice to randomly
turn left right
we've only defined it's okay so now
we've we've done that let's set turn to
false again because remember it was true
in this case so now we're going to set
it to false again because guess what
we've already turned okay so now
in the in the opposite case in the
opposite case um let's see so um oh so
guess what guys so I missed one thing
here so the one thing I missed was
saying uh I've got this observation um
so if n is greater than one so if at
least one iteration has been made right
so if which I party increment if at
least one iteration is made
check if turn is needed right so the if
at least one iterations made let me add
that there this that means that all this
is have to be indented boom-boom-boom
going to go ahead and indent indent
indent indent
okay so I've indented everything and now
I'm going to check in the opposite case
so if if not if not so else if um not
turn okay so if no turn is needed so let
me let me write that out if no turn is
needed go straight right so if no turn
is needed and I still be determined this
is coming up like should I turn or not
and that's going to be the the big
reveal like how do we know whether or
not the turn and that's the
reinforcement learning step so the
action we're going to get it's going to
be forward right which we've already
defined based on whatever we see in our
observations observation underscore and
right okay so there's that and then um
if there is an observation ah the game
has started and check of a turn is
needed or not the game has started
check if turn needed alright so if there
is an observation so if observation hold
on man words are hard observation n0
sorry no n0 everybody's following
everybody's following everybody's good
everybody's good all right great okay so
um observation n if it's not equal sorry
if it's not equal to none okay so if
there is an observation game I started
checking the turns needed
so so now we're going to run our
function that we're about to define with
our reinforcement logic reinforcement
learning logic so total sum so here your
the variable that we're going to get get
back from this so total sum previous
total these are our variables we're
going to find what each of these do um
so they're going to be four variables
that we get back so total sum previous
total sum RJ and then determine turn
that's our that's the name of our
function that we're going to define
based on whether or not we want to turn
based on what we see in our environment
the observation um and in that first
environment and the only environment
which is why we say Z J is that
iteration variable that we defined
earlier the total sum which is the total
sum of iterations and in the previous
total sum which is our way of comparing
okay Oh Anna is one more sort of reward
sure those are what we're going to use
those would be five variables we're
going to use to determine whether or not
we should be turning okay um that's so
there's that um okay oh that's a big big
big big variable okay I mean so a big
line or function okay so then we're
going to save a new variable for
variables for each iteration so now
we've you know we determined so this is
the end end game right we've we've run
our reinforcement learning we've
determined that yes we want to turn and
that where we want to turn right are we
solve our two questions and now we're
going to we're going to implement that
turn or that action which is a turn
right and if in return our four
variables right that that open a I gives
us whenever we run the environments step
function which is a time step right so
it implements the action right so that
the action that we define up here okay
and then we the last
in render our environment right so we're
always rendering it we've got to render
it for every time step okay um
and then obviously um I'll have this
like ending code which like if the name
and what was it it's like equal equals
under main then if name then make okay
so there's that and now we're ready to
actually to create our um determine turn
step so this is the reinforcement
learning step reinforced so let's see
hold on this is our reinforcement
learning step reinforce meant learning
step let me check if everybody's on
board reinforce the learning step okay
so it's gonna be called deaf determine
turn okay let me check if everybody's on
board real quick um let's see main main
main main thank you
Rodrigo and shoe bomb okay so I mean
make sure right okay
okay so now we're ready to determine our
turn okay um okay so let's go ahead and
and write this step okay so um so turn
so remember those are what are variables
well we we defined those down here of
the observation the reward n um and a
previous total sum the total sum
observation N and then the turn so these
are our variables so I'm just going to
copy and paste those right because we
already defined them uh and well we
don't need to add this because it
already we don't need to add this index
counter because it already knows that
we're just going to make it something a
little more pretty okay so so now we're
ready to run this variable so okay so
here's the basic logic so for
for every 15 iterations some that took
some the total observations okay and
take the average that's what we're going
to take the average if it's lower than
zero change of direction okay that's
what we're going to do okay so um that's
all we're going to do and right so
basically what this is what this means
is like if so it's going to use the
reward as as a as a as a like a a
pointer it as a guide so if basically
it's saying that if if you've gone for
50 iterations and there's there so let
me just write us up so if if we go 15
iterations uh up with getting if we go
50 iterations and get a reward each step
we're doing something right we're doing
something right
so that's when we want to turn that's
when we turn okay so okay so that's the
basic logical let's go ahead and write
this out so if J is greater than or
equal to 15 right so so J is gonna be
there our reward okay for this step and
basically it's saying okay if you've
gone 15 iterations or more sorry it's 15
or more sorry 15 plus iterations so um
if the total sum of the iterations uh
sorry so if the total sum which is the
reward is the same as the iterations and
how do we define sameness well same this
is going to be a division right if
they're the same number uh as in there's
no remainder then turn is gonna be true
okay turn is gonna be true else um well
if it's not the same as in well you
haven't gotten a reward for every
iteration you've actually crashed some
times then turn is going to be false
okay so this is how it's it's reading a
reward it's using the reward as a guide
to to determine whether or not to turn
the actual direction to turn is random
but the but but
but the the reinforcement learning is
using the reward to determine whether or
not Saturn okay so we still haven't
defined the reward yet so that's going
to come up uh so assuming that we've
done this we've already defined you know
whether or not we we want to turn we can
go ahead and reset these variables
because we've already defined them they
played out what we what we wanted and
we're going to go ahead and reset them
okay so that includes the sum of rewards
the iteration count which and also the
previous total sorry nope and to the
previous total that this is this is when
it gets that the value of the total sum
because we've reset the total sum and
now the previous total is going to get
what happened before um okay and so and
it's a way of storing what we had before
um just so we know what what we had
before it's just it's good to give a
counter of that and we can extend that
too okay so means make sure everybody's
following alright thanks for a nice
world uh all right cool all right cool
so um previous total sum total sum okay
total sum equals zero okay so else we're
going to say turn is false
Oh basically if so this is the else so
this is if if it's not before not
receiving a reward every 15 iterations
then we're gonna say okay so don't turn
okay and so now we want to define now we
want to define whether or not we want to
clone now we want to make sure you know
empty white space not necessary keep it
clean you know how it is you know what
it is so if we have an observation
observation and if we have an
observation and there's something there
right if there's something there then
we're going to say okay we want to
increment the counter that's which which
we
which were comparing above we're going
to hit them at the counter and the sum
and the reward some okay so let me write
this out so J plus equal to this or
counter J plus equals 1 and then total
sum plus equals reward N and then total
sum reward n okay so now we're going to
return turn J total sum everything that
we calculated here and that's it okay
boom so let's go over what happened here
okay so um so okay let's go through this
step by step we initialized our
environment and then a set of variables
right that were that we were later going
to use okay then we define three actions
right three keyboard events going left
going right or going forward okay and so
because that's all we're gonna do so
then we started this while loop because
this is just gonna keep on running as
you know forever and we said and we said
okay so let's increment our counter
because well this for every step that
we're running and then we said if you've
MIFF our game has made at least one or
iteration check if we need to turn and
so okay so assuming that we made at
least one one iteration so the game has
moved one time step yet well uh and we
have something that we're seeing what
right the observation of the game arm
which depends on whatever game we have
we're going to store the reward in the
previous score and then determine if we
should turn or not so if we do turn that
we're going to pick a random turn so let
me go left to right encapsulate that
inside of an action variable and then
set turn to false again because we've
already done our action else if no turn
is needed just keep going straight and
uh this is how we determine whether
whether or not we want to turn with this
determines turn function and we use
those variables we defined previously
and then we actually implement that term
as a turn as an action using the
environment step function how do we
determine whether or not we want to turn
well for every 15 iterations we sum
total observations and we take the
average if it's lower than zero we
change the direction if we go 15 plus
iterations and get a reward at each step
we're doing something right and that's
when we turn that's our signal right in
Y 15 well it could be 16 it can be 17
it's arbitrarily going to be 15 right
now so if it's greater than or equal to
15 we'll take that sum divided by the
number of rewards that we got and if
it's the same because if we've been
doing it right this whole time turn or
else don't turn reset our variables and
then uh this this code down here is how
we get that some of the rewards and
returns okay so that's a basic
explanation I'm gonna go ahead and run
this all right um all right and okay so
so let's go ahead and run this code all
right um well go ahead and run this code
arm by saying what I call it to call
this demo arm right so where did I put
demo put it somewhere uh probably in
here right so uh Python I think it's
bigger whoa way bigger so Python demo
dot PI demo dot hi so now we're gonna
run this baby boom it's connecting to
our local docker container which has our
DNC server um WebSocket connection
failed whoa okay let's see what's
happening here ah Shh let's see let's
see let's see let's see um okay so I'm
gonna close out this let's try that
again sometimes if you open another
window it starts working so did the oh
okay so WebSocket closing on handshake
um Wow
this was working right before I started
the livestream okay so let's figure what
is going on here um so well first of all
first of all okay here's here's what it
is uh so online 80 line 80 in main
forward and observation line 80 what is
happening
for observation cane observation let's
see what's happening here armed
environment render uh okay so what I've
been saying here is else if turn forward
for observation in opposite if you guys
have suggestions open to those two um
let's see what people are writing here
Shh
okay so Oh capital have that might be it
that is that what it is is it i define
its capital f oh yes yes thank you okay
so now let's run this thing see look at
that uh yo yes okay awesome yo-yo okay
awesome yo yo yo okay great so what is -
it's connected to our local docker
container using the VNC protocol
remember so this is a this is a this is
a kind of like a virtual machine but
it's it's inside of this docker
container as a BNC um using the VNC
protocol and so now it's gonna connect
to github uh and it's going to let's see
let's see what's happening here uh come
on baby
yes you know what it is so here's our
game it's about to start
it-it's gonna load up and then it's
gonna run our code all right come on
coaster racer you know what it is
preparing graphics how great is that
preparing graphics that's some flash
 right there okay man it's laggy but
okay uh it's every 15 times if so so
iterations move fast in the game right
so it's like 15 steps are happening
every like second okay um and as you can
see it's it's determining like oh if I
hit something that I shouldn't be doing
that so randomly moving at different
directions if I hit something randomly
move in a different direction it doesn't
know it doesn't know like if I hit
something on the left to move right or
if it has something on the right smooth
left but it does know if it hit
something with it if it's not doing
something right for 50 iterations stop
okay so there's a demo code I wrote that
run
little bit it's kind of laggy but it's
pretty cool right
um boom we felt we fall fallen and it's
just gonna keep on going okay so I'm
going to exit out of that I'm gonna go
back to you guys quit quit out of
Terminal uh terminate as a terminator
says and then open up this screen
sharing okay
so I okay so uh last five minutes you a
and then we're good to go all right okay
all right so uh neural network is not in
eleven lines of code such as nine this
is my code right yes make a so Mick yes
this is this is uh one of our challenge
winners code Nick Ben holes this was one
of his entries to the challenge I just I
really liked it and I wanted to demo it
for you guys because I thought it was
not hard enough that it was like gonna
take like two three hours but it wasn't
easy enough where it was like just like
trivial this was just use reinforcement
learning and it was it was a good
example of that um where is the it okay
any good examples of universe I'll post
some examples in the description a
tutorial on Gann check search generative
adversarial networks on KITT on YouTube
my video is probably the first one that
that's couldn't pop up I'm gonna do more
in the future for sure I'm actually kind
of waiting for that to get a little
better because there's a lot of
possibilities with Gans like seriously
like seriously like generative models
for video like I mean like we could we
could generate movies and then say I
want to be in this movie assuming it was
good enough and had enough data like I
want you to to to generate Star Wars
except put me in it and like not have
Gungans like not have Jar Jar Binks like
that's the level of where we could get
suit like that's where I see the
trajectory moving in generative models
it's incredible with AI if you can dream
it it's possible if you can dream it
it's possible where did you learn
machine learning techniques on the
internet from machine learning subreddit
from Twitter from implementing code
myself on github from courses like uh
Andrew Long's course and from the deep
learning course on Udacity how are how
are you sure this code actually learns
because it's receiving the reward and
it's moving
reward what's happening on Friday party
I can't answer that right now
but you're gonna love it what do you
think of the new Apple paper I'll give
Apple
I still don't I still don't fully you
know respect Apple yet but if they if
they keep going with this yeah you know
this open source stuff you know there's
there's some potential there how did you
get your first 10 YouTube subscribers
just by posting videos even though I
just even though people didn't like them
that much I just I just believed in
myself I I just like a you know Reno a
positive feedback loop um practical
practical application for this for this
specific bot um uh any kind of racing
game that movie that's moving left to
right this could be applied to did you
check song Hans paper hit - uh not yet
I've been really busy um but I will how
to be a good programmer I'll make a
video on that watch all my videos
Tehran's custom voices system video um
custom voice assistant uh that's a good
question I haven't done voice
specifically like a voice assistant I'd
then build a tensorflow chat bot but not
a voiced version of that so that's gonna
come up um what do you think of
Microsoft has your ml actually you know
Microsoft is uh surprisingly starting to
get cool again I mean it's it's uh it's
incredible like what what Satya Nadella
has done he's he's he's taking Microsoft
in a different direction so I'm um
yes Mik I'm gonna add the link to the
descriptions hey Suraj what's next guys
just wait for Friday
um wait for Friday seriously like wait
for Friday are you going to do interview
videos yes I'm gonna do those soon yeah
I mean it's not in the immediate plan
maybe in two two weeks wrap on universe
as always I've got a wrap
um okay so wrap on universe okay I've
got a game but I do it without a thought
I look at the future and think man I got
to go away from here and find my flow
man my world is so high I'm so in the
sky I'm like a universe my mind is so
insane I'm like a fly on
as the universe comes down with planets
my my my okay that was it um that was my
yo be hyped man yo get hyped get hyped
get get hyped get super high because
this is this is huge I am meeting some
important people today okay so are you
vegetarian no um okay so bars okay so uh
have you looked into a hierarchical
temporal memory by Numenta yo Numenta as
great as Jeff Hawkins book on
intelligence is and as as much as I love
the idea of artificial general
intelligence Numenta hasn't really done
anything you know it hasn't published
results that that compared to deep mind
uh and they're kind of a joke in the
community so you know yeah and also
there hasn't any real innovation I mean
people have known this you know this
kind of hierarchical thing happening in
the brain but anyway so Elon uh hype
equals hype Elon uh alright cool so yeah
is it is it's not Elon but it will be
not not yet um not not Elon eventually
it you know maybe later this year I'm
taking my time I know I know what's
gonna happen we're gonna know is it's us
you know I'm saying it's we are a squad
guys we are we are an army we are a
force we are a movement and we are gonna
get everybody we're gonna get the
attention of the entire world okay we
are gonna get the attention of everybody
because this is a war path that we are
on we're gonna solve intelligence okay
so that's it for this video I love you
guys
thanks for watching um and for now I've
got to go start a revolution or sorry
continue a revolution so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>