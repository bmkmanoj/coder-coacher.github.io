<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tone Analysis - Fresh Machine Learning #3 | Coder Coacher - Coaching Coders</title><meta content="Tone Analysis - Fresh Machine Learning #3 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tone Analysis - Fresh Machine Learning #3</b></h2><h5 class="post__date">2016-07-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/89FHXM2q36s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">how does that make you feel I'm not sure
uh-huh
it's hard to say yeah well there's an
episode of serology coming and I just
don't have time for this right now so
polo world
it's Suraj have you ever had a hard time
trying to understand what someone is
trying to say to you people are
confusing I don't even understand my own
emotions half the time much less what
someone else is feeling or thinking when
we read a piece of text or listen to
someone speak our brains are performing
tone analysis we're trying to understand
the meaning behind the words that is the
sentiment and the emotions and the style
it's not an easy task at all but this is
something machines can do pretty well
now it's all a part of a subfield of
machine learning called natural language
processing standard approaches to NLP a
couple years ago involved extracting a
set of features from some labeled piece
of text the features were usually
engrams
engrams have nothing to do with graham
crackers even though they are extremely
delicious engrams are just sequences of
words so a unigram is one word by graham
is two and trigram is three once the
engrams were extracted the next step was
to train a linear model on some pre
labeled data so they could classify
similar text the process of feature
extraction saw a huge leap forward when
google open source something called word
to Veck word Tyvek is a toolkit that
helps in code words into vectors these
vectors are representations of words
called word embeddings that are learned
by training on a given corpus the
toolkit consists of two distinct models
Skip Graham and continuous bag of words
the Skip grant model predicts the
neighboring words given the current word
in a given window in contrast the bag of
words model predicts the current word
given the neighboring words in a given
window these model both help predict and
encode words once we have these vectors
we can use them to do all sorts of text
classification including tone analysis
Oh deep learning uh-huh one of the first
papers to show that deep learning could
improve text analysis was called
convolutional neural networks for
sentence classification although CNN's
were intended for computer vision these
guys applied it to NLP they first
trained the CNN on a set of word vectors
that Google extracted from a hundred
billion word corpus using their own
words avec toolkit after training the
CNN had built
presentations of all sorts of word
categories since the vectors weren't
labeled in any way the training was
considered unsupervised after they had a
train on a set of Google vectors they
then trained it using labelled data so
that it could perform sentiment analysis
a later paper called text categorization
using LST M for region embeddings
improved on it they needed the same
basic experiment but the key difference
is that they didn't just use a CNN to
create embeddings they also use a long
short-term memory network an L SCM is a
type of recurrent neural network that
can remember dependencies from way back
in the sequence of data and they found
that they had the best classification
result when they combine the embeddings
from both the LS TM and the CNN just
like two peas in a algorithm that was
terrible they also found that embedding
regions that are sets of words was more
effective than embedding single words
this idea of abstractions of a hierarchy
of knowledge in a given document helped
inspire a fresh paper released just two
months ago called hierarchical attention
networks for document classification
these guys said let's create a new
neural architecture to model a document
it starts by encoding words and applying
an attention mechanism to extract the
most important words then it encodes the
sentences using the weights it learned
and applies an attention mechanism to
that - to extract the most important
sentences it uses those weights to build
document level vectors so it's creating
vectors for each layer of abstraction
within a document and building them off
of each other
the encoder for each of these levels is
called a GRU neural net so after they
initialize the model using vectors they
got using word to Beck they trained it
on labeled data and doing this with
their novel neural architecture pretty
much outperformed all previous attempts
so how do we implement this stuff
ourselves well as Professor young says
deep learning requires our rocket the
model and rocket fuel the data but
sometimes you just want to get done
and training is too time expensive
that's why we're going to use IBM's
Watson API to perform tone analysis on
an example set first we'll need to sign
up for their cloud service called
bluemix once we've registered will click
on Watson then tone analyzer will create
a new service using the standard plan
which lets us try it out for free so no
need to enter a credit card which is
perfect because I'm poor then we'll
click on service credentials and record
username and password since we'll need
them to authenticate from our web app
then we can generate a new note Express
web app using NPM and the Express
generator module in our app we'll import
our Watson developer cloud NPM module
which acts as a thin JavaScript wrapper
around their API we have two routes here
both for our index page we'll start with
the get route when we make a get request
to the index page we want to display
some HTML that we can send
programmatically here we'll send an
input form that asks for some corpus
then in our post Ralph will retrieve the
input that the user submits via the post
request then initialize the tone
analyzer variable fill in our
credentials and call the tone function
using the user input variable as the
parameter this will return the analysis
of the text as JSON which we can view in
terminal let's try it out as you can see
it raised the Corbett's on three levels
emotions language style and social
tendencies you'll get back a percentage
for each of three language styles and
five social tendencies it doesn't set
both the document level and sentence
level tone analysis is a tool you can
use to better your writing and be more
clear about the message you're trying to
convey dope links for you down below
please subscribe for more ML videos I've
got to go fix an indentation error so
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>