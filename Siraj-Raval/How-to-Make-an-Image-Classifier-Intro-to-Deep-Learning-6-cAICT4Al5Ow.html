<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Make an Image Classifier - Intro to Deep Learning #6 | Coder Coacher - Coaching Coders</title><meta content="How to Make an Image Classifier - Intro to Deep Learning #6 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Make an Image Classifier - Intro to Deep Learning #6</b></h2><h5 class="post__date">2017-02-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cAICT4Al5Ow" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">how do we classify things we consider
people to be experts in a field if
they've mastered classification doctors
can classify between a good blood sample
and a bad one
photographers can classify if their
latest shot was beautiful or not
musicians can crack the by what sounds
good and what doesn't in a piece of
music the ability that classify well
takes many hours of training we get it
wrong over and over again until
eventually we get it right
but with a quality dataset deep learning
can classify just as well it's not
better than we can we'll use it as a
tool to improve our craft whatever it is
and if a job is monotonous it'll do it
for us when we reach the point where we
aren't forced to do something we don't
want to just to survive will flourish
like never before and that's the world
we're aiming for
hello world it's Suraj and today we're
going to build an image classifier from
scratch to classify cats and dogs
finally we get to work with images I'm
still in hives enough to do the Macarena
sure so how does image classification
work well there are a bunch of different
attempts in the 80s and early 90s and
all of them tried a similar approach
think about the features that make up an
image and hand CO detectors for each of
them but there is so much variety out
there no two apples look exactly the
same so the results were always terrible
this was considered a task only we
humans could do but in 98 a researcher
named Yamla kun introduced a model
called a convolutional neural network
capable of classifying characters with a
99% accuracy which broke every record
laocoon CNN learned features by itself
in 2012 it was used by another
researcher named Alex Khrushchev ski at
the yearly imagenet competition which is
basically the annual Olympics of
computer vision and it was able to
classify thousands of images with a new
record accuracy at the time of 85
percent since then CNN's have been
adopted by Google to identify photos and
search Facebook for automatic tagging
basically they are very hot right now
but where did the idea for TNS come from
and you these comments all be inspired
core-tex every single thing we see into
the vortex hellfire blinds of the sign
they're all going to column-organized
align and it helps us classify what we
see cats dogs take men a broccoli
ComNet learn don't bat business or
features classifying me as the king of
teacher well first want to download our
image data set from tackle with a
thousand 24 pictures of dogs and cats
each in its own folder we'll be using
the Kara deep learning library for this
demo which is a high level wrapper that
runs on top of 10 truffaut it makes
building models really intuitive since
we can define each layer as its own line
of code
first things first we'll initialize
variables for our training and
validation data then we're ready to
build our model will initialize the type
of model using the sequential function
which will allow us to build a linear
stack of layers so we treat each layer
as an object that feeds data to the next
one it's like a conga line kind of no
the alternative would be a graph model
which would allow for multiple separate
inputs and outputs but we're using a
more simple example next we'll add our
first layer the convolutional layer the
first layer of a CNN is always the
convolutional layer the input is going
to be a 32 by 32 by 300 pixel values the
three refers to RGB values each of the
numbers in this array is given a value
from 0 to 255 which describes the pixel
intensity at that point the idea is that
given this as an input our CNN will
describe the probability of hit being of
a certain class we can imagine the
convolutional layer as a flashlight
shining over the top left of the image
the flashlight slides across all the
areas of the input image the flashlight
is our filter and the region it shines
over is the receptive field our filter
is also an array of numbers these
numbers are weight at a particular layer
we can think of a filter as a feature
identifier as our filter slides or
involves around the input it is
multiplying its values with the pixel
values in the image these are called
element wise multiplication the
multiplications from each region are
then summed up and after we've covered
all parts of the image or left the
feature map this will help us find not
very treasure but a prediction which is
even better since our way to our
randomly initialized
our filter won't start off being able to
detect a specific feature but during
training our CNN will learn values for
its filters so this first one will learn
to detect a low-level feature like curve
so if we place this filter on a part of
the image with a curve the resulting
value from the multiplication and
summation is a big number but if we
place it on a different part of the
image without a curve the resulting
value is zero this is how filters detect
features
well next PATH does feature map through
an activation layer called riilu or
rectified linear units riilu is probably
the name of some alien but it's also a
nonlinear operation that replaces all
the negative pixel values in the feature
map with 0 we could use other functions
but riilu tends to perform better in
most situations this layer increases the
nonlinear properties of our model which
means our neural net will be able to
learn more complex functions than just
linear regression after that we'll
initialize our max pooling layer pooling
reduces the dimensionality of each
feature map or retains the most
important information this reduces the
computational complexity of our network
there are different types but in our
case we'll use max which takes its
largest element from the rectified
feature map within a window we define
and we'll slide this window over each
region of our feature map taking the max
values so a classic CNN architecture
looks like this 3 convolutional blocks
followed by a fully connected layer
we've initialized the first 3 layers we
can basically just repeat this process
twice more the output feature Maps is
fed into the next convolutional layer
and the filter in this layer will learn
to detect more abstract features like
pause and dose one technique we'll use
to prevent overfitting that point when
our model isn't able to predict labels
for novel data is called drop out a drop
out layer drops out a random set of
activations in that layer by setting
them to zero as data flows through it to
prepare our data for the drop out will
first flatten the feature map into one
dimension then we'll want to initialize
a fully connected layer with the dense
function and apply riilu to it after
drop out will initialize one more fully
connected layer this will output an n
dimensional vector where n is the number
of classes we
have so it would be - and by applying a
sigmoid to it it will convert the data
to probabilities for each class so how
does our network learn well we want to
minimize a loss function which measures
the difference between the target output
and the expected output to do this we'll
take the derivative of the loss with
respect to the weights in each layer
starting from the last two compute the
direction we want our network to update
will propagate our loss backwards for
each layer then we'll update our weight
values for each filter so they can
change in the direction of the gradient
that will minimize our loss we can
configure the learning process by using
the compile method where we'll define
our loss as binary cross-entropy which
is the preferred loss function for
binary classification problems then our
optimizer rmsprop which will perform
gradient descent and a list of metrics
which we'll set to accuracy since this
is a classification problem
lastly we'll write out our big function
to train the model giving it parameters
for the training and validation data as
well as a number of epochs to run for
each and let's save our weights so we
can use our train model later overall
accuracy comes to be about 70% similar
to my attention span and if we feed our
model a new picture of a dog or cat it
will predict its label relatively
accurately we could definitely improve
our prediction though by either using
more pictures or by augmenting an
existing pre-trained network with our
own network which is considered transfer
learning so to break it down
convolutional neural networks are
inspired by the human visual cortex and
offer state of the art and image
classification cnn's learn filters at
each convolutional layer that act as
increasingly abstract feature detectors
and with care often tentacle you can
build your own pretty easily the winner
of the coding challenge from the last
video is charles david block he used
tensorflow to build a deep net capable
of predicting whether or not someone
would get a match or not after training
on a data set and had a pretty sweet
data visualization of his result wizard
of the week and the runner-up is Sally
McLean organized and documented code the
coding challenge for this video is to
create an image classifier for two types
of animals instructions are in the
readme post you're getting in the
comment and on the winner next Friday
please subscribe if you want to see more
videos like this check out this related
video
now I got to upload my mind so thanks
for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>