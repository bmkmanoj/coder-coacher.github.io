<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Recurrent Neural Networks - The Math of Intelligence (Week 5) | Coder Coacher - Coaching Coders</title><meta content="Recurrent Neural Networks - The Math of Intelligence (Week 5) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Recurrent Neural Networks - The Math of Intelligence (Week 5)</b></h2><h5 class="post__date">2017-07-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BwmddtPFWtA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and today we're
going to generate words so given some
book or movie script or any kind of text
corpus you can it's plug in play so you
can give it any kind of text corpus it
will learn how to generate words in the
style of that corpus of text and in this
case we're going to give it a book the
book is called metamorphosis by Franz
Kafka which was a really crazy weird
writer from the 20th century anyway he's
cool dude anyway we're going to generate
words in the style of that book and this
can be applied to any text any type of
text it doesn't just have to be words it
can be code it can be HT know HTML
whatever it is but that's what we're
going to do no libraries just numpy so
I'm going to go through the derivation
the forward propagation calculating the
loss all the math so get ready for some
math put on your linear algebra and
calculus hats okay so this is kind of
what it looks like this first image here
and I'm going to actually code it as
well so it's I'm going to I'm not just
going to glaze over I'm going to code it
so we can see the outputs as I go but
the very end part will be I'm going to
code the important parts let me just say
that okay so okay so check it out given
some text corpus it will predict the
next character so what you're seeing
here is it actually printed it
predicting the next word but we're going
to do a character level recurrent
network so that means it's going to
generate character by characters okay so
character by character by character not
word by word by word okay so it's going
to be trained for a thousand iterations
and the more you train it the better
it's going to get so if you leave this
thing running overnight on your laptop
then by the time you wake up it'll be
really good however I wouldn't recommend
training it on your laptop as my song
says I train mom models in the cloud now
because my laptop takes longer right so
what is a recurrent Network right what
is this what is this thing we've talked
about feed-forward networks I've got two
images here of feed-forward networks the
first image is the most popular image
right it's that really funky looking
neuronal architecture but it's you know
it can be kind of confusing if you think
about it because it's not like these
neurons are classes and these classes
have links to all of the the other
neurons like it's some kind of linked
you know massive crazy linked list kind
of thing no it's or tree like thing it's
not really like that what's really
happening are a series of matrix
operations so these neurons are the
output of a series of matrix up these
neurons are actually just numbers that
we then activate with an activation
function so a better way of looking at
it would be as a computation graph a
more mathematically sound way of looking
at it so if you have some inputs and you
know the input could be anything what
you would do is you would multiply the
input by the weight matrix add a bias
value and then activate the result of
that and that would be your output that
you then feed in to the next layer a
layer that what you see as these neurons
a layer is actually just the result of a
dot product operation followed by adding
a bias value if you want to add a bias
which you should in practice you should
add a bias a built neural networks
without biases before for examples but
you really should add a bias and I'll
talk about why in a second but you
should add a bias value and then you
activate the output of that and by
activate I mean you take the output of
that dot product plus bias operation the
output of that and you feed it into a an
activation function a non-linearity
whether that's a sigmoid or tan H or
rectifies linear unit and the reason we
do that is so that our network can learn
both linear and nonlinear functions
because neural networks are universal
function approximator x' if we didn't
apply an activation function to it it
would only be able to learn linear
functions we're going to learn nonlinear
and linear functions and that's why we
apply an activation function to it now a
great way to remember this whole thing
is to just rap about it so input Tom's
weight add a bias activate repeat here
we go
input sing with me x weight add a bias
activate repeat and you just do that for
every layer you just repeat that process
okay so people or networks they're great
for learning an input-output pattern
what is their what is the rule here
between these
of inputs and a set of outputs right and
in the end a feed-forward Network and in
fact all neural networks it's just a 1
it's just one big composite function
what do I mean by that I mean that you
can think of a neural network as a giant
function and inside of that network are
smaller functions nested functions a
composite function is a function that
consists of other functions what do I
mean by nested functions
remember this computation graph that we
just looked at right here these are all
functions each layer is a function right
input times weights add a bias activate
that is a function that you feed the
output of to as the input to the next
function so what a neural network is so
the most nested function right in the
middle is this most nested function is
the first layer value whose output we
then feed to the next layer which would
be the next function whose output we
feed to the next layer so the largest
function the the most the the function
on the on the outside here is then the
output layer because we're feeding it
the inputs output the output of what of
all that that chain of computation that
already occurred right so that's what
that is so it's a composite function and
we would use p4 nets anytime we have two
variables that are related temperature
location hide and wait car speed and
brand these are all mappings but what if
does has done I'm just adding my own
sound effects don't add um what if the
ordering of the data mattered right what
if you had stock prices right it's a
very controversial topic but I just you
know the stock price thing gets a lot of
views even though I you know I don't
want to I don't want to i don't really
personally care about finance data but i
know some of you guys do and you know
I'll probably talk about it more in the
future
anyway tangent back to this what if the
time matters right so stock prices are a
great example of when time matters you
can just predict a mapping between time
and the price what happened before what
the stock prices before are what matter
to the current stock price that's
actually available in the
in the context of stock prices but it
applies to all time series data so video
right if you want to generate the next
frame in a video it matters what frames
came before it
you can't just learn a mapping between a
frame and the time that that frame shows
up because then what happens is given
some new time you can just generate a
frame based on nothing else right it
depends on the frames that came before
it you see what I'm saying the sequence
matters the sequence matters here the
alphabets or lyrics of a song you can
just generate a lyric or an alphabet
depending on the index that it's at
you've got to know what came before it
try to recite the alphabet backwards and
so to get into neuroscience for a second
try to recite the alphabet backwards
it's hard right zui x w ki qu okay see I
can't even do it right now I'm not going
to edit that out so or any song try to
recite a song backward you can't because
you learned it in a sequence it's a kind
of conditional memory what you remember
depends on what you've what you've
stored previously right it's conditional
memory in that way and that is what
recurrent networks help us do they help
us compute conditional memories they
help us compute the next value in a
sequence of values so that's what
recurrent networks are good at that's
what they're made for and it's not like
it so there's some new technology
recurrent networks are invented they
were invented in the 80s neural networks
were invented in the 50s but why is this
super hot right now why are you watching
this video because with the invention of
bigger data and bigger computing power
when you take these recurrent networks
and give them those two things they blow
almost every other machine learning
model out of the water in terms of
accuracy so it's just incredible anyway
this is a picture of a three-layer and
they could this is a picture of a
three-layer recurrent Network right so
you've got your first layer which is
your input your hidden state your output
layer and so that would just be a
feed-forward Network but the difference
here is that we've got this other layer
right here and that is so what that what
that other layer is it's not actually
another layer the difference is that
we've added a third weight matrix so
we've got our first weight made
our second wave matrix we've got a third
wave matrix and that's really what makes
it different than a feed-forward network
is that we're adding a third wave matrix
and what the third weight matrix is
doing it is connecting the current
hidden states so the hidden state at the
current time step to the hidden state at
the previous time step so if they were
current weight matrix and you'll see
programmatically and mathematically what
I'm talking about but that's really the
key bit here for recurrent networks
that's what makes it unique from
feed-forward networks and so what this
does is whenever we feed in some value
you know because we are training this
network right we continuously feed it
new data points data point after data
point from our training set but for
feed-forward networks
we're only feeding in the input we're
not feeding in that the previous hidden
states
we're only feeding an input after input
after input and the hidden state is
being updated at every time step but
because we want to remember a sequence
of data we're going to not just feed in
the current data point wherever we are
we're also going to feed it in the
previous hidden state and that is and by
that I mean the values that are computed
from the previous time step for that
hidden States right that set of numbers
that matrix and so you might be thinking
wait a second why don't we just feed in
the input and in the previous input as
well from the previous time set why are
we feeding in the input in the previous
hidden state because input recurrence
only remembers what just happened that
previous input but if you feed it in the
previous hidden state then what's
happening is it can remember that
sequence it's not just about what came
right before it it can remember
everything that came before it because
you can think of that hidden state as a
kind of like a like think of it like
clay that's being molded by every new
input it's being molded by every new
input and by feeding that clay that's
being molded back into the network it's
it's being a it's learning neural memory
so it's a form of neural memory
conditional memory and it can remember
sequential data so right so here's
another example just to give a few more
examples before I go into the code here
but we
have so this this is a very popular type
of image for recurrent networks so
what's happening is it's we're feeding
in the current input calculating a
hidden state and then computing an
output and then for the next time step
we're giving it that new data points as
well and so the blue arrow is what's
different here compared to a
feed-forward Network we're feeding in
the previous hidden state as well the
input to compute the current hidden
States to compute our output our Y value
and we're using a loss function to
improve our network every time and so if
you think of what that recurrence looks
like it looks like this so remember that
feed-forward network we just looked at
the difference here is that we are
feeding in the output of the hidden
state back into the input the output of
this wait times bias activate operation
that's in a layer okay so of the formula
for a recurrent Network looks like this
which basically says that the current
hidden state HT is a function of the
previous hidden state and the current
input okay and the theta value right
here are the parameters of the function
so the network learns to use H of T as a
lossy summary of the task relevant
aspects of the pass sequence of inputs
up to t the loss function that we're
going to use here is going to be the
negative log likelihood okay this is a
very popular loss function or recurrent
networks look like plain old recurrent
networks not using anything fancy like
long short-term memory cells or
bi-directional
capabilities but the negative log
likelihood usually give us the best
output or the best accuracy for plain
old recurrent networks which is why
we're going to use it and we'll talk
about what that consists of in a second
but our steps for this are going to be
the first initialize our weights
randomly like we always do and then give
it then we're going to give the model a
char pair so what is the char pair the
char pair is going to be the input char
so that's some seed some some letter
from the training text that we want to
give us input as well as a as the target
char and the target char is going to be
our label so our label is actually the
next char so if we take the first two
chars from some input texts from some
Korkis let's say the word is the the
input char would be T then the target
char would be H so given T we want to
predict H so you see how that that
target char acts as our as our label
that we're trying to predict and so once
we once we have that H we can compute
the most likely next character and then
compare from our forward paths we're
going to calculate the probability for
every possible next char given that T
according to the state of the model
using the parameters and then we're
going to measure our error as a distance
between the previous probability value
and the target char so that that's
that's what axes are in our our label
the next char in the sequence and we
just keep doing that so it's a dynamic
error right and so we once we have that
error value we'll use it to help us
calculate to help us calculate our
gradients for each of our parameters to
see the impact they have on the loss and
that is back propagation through time
and we call it through through time
because we are using that that hidden
States a hidden state matrix that
recurrent matrix value but otherwise
it's just the same it's just back
propagation it's called through time
because we are applying that some hidden
say 2 hidden state matrix to it ok so
then once we have our gradient values
we're going to update all the parameters
in the direction via the great in the
right direction to minimize the loss
that's great in the sense V are
gradients and we just keep repeating
that process so everything is the same
here gradient descent as a fee for
network gradient descent calculating an
error value a forward pass for the
difference is that we are connecting the
current hidden States to the previous
hidden state and that changes how the
network learns so what are some use
cases I talked about time series
prediction specifically weather
forecasting yet stock prices traffic
volume sequential data generation as
well music video audio any kind of
sequential data what is the next note
the next audio waveform the next frame
in the video ok and then for other
examples I've got great one a great one
here for binary audition that was
originally invented by track
who is a great technical writer
definitely check that out and so once we
understand the intuition behind
recurrent networks then we can move on
to LS TM networks and bi-directional
networks and recursive networks those
are more advanced networks and that you
they solve some problems with recurrent
networks before you get there you've got
to understand recurrent networks okay so
this code contains four parts the first
part is for us to load the training data
then we'll define our network then we'll
define our loss function and the loss
function is going to contain both the
forward pass and the backward pass so
the real meat of the code is going to
happen in the loss function and what
it's going to do is it's going to return
the gradient values that we can then use
to update our weights later on during
training but the meat of the code is
going to happen in the loss function and
once we we've defined that will write a
function to then make predictions which
in this case would be to generate words
and will train the network as well ok so
our first step is going to be load up
our training data so to load up our
training data the to load up our
training data I'm going to say ok so
let's define what that what that data is
by the way so if we open this file we'll
look at it Casa Calcutta TST it's one
morning when Gregor Samsa woke up from
trouble dreams with a right so this is
just a book it's a big book a big txt
file that's what it is the input is
going to be ok so we'll open it up using
the native functions here of python and
it's going to be recursive because we
want to we want all of it we'll just
read that simple plain txt file
and then we're going to say ok let's get
that a list of data points and our chars
in this case we'll store it in charge
and we'll define how big our data is as
well as our vocab our boat capsized and
we can say that the it's going to be the
length of the data that that big text
file as well as the length of the chars
how many chars do we have and we'll
print it out for ourselves just so we
know how many cards are
our and once we've done that we can go
ahead and print it out and it's going to
tell us how many unique char there are
which matters to us because we want to
make a vector of the size of the number
of chars that there are so let me go
ahead and print that out and it's going
to tell us exactly what the deal is and
so we've got a that's how many
characters it has okay so the data has
137 K characters and eighty-one of them
are unique okay good good to know good
to know our next step is to calculate
the vocab size okay so we're going to
calculate the boat capsized because we
want to be able to feed vectors into our
network we can't just feed in raw string
you know chars we've got to convert the
chars to vectors because a vector is an
array of a float values in this case or
a vector is an array a list of numbers
in the context of machine learning and
so so we'll calculate the vocab size to
help us do this so we're going to create
two dictionaries and both of these
dictionaries are going to convert the
both of these dictionaries are going to
convert the characters to integers and
then the integers to characters while
respectively one we'll convert from
character to integer which is the one
that I've just written and then the next
one is going to say let's convert the
integers to characters and once we've
done that we can go ahead and say well
let's print all of the values that it's
it's storing because these are our
dictionary that we're going to use in a
second to convert our values into
vectors so let's go ahead and print that
and what's the deal here oh and numerate
write a new breaks great great right so
here are our vectors right there it's a
dictionary or here here are dictionaries
one for characters two integers and one
for integers two characters okay so once
we have that now
so we've done that already and so then
we're going to say let's create a vector
for character a so this is what
vectorization looks like for us so let's
say we want to create a vector for the
character a so we'll say it will
initialize the vector it's empty so it's
just a vector of zeros of the size of
the vocab okay and so of the size of our
vocab and then we'll say okay so so
convert the knot now we're going to do
the conversion we'll say char to integer
so a to the integer so that's so that's
going to be our input it's going to give
us an integer value and we're going to
set it to one and so what happens is
when we print out this vector it's going
to be a vector of size let's see if I
got that right there's going to be a
vector of size hold on all right
important um pie I forgot importing
numpy yeah okay right so it's a vector
of size how many unique characters were
there there were 81 unique characters so
the vector of size 81 and all of those
values all those elements in the vector
are going to be 0 except for the one
that is the mapping between a and its
respective integer in that dictionary so
that's how we mapped it that's why we
created those two dictionaries so this
is what we would feed in as a so we will
feed it in two of these because remember
I said that we have a char pair so we'll
feed an A and whatever the next
character is as our input which would be
our input in our label value and the
label is our other character our next
character ok so then for our model
parameters we're going to define our
network remember it's a 3 layer Network
we have our input layer our hidden layer
and our output layer and so all these
layers are fully connected so that means
every value is going to be connected to
every other value between layers ok so
the way we'll define that is 2 well
first let's define our hyper parameter
but I got it we got to define our tuning
knobs for the network so we want to say
that our network and I have a hundred
hidden neurons words for it
neurons for it's hidden layer and then
we're going to say that we want there
going to be 25 characters that are
generated at every time step that's our
sequence length and then our learning
rate is going to be this very small
number because if it's too slow then
it's never going to converge but if it's
too high then it will overshoot and it's
never going to converge the learning
rates by the way is a is how quickly a
network abandons old beliefs for new
ones so if you're training your neural
network on cat dog images the lower the
learning rate the less likely it will be
to when given a new dog picture if your
just been trying it on cat pictures if
you give it a new dog picture the less
likely it'll be to consider that as a
part of the training data you're kind of
be able to recognize both the lower the
learning rate the more likely it will
consider that dog picture just an
anomaly and just kind of discard that
internally so it's a kind of way of to
tune how quickly a network diao abandons
old beliefs for new ones that's another
way of putting it
anyway so that's for our hyper
parameters now we'll define our model
parameters right we've defined our model
parameters and now we can define our
network's wave values so the first set
of weights are going to be from our
inputs so X so W X H so X is our input
this is what the terminology is right so
the weights from our input to our hidden
States right so that's going to be
initialized randomly using the numpy
random random brand and function and it
will be with value between the hidden
size that we've defined and the vocab
size because those are the two values
that we're dealing with here and we'll
multiply it by 0.01 because we just want
to scale it for a character level
recurrent Network because it's a
character level recurrent network so
input to hidden state and so then we
will repeat that process but this time
for our not from our input to hidden but
for our hidden state to our next hidden
state and so that's our recurrent weight
matrix right there that's our current
weight matrix and so lastly we'll have
our third
matrix which is our what's what's our
third way matrix our third wave matrix
is our hidden states to our outputs
value our output and so that's going to
be vocab size to between between the
vocab size and the hidden size and then
we will also since we have two bias bias
these will say the bias for hidden state
will be initialized as a set of zeros of
size of the hidden size because it's for
our hidden state and then we will so
that's our hidden bias and one more bias
and that is for our our output by that
is our output bias also a collection of
zeros the difference here is that is of
the vocab sighs okay and so yeah great
oh let's see what we got here
insides is not defined in size is right
here compile compile what's still hidden
size is not defined yes it is yes it is
invalid syntax crate so the function is
going to take as its input a list of
input chars a list of target chars and
the previous hidden state and then this
functions going to help put a loss a
gradient for each parameter between
layers and in the last hidden state so
what is the forward task so the forward
path in a recurrent Network looks like
this this function describes the forward
pass or at this function describes how
the hidden state is calculated right so
so so how is the forward task calculated
so the forward task is remember it's
just a series of matrix operations so
this is this is basically our forward
path right here what you're looking at
right here so this first equation right
here is what is let me make this smaller
so you can see so the way we compute
this math operation right here this is
the forward pass is the dot product
between the input to hidden state weight
matrix and the input data that's this
term right here plus the dot product
between the hidden States the hidden
state the hidden state matrix and the
hidden States and then we add the hidden
bias and that's going to give us the
hidden state value at the current time
step right so that's what that
represents and then we take that value
and we feed it we compute a dot product
with the next weight matrix and that is
the hidden state to the output and then
we add that out that output bias value
and that's going to give us the unnormal
unnormalized log probabilities for the
next charge which we then squash into
probability values using the this this
function P which is actually right here
P right here but I'll talk about that in
a second okay so that's our forward pass
and then for our backward pass the
backward pass is going to be before I
talk about the backward pass let's talk
about the loss per second so the loss is
the negative log likelihood so it's the
negative log value of P and P is this
function here so which is represented
programmatically by this right here
right so it's the
it's e to the X where X is the output
value from the that it received divided
by the sum of all of the e to the
probability values okay and that's going
to give us P a p-value okay and so we
take that p-value and then we take the
negative log of that p-value and that is
our loss scalar that lost scalar value
and so once we have that loss we're
going to we're going to perform back
propagation using that loss and so the
way we compute back propagation to go
over this is by using the chain rule so
the chain rule is from calculus what we
want to do is compute gradient for each
of the layers okay so for each of the
weight matrices okay given an error
value we're going to compute the partial
derivative of the error with respect to
each weight recursively so the reason
we're using the chain rule is that so so
because we have three wave matrices we
have the input to hidden hidden to
output and hidden to hidden we want to
compute gradient values for all three of
those so that's what this looks like we
want to compute gradient values for all
three of those weight matrices and the
way we're going to do that is to compute
our loss using the negative log
likelihood and use that laws to compute
the partial derivative with respect to
each of these weight matrices and once
we have those though that's our gradient
value that's the change that's the Delta
we can then update all three weight
matrices at once and we just keep doing
that over and over again
so our first gradient of our loss is
going to be computed using this using
this function so compute P minus one and
that's going to give us our first
gradient and we're going to use the
chain rule to backward pass that
gradient into each into each weight
matrix so let me talk about what I mean
by this so the chain rule so remember
remember how I said neural networks are
giant composite functions right it's a
giant composite function and what the
chain rule lets us do is that lets us
compute the derivative of a giant of a
function as a salt as the product of
derivatives of its nested functions so
chain rule in the case of f of X right
here if f of X is a composite function
that that consists
G of H of X then the chain rule would be
to say well let's compute the derivative
of G of H of X times the derivative of H
of X at nested function so you multiply
it by the derivative of the inside
function and that will give you the
derivative of that bigger function okay
and you keep doing that for as many
nested functions as you have here's
another example if I want to derive the
function 3x plus 1 to the fifth then I
would say well this is actually a
function and the function is the outer
function G of X is 3x plus 1 to the
fifth so so we're using the power rule
we take the exponent value move it to
the coefficient and subtract one from
the exponent so then it would be 5 times
3 of X plus 1 to the fourth times the
derivative of the nested function which
is 3 of 3x plus 1
and that's the chain rule and so then if
we multiply those two derivatives
together that will give us a derivative
of the larger function f of X so that
same logic applies to neural networks
because neural networks are composite
functions so we are recursively moving
this derivative this partial derivative
value by moving I mean multiplying dot
product or computing the dot product
between the partial derivative
calculated at the last layer and we're
multiplying it by every layer
recursively going backward this will
make more sense as we look at this
programmatically but that's what's
happening here
and yeah that's what's happening here so
let's let's let's let's code the cell by
the way the bias the reason we add a
bias
is it allows you to move the thing of it
as like this you know in the y equals MX
plus the equation it allows you to move
the line up and down to better fit the
data without B the line will always go
through the origin 0 0 and you might get
a poorer fit so a bias is kind of like
an anchor value anyway to define our
loss function our loss function is going
to be so we're going to give it our
inputs and our targets as its parameters
as well as the hidden state from the
previous time step ok so then let's
define our parameters that we're going
to store these values in so I'm going to
define four parameters ok these are
lists that
going to store values at every time step
in okay as we compute them so these are
empty dictionaries so X of X so X s is
going to will store the one hot encoded
input characters for each of the of the
25 time steps so can sort this will
store the input characters HS is going
to store the hidden state outputs okay
YX will store the target values and PS
is going to take the Y's and convert
them to normalize probabilities for
chars okay so then let's go ahead and
say H of X H oh sorry
HS the value of HS is going to be the
reason we're copying that so check this
out we're going to initialize this with
the previous hidden state the HS
currently with the previous in states
and using the equal sign would just
create a reference but we want to create
a whole separate array so that's why we
don't we don't we don't want HS with the
element negative 1 to automatically
chain if change if H previous has
changed so we'll create an entirely new
copy of it and so then we'll initialize
our loss as 0 and then and then okay so
we'll initialize our loss as 0 so this
is our loss scalar value and then we'll
go ahead and do the forward pass so the
forward pass is going to look like this
ok so we've already looked at it
mathematically and now we can look at it
programmatically so we'll say ok so for
each value in the range of inputs so for
the length of inputs let's compute a
forward pass so the forward pass is
going to be we're going to start off
with that one of K representation we
place a 0 vector as the teeth input and
then inside that T input we use the
integer in inputs list to set the
correct value there okay so that's that
in that second line and then once we
have that we're going to compute the
hidden state now remember I showed you
the equation before we just repeat that
equation here and then we compute our
output just like I showed before and
then our probabilities of the
probabilities for the next chars once we
have our probabilities we'll compute our
softmax cross-entropy loss which is the
negative log likelihood it's also called
the
entropy you'll actually see that in
tensorflow the cross entropy as a
predefined function but we're computing
it by hand here and so once we have the
forward pass now we can compute the
backward pass we're going to compute the
gradient values going backwards so
initialize empty vectors for these
gradient values right so the gradient so
these are the gradient are the
derivatives the derivatives are our
gradient it's the same thing here so
we're computing our derivatives with
respect to our weight values from X to H
from H to H and then from H to Y and
we'll initialize them as zeros and then
also we also want to derive we also want
to compute partial derivatives or
gradients for these of bias values for
our hidden state and our output and then
as well as for our next which means the
next time step that the hidden state in
the next time step derivatives for all
of them when we do back propagation
we're going to we're going to collect
our output probabilities and then derive
our first gradient value
now our first gradient value it looks
like this let me go back up here this is
how we compute our first gradient value
with respect to R with respect to our
loss all right that's the first gradient
value so we're going to compute the
output gradient which is the output
times the hint states transpose and we
can think of this so one so check this
out right here so this is our first
partial derivative with our for our our
hidden States to y2 our output layer
that matrix and you can and so what we
do is we compute the dot product between
that output and the transpose of the
hidden state the reason we use a
transpose is we can think of this
intuitively as moving the error backward
through the network giving us some sort
of measure of the error at the output of
that layer so when we compute the dot
product between the transpose of some
layers matrix with the derivative of the
next layer that is moving the error
backwards it's kind of it's it's back
propagation because the error value it's
constantly changing with respect to
every layer that it moves through and by
multiplying it by the transpose of a
layer the dot product from the partial
derivative with the previous layer times
where we currently are it's going to
output a gradient value that
that that derivative right and we'll use
that derivative later on to update other
values as well so we're also going to
compute the derivative of the output
bias and then we're going to back
propagate into H so notice how we are
continuously performing dot product
operations here for every single layer
we have we're also back propagating
through the pan H non-linearity right so
we are computing the derivative value
and this is programmatically what they
do what the derivative of tan H looks
like and we're using the computed
derivatives from the previous layer that
we were at at the end of the network the
tail-end as we move through to the
beginning as we're using them as values
to compute the dot product of the whole
point of computing the dot product with
these with respect to each of these
layers is that we are computing new
gradient values that we can then use to
update our network later on so then we
use that raw value to update our hidden
value and then we lastly with we compute
the derivative of the input to the
hidden layer as well as a derivative
derivative of the hidden layer to the
hidden layer and once we have that we
can return all of those derivatives our
gradient values are our change values we
can return all of that now there's also
this step right here to mitigate
exploding gradients which we're not
going to go into right now because it's
not really necessary however I will say
this that whenever you have really
really long sequences of input data like
like the Bible just a huge book then
what happens is as the gradient is
moving by moving I mean you're computing
the dot product of it for every layer
with the current weight matrix wherever
you're at using the partial derivative
the the gradient value will get smaller
and smaller there's it's a problem with
recurrent networks that's called the
vanishing gradient problem okay and so
it gets smaller and smaller and there's
a way to prevent that one way is to clip
those values by defining some some
interval that they can that could they
can reach or another way is to use LSP m
networks which we're not going to talk
about but anyway yeah so that's our
forward
backward paths we computed that inside
of the loss function and we computer our
loss as well right here using softmax
cross entropy so for as many characters
as we want to generate we will do this
so we'll say the forward path is just
like we did before it's the same exact
thing it's just repeating the code over
and over again input times weight
activate repeats get the probability
values pick the one with the highest
probability create a vector for that
word customize it for the predicted char
and then add it to the list and we just
keep repeating that for as many n
defines how many characters we want to
generate so we can generate as many
characters as we want on a trains
network and we'll print those out ok so
then for the training part we've really
competed we've completed that that meted
that code right but now for the training
part we're going to feed the network
some portion of the file and then for
the loss function we're going to do a
forward pass to calculate all those
parameters for the model for a given
input for a given input output pair the
current char the next char and we're
going to do a backward pass to calculate
all those gradient values and then we're
going to update the model using a
technique if it's a type of gradient
descent technique called
a de grad which is just it just decays a
learning rate but it's great in descent
you'll see what I'm talking about it's
not complicated but it's called a de
grad so we're going to create huge
arrays of chars from the data file the
target one is going to be shifted from
the input one so basically just shifted
by one as you notice here so now we have
our inputs in our targets right and
these numbers are actually character
values in the dictionary but they
represent the hippo they help us create
vectors where the indices here represent
the one out of all the zeros and the
zero vector and that's what we feed into
our model so at a grad is our gradient
descent technique and the difference
here as composed as compared to regular
gradient descent is that we decayed a
learning rate over time and what this
does is it helps our network learn more
efficiently this is this is the equation
for at a-- grad we're a step size means
the same thing as a learning rate but
basically the learning rate gets smaller
smaller during training because we
introduced this memory variable that
grows over
time to calculate the step size and the
reason it grows while the step size
decreases is because inside of the
denominator of this function right here
this is a programmatic representation of
the mathematical equation that you're
looking at right here so here's the
programmatic implementation of that we
calculate this memory value which is we
is our gradient right of our parameters
and then we update our and then we
update our weight matrix condition on
the learning rate which decays over time
via this function right here so finally
so this is really this is so we compute
we've done all the math and now it's
just implementing it so so we have our
weight matrices here we have our memory
variables for Atta grad and then we will
say for a thousand iterations well
actually a thousand times 100 iterations
we want to feed the loss function we
want to feed the loss function the input
vectors to see how this part works we're
going to feed the loss function our
input vectors and then we're going to
compute a forward task using that loss
function and it's going to compute the
loss as well it's going to return the
loss function or the lost scalar it's
going to return the derivatives or
gradients with respect to all of those
weight values that we want to update and
then we're going to perform the
parameter update using a DES grad right
so we'll feed all those derivative
values to our at a grad this is a de
Bresse so so we'll feed all those
derivative values to our ad a grad
function right here okay and it's going
to update our parameters and basically
the learning rate just decays over time
that's what that's why I'm M is
calculated to decay to learning rate
over time and which just helps with
convergence and there's different
gradient descent techniques atom on
different ones like that but momentum
but yeah Atta grad is one of them and so
once we do that we can look at our
sample function here or sample function
and our sample function is going to
right here we're going to keep we're
going to generate 200 word of 200
character sentences at a time for
for a thousand times 100 iterations so a
lot of iteration 100,000 iterations okay
so let's go ahead and run this and see
what happens okay see the first
iteration is really bad look at that
it's just like weird characters okay but
now it's got more human readable
characters okay it's getting better now
it's like he ate less notice how the
loss of decreasing very rapidly here as
well okay and so yeah it's getting
better over time okay so that's it for
our network and let me stop this and you
can feed it anything really you can feed
it any text file it's going to work with
any text file okay so we've computed the
forward pass the backward pass that the
backward pass is just a chain rule okay
I've got links to help you out in the
description but it's just a chain rule
we're just continuously computed
computing derivatives or gradient values
partial derivatives or gradients same
thing we call them partial because there
were with respect to each of the weights
in the network going backward and we are
moving this error by moving we're
computing the dot product of each layer
matrix by the derivative of the previous
layer just continually and that's the
chain rule and if we do this we can
generate words we can generate any type
of word we want to give in some some
text corpus you can generate Wikipedia
articles you can generate fake news you
can generate anything really code and
yeah so also for deep learning you might
be asking what for deep learning which
of these layers do we add deep which
where do we add deeper layers to do we
add more layers between the input and
the hidden state between the hidden
state and the output or between the
hidden state and the hidden state matrix
which direction do I add deeper and
deeper layers well the answer is that it
depends this is one thing that's being
worked on but the but the idea is that
you'll get different results for
whatever whatever set of matrices that
you add deeper layers to there's
different papers on this but yes
adding deeper layers is going to give
you better results and that's deep
learning recurrent Nets applied to deep
learning but this is a simple three
layer feed-forward network that works
really well and I would very much
encourage you to check out the github
link in the
and the learning resources to learn more
about this so yeah please subscribe for
more programming videos and for now I've
got to do a Fourier transform so thanks
for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>