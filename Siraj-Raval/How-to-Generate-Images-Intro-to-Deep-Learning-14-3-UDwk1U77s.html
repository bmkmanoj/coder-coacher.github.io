<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Generate Images - Intro to Deep Learning #14 | Coder Coacher - Coaching Coders</title><meta content="How to Generate Images - Intro to Deep Learning #14 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Generate Images - Intro to Deep Learning #14</b></h2><h5 class="post__date">2017-04-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3-UDwk1U77s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">whole world it's Suraj and what happens
when we encounter data with no labels
can we still learn from it we're going
to use a really cool model called a
variational auto encoder to generate
unique images after training on a
collection of images with no labels most
of the recent successes in deep learning
have been due to our ability to Train
neural networks on huge sets of cleanly
labeled data so if you have a set of
inputs and their respective target
labels you can try and learn the
probability of a particular label for a
particular input intuitively this makes
sense we're just learning a mapping of
values but the hottest area of research
right now is learning from the raw
unlabeled data that the world is
absolutely brimming with unsupervised
learning one type of model that can do
this is called an auto encoder
autoencoders sequentially deconstruct
input data into hidden representations
and use those same representations to
sequentially reconstruct outputs that
resemble their originals Auto encoding
is considered a data compression
algorithm but their data specific so it
can only compress data similar to what
it's been trained on they're also
relatively lossy so the decompressed
outputs will be a bit degraded compared
to the original inputs usually a
well-known compression algorithm like
JPEG does better so what are they useful
for absolutely nothing just kidding one
major use case is data and denoising
where we train an auto encoder to
reconstruct the input from a corrupted
version of it so that given some similar
data that's corrupted it can be noise it
another is to generate similar but
unique data which is what we'll do there
are a bunch of different auto encoder
types and each has its own unique
implementation details but let's dive
into one I find particularly interesting
the variational auto encoder or Dae
while deep learning is a great way to
approximate complex functions Bayesian
inference offers a unique framework to
reason about uncertainty it's an
approach to statistics in which all
forms of uncertainty or expressed in
terms of probability at any time there
is the evidence for and against
something which leads to a probability a
chance that it is true when you
something new you have to fold this new
evidence into what you already know to
create a new probability Bayesian theory
describes this process mathematically
the idea for the Dae came when these two
ideas merged so looking at it through in
Bayesian lens we treat the inputs hidden
representations and reconstructed
outputs of a BAE as probabilistic random
variables within a directed graphical
model so it contains a specific
probability model of some data X and
latent or hidden variables Z we can
write out the joint probability of the
model this way given just a character
produced by the model we don't know
which setting of the latent variables
generated the characters we've built
variation into our model it's inherently
stochastic looking at it through a deep
learning lens a bae consists of an
encoder decoder and loss function so
given some input X let's say we've
gotten 28 by 28 handwritten digit image
which is 784 dimensions where each pixel
is one dimension it will encode it into
a latent or hidden representation space
which is way less than 784 we can then
sample from a Gaussian probability
density to get noisy values of the
representations let's start writing this
out programmatically after importing the
libraries and finding our hyper
parameters we'll initialize our encoder
network it's job is to map inputs to our
latent distribution parameters we'll
take the input data and send it through
a dense fully connected layer with our
choice of non-linearity to squash the
dimensionality which will be really then
convert the input data into two
parameters in a latent space we pre
define the size of using dense fully
connected layers again the mean and the
log Sigma the decoder takes the Z as its
input and outputs the parameters to the
probability distribution of the data
let's say each pixel is either 1 or 0
since it's black and white we can use a
newly distribution since it defines a
success as a binary value to represent a
single pixel so the decoder gets the
latent representation of a digit as
input and outputs 784 Bernoulli
parameters one for each of the pixels
we're going to use these two variables
we have here two randomly sample news
similar points from the latent normal
distribution by defining a sampling
function epsilon refers to a random
normal tensor once we have Z we can feed
it to our decoder the decoder will map
these latent space points back to the
original input data we'll initialize it
with two fully connected layers and
their own respective activation
functions and because the data is
extracted from a small dimensionality to
a larger one some of it is lost in the
reconstruction process but how much we
need a measure of this and that will be
our loss function I want to generate
some data unpredictably so my model is
the Catholic probability for a VA e the
loss function looks like this the first
term measures the reconstruction loss if
the decoder output is bad at
reconstructing the data well that will
consequently incur a large cost here the
next term is the regularizer
regularizing in this case means keeping
the representations of each digit as
diverse as possible if a2 was written by
two different people we can end up with
very different representation that's a
bad thing we only want one since they
both wrote the same number we penalize
bad behavior this way and it makes sure
similar representations are close
together so our total loss function is
defined as the sum of our reconstruction
term and the KL divergence
regularization term all right so this is
the dopest part the way we normally want
to train this model is to use gradient
descent to optimize a loss with respect
to the parameters of both the encoder
and the decoder but wait how are we
going to take derivatives with respect
to the parameters of a stochastic or
randomly determined variable we've built
randomness into the model itself
gradient descent usually expects that a
given input always returns the same
output for a fixed set of parameters
the only source of randomness would be
the inputs what do we do cowboy we're
gonna leave parameter ass we want to
repr ammeter eyes samples so that the
randomness is independent of the
parameters so we define a function that
depends on the parameters
deterministically and we inject
randomness into the model by introducing
a random variable instead of the encoder
generating a vector of real values it
will generate a vector of means and a
vector of standard deviations then we
can take derivatives of the functions
involving Z with respect to the
parameters of its distribution will
define our models optimizer as rmsprop
which performs gradient descent and it's
loss function as the one we defined then
we'll train it by importing our digit
images and feeding them into our model
for a given number of epochs and batch
size for our demo we can plot out the
neighborhood of the different classes on
a 2d plane each colored cluster
represents a digit representation and
close clusters our digits that are
structurally similar we can also
generate digits by scanning the lading
plane sampling latent points at regular
intervals and generating the
corresponding digit for each of these
points so the three key takeaways here
are that variational autoencoders allow
us to generate data by performing
unsupervised learning they are a product
of two ideas Bayesian inference and deep
learning and we can back propagate
through our network by performing a
reaper ammeter rising step that makes
randomness independent of the parameters
we derive our gradients from Mike
McDermott is last week's coding
challenge winner he cleverly applied the
multi-armed bandit problem to the stock
market each block he created used a
different investment strategy based on
reinforcement learning to prophet and
his ipython notebook is a great example
of what well-documented code looks like
wizard of the week and the runner-up is
SGS var he successfully took state into
account which made it the contextual
bandit problem dope submissions guys
I've Allen to both of you the coding
challenge for this video is to use a bae
to generate something other than digit
images details are in the readme github
link so in the comment and winners are
going to be announced next week please
subscribe if you want to see more
program
videos check out this related video and
for now I've got it even with my hair so
thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>