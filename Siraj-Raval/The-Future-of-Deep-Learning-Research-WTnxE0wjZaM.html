<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Deep Learning Research | Coder Coacher - Coaching Coders</title><meta content="The Future of Deep Learning Research - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of Deep Learning Research</b></h2><h5 class="post__date">2017-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WTnxE0wjZaM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and what is the
future of deep learning that's the topic
for today inspired by something that
Geoffrey Hinton recently said this talk
is gonna be divided into three parts I'm
gonna talk about how backpropagation
works what the most popular deep
learning algorithms are right now and
finally seven research directions that I
have personally hand-picked okay that's
the talk in three parts so let's get
started here so this whole video was
inspired by what Geoffrey Hinton
recently said in an article so Geoffrey
Hinton is the Godfather of neural
networks he's the guy who invented the
backpropagation algorithm back in 86
which is the workhorse of all almost
almost all deep learning okay so without
backpropagation all the great things
we're seeing in deep learning would not
be possible today self-driving cars
image classification language
translation almost all of it is because
of that propagation so this what Hinton
recently said is causing shockwaves in
the deep learning community he said that
he was deeply suspicious of
backpropagation his own algorithm and
said my view is to throw it all away and
start again and I have to say that I
agree with Hinton I know it's crazy
right because back propagation has just
given us so much but if we really want
to get to artificial general
intelligence we've got to do something
that's more complicated or just
something else entirely because it's not
just about stacking layers and then back
propagating some hair gradient
recursively that's not gonna get us to
consciousness that's not gonna get us to
systems that are able to learn a huge
variety of tasks everything from playing
games to piloting an aircraft to
figuring out the most complex equations
in the universe it's got to be about
more than just gradient based
optimization so let's first start let's
first talk about how back propagation
works okay so the billion dollar
question is this probably
multibillion-dollar actually how does
the brain learn so well from sparse
unlabeled data that's how we learn
we don't sit there we don't have labels
for everything we're learning if you
look at a baby it's incredible how much
it learns without some kind of
supervision right it can learn how to do
all these different tasks stack blocks
and all these they learn how to speak
and there are no labels per se in the
sense that we use them in deep learning
it's all happening unsupervised and when
a sparse means few right so it's not
about very dense descriptive data it's
sparse right there's a lot of zeroes in
it and yet we can still learn from it so
how does it do this well let's first
understand how back propagation works so
in back propagation so first of all a
neural network is a huge composite
function it's a function consisting of
other functions and these functions are
all in the form health layers right so
you've got a input layer a hidden layer
maybe multiple hidden layers and then
finally an output layer and you can look
at it as this four-step process that
I've got right here so the first step is
to receive a new observation X in a
target label Y so this could be some
image of cancer cell and then the label
cancer right and they could be either
cancer or not cancer and so you'll take
that input and you already have the
label right that's that's how back
propagation works as long as you know
that label you are golden but you've got
to know the label so you take that input
it's an image think of it as a series of
pixels so it's just a huge group of
numbers so it's a vector right so you
take that group of numbers and you then
you go to step 2 you feed it forward
through the layers what do I mean what
do I mean by feeding it forward you you
continually take that input multiply it
by some weight value add a bias value
and then activate it by applying a
non-linearity to it and you continually
do that over and over again until you
have an output prediction and I'm gonna
go over this more in a second we're
gonna look at the code but once you have
that output prediction you compare it to
your actual prediction your real label
by doing this a difference the
subtraction right you you're subtracting
the actual from the from the
that right and that that difference
because it's these are all just
numerical values that difference is your
error and then you go to the last part
step for back propagating that error so
once you have that error
you're gonna compute the partial
derivative of that error with respect to
each wait recursively for every layer so
you'll compute the partial derivative
with respect to the layer before and
then you take that error gradient that
you that you've just calculated and use
it to compute the partial derivative
with respect to the next layer and
you'll keep doing that every time and
then what happens is you're going to
have a set of gradient values that you
can then use to update all the weights
in your network for as many as there are
so the process is input feed-forward get
the error back propagate update the
weights repeat feed-forward get the
error back propagate the peat over and
over and over and over again hundred
thousand million times right and that is
the back propagation algorithm I'm gonna
go into it in more detail but that's at
a high level okay so the paper that I'm
talking about where Hinson released this
I've got it linked to right here but
it's a very old paper it's it was it was
done in 86 and the reason it was created
in 86 and the reason that Hinton is such
a gene is because everybody was telling
him this is not gonna work you've got a
thing of something else but Hinton held
strong to this belief okay and I think
that is the mark of a good researcher if
you really believe in something to not
let anything else influence what you
believe in right stick to your belief if
you're wrong you're wrong but at least
you stuck to what you believed in and
you and you listened to other opinions
as well but you really you really
believe in something so the reason that
it works now and it didn't work in the
80s is because now we have the computing
power and the data necessary to have
these huge amazing classifications and
these amazing generations right for
classification and generative models for
both so let's just look at this
canonical example of a very basic neural
network that uses back propagation
scratch out the input number for it's
just three inputs right so we have it's
a 3 layer Network input hidden and
output I'm gonna go through this kind of
fast because we're gonna get to what
really matters in a second here
and if
already if you already know how
backpropagation works just skip forward
probably I'm gonna estimate five minutes
from now so we have this very simple
basic neural network and the goal is to
take some input data and then predict
the output label right so we've got some
input data which is a series of triplets
0 0 1 0 1 1 you know etc and then we
have a set of Associated labels 0 1 1 0
so for 0 0 1
The Associated output label Y is 0 and
then etc etc alright so that those are
our inputs and our outputs we have this
non-linearity which is a sigmoid
function it's an activation function and
I'll talk about that in a second but
we'll take our input data we will take
our output data and we want to learn the
mapping function right so then given
some new output 0 1 1 or 1 0 1 some
arbitrary triplet we'll be able to
correctly predict the output label as it
should be right so the first step is
first to initialize our weight values so
our weight values are a set are both
matrices they are they are randomly
initialized matrices and so what happens
is when we have our input right so again
remember just scratch out the fourth one
it's because there's only three it's a
triplet we'll take that input triplet
multiply it by the weights and those are
the matrices and so that's why you see
these arrows right the reason we're
using we they say we need linear algebra
in deep learning is because linear
algebra takes the standard algebra
operations like multiplication and
division and addition and it applies it
to groups of numbers that are called
matrices so linear algebra defines
operations that we can apply to groups
of numbers matrices for example the dot
product which is used heavily in deep
learning that's in fact that is the
multiplication we use in all types of
deep neural networks it's a way of
multiplying groups of numbers together
which is what we're doing right we're
taking our input multiplying by a weight
matrix and then we take that result and
we add some bias value and a bias acts
as our anchor it's a way for us to have
some kind of baseline where we don't go
below that in terms of a graph think of
like y equals MX plus B it's kind of
like the y intercept for this function
that we are trying to learn right
and once we've multiplied our input
times our weight value added a bias and
then applied some activation function to
it which is our non-linearity the
sigmoid that's going to give us an
output and we just take that output and
do the same process for the next layer
and the next layer and however many
layers we have okay so that's what we're
gonna do using the dot product and then
we're gonna back propagate the error
once we compute it so back propagation
you don't need to know all of calculus
to understand back propagation you only
need to know really three concepts from
calculus the derivative the partial
derivative and the chain rule which I'll
go through in a second so first I'll go
through the derivative so the derivative
is the slope of the tangent line of a
function at some point and though an
easy way to compute the derivative for
some function like say y equals x
squared or any function is to compute
the power rule which I have right here
so you'll take the exponent and you'll
subtract one from it and you'll take the
original exponent and move it to the
coefficient so for y equals x squared
you take the to move it to the
coefficient subtract one so then it
becomes two X to the first which is two
x so the derivative of y equals x
squared is 2x so the reason and so the
derivative tells us the rate of change
it tells us how fast some function is
changing and what what is happening for
for gradient based optimization in
neural networks in all of deep learning
most of deep learning is we have some if
if we were to map out all the possible
error values on the x axis so just
imagine these are all errors and then
all the possible weight values on the y
axis it would come out to be a parabola
just like this and what we want to do is
we want to find that minimum error value
we want to find those weight values such
that it's gonna give us the minimum
error value and what that means is we
want to find the minimum of that
parabola and the way we're going to find
that minimum of the parabola is by
computing the derivative which tells us
the rate of change of wherever we are
and then we're going to use it to update
our weights such that we are iterative
ly incrementally continuously moving
closer and closer and closer and closer
to that minimum point
and once we have that minimum point that
is our optimal point where the error is
smallest and the weights are at their
most optimal values such that the error
is in the me the smallest every time we
make a prediction right that's why it's
called gradient descent in general right
so when we take this very very popular
optimization formula gradient descent
which I just described and we apply it
to deep neural networks we call it back
propagation right because we are back
propagating an error gradient across
every layer that we have and so the
reason we know we need to know the
derivative is because we're you because
we're going to what we're actually
computing is the partial derivative it's
derivative because a neural network
don't just have one variable it has
several variables right for however for
however complex your function is so we
want to compute the partial derivative
of the error with respect to each weight
right so when I say with respect to I'm
talking about that way and none of the
others so you can think of a partial
derivative as saying okay well what is a
partial derivative with respect to X for
this equation what that means is we are
only computing the power rule for X and
we are ignoring everything else so Y to
the fourth is ignored and when we
compute the derivative of X it's going
to be 1 right so then we are left with
5y now if we're doing the partial
derivative with respect to Y then we
don't care about X we only care about Y
so we do the power rule for Y to the 4
so it's 4y cubed plus 5x because Y the
derivative of Y has 1 so then the X
remains so that's what we're computing
we're computing the partial derivative
and that's what's going to give us our
error gradient the gradient tells us how
which direction to move on that parabola
to get to that the optimum of that
minimum point gradient descent and the
last part is the chain rule right
because a neural network is a giant
composite function right look what did I
just subscribe I described taking an
input value multiplying it so of input
times way add a bias activate right
we've talked about this before input
times weight added bias activate that is
the formula that is happening that is
the function right that is happening at
every layer
and these layers are nested so every
time you add a layer you are adding a
nested function inside of this giant
composite function that is the that is
the neural network so the chain rules
tells us how to derive a composite
function what you would do for a
composite function is derive the outside
keep the inside and multiply it by the
derivative of the inside so that is a
rule and that rule apply for cursive
leaf or as many nested functions as you
have so that's the chain rule and so now
that we understand that we can do back
propagation that there's there's your
calculus primer on doing back
propagation so the rest of this very
canonical example is saying for 16,000
iterations let's feed forward that input
data through each layer and so what we
do for each layer is say okay we've got
K 0 that's our input multiplied by the
first synapse matrix and by multiply I'm
talking about dot product Thank You
numpy apply the activation function or
non-linearity to it so the activation
function the reason we do that is
because a neural network is a universal
function approximator I'm telling you a
lot right now so just don't worry if you
don't understand everything there's a
lot more to come and then re watch this
video and I've got a million other
videos on this stuff as well so I'm very
excited right now where was I
okay so we were taking the input times
the weight were at input time and so in
this case we don't have a bias right
because this is very basic but usually
we have a bias so we're doing input
times weight activate okay bye times I'm
talking about dot product so we say okay
and then you repeat that again for the
last layer and then k2 is gonna be our
output prediction and then we compute
the error by finding the difference
between our actual output in our
predicted output then we perform back
propagation we take that error weighted
gradient and we see in what direction is
this target value by computing the
activation of that output value and
multiplying it by the error and that's
going to give us the gradient value the
Delta the change right and that Delta is
what we're going to use to update our
weights in a second but we've computed
the Delta the gradient for this layer
right though
the hidden lair let's get it let's
compute the gradient for the next layer
so recursively so we'll use the k2 Delta
to can see how much the K 1 value
contributed to the k2 error and once
we've got that K 1 error we'll we'll do
the same exact problem process again to
compute the K 1 gradient so the first
layer is gradient and once we have both
gradients then we can up update both of
those weight values using those grades
and we just do that over and over again
60,000 iterations that is back
propagation so I wanted to go into a
tangent no pun intended to talk about
derivatives and ingredients and how back
propagation works but that propagation
is the workhorse of deep learning and
this is a great chart the neural network
suit that shows many different types of
neural networks there are so many types
of neural networks out there it's not
just one there's a lot right and back
propagation is the optimization strategy
of choice for almost all of them right
almost all of them use labeled data and
then back and then back propagation has
an optimization strategy to learn some
mapping function right everything is a
function in life everything is a
function love is a function emotions are
a function that the sound of the
airplane above and then relating that to
how fast velocity and you know all these
different variables it's all you can
represent everything as a function math
is everywhere math is all around us
math is beautiful it's beautiful
seriously oh my god it's awesome anyway
everything is a function right so we're
trying to learn the function and
supervised learning using back
propagation is a way for us to do that
so how do artificial and biological
neural networks compare so this is a
very basic view of how they compare the
idea it's such a rough it's such a rough
the initial perceptron the initial
neural network were so roughly inspired
by biological neural networks it wasn't
like they were saying well let's let's
implement a neuro trend
let's let's implement you know dopamine
and dendrites
in all of their details I mean neurons
are these very complex cells it's very
basic all the only inspiration is saying
you have some neuron it's got a set of
dendrites that receive some input it
performs some kind of activation from
some kind of activation on that neuron
what what that means is it decides
whether or not to propagate that that
signal onward or not using some function
and if it decides to then it sends it
out that's it that's that's the extent
of the inspiration between artificial
and biological neural networks right
because we have some input we compute
some activation function like riilu or
sigmoid or you know there's there's many
of them out there and then we output the
value right so the brain has a hundred
billion of these neurons numerous
dendrites and it commits it uses
parallel chaining so each neuron is
connected to ten thousand plus others
compare those two computers right
computers don't have neurons in terms of
hardware they are made of silicon and
they are serially changed which means
these transistors on or off switches are
each connected to two or three others
and they form logic gates so with and
they are great at storage and recall
even though they are not as parallelized
as our brain they are still better than
at some things we got to admit then we
are like it's better at calculating
numbers in in memory right we can't
compute a million times a million but uh
but a computer can however what our
brain is really good at that computers
are not is creativity right we are able
to take some idea that is completely
unrelated to another idea and apply it
and then it results in some amazing
innovation or task and we are great at
connecting different concepts together
we are great at being able to learn many
different things and apply our knowledge
to many different tasks and that's what
we should be trying to do with AI and so
there are some really key differences
between our brain and artificial neural
networks first of all everything in the
brain is recurrent that means there is
always some kind of feedback loop happen
in any type of sensory or motor system
right
not all neural networks are recurrent
there's a lot of lateral inhibition
which means that neurons are inhibiting
other neurons in the same layer we
haven't seen a lot of that in deep
learning there is no such thing has a
fully connected layer in the brain
connectivity is usually sparse although
not random
usually we have fully connected layers
at the end of our networks like say for
convolutional networks but in the brain
there are none right everything is
sparsely connected but it's it's smartly
sparsely connected brains are born
pre-wired to learn without supervision
so we talked about this a little bit
right now babies can know things even
though they don't they learn there
aren't given labels or any kind of
supervision and lastly the brain is
super low-power at least compared to
deep neural networks right the brain's
power consumption is about 20 watts
compare that to arguably one of the most
advanced AIS today alphago it used about
1200 CPUs and 176 GPUs not to train but
just to run just imagine how much how
many watts that takes that's like an
order of an order of magnitude more
power than our brain takes which is
which is annoyingly inefficient right so
we can definitely definitely definitely
improve on that there's this great book
by this Harvard psychologist Steven
Pinker which I've read and I would
highly recommend it called how the mind
works and this book is from a
neuroscience perspective not a machine
learning perspective but we need more of
that we need more of that because there
are certainly a lot of Secrets here that
we haven't figured out but we're trying
so this is a great book to read and it's
a there's a great quote from that book
that I'm gonna read out to you which I
particularly like the quote is the brain
is not a blank slate of neuronal layers
waiting to be pieced together and wired
up we are born with brains already
structured for unsupervised learning in
a dozen cognitive domains some of which
already work pretty well without any
learning at all right evolution has
primed us to be able to do certain
things even though we don't have any
real-time learning happening it's just
wired into us right so there is
something to be
about structure versus learning
everything anyway okay so we've talked
about that so where are we today right
so that was the first part here the
second part and then we'll get to the
third part research directions so where
are we today in unsupervised learning we
know where we are with supervised
learning that means when we have labels
but what if we don't have labels well we
can divide machine learning into two
types
besides supervised and unsupervised
classification and generation right
these are two tasks and one meta way of
looking at it as is as creativity and
discovery when everything else is
automated for us when all of the you
know all of the brainless labor that we
don't care about when all that is
automated what's gonna be left for us
humans is our two tasks creativity and
discovery right what can we create what
can we discover and we're and we and we
can frame those things as classification
discovery and creativity generation so
for classification
what is something clustering right
clustering is perhaps the most popular
technique when it comes to
classification and there are many ways
to cluster data right if you don't have
the labels but you do have the data
maybe you can learn clusters for all of
these labels such that they're that
you'll be able to know what groups each
cluster are in so it's like learning
without labels right there are several
strategies to learn clusters from data
k-means is perhaps the most popular
dimensionality reduction techniques like
T distributed stochastic neighbor
embedding or th t-sne or principal
component analysis there's an anomaly
anomaly detection but most of them still
used some sort of supervised learning
and the ones that don't use back
propagation are not necessarily better
there are actually very simple
algorithms like k-means is just you know
these four steps right here it's very
simple there's it's just basic
arithmetic and that's where we are right
now
there's also Auto encoding right
auto-encoders are really popular for
unsupervised learning the idea is that
if you are given some input try to
reconstruct that input
through outputs you have an input you
learn some dense representation and you
try to reconstruct it from there and
this is great for dimensionality
reduction alerting some feature some
features etc for generation perhaps the
most popular right now is the generative
adversarial Network so I met the creator
he and good fellow we had a good
conversation in San Francisco we had you
know he's a really smart guy and really
I mean the idea was so basic right it
was such a basic very intuitive idea
yeah it is the reason behind a lot of
hype and deep learning right now the
idea is to have two networks one tries
to fool the other right you have a
discriminator and you have a generator
and so what happens is you have some
data set let's say some images and you
want to generate new images that look
very similar but they're new so what you
do is you take one network and it's it
takes in an input of one image it
applies some distribution function to it
right in latent space so what that means
is like a Gaussian or something like
that
so take some Gaussian distribution
multiply it by that image and so the
image is basically a group of numbers
right pixel values and when you apply
some distribution value to it you change
those numbers ever so slightly so then
if you look at it as a picture it's that
it's it's a slightly modified picture
and that picture is then fake and it
only does this sometimes sometimes it
shows the real one it shows a fake one
and the discriminator is a classifier it
right so you know what the real image is
and you know what but you don't know the
fake image is fake or not right the
classifier doesn't know so it's got it
so it tries to classify the fake image
and if it gets it right or wrong you
could take its prediction compute an
error value between the real and the
fake and then again back propagate an
error gradient value right so you are
still using back propagation across it
so the whole thing is what's called
end-to-end differentiable because we can
differentiate every weight value in the
in this in this system so even though
there are no explicit labels we are
still using back propagation it's self
supervised so it's like we are creating
the labels another great example our
variational auto-encoders what we are
embedding
stochastic city inside of the model
itself that means inside of the layers
we have a random variable what that
means is the the neural network is not
deterministic
it's stochastic you cannot predict what
the output is gonna be that means that
if you have some input you feed it
through these layers one of them is a
random variable so it's a distribution
that's applied to that input what
happens is the output is going to be
some unpredictable new output that you
didn't predict before which is what
you're trying to generate right and
lastly
and these are the bleeding edge of
unsupervised learning models by the way
and lastly is the differentiable neural
computer so I I am gonna go out on a
limb and I'm gonna say that the DMC is
the most advanced algorithm currently
that uses that propagation out there
maybe maybe alphago is better but we
haven't seen the source code for that so
I wouldn't know but in terms of openly
available source code the dnc is is is
amazing it's also highly complex there
are so many moving parts in the
differentiable neural computer and I
have a video on this just search DNC
Siraj but there are so many moving parts
here you've got read and write heads but
basically you are separating memory from
the network itself right so you have
memory and the analogy fit that they
made was between DNA and the brain right
so you have DNA these this is encoded
external memory so you have an external
memory store and then you have your your
internal controller right and so the the
net the the controller is pulling from
the memory and there are read and write
heads between the controller and the
memory between there there are links
between different rows in the memory
basically you have let me show you this
let me show you this you have so many
different differentiable parameters all
of these you have you have read and
write heads
you have Ellis TM cells every single one
of these matrices are and everything one
of these major trees are differentiable
so this is a gigantic very complex
system and everything is differentiable
right so that there's that and so now
and what they did was for the DNC was
they generated a random graph and of
different subways and they use it to try
to predict where someone was gonna go
based on some questions which is just
incredible they also trained it on
family trees and a bunch of other things
but basically the best unsupervised
learning methods still require back
propagation so my point here is that
back propagation really is the workhorse
of deep learning even in the
unsupervised setting but another thing I
want to say is that a lot of deep
learning research is all about making
small incremental improvements off of
existing ideas and a lot of times
academia kind of pushes us in that
direction it pushes you to make
incremental changes maybe like tweaking
one hyper parameter or adding some new
layer type or maybe new some new cell
type like at GRU or whatever but if you
have but if you if you if you think of a
radically new idea you can really shake
things up seriously and the idea it
doesn't even have to be that difficult
it really does it it doesn't even have
to be that complex like think of games
like think of generative adversarial
networks it's such a simple idea you
have two networks one tries to fool the
other that's it it's just two neural
networks one tries to fool the other and
Jana Kuhn said this is the hottest idea
in the past 20 years in deep learning
and look at this I mean this idea was
invented just two years ago look at the
number of Gans that have been have been
inspired by that first paper there are
so many and this is in two years all of
these different I could go on you could
make an entire four month course on all
the different types of Gans out there so
my point is anyone can think of a really
good idea when it comes to D pointing
the the playing field is is level for
everyone so let's get to their future
research directions okay so the first
one so my thesis is this is that
unsupervised learning and reinforcement
learning must be the primary modes of
learning because labels mean little to a
child growing
right so we need to use more
reinforcement learning more unsupervised
learning and then we're gonna get to
somewhere somewhere better than where we
are right now so the first we research
Direction is Bayesian deep learning
which is not discarding backpropagation
is just making it smarter what do I mean
by this Bayes Bayesian logic is all
about having some prior assumption about
how the world works versus frequentist
which just assumes that we have no
assumptions right so when you take
Bayesian reasoning and apply it to deep
learning you can have amazing results
and this has been proven in the case of
variational autoencoders but deep
learning struggles to model this
uncertainty so when I talk at what I
want in what I specifically mean when I
say Bayesian deep learning is smarter
weight initialization and perhaps even
smarter hyper parameter initialization
right and this kind of relates back to a
child and how evolution has primed us to
know certain things before we've learned
them in real time right there are
certain learnings we already have we are
weights in our head are not initialized
randomly when we start learning we have
some sort of smarter weight
initialization so Bayesian logic is is
it is a great direction is a great
research direction just combining those
two fields Bayesian logic and deep
learning the second one is called spike
timing-dependent plasticity and a great
analogy for this is saying you know
you're trying to predict if it's gonna
be raining or not you can go out there
and you can see if it's going to rain
literally with your own eyes or you can
look at your roommate who tends to take
an umbrella every time he goes out and
every single time he walks out with an
umbrella
it happens to be raining so rather than
try to go out there yourself look at
it's raining or not instead you just
look at your roommate
see if he picks up an umbrella and if he
does you know that it's gonna rain so
you take an umbrella so the analogy
applies to spike timing-dependent
plasticity because you can't properly
back propagate for weight updates in a
graph based network since since it's an
asynchronous system so we trust neurons
that are faster than us at the task so
it's all about timing
looking at neurons and
faster firing and using those neurons as
a signal as a signal for how we learn so
suppose we have two neurons a and B and
a synapses on to be the stdp rule states
that if a fires and B fires after a
short delay the synapse will be
potentiated okay so the magnitude of the
weight increase is inversely
proportional to the delay between a and
B firing so we're taking timing into
consideration which D pointing currently
does not do the time of firing the third
idea is our self-organizing maps so this
is not a new idea at all
but that's okay that's another thing
that I want to mention there is so much
machine learning and deep learning
literature out there there is a lot and
a lot of times the best ideas are
forgotten they are lost in the mix
because there's so much hype around
certain ideas and sometimes it's
unnecessary hype around certain ideas
and some of the best ideas could have
been invented 20-30 years ago I mean
look at deep learning right so it's just
all about finding those ideas and
self-organizing maps are one of those
ideas where you know this is an older
idea but it has a lot of potential and
not many people know how these works how
these work but this is a type of neural
network that is used for unsupervised
learning so the idea is that we have we
we randomized the node weight vectors in
a map of them so we have some weight
vectors and then we pick some input
vector that's our that's our input data
and we traverse each note in the map
computing the distance between our input
node and all the other nodes and then we
find the node that is closest the most
similar to our input node that is the
best matching unit the B mu then we
update the weight vectors of the nodes
in the neighborhood of the B mu by
pulling them closer to the input vector
and what happens is this creates a
self-organizing map and you can
visualize it as different colors but
it's a basically clusters of different
data points so it's basically clustering
and I think this is a great idea it
doesn't use it that it doesn't use back
propagation and we should look more into
that the fourth idea the fourth for the
fourth direction or synthetic gradients
so who
Andrew Trask has a great great blog post
on this that I highly recommend you
check out it's really in-depth but this
idea came out of deep mind this idea
came out of deep mind and it's basically
it's a much faster version of back
backpropagation in which you are not
waiting as long to update your weights
so individual layers make a best guess
for what they think the data will say
then they update their weights according
to that guess and they call this best
guess the synthetic gradient because
it's a prediction of what the gradient
will be not what it actually is and that
data is only used to help update each
layers guess or synthetic gradient
generator and what this does is it
allows individual layers to learn in
isolation which increases the speed of
training individual layers can learn
without having to do a full forward and
backward pass so that synthetic
gradients and I think and and it's weird
because even in the machine learning
subreddit people who are talking about
synthetic gradients but some of the
questions were hey we need more of this
why hasn't why hasn't this been talked
about more and people don't know right
so this is a great idea came out of deep
mind and definitely learn more about
synthetic gradients the fifth research
direction is our evolutionary strategies
so open AI had a great blog post on this
evolutionary strategies as a scaleable
alternative to reinforcement learning
but evolutionary strategies have not
given us a lot of success so far but
that's okay just intuitively they make a
lot of sense right trying to resemble
evolution you have Fitness you have a
fitness function that determines how fit
some individual is and these individuals
mates right so there's crossover and you
know it's basically survival of the
fittest you have you have mutation
selection and crossover via of Fitness
function and you can do this with a lot
of games right so you can have several
neural networks and you can use
evolutionary strategies to have the best
one win or or survive longer than the
rest so I think there's a lot of
potential for that and it's very similar
to reinforcement learning so if I if I
were to pick the lowest hanging fruit
right the lowest hanging fruit
in terms of revolutionary ideas to come
to the table of really radical changes
it would be in reinforcement learning
deep reinforcement learning
reinforcement learning is all about
learning from trial and error right you
have some you are some agent in some in
some environments right it's called the
agent environment loop you perform an
action in that environment you get a
reward yes or no and then based on that
reward you update your state your
learnings and you continue that process
so alphago used reinforcement learning
deep reinforcement learning to get
really good at its game and there are so
many low-hanging fruits and deeb
reinforcement learning how do we learn
the best policy just there are so many
unanswered questions
so reinforcement learning in general is
a great place to do to just focus on in
terms of research and the last one is
the most capital intensive and perhaps
the hardest but I just had to mention it
right we talked about how transistors
are on off switches and they are chained
together serially to for to perform to
form logic gates
whereas neural networks are are parallel
in their construction so they're
connected to ten thousand other ones so
perhaps instead of trying to replicate
the rules of intelligence in silico or
at least on the current types of chips
we have let's just change the hardware
completely right at the hardware level
and IBM's neuromorphic chips are a good
example of going in this direction
google's TP use tensor processing unit
but basically the idea is to wire up
transistors in parallel like the brain
really I think I think anyone can can do
this you know you if you have some idea
I mean think about it the brain is only
running on 20 Watts so it can't be that
expensive right in terms of hardware or
wetware right so there so if you have
some idea you can crowd fund it for
whatever hardware you want to build and
then you know use we funder or
Kickstarter and yes I think you can even
have a start-up for hardware for for
machine learning for deep learning so
what is my conclusion those are my seven
research directions that I wanted to
talk about today as a way as a response
to Hinton
talking about backpropagation so what is
my conclusion what do I think I think
and so I agree with Andrey Carpathia who
is one of the best deporting researchers
out there he's a director of AI a Tesla
now and the conclusion is this let's
create multi agents simulated
environments that heavily rely on
reinforcement learning and evolutionary
strategies Carpathia this great talk at
Y Combinator which I didn't attend but I
the slides are online but check this out
he had this one slide that said
intelligence the cognitive toolkit
includes but is not limited to all of
these different aspects of intelligence
attention working memory long-term
memory knowledge representation emotions
consciousness
there are so many different topics that
encompass learning it's this Orchestra
of different of different concepts and
they all work together to define
intelligence or intelligence so the
conclusion is we need to create
environments that incentivize the
emergence of this cognitive toolkit so
doing it the wrong way is to use this
environment what does this incentivize
incentivizes a lookup table of correct
moves right for pong but what is doing
it right this to agents in this world
there's some food there's some survival
there are learning to adapt to each
other it's much more like real life
itself right and that incentivizes a
cognitive toolkit cooperation attention
memory emotions even right with more
complexity so it comes down to the
exploration versus exploitation dilemma
from reinforcement learning how much do
we want to exploit existing algorithms
back propagation by making incremental
improvements versus how much do we want
to explore entirely new ideas and we
need people doing both we need people
improving the deep learning algorithms
because there's still a lot to be
improved upon but we also need people
working on exploration like entirely new
ideas in fact I think we need more
people focusing on that that we have
currently so if I were to you know take
some away I would say let's take 20% and
put them 20% from the exploitation and
put them in the exploration category
so yeah it's just something to think
about I hope this video helped you think
more about all these concepts and where
we're headed and where we should go I
hope it gave you some ideas for what you
might be more interested in and I'm
gonna keep making videos like this so
yeah please subscribe for more
programming videos and for now I've got
it evolved so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>