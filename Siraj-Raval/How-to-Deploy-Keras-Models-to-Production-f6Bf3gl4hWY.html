<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Deploy Keras Models to Production | Coder Coacher - Coaching Coders</title><meta content="How to Deploy Keras Models to Production - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Deploy Keras Models to Production</b></h2><h5 class="post__date">2017-06-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f6Bf3gl4hWY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and today we're
going to learn how to deploy a Karass
model to production and the app that
we're going to build a specific app is
going to be able to detect any
handwritten character that you draw in
the browser it's just it's just going to
be able to tell what that is so let me
write out a two this is a dent this is
the demo right here
now hit predict so to let me clear that
okay how about a three Scott of three
okay let's try something else how about
a nine that's a seven because that was
badly drawn and then one more how about
a zero or six zero cool okay so that's
what we're going to do and we've got
four steps here okay so the first step
is a trainer model in care off so we're
going to train our model simple MISD
handwritten jerok digit it's all over
the internet that's not really the value
at here the value add is going to be us
writing our flash backend so we're going
to glaze over this chaos model this MN
is T and we're going to get to the real
meat of it which is writing out a flask
web app to serve it so our first step is
going to be a trainer model and care us
and then our next step is going to be to
save it then our third step is going to
be to write our flask backend which is a
Python web app framework it's a very
it's a very small thin very thin weight
micro framework for serving data in the
browser using a Python back-end for
requests you know get posts set to
server so we're going to use it to serve
our saved chaos model okay and then once
we're done it's going to be running
locally just like it is right now
like it is on local host on port 80
eight eight and then we're going to
deploy this code to Google Cloud and
that means anyone can use it
so I already made a video on how to
deploy our tensorflow model to
production rights using tensorflow
serving and that's for like you know
high grade production quality you know
millions of people are using it it's
what Google uses that's when you want to
use tensorflow serving so you could use
chaos with tensorflow serving as well in
fact Francois show let Xiao shellay I
kind of work on my French and Dutch now
that I'm here in Europe we might get
interrupted by an angry Dutch lady but
it's all good the show must go on
she's next door okay or was that yes so
we have to we could use tension flow
serving if we wanted to
you know save it with care Austin youth
central serving because you'd you would
build a model with tear offs save it as
a tensor profile and then serve it with
tensho serving but the easiest way the
absolute bare bones easiest way to take
a train model deploy it to a web app and
share it with your friends is using this
ok this is the easiest way that I've
found I've been trying out a bunch of
different ways so if you have a model
and you just want to show people right
this is the way to do that if you have a
model and you want to not not just show
people as a demo because it's easy to
access in the browser but you want to
actually build a business around it
tensor boat serving is the way that also
applies to this right and we'll talk
about how it applies what I mean by
applies is we would still deploy our
code to Google cloud and we would still
train a model with careless write the
only difference is for the backend we
wouldn't use flask we would use tensor
flow survey okay so this is for that you
know easily getting it into the browser
basically that's that's what I'm running
to it ok so where was that let's let's
let's get started right so first I'm
going to explain what we're going on
here like what this is and then we'll
get into the to the code part ok so ok
so what is our stack look like so we're
going to use care offs with a tension
plug back end so care offs with
attentional back end to train a very
simple 8 layer convolutional network to
recognize handwritten character digits
right so 0 through 9 all these images
and then they all have a label you know
0 1 2 3 4 and our job are our CNN's job
is to learn the mapping between the to
write pattern recognition very tried and
true model everyone knows about it but
here's the here's the cool part we're
going to use flask as our back-end to
serve these pre-trained models so we're
going to train it locally it's going to
and then we're going to save the model
as a wait file and then we're going to
serve it with flask
you could also use node right you could
use any number of J's web frameworks
there's like ember all these jams
frameworks out there but I would not
want to write a back it backend code in
JavaScript people do it all the time I
don't want to do it because I just
prefer Python right we as machine
learning engineers we write Python
anyway so let's just use the Python
framework you can also use Django but
again this is the simplest way to do it
why because flask is just you
you literally I mean look at this this
is an example right here pip install
flask import it initialize it writer out
boom and that's all you need to run and
then this it's going to type out hella
where is going to show HelloWorld in the
in a browser with Django you know is it
there's a kind of skeleton to it you
know the app you know the HTML files
have to go in a certain directory the
J's files have to go to insert directory
it's similar to what's that review
framework on Rails it's similar to Rails
in that way but you know flask is just
super simple right I'm talking to people
who like are experimenting with their
models and they just want to like show
people right you know ten twenty hundred
four hundred people but not like
millions of people right times about
serving is way to do that okay so what
else is out there right why I use flask
and just native JavaScript aren't there
other frameworks the answer is yes there
are this is just the simplest way
because I've been trying out a bunch of
them but I want to talk about three just
so you get an idea of what the space
looks like okay so the first is Karagias
now this is like the de-facto like most
stars for using tear-offs in the browser
it's got GPU support it can only pertain
only it only supports forward pass
inference that means you don't train
your models in the browser you have to
have them trained once they're trained
then it's going to use GPU acceleration
to make that prediction right to go to
the layers once you've got your you know
input to just make make inference faster
and it's using web loss and ND array
these two libraries that are basically
like the javascript versions of numpy
and could not CUDA but like yeah
whatever whatever whatever kudos
whatever's on top of CUDA right when it
comes to put when it comes to running
things in Python so that's what it does
you use Carol sometimes reflow it's got
a bunch of interactive demos and it's
pretty cool it's pretty cool but again
it's a lot of work to get to get to get
working
I was trying it out but check out these
demos these demos are pretty cool like
this bi-directional lsdm demo so it's
basically like doing sentiment analysis
on on text so like I really really love
my life it's going to be you know green
where as I say who are interested
trade you know sex sin drugs oh it's not
that bad fifty fifty percent okay I hate
people hatred virgins kill me needs more
training need more training okay just
like people do sometimes okay so that's
one way you could do it right so if you
want GPU acceleration once this so I'm
saying try out this way do this way you
can literally get this running in 30
seconds using the code in the browser
literally just clone the repo install it
with piff install required requirements
on txt recursively and then run the app
it's that simple it's literally that
simple and you'll have it in your
browser once you get that once you get
this working and you got a feel for how
this structure works then move on to
using tear off such a s okay later on if
you want GPU acceleration and then tens
of flows serving another way to do this
is web DNA so actually so Francois the
the creator of chaos recently shared
this library as the fastest way to do it
in the browser web DNN so he liked so
they clocked it against Carris ajs and
it blew carriage a us out of the water
however however so you might be saying
like why don't you just use this one
then why carol is yes when i tried
running this i got a specific error and
i didn't see it in the issues but it is
a real error and the error was like it
was like XC run cannot find metal
dependency i was like what do you mean
metal so i was like looking up like
metal OSX and I found out that metal is
and is an apple specific dependency for
running code on the GPU right don't you
love how Apple always like like wraps
all their libraries with these like neat
pristine interfaces and it just makes
you want to just dive into them be like
yes I'll do anything with metal yes this
looks so awesome
but the fact is that not everybody has
OSX and this require this has an OSX
specific dependency web DNN so if you
have Mac definitely definitely try it
out but not everybody has Mac this the
one I'm using is is operating system
agnostic which is what we want okay so
now that we have that let's
well what else so so that's one and so
the third one is called neocortex so
neocortex is also very cool it's got
some great examples in the browser that
we can that we can try out so it
initializes and then does the same thing
like predicting classifying these images
but the problem with neocortex is look
at look at this and there's a good thing
to do look at when the last commit was
it was a year ago
we want libraries that are actively
maintained why because if you don't then
it leads to what's called code rot and
code rot is when code just deprecates
right we don't want deprecated code but
it is pretty cool okay so those are
three that I wanted to talk about okay
so let's go ahead and actually do this
okay so where do we get started here to
get started let me X out of these X X X
X naught okay gone gone gone okay so now
let's get back to what we were doing
here so the first thing we're going to
do is just train our model right so I'm
just going to glaze over this code and
like talk about what's happening I'm not
going to actually type it out because
we've seen M NISC
many times but I'm just going to refresh
just so we have some kind of base to
move forward from so we're going to
build a model that's going to be able to
classify handwritten character digits
okay so we're going to import futures
just for Python compatibility between
2:00 and 3:00 tear offs and all of its
dependencies and once we've got Karos
we're going to say okay we're going to
do this with mini-batch gradient descent
with batch sizes of 128 images per batch
there's ten different classes and then
twelve epochs right so there there are
certain number of batches within epochs
so we define number of epochs and then
run a certain number of batches for
every epoch during training and then
we're going to use this beautiful method
that's super simple if only all data
sets use something like this right load
data it's going to download it split it
into training and testing sets for us
just like that okay once we have that
then we're going to say well assuming
which what format it's in we're going to
arrange the data in a certain way so
that's why this this channels per
Flagg is there either it's going to be
you know it's going to show the a
certain layer of convolutional matrices
or it's going to do it the other way
it's going to reverse it and so then
more reshaping and to float32 and then
we're going to convert our class vectors
to binary Class matrices is it this or
not and then we're going to build our
model so it's going to be a sequential
model in chaos with eight different
layers right so we're going to start off
with a convolutional layer that's going
to act as a filter for that image and
then we're going to say okay now that we
have this layer will add another
convolutional layer so it's going to be
it's going to take that big image and
continuously split it into smaller
subsets of images and then we're going
to use pooling to decide what which what
part of the image is most relevant that
it that is what part of the image has
had something drawn on right the
character itself that's that's the
relevant part then drop out is a
technique to improve convergence by
randomly turning neurons on and off
we're going to flatten it because it has
way too many dimensions and we want a
very small output prediction write a
label we don't want like this huge array
as our output once we have that then
we're going to say okay we're going to
use a dense layer because we want all
that relevant data drop out again just
for convergence and say usually drop out
happens twice sometimes three times but
I don't see it happen more than that
unless you're using like yeah generally
it's two to three times then we're going
to use a last dense layer to squash it
using a soft max function it's going to
output a list of probabilities of what
what class is going to be it's a
multi-class classification problem and
then once we're done with that we're
going to use our optimizer at a delta
which if you saw my evolution of
gradient descent video which I hope you
did you now have a better understanding
of why we use these optimizers right
it's an adaptive learning rate method
that is is rivaled only by Adam and add
a grad okay and so then we're going to
use this categorical cross entropy as
our loss function because we have
multiple classes not binary cross
entropy is this is this you know black
or white no it's categorical because
we've got ten classes then we're going
to train that stuff we're going to train
the model okay with this fit method and
I'm going to test how well it did
then at the very end this is now this is
the very important part that's that's us
building our model okay we're done
building a model now it's time to save
it to JSON and the weights file so we're
going to save two different entities
here one is the JSON file and the JSON
file is there because we want to save
the structure of the model itself this
is going to save the architecture of the
model the other part are the weights and
the weights are the learnings right once
we've trained it all of those learned
values of from the matrices of what it
means to be a zero or a one or a two any
of those images all that's going to go
in our waste file okay and so we're
going to save that and we're going to
say both of them then we're going to
load both of them later using flask okay
so that's it for our training part and
then we would just train this model
right which I could do but I mean I
trained it before right so just like
that right it's going to do everything
but I already have a train here the h5
file and the JSON file h5 by the way is
the format for Kaos models okay so we'll
have both of those and once we have
those we're going to let's see let's see
now we're going to write our flask Apple
so we did we trained our model we did
step one and then we saved it that was
step two and now we're at step three
writing our flask back-end to say to
serve our saved model that is the h5
file as long as a JSON file and then
we'll look at the dependency classes
that make the help make that happen okay
so we're going to first import flask
right this is our web framework our
micro services framework and a few of
its related dependencies right because
flask alone isn't enough we've also got
to have these dependencies we've got
flask
we've got render templates why do we
have render templates because generating
HTML from Python alone is kind of messy
so what this does is it lets us define
an HTML HTML file a standalone HTML file
and then we can just call that it's
called index.html this is going to help
us render that using Python and then
request for just handling all these get
post set requests right
okay so that's four flasks and then
we're going to import hold on its render
template not templates template template
okay
that's not a language okay so then we're
going to import side PI and side pi is
going to have a couple functions because
what we're going to do is we're going to
take that image that the user draws and
we're going to reshape it using these
methods right so this is our scientific
computing library we're going to reshape
whatever the user draws so it's in the
right image format and then feed that
directly into our Spri training model
right so we've got in save and read and
image resize those are the three that
we're going to need okay so we've got
that and then of course numpy duh
because that's our matrix math operation
a library we love that and then we're
going to of course import tear-offs top
models to import our model that we've
trained and lastly re re is regular
expressions a great way to handle huge
sets of string data without having to
sort through all of it okay
and so that's oh we've got some more so
import sis is going to help us do some
system level operations like there's now
this is now where I'm just going to load
the file itself okay we've got that and
then we're gonna import OS for some
operating system data and then we're
going to now we're going to use this to
say okay we're going to say this is
where our model is let's define where
our model is all right and and OS to do
this see our imports are already coming
in handy here so we're gonna say okay so
that's where our model is saved in this
model in the model folder okay and then
from load import that okay so that's
going to that's going to that tells our
app where the model is going to be saved
and then we're going to say we're going
to import this load class which is going
to help us load the model and then we're
going to initialize it okay so that's it
for our dependencies and now we can
initialize flask app or initialize our
flatgap so we're going okay so the app
is flask given a name which is going to
be will define later okay so that that's
it for a flask app and then we're going
to import two or so not in
or declare two global variables that
we've defined elsewhere and you'll see
what these are but basically the model
is the model object for how we
encapsulate the model file and the graph
is the computation graph right which is
like a session from inside we run the
model it's akin to a session in this
case and then we're going to initialize
these variables so we're going to say ok
so model and graph initialize both of
them from the load from the net for the
load dependency comes from from load
import that's where that comes from
comes from ok so then once we have that
let's write out that main function right
let's write out that main function so
we're going to say ok if name equals
main what port should we run this app in
right hold on if well we're going to
decide that the port is going to be hmm
well let's get it from the environment
it's going to be port 5,000 because
nothing else is running on that port
unless it is which it's not it's not and
once we have that we can run the app
locally using app dot run so say oh
that's that's where we're going to run
it that's like in the browser that's the
address so it's going to be like zero
point zero four zero zero at pork 55,000
all right and so we can define that as
well
super simple stuff you know if you do
machine learning for a while everything
else seems super trivial just boring in
a way no it's not boring just I mean
just you know boilerplate stuff but the
the what we're doing overall is cool
okay so then we'll say ok so run this
app we've defined it and let's all ready
do that we defined it and now that's it
that's it that's it for the that's it
for the name pot for the main main file
so now we've got to write some helper
functions here right so we've got two
helper functions that we want to make
here the first one is called index and
then the other ones is called predict so
we'll say ok so this is how we're
routing our
files so this is this is the app that
fought a stop I file this is how all of
this is how we tell our app what happens
when every user goes to a certain
address right so if you go to you know
flash Looney Tunes then load up the
Looney Tunes function if you go to slash
hello world and load up the hello world
function so if they if the user goes to
this just you know slash that means that
well there on the main page so let's
give let's serve them the index so we'll
say at this route let's define an index
function which will write this
functionality and all its going to do
all it's going to do is going to render
the template which is index dot HTML
which we'll talk about afterwards that's
one of our dependencies here right is
the high level code so that's it it's
going to render that HTML template
index.html it's going to serve HTML
that's it okay so then once we've got
that then we can say okay what about if
the user goes to this predict route well
the user isn't going to specifically go
to predict when the user hits submit
well you know when they draw the number
to hit submit on click that's when
predict is called well now we've got to
write code for that predict one to show
what happens when the user clicks that
so we're going to use two methods here
we're going to use both get and post and
we'll say ok so for predict we're going
to say well let's get that image data so
from the request we're going from the
request we're going to get that data and
call them ok and that's going to get the
raw that's going to get the raw data
format from the image right it's just
the raw serialized data and now we have
to reshape it so we can fit it into our
model right the user drew something
right we're going to get that image
we're going to reshape it so it's fit to
be fed into our model and then we're
going to take that image be
into our model and it's going to output
the prediction okay so we'll say okay so
we've got that image data and now we're
going to encode it using this helper
function oh we have one thing we have
one more helper function I forgot about
so we've got image data and we're going
to say that's going to convert the image
that's going to basically convert the
image into a more suitable format so
once we have that if we're going to read
it into memory so right now it's still
reading it directly from the saved image
now we're going to read it into memory
using this mode L and then we're going
to and then we're going to invert the
image so we're going to say okay NP
invert and what this does is it's a
bitwise inversion so that all the black
becomes white and all the white becomes
black and it makes it easier for us to
classify okay once we have that then
we're going to make it the right size
with the x equals image resize X when we
want it to be 28 by 28 pixels right
because that's what our model expects
that's that's the image size that we
trained it on so we're going to resize
it like that and then we're going to
reshape it so if it x equals x dot
reshape and then we're going to and so
now we're going to make it into a 4d
tensor of 120 of 128 28 1 of that size
so say for D tensor and that that is
what we feed into our model a for T
tensor okay so image dot reshape and so
now with our computation graph so this
is where that graph global variable
comes in will say graphs as default to
form the prediction so we'll say modeled
up predict x given that newly reshaped
image and then convert the response to a
string so we're going to take whatever
comes out as a response and we're going
to use this array string method to
convert it to a string and we're going
to say M Peter Arg max to get the max
value of whatever came out of that using
only a single access to a single
dimensional response which is just one
string
and then we're gonna return it return
response just like that okay and yeah
that's it
oh we've got and then that one we had
that one more method what was it it was
a convert image and so this is that last
two line helper function so this is this
is going to help us convert our image
into a raw representation or it's going
to decode it from bei 64 into raw data
basics t4 is like the default encoding
whenever we write it out that's just
like how it how native the native
JavaScript decided to encode it as and
we could decode it from basics before
and to just raw binary data so we could
then a lot of image conversion happens
here so we'll say okay and so this is
what we use our regular expressions
these were to say we'll get all the
parts of the image that are encoded in
base64 and convert them into this string
so that
or put them in this strange so that we
can then decode them so then we could
say we'll take whatever the so it can be
saved as output PNG the image that the
user drew so we're going to take that
image and then say decode it from basics
before cool ok so that's it for that's
it for this file for the app top 5 app
top hide file and then once we have that
now we can look at our dependencies here
like how did we how did we do this right
so we called some classes here and what
I want to do is talk is talk about what
classes we called ok let me just make
sure all this is correct
basics before yep yep yep
okay
cool alright so so we have that and so
now I want to look at the where was on
it okay tap top I trained up high and
then okay so then load up high let's
look at so let's look at some of these
dependency files so load up our mineral
load up high remember we called in it at
the beginning remember we were like
where was it model graphed in it this is
what's happening and load up high under
model and then stuff these are saved
models right away h5 and JSON what we
did was we loaded up our JSON okay and
our h5 file and we compiled them so that
we can then get the default graph okay
and so we said now we compiled them and
then we returned the default graph from
tensorflow
because we need both of them okay so we
had both of them and so when we hit
compile it's not actually training it's
just evaluating based on what it already
is like it's already trained and we're
already we're going to make sure that
the loss of a certain but that's what we
have these prints things we're going to
make sure the loss is a certain way the
accuracy is at a certain level and that
yeah and we can print those out so
that's what load up pi does and then
we've got this index of Jas file now
this is this is what's happening in the
background of the index.html this is
like pure JavaScript and there's no
jQuery basically what it's doing here is
it's it's listening to your mouse
movement to track to actually make the
drawing happen it's all in JavaScript
it's actually very short 83 lines of
code but in JavaScript it's using an
event listener to detect mouse movements
to then draw pixels on the screen okay
that's what this first part is doing and
then right here what it's saying is now
that here's that here's a really
important part Emily for the planes okay
and then the Clear button is just going
to clear the screen and we can select
the colors in the line width so here's
the last dependency that I want to talk
about is the index.html file
so for index.html
we're drawing a bunch of Dom elements
right like you know the button and the
like little browser thing at the top the
panel at the top and so then we've got
this done here's the most important part
when we click my button right on click
this is what this is a function that we
want to run okay we're going to say get
the element by ID so we're pulling an
element directly from the Dom and
storing that in the canvas object and
that is our image that the user Drew and
then we're going to say well convert it
to it a suitable string format so that
we can then make a request to it and
then use Ajax as a way to make a post to
the predict route using the image as a
parameter so it's going to make a
prediction using that image and then
it's when it when it's successful
you would this callback it's going to
return that response and that response
was here right this is the output
prediction once it's made the prediction
and we reshape that image it's going to
return it here and then it's going to
output it just like that right to HTML
okay so that's that's how that works and
so now where are we now so we've done
step three we've written our flash back
in to serve our saved model it's that
easy there's no other magic happening
under the hood it's just raw flask raw
JavaScript and care off with the
potential back-end and you can make a
web app just like that and there's a
bunch of other helper library there's a
bunch of other libraries and talk about
them as well and they give you things
like GPU acceleration and more
infrastructure tension load serving I'm
talking about ten serving specifically
gives you more infrastructure to run
different versions of models to deal
with life cycles management's things
like that okay so now in the last parts
deploying our code to Google Cloud okay
so this is actually super super simple
it's two it's two commands g-cloud app
deploy and then g-cloud app browse this
deploy app this deploy command is going
to take your entire repository when
you're in that main when you're in that
main directory and just deploy all of it
to Google cloud assuming you've
authenticated right
like you've already typed in your
username and password and apply that to
its own container in Google Cloud okay
and once it's done it's going to build a
container so it's going to build a
container image it's going to docker
eyes it and then deploy it to App Engine
hold on it's not going to docker eyes it
we would have to docker eyes it
ourselves if we wanted to but it's going
to deploy as a container to App Engine
an app engine is Google clouds service
for running apps it's like Heroku but
like Google clouds version and then once
it there if we want to view it we just
type in Google g-cloud app browse and
then it's going to be at our project ID
which is going to output appspot.com
and just like that you can now serve
this model to your friends and show them
what you built okay so the more info is
here right right on Google cloud I put a
link to it but basically you need to
download the SDK for Google clouds to be
able to use this it's not just a simple
pip install okay and once you've got
that then you could run it super easily
right also this guy I found this really
great tutorial as well it's more
detailed than what I'm doing it's
actually a little complicated like but
it's a pretty good tutorial as well link
to that there but basically yeah we
could just deploy the Google cloud cools
I'm going to end this by answering two
questions and then we're out of here
so question one is how can I count
objects in an image great question so
for something simple like that you can
just use OpenCV right you can just use
OpenCV you don't actually have to use a
pre trained model for that you could but
I think that would be overkill yeah use
OpenCV and then the method is called
yeah those are like multi object
detection
we have multi tracker that's the class
the multi tracker class and in one more
question
could you please make a video about
semantic nets using tensor flow I've got
several videos on semantic nets with
tender flow
check out my live my earlier live videos
from the Udacity deep learning
nanodegree several semantic nets like a
game of thrones just like Game of
Thrones Suraj that one's going to be
good for you
cool please subscribe if you like this
video and for now I've got to go deploy
my hair to production so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>