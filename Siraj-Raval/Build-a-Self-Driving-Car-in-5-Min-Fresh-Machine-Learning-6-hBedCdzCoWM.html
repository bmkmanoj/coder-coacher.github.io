<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Self Driving Car in 5 Min - Fresh Machine Learning #6 | Coder Coacher - Coaching Coders</title><meta content="Build a Self Driving Car in 5 Min - Fresh Machine Learning #6 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Self Driving Car in 5 Min - Fresh Machine Learning #6</b></h2><h5 class="post__date">2016-08-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hBedCdzCoWM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm glad I can book a self-driving
goober now hey this car isn't
self-driving I need to will never be
hello world it's Suraj and in this
episode we're going to talk about how
self-driving cars work then implement
our own self-driving car in a simulated
environment self-driving cars aren't in
the realm of science fiction anymore
real companies like Toyota and Ford have
millions of dollars in R&amp;amp;D pouring into
this technology services like uber and
lyft that currently pay human drivers
will soon deploy entire fleets of
self-driving cars so prepare for Skynet
just kidding in two or three years we're
going to start seeing hundreds of
thousands of self-driving cars being
sold to regular consumers get your
self-driving trucks right here but how
do they work well when we humans are in
the driver's seat we're observing our
environment by receiving an input of our
surroundings and simultaneously
processing it in order to make a
decision of which way to move the
steering wheel this can be translated
into a machine problem known as slam Rio
or simultaneous localization and mapping
and it's something all self-driving cars
do a self-driving car is usually
outfitted with a GPS unit an inertial
navigation system and a range of sensors
it uses the positional information from
the GPS and navigation system to
localize itself and the sensor data to
build an internal map of its environment
once it has its position in its internal
map of the world it can use that map to
find the optimal path to its destination
that avoids any kind of obstacles be
that dead babies or Pokemon once the car
has determined the optimal path to take
that decision is then broken down into a
series of motor commands which are fed
into the car's actuators that's a
high-level description of how they work
but roads are complex it's not just
about avoiding obstacles there are
weather conditions that require changes
in the way you accelerate different
types of road signs and situations that
you probably couldn't ever predict a
recent paper came out just this year
called long-term planning for short term
prediction these guys proposed a
planning algorithm for self-driving cars
specifically one that would be able to
make immediate actions so as to optimize
a long-term objective an example they
used was a roundabout when a car tries
to merge in a roundabout it should
decide on an immediate acceleration or
braking command while the long-term
effect of the
and it's a success or failure of the
merge traditionally planning for
self-driving cars is done via
reinforcement learning the car learns to
continuously correct its driving
capability over time through trial and
error when training the car or agent
observes a state s that is a scene that
it observes and takes an action a and
depending on whether or not the action
was good however we define good it can
receive a reward R then it moves to the
next state s and the process repeats the
goal is to maximize the reward and that
depends on a policy which Maps state to
action that it learns over time the
state action value function is called Q
and it helps find the optimal policy but
it can be super hard to learn Q in an
environment as dynamic as roads with
multiple cars it's not just a problem of
predicting your own cars actions you
have to be able to predict other cars
actions as well so to solve this problem
of learning Q they used a deeper current
neural network to learn a policy and the
input to the neural net was a vector
that contained both the predictable part
the speed of the car and an
unpredictable part the speed of other
cars so it could learn from both they
applied it to just two features adaptive
cruise control and merging roundabouts
but is there a way to make one learning
algorithm that can learn everything from
the ground up the technical term for
this is end to end and an even fresher
paper that was released about three
months ago tried it a team from Nvidia
put three cameras on a car windshield to
receive input data fed this video data
to a convolutional neural network and
features were learned by themselves they
didn't explicitly decompose the problem
into sub modules for different scenarios
there CNN mapped what it saw from the
input directly to steering commands it
was first trained in a simulation with
pre-recorded video then trained by a
human driver they got great results but
it was hard for the paper authors to
differentiate the feature extractor part
of the neural network from the
controller part so it was difficult to
test each that's why most real-world car
manufacturers have decided it's not yet
possible to test and verify an
end-to-end system they end up just
making software where each module is
separate and can be tested on its own a
hacker named George Hotz built a
self-driving car in his garage with just
a couple of cell phone cameras and the
total cost turned out to be just a
thousand bucks let's train our own
self-driving car using q-learning to
drive itself without running into
obstacles
after we declare our imports let's write
our training function for our car first
it will take in a neural net with a set
of hyper params as the parameters then
we'll define some variables for the
number of frames we want to observe for
both training and testing well then
define our positional variables for
localization we'll create a new game
instance and get the first state of the
game instance we'll also set a timer for
tracking purposes then when we start
building experience replay will update
our positional variables then choose an
action depending on the state randomly
if the random variable is outside of our
constraints we'll get the Q values for
each action to help us find the optimal
policy we'll take that action and if it
is valid we will get a reward
once it's done observing the game and
building experience replay we'll start
training sampling the experience replay
memory and getting the training values
it'll then train the model on this batch
that is a neural network then update the
starting state and if the car dies long
the distance and reset the cars life
finally we want to save the model every
25,000 frames in the weights file let's
see how it looks in a simulated
environment it constantly tries to avoid
obstacles through a mix of reinforcement
learning and a neural net once you've
got it working in the simulator you
could port it to a real RC car and have
it self drive all over your room links
down below for more info def subscribe
for more ml videos I've got to go to
send some gradients so thanks for
watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>