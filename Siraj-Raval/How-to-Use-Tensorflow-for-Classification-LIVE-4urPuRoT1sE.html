<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Use Tensorflow for Classification (LIVE) | Coder Coacher - Coaching Coders</title><meta content="How to Use Tensorflow for Classification (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Use Tensorflow for Classification (LIVE)</b></h2><h5 class="post__date">2017-01-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4urPuRoT1sE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">live stream is starting soon it's
starting - it's about to start
it's about to go down live stream is
about to go down in fact it's probably
already going down oh there I am
hello world its Raj good to see you guys
ml squad is in the building
let me shout out some names Igor lore
Dias catchy
Mik Raj Sudan Shu Brennan yo we got the
whole machine running squad in the house
right now who is ready to order some
tension flow I'm so excited for this
intense flow Masood go Goro Spencer
alright alright alright alright okay
cool hi everybody hi okay so let's get
down to business as they say in Milan
let's get down to business and defeat
the loss function okay so anyway um
let's start off with a five-minute Q &amp;amp; A
so so hit me up with your most intense
machine-learning questions or you just
want to know you know anything I'm just
will go for it and then we're going to
use tensorflow
to classify housing prices okay it's
going to be dope
it's gonna be the first time we're using
tensorflow from scratch in a live
session it's gonna be awesome
okay so here we go hi hi hi hi hi let's
begin I'm doing good I'm doing good I'm
so down I do have a sore throat but like
you know I'm a human I know but like
it's crazy but it's cool it's cool
um what kind of method approach do you
use to manage your time
Mik great question I so um what do I do
to manage my time I write down what I'm
going to do for the whole week before
the week starts so every Sunday I'll
write down you know the the weekly goals
I so I have a weekly to do - do I have a
daily - do I have a monthly - do I have
a yearly to do and then I have a
five-year to do so I planned things out
in intervals like that and and I make I
make sure my goals are accomplishable
goals so that I get that positive
be back so I can keep going is Google
released his own OS a chrome Chrome OS
yes our language no our only Python
recommended books on computer science or
cryptography um your choreography is so
dope I wish I could just deep dive into
cryptography that is like some ancient
Egyptian pharaoh mummy you know what I'm
saying like you have to a good book on
cryptography is my book he centralized
applications the best-selling software
engineering book on Amazon for 2016 and
a good book for machine learning is
machining a probabilistic approach by
forgot the name but that's the name of
it what do you can start wars I love
Star Wars
I'm actually not like I'd love the old
ones the new ones like I was kind of
disappointed by episode 7 so it's like
whatever it's kind of conservative then
for Disney's part we have to make our
own stories guys we are a new generation
we're gonna make our own stories they're
gonna be as good if not better than Star
Wars and we're gonna have a machine when
I get to be dope and when we make
stories it's gonna be technically
accurate what if there are more than one
local minima in gradient descent I'll go
great questions so that's so um yeah so
sometimes we've had more than you know
so with gradient descent it's like it's
like a 3d um route for the valley right
and you want to remember what I talked
about last lecture go ahead drop a ball
at football and see where it fits but
what if we have multiple balanced well
then that's when as a second-order
optimization function comes in we have
to find the local minima that is closest
to uh that is that is going to best
optimize our function we're going to
talk about that later but but the key
word to remember is a second-order
optimization function tensor calculus
that's exactly what we're going to say
are not at a low level but at a high
level because a tensor flow is going to
do a little bit of magic for us
can you explain max you mind tensor flow
I will absolutely explain the math
behind tension flow tensor flow is
better than torch exactly a strodge are
more layers always better in a neural
network a great question tomorrow no um
not always not always usually it is but
uh so if you have a smaller data set you
don't really need that many layers so
remember with with machine learning
there's always a trade-off there's
always a trade-off any engineering in
general there's
and in life there's a trade-off as well
but we want you when we when we optimize
for so when we increase the layers we
increase the computational complexity
but we also increase the accuracy so
there's a trade-off
how should I prepare for Google brain
residency program interview um Kaggle
title challenges are great and the
tensorflow
intro Docs watch on my videos but you
probably already have you all that you
apply the code you'll be good to go you
can try that idea that's the book thing
can you give a new research idea that
can implement intention flow yeah so
here's an idea I've had for a while
somebody should roll with this take the
synthetic radiance paper from D months
indicted ratings so they kind of like
stopped using back propagation just for
this paper and then take the idea of
one-shot learning so probabilistic
programming and then combine these two
ideas together so synthetic gradients
and one-shot learning boom there's your
landmark paper for the year I don't have
time to do it so someone just roll with
that it's tensorflow usable in raspberry
pi yeah actually somebody made a wrapper
for Arduino so two more questions that
never get started
how does genetic algorithm fit into
machine when you genetic algorithms are
good for optimizing hyper parameters for
us and let me talk about that for a
second so I've got some emails from
people who are like and also articles
what people like what do you think about
this where Google are using machine
running Google is using machine learning
to optimize machine learning so like
what do we do guys machine learning is
not going to take your job so wet okay
we we will be um so if even if there's a
even if there's a job apocalypse machine
learning engineers will be the last of
people to have jobs not that that's
going to happen we're going to create
new jobs in the new data economy and
we're gonna have basic income and things
like that hopefully think cryptocurrency
so check out my post social point it's
already possible and also grants point
but um don't worry about machine
learning replacing your job as machines
Urich if that actually happens that we
solved intelligence and then there's no
the idea of jobs and money and scarcity
all goes away anyway okay so let's let's
go ahead and start yes let's go ahead
and get started best way to start deep
learning so to start my course book
which at this course okay so what okay
so that's the five into an eight we're
going to do we're going to use tensor
flow
to classify housing prices okay so
that's what we're going to do and I'm
going to use a Jupiter notebook for one
so let me go ahead and start screen
sharing immediately and we'll get right
on into this ish here we go
okay so let me move this chat window
over here so I can still see you guys I
need to see myself but I just need to
see you guys and then I'll also have a
quick time up so I can you know see
myself alright new movie recording
alright and then that goes away and I'm
right here okay just minimize myself
yeah the one comes down blurred I'm
gonna get a better one okay so here's
what we're gonna do guys okay so we have
a housing data set a one-shot learning
was the name was the other thing okay so
that readies in one job okay someone do
that and just in general one-shot
learning so we need more one two
learning progress because no not
everybody has a huge data sets and huge
meeting power okay so I'm gonna explain
things slowly this time okay I'm going
to thanks Alexander much love okay so
I'm going to explain things slowly this
time okay so I'm going to start off by
talking about a neural network okay so
it's a lot okay we see this image a lot
of a neural networks right but the one
thing I want to say is you see only
circles we call them neurons
they're not actually objects they're not
classes these are just representations
of numbers let me zoom in a little bit
they just represent numbers okay because
when we include data into a neural
network into a neural network intention
flow we fought a a computation graph
um and these are not these are not
actually like neural you have not class
objects when we take a when we take an
input let's say like you know what we're
going to do housing prices and we apply
when we apply a some matrix math to it
it's going to take that value and it's
going to do so if it's a 1 value and we
multiply by a matrix of say three values
it's going to then become three or four
values those values are what we
represent as neurons they're not
actually objects and we take those
values and apply a set of matrix
operations to them and then BOOM that's
a next set of neurons but these neurons
are not actually classes they are values
okay so that I just want to start off
with that so that's that's that's that
now let me show you guys the graph that
we show you guys a data first so here's
the data set I mean let me zoom in
normals
okay so this is a set of housing prices
okay so the first one is the index which
is the number the next one is the area
which is the size of the house the next
one is the map the number of bathrooms
then the price and then this and then
the the price per square the price per
square inch okay so that's what that is
what we want to do is we want to
classify this but this isn't a class we
don't have labels right now we're going
to add labels okay we're going to add
labels where it's going to be a good
good where it's going to be either a
good buy or a bad bot because what we
want to do is we've given one of these
features okay we're going to decide with
features to use but given one of these
features you once again classify the
house as either a good buy or a bad bot
okay so mate when you shut down my
screen for a second just so the bit rate
goes up a little bit okay I want to
unload it be not that laggy okay so so
that's what we're going to do okay so
that's our data so let's go ahead and
start doing this in a jupiter notebook
okay so i'm going to do it in a jupiter
notebook alright so the first thing i
want to do is talk a little bit about
let me just make sure that this works
first no let's see yeah okay it works
great
okay so tensorflow why are we using
texplo in the first place so yes this
trip is going to be let me
the font bigger actually the phone is
missing
okay we're you center flow because
Google created it for this is going to
be a supervised problem okay yeah its
price per square foot this is a
supervised problem we're using tensor
flow because we in tension flow we are a
tensor flow was created by Google and it
was built to scale they've used it for
many years they released it it was kind
of like you know use coming down from
Olympus and giving fire to the humans
right
we know that tensor flow can scale we
know that it's reliable because it's
used in production by Google I mean
Google search uses tensor flow okay so
this is a reliable library although both
high torch is pretty cool too it just
came out this month and it introduces
the concept of dynamic computation
graphs
usually we have two interpreters right
we have a Python interpreter and then we
have a computation grep interpreter but
what I torch does is it has one
interpreter for everything okay so and
so jupiter notebook is really it's a
great concept basically you can it use
of a it allows us to view our code and
add markdown to our code it lets us add
um a bunch of you know critic things to
our code yes Prometheus is the right
answer that I was looking for okay so
let's go ahead and start by importing
our dependencies okay so we want you to
classify a problem also let me show you
guys what are your own that looks like I
didn't to show you guys what it's going
to look like so this is what it's going
to look like okay so we're going to feed
in two inputs and we're going to apply a
set of weights and biases use a soft max
function and then output a the housing
price as well as the the the label which
is good or bad okay so um we'll talk
about that in a second let's go ahead
and first support import our
dependencies all right so yes I'm
focused on the content Thank You pelage
so here we go important pandas as PD fly
pandas is our beautiful library to work
with data as tables workplace data I
first level okay so the next one is
numpy numpy it's going to help us use
numbers use number of matrices both pin
is intentional needed so use number of
86 okay the next thing is map pot light
because we're going to we're going to
show this graph we're going to show this
rap in a second and what else we one map
pot lives pipe lot as PL key
I prefer tangible I plot shoot arrows
and a finally pendulum as he a okay
that's it those are our four libraries
and we can go ahead and compile it boom
so because there are no errors we can
keep going right so that's a great thing
about Jupiter slash ipython notebooks is
that they like you compile as you go so
you can see you know what is happening
okay so that's what we did there now
we're going to load the data not so that
was that was so step one is to load data
load data okay so let's go ahead and
load data how are we going to load data
we are going to use the pandas a a
library to help us do that so the first
thing we're going to do is we're going
to use the pandas read CSV function so
because we have a CSV file okay um so
we're going to read us in as a data
frame object so what is a data frame
object data frame object is a is an
object in memory that canvas creates
from a CSV file that we can then easily
parse and I'm going to show you whatever
I mean by easily parts we're going to
take this data frame variable that we
just created and we're going to list
what the we're going to remove the
columns we don't care about so how do we
know which columns we don't care about
right so let's go back to our data for a
second we have several columns here
which are the ones that we want to use
to predict if a house is good or bad
well what we're gonna do is we're gonna
take out the index because that's not
gonna really give us anything it's just
a number
of what each column gets the next one is
of the let's say area and bathrooms
right so those are the two features that
like we're going to use area and
bathroom for and I need the price for
the square when a pieces price or the
square price because when I look for a
house I want to make sure that it has I
had a certainly and that's just what I'm
using right the design which features to
use is its own it's its own discipline
in and of itself what features should be
used and a good rule of thumb to go by
is is um what features will you
personally use to make a prediction okay
um now let me let me um give you guys
this data how do i because it's data oh
my greatest so you know just I'll say
let's just take all this let me give you
guys a state of real quick and I'll
paste it into the chat so you guys
that's it so data TSP I will create a
public gist boom and I'll paste it in
the chat ready get ready for this guy's
gonna paste it in boom goes your data
that's a data file alright so now you
guys can do that along with me alright
so we are going to remove the features
we don't care about okay we're going to
remove the features we don't care about
we don't care about the price we're not
going to care about the square I speak
only won't care about the back the
number of bathrooms and what was the
second thing the area that's that's what
we're going to be using right now okay
so an access is one because oh we're
only going to use the first access from
the data set all right so so data frame
not drop so that's actually removed oh
let me say what we just say we've
removed the we removed the features we
don't care about all right so we remove
the features we don't care about now
we're going to only use the first ten
rows of data set in this example so we
only want to use the first ten of these
right right up to here right up to here
okay
no Oxford I don't
once you define okay so so how do you
say that well easily you know the great
thing about a different project is we
can say we can say I won from row zero
to read ten boo so that's going to help
us that we want to only use we only use
the first ten row that's it okay so
that's it so now we have our data frame
effect so let's go ahead and print this
and here's the great thing about Python
notebooks if we can now print this in
see what we have and you'll give us an
error if it doesn't work okay so there
we go V dot syntax so let's see what I
did here so on this line and data frame
got drop it's pointing to this access
equals one and the problem here is
invalid syntax so we have index square
prize oh yes so it did okay so the this
bracket actually goes here that's where
the bracket goes now let's let's compile
okay so there we go there is our
beautiful clean formatted data and we're
only using the first ten columns and
we're just using the area and bathrooms
as our features and remember feature
selection is an entire discipline and of
itself and we could have used a square
price and we could have used the price
as features but what I'm looking for or
the area and bathrooms okay that's what
I look for when I try to predict if a
house was a good buy or not for me okay
um so so that's so now we have our
features so let's introduce our our
label so what we just did so step one is
to load the data and in step two is
going to be to introduce labels because
right now there are no label so we could
just do a regression right because we
could then prevent the next value and
what we use regression for for
predicting the next value in a
continuous set um so that's what we do
for that but what we're going to do is
we're to convert this into a
classification problem so add labels
let's have step two so we're going to
take a dataframe
object and if anybody doesn't have the
data go ahead and ask them income we're
going to paste it come into the chat a
link to that gist alright so
we're going to do is we reduce the
labels so we want to say our labels are
going to eat or goodbye or a backlog and
so how do you represent that well for
simplicity saying let's just use binary
numbers right so a goodbye is a one and
a bad by this is zero so I just randomly
had like you know a set of for our 10
for our 10 values so we have to count 10
right so we want one one one zero and
you know we'll add some variety in there
so let's see how many that bad it's
that's three six nine but we want uh we
have 1 1 0 0 1 and then 0 okay so we've
got 10 Dhabi so we're gonna add our
labels um and so did that sir so one is
good and 0 is back the 1 is good goodbye
and 0 is bad luck okay
so one is goodbye 0 is that now um now
you can see the first part of the codes
let me let me paste the link I'm going
to repay so link boom okay if you can't
basically okay so now you can't see the
first part of the code well that's let
me go up that I just I can't go back you
have to keep going okay
so one is goodbye is there is a bad box
so we need to find our setup labels now
the next step is to turn true false
values into ones and zeros so we're
going to say the location variable is
going to define those labels for us all
right so so let's go ahead and add the Y
to values which which well so y2 and
we're going to use a data frame object
where is y1 okay so what did we just do
so what we just did is and said y2 is a
negation of y1 right so we define y2 as
animation and a y2 is a patient of y1
it's the opposite opposite okay um right
so
so there's that access one is there is
the call okay so now Y so Y to mean we
don't like a house
why do need we don't like a house okay
so let's go ahead and define y - okay
different unlock location and we're
saying okay so what is that value that
we want um
y2 and then we'll say okay so we're
going to convert it to an H value
rightly so we want to remember that the
type were converting to is an int so how
do you convert it to an int value so
we're going to say as type int and so
what this says um if it turned
true/false values into ones or zeros so
turn true/false values to ones and
zeroes um okay and now we've done that
and so now let's print out what we have
here let's see what this looks like
great thing about ipython notebooks we
just praise what we have here definitely
have a syntax error so there it is and I
think Sagar mentioned this earlier so we
are going to add to line three
so which one is that our bracket yes
just like that okay and so now you have
an extra one
okay okay so what do we do so we added
labels but instead of saying good or bad
we had a cute label so this is just for
you know simplicity sake we don't want
to convert text to integers we're it's
going to say to a raw value so so Y so
if Y one has a value that means that is
a good luck
and every time Y one has a value every
time Y 1 is 1 y 2 will be 0 every time y
2 is 1 Y 1 will be 0 okay so that's just
our way of labeling our data for now
okay so we've added our labels that was
set to remember so step one was to load
the data which we did into a data frame
object we parsed it and then step two
was to add the label to the data right
which makes this a classification
problem if we're going to classify this
data okay we're going to classify
housing
if a house is a good buy or bad buy
based on on the area and the number of
passwords okay not bedrooms right well I
guess I mean the data didn't have
bedrooms did it okay so but yeah
bedrooms would probably you know be
better if we had that so now we have all
our data in a data friend we have to
shape it in matrices there eat intention
posters now step three is to prepare
data for tensorflow so depending on
which machine learning library we're
using we can we will prepare it a
certain way but in general in general no
matter what day we have or once you
convert it into tensors so let me
explain what end result so um so tensors
are it's a high level and so tensors and
so ten turns are a generic version of
mate of vectors and maces so um a vector
is so like vector is a list of numbers
then vector is we just write up this is
important because we see these words a
lot to take a list of numbers then a
matrix is a list of lists of numbers
okay so then so a vector would be a one
D tensor matrix would be a to D tensor
and then whatever a risk of list of list
of numbers is would be a three D tensor
and then that just continues okay so a
tensor is like a very generic term for
both matrices matrices and vectors and
these tensors are 1/2 or how we
represent data in tensor flow right guys
machine learning neural networks it's
all just matrix math it's a collection
of operations that we apply to some
include matrix and we continually apply
them like a chain of these operations
until we get to an output and then we
and then we apply an optimization
function to to minimize a loss and I'm
going to talk about that in a second
we're going to do that but that's what
this day is ok so so that was a little
short like the thing on Hendrix for
but to get back to what we're doing so
we're going to take our data frame and
we're going to say let's see we want to
take the area and the bathroom so we're
going to take our features right we're
going to take our features and we're
going to convert that into tensors we're
going to convert our features and attend
yourself convert features to 10 to
include tensors
instead we're going to burn features and
to change link rate tensor um and this
session we type int or probably an hour
we'll see as matrix and B we want you to
we want to say okay so as a matrix
that's an invert so now we're going to
convert our labels to a two input
country as well right so let me show you
guys this image again okay all right so
just right so here are our C just like
right here this these two purple circles
those are our input tensors are features
and our labels we're going to feed that
into a sec you haven't create our
weights yet we've just so if you just
block out everything but these two
purple lines that I'm sorry these two
purple circles that's what we just rip
okay um so now uh so that's what we did
for that so now we're going to convert
our labels imputation circuits okay so
I'm sorry our labels into ten trips or
say a beta friend blog since I started
probably gonna happen Seoul today
okay so doc location and then well what
were those up labels that we created and
guys we really have um one label as well
I'm just you know is um okay so I'm
going to focus on this let's see let's
see this compiles okay so syntax error
what do we have here so right so it's an
extra back bracket all right so area
bathrooms um we have
okay so this needs to play need an extra
bracket here and then what else do I
have here so for y1 I have a bracket
well I need another bracket and then
we'll compile that let's see what else
we got here just Jo comma aren't
tricking our notebooks so great guys we
can just continue we can just we can
just compile as we go we can just
compile as we go a different application
y1 y2 what's the dealio okay we're going
to remove that we want to say what is
going on here we've got y1 y2 done
location and this is a bracket oh let's
see oh okay let's see what's going on
here whoa that's a lot none of area
bathrooms are in the columns hold on a
second area bathroom are in the columns
let's see what we did here so he's at a
data frame table location we converted
area backwards to a so matrix um and
then we said okay as matrix interesting
okay so right so we did have area
bathrooms um remove the closing bracket
um
remove the closing brackets on remove
this one and we want to add interesting
missing quotes oh there it is right
missing clothes that's what it was oh my
god okay yes all right there we go
okay good it scared me for a second
let's print on what we had here so what
do we just create oh so what is this
this is what our input matrix looks like
okay so we have the area in the
bathrooms and this is what our labels
matrixyl cyclist I print out my label
matrix
okay so that's our input matrix and
that's our label matrix guys we have our
inputs now we're going to prepare our
parameters and so what step are we on
now we're on step four so step three was
to prepare the data for tension flow so
we can format in our data for tension
flow and now we're going to spend for is
to write out our hyper parameters okay
so what are our hyper parameters so the
first one is going to be our learning
rate and so when did we last seas are
going to break we use a learning rate
when we are the last live session to sum
that up we the learning rate controls
the rate at which we learn I know that
tennis you know
so what the better explanation learning
rate defines how fast we reach
convergence to be technical convergence
is when our model is at its optimal fit
when we have that optimal fit where the
error is minimized and the learning rate
defines how fast we get convergence we
had to say okay to say Oh make the
learning rate a million and just get
there as fast as possible
because if you go too high then your
your models not going to converge if you
go to too low it's gonna be too slow so
remember like all things it is a trade
arm that is the word of the day
machine learning is a series of
trade-offs and go as M trade-offs
applause okay so the next thing is a
training one we're going to craze think
mm x and y mm I don't know I mean we
could we could try 10,000 in a second I
don't know your own say so and that's
what we do we we train for a number of
epochs with your results and then we say
well is this is this prediction accurate
or not
and then if not they will change will
tune or hyper parameters and set again
okay so then the number of displaced X
so how often do we want to display
so then how often do we want to display
the process of training I have a number
example which is going to be the size of
the number label which is 10 okay so
that words are hyper those who are hyper
parameters and now guys we are ready to
compile and make sure that runs is if
you create our computation bracket so a
bit on computation create our
computation graph
neural network okay so complication grab
neural network or the same thing but
before we get that we do one quick
review from above what we've done so far
we imported our dependencies then we
loaded our data which is a CSV file then
the data can take a bunch of features
but we only wanted to use the area and
the bathrooms as our features we removed
everything else using those two things
we want to predict if a housing price is
good or not but guess what there are no
labels in our data so what did we do we
added labels because data frame objects
are really easy to parse add data from
remove data from and so we added labels
y1 is when y1 has a value 1 it means
it's a goodbye
when y2 has a good value that is a that
is when it's not a goodbye then we
prepared our data for tensorflow how do
we do that
we look at our data frame object and we
converted our features into an input
tensor and then we convert our labels
when you put tensor as well we printed
them out we defined our hyper parameters
and now we're going to do we're going to
write out our computation draft okay so
let's go ahead and write out our
computation graph so let's go ahead and
do this so the parts I'm going to do is
create I'm going to create a placeholder
for our feature and click tensor that we
just defined input X and what this is
doing is so for me quick for our feature
input country get your input country so
intent Rafi it will fit in an array of
examples each example will be an array
of two slope values area number of
bathrooms and so none means any number
of examples you don't hit the funk which
is you know usually the batch size but
we can suppose we're just going to say
none so it's just generic we can say
however many we want I will allocate it
that will happen we've allocated at
number beforehand and this allows us to
have any number of examples and 32
because that's the size of this input
tensor okay so I'm sorry not 32 to 1
minus 6 so
- because we have two features okay and
and it's a 2d matrix right because we
have two features so we've done that
and so the next step is to now create
our ways so create wait until another
thing placeholder pupfish are gateways
so placeholders in Interpol are gateways
for data it's how we feed data in for a
computation wrap our big way for data
into our computation rack alright so the
next step is to create weights so how
are we going to create our weights so
we're going to define our weight as W
and we're going to say TM thought
variable and so we can just write aside
so we'll define our waist and it's going
to start off its as a set of 0 because
we haven't and that's how you should
start off your weight um for a simple
example like this um although with
transfer learning uh you know your
weights aren't 0 their third they've
been training beforehand so this is a
2x2 flow matrix 2 by 2 slope pages and
and we're going to keep updating them
and we'll keep updating through the
training process that's what we're going
to do uh and so why do we use a variable
well in tensorflow
a variable is um when dave variables
hold an update parameter so variables in
TF hold and update parameters and you
have ways um
BM weights or any other things you want
to so they're they're basically in that
memory buffers containing tensors
okay um more a little more technical
about but done these are our ways
okay so the next step is to pan our
biases so um we're going to have our
biases so Adam Pisces and so we want to
buy X's right because we have to eclipse
um we want to bison because we have two
inputs and we're going this is also
going to be a CF variable um okay so and
just a few my cute flow matrix okay I
already type that out and
we're going to close the bracket here
and add a closing parenthesis okay so
let's see what this actually we're going
to do one so let me show you guys what
we have so far so now what we've done is
we create our input tensor we have me
actually use this little square thing
and we've created our weights and now
we're going to add our biasing so this
is what we're about to do is we're going
to add this other purple square looking
dots so yes we're going to use that
combination to update our weights in a
second but first way to define our
biases and why do we use biases
well biases are going to help our model
date better so a good example is like so
example is be in the widen folks MX plus
B equation B is the bias like that oh
right so because V takes outline and it
adds the y intercept which makes it fit
better so that's what biases do they
they are up there they're a part of the
larger goal they they it's like you know
if you didn't have B in the y equals MX
plus B the line wouldn't be the red line
that you're looking for right so um okay
um and I'll go over you know everything
we've done at the end guys so right now
we've added our biases and to the next
step is to a chocolate we're going to
perform some major tests so now we're
going to multiply our leaks by our
inputs so this is our first calculation
that's happening here right because
weights are will be multi weight for how
we govern how data flows in an arc of a
weight for how we govern how data flows
in our coming back okay so let's go
ahead and perform this so we'll say
we'll define it as Y values all sick and
um we'll say and yes wait can we can
initialize weights as random as well um
and depending on you know what you're
doing it can be different but right now
we're initializing that of zeros and to
perform this actual matrix
multiplication step the pentacle has
this great built-in matrix
multiplication function um a graph we
can say
it's okay park people's and then our
weights and then our biases and what are
we going to do here we're going to
calculate the prediction to move and to
do that to do that which multiply the
input matrix by the weight matrix and
then add the biases so let me write that
out multiply the input by waist and add
biases and add like six okay so it's
kind of like y equals MX plus B it's
just similar operations okay so we've
done that and now it's now we're going
to do mark softmax function okay we just
are same one softmax is another way to
consigue so we've done this part right
and now we're going to do this part
which is we're going to take those
values we're going to apply a soft
message to it and what does softmax -
does anyone remember shout it out in the
comments going to explain it in a second
it's type it out if someone can check
that out I will give you a child
tell me what the softmax function f so
we're going to take softmax I stop next
to this value that we created right
we're going to apply our softmax to this
value click apply some next to value we
just create okay so and then what does
it's an activation function so it's now
an activation function and it does
something
oh wait
so let me go ahead and so I just yes it
normalizes our value so what softmax
does is it normalizes our valuated what
do I mean by that it takes our value and
it converts into a probability that we
can then feed to our output so it's our
last step before we feed to our helpless
so let me make sure that I type all this
ish out perfectly okay so on line 14
variable of zeroes
I said take very little zeros oh I need
a bracket here okay kids are zeros the
laser focus on what if what I've done
here so um
let's see interesting so there is a
extra value here um let's see what's
going down here
TF done variable TF zeros Oh extra
dollar okay okay so now the next step is
to say I was good you know what it is
it's all good okay so I need to add a
bracket there I think all right yeah so
I'm having one fair and once you add one
here and then we say compile and so then
for the Y values it's telling me what
I've done wrong so it's saying hey Suraj
listen buddy listen you need to apply
your matrix multiply x WB th ad
um okay just what else we got here Y
values and let's say name X is not
defined X is not defined
leave me exit oh because I didn't define
it yes so X is that value okay great
great so and I hit enter so I need to go
ahead and add one more thing for
training so okay so what are we just
doing we had it um
the code is going to go online yes I'm
going to post it in the comments I'm
done we've got 15 minutes okay so what
we're going to do let me say you've got
that soft max value and now we can eat
it for output so let me type that out so
what are we doing here we're going to
feed oh so we never did this part so
we're set feet in a matrix of labels let
me just go over what I've just done here
okay so uh so these are our two
placeholders right so X is up here and
then Y is down here but this right so
one is our labels and then one one is
our set of features they created our
ways we come and there are biases and I
mean this is our computation step right
here we multiplied our weights by a by
out by our inputs and we handed our
biases and we sit and then we use that
value W calculated we input it into a
soft mask layer which converted it into
a set of probabilities okay so so
there's that and now we're going to
apply we're going to perform our
training set perform training so we've
done these steps and now step six is to
perform training step six is to perform
print all right so let's go ahead and
work so this is this is the magic part
attention flow so if you're here in the
live session last week then we did this
manual so so let me just write out what
we're back to you what we're going to do
is we're going to count create our cost
function and the cost function we're
going using is immediate squared error
all right so we did this last live
session when the great things about a
course is that we have continuity and so
we can say we can say minus y but this
is going to be the equation and I'm
going to show the equation in a second
but what this does is it says we want to
calculate the error so between our two Y
values and we're going to divide by the
number of us so the mean squared error
is going to take the average of the
difference in values which is our error
the squared difference and that's what
this is doing so um so reduce some
basically confuse the element the summit
element across dimensions of ten so
immediately write that out reduce some
confuse confuse elements the sum of
elements across dimensions about a
concern and so then let me show the
equation for this in a second what we
just did so the two different values
were using are the
the two three dollars are using is our
predicted the predicted values and then
the actual values for the outputs that
is our cost function we want to minimize
this cost function over time and to do
that we're going to perform gradient
descent so we're not so the breaking
ball tends to flow is because the fine
radiance and ads are optimization
function we don't have to actually write
out every step right nu and gradient
descent every step means we're computing
the partial derivative with respect to
our input variables which in our case
would be the retardation in a set of
weights and the diocese so that's a
we're going to say we have a cost
function we want to minimize that cost
using gradient descent and our learning
rate will define how fast we want to do
that okay so not to call me during a
live session okay so let's see what
we've got here um we're going to say Y
is here right and right so this should
be Y under squat so that's why that
didn't work and so the next thing is we
want to make sure that name y is not
defined how about now no it is defined
because I just updated it there we go
great so yes so I updated the Y and now
we're going to create our session um
okay so let's initialize our session
this is still a part of the training
step going to neutralize our variables
and tend to closed session so in
tensorflow meeting we encapsulate our
coming HT graph we should we encapsulate
our competition Draft using utilize all
variables using a session object so we
tend to float whenever you want to kind
of training get the first initialize all
the variables and what initialize all
variables does it just it does exactly
what it says initializes every variable
that you've declared before catbag that
means those TF table variables we
declared it beforehand and
the placeholder objects we did
beforehand right so every 10 jablow
generic variable that we define
beforehand this initialized it for the
session so I mean this could be you know
this could be done under the hood as
well but for now we're going to we're
going
textbook asks us to define it so we
create our intention our session and
then we just rerun it by using the old
variables that we've initialized as our
input okay
and of course resume all right so no
attribute initial all variable so what
was that so initialize all variables
with a a set of parentheses and then TF
top session let's see what else we got
here t echte initialize I am miss Bowman
initialize okay initialize Raven okay so
here we go let's let's do this is the
last bit that we're going to do this is
the actual training room this is the
training okay so let's go to do sort
prepare enough for every epoch that we
have for training P pox how many people
do we have in this life section 300
people go awesome okay so for so for
every training epoch home we define as
300 well what was it blows in number
2000 we define us mm we'll wait to run
our session given our optimizer which is
gradient descent so this is for
performing gradient descent and we're
going to feed in this is where we
actually feed in those placeholders that
we defined earlier
so those placeholders are going to be
that the first is going to be that x
value which is going to be our features
the input X and the next one is going to
be for the labels we just want to be are
a foot lot better okay so how does that
and so that's it so now that's it really
and now that you just you know write out
our debugging message we're just going
to be right out logs of training so if I
display step equals to zero and then
we'll say let's run this session getting
our cost function in R and then we're
going to UM and we actually already just
did this but we're doing this just to
print it out just so we can see you know
what what's happening at each step okay
so our input is going to be that first
tensor and then our other employees
maybe get the other tensor that we need
that we need to find yep for them I'm
training step it's going to be no C so
this part in turn it's this part right
here because we don't actually it's just
just long that is it that's it really so
what we're doing is we're printing out
the training step and let me just go
ahead and run this down okay so our
first attacks are so is going to be X
right this doesn't need that thank you
else we got here X input X Y hmm fee
dict
equals session dumb run feet dipped
equals y oh okay yes okay
okay awesome so boom so that's how fast
trained because because it was only ten
values okay it was only ten dollars and
so what is happening here let's look at
this the first column is our set of
training steps right and the next one is
our cost function and the cost function
is minimized over time okay and and then
eventually it's finished training so
what is the book so it ends up with the
cost function 0.109 whatever right so
this is this good or bad I don't really
know but it's
it's better than the first cost value
that's for sure we don't know if it's a
good cost function or not it can be kind
of arbitrarily defined of what um those
labels were ourselves so let's go ahead
and test this out however you might test
it ever call / wardrobe and I'm also
like really sick which is like I don't
have time for that guys I'm Trent I'm
teaching this dope ass on cords okay so
we're gonna feed in um our input and
we're going to test it out we're going
to see what happens now okay so this is
our output so what is it here so this is
the prediction right so we've trained
our model and now we're going to do our
prediction right and so it's guessing
that they're all good houses because
these values are all above uh so
remember I said we have y 1 and y 0 so
it's saying so so let me go let me go
back up for a second so you guys can see
what I'm talking about here so we
defined remember this y 1 and y 2 that's
what it's outputting that's that's what
it's out is just the wider one from the
white tube it's saying um these values
rounded are closest to 1 right on the
left side so that means it's all one and
values on the right are all closest to
zero which means it's zero so what it's
saying is it it's saying all houses are
a good bot but that's not the case so
exact seven head of 10 correct but the
actual thing is it wasn't oh they
weren't all good
they were just some of them are good
right so only three um only some of them
were good so step at a time correct
which is not bad probably prove uh maybe
we could add a hidden layer add a hidden
layer add I think there that's what I
would do I would add a hidden layer and
then I would fly it again so that's a
kind of so that's my example for this
okay so let's go back to screen sharing
okay
stop screen sharing go back to me hi
okay so uh that's what we did for that
and I'm going to I'm going to add the
code to github link 5-minute ending Q&amp;amp;A
and then we're good to go
Kevin I have a video for you guys to be
on on Friday which I'm super excited
about Kim
young with your questions let's go
anything why are using Jupiter any
special perks Jupiter because uh it
allows you to compile and see what
you're doing in real time it's great for
visually looking at especially for data
it's great for visually looking at what
you're doing exactly what Jay said how
do you choose the number of hidden
layers or not of unites while trying to
develop a neural network it depends on
how big your data is the more data you
have generally the more hidden layers
the more data you have the better it is
to add more hidden layers um
right hi George vs. tensorflow for
newcomer absolutely tensor flow don't
even don't even trip well but you know
hi George has some great architectural
ideas that I think we can you know we'll
see where that goes
it's a really exciting space guys it's
only January and we're already seeing so
much innovation in this field in fact
this pace of innovation is accelerating
itself
it's insane um how many layers should we
add for this case I just answer that um
can you say something about google's
deepmind
machine running um well I mean they
haven't really done anything this year
yet but just wait give them like two
weeks I expect to see some state of the
art in something yeah paper in like
within two weeks
how does high supply an image data set
we're going to do that in two episodes
for this course with high level you want
to label data set a supervised approach
um with labels look at Google's
inception you don't even training
yourself they were already in it on a
million images you can use transfer
learning to apply that and then add in
whatever other images you want to
classify and because of transfer
learning you don't need that big a data
set to train it and I have a video on
that called guilt intensive lineage
classifier in five minutes how much copy
did you have I had a cup is it the same
life session the one who are doing with
Udacity yes um any video is a recurrent
neural Nets planned
yes that's coming out in about three
days uh do you think that Udacity
equally of course apparently for a
defunding job yes one image
you do the assignments okay that does it
Kavya you have to do the assignments you
can't just watch the videos if you do it
do it like Shia LaBeouf two wins I'm a
huge Shia LaBeouf then by the way guys
recently um because he doesn't work for
the City Board did you age I'm 25 did
you study at university yes what
computer science specifically robotics
um anything on memory networks yo I want
to do memory networks that's um that's
an advanced that's like generative
adversarial necklace should that I find
super interesting at the cutting the
bleeding edge of the field we've got to
get our basics down if you should take
something out of this live session what
you should take out is our um three
things one how to do gradient descent
and that propagation to UM a basic an
idea of what the UH the main variables
are with tensor flow that means
placeholders TF variables the optimizer
function weights and biases okay is
everything gonna build on that can get
those simple things then everything else
is going to be much much busier and the
third thing is um a softmax function
sorry activation functions an activation
function is what we use to convert
numbers to probabilities there's several
types of activation functions in this
case we use softmax which university
Columbia University but guys I want to
end this with one piece of advice and
then we're good to go
a lot of what we learn is what we tell
ourselves we are capable of doing
that's what degrees our degrees tell us
that allow us to tell ourselves hey I
now know this I can do it but we have to
flip that way of thinking
it's not about oh I have a degree now
I'm a computer scientist I have a degree
now I can do X know if you study
something and you do is if you can
create the code and it compiles and runs
and it gets you help with that you want
it you now have the ability to do that
so don't be restricted by the dogma of
oh I need to read this or ate this
before I get to this think of something
you want to build start
building and along the way learn what
you need to build it by the end you are
going to get really good because if
you've ever engineered anything reported
you know that if anybody asks you a
problem about it you know every answer
why because you had to deep dive into it
to be able to build that okay so that's
it um all right so believe in yourself
specificity believe in yourselves the
world needs you guys okay we need you we
are starting a revolution okay we are in
the midst of a revolution unlike
anything the world has ever seen before
and we are going to you're going to do
some awesome okay we're going to do
some awesome okay that's it okay so
thanks guys for watching the video is
coming out on Friday
it's going to be dope and uh continue
the conversation our slack channel for
now I'm going to I'm going to yes I'm
going to do the math tutorial in a
second um okay so anyways for now I've
got to work with Udacity on something
I'm glad to be ghastly and just hang
with them and you know see what we can
do there's some really cool people for
now that's what I got to do so thanks
for watching love you guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>