<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Make a Simple Tensorflow Speech Recognizer | Coder Coacher - Coaching Coders</title><meta content="How to Make a Simple Tensorflow Speech Recognizer - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Make a Simple Tensorflow Speech Recognizer</b></h2><h5 class="post__date">2016-12-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/u9FPqkuoEJ8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and let's make
our own speech recognizer using
tensorflow speech recognition has gotten
so much better in the past few decades
in the 50s the general consensus amongst
computer scientists was that speech
signals needed to first be split into
little phonetic units then those units
could be grouped into words but even
though this seemed like it would work
well this approach did not give us good
results the first-ever speech recognizer
was called Audrey by Bell Labs in 1952
it could only recognize spoken numbers
between 1 and 9 and was built with
analog electronic circuits the renowned
scientist and VP at Bell Labs John
Pierce banned speech recognition
research because the results weren't
promising enough but a small group of
visionaries at a newly formed team
called DARPA went against popular
opinion and created a system called
harpy it used 15,000 interconnected
nodes and each represented all the
possible utterances within the domain
they used a brute-force search algorithm
to map the speech to the right nodes to
get the text this approach was slightly
better but then big blue invented
something called the hidden Markov model
HMMs represented utterances as states
and probabilistic we predicted what a
word was given the fee nomes it was made
up of when words like you are pronounced
they can have different durations like
you or you and HMS captured the
plasticity Awards by using a
probabilistic approach the hmm pretty
much maintained its position as king of
speech recognition throughout the 80s
and 90s as researchers improved them
more and more and some weirdos kept
trying this dumb technique called
artificial neural networks but of course
it didn't get good results one of them
this guy Geoffrey Hinton kept on trying
out neural networks until all of a
sudden a couple years ago it started
outperforming everything did people tell
you Geoffrey you're wasting your time
many times and would you sit back give
me another 6 months and I'll prove to
you that it works
the key was to give it more data and
computing power this is deep learning
now these deep neural Nets are how
services like Siri and echo and Google
now hear you speak and with Google's
machine learning framework tensorflow
we're going to build our own deep neural
network that learns to recognize spoken
numbers we're going to download a
labelled data set of people saying
numbers build a neural network train it
on that data then test it out see if we
can recognize other spoken numbers it'll
be 20 lines of Python code and I'll
explain things as we go ready let's
first import TF learn TF Lauren is a
high level library built on top of
tensor flow that is easier to read and
great for fast prototyping our other
import is a helper class we've created
called speech data
this will help fetch data from the web
and format it for us now that we have
our libraries let's define our hyper
parameters or tuning ops we have three
of them the first one is the learning
rate the learning rate is what we apply
to this wait updating process the
greater the learning rate the faster our
network trains the lower the learning
rate the more accurate our network
predicts so it represents a trade-off
between time and accuracy next we'll
define how many steps we want to train
for 300,000 we have our hyper parameters
now we can fetch our data this is where
we'll use our helper class speech data
specifically it's batch generator
function this function will download a
set of WAV files each WAV file is a
recording of a different spoken digit
like and each is labeled with a written
digit it will return the list of labeled
speech files as a batch then we can
split our batch into training and
testing data with pythons built in next
function we'll use the same data for
testing for simplicity so it'll be able
to recognize a speaker we trained it on
but not other speakers now that we have
our training and testing data it's time
to make our neural network so what kind
of neural network should we use for this
I'm going to wrap the answer to this did
you drop out turn it up once a one
problem is classifying images input
image output label ain't no sequences a
one-to-many problem gives an image
captions input image output sequence and
all of them abstractions a minute in one
problem is sentiment
this input sequence output positive
ain't no accident a problem that's many
to many is a sequence of waves output
sequence of words then our model says
since spoken words are a sequence of
sound waves
we want to use a recurrent neural
network since they're capable of
processing sequences so we'll initialize
our net by calling TF learns input data
function this initial input layer will
be the gateway that data is fed into the
network and the parameter will help
define the shape of our input data or as
tension flow calls it our input tensor a
tensor is a fancy word for a
multi-dimensional array of data our two
parameters will be the width and the
height the width is the number of
features that are extracted from our
utterances in our speech data helper
class and the height is the max length
of each utterance for our next layer we
use TF learns LS TM or long short-term
memory function in a recurrent net the
output data's contents is influenced not
only by the input we've just put in but
by the entire history of inputs through
our recurring loop LS TMS are the type
of recurrent net that can remember
everything it's fed and because of that
they outperform regular recurrent Nets
consistently we'll use our previous
layer as our first parameter since we
are feeding tensors from one layer to
the next then the number of neurons
there's not really a rule for knowing
how many neurons use in a layer too few
will lead to bad predictions and too
many will over fit to our training data
meaning it won't generalize well let's
pick 128 and then our dropout value
which says how much dropout do we want
dropout helps prevent overfitting by
randomly turning off some neurons during
training so data is forced to find new
paths between layers allowing for a more
generalized model our next layer will be
fully connected meaning every neuron in
the previous layer will be connected to
its neurons and our number of classes
are 10 since we are only recognizing 10
digits we'll set the activation function
to softmax which will convert numerical
data into probabilities lastly we'll
create our output layer as a regression
which will output a single predicted
number for our utterance we're using the
popular atom optimizer to minimize our
categorical cross entropy loss function
over time so we get a more accurate
prediction now we can initialize our
network using TF learns deep neural net
function and set tensor board verbose to
3 which means
you want a detailed visualization well
initialize our training loop then fit
our model to the training and testing
data for ten impacts with our specified
batch size then we'll predict a spoken--
digits value from our training data we
also make sure to save our bottle for
later use and print our result let's run
this thing
TF learn has a nice log of important
training variables built in just from
running the fit function so we don't
have to specify what things to print
after it's done training it'll predict
the digits and if we wanted to we could
just record ourselves saying a number
and place it in the data directory then
predict that so to break it down L STM
neural networks are used in
state-of-the-art speech recognition we
can use TF learn to quickly build and
train a deep neural network to recognize
speech and good hyper parameters like
the learning rate are those that are
balanced between trade-offs like time
and accuracy the winner of the coding
challenge from the last video is Mick
Van Holtz the challenge was to generate
text in the style of Lord of the Rings
using TF learn Mick trained an LS TM
network on the gand elfish language then
headed output new Gandalf fish like
yellow lotus hair river badass of the
week no new coding challenge for this
video since the challenge from the
makeup video game bot video is still
running if you haven't watched it yet
check out the link to it in the
description and the due date is Thursday
December 15th at noon PST which is one
week from today please subscribe and for
now I've got to get tickets to ICL our
next year so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>