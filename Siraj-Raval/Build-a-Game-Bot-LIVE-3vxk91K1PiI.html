<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Game Bot (LIVE) | Coder Coacher - Coaching Coders</title><meta content="Build a Game Bot (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Game Bot (LIVE)</b></h2><h5 class="post__date">2016-09-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3vxk91K1PiI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello
okay wait someone can hear me right you
can hear me I'm testing this hello
okay wait forget your melee all right
all right perfect
so okay cool here we are hi everybody
what's good what's good welcome to this
we're about to code some stuff about to
code some stuff all right
there's like an echo which is weird so
like I can hear myself after I've typed
something so I'm just gonna like mute my
own voice there we go okay so yeah okay
here we go we're gonna code some game a
eyes with opening I Jim open AI is the
startup you know Elon Musk's startup
they want to decentralize everything be
centralized AI make sure that it's not
in the hands of just Google so I'm a big
fan of that so yeah I want to start off
with like a you know a few minutes you a
if anyone wants to ask me anything we
could just get on that you know what I
mean so what's up everybody
ask away I will wait just a little bit
and then we'll get right into the code
I've never done this before so this is
do I think I'm a programmer I I think
sometimes that happens I think from time
to time I'm a programmer but I really
try not to be like I don't want to be a
programmer but like I I think I can be
sometimes how old am i I am 25 years old
I'm 25 years old
yes what do I do for a leave living I do
this YouTube thing full-time I that's
that's my living I just do YouTube
full-time I'm not
making that much right now I mean you
know it's getting better and better but
right now it's like it's you know it's
it's still climbing up in terms of the
money I'm making ads are not good by the
way like that that stuff is just not
working out so there are other methods
clients approaching me and stuff to make
videos for them what ingredients do I
usually put on hamburgers I usually put
uh oh my god these questions are really
coming in uh uh what in green so I put
on hamburgers I put onions that's right
I know a lot of people hate onions but I
love them and I like everything spicy
it's probably cuz I grew up eating spicy
food because my parents are Indian and I
was born in Texas so like double spice
wham either what is your favorite
machine learning library to use it is
tensorflow are your parents are your
pants a compressed file because I'd love
to unzip them thank you they are
compressed right now are you an AI
researcher not officially what's your
qualifications I went to school at
Columbia studied machine learning there
worked in the robotics lab worked at
Tullio been a software engineer for two
years studying machine learning for two
years on my own are you going to school
no uh no I'm not school is overrated
learn everything from the internet yeah
I know that's kind of like you know
weird or whatever but like learn
everything from the internet traditional
school is stupid where do you work I
work on this YouTube channel full-time
what's your education my education is a
college undergrad are we all just
modifying scripts
I guess so when did you start
programming uh like freshman year of
college I was uh I was like studying
finance and I was like okay yo I need to
like make some money I want to I want to
do some great things in my life so I so
I took a semester off and I went to
Europe forgot couch trip for three and a
half months I stayed with a guy named
Alex macaw and he was awesome and he
like inspired me he wrote he wrote the
book on JavaScript and he has a start-up
now and he travelled the world for a
year so I think just meeting somebody
really inspirational in person just
changed me and I was like okay I got to
do computer science stuff so stressed
new year of college
have you taken psychedelic substances
answer is yes do it in a controlled
environment with someone you care about
would you present
wavenet I have in a video check out
generate music with tensorflow uh yes
I'm going to do a video on Google's do
research crepe or the Machine machine
translation once soon a brain-fuck
machine learning program that would be
awesome
uh okay what's your favorite computer
vision project probably um OpenCV still
because like I mean you're Europeans if
like try to make their own TV thing
sorry
Americans are still better as software
definitively if you learn everything
there how do you prove that what you
know when you apply for a job if you
have no title um that's a good question
actually I mean with Udacity there's
like nano degrees so there's that
there's projects and then they're just
like presenting yourself in person so I
think like your github repository like
github repository github profiles are
the new resume at least if you're in
software I I want to do more than
YouTube to inspire and equip developers
I'm looking at other methods this is one
way I'm experimenting right now when did
you start learning ml I would say I
started learning ml two years ago is a
master's degree worth it I think that a
master's degree is worth it for two
reasons you get the time to study and
you don't have other obligations if you
can if you can find the way to have the
time to study without a master's degree
then I would go for that because the
bureaucracy is involved with graduate
school or can totally get in the way so
really it's just about money and time
like if you can find a way to study go
for it that's what I did the best MOOC
I've come across for ml is probably the
Udacity one by Google on deep learning
it's that one dude who works at Google
and it's using tensorflow and it's like
four modules and and ruins course is
great but it's totally overrated in fact
that's one of the reasons I started my
channel because because there's not
enough application-specific code it's
all just like here is this like huge
algorithm this huge equation like
do whatever you want with it and so my
videos are more like here's this huge
algorithm but like here's what you can
do with it favorite idol um my favorite
idol is probably Kanye West Tupac Shakur
and President Obama who else uh let's
see I just like like revolutionaries
people who like just don't they don't
they don't give a shit they just like
you know they have something to say and
they want to say it really loud so yeah
and also Ian's good fellow at open AI
because generative adversarial networks
are awesome and just like everybody who
works at you mind because that stuff is
awesome why Harambee died I don't know
Keanu or tensorflow tensorflow because
it has more support for it how easy is
it to find a remote ml job it's actually
really easy compared to other types of
jobs uh for someone new to ml Wood Khan
Academy cover the math you need
absolutely
I love Khan Academy and it kind of
counted me if you're watching this for
some reason you know contact me because
I want to get on that
Murphy's probably to test your elements
of statistical learning I would actually
not recommend reading a textbook because
for me whenever I read a textbook I'm
just like super bored I'm like oh my god
and by the end of it I was like okay I
learned a lot of like really I just feel
like like what do I do with all this
like I prefer like short form articles
long-form articles videos and
implementing things that's the best way
to learn for me is just to implement so
are are June I would just like go to
github search and machine learning and
just like start like recoding those
projects that you see another job to
earn more money I don't right now I do
this full-time hopefully it works out
our Python 100% Python 4 ml and data
analysis are is like Python is just way
more modular it has way more support I
did I saw that YouTube 8 million ID
saying today my plans for the future I
want to be the Bill Nye of computer
science I want to be like the guy who
like people look at and they're like
that guy inspired me I want to do
machine learning I just want to get
everybody to do machine learning I think
it's the future I think that's
everything will be is too is everything
is going to like involve machine
learning in some way if you don't know
Python uh and you want to do see no dude
you should totally like Python is better
than C because C involves like you know
dealing with memory and like deadlocks
if you're if you're new to if you're new
to programming you should definitely
start off with Python uh how did I learn
coding I started to uh what did I do oh
I had this idea okay so I remember it in
college the way I learn coding was
everybody went home for this for winter
break and I stayed in cells like two
weeks and I was like what are you doing
and I stayed in for winter break I had
this idea for that this iPhone app or
you could just like wave your phone like
a conductors baton and it would change
the tempo of the music in real time and
so just like I got to do this so just
based on the idea I like force myself to
learn iOS and like it was super hard but
like by the end like when I finally
started moving the phone and the the
tenth book started changing I had to
learn about fast Fourier transforms I
had to learn about audio engineering but
in a bit it actually worked
the app was kind of bad but like it
worked and so that success like kept me
going and it kept it make it made me
want to do more and more
thanks for saying you love my channel
nodejs is better for machine learning I
guess it is yeah the Udacity course
search deep learning Udacity Google it's
going to be the first link my favorite
ml podcast would be a or blog would be
um hmm I'm not sure if there's so many I
just like the machine learning subreddit
that's where most of my stuff comes from
uh build apps in real time okay cool
yeah sure C is faster for sure um but I
guess um with Python you can wrap
seashells and then call them in Python
so you don't actually have to write the
C so there see happening under the hood
but like python is great for like
understanding things the best tutorial
for tensorflow
are my videos so far I
also Google's official ones on their
website ah
so one of my sources for learning about
machine learning this the machine
learning subreddit the what else is
there
there's hacker news there's the
futurology subreddit there's I follow a
few machine learning researchers on
Twitter so like board Yamla Coon which
is not real but it's actually hilarious
and there's one more apologies
srinivasan on twitter all of the guys
who work at Andreessen Horowitz are all
like really on the ball when it comes to
what's next I did do the Andrew on
course I didn't remember much of it so
like I would just like that's like par
reason I started my channel uh because I
just thought it was boring I do it work
yes I'm worried about advanced AI and I
think the best way to solve that is to
make sure it's democratized and
everybody has access to it and I think
that we should a I should augment
ourselves so we'll have like a neural
lace in our brain or some kind of chip
or something or even you know with the
iPhone 7 you just put it in your ear you
can start talking to Siri so it's going
to be less and less weird to talk to
your phone but I think AI can augment us
and make us better rather than it being
like a separate thing like a god that it
just like controls us it should make us
gods so that's what I think will help us
not have an evil a oh okay we're going
to start building the game bot in 30
seconds here we go I'm going to answer
any last questions favorite place in the
world go hiking is a Yosemite how do I
do I keep myself fit yes I go to the gym
yes I would collaborate with ml people
game theory and AI that's a long
question if you want to become AI
researcher start learning uh just go to
github and like uh go to the tensorflow
a github repository to the model section
and try to re-implement all of those
models okay so here we go we're going to
start building this this bot uh yes I
like drugs from time to time okay here
we go
we're going to start we're going to
start building this thing okay so I'm
going to start share
in my screen I just have to just get on
this so the first thing I'm going to do
is share my screen okay here we go
desktop
all right and Here I am I'm going to
show up here okay here we go all right
so I'm going to go sublime I'd say I'm
going to say I'm going to make a
directory and I'm going to sit let me
make sure that I'm I'm still on here
okay
here we go I'm going to minimum I'm
going to minimize this so I don't have
to okay there we go all right and this
is going to be minimized make sure it's
all good I'll put this up here and we're
going to get started in a second it's
laggy right it's laggy but you guys can
still hear me right like even though
it's laggy okay so here we go I'm going
to say make directory I'm going to make
a new directory so I'm going to start
this this bot I'm going to say make
directory test 1 test 2 test 1 oh and
did that already just make directory
test - ok so TD test 2 now I'm in my cat
C directory right ok here we go
the first thing I want to do okay make
sure it's all but there's so many
windows open right now holy shoot audio
is not laggy at least ok cool green CL
is for real hackers well I like whatever
I like okay so here we go so first thing
we do is clone a gym so the gym
repository is the B the reinforcement
learning library created by it open a ah
we're going to clone it into this Oh
increase the font size good call thank
you thank you
how do we go into a boom boom ooh boo
boo boo boo boo boo right how's that
okay we increase the font size I'm in
the corner over here boom make sure it's
all good okay so now that Jim is in here
we're going to CD into Jim
the gym is like a training gym for hey I
it makes it better and better over time
and we want to install everything so
we're going to use pip our Python module
to install literally everything okay so
it's literally going to install all of
our dependencies for Python for gin
and that's it that's all so once one
this is done we're ready to go okay so
now that we've installed Jim we're going
to run our first environment okay
so let's so I'm going to use sublime
sublime is my text editor of choice and
when it's a test run pie so it's going
to open that up in sublime so I'm going
to bring that down here okay and
here we go here we go here we go so
first thing we do is I'm going to import
Jim okay that's that's the environment
and then I'm going to create an
environment okay so it's going to be Jim
Jim yeah this is going to be on the
channel at the end of the transmission
you're going to be able to view it
afterwards so yeah anyway so so so this
is the first step is to initialize the
environment what are we going to train
the agent in okay so that's right so
it's kind of its kind of not HD right
now guys and sorry about this my first
live stream but it's going to be better
next time if I do this next time I
probably will because this is kind of
fun
our increased font size good call good
call good call thank you thank you thank
you here we go I'm going to increase the
font size
let's see boom boom boom boom boom boom
okay that's huge all right so we're
gonna initialize our environment it's
going to be card pull so the car pool
environment is just like a steak right
so the car pool game is like a stick and
it's just trying to balance as as a box
move okay I don't use an IDE because I
don't have time for that it's just
bloated I just want a simple you know
Python just super fast you run a script
that's it okay so here we go so we got
card pole right and we're going to reset
the environment which means like it just
means like let's get started just means
like initialize like the environment is
ready to go so we're going to run this
for a thousand time steps okay so we're
going to say what thousand time steps
and for each time step we want to render
the environment so we're going to say
okay so then we're going to be able to
view it okay so we're going to say take
a step and what step means we're going
to take a random step so that means the
agent in our case it's going to be the
card Cole is going to move in a random
direction every
and so the the method of doing this is
action space sample so that's the method
that says pick a random action okay okay
so let's just see how that how that
works we're going to run back just that
script that's it so I'm going to say
Python test run PI boom what happens Oh
Python test run PI invalid syntax what
the hell okay here we go oh right yeah
that thing cool let's run this little
module name request oh my god here we go
okay so we're going to make sure we have
virtual environment we'll create a
virtual environment right all right
thanks guys
okay so we have a virtual environment
we're going to sorts our virtual
environment which means that we can see
what's going down here okay and we're
going to say pip install requests okay
and so then we're going to run it again
oh and num Potts oh oh I got to
reinstall like that Shh boo boo boo boo
I'm going to reinstall Jim one more time
I forgot you have to you have to redo
your environment okay first you have to
create a virtual environment so that
your dependencies aren't all over the
place I always create a virtual
environment for every repository that I
make okay so once this is done we're
going to run this code this is the code
one more time we create the environment
a thousand times steps render at every
time step and then take a random step
that's all it does
hey thanks for coming to the party
Anthony it's all good here we go test
run let's see it boom okay that's it
that's all I did it just ran for a
thousand time steps and then do it
didn't learn anything now we're going to
add a little bit of logic to this okay
so the great thing about Jim is it is a
reinforcement learning library okay it's
it's all about learning with through
trial and error the agent is going to
get better and better over time okay
Arjuna virtual environment is kind of
like
uh it's it's it's it's like creating a
container where you say okay I don't
want to have to deal with anything else
on the on my operating system I don't
want to have to mess with any other
dependencies I just want to be in this
like empty box and in this empty box I'm
going to reinstall all of my oh man
these comments are hilarious I'm just
going to install all the dependencies I
need for this specific repository I do
it every time I have a new repository
okay so let's so let's make this thing
smarter let's add some actual machine
learning in here okay so we're going to
keep we're going to keep um this car
pool environment okay and I'm going to
I'm going to say for our number of
episodes I'm going to say for a number
of episodes let's say I episode each
episode is like if you know your cart
falls over so I'm going to say for a
number of episode in the range of 20 so
for 20 episodes so for 20 episodes I'm
going to get it my observation from my
environment an observation is different
depending on whatever your your
environment is Jim has like a thousand
environments you can have pac-man you
could have a bunch of Atari games you
could have even 3d games doom so we're
just using card pull that's simple for
right now so I'm gonna say okay so for
this observation we're going to reset
which means I just get that first
observation okay and then we're going to
say I want a hundred time steps for
every 100 time steps for every episode
okay so we're going to render this
environment at every time step and we're
going to print out whatever we're
observing in our caves in the case of
the card poll it's going to be the an
array of velocities of where the car
pole is moving we haven't done any
machine learning yet I'm just rendering
this thing as it moves okay but we're
about to this is the machine learning
part okay I'm going to take an action
okay and this action is going to be a
random it's going to be a random action
and arrange 100 okay T and range 100 yes
oh yes thank you as you as II yeah yeah
yeah good call all right cool
I'm not running on a GPU I'm running on
a CPU on a MacBook okay so here we go so
for that action we want to take a step
and a step is going to complete the
agent environment Luke okay I'm going to
explain that in a second but we're going
to get back an observation so we're
going to get back an observation a
reward done info and we'll take a step
so what's happening here is a step
function completes an action and it
returns back four variables the
observation is what it sees the reward
is it's different depending on whatever
environment you're in in our case it's
it's that the pole is still standing up
so it's going to be a set of velocities
done is just a boolean like did we die
or not and info is a bunch of
Diagnostics that's it that one line is
the reinforcement learning that's
happening here okay so we're going to
say like okay so if if we're done if
we're done then just print out okay
episode is finished Windows is not life
episode is finished Windows is bad sorry
Windows sucks after time steps after
whatever number of time steps okay now
and then we're going to say break we're
going to say break okay so let's run
that okay so this is the actual machine
learning it to the reinforcement
learning see agent environment loop all
right so let's run this baby boom so
what it's printing are the velocities
like as it's moving it's learning to get
better every time okay and so the
episode is finished so that that trains
our agent and we can save those weights
over time let's see let me answer what I
miss the old hello world it's Roger
hello world it's Suraj there you there's
there it is okay what does step actually
do step completes an action step is a
function that takes an action and
actually implements
in the in the rendered environment I
make a bit for synthetic gradients paper
that yo I really want to make one I have
been waiting to make one on that paper
that paper is so dope I when I read that
paper I was like oh my god
backpropagation is not a thing anymore
this is amazing so yes I will make one
on that Lubuntu is life a true word word
is there a way to run tensorflow
and open AI on Windows great question I
know there's a way to run tensorflow
I'm not sure about open AI okay so that
was the that was a simple problem now
I'm going to let's see I want to do
something a little more complicated so
I'm going to say we're going to we're
going to do something a little more
complex so we're going to do the same
thing in the carpool environment but
we're going to use something called hill
climbing as a policy okay so hill
climbing o climbing means we're going
and not just do it not just try a bunch
of random steps but update our weights
by
making sure that hi Nico uh yeah na
alright you guys are getting obsessed
with weed now like all right just chill
you know I don't say okay here we go
we're sure we're focused right now right
okay here we go we got to be focused
let's let's focus here
all right so hill climbing is a
technique where we say initialize
weights randomly and we're going to
initialize weights randomly and then and
then if if the weights are good if what
the reward is like a good thing then we
want to save those weights so we so we
incorporate memory into this as well
it's not just randomly trying things we
use our memory just like our you know
our brains use memory as well so utilize
memory to save good weights yeah focus
exactly uh both are do we know yes there
is the Japanese cucumber farmer did
something like that if you go to github
and type in tensorflow Arduino I promise
you 100% you will find at least three
repositories ok so here we go
so right so Oh
also I want to import numpy because I'm
about to do some some math magic in here
okay here we go
won't this be stuck at on local maximums
no okay so so first thing I'm going to
do is define a run episode okay and let
say the two primitives for that are
going to be the environment and a
parameters the parameters are going to
be the weights okay um so this hold on a
second okay so this isn't this is going
to be art our implementation of the
Asian environment loop it's going to
take our agent from start to finish and
it's going to result in some reward
value depending on whatever action and
we're going to initialize it after we've
initialized our environment okay so this
is a function that we're going to
initialize after we digitize our
environment okay so um will the stream
be available to watch tomorrow yes it
will be and I'm going to end it in like
ten minutes okay so that's because that
because I've got some technical writing
to do and I've got other stuff to do for
the channel okay here we go
so first off first things first okay
we're going to get okay burn sink trips
we're going to get our observation like
we always do
alright that's the first thing we do in
an episode and then we're going to make
this total reward variable yeah I could
test it on Mario I will remember that
for next time
so for 200 time steps we're going to do
this okay so for in the range of 200
we're going to render our you can test
it on literally any game on a yes yes
I'm going to upload the sample code
Carlos absolutely absolutely I'm going
to put it in the description for this
video okay so we're going to say okay go
ahead and render and render our
environment like we always do okay so
now we're going to initialize random
weight vectors okay so I'm going to say
so I'm going to say take an action okay
and if it's zero so actually I'm just
kind of like type
how because like it's hard to do like a
million things at once or now let me
just type this out and I'm going to then
explain it in a second
okay it's less than zero else what okay
so what's happening here is I'm
initializing random weight vectors as
parameters and multiplying by respective
observation and I'm going to use matrix
multiplication to sum the products and
if the total is less than zero then we
move left else we move right so what
this is doing is it's randomly
initializing a set of weight vectors to
move the pole left or right okay that's
all it's doing left or right okay let me
see what the comments up here are let's
see what's the difference between range
and X range uh so in so rank returns a
list and X range returns an X ray object
which is kind of like an iterator and
generates numbers on demand um I think
like I it's weird because in Python
three range does what X range used to do
and X range doesn't exist so if you want
to write code that will run on both
Python 2 and Python 3 you shouldn't use
X range so I'm just being weird so like
don't just like use range like yeah
exactly mighty magic yeah exactly
so um can you upload will you be
broadcast this video later yes okay um
let me see my still okay cool
everybody's in here but it's good ok so
here we go where were we so yeah I've
I've initialized random weights
neutralized random weights okay and then
we got this we can finish this guy's in
eight minutes or we got eight minutes
left and so I'll also try to squeeze in
time for more questions which you guys
can also ask cause I'm doing this okay
here we go
so now I want to get my observation and
my reward and done and info and that's
going to happen as I take the step
function at all with the environment
step and it's it would complete the
action okay and so now I'm going to
increase my reward so it's a total
reward that variable that I initialized
for is going to get whatever it's in my
reward now so if it's done so that means
if that pull tipped too far if done then
break right and then return the total
reward all right so there's that so that
is our run episode function okay I read
it yes exactly exactly so now um so now
I'm going to do the actual train
function okay here we go so training
time let's train this baby let's train
this baby what the observation the
observation in this case is a the it's
an array of full of velocity values so
it's a set of vectors of where the pole
is in space what model does this
actually use the model is a it's it's a
type of reinforcement learning that is
called is it's the agent environment
loop Thank You Omar I will definitely do
more of these it seems that you know
depending on you know how you guys like
this which it seems like this is this is
good this is kind of fun this is crazy
this is like a rush right now I'm like
I've never done this before so I feel
like I feel like I'm in the zone like
you know what I'm saying okay here we go
so um okay here we go so so now it's
time to initialize our environments I'm
going to say Jim dot make cart Pole v-0
alright and so now I've made my
environment and now I'm going to say
okay episodes her update equals five so
that's how many episodes I want and so
now I'm going to define a function
called noise scale so noise scaling is
the is it's a value that I'm going to
multiply my weights by every time so
that they get better over time so this
is this is this is the actual hell
climbing policy so that's the name of
the policy it's hill climbing which
answers your question of mighty magic
its hill climbing that's the type of
policy
the environment line from above uh let's
see
the environment line from above yo you
know what I do need to delete that thank
you for thank you for catching that up
his Shawn thank you
alright here we go so noise scaling
alright we did that total reward noise
scaling where it was I where am i based
um I will fix all that I am in San
Francisco California
alright alright here we go so now I'm
going to sit create my parameters why is
this kind of like not like oh thank you
uh blows air okay so now I'm going to
randomly initialize vectors of weights
that parameters equals numpy to random
number and emmm and four times two minus
one Stetson initialized at set of
weights between negative 1 and 1 ok
that's just what that is so then I'm
going to say bet reward equals zero and
that's the reward that I'm going to save
later ok so I'm going to run this for
2000 episodes
ok that's what I want to run this for
I'm going to say in the range of of 2000
run this ish okay it's noise scaling
like the learning rate in a way yes yes
it is that's that that's a great
question it is it is just like that it
is a is it is something that that
improves your training over time just
like the learning rate does okay so new
params equals parameters plus numpy it
up and um and so this is going to be the
same thing that that set of initialized
weights between negative 1 and 1 minus 1
and this is where this is where the
noise scaling goes I'm going to say
times noise scaling this is the machine
learning part right here okay so it's
going to update those wait that new set
of parameters every time okay first
return not in a good place
oh yeah you're right you're totally
right thank you thank you thank you
thank you for that
Andre us okay here we go here we go um
all right so now so now okay
reward it's run episode we're going to
get that reward we're going to use our
run episode function okay that's going
to complete the agent environment loop
and we're going to say environments as
the parameter the one we just
initialized and those that new set of
parameters that we initialize okay
that's that those are the two parameters
that we're going to use so that's gonna
be a reward and now we're going to print
that we're going to say print uh we're
going to print reward reward um blah and
then best and then we're going to say
reward then best reward so that's going
to show what's the difference right okay
here we go
here we go I have one more like little
last thing okay so we're going to say if
the reward if the reward improves with
noise we want to update the reward and
keep the weights so if reward it's
greater than best reward then that's
reward will then become whatever the
reward was and parameters it's going to
be get what the new parameters are and
then finally if the upper threshold of
200 is reached which we want to set for
the reward then we break that's it okay
um so there's that um where else are we
I'm struggling to like see everything
here okay so then okay so that's it
that's it so now we're going to just run
this we're going to say train we're
going to run our train function with
submit equals false because we don't
want to submit it anywhere and we're
going to say print okay so let's just
run that shit
let is could you reduce noise over time
we could we could reduce it over time I
think for this simple example were kind
of keep it static but there's a bunch of
things yeah no absolutely you could
reduce it over time you can try
different you can you can make sure your
weights aren't a random you could try up
you could try weights that are synthetic
I mean you could look at different
policies that's the fun of it like open
AI has totally gamified this whole
process so let's run that Oh fun okay
sorry
uh yeah oh my god okay uh let's see
what's going on here uh what the okay
global name observations is not defined
where is that what line is that on
global name observations is not defined
that is underlined seventeen let's see
that guys what's going on here well will
name observation Oh observations is not
defined observation there we go run that
oh boom boom okay so yeah it's doing
it's doing hill climbing it's doing hero
climbing it's doing here climbing whoa
okay cool okay I'm really happy that
this is working okay where's the next
for the four so it is trying a bunch of
random weights and it is multiplying
that noise scaling constant that we had
before every time if the weights are
better it's remembering those weights
instead of just continuously trying
other new random waves and that way it
gets better and better over time okay
this is going to run for probably like
isn't it so good when it works are the
way it's part of a neural network that
is a great question mighty magic magic
it is it is part of a neural network
okay it's it's a one layer neural
network so the best way is eleven and
the old one is so the so the best one is
on the right and the old one is on the
left and hopefully it finishes soon yes
it is it is like a genetic algorithm is
there a way to make a deeper or change
the size of hidden layers not with just
Jim we we have to integrate tensorflow
which I can do in a few
video actually I think tensorflow and
and Jim go together very well uh but
yeah so so yeah so so that's that's it
training so now while I trains I'm going
to answer I'm going to give it five more
minutes to answer up any other questions
so I'll just like just like go for like
just like whatever you want I will
reveal all just go for it you know what
I mean if you guys have any questions
and stuff so let me just like fullscreen
this baby so there's less lag less lag
alright um stop screen sharing okay I
think there's less lag now right okay
though
hi hi hi so there's less lag can you
show the show well um the code wallets
running as well uh yes I can show the
code in a second you know I'm just going
to link to it later what is the best
Linux distro to get started intense to
flow a bun - do you do more of these if
you have time I totally will
how many years until I Jarvis like AI is
real I would I would say a decade from
now at a decade - from now seven to ten
years where to start learning ml like
full time now appearing a little timid
shit oh my god I love it you guys are so
funny
where does our learning ml my channel
start from video one go all the way
through implement all the code
associated with my videos thanks Tyler
you are awesome I told it very well in
two months for a gig yo uh watch my
videos and also go to the machine
learning subreddit go to go to it every
single day I made it a habit of mine I
wake up go to machine learning subreddit
look through everything
people are super harsh in the machine
learning subreddit by the way like they
will just tear everything apart
usually like skeptical people who are
like super smart or like that anyway if
you meet one of these ml researchers
don't just like these hyper critical
people just like tear you down with
their eyes cuz you know they're just
like you know like scientists right who
is hiring for these skills absolutely
everybody
in fact the nanodegree guy at Udacity
who I'm working with
oops I just revealed that by the way
that self-driving car course like I'm an
assistant instructor for that awesome
just because the guy saw my videos but
of that guy was like even if we had a
dude si is awesome he's like even if our
course was full we would still have like
less than 1% of the need for
self-driving car engineers so that so
who is hiring for these skills literally
like everybody will soon start hiring
for the skills like right now there's
like tech companies and not 10 companies
but soon every single company is going
to be a tech company ah awesome Niko
you're awesome um will you organize
meetups as well
I actually having my first talk tomorrow
at the write the docs meetup in San
Francisco right the docs
cuz you asked me like how I do all this
stuff but yes I want to organize meetups
definitely shoot me an email with some
ideas like I'm open to it cool how much
math you think is needed to do real
research yo you you definitely need some
actual like real like cutting-edge stuff
you then you then you got a know some
math I would say like linear algebra
statistics and um game theory and also
just like a like quantum physics that
has nothing to do with machine learning
but like quantum physics quantum
mechanics that stuff is just like it
puts you in this way of thinking that I
think can be applied to machine learning
uh yo I would love to come to Brazil at
some point hi graph theory exactly yeah
exactly Amazon is playing shit tons of
gold and I would love to do yes I'm
working with Sebastian through uh and
yeah Wow - everything cool Wow
so this was a trip alright guys well one
more question then I'm out whoever
whichever question I see first let's see
just go for it just let's see it I'm
done ready for this yes any time how
would you use ml to look at your video
for example and see when the video
change from just your face to the view
off your coat
ah girls do think ml is sexy because we
are going to make it sexy right let's
make it sexy because we're awesome
awesome do I own bitcoins I do I
actually used to be super obsessed with
bitcoins if you guys look at my older
videos you'll see like this Bitcoin
music video I made is actually pretty
hilarious but I definitely want to make
a machine-learning music videos too and
that's like more you know production
heavy because like once you get a 10,000
subscribers on YouTube and they let you
use their studio space in LA which I'd
like to use for a music video I just
don't have time because I'm like doing
this full-time
am I still a researcher or working for
any company I'm not working for anybody
I am working for me and then clients
approached me bank and I no one can buy
me out
except for deep mine so yes deep mind if
you're watching you can totally buy me
out I will do anything for you
a two pocket machine learning video
would be awesome do I program in other
languages yeah I mean like when I worked
at olio like you I had to write
documentation in like ten different
languages and like ah but I just prefer
Python because it's just simple like you
know like this stuff is just like I just
want to get right to the the good stuff
the logic the algorithms that's what
matters is not the syntax stuff just
pick some language and just go for like
you know and I would say it's Python um
okay deep learning is not going away
anytime soon it's going to evolve into
something better in my opinion we're
going to start getting into one-shot
learning like that's what's going to
come after deep learning where you don't
need like a huge amount of example to
train and things and what am i doing in
my free time I what do I do in my free
time yeah that's a good question
so besides doing this I I've recently
started taking a like Bruce Lee classes
to kind of be like Bruce Willy I a
freestyle rap um and I hang it with my
friends and how did object to see break
my heart it really just it just when I
saw Swift I was like yo you know why did
I okay I'll tell you how objective-c
broke my heart I was like uh splitting
strings live like like in like four or
five lines of code and objective-c and I
was like yo this takes so long to do
like I just need like to do it in Swift
you just do it in one line in Python
it's just in one line Objective C doing
anything yes jeet kune do-- yes
that is exactly what I'm doing I'm
excited cuz I met this dude he's like he
is awesome why don't I do a freestyle
rap right now and memorize my ML lyrics
I will do a quick wrap here we go
I mean I need a beat but like let's just
go for it here we go I'm just gonna free
stuff you I got backpropagation
I do it for this nation you guys see me
I'm like a hardcore patient yeah I'm
from the planet facia I came out here
and take you synthetics out like a
Geisha from Japan with all this stuff
all around it's like I'm Peter Pan a fly
in the clouds okay that was it anyway uh
yo BAE's is cool I'm not saying anything
bad about BAE's like vases bass is
pretty cool a Bitcoin trading bot that
would be a lot of yo okay
on corn at AI that's actually my next
video
uh I mean nope thank you ah
recommendation systems I actually did
don't build a recommender system that's
machine learning for hackers number four
check that out I got to redo that video
cuz I used to talk way too fast and and
I know Anthony I know that's that was
amazing was okay none okay um yo yo yo
yo
okay Meg deechi let me like I need to
understand this question okay thank you
I love Tunisia as well I want to go
there eventually when I go there okay
kenta test flow yes I mean can it work
with a video stream I guess so
I guess I could work with a video stream
I don't know exactly what you mean by
that like do you mean like training it
on like video frames why no windows
because I don't know like I switched
over to unix-based systems and I never
went back and I know like you know what
Satya Nadella it's tough Microsoft is
trying to be all cool and stuff and like
you know implement bash like
terminal but um I just
also I switch to an Android phone
because like Google now is way better
than Siri I think comma AI will be
successful 100% they're going to be
bought out by probably Google alright
guys so that's it for now I'm gonna make
more of these okay thank you for
watching I think this was a success I'm
gonna hit stop broadcast and uh thank
you all for being here and you're going
to be able to see links to to a bunch of
things alright so thank you guys for
watching
Oh for now
let's say for now I've got to go to the
bathroom to do things uh so thanks for
watching thank you bye MA love you guys
okay bye alright</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>