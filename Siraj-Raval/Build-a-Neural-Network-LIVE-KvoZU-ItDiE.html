<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Build a Neural Network (LIVE) | Coder Coacher - Coaching Coders</title><meta content="Build a Neural Network (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Build a Neural Network (LIVE)</b></h2><h5 class="post__date">2016-10-12</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KvoZU-ItDiE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello can anyone hear me
who can hear me I am live I know I'm
late but can you hear me is the question
I am talking I am talking I'm not sure
if anybody oh my gosh holy that was
loud yeah yeah you guys hear me okay
here we go hi everybody hello world is
Suraj and we're today we're going to
build a neural network okay it's going
to be a special type of neural network
okay awesome
it's a special type of neural network I
that is called an L STM neural network
it's like probably the most advanced
neural network I could think of but to
do it an easy way so this is going to be
a challenge but it's gonna be super fun
we're going to generate city names using
this in Python we're going to generate
city names just random city names we're
going to train it on a list of every US
city in every single city in the US and
then it's going to generate new city
names from scratch yes - long short-term
memory um what's Matias a neural network
is an algorithm that replicates neurons
in the brain and you can train it to
learn things it's a learning algorithm
okay so we're just going to get right
into well I'm going to do five minutes
QA and then we can just get started okay
attach the different types of neural
networks okay so so there's the regular
type of neural network which is just fee
forward in a feed-forward neural network
data just flows one way through the
through from the beginning from the
input layer all the way to the output
layer that's a feed-forward neural
network and those things are good for
predicting the next number in a sequence
of numbers I'm going to build this using
tenth TF learn yes and tensorflow it's
it's a library on top of tensor flow you
guys going to you're gonna love this a
recurrent neural network is a type of
neural
or where the data flows not just through
it but then back again
so it's recurrent it goes back and forth
through that and that's good for a
memory so anytime you need to remember
maybe a sequence of music or sequence of
text or poetry if you want to generate
something some new type of text that's
what recurrent networks are good for I
can build a neural network from scratch
it's possible using numpy the scientific
computing library and then one more type
of neural network and the one we're
going to do in this video is called an
LS TM neural network which is a type of
recurrent Network it's called long
short-term memory so it can remember
things from way back in the sequence of
data so it's like oh it remembers
everything which is what we're going to
need for the city because there's so
many different cities for this city
generation let me answer a few more
questions I've got about three more
minutes I want to get right into it this
time how did you want to build neural
networks by just taking time and going
through the machine learning subreddit
going through github and just
downloading a bunch of neural networks
from github repositories just playing
around with them seeing how they work
comparing them comparing different
library implementations of it and then
building my own from scratch using them
plot where can you get tensorflow
google comes from just Google tensorflow
is first like numpy is a pain build it
from scratch I'm gonna um build an LS TM
from close to scratch is c-sharp good
for neural networks um there's the
microsoft c NT k library which i don't
really like that much because I don't
like Microsoft I mean no you know you
don't know anyway I'm not gonna
apologize all right let all right we're
going to get to the tutorial um yes
definitely more powerful than hidden
Markov models I mean hidden Markov
models were kind of the precursor to
deep learning this old craze going on
with deep learning right now deep
learning kind of makes hidden Markov
models not as not as relevant anymore
kind of design and build a dataset you
just have to how do you design and build
a dataset I mean you can just create an
Excel spreadsheet and then for the X
column you know like put like number of
times that I've you know been laid and
then yes-no yes-no for every day or
something
there you go there's your dataset CSV
and Python can read CSV files very
easily right now I'm in San Francisco
the goal of this neural network is to
generate a city names from scratch like
new city names we're going to train it
on city names it's going to generate new
city names ok so I'm just going to get
right into it
here we go let's see screen share I
would recommend my videos to get started
start from machine learning for hackers
number one screen share so I'm gonna go
to the desktop okay and holy that's
a lot of alright so I'm going to
move this and it's going to show me and
we're going to make this bigger so I'm
going to be in the corner and you guys
your text I'm going to put right up here
so I can look at it your chats while I
code this thing ok um ah ok
apart from tensorflow and python yes
there are dependencies I'm going to be
showing you guys which dependencies
we're going to use let me make sure that
everything is working well here ok we
make sure everything's working well make
sure my text editor is big nice and big
text editor right that's what we want
help with did that go all
right there we go I'm gonna make sure
everything's nice and big all of nice
big text is that um is that good and big
for you guys is that readable right here
that's this level umm this is good right
alright we're just going to get started
and if anybody says
saying women this is going to be
probably 30 minutes I'll make it bigger
okay
okay how big let's dig right all right
here we go
a big bigger okay that's as big as we're
gonna go guys okay let's get started
oh yeah okay here we go to get the
dead the dead dead uh okay so first
things first we're going to import our
dependencies okay let me um bring up my
notes for a second so I make sure that
this is the right okay so that it
it uh and we're going to build this in
Python and it's going to be made of
silly windows up there OSX for a
bunch of for deep learning I would say
good luck to I know I'm on OSX polite
okay here we go so we're going to start
off by importing the first module this
is going to be called future so the
future module is tor
it's the link between Python 2 and 3
it's a way for us to use Python 2 or 3
without there being any kind of version
errors between what we're over using so
I'm going say from future import
absolute import I'm going to have a
recording of the session for sure
division and the print function those
are that's and let me turn on Python
because right now it's in plain text so
Python go there we go there we go so
hold on this shit's big so those are our
those are our dependencies ok so we
haven't we have another one ok so the
next one is OS we're going to import OS
that allows us to have operating system
dependent functionality we're going to
use it to read in file paths which is
where our datasets going to be we're
going to read in our data set using this
which we're going to download in the
script okay so that's OS what else we
need to import 6 and we're going to
import something from 6 called moves so
let me just write this at the top right
 LS sorry for the language I
don't know I don't care no no no
apologies over LCM to generate city
names ok that's what this is
this whole thing okay so firm six the
important moves okay and so what that's
going to do six to another library for
like commonalities between different
Python versions and moves is we're going
to use that for the URL live module
which is how we're going to pull data
from the internet okay in a second so
what else we're going to import SSL
which is how we're going to long
short-term memory Network a long short
long short term memory nm to generate
city generated cities let's just say
generate cities okay so important SSL
that's going to let us connect to the
internet and then of course we're going
to import TF learn DF learn is going to
be our machine learning library that's
how we're going to do the TF learn we're
going to work with some operations for
our data so we're going to say from TF
learn 30 minutes exactly thank you from
fields learn that data utils work in
full screen work in full screen uh know
okay here we go
stop but so we're going to import
everything from the data utilities okay
um so okay that's those are all of our
dependencies TF learn that's those are
all of our dependencies that's it now
we're going to start coding okay so the
first thing we want to do is get our
data
so obviously step one retrieve the data
okay that's this is the data okay we're
going we're going to get our data okay
so so first things first we're going to
create the path for our data set and
we're going to call it US cities dot txt
okay that's central we're going to call
our our data set so if we don't have
that file already okay if we don't have
it we want to tell our machine that so
that's where the OS module is going to
come in we're in said if not OS the path
is file and then the path as the
argument the PF learn is a is a wrapper
on top of tensorflow that makes it a
little easier to use so it's great for
learning
okay so it's not really an add-on it's
just like if I were to write an entire
neural network maybe like a hundred
lines of neural network and tensorflow
and TF learn I could access that neural
network and maybe two lines of code and
it just says like access neural network
so it's like an M it's a layer of
abstraction on top of that complexity of
tensor form so the trade-off is you
don't get that you know fine grain you
know control over everything but the
good thing is it's easier to understand
it's more readable
Chara's is similar to TF learning and
that is also a it's a layer of
abstraction over tensor flow and theano
and a few other libraries okay so
retrieving the data so if so if we don't
have that in our file path we want to
create it right so we're going to say
we're going to create a context
caps-lock sense okay context that says
um create unverified Bridgette um - I'm
too soon into this can't make it from
scratch right now book next live stream
I will okay
but just follow on we're going to you're
going to you're gonna like this create
an unverified context what is that dude
that just initialize a bunch of key and
trucks managers and because we're going
to get data from a server in a second so
that's just some initialization stuff
okay let me um let me make this a little
smaller okay that's all just a little
smaller okay so now we're going to say
now we're going to retrieve the actual
we're going to retreat the actual data
so we're going to say we're going to use
the URL live module of moves to retrieve
our data and uh let's see URL live
module we're going to retrieve our data
and we're going to say request um URL
retrieve make computers from scratch
nice okay
one day I actually have before it's not
a big deal anybody can do it okay so oh
I will upload it I'm recording it so six
package is good for being a kind of
gateway between Python 2 and 3 so you
can write Python 2 code and it works on
Python 3 and vice versa ok and so here
is what we're going to retreat so this
is the link to the data set that we're
going to retreat I have this paper let
me I have this written down some words
I'm going to paste this in this is the
dataset ok it's a huge link it's a huge
link ok boom this whole thing that's our
US cities data set ok so I'm just going
to say get David set Oh
just like that make it a little smaller
okay so that's our data set
alright we've done that and we've
retrieved it and I want to save it to my
path and with my context equal to the
context I just created ok so boom that's
it that's something that's my data set
so now ok it's time to do some machine
learning on this stuff ok so it's going
to be on github it's going to be on
github don't worry man it is such a trip
to read comments and code and do it all
alive at the same time this is
crazy I love it though I love it I love
you guys you guys are awesome okay so
max length equals path type ode who
spotted that path - Xavier path typo oh
thank you you thank you that s okay so
max length so this is the max length we
want cities to be city named max length
we don't want them to the cities that we
generate to be um line breaks a good
idea thank you thank you for them so we
don't want our city names to be longer
than 20 characters we're going to set
this max length all right
I checked the type okay so mesm max
length and so now we're going to
vectorize our text ball okay so we're
going to take vectorize the text file
what does that mean well we have a bunch
of import typos I ignite I thank for
coming
okay so vectorizing a text file we have
a data set we want to vectorize it we
will only have a data set of words we
want to vectorize it so what does that
what does that mean I'm going to get
that typo in a second what does that
mean it means take all these words all
these thousands of words and find those
commonalities between those words and
make those abstractions of those
commonalities so if I have a set of
words like a raccoon squirrel pigeon and
dog the vector that would be created
from those eventually would be animal it
would it would be the specific word
animal but it would be a representation
you like a numerical representation that
that is all of those things okay
so it so that's what vectors are they
help us abstract huge syriza's series of
data into something that we can
manipulate later and we can use these
abstractions to generate new data so we
could use that animal abstraction that
to then generate a new animal like a
wolf okay that's the great thing about
abstractions Thank You Emerson okay so
let's let's make our vectors so our
vector is going to spit back are three
things we're going to call it X Y and a
charge dictionary so it's going to let
me just write let me just write this out
okay so it's going to be called a text
file - semi redundant sequences okay
that's the mess that's the function that
TF learn provides and it's going to
create vectors for us and it's going to
take arguments the arguments is going to
take is the path so where we are - where
we are
where's the data set that we're making
vectors from so that's the path and then
the sequence the max length which we
defined earlier the Mac I won't say I
will post a repo at the end of the video
so where we are posting what is the max
length we already defined it right and
then finally redundant step equals three
okay so that means a how many times do
we want to do this we're just going to
say three times okay now make a line
break here okay so that's to vectorize
and so that so what what X Y and
uh it's going to be probably a 20 20
more minutes we'll see 20 more minutes
okay so what is this doing this is uh it
is creating vectors from our words and
it returns the inputs of targets and the
dictionary the inputs that's the words
the targets those are vectors and the
dictionary of those things okay I am NOT
on header all but I will admit I am on
coffee yo you need coffee to do this
this the stuff that I do full-time you
know what I mean I will admit it I love
I love coffee couldn't do it without
coffee okay anyway but I have never
tried at a row I've never tried at all I
have friends who have I've never tried
okay all right thanks I'll be touch Oh
just 20 minutes oh you want more I mean
I could go for he knows it okay the
neural network is going to generate city
names we have a data set of cities I was
going to generate new city names okay
this okay Keurig man shrooms I've
done shrooms before in fact the reason I
started the YouTube channel is because I
had a very a good shroom trip oh my god
he just admitted that he just admitted
that because he does get hot what anyone
thinks okay here we go
um here we go create an LST M wait yes
whoo - redundant steps equals three
means we're we're just going to go
through three sequences to make that
happen okay okay here we go here we go
here we go so now we're going to create
our LCM create LST n uh really Jorge
holy I love it I love it I
JavaScript
maybe someday yeah I mean eventually
hopefully more hey that you quit your
job to do something that you liked
because it's not like you're you just
became crazy anyway okay create
Colosseum let's do this so we're going
to create Alice TM we're going to call
it G okay we're going to call it G on
Udacity I want I am working with Udacity
on the self-driving car course oh my god
I just admitted that but it's going to
be awesome yeah you know that
self-driving car nanodegree I'm working
on that
wait I'm going to show you guys next
week okay next week I'm going to I'm
going down to Mountain View to meet with
a team and stuff it's gonna be crazy
they just saw my self-driving car in
five minute video and then they're like
oh you should work with us I'm like oh
my god
Sebastian through and it's you the guy
who like you know made Google X and
stuff anyway that's going to be exciting
okay here we go
so TF learn so we're going to create our
LS TM and create Ellis again we're going
to create layers okay we're just layer
by layer that's what the employed is
great for you can define its entire
layers in one line of code just like
layer layer layer layer lightly okay um
I don't care what the government thinks
come at me if the government is watching
and they think they're going to do
something as I did some drugs come at me
okay
come at me you can't you can't stop me
okay here we go so TF learned input data
okay we're going to save the shape and
so this is our input layer well this is
our input layer okay this is our input
layer so we're going to put the data in
so we're going to say the shape equals
um none Max lame I'm going to just come
in it I'm going to I'm going to talk
about what I'm doing a second so char ID
X okay car ID X so what is this doing
this is saying make our input layer and
this is the size of our input layer it's
going to be up to twenty characters and
I wrote input wrong did not wear input
data annoying okay so that's our input
layer and now we're going to create our
next layer on our next layer is an LST
Emily okay so TF learn LSD mg5 twelve
that's going to be the size of our
matrix Thank You ace ace I will I will
get better at this stuff to make it more
understandable
okay so return sequence equals true okay
so what is this this is the lsdm layer
so tell us ham layer is basically you've
got you've got 512 nodes in this layer
that's that 512 number a layer okay you
have 512 neurons or nodes in this site
it's a lot that's that's deep learning
that's the deep part okay you've got 512
of
um Thank You Omar I got this okay 512
layers and the LST M is basically long
short-term memory inside of each of
those neurons you've got little gateways
basically an LS TM was created recently
and basically anything that we we put it
up we throw any kind of data that we
throw an LS PMF usually LS EMS or what
works best to learn we're not sure why
they're the most they're the most
complicated complicated types of neural
networks out there but also they also
provides the best most performant
results okay so we've got four more
layers to create okay why 512 I mean
it's just it's one of those things where
it's just kind of become standard like
you know one guy did it and it working a
great result so let's just all do 512 I
mean I have two 513 to your right um
Peter you're right
so it's Peter Peter is right so it's not
it's not just what's in the layer it's
it's not just how many nodes are in the
alert it's how many layers but I guess
in terms of wide and deep learning it is
both look LSD means long short-term
memory network LLC are great for chat
box why are both variable names gee
because we're going to keep we're going
to keep using G we're going to keep
using G as we build our lives okay okay
uh we're going to keep using G because
we're building our LST M okay so now we
built that and now we're going to create
dropout okay so TF learn dropout okay
we're going to say G again we're going
to keep using G okay
so what does that mean what is dropped
out okay so how does it relate to
recurrent neural networks an LS camp is
a type of recurrent neural network so it
is a subset of a recurrent neural
network I'm not a part of the alphago
team yet but okay so um it's a type of
record so what is dropout when we are
training our neural network when we are
training our neural network okay data is
flowing through the neural network right
data is medium deciding : data is
flowing through our neural network and
when we train it sometimes we have
something called overfitting whether we
have something called overfitting and
overfitting is when
I'm running it only on a CPU not a GPU
overfitting its when the data when the
learned model is fit - well - only the
data set that we train and we can't
generalize it to new things so to
prevent overfitting there's a technique
called drop out drop out and would drop
out does is it randomly turns off some
nodes it randomly turns off nodes while
training so it doesn't go through the
same grooves you know like these grooves
that we create and then every time you
know neural pathways are kind of like
when you think a certain way and you get
older you have these grooves right and
so it's hard to break out of those
grooves that's kind of a rough analogy
but like drop out basically turns off
nodes so it has to find new groups every
time and what that does is it makes it
easier to generalize okay that's that's
as good my explanation is gonna get
Burnett so that's dropped out real great
on another lsdm layer okay I just kind
of fried my CPU I was going to pry my
CPU exactly uh okay so um Kiev learned
dropout so that was our dropout layer
we're going to create one more Alex key
M layer I'm going to send me five twelve
again and then we're going to add more
dropout because we want dropout it every
layer okay so another dropout
g5 twelve okay uh and then oh no sorry
dropout 0.5 oh by the way 0.5 when we
create dropout it's just a coefficient
it's just a measure of how random do we
want to get we could say point four
because eight point six Leonard I'm
going to get to that in a second okay
I'll be Sheikh I'll swing dropout one
more time so dropout is a way to
randomly turn off nodes in your neural
network as it trains and what this does
is it prevents overfit it prevents
overfitting and overfitting means your
your train model will work for new data
sets it's only going to work for the
data setting you train to make
predictions but you want to make
predictions of data that it hasn't seen
before and that's why we use dropout and
it's in and geoff hinton the guy was
like The Godfather neural Nets made it
and everyone's been batshit crazy about
it since okay
why did I write the last two lines twice
because we have multiple layers to this
LS TM it's not just one layer okay uh uh
M zero four eight one uh that's that's
good intuition but I it's I don't think
it's that I think it's like a it's a
it's a measure of it's just it's just a
coefficient and I think like later on
it's like it's changed in a different
way anyway I gotta keep going here okay
so so that's our dropout layer and then
what else is left what else is like we
have our last layer we're going to
create our last layer our fully
connected like our last layer okay so G
equals TF o TF learn dot um fully
connected okay G length the length of
the fully connected layer is going to be
the size of our dictionary and then
we're going to create our activation
function which is called softmax softmax
is a type of it's a type of logistic
regression it's a type of logistic
regression that is good for
classification which is what we're doing
we're classifying big sequences of text
and I'm going to generate new sequences
okay I'm going to draw the ship you know
what I'm going to show you guys a
visualization that second let me just uh
I'm gonna post Errol to github and
you're going to be able to watch this
later so just follow along right now be
interactive I'm going to watch what
you're saying and so okay so here we go
so that's it
we built our neural network that's all
okay we're done now we're done with that
now we're going to generate our actual
sequences okay so generates sittings
okay we're at that part right that
generates cities Park generate cities
okay so here we go we're going to
generate stage we're going to call this
generated file M um right we're going to
photo generate file and we're going to
Kiev learn sequence generator Kiev learn
has a sequence generator for us it's
made to generate these sequences for
such big fat okay well
a bit good to know the chat is not
frozen
is it a regression problem or a
classification problem this is a this is
a regression problem that uses
classification early on the end result
isn't classification it's using
classification early on to jet to
classify to is classifying words as
vectors first okay so stick with
generator why is G wait what is
important I'm going to play n at normal
hours of text summarization
why is G interpreted as five separate
layers when it's one variable being
overwritten because it's uh well it
we're adding layers to what already
exists is there a list of commands in TF
learn yes it's on the game okay so okay
so G Dictionary equal to R ID x and then
sequin okay and then sequence max length
or / max line excellent now not over it
and add it to its exactly um click
gradients equals 5.0 I'm gonna explain
this in a second let me just write this
out not a lot of space in the brain for
a lot okay there we go okay I kind of
generate new sequences I am
ahmud with yet how big is your source
data it's about 20 megabytes it's just a
list of every US city um and let's see
um okay so so what this is doing is
going to say generate those sequences
could have been our dictionary the max
length of 20 click the gradient at 5.0
that's just a standard number we're just
going to keep there it doesn't matter
that much
and the check point path model US cities
so this is going to save checkpoints as
the trains which means like if something
happens to my computer like you know I
download some porn and it destroys
everything it's going to have those
checkpoint save so the model next time I
start training it's going to
go from there build it from scratch and
Rico that would be so long but I will I
will do that later okay so here's our
last part the training part okay that's
it we have five more lines guys we have
five more lines okay stick with me here
so for I in range for it okay so now is
a training part we're going to say
create a seat I'm going to tell you a
seat in a second seed random sequence
from text file um half next one okay
let's see what does a seed do a seed
helps us start from the same point every
time when we generate new things so when
we're about to generate a bunch of city
names right and so if we start from the
same point that's what a seed does let's
start from the same point so that we
have a little bit more weight a little
bit more names are more similar than
they would be than they would otherwise
be okay let me just read more could you
please do a new line of TF learn fully
connected yes good call thank you okay
okay
so that's our C and now we're going to
fix our model our generated cities model
this is the this is this is the learning
part okay so so I'm going to take those
three inputs I'm going to say X is our
input data Y is what we've created with
our vectors our validation set is called
0.1 batch size 128 so now I'm defining
how much we're going to Train I'm just
going to say 128 for batch sides
how many epochs do I want an epoch is
like an episode and how many episode run
IP is what we're going to call this
thing we're going to call it US cities
okay this is best to drink the fit is
the Train okay until now so now we're
going to print a be test day we're going
to take a test day because we're going
to bring this terminal and we're going
to say print what else we're going to
print test print so now we're going to
print it generated we're going to put
the generated city's generate 30
temperature equals 1.2 sequence see
and then just keep we created okay so
that's it and maybe we can do this a few
times so then with different
temperatures what is temperatures mean
I'll pretend that in a second okay so
this time it's for the temperature of
1.0 by 40 um you can do more than 40 I
just don't have like a huge GPU so I'm
just like 40 is good enough for right
now I don't feel like training it for
longer okay so there that's it okay
that's it let's see um
okay the MDOT bit line okay mo save that
perfect end up in line um so MF it
basically is taking our what we've
generated from sequences from our
sequence generator at that model okay at
model and it is it is it it's taking the
training data and it's adding it to our
LST M so that's that's the actual
training bit do you make enough money
out of YouTube no the answer is no but I
won't be bought out unless you're
deepmind so it's all good how did you
choose the batch size it is in relation
to the dimensions or note of samples of
data it's not related I just randomly
chose 128 shouldn't it be G dot fit
what's M so that's a good question so M
is M is the the model but there's a
little bit of magic happening here as
you can see like those two things aren't
connected but the F'lar knows that
they're connected and yeah so let's just
let's just train this um okay let's see
what happens when we let me turn out
command line okay where are we where we
are I thought I mean we make this bigger
okay
make it big that's hell oh my god I have
two scenarios okay here we go
and what boom
okay oh my god okay oh okay so let
me answer some more questions how does I
do and I if you don't have to finally
don't have the library how do you do you
have to download the file and then what
is the loss function so loss function
helps us umm the loss function will help
us it's something we need to minimize as
we train the loss don't show you
something we need to minimize as we
train and it's basically a way for us to
measure how good our learning algorithm
is doing okay so I'm about to compile
this thing but I'm running out of time
so I'm going to see what is this error
let's see um it's going to be a lot of
 because the problem is that this
text was so big that I didn't I should
have been compiling and checking for
errors as I was going but it's okay it's
okay I'm just double-checking these does
anyone have a link I'm going to have a
link to this video when it is done and
right now I am going to print out what's
happening here let me go ahead and and
see no I want to purchase that okay
so right under my
boom okay training where is that
happening line 33 don't need that oh no
module name careful are you kids
okay I know I don't I don't register uh
yes I'm Indian and American both uh born
the UI's parents from India
uh no module negative learn okay
 in a second here um although like
on okay so now it's now it's uh it's
working okay so it's training on that
data what's happening it's training on
that data
and you can see that there's a bunch of
like a text here that's printing out
like vectorizing text text total length
distinct chars total sequences that we
didn't code when we never printed this
stuff we never did that okay
that's because TF learn is doing this
itself this is a lot of magic happening
with Tier four like these functions like
sequence generator right sequence
generator and then random sequence from
text file these are very high-level
functions okay bigger font okay alright
so this is going to take prop so let me
come over this is probably going to take
like uh probably 20 minutes to fully
train which we don't have time for so I
went ahead and I'm going to pause that
and so here's here's an example I I
compiled this beforehand okay so you can
see like what the temperature is that we
wrote what's happening these are new
cities that are that have been generated
they don't exist
they've been generated from the cities
that we already have like more wood and
you know CN so rocks
okay so stuff like that and if you want
to see the data set that we use for this
let me just take that thing I'm just
going to copy that data set yes I'm
going to ask me anything yet for sure
give me a second let me just take this
day to say and then
I'm going to put it into my browser to
you guys and see what it looks like I'm
going to paste it in and I'm going to
put it right here okay so take a look at
this this is the data set it's huge it's
every single US City okay to train on
these words okay so it's about 20
megabytes all right so now that's that's
that that's what we have time for today
I want to keep doing these live streams
I'm going to do a five-minute AMA before
ending so let me just stop screen
sharing and go to full screen for a
second okay I'm going to put this down
here so see what's going on all right
and I'm going to answer 5-minute
questions okay any questions okay okay
here we go five minutes so um I I want
to do a gluten bun too with Windows I'm
scared of losing data use parallels then
parallels is great for that parallels
downloads are parallels um thank you
what exactly is an epoch and epoch is
like an episode of training yeah so you
have like 20 epochs that means like 20
episodes of training
how many hidden nodes there were 512 in
this one draw the neural network great
idea um me do that in a second did I
study at university yeah I went to
Columbia University I studied computer
science there where is to start learning
machine Monique my channel start on
machine learning for hackers one go
through every single video up till now
how should I start learning just my
video okay so for movie lens data for
recommendation engine I would recommend
using tangent flow a you would need a
deep neural network there's a type of
recommendation system called a
collaborative filtering system if you go
to github and you type in TF - re comm
is a great library for that an image
recognition application see my video
called crayon the image classifier and
intention flow in five minutes I did
that um when TF learned you can you can
specify the CPU or GPU using one of the
parameters there's a method for that if
you search CPU or GPU tensorflow in
google it's going to be the second link
on stackoverflow acting any book you can
recommend for a python newbie it's
called learn Python the hard way it's
called learn
learn Python the hard way it's the best
Python book you could read okay um what
area to write your thesis on tensorflow
I would say uh what's hot right now
probably hmm
one shop learning with tensorflow
one-shot learning and I have a video on
that so you search my channel one shot
learning um let's see
implement data compression and noise
reduction you can do that using an auto
encoder I have a video on that called
build an auto encoder in five minutes
can you do a video classification model
Carlos that is a great idea I don't
think I've done that yet so that that'll
be cool how cool would it be to generate
video like random video so you train it
on a movie and then it generates new
scenes I that didn't exist so like
real-life scenes but then is output that
we promised her do I do YouTube
full-time yes I'm a full-time youtuber
okay um you're really interested in
theoretical CS um I'm not sure if I get
in mathematics or computer science go
for computer science that way you learn
in the applied mathematics for computer
science hi Omar love you thank you uh
how would you do it with Ganz yes yes
one yes I'm India how do you do um uh
okay um anyone can be a data scientist
that's why new series is about and
because you guys are here alive I'm
going to tell you what my next video is
about I'm still writing the script but
it's coming out in two days it's called
it's using Twitter for sentiment
analysis so we're going to be mining
Twitter data and we're going to do
sentiment analysis that I know my hair
is less crazy today right it's less
crazy okay
why are Indians good at CS I you know
what it is I think it's just like your
parents just growing up or just like
study study study education education
and and make money and that's all like
computer science really uh you're
amazing George sure learn Python if I
already know Java
Plus mr. Bain is absolutely yeah um
Thank You Gia uh Udacity do the machine
learning nano degree not that data
analyst well exactly it's easy to learn
if you know can we make a peer-to-peer
neural network yo I never even thought
about that
the answer to life that's a what would
that even look like that's that's that's
a good question um anyway America people
are lazy well we're not lazy I mean
we're going to Mars in ten years we're
going to have a million person colony in
four years and it's going to be the
whole world so we're all going to do it
okay we'll build a nuke we'll build a
new country and on Mars it's gonna be
crazy anyway I'm going off-topic what
are the spikes behind you I'm in a sound
room okay I'm in a sound room and this
is good for blocking sound I'm working
out of a co-working space in San
Francisco thanks Karen I love Toronto
okay so that's all for today I'm going
to go I'm going to stop the broadcast um
I'll answer one more question did you
participate in kaggle I have
participated in cattle cattle is a great
source to become better at data science
look at past projects look at what they
did and try to try to replicate the
results
me and Elon yeah I'm actually I might be
meeting you on this week because Greg
Brockman the CTO at open a I let said
she wants me to come in to talk and so
like you on comes in once a week I know
that so like there's a chance I could be
like yo yo Greg you wanna you wanna
intro me to Ilan or something on me so
we'll see anyway thank you so much guys
okay alright I'll do another one soon I
don't know when but thank you so much
for watching for now I've got to go
drink some coffee so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>