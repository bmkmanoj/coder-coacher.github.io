<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Do Style Transfer with Tensorflow (LIVE) | Coder Coacher - Coaching Coders</title><meta content="How to Do Style Transfer with Tensorflow (LIVE) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Do Style Transfer with Tensorflow (LIVE)</b></h2><h5 class="post__date">2017-03-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YoBEGQD3LCc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's too much and today
we're gonna build style transfer using
just tensorflow
nothing else so let's answer some
questions 5 minutes 5 minutes you a and
then we're gonna get started I need
myself alright who's in this chat room
right now all right well we got Dan
Shipman in here from the coding trade we
got Fernando we got some cool people in
here right now we got some celebrities
guys we got some celebrities in here so
laughs we did up che Jack hi everybody
Wow Dan was actually the first one in
here I'm honored dance to see you here
we watch each other's live streams
occasionally get get inspiration hi from
Germany we got a bunch of people here so
let me uh answer some questions hello
from Moscow we are going to do the math
behind style transfer guys it's gonna be
awesome and we're gonna really
understand exactly what's happening
under the hood know Karros it's gonna be
awesome so check out the link in the
description to follow along with my
notes usually I wouldn't you know show
that but I'm gonna show it right now
hello from the Netherlands parvesh
Arvind
I mean I'll say three more names and
they were good to go lunch time is
perfect timing isn't it uh er ma ascend
and then one more name Bulgaria bug yeah
from Stockholm Sweden and of course all
these up okay so hit me up with those
questions guys cuz I am so excited to
actually build this thing okay because
I've been looking at my notes and trying
to figure out exactly how to explain it
to it's gonna be awesome
we got Grenada okay questions
Norway okay hit me up with your best
questions as they say as I say right now
uh hello from Israel is tension flow a
good library for a deep learning
beginner yes because it has the most
documentation it's got the most headway
in terms of all the other deep learning
libraries there's so much content
created created around tensorflow not
even just meeting like other people that
yes I think it's the best way to get
started and it's it's right now right
now it's the industry standard let's see
how that what happens in the future what
is the meaning of style transfer style
transfer me
it's we frame adding a filter it's you
know it's like filters right Instagram
filters but we framed this as an
optimization problem okay in machine
learning we try to frame everything as
an optimization problem where we
minimize a loss function so style
transfer is an optimization problem
where we have two images we have a
styled image which slave say of dando
painting and then an image of say
whatever we want like yourself and we're
trying to minimize the difference
between these two images images and
that's the transfer we're transferring
the style of this van Gogh painting all
the textures and the waviness and the
colors onto this host painting that are
this host image and we're gonna figure
out how to do this mathematically it's
not magic we know how to do it all of it
okay what is zero shot learning we're
gonna talk about zero shot one-shot
learning at the end of this course it's
at the bleeding edge of everything I
can't wait to get started with that but
it means but it means machine learning
with very little data and that I believe
is the future of all machine learning by
the way there's so much cool coming
out right now out of deepmind my homie
Oreo up in y'all's it they had this new
paper that basically beats DQ which is
their own algorithm that like cause
Google to buy now with this new model
called hierarchical reinforcement
learning so we're starting to see a
convergence no pun intended between
different machine learning ideologies
like this idea of a distraction between
layers and the idea of reinforcement and
combining them together and then this
just they they were able to beat pong in
like 10 minutes it was awesome okay let
me answer three more questions before we
get started how transfer learning can be
done using TF potential flow we're gonna
use transfer learning right now so I'll
answer your question athlete code would
this also work with writing styles I
actually have a video on that called
build an AI writer yes absolutely and
I'm gonna make another video on that
literally next week can you can we make
a program that extract knowledge from
story absolutely text summarization I
will have a video on that later on in
this course Suraj answer my question if
the network is possible to use in
trading we're not going to use a
convolutional net in trading we're going
to use a recurrent net in trading and
we're going to
and I made a video on that not this one
this one will be used where's your
girlfriend no girlfriend I'm single and
happy being single I have too much to do
today I'm happy being single I am a
beginner go more detailed I will go so
detail two darts don't even don't even
trip
Suraj can you recommend ml forum please
the comments section of all my videos we
are essentially a community guys
essentially we are a community of 75,000
strong engineers everyone from middle
school students who are just getting
started learning algebra 2 PhDs at
Google pushing real research so we are a
very large community and the culture we
set up is such that if you can't ask a
question you will get it answered ok
can we build on Google inception for
this task yes you can we're going to use
a different model called a DG g60 model
ok so one more question and then we're
gonna get started with this what is the
best area to focus in AI uh so deep
learning but specifically focused I mean
you know focus can be taking a lot of
different ways focus for research focus
for production focus for a beginner
focus means just a focus on I mean I
mean there's so many things you can
focus on but I would say it's such a
generic question uh generative
adversarial networks because those are
the coolest things right now to me all
right so that's it for the questions and
so now we're gonna get started with this
so we are going to build today a combo
we're going to build a style transfer
and it's not that we're gonna build a
convolutional net from scratch we
already have that we're going to chop
off the top layer and then we're going
to add our own layer on top of that to
do this style transfer so let's just get
started with this I will explain things
as we go and remember the code is in the
description follow along with me it's
gonna be awesome
focus here we go
alright ok so let's see let's get
started with this ok so what I'm gonna
do is I'm not going to code the parts
the parts that are not machine learning
I'm only gonna code the machine learning
part so what we're going to do today is
we are going to perform style transfer
so let's look at this image for a second
let's go to this link it's just a paper
of a bunch of style transfer images and
it's just a way of describing what we're
doing here
so the first paper that did this I
talked about this in the weekly video
was oh let me show myself as well was
the Gattis paper right a neural
algorithm for artistic style that was
much low hands-on that was the first
paper that did this ok and we and since
then there have been quite a few papers
that have built on top of that right so
the first one just transferred the style
which is what we're going to do today
we're once you transfer the style today
but there were subsequent papers that
built on that idea they did it for video
for example and what they found when
doing it for video was that there was
actually a lot of choppiness because
think of it a video is just a collection
of images and we want to of what
happened was there was a lot of
choppiness between frames so what they
did in the next paper it wasn't the same
group it was a different group but for
video style transfer was they added
another loss function called optical
flow based loss so they minimize not
just three or two loss functions they
minimize three or four loss functions
so just chaining these loss functions
together and what happened was this
beautiful video that we can see here you
know like it's it's very you can just
think about all the potential this just
happened last year so just think about
all the potential it has for artists for
all sorts of creative things and
snapchat now has real-time filters so
this doesn't even take training you can
just do this in real time okay so we've
seen a lot of progress starting through
that initial paper and so what we're
going to do is we're going to build
style transfer the original way the way
that the original paper was done and
we'll talk about all the ways of
improving that so let's just go down to
this image and take a look at this image
right because either these are the two
images that we are using right now and
wait let's talk about the process of
what we're doing we're gonna slice off
that top layer because originally okay
so the network we originally used was
called vgg 16 right this was a an image
classification convolutional network
right so at each layer it would apply a
series of operations to our input image
so we can think of our input image as a
matrix of values it's a matrix of values
right a pixel values and we apply a
series of operations to that image
because at each layer at each
convolutional layer we have what are
called a stack of filters okay and these
filters are learned over time and so for
bjg 16 they trained it on thousands of
images so it's already got a bunch of
filters at each layer and at what's
happening at each of these filters is it
is multiplying those filter values by
the input image okay and video is
glitching a lot skipping a lot of frames
okay thanks for that let me just remove
myself that's gonna help alright and so
greetings from Hong Kong okay so
hopefully that helps okay and let me
know if this is still glitching all
right close up this other frame just try
to keep it minimal okay so we're going
to it uh so that's what we're gonna do
and so this is the vgg 16 layer okay and
so the idea here is that let's let's
also look at this is this image right
here that's helping right okay so let's
take a look at this so let me let me
explain what's happening here for a
second so this is a great great image
right here so we want the contour lines
from the content image we want all those
lines from the content image and we want
the textures from the style image okay
those are the two different things we
want and the way we're going to do that
is we're going to add each layer there
are a collection of filters so what are
what are these filters thanks Allen
what are these filters these filters are
3d vectors so why are they
3d well they are 2d there are a
collection of matrices right but there
are 3d because the third up the third
dimension is it's that RGB and it's a
collection of them so we've got like say
however many filters we want to define
the more filters the more accurate are
going to do classification is going to
be and these are the filters that we're
going to use and so what happens is at
each convolutional filter we're going to
perform a matrix multiplication and then
a summation operation and if they're if
it detects if it detects the feature and
the result is gonna be a very large
number but if it doesn't detect the
feature it's gonna be zero and so we can
think of these filters that's feature
identifiers okay they're identifying
certain features and so what we're going
to do first for this for this is we are
going to perform we're going to minimize
the loss between the labeled image and
the feature so what happened actually so
what vgg was initially set out to do was
he was initially set out to minimize a
loss between a labelled image and a
feature map output so at each of these
layers after all of these operations
it's going to out mow output what's
called a feature map or an activation
that it's the same thing which is just a
huge matrix of values okay and we want
to minimize the difference between what
that feature map is and then what our
content is okay so that's what we're
gonna do here and so those are our two
images right we have a Content image
that's gonna be whatever we want to
modify and then a style image which is
gonna be whatever style that we think is
cool that we want to apply to this
content image lastly we have this mixed
image which is going to be just an empty
random noise initialized matrix that
we're going to add to over time okay
we're gonna use we're gonna compute two
different style log loss functions we're
going to do the silo loss and we're
going to do the content loss and then
we're going to combine those loss
functions and then we're gonna use a
gradient value which we're going to talk
about to update this mix image okay so
that's the high-level overview of what
this what's going to happen in after a
hundred to say a thousand iterations
this image is going to be
okay so that's what the high level is of
what this is okay so we're gonna start
off by importing or for dependencies
matplotlib is gonna help us plot out
what we see tensorflow is our machine
learning library numpy is gonna help us
calculate what's called the gram matrix
that we're gonna do I'm gonna talk about
later on and then kill that image is
just gonna show the image that we want
to show okay I am now using tensorflow
version 1 and everybody else should as
well they have updated it and the other
thing is uh I'm using Python 3 so
everybody should update to Python 3 yes
I have finally updated to Python 3 ok
and it's really easy to update just you
know Google update Python 3 Jupiter
notebook it's just uh you know you can
do it in two or three lines of command
lines with anaconda so the first thing
we're going to do is import eg g16 this
is a 16 layer convolutional neural
network ok this was pre trained ok so
this network already has all of those
filters it already has all of those
filters and we're going to use these
filters as tools to help us a perform
style transfer ok so that's the first
step is importing vgg 16 and then we're
going to download it so I've already
downloaded it it's a big file half a gig
and it's probably gonna take you know
depending on your bandwidth anywhere
from 10 minutes to an hour to download
this thing but once you download it
you're good to go
because everything else is gonna be
local ok so now the next step is to
define our image helper functions so
we've got three of these and you know
they're very you know standard load load
the image save the image and plot the
image ok and it's using numpy to do
these three functions so these are just
standard functions and I'll talk about
these later on but right now just note
that they are to load an image save an
image and plot an image ok so we haven't
done any machine learning yet these are
just you know standard image helper
functions so now let's get to the
machine learning ok so what we're going
to do right now is we are going to
define our loss functions okay so before
we define our loss functions we want to
define the mean squared error so let me
just type this out and I'm going to talk
about what is the mean squared error
okay so the mean squared error
is a function given to input tensors so
our input tensors in this case are going
to be called a and B and I'll talk about
what these tensors are but inside of
this it's just one line of code and the
one line is going to be ten to close
reduce mean function and then we're
gonna take the square value of the
difference between both of these tensors
that's it okay so and then I'll compile
that okay so what is happening here so
the mean squared error is the average of
two is the is e is the difference
between the average of the square of the
difference between both the output
feature map and the image that we're
going to the art input image so let's
look at what's happening here okay so it
was called um vgg 16 because there's 16
layers and uh you know more layers mean
you know generally better predictions
but less layers mean less computation
time so it's a trade-off
so for mean squared error we're taking
two input tensors so one of these
tensors is going to be our image okay
either our content image or our style
image and we're going to use it for both
and the other tensor is going to be the
the feature map okay the result of the
whatever layer that we choose and so
what we're gonna do is we're going to
subtract the difference so these are two
matrices okay and we're going to
subtract the difference the square of
the okay and then we're gonna square
that and then we're going to do reduce
mean so what is reduce me okay so right
so this just this value right here TF
dot square of the difference between
these two tensors is going to be a
matrix value and then we want to reduce
the mean so what does that mean so we if
we have a matrix to reduce the mean so
if you'll just be like this we're going
to find the average of all of those
values inside of that matrix so for this
two-dimensional this matrix right here
one one to two okay
it's going to be a 1.5 so that's the
average value of this whole measure so
this is going to output a scalar which
is a single value okay that's what means
we're at error is doing okay and it's
away and and and we the reason we square
it so that it's positive okay
we want a positive value okay so that's
what we're going to use as a helper
function inside of our content laws and
our style laws okay so the first thing
we're going to do is write out a
function for our content loss okay so
we're going to call it create content
loss and inside of it we're going to use
that's mean squared error function all
right thanks the guards so our
parameters for this are going to be
session okay so our tension post session
the model we're going to use I need to
relax okay I'm trying to talk slower in
these live sessions so let me do that
because at one point I'm hyped and the
other point I want to be as clear and
communicative as possible so I will slow
down I'm really trying to improve the
speed of my speech I've done a lot of
great feedback on that and I'm very open
to more feedback so the parameters for
this content locks are going to be 10 to
float session the model which is vgg 16
the content image and then the layer IDs
which are the indices for which layers
we want to use to get those output
feature Maps these are the the the
layers that we we have decided to use
for optimizing for content loss and
these are gonna be the higher-level
layers okay because those higher-level
layers in a convolutional net are akin
to the content right these are the big
high-level objects that are inside an
image or like you know for a van gogh it
would be that moon and the you know
houses things like that and the lower
levels are the texture are the contours
like the lungs quantum AI actually
increases the speed of my videos
interesting because people okay well
you're in the minority okay but maybe I
don't even know that it'll be cool to
get some data maybe even do a poll back
to this so the first thing I do is we're
going to define a feed dictionary now a
bean dictionary is a Python dictionary
object that's generated with
placeholders as keys so this essentially
is going to generate a set of
placeholder values okay and the
placeholders are going to be your image
right so that's it so what this did is
it generated a key value pair where the
key was the image and the value was the
content image so we do this every time
we want to feed anything into our
computation graph we feed it in as
a dictionary okay so that was a first
step and then the next step we're gonna
do is we're going to define what our
layers are now we have our model that we
define as our parameter and then we're
gonna get those tensors by defining
those layer IDs okay so we can play
around with what indices we want to use
for our layer IDs and the researchers in
this paper div as well you're gonna get
different results for different layers
that you use okay and this is not to say
that these are the best indices but they
are there are a set of indices that do
give us good results and you know
abstracting this question even further
what defines beauty can we can we frame
beauty in and of itself as an
optimization problem this is something
to think about in the future how can we
minimize a loss for beauty beauty is so
subjective but can can it be objective
so something to blow your mind a little
bit okay so those are layers so the next
thing we're gonna do is we're going to
calculate our values so these are the
output values when we run our sessions
given the layers that we've just
calculated and we feed it in our feet
dictionary okay okay so what this is
going to do is it's going to get the
output values for those layers for the
for the content image okay so the next
step is we're going to say okay so we're
going to run the model graph now okay so
for the model graph we're going to say
as default all right see how many and so
model graph has default and okay so now
what we're going to do is we're going to
initialize our losses so this is setting
so we can so we're going to add
computational notes to it and that's
we're gonna do right now so let's first
define our losses because we're actually
I calculate a collection of losses so
we'll initialize an empty list okay
we'll call it layer losses that's that's
the name of our list and the next step
is we're going to let me move down a
little bit we're going to say okay so
for each layer that we have valued for
each layer that we have we're going to
iterate through those layers that we
defined in those indices okay
values layers okay that's why I start
contributing to AI is to just start
pushing code to github that you that you
find fun and documenting it really well
and then you know marketing like posting
its people and sharing it with people
we're all sharing you know if the line
between research and production is is
quite thin everything is really a
discovery in and up in any way even a
simple hyper parameter change attention
can result in an incredible discovery
push another link is in the description
okay so what we're doing is for every
layer we are iterating through every
single layer right now we're going to
get that value okay so what is that
value we're gonna define it as a TF
constant which music cannot change and
this is going to be the content images
value okay so that what we're going to
do now is we're going to calculate that
loss okay that loss and now this is
where we use that mean squared error
that we defined earlier and we're going
to use it to the two input tenses are
going to be the value at a layer and
then the constant value so this is the
both the content image and then the set
of features at a layer and we're going
to minimize that loss the best book for
deep learning is the deep learning book
by Ian Goodfellow okay
no the one by yoshua bengio should
Sergio show a venti OD pointing it's
such a great book especially for the
mass loss of means right there okay so
now we're going to say okay so these are
all of our losses that we calculated and
we'll put you appending to that list
that empty loop this point to do write
more games I'm full on game AI course
next so we'll see how that goes I think
it'll be ripped very very popular so
once we have all of those loss functions
template be a good average value using
this reduced mean function okay so these
are our layers losses and that's after
we're done with everything okay and then
uh we're gonna say okay so at the end of
this we're gonna return the total loss
so what this is going to do is this is
going to give us a total
value and let's talk about what we just
said we said okay we're going to get the
mean square of the future activations in
the given layers in the model so between
the content image and the mixed image
and so when this is minimized it's going
to when we minimize this it's going to
make the mixed image that much more
stylized okay so this this defines our
content loss so ideally we can do to the
style loss as well right we just take
both a feature the feature maps from a
layer and then the you know the image
whether the style image of the content
image and we just calculate the mean
squared error between them and we
minimize that but we cannot a previous
line from the last I have a typo thank
you but we cannot do that okay so we
cannot do that because for whatever
reason well that actually compiled
without any errors because okay so let's
let's actually answer this why we can't
talk about write total loss Thank You
Alan so so we don't do that for style
for style we add another step called the
gram matrix and let's just really talk
about what is happening here so the
reason we use a gram matrix so let's let
me show an image of this this will help
so that's okay so this is so this is
kind of scary looking but don't worry
about it a grande matrix all it is is we
are taking the measuring the correlation
between our feature chant-like vectors
after flattening the feature filter
image into vectors so all this is doing
is it's taking it's it's it's the matrix
product between our initial matrix and
then its transpose which is just which
is just flipping at 90 degrees
essentially we're just multiplying a
matrix by its transpose that's it
multiplying a matrix by its transpose
that is the gram matrix okay and so
that's what we're doing for that layer
okay and for our style so for every
style layer that we choose we're going
to calculate a gram matrix and that gram
matrix is what we're gonna use to
minimize via the mean squared error so
let's just start building and then we'll
start start talking about what exactly
is happening here so for our brand
matrix function we're going to have our
input tensor okay so if a vector of the
dot products four vectors of the feature
activations of a style layer yeah I did
it was a people sign right to the total
total loss okay so the brand major ten
remember guys have been following along
in the github link that I've linked you
in the description except all my notes
I'm basically talking through it and
coding at the same time so this is gonna
be a four D tensor okay this is gonna be
a four D tensor at a given layer because
we have the we have right so it's going
to either collection of pixels and then
the RGB which makes it 3d and it's 40
because we have a collection of those so
we have several of those so we have a
collection of 3d tensors which means it
takes four D tensor and that's what this
shape is going to be and what we want to
do for our style layers is we're going
to calculate our brand matrix hello
Abdulla so now we're going to say let's
get those channels
okay so channels are just each of those
so if you think about the outputs of
each layer so an output of each layer is
going to be let's see what our history
was see these like stacks of layers each
of these stacks is a matrix and we call
those our channels each of these is one
of our channels okay so it's and the
word activation and feature as it's used
similarly so feature map activation map
same thing okay so back to our number of
channels what we want to do is we want
to define these channels and we're gonna
get the number of each feeder channels
for the input tensor which is assumed to
be a convolutional layer with four
dimensions okay
and then we're gonna say let's get the
matrix we're just going to be B let's
talk about this matrix Adobe this matrix
is going to be e we have a shape it's
gonna be negative 1 and the number
so what do we just do here so uh
negative one means whatever number makes
this data fit that's what you put
negative one in here but what we're
doing is we're reshaping the tensor so
it is a two dimensional matrix so it
basically just flattens the contents of
each of the feature channels that's what
that it's flattening the contents of
each of the feature channels so that we
can multiply it in a second duty F's
matrix multiplication function New York
we are making it's akin to normalization
okay it's we're taking both of these
values between art style and are a mixed
image and we are normalizing it using
this reshape function such so that we
can multiply it in a second okay so
let's get back Ram matrix now okay so
we're gonna use tensor flows matrix
multiplication function to do this and
we've got this great transpose function
so we're gonna remember it's a brand
matrix is just a matrix multiplied by
its transpose so the same matrix will
multiply by its transpose and then okay
so their transpose by the matrix and
remove this comic if we don't need it
and then that's gonna be our Ramage's
and then we can return that okay uh so
style transferase an extension of
convolutional nets has ganzar a whole
different ballgame they're a whole
different ballgame we're gonna talk
about that later but before we
understand how gans work we have to
understand how transfer learning works
and how convolutional nets really work
and that's the goal of this okay so
that's it for our Graham matrix so that
is the extra step we add the style loss
okay so let's let's actually compute
style walls all right so what we're
gonna do is we're going to compute saw
loss now given that Graham matrix
function that we used earlier so the in
flicks to this are going to be the same
you know basic format that like we did
for the content loss except we're using
a solid image as are any but not a
content in it right and we're adding
this extra step which is gram matrix
step so we'll talk about what this looks
like when we get to it but we're feeding
in remember the dictionary and this
creates placeholders for our feed dict
and
we're going to and this is going to
create a placeholder value for our style
image and then the next step is to get
the layers so our layers are going to be
whatever we got from our layer IDs
whatever we declined and we define these
earlier or we will define these layer
IDs right these are potentially akin to
hyper parameters for this for this
particular optimization problem because
as we tune these are the results will be
different right so mmm those are our
layers so now we're going to define our
model okay so it's you know very similar
we're gonna define our model as defaults
and so we're gonna define our Graham
layer so this is where our this is the
line that is different
comparatively compared to the content
loss the style loss means we have to
take the graham matrices that is a
difference here we're taking the graham
matrices of each layer we're not just
saying here's the raw layer value which
is just you know that matrix we're
saying get the gram matrix of that layer
so and also you know to give some you
know back up to this
Gotti's the guy who initially made this
when asked why the gram matrix in a talk
he said the grande matrix encodes
second-order statistics of the set of
filters I'll talk about denoising in a
second Xavier but basically it's looking
at it from a higher level so it sort of
musha's all the features at a given
layer tossing spatial information aside
in favor of a measure of how different
features are correlated so by so Graham
matrices essentially are like they toss
away everything that's unnecessary just
to focus on this style and and this
works for style but not for content it's
lower layer and I'm sure there's more
theory around why we're using the grande
matrix but that's the best I could get
out of Gatti's and you know it's better
than just saying it just works right
which is a lot of machine learning right
so so that's the gram layers and then we
have where were we again so I went up
first I gonna go back down okay so where
were we we were right here so we said
that we're taking our gram layers and
we're feeding in our dictionary so
repeating at that dictionary that we
just defined bedecked
and we're saying that we're going to
define our layers losses so be big and
then so now we're defining that MP a
list that we're gonna add all of our
layer losses to it right so so that's
that those are our two lines before we
get started with our iteration period so
for our iteration period what we're
going to do is we're going to say okay
so for all of those brand matrices at
each layer we're going to compute the
loss function so that we can minimize it
and so we have we have to input the
value which is a dark image and then B
Graham layer which is the gremlin okay
so the values gonna be constant because
it's a TF punt because we don't want it
to change right we it's not a variable
because we don't want it to change it's
gonna stay the same and now we're gonna
just talk about the loss so loss is
gonna be the mean squared error between
and now this is the important part the
important part is we're calculating the
mean squared error of the DRAM layer and
then the value constants so this is
between the grande matrix and the value
of a brand map matrix when inputting a
style image okay so that's between each
of the layers and the input style image
layer okay so then once we have all of
those losses we're going to add them all
to our list style list so layer equals
layer the losses at each layer so you
know we're combining these losses and we
later combine the combination of those
losses between right since I combining
and then combining again well we'll talk
about the second step of combining but
this isn't the first step of combining
we're combining losses for style and for
contents okay so we're impending
whatever we calculated at each iteration
here and then now we're going to
calculate the total loss so the total
loss total loss is going to be the going
to reduce the mean Queen players so that
we're gonna take the average of
all of those lobsters remember this just
takes the average of every single number
that we have in our matrix and then
we're gonna return that value okay and
that's our style floss and we can and
this is a scalar value it's a single
number okay
the scalar value so that's our style
loss and then what we got here we got
some in dalek syntax my favorite my
favorites okay all right
comma yeah okay so that's what we did
for that and right so feed dick model
that creates okay model dot create the
dict image style image what is it saying
here Oh brand matrix so for gram matrix
gram layers we have feed dig where was I
so many things to keep track of your oh
right that was what it was
okay so um let's see oh right yeah that
great brand matrix layers and then feed
dict where we do our matrix layers for
layers
oh right let's see oh I have a lot of
code here that I'm we can hold on a
second so gram layers are going to be
the gram matrix layers for layers in
layers
oh so what actually there's an extra
line here that I forgot about so that
about certain line here hold on there's
a certain line that I'm missing here ah
okay you just remove these lines right
here great so now so there's actually
one more loss I lied there's one more
loss but I lied because it's very very
trivial and we use it was using the
paper but it's it's not you know it's
very trivial and it's it just starts to
confuse if we simply talk about it at
the start but we're going to talk about
it now so this is just this is the
denoising loss and so what happened
when they when they didn't do this loss
when they just computed the style and
the content lost the image was okay but
when they added this denoising loss
which we can also call the total
variation loss it's also called that
what happened was the results improved
so what it does is it calculates a
difference between the so it shifts the
input image by one pixel on the X and
y-axis and then it calculates a
difference between the shifted image and
the original image and so the absolute
and we and we use the absolute value to
make it positive okay so let's talk
about this so this is the one more loss
function that we're gonna add very
trivial loss function it's gonna be code
but you know it's necessary to just you
know slightly improve our result and you
know there could be even more loss
function that we can think about and
write so there are sixteen layers here
okay but we need the absolute value for
this and oh in fact I could just you
know I'm just gonna paste this in here
because we're gonna get right to the
meat of the code I'll just talk about
this since this two line that's got a
lot of Brent for medical things here so
we are what we're doing here is we are
taking the absolute value to make this a
positive value right and we're gonna
calculate the sum of the pixels in these
images and basically it helps suppress
noise in the mixed images that were
generated okay so well counting the sum
of the pixel values between the shifted
image and our original image and this
the variation and the variation is
referring to that shifted image and the
original image is it removes the noise
and the noise is like the blurriness
it's not that clear and by shifting it
in my you know minimizing it we're kind
of like recreating this blurriness and
we're we're saying you know we could
even shift it more than one pixel and
try that they didn't try that you know
shifting it you know we could do other
um you know artificial noising step look
what can we do to like you know mess up
this image in whatever way okay and then
we want to optimize for minimizing that
so that our actual value is smaller
okay so mmm so now
what we're going to do is how is the
house at frame rate by the way guys but
definitely tell me in the comments how
you feel about the frame rate I'm trying
to improve my life livestreams okay so
now we're gonna get to the good stuff
this is the meet of the code
this is where it all comes together the
style transfer algorithm this is where
we build our model and we're going to
use the loss function that we calculate
okay so let's talk about what these
parameters are going to be so the
parameters are going to be the text is
blurred pretty cool frame rate thanks it
okay framer seems good all right cool so
how much so how much do we want to weigh
these loss functions is a good question
okay so you know like this this can be
played with right so what they did so
you can see here that the weight style
the weight for the style is gonna be 10
so it's almost you know it's like 8
times more than the weight for the
content and we can modify these weights
so that we can we got 144 P over there
okay um bury the text we'll make this
bigger that's 720 p by shabam okay
interesting so that all over the place
okay so so we're weighing this style way
more that will rank the content and it
doesn't mean that these are the best
weights and in fact we can have learning
algorithms for learning the best ways we
could learn the best way slater right so
that's that those are the weights that
we're gonna use and we're gonna define
these weights in a second but right so
let's go ahead and just do our first
step
like I'm assuming that everything else
we did was just a helper function for
this this is the real deal so we're
first gonna define our model okay it's
gonna be BG 16 we imported it but we're
good to go right 16 layer convolutional
net fully connected layer at the end
it's sleeping like oh I'm gonna be used
for classification that's what is
thinking right now okay so now we're
going but it doesn't know any better
it doesn't know any better we're not
going to use it for classification we're
gonna use it for style transfer so we've
got our graph and we're going to feed in
our model okay so that's the session
remember the session always encapsulates
our copy
Congrats okay so then we've got these
print functions here that we're going to
use to help us see what's happening and
I'll just paste these in because they're
really just help her no good so now now
is the good stuff so here's our lost for
our content let's our first loss
function and we define me we defined the
velocity right so the session is going
to we're gonna give it the session value
we're gonna get the model value and
we're going to give it the content image
and the layer IDs okay so no buffering
don't interesting okay good thing you
could say all good things to consider
okay so once you give it the content
obviously because we are trying to
minimize the loss for the content and
then we're going to say other layer ID
so these are the indices so right we
just feed in those layer indices and
it's going to calculate the difference
between the raw activations adding it at
the given layers and our content image
and we think of that as a matrix just a
raw Activision's activations no hidden
step and the value the output value is
our lost content and remember this is a
scalar value okay this is gonna give us
a scalar value the next step is to
calculate our are silos okay so for our
style loss there is that extra step that
extra step is going to be the brand
matrices calculation so it's not that we
just give it those raw activations we
also want to give it the we take those
raw activations and we calculate the
gram matrices from them okay and and the
same thing but on the you know in this
in this you know function we're not
we're not talking about the brand
matrices that's all happening internally
because we defined that on the outside
it looked the same we're just good
programming right we we wanted to look
the same
because there's no reason for us to
expose that grand matrice for a matrix
calculation externally for you know
this function for reusability okay so
that's for our loss and that's for our
style and remember we had one more very
trivial loss function for denoising
right so for D noising we said we just
said well take our model and then
remember to denoise it so that you know
it's just so a little less blurry
just you know a little touch-up at the
end okay so those are our three loss
functions and now what we're going to do
is we're going to adjust Xavier that's a
great question why don't we use the gray
matrices for content loss um so so it's
a second order up it's a second order
statistic meaning for for Scott so style
is actually you know it's it's you can
think of style as more abstract than
content content is something we can
point out and say that is content like
for example the what is the famous
content like the the clock that is
bending in the Dali picture dollies
these uh
where's my mouse the Dali pinyin with
the clock that's bending that is that is
content that's something we can look at
and we can definitively say that is the
content so we can take the raw
activation and say you know it's just
literally there it describes that that
object but style is much more nuanced
style is much more embedded and
ingrained throughout every layer it's
not just I got one layer we say oh that
is that that is where the clock is it's
embedded in every layer so by taking the
brand matrix we're kind of abstract
another layer of abstraction to say that
we want a style is even more abstract
than content and so grand majors please
help us create that extra layer of
abstraction okay so now we're going to
create those adjustment weights right so
for our content in art style so it's
basically just the same thing here so
we'll just you know copy and paste same
thing over and over again to three lines
but basically it is creating control
variables for adjusting the values of
the loss functions okay so we want to
adjust how
we want to adjust how how much we want
to weigh each of them okay and so now
what we're gonna do is we're going to
initialize them right servitor say so
we're gonna say session not run we want
to initialize these values so this is
the actual run step and the the the next
step is we're going to adjust actually
adjust them because we haven't actually
adjusted then we just decline them now
we actually adjust it now we actually
adjust them style transfer can
definitely be applied to audio and
wavenet is a great application of that
and there you know there's a definitely
a lot of discoveries to be made around
speeding up wavenet okay but the idea of
transferring the style to something can
be applied to all forms of media not
just images audio video you know all
sorts of things
hmm but these are the updated values and
the reason we're using this one e 10
values is because we it basically is
you're taking the reciprocal values of
the loss functions and then it's going
to using this small value 1 e minus 10
is added to avoid the possibility of
division by zero so if lost content was
equal to zero this would just throw an
error so that's why we add this very
small because almost think of it as a
bias vector but for justing adjusting
these uh these uh weight values okay and
so now we're gonna actually combine
those losses so now that we've defined
the losses we just find how much we want
to weigh each of them now we finally we
combine the losses into one big huge
blocks function and if the weighted loss
function that we will minimize to
generate the mixed image gives and the
reason we're multiplying these loss
values with the reciprocal adjustment
values that we calculated up here is
because we can use the relative weights
for the loss functions that are easier
to select the exact choice and the
companyÃ­s
of the client layer or the style in the
content labels
so this is our combined loss function
and getting into a good vibes five
minutes and we're gonna get right to
thee
we're gonna get right to the actual
output value we're almost there guys
think
you guys are very patient for sticking
with this right there's a lot of stuff
 them now so now we're going to
calculate the gradients so let's so the
gradient is a great thing to talk about
right so we have our combined loss
function and now we're use
tension-filled Bement gradient function
to get full value right it's not just
one you we're using multiple gradient
values and we're going to get the
combined loss given our models include
value and they'll combine loss so this
is what its gonna do they're just going
to get the gradient of the combined loss
function with regard to the input image
which is the mixed image so this just
wants to minimize difference between the
mixed image and remember that mixed
image is just a blurry
you know nothing image rights and
initialize random noise image and that's
what we want to output as our fully you
know output value that the transferred
style image and the gradient is gonna
get the it's a mathematical function so
the gradient value is gonna give us a
direction and so a great image of this I
have a great bet that I'll talk about
it's hope building the eyewriter
also I'll do another one
you know generates Shakespeare your
paintings our Shakespeare or text check
out that is not yet that gradient that's
Nike and some dude looks like that
gradients back signaling basically I'm
just trying is realize what this looks
like basically it we are taking the none
of you sorry okay so we have a sigmoid
function and we the gradient is like if
we were to take a line I'm just showing
this with my mouse up or down that's it
up or down we take numbers and doing
them push these numbers up we want to
push these numbers down and so that's
what the gradient is doing so when we
take these gradient values okay we take
these gradient values and we multiply it
by weights but the weights in this case
are gonna be the image it's going to
update our image in a direction which is
up or down that is going to minimize a
okay so the gradient is a collection of
those gradients for each of those
feature vectors for each of those
remember it's a it's a stack of features
it's a stack of features okay to take
the list of tensors the gradient was
important super important but pushing
numbers up and down so you didn't get
that right so hmm these are a collection
of scalar values okay these are a
collection of scalar values and when we
take these gradients and we these are a
collection of scalar values and we're
gonna use them not here but in a second
we're gonna actually I'll talk about
them when we when we it's an M but
basically uh I'll talk about them just
okay so this is gonna give us a list of
scalar values okay that's what Brady's
been doing with regard to the loss
function and we'll talk about what it's
doing with the scalar values in a second
but just thing about has scalar values
right now we're about to get them so now
we're going to initialize that mixed
image we haven't actually initialized
the mixed image yet now we initialize it
right so we're using random the numpy is
random dot ran function to initialize an
empty matrix of just random values okay
and we're going to update this next
image through us through iteration okay
so so now it's time for our training
staff so for every four so for number of
iterations that we have and we have
quite a bit of iterations to do you know
anywhere from 100 to thousands this by
the way is gonna take like an hour on my
laptop which is a macbook 2016 a force
touch bar which sucks god I need a
better computer anyway so um great talk
now so the first step remember is gonna
be to create the P dictionary all right
so we're gonna create the fie dictionary
and then given that mixed image right so
we just initialize a mixed image create
that feed dictionary okay
now what we're gonna do is we're going
to calculate the value of the gradient
as well as adjusting the value so it's
breaking up from time to time it could
just be you
okay I'm interesting to note
so that's couple minutes left so what
I'm gonna do now is I'm going to talk
about the gradients and so in order to
focus on the gradients that we're going
to do paste the rest so that we could
focus on the gradient values okay so we
have those gradients right so there are
collection of scalar values between the
mixed image and our combined loss
function so you know think of them as
like they're the representation of like
that what we want to use to help us you
know increase the style in our that
mixed image what how do we stylize that
image the gradients are gonna or give us
tell us how to update our image okay a
gradient is a slope value it's it so
give it a sigmoid function so just you
know remember so for you know fee for
nets we took the derivative of a sigmoid
and it gave us a a line a straight line
a gradient means slope it's just a
straight line and it's the line either
points up or it points down this is a
great image it either points up or it
points down okay
so it's you know a QB plus 2 or minus 2
right and so so when we take these
gradients and we multiply it by that
image it's gonna transfer it it's going
to update the image in some way and
every time we try every time we minimize
our loss the gradients is going to be is
going to be better and by better I mean
it's going to help us it's going to be
it's going to minimize the difference
between D output image and our style
image all right it's gonna every time
it's gonna be minimal minimal
all right so eventually when it's 0 a
local minimum that the output image is
going to be the most stylized that it
can be for whatever however we frame
this problem so
this step is going to remove the single
dimensional entries from the shape of an
array so that our gradient value is
going to be reduced such that it's going
to be the same size so that we can
multiply it by our matrix okay so then
we're going to scale the gradient so
what do we what are we doing and why are
we do this this is the same thing as
learning rate so it's the ratio between
the weights and the updates so if we
don't scale it properly then it's not
going to converge fast but if we if we
don't scale it fast enough then it's not
going to converge ever if we scale it to
something I'm sorry if we scale it too
slowly then it's never going to converge
if we scale it too fast that's gonna
over fit so so we have to update not
just our gradients but our our weights
at each layer so that it's going to
converge properly that's what this step
is and then we're like you perform a
gradient descent and so this is the
actual gradient descent spar right
is what I'm talking about we take those
back gradients which is a scaler and
then we multiply it by the scale value
that we calculated here and it's gonna
give us that output mixed image which is
gonna suck it's gonna suck it but it's
not gonna look like anything but the
more we update this gradients the more
this image is gonna look Dover and Dover
okay like more and more stylized okay
and so that's gonna be our mixed image
and then we're going to clip all the
values that are not between 0 and 255 so
everything more we're gonna clip it
because we want this to be an RGB value
and then we're gonna print out the
number of iterations and we're gonna
plot them okay so that's what that's
gonna do and then we're ready to show
you know what we're going to so that's
that dark style transfer algorithm now
we can print out load images not define
I probably didn't oh I need to define
the load image function earlier it's I
didn't compile that earlier let's um we
just show this okay so this is actually
like if I were to actually run this
right now it would take a lot of
computation power which would lag the
hell out of this live stream and I
definitely don't want to lag this live
stream further so let me talk about this
for two minutes and we're gonna do an
ending Q&amp;amp;A okay so we're worried okay so
remember so given the style image the
content image and then the indices of
whatever we want to use like what are
the layers were choosing for this and
then how much went to weight each of
those loss functions is going to slowly
minimize that loss so this this even
this first iteration is going to take
like like five minutes so even in this
first iteration you already see that
it's getting better like like already
went from nothing to this in one single
iteration okay and after the others is
gonna be so it's kind of like an x-
exponential curve so it's it's super
good at first and then every subsequent
iteration is gonna get you know the the
the improvement is gonna get smaller and
smaller over time okay okay so let me do
the five minute to an eighth to end and
then we're gonna get started hi guys I'm
definitely gonna improve the like on I
really want to improve these live
streams and I really want to and I will
I promise it well because I love you
guys and I want to make this better for
you okay so as any you know leftover
questions you have from this live stream
that's which I'm gonna read out very
clearly for the people who are watching
this later and then I'm going to end you
know whatever other questions you have
as well about life or I mean machine
learning Suraj what do you think of
neuro evolution of augmenting topologies
needs as a genetic algorithm and you
think you will do a video on it sometime
so genetic algorithms I've done a video
on genetic algorithm is called um
genetic algorithms first learn Python
for data science they're really cool the
idea of evolution of Darwinian evolution
it's really cool and it's it's how we've
evolved right but in practice in
practice we don't see you know as good
results as we see with you know these
with deep learning but you know we might
later on we you know who knows and I
think that there are ideas from genetic
genetic algorithms that can be applied
to deep learning remember what we're
seeing in the real discoveries that are
happening right now is when we are
taking these abstract ideas this idea of
hierarchy from deep learning this idea
of an agent of an reinforcements of
trial and error from reinforcement and
by combining these ideas
we're gonna get even better results so I
think genetic algorithms have a lot of
great ideas to give to us okay and I
would I will definitely do more videos
on genetic algorithms in the future how
to communicate with objective-c
don't use Objective C you Swift how to
improve because Apple is now maintaining
that and actually Swift is great for
even server-side code at this point not
just mobile apps how to improve CV for
Google intership look cool I have a
video on job interviews that I'm going
to release very soon either this week or
next week I already have the footage I
just need to edit and release that how
close are we to humans to solving
intelligence my best guess is five to
ten years unless some kind of
cataclysmic you know anything bad
happens that prevents that the rate of
discovery that's happening right now are
there starter videos that you talk to
slower in ah I'm just gonna keep talking
slower and slower okay uh okay so a
couple more questions do you think that
evolutionary slash genetic algorithms
can create the structure of a neural
network absolutely I mean absolutely
they've we've seen them creates a bunch
of other things as well I don't think
I've ever seen anyone tried to do that
so that's a great project to try to
recreate let's say a simple three layer
feed-forward neural network using
genetic algorithms that would be a great
project Bob's tenure is very optimistic
but just look at like the paper that was
just released yesterday by deep mind
when they already beat their deep to
network that this can be generalized to
a bunch of different games um what else
should we learn in AI after ml and do
after ml and DL that's really the the
bleeding edge right now but I would say
if you want to go just even further like
the real future one-shot learning
specifically probabilistic programming
okay probabilistic programming or you
can call it Bayesian program learning
it's the same thing you have any
examples of using a neural net on random
images from the internet oh yeah Dolan
tensorflow image classifier in five
minutes okay
how do you keep up with all the white
papers that are released Andre karpati
has a great website called archived
sanity org i AR XIV SN sa n ity google
that and an AMD r ej great is i that's
my tool
okay I'm gonna answer two more questions
and then we're done if it's only five to
ten years should I start a computer
science degree next year or should I
roll on my own with you engine Udacity
we're all on your own Anton roll on your
own
remember to have your github full of
great projects because github is the new
resume okay and practice your
interviewing skills and I have a video
on that very soon okay two more okay so
actually two more questions additional
resources for style transfer I will link
those to those in the description also
my last video last weekly video it's at
some great resources in there one more
question okay what do you think about
the new no uh I want to make it a good
question what drives you
shabam gupta i okay so what drives me to
be you know totally honest with driving
number one one anything is to solve
intelligence by teaching you guys you
know whatever I whatever I know you guys
can help us all cuz it's a shared
journey we're trying to solve
intelligence so that we can solve
everything else you have so many
problems in the world if you've traveled
to developing countries you see just the
scope of problems is so immense and it
is just I am very impatient and I want
to solve all these in my lifetime I want
to see it also and the best way to do
that is to make better more intelligent
software it is the best way to do that
okay
and that's what drives me and also just
I've always wanted to do great things
and this is a great way to do that and
also I just I want to be out there and I
want to I feel like I I feel like I have
a responsibility to lead it's like this
internal like I I just feel like I need
to dream big and then and leave and and
and I want to and and see you guys
become leaders as well because you are
the real leaders of the future I'm here
to help you guys become leaders okay uh
so that's what I'm here for and I will I
will keep going Oh keep going no matter
what happens I will just keep going and
I'll keep going until my last breath
hopefully there's no last breath because
we saw hayian
you know we have the singularity okay is
the appointing a bad no it's not a fad
it's a it's a next step in a series of
discoveries and I'm sure the next thing
is going to be even better but David in
a way it's not like it's that's the end
goal right there's gonna be more after
it but it's a part of this thing about
I'm not working at Twilio okay so it's
one thing full-time all right so that's
all for my questions thanks guys for
being here I have a video coming out
this on Friday like always and uh okay
so that's it for this live stream let's
see anything else I want to do now I'll
just say I'll save the rap for next time
okay so love you guys remember to uh
links are gonna be in the description
everything's gonna be awesome
remember to join our slack Channel all
right love you guys and thanks for
watching for now I've got to go drink
some coffee and then transfer the sub
the coffee into my brain and just
minimize a loss between my sleepiness
and my wakefulness so Oh freeze uh-oh
someone said free stuff so I'll do it
because you guys know I love to
freestyle um I'm fruits all about coffee
Joe I love to drink coffee
no no that's I want to do it about
machine learning so uh so what's it when
we just talked to all we talked about
style transverse or style okay I love to
talk about style I take my boat drive
down the River Nile I do it in a spit
out pile that's not about its flow
anyway that's it for this time people
laughing cuz I'm trying to freestyle it
doesn't matter cuz I'm trying to go in
de Nile River
you got ancient secrets that the
Egyptians made but now we got even more
man bars bars bars okay whoo freestyle
transfer anyway alright thanks for
watching guys</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>