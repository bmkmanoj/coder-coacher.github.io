<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Vision | Coder Coacher - Coaching Coders</title><meta content="Machine Vision - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Siraj-Raval/">Siraj Raval</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Vision</b></h2><h5 class="post__date">2018-02-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EMjPqgLX14A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello world it's Suraj and just a few
days ago
Facebook's AI research team released a
demo called dense pose they were able to
map out every single pixel of a human
body in a given video and not just for a
single human but for many many humans
all at once
even more impressive they were able to
do this in videos with lots of
distractions and general chaos on a
single GPU / them nope just deep
learning this is pretty cool and has
tons of applications and we're gonna
learn how they did it in this video
creating 3d animated characters is a lot
of work the tools to do so are expensive
and require teams of people working for
months on end big production studios
with the available budgets are able to
track humans and convert them to
animations but for people without big
budgets this technology will democratize
that ability remember my video on the
deep fakes algorithm well this can be
used for a full-body version of that if
we can track a human we can swap out
their entire body with a different one
lending to some surreal scenarios like
geoff hinton charging into Mordor
instead of Aragorn augmented reality
applications could use this to label
people that you see in real time with
all sorts of statistics and it would
give away four machines to be able to
better read our body language for
everything from sentiment analysis to
full-body tracking to virtual reality
gaming this is the new state of the art
inhuman pose estimation and to
understand how it works we're gonna have
to try and work through the thought
process the authors had both in terms of
building on previous discoveries and
trying different methods so let's say we
have a video of a human dancing this is
a 2-dimensional grid of pixels but when
you or I look at it we're able to tell
that there are indeed 3d objects that
are being represented by this 2d grid we
want our computer to have this ability
as well and in a way that
can visualize it meaning will want to
transform this 2d human into a 3d model
once we have that 3d model we can do
whatever we want with it
put it into any sort of scene swap it
with another 3d model change its
features lots of possibilities but all
of these possibilities depend on us
being able to construct a 3d model of
this human in real time that updates its
movements as the human moves we want to
construct a correspondence this is a
computer vision term that is a measure
of how well pixels in one image
correspond to pixels in another image in
our case it would be a 2d to 3d image
and we don't want any holes in our image
we want all the pixels to be as close
together as possible so we'll call it a
dense correspondence and we'll just
focus on doing this for humans for now
to create a dense correspondence we'll
need to perform some object detection
object segmentation and pose estimation
that's a multi-level problem so we want
to start with a method that's as simple
as possible we've got so many different
avenues to go about this but ideally we
could use some sort of labeled data set
because having a label just makes
training machine learning algorithms
much easier since it just involves a
learning a function that represents the
mapping between the input data and the
labels in this case what would the ideal
label datasets look like there are tons
of labeled image datasets out there
these days
Pascal see far image net these are
basically big collections of images of a
variety of random objects each with
their own particular label these data
sets have been a catalyst for all the
recent progress in computer vision
algorithms but we don't want to just
label a human if we see one in a video
we want to be able to create a 3d model
of one there's not really a data set of
human images with the label being the 3d
model so we'd have to create one
ourselves and it would involve humans
manually creating annotations that
relates 3d images to surface based
representations of the human body and
that's exactly what
did they basically asked the annotators
to annotate regions corresponding to
defined body parts like the head and the
legs all of these annotations were
labeled with their corresponding 3d body
parts which acted as the label they did
this for 50k humans which summed up to
be a total of five million manually
annotated correspondences once we have
our data set we're gonna have to decide
on what model to build we know that deep
learning is the state of the art when it
comes to classification and that
convolutional networks are the state of
the art in image classification but it's
not just classification we're trying to
do but regression as well what's the
next move the human is going to make the
next question would be has anyone done
something similar with a convolutional
network of course luckily there was a
recent architecture called dense reg
that did this for all sorts of objects
and got decent results so we could start
with that architecture in the first step
the network will classify a pixel as
belonging to either the background or
one of several region parts that gives a
rough estimate of surface coordinates
this is essentially a labeling task that
can be trained using gradient descent in
the second step a regression model will
indicate the exact coordinate of the
pixel within the region part a more
formal way of saying this is that in the
first stage it will assign position L to
the body Part C that has the highest
likelihood as calculated by the
classification branch and in the second
stage it will use the regressor to place
the point L in the continuous coordinate
pair UV that is a parameterization of
Part C C can take 25 values one would be
the background meaning that P is a 25
Way classification unit and we can train
24 regression functions are each of
which provides 2d coordinates within its
respective parts both the classification
and regression tasks are trained by
minimizing a respective loss function
but the regression loss is only taken
into account for a part if the pixel is
within
specific part so our network can work
but it requires a lot of tasks for a
single Network like part segmentation
and pixel localization they use a
technique called region of interest
pooling to create different regions and
fed the results seeing features into
region specific branches this decomposed
the complexity of the task into
controllable modules all of which which
could be trained jointly in an
end-to-end approach so it's a fully
convolutional network on top of region
of interest pooling that is entirely
devoted to two tasks generating a
classification and regression head that
provide part assignment and part
coordinate predictions to improve the
model they used a technique called
cascading meaning using a collection of
models using all the information
collected from the output of one model
as additional information for the next
classifier in the cascade the output of
the region of interest a line module
feeds into the dense network as well as
networks for the masking and key points
tasks the first stage predictions from
all tasks are then combined and fed into
a second stage refinement unit of each
branch when experimenting on novel
videos their architecture worked well
across the board for not just one human
but multiple humans unfortunately they
haven't released the initial source code
just yet but we can recreate what they
did using the details in the paper also
the data set they created is open source
so definitely check that out
three things to remember from this video
dense pose is a new deep learning model
that can estimate 3d models of multiple
humans from just a video on a single GPU
they use a collection of convolutional
networks to do this
performing classification for assignment
and regression for coordinate
predictions and they open source the
data set they created mapping humans to
their corresponding 3d models please
subscribe for more programming video
and for now I've got to make a goodbye
pose so thanks for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>