<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Closing Remarks and Q&amp;A | Coder Coacher - Coaching Coders</title><meta content="Closing Remarks and Q&amp;A - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MongoDB/">MongoDB</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Closing Remarks and Q&amp;A</b></h2><h5 class="post__date">2012-10-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ndL9c2-ahxY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so first I just wanted to thank
everybody for
coming both in person and online and I
want to talk a little bit about how
everyone here can help us with MongoDB
and you know how we're going to take
manga to be from where it is now and
what we're going to do with it for the
next you know five to ten years so you
know you go back in time a little bit
right Mongo we've been working on the
code for mongodb for just under five
years now I'm in five years and the
database timeframe is early right most
databases that people use heavily our
old right you know 20 30 years old and
so it's still very very very new so so
first we clearly think there's a lot of
work to do and plan on working on core
features for at least the next five to
ten years so a very long time line here
but you know one of the challenges as we
sort of as the community grows a lot and
as tendon grows a lot is to really keep
in touch with the people who use mangu
every day but if you go back in time to
when we first launched Mongo and there
weren't very many users of long ago you
know I personally knew most of the
people using long ago in production we
would work with them directly all the
time and so you know for the first six
months it was really you know there's a
small 10gen teen like four or five
people and we knew everyone using it
which was great we were able to fix
issues very quickly we're also adapt
very quickly real to add features very
quickly things worked really well you
know move you know fast forward to now I
probably know you know Oh point one
percent to the people using Mongo I
talked to a very tiny percent of the
percentage of the people this is sort of
natural right I can't talk to you
thousands of thousands of people just
challenging and what we really need from
the community and what we really what we
really need is to make sure that the
people working on the product to make
sure that you know me heavily that every
engineer who actually works on MongoDB
understands how people use it
understands how people care about it
right it's a very it's very bad of
people building it don't know how people
use it and so you know obviously there's
always people can help out now right
there's JIRA where people can put
feature requests can put bug reports
there's the mailing list and I think
what we really would like from the
community is just even more engagement
right you know a few features you want
don't just say hey this would be a cool
update operator really come to us and
say you know really try to tell us like
why help us understand what's going on
because the problem is that there are
thousands of feature requests that are
all pretty good and what we really need
to just figure out which of the hundred
that really really matter to people and
understand why and so if there's one
thing that you could do to help us it
really helped us understand how you're
trying to use Mongo and how we can make
Mongo more effective for all the
applications you want to use it for and
now I think Dwight and I will take some
questions so the question is all does
the aggregation framework and all the
features work across work with starting
and the answer is yes so all the
aggregation features work sharted there
shouldn't really be any develop any
difference from the developer standpoint
everything that works on a single shard
will work on a shard a cluster
so the question was for records that are
deleted from TTL collections you know
can they cause fragmentation since they
could be a varied sizes so there's
another new feature in 2.2 which is a
different allocation strategy that you
can turn on for our collection that
instead of allocating the exact number
of bytes for a record allocates up to
the power of 2 which based on the way
the free list management works causes no
fragmentation and when you turn on TTL
collections for I when you turn on a TTL
index for a given collection we will
automatically turn that on also so that
means if you're using TTL collections it
would be almost basically impossible to
get fragmentation meaning you don't need
to run manual compaction because of that
rounding up right because we're rounding
up to the near-ir 02
so the question is you know what are the
implications of different pipelines in
aggregation so right now all the Pythons
and aggregation are in memory and is a
cap on how big they can be over time
we're going to be doing on disk
pipelines also so that you can you know
if there are very big pipelines you can
push them out to disk and then read them
back in but for now it's capped it's a
pretty big cap and it's based on the
amount of ram available in the system so
that if you've got if you've got a box
with 20 5252 256 gigs of ram you'll be
able to a very large five line cut any
issues but it's based on how much room
you have and so the locking mechanism in
aggregation is the same so you can be in
and also does all the same yielding and
same truth queries so you can be doing
aggregations while you're doing all your
other operations also and are you
talking about the output aggregation
size or the input size even use alone
sighs right so think about it this way
there's the the actual input can be as
big as you want right but it's like
after the fur after the first stage
where we actually are computing new
results that has to fit in memory
so the question is what future courses
we plan on releasing on the education
site and I don't think we have anything
planned beyond the first two right now I
think we're going to see how those first
you go and see what the demand is and
see see what people are interested in
this is it one thing being discussed is
sort of but not decided is on the
developer course kind of doing it by
language but of course that would be a
big project because there's a lot of
languages but but it makes sense right
so so that's something under
consideration but as you said I think
we're going to iterate on it will do the
first first round and then we'll see
what everybody says and go from there so
the question is can you get different
documents in a t-tail collection of
different expire times so the expire
setting is the same for every document
right you're going to say that every
document you know it's a 15 minutes or
60 minutes but you can set that field to
whatever you want so let's say a
document you want to live for 24 hours
you just set that time ahead right so
you say that you know this shopping cart
i wanna last for an hour so I set it to
an hour in the future so you can you can
tweak it that way you can modify the
actual field as often as you want so
that while this the overall setting is
the same you can still control when
things actually get deleted on a per
document level can you have to TTL
indexes on one collection I don't
remember ah I think you can Oh
this has to do with the veg marathi in
the replication center I've got you
writers one sent you veggies
Confederation Congress that gets
replicated all the Beijing confirm that
would be one bench 1 150 my father any
rules operation before
so I think the question is on you taking
been on the bulk inserts yeah is it the
only form of backed writing you can do
to a primary is a bulk insert it's a
bulk insert basic question so this is
about you so the question is on if I'm
doing to bulk inserts at the same time
on the primary and their bachelor's head
of those correspond to batches on the
replication side so batches on the
primary aren't necessarily done in
isolation right so I could do a batch
and I made you the first 20 and then
don't let someone else do some and so
the so they could be interleaved on the
secondary so the question is right so
the question is now say I do a bulk
insert to 100 document so that I call
getlasterror says wait for replication
wait for these to be replicated so you
will you know so it's the same thing as
before is you will wait for all hundred
to be replicated and if other things
also slipped in there too so you're
intermingled you'll end up waiting for
more than 100 you know 150 rights may
have happened on the secondary but
you're guaranteed that every right that
you did on that connection is on the
secondary
broad my upgrade to two to one by one or
two shut down the entire cluster and
so the question is can I you know
upgrade a running system in production
without any you know it with a rolling
upgrade and so the answer is yes so the
general way you do mongo upgrades are if
you've got a shortage cluster you'd up
great you know config servers first then
Mongo esas and treat shard for each
replica set you do the secondaries
person in the primary and you can do
these in a rolling fashion so the
question is does the tag is the field
bank at helping the shard key yes so it
has to it has to be the shark key does
the aggregation framework these indexes
so yes it uses indexes in a couple
different ways so it uses into obviously
is the first part of the match is a the
first part of the pipeline is a match or
a sort it can use the index it also does
use covered indexes if it can for
certain cases so it will use index as
much as possible I think there are more
ways that can use indexes in the future
but it definitely is using indexes now
so it's not reading the entire data set
for every pipeline if it doesn't but
mainly it's using them at the head of
the pipe correct right so if you ideal
you put a match at the very start right
yeah you've got a match that can use an
index you'd want to you want that first
there's a little bit of optimization in
there so we'll try to move things
forward if it can but I don't think the
optimizer is brand new and so if you
can't help a little bit it would
definitely be good yes yes oh I'm sorry
good question and my programmer yes yeah
go look on github
yeah so the question is is there any
plan to make Mongo run multiple
MapReduce jobs in parallel like Hadoop
so yes the so they talk about the
JavaScript engine yep so the the main
reason why you can only do one at a time
right now is that the JavaScript engine
we're using currently doesn't really
work very well with multiple you know
you can't really won multiple JavaScript
reg threads at the same time we are
looking at a couple of different options
to switch Africa to switch Thomas trip
engines and hopefully the ones we switch
to will let us do multiple threats at
the same time and then we will
definitely support multiple MapReduce
jobs at the same time right that's the
family issue there and aggregation and
you can run all the what for aggregation
pipelines you can't unreal tible
aggregation problems at the same time
right the concurrency there is the same
as for normal queries so you can run as
many as you want in parallel yeah and
you can use the dupe if you want with
the Hadoop connector
do we have any plans to do certification
Andrew what's the answer yeah yes Andrew
says yes right so for the first set of
courses were simply doing certificates
of completion you know we want to make
sure that we've that we're doing a good
job on these courses and then we'll
probably do certification thereafter
once we figure out how to do that that
is good yeah so the question is so the
locks are now by database into two
what's the plan for the future right so
so largely it depends on what happens
with 22 you know I think so much has
changed and the you skate the workloads
have changed so much we're trying to
figure out what the next right step is
you know obviously we can't make the
lots more granular there are also other
things we could do for concurrency in
terms of journaling with other with
other aspects of the system so it's
actually unclear what the next step is
and that's really going to depend on you
know what happens with actual real-world
scenarios with 22 you know 22 is
obviously only a few weeks old at this
point and so really we really could use
a lot of feedback here in a lot of the
you know real world cases where
concurrency is still an issue and then
we will figure out the roadmap to tackle
those we really want to avoid just
guessing what's going to cause the next
problem when it may actually not be an
issue at all and it could actually make
things worse so we really want to do
this very empirically so are you saying
you're debating in your mind between
like say a collection level lock and
just going super granular right as
collection of locking there's more
granular locking there's level to a
record level yeah how it works with
journal in a lot of different ways we
could take this is not a different
possible next steps so it's not clear
what the best one is yet but it'll get
more granular it's questions I think
we're going to take out two more
no shower any plans of liver to release
palma de or arm to serve and are there
any plans to release mongodb forearm to
serve embedded in mobile there is a
strong desire there are actually a few
people running it so I think it's Reeves
up we're going to leave them a little
bit of work on it I think we actually
had some interns who did it for fun so
it is possible there are people running
it I think they actually do it well we
take a little bit of changing some of
the some of the more deeper parts rather
than just hacking it to work together so
it definitely is a desire you know I'd
love to have you know i love to be able
to use Mongo on my iPhone but probably
not in the next few months for sure it
would be helpful to get some feedback
like gun if you would find that useful
like here's what I'm here's why they
want to use it for and here's why and it
would help inform us is the kind of how
much it makes sense the yes it's not
imminent but it it theoretically makes
sense the actual footprint of the Mongo
d process is very small it's like eight
megabytes maybe so it it feels like
Mongo uses lots of memory because you
run top you see this giant number but
it's because it's counting all of your
file system cache it's touching right as
memory it uses written in Resident bites
but actually the process itself can fit
in a very small amount of memory so it
would be possible to run it on embedded
things in theory but it hasn't been kind
of product eyes for that yet so I'd say
it's definitely not ready for that
without extra efforts
so I think we are running out of time so
I think in closing I think 10 say thanks
again for coming and you know either in
person or online and no thank you very
much and I think just a you know please
try to to get us feedback that's the
thing we want more than anything just to
hear from you you know a lot of changes
and for example the concurrency stuff we
want to know where is it working well
for you where is it not there may be
things that just a little bit of tuning
on it could could could make better at
this point after a lot of sort of
infrastructure has been put in place
there so but thanks for coming thanks
for watching online</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>