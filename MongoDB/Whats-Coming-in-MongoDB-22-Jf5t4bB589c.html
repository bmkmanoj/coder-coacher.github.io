<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>What's Coming in MongoDB 2.2 | Coder Coacher - Coaching Coders</title><meta content="What's Coming in MongoDB 2.2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MongoDB/">MongoDB</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>What's Coming in MongoDB 2.2</b></h2><h5 class="post__date">2012-08-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Jf5t4bB589c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so what's coming into two so one
of the big things in to choose
concurrency a lot of improvements in
concurrency 20 had a lot of improvements
you to actually resolve a lot of the
issues that people are having and 22
should have a lot more a couple of big
ones so one is DB level walking take a
step back for a second actually it's
hard to describe what locking and Mongo
is right people think about what it
actually is it's not BBB level locking
Mongo is not like you know my I Sam
anyway here ever use my I salmon in my
sequel front of people so the deal with
my I am in my sequel is that its
collection level locking but basically
if you do a query that takes five
minutes well nothing else can operate
while that's happening you have
exclusive access to that table for five
minutes walking among was very different
so all Mongo operations are interleaved
right it's kind of if you think about
sort of a a single thread if you think
if you think about a system with a
single thread where everything that's
interleaved right so think about like a
nodejs I l'application where's a single
you a single thread and everyone's just
interleaved that's sort of more of the
way mongos design it's actually not
using a single thread but it probably
should could be or using a swan number
of threads and the idea is that
basically everything is time sliced so
there's two different aspects of it
there's two different aspects to it
there's how many different locks are
there is how good the time slicing is
and this how good time slicing is
relating to disks right the key for a
database and especially you know thank
you for a most database is that you
never want to hold the lock while you're
touching disk disk access is you know
way slower than RAM and so you want to
make sure when you're doing your time
slicing that your time slicing around
disk access so those two things we're
doing in two to one is DV level locking
which basically means that the time
slices hat our around Phoebe's not
around the server so that's a big step
forward the biggest issue is actually so
you can do some crazy things and
actually put different collections at
different databases and do all sorts of
hacky things but the real benefit of DB
level locking is that rep
location uses a different law right yet
replication is like a regular Mongo
query basically and it stores data in a
collection and it uses that collection
for doing all of its sync sinking and
all that sort of stuff and so now that
it has its isolated an isolated lock
replication isn't really impacted by
database operations so that's pretty
good and you could do other things too
but the big thing in 22 actually that
actually will really help performance is
yielding with this access which
basically means making sure that when we
do time slicing time slicing is
completely aware of what's going on in
the RAM and what's in R and what's on
disk and that if you're trying to do
something that's going to touch disk
that you do not hold the lock while
you're touching disk and so there's a
whole so in 20 we started working on
this then we did a lot of work on it and
we'd hit it a few of the key pain points
and for those key pain points that made
a big difference what we did in 22 is
very different using the exact same
underlying system for tracking and
synchronizing our knowledge of what's in
RAM versus what's on disk we're actually
at a very low level basically a boarding
operations when they try to touch disk
and hold the lock so basically this
literally code at the very lowest level
of the system that says hey I'm trying
to access a record if this record is in
memory great I'm going to let you
continue if this record is on disk and
you haven't you know modified anything
yet I am actually going to abort you and
say you know you have to restart and
before you restart make sure you load
this dislocation of off of disk and put
it into memory sort of a simple concept
but the benefit is that at the end
you're really never touching disk in a
lock which basically your meat you're
bound by mostly by ram which is really
what you want to be not bound by disk
speed so it's actually pretty big change
the other two things we added are
related to this which is that you can
actually measure page fault by database
which is pretty cool so if you have a
bunch of different databases you can
actually measure exactly what's going on
which database is causing page faults
and all those of interesting things and
you can measure number of page faults
that caused operations to get a boarded
and if we did miss a case where we can't
abort something you can actually you'll
be able to see very clearly how many
page faults happened with the lock being
held that for some reason we were not
able to abort the operation that's great
because then if you see those you can
tell us and we can fix them and it's
great because you can actually very
clearly see exactly what's going on in
terms of the disk subsystem which is
pretty cool i think it's like this stuff
up wanted i wanted or my sequel a lot a
long time ago but never had so this is
pretty cool so that's concurrency
changes the next big thing in 22 is the
aggregation framework so obviously if
you talks on it today but the basic idea
for those who don't know is that being
able to do single simple aggregations
and Mongo pre 22 is too hard but if you
remember one of my design goals is that
I want aggregation to be simple with
MapReduce it's the MapReduce is not
simple nor easy nor fast so sort of
fails and all funds it's good for
certain things but it's not awesome and
we want something really good and we
want something awesome too I guess so
what does it look like for those of you
don't know so let's say you've got a
collection of blog posts and blog posts
have a array of tags associated with
them and you want to compute a simple
tag cloud now this is all you have to do
before you have to do a MapReduce job
you have to write JavaScript inside of
your Python code it's a big mess now you
just say unwind tags especially means
explode the tags array and then count
tags you know basically do a group so
for each tag free some of you know plus
equals one very simple very short if I
actually have the map the MapReduce code
up here it would be very hairy and very
messy and not very pretty so this is
much nicer and a lot faster as well so
that's really quite nice
next is TTL collections so T tale
collections into two are going to be
fairly straightforward and there are
some things you could implement on your
own it's just nice that the database
does it for you basically let's say you
have sessions and you want sessions to
automatically expire when they haven't
been updated in a day so all you have to
do at this point is say create an index
on last updated and set the flag expires
after seconds which is 86400 which is
how many seconds are on a day you set
that flat you set that flag everything
else to take taken care for you it's
basically like a background job
constantly deleting things so it's
always very incremental and very fast
now the big problem with this kind of
workload easy good sort of a high insert
high delete workload is that you can get
fragmentation so there's some stuff we
did for this and basically if you use
TTL collections it automatically
configures the collections in ways such
that is impossible for them to get
fragmented seems like a cool feature
maybe we should expose it so we did that
too so fragmentation like any storage
system is definitely a problem the
reason why it's a problem is that the
storage system tracks free space in
buckets of power of two alright so there
is a list for each power of two up to 16
megabytes stores areas and discs are
free so if you've got records on disks
that are 513 by through 713 but one up
on 36 37 38 39 13 they are stored in the
same free list so now let's say you've
got something really ugly you insert a
million documents that are 600 bytes
then you modify every one of those
million documents and now there are 650
bytes those million six hundred bite
locations are now sitting on a free list
now you go ahead and modify a few more
things three or six 50s in your base now
you try to go insert something at seven
hundred bites well your 600 bite records
are too small you're never going to use
them big problem so a lot of ways to
solve this so what we're doing in 22 is
actually it's not on by default but it's
an option that you can turn on whenever
you want you can turn it on for all if
you upgrade to 22 you can turn on for
collections as well and basically what
it says is anytime you allocate space in
this collection allocated up to the
power of two so never allocate 713 bites
always allocate 1024 bytes so when you
delete it you will you've got you know
you always have 1024 so in the previous
example where you insert a 600 million a
million six hundred bite records and
delete 100 please delete a million you
have exactly 1 million 1024 bike records
if you go into as long as 813 bites you
can take one from there so it's pretty
good so it's basically no way you can
get unused fragmentation now that you
can have wasted space if you of all of
your documents grow from 813 to to 1300
but that's nothing to the common case
the common case of fragmentation is
where you've got these little holes that
you can't use because things just don't
fit anymore now obviously this will use
about fifty percent more disk space on
average than not using it but the
benefit is that in you know so in the
short term it actually it seems like
it's more expensive but in the very long
term if you have a lot of fragmentation
you actually end up wasting a lot more
than fifty percent and you get some
performance degradation which is this
way you're all you know performance is
always going to be fairly consistent but
you're not going to you're never going
to get a drop-off and the wasted space
is fixed whatever you have the beginning
is what it's going to be forever so it's
much more predictable and predictability
is generally Trump's most other things
in my mind so that's what that's that
there's a lot more stuff we want to do
later but this is what we're doing for
422 okay to data center awareness and
this is sort of a weird feature because
a lot of it came for wanted to be data
center where in certain cases but it's
actually it's really nothing to do with
data centers basically the idea is that
it's tagging for sharding so I picked a
very obtuse example on purpose so you
can tag shards you can tag shards ABC
you have many shards per tag so I can
have three shards types a three shards
tags be three shards tagged with see
whatever you want they can be any text
you want so they could be locations they
can be random numbers they can be
strings different colors doesn't matter
you know as many charges you want with a
certain tag you can have as many tags
for short as you want
a shard could have a tag a bee I'm sorry
could have a tech a comma B kind of a
comma C it doesn't matter each shard has
a list of tags associated with it then
for a given collection you say hey for
let's say I'm shortening on x for x
between 0 and 100 I want those chunks to
be located on shards tagged with a I
don't care about anything else I just
know that I want it on the charge tagged
with a and so on and so forth so what
does this actually do for you well let's
say that you want to have a email system
and your email system is going to have
three data centers a European data
center a US data center and an Asian
data center every replica set is going
to have let's just say three news in
each data center so each replicas thats
going to have nine nodes total I'm just
making this simple because it's easier
and I'm gonna have three types of
replica sets I'm gonna have a an e data
center or European data center I'll call
it the yeah i'll call it e the American
data center alcohol na and the agent
center i'll call a a little bit up to
use for fun so what is sharp so I'm
going to tag certain shards with e what
does that mean so a shard CAD with E
means that again every char has three
nodes and each one of the data centers
but all shorts head with E are going to
have this the nodes in the European data
center with a higher priority than every
other data center so my three nodes and
Europe are going to be a priority to my
three nodes in the US are going to be
priority one and my three dozen a jargon
airy priority one right so that means
that if any of the nose in Europe is
online that's going to be where my
primary is located that's where all my
rights are going to go for that chart so
now if i have now you have to define a
shard key so my shark key is going to be
location comma email address so now i
can say for all people who live in
england i want to put you on shards tab
with E this is pretty cool right because
now I can say that hey if you're if you
live in europe i know that your rights
as long as that European data center is
online at all all of your rights are
going to that European data center if
the European Center did if the European
data center goes down completely you're
going to fail over to something else
doesn't matter I don't really care which
one at that point they're both bad but
you know at least still be up Google to
write you know read and write your your
data it's fine and then when the
European did data center comes back
online it look at the news data they'll
sync up and then I'll take over again in
your s will be fast again it's pretty
cool and then you can do it for
different countries right to the people
in the US will be home to the US data
center people an age will be home to the
age of data center so that was a main
use case but you can use it for a lot of
different things right so you can use
this for let's say you get non
heterogeneous hardware and you want to
say that look I only want to put certain
I could put like different kinds of data
on one shard or different types of chars
maybe I've got like an SSD char and a
spinning disk shard or different you can
isolate data that way if you've got a
multi-tenancy application you can have a
hundred shards and have your good
cluster and your bad you have your good
section in your bad section based on how
much you care about certain customers
right and you can isolate certain
people's chunks 21 places or other
places and you can tune those things
whenever you want like you say oh you
know what my bad customers actually are
annoying me these days I'm going to take
away a few shards from them and add them
to the other cluster that's fine the
system will just you know you change the
config and the system will start
rebalancing things and eventually how
it's out the way you want so there's a
lot it's actually a lot of different use
cases for it it's actually very powerful
but very simple to configure but lots of
different i'm actually kind of very
curious to see all the different ways
people are going to use it people
actually keep coming up to me with other
interesting ways to use it so i'm really
curious it's going to happen when we
actually release it it is available
today you can start playing with it but
it'll be in 22 but it's there now if you
want to tell you around with it so those
are the things that are really coming in
to two and on based on that I think
we're all set and once again thanks for
coming out today it's been a lot of fun
and I hope see you guys later tonight
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>