<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Scaling MongoDB | MongoDB | Coder Coacher - Coaching Coders</title><meta content="Scaling MongoDB | MongoDB - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MongoDB/">MongoDB</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Scaling MongoDB | MongoDB</b></h2><h5 class="post__date">2011-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lnY8D3TL_tM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so this is five steps to scale your
MongoDB I gave this talk the other day
and it lasted just about an hour and 20
minutes and then Adam suggests I do it
tonight and condense it into five
minutes so hey like this is about as
condensed as I can make it I think I'm
originally this sort of assumes that you
know how a MongoDB works so but most of
the concepts will apply to any database
and so let's jump through it so you have
a MongoDB cluster you want I get faster
step number one optimize your queries it
turns out whether you're running or a
thousand servers or a single server you
know computer science works and you know
time complexity works you know a b-tree
index is faster than a table scan it
doesn't matter whether you have a
petabyte of data or a gigabyte of data
right so analyze your queries here we
have looking at the query analyzer
inside a bongo at the top we have a
query I'm saying DVD collection dot find
so you know some where my title is equal
to my blog if I do query dot explain
it's going to give me the explain plan
just like in a relational database would
but they tell you about this here we can
tell this curt this query is gonna be
really really bad because first of all
it's a basic cursor which means it's
doing a table scan and scans is the
number of documents that we actually had
to look at in order to satisfy the query
57,000 is a lot so that's you know I
took 108 milliseconds and that's like an
eternity in MongoDB labs so the way we
fix this is we add index to it right and
again doesn't matter whether you're
running on a thousand servers or a
single server you know you need to do
this to make this query fast whoops
number to know you're working set size
right so one of the things we found in
MongoDB is that one of the you know
things people do is they deploy a
database and then in front of that they
stick a memcache right and we think this
is kind of silly you have lots and lots
of RAM in your database server typically
so why not embed that memory cache right
into the database and that's exactly how
long the DB works so this is my attempt
to draw this this ratio of you
I've got a small amount of RAM that's
caching you know actively use pages and
then I've got a much much larger amount
of disk that's storing my entire
collection right so basically accessing
Ram is you know several orders of
magnitude faster than accessing disk you
know just a reality of physics this is a
MongoDB thing this is true in my sequel
and Oracle and nad any database hitting
something that's in RAM is gonna be
super fast hitting something that's on
disk is not right so basically what does
this mean for you well it means you want
to think about the total database size
and how that relates to the set of those
that data that's actually active at any
given point in time so if I'm managing
sessions on a website
I may have billions of users but only a
hundred thousand of them are active at a
time those hundred thousand users that's
my active working set and I want to make
sure that I have enough memory to hold
my active working set in memory right if
I want those queries to be fast
alternatively if I'm you know
maintaining an archive and I don't care
if it takes you know sort of disk epochs
of time then I might have a very small
amount of memory and again if this is
running on a thousand servers it's the
same pictures whether it's running on a
single server you want to be thinking
about the size of the amount of RAM in
your database to the size of the total
database size and what amount of that
actually needs to be in memory and don't
forget about your indexes they take up
memory - - in your file system I
couldn't come up with a cool picture for
this but it turns out when we go look at
people having performance problems on
their database you know again this is
not unique to Mongo this is whether
you're running my sequel or Oracle or
anything a little Oracle's totally
different things and forget I said that
Exe three is like 10 years old folks
like we shouldn't be running it in
production it is ancient technology ruin
ext4
or XFS these are much much better file
systems I don't know a lot about Gluster
but I want to learn more it seems like
interesting maybe you'd be a great thing
to run your database on hopefully the
next guy can can tell you more about
that but basically the thing that's
really slow about AFC 3 in the case of
MongoDB is when we need to pre allocate
a file we need to allocate like 2
gigabytes of zeros against
three it actually needs to go right to
gigabytes of zeros to the disk I know
it's crazy right you're not even
accessing that data well an EFT for an
XM s you can just say yeah there's
theoretically two gigabytes of zeros
here and I don't actually have to write
them right it'll just do that for me the
other thing most file systems by default
have access time turned on so every time
you access the file it goes and updates
the file to say it was last access now
you know this is really convenient when
you're like looking at your directory of
PowerPoint presentations try to figure
out like which one you open yesterday
but for a database it's terrible right
because of every page of your database
that you read you're actually writing to
your database you're writing to the
underlying file system that's gonna slow
your database down to a crawl
turn off access time tracking again this
is not unique to MongoDB any database
you're running you should do this choose
the right disks so there was a great
talk at Austin the other day about you
know what every engineer should know
about disk drives okay so the disk drive
it doesn't matter whether you're buying
a 15k SAS drive that you're paying way
too much money for or like a 5400 rpm
like little two and a half inch drive
these things
regarde in a database it doesn't really
matter what your serial read and write
performance is and those are the numbers
that those guys quote about these disk
drives the thing that really matters is
seek time because most of the stuff
you're doing is random i/o and seek time
is governed by a mechanical arm that's
got to swing over the disk there's just
no way that's gonna be as fast as like
flipping a bit in the transistor so the
average disk drive we find a good
assumption is it can do about 206 a
second you know and this is true for a
15k stash drive it's also true for much
slower drives right the the faster
drives are going to transmit bandwidth
quicker but turns out doesn't really
matter for most fan most database
applications so if your database is on a
single disk you're gonna be able to do
if your cache is cold and you start
sending queries max my guess you're
going to be able to do about 200 queries
a second right if you run to raid 0 what
raid 0 does it striped your data across
multiple disks now in this picture I
have three disk drives each of them can
do 200 seeks a second now with my
database of the cold cache when I start
running assuming it's a random access
I'm probably be able to do about 600
reads a second write again cuz every
reads gonna hit this
we run raid 10 I'm doubling up I have a
mirrors of each of my sections of data
now I think I'll be able to do about
1200 reads per second right so I've gone
from 200 1,200 6x performance by adding
6 disk drives
go figure 6 times 1 and yeah so anyway
choose the right disks raid matters and
oh yeah yeah SSDs are awesome you know
an SSD is like 0.1 milliseconds to do a
seek versus 5 milliseconds to do a seek
on a drive so it's not free but an SSD
in your database
especially for a random access database
it's going to be great shard so it's
really if your application is slow if
you're using bad indexing strategy if
you have slow disk drives most of stuff
is going to matter you want to optimize
the performance of your your software on
a single node you know and do that
before you really about to worry about
scaling out scaling outs gonna add a lot
more complexity than running a single
database server so I would recommend
doing those other things before you even
get to the point of trying to run a
charted cluster with Mongo right a Mongo
charted cluster lets me spread my
workload over many many more machines I
can basically spread my data over
multiple clusters of resilient replica
sets of my data so in this picture I've
got 4 shards simplistically I can think
about this as range based partitioning
so if I'm storing user IDs I might have
user 0 through 10 over here 10 to 20
over here and so forth you can continue
my counting and then within each shard I
have replicas of the data so I have a
single writable master and I have
multiple copies of the data right a
cluster like this we can scale out to
hundreds of servers or some of the
largest production deployments that
running today each one of these is going
to be able to process thousands if not
tens of thousands of writes per second
again depends on your workload depends
on your disk drive depends on your
working set size depends on your query
optimization your index choices got
optimized all those things but this is
going to be a very very high performance
cluster you're going to be able to add
additional capacity to it by adding more
servers and you're going to be able to
you know multiply those gains you have
of having good queries good disk drives
good file system configuration and a
great database Thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>