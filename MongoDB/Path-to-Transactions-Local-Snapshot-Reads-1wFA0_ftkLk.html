<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Path to Transactions - Local Snapshot Reads | Coder Coacher - Coaching Coders</title><meta content="Path to Transactions - Local Snapshot Reads - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MongoDB/">MongoDB</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Path to Transactions - Local Snapshot Reads</b></h2><h5 class="post__date">2018-04-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1wFA0_ftkLk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi and welcome to our video series on
the path to transactions as you guys
know MongoDB is coming out with
transactions in forw but we didn't get
here overnight there's been plenty of
projects along the way to help provide
this functionality to you and one of
those is the local snapshot rates
project and we have tests here today to
talk us through it
so tests if they lead engineer on the
replication team I'm Allie Cooper all a
product manager on the core server and
let's get started so for this past
release cycle I've been working on the
storage team helping to build the local
snapshot reads project so local snapshot
reads is an important building block to
multi document transactions that allows
you to read from a single point in time
across multiple network operations so
let's take a look at how you'll be able
to run a local snapshot read in MongoDB
400 so the first thing that you're going
to do is start a new transaction with
read concern level snapshot so this read
concerned snapshot indicates to us that
all of the reads performed as part of
this transaction should be done from the
same a point in time so then you can
open up a cursor say finding all
documents that match some particular
filter and then you can iterate the
cursor and now behind the scenes while
you're iterating this cursor the driver
may actually be doing several network
operations because it does your initial
find returns back a batch of data but
maybe not all of the data fits in one
batch so then as you keep iterating it's
issuing get more operations to the
server until you've iterated everything
that you want to iterate so if you have
like a million documents that had a
equals five good match you don't want
that all returned at once instead we do
it in batches exactly so behind the
scenes we're doing several network
operations potentially rate and then
finally you can commit your transaction
or abort your transaction so you might
wonder why do I need to
commit or abort in my transaction if
it's read only if I don't have any
rights that I'm trying to commit and the
reason is that while you're holding on
to an open wire tiger snapshot so say
your snapshot is here you have time
moving forward so as this snapshot is
getting kind of older and older that's
putting more cash pressure on wire tiger
so when you if you commit transaction or
a board transaction will release those
resources
releasing cash pressure on wired tiger
right so like basically an abort or
commit tells you you're done with these
resources and I can go ahead and start
cleaning than that phone is everything
exactly that you're not going to be
reading from this snapshot anymore so
it's safe to release it perfect yeah and
if you don't do this in time then we'll
just kill that for you so you don't run
into issues hope you don't take it away
in killing so oh and the local snapshot
reads part is that you'll only be able
to do all of this on a single replica
set in MongoDB for Oh the grander global
snapshot reads that you can do on an
entire shark charted cluster I will be
coming later okay so to understand how
we built this let's just take a look at
how normal query execution works in
MongoDB today so this is a client-side
code this is like server code yes this
is very high level my gonna be a surfer
tends to fit onto one fly so let's
imagine we're doing the exact same thing
so you have some find operation and
you're matching against some filter for
what documents to return and let's say
for sake of example that this is doing a
collection scan so we're going to have
open a wired Tiger cursor which is doing
the actual collection scan and so while
we're trying to fill up your batch
we'll iterate our biotech our cursor
will check if the cursor matches sorry
we'll check if the next to document
matches the filter and if so then we'll
add it to our batch and and this is the
part that I really want to look at is
this yielding so periodically while your
query is running in MongoDB we will
yield in order to allow other operations
to progress so there are a few steps
that happen in yielding so the first we
will check for interrupts so an
operation can be interrupted if either
it exceeds its max time ms or it's been
killed due to a kill up or a kill
sessions so periodically while the
operation is running it will ask has
somebody interrupted me so the next
thing that we'll do is we'll save the
state of our wire Tiger cursor so we'll
tell the wire Tiger cursor remember
where you left off in this collection
scamp's okay next we will release our
locks and release our wire Tiger
snapshot so we release our wire Tiger
snapshot for the same reason that I
discussed earlier as time is moving
forward and your snapshot is getting
older and older
that puts cache pressure on wire tiger
so we want to release those snapshots at
so that a wire tiger has not under so
much pressure
and we'll also release our locks because
that allows DDL operations to make
progress
so even normal queries are using wire
Tiger snapshots is that what this does
same exactly normal queries are doing a
snapshot read reading from a single wire
tiger snapshot until they yield and
release that snapshot and we'll see what
happens next so after they've released
these resources they'll reacquire their
locks and they'll reacquire a wire tiger
snapshot but not the one they were
reading from before they'll acquire an
or one because when they released the
previous snapshot that was indicating to
wire tiger you don't have to remember at
this point in time anymore and now we'll
start reading again from a newer point
in time right right so like each like
event I guess or batch each yield each
yield
yeah each yield is a single point in
time but beyond that it could be
multiple points in time exactly yeah
so then finally once we have acquired a
new biotech our snapshot we will tell
ryo tiger cursor to restore its state so
we had told it remember where you left
off in the collections gap and now
magically even though it's reading from
a new snapshot in wire tiger it can pick
up exactly where it left off in that
collection scan so that is our normal
yielding process so yeah we do this for
a while we try to get documents to add
to our batch and eventually we fill up a
batch and we return it back to the user
ok so normal query execution so I think
you've started to infer what snapshot
read execution looks like so basically
for a snapshot read out we want to do
all of the same yielding behavior except
we don't want to release our locks and
we don't want to release our wire tiger
snapshot so we don't release our wire
tiger snapshot so that we continue to
read from the same point in time no
matter how many times the query is
yielding right and we don't want to
release our locks basically because we
don't have a multi version collection
catalog so if like we're reading from
like this point in time and we were to
allow like some index builds or
something then the in memory state from
the newer point in time would no longer
match up with the snapshot that we were
reading from and it would be confusing
so instead for a snapshot we will simply
hold on to our locks for the duration of
the operation right cool so I'll still
like check
interrupts because you can still kill a
snapshot read very importantly yes but
only operations can be killed when
you're yielding right like so an active
operation on a process can't be killed
because it needs to like yield at some
point I don't know in order to know it
right exactly it's not going to kill
itself until it's notice that somebody
has killed the operation right yeah so
to build snapshot reads basically you
know we're putting an if statement
around these two operations so it
doesn't look like a very difficult
project and it shouldn't be difficult
right because wire tiger already gives
us the ability to do snapshot reads
right all we're doing is not abandoning
and reacquiring snapshots and wired
tiger right so yeah so this was pretty
easy for a single Network operation so
the challenge was more in how we're
going to read from the same point in
time across multiple network operations
which is ultimately our goal right so
the way that we read from the same point
in time for a single operation was to
not really start locks and not release
our wire tag or snapshot so now we need
to find a way to do that when we're
having multiple network operations that
are reading from the same point in time
so basically we need some kind of notion
of like a user session where we can hang
state like these locks and the handle
tour wire a tiger session across
multiple network operations so you
talked to Jason last time about building
the logical sessions project and MongoDB
so that's out what we're going to use
because a session is an entity that
logically encapsulate all of the users
operations like for some given period of
time and it can be used to associate
State among multiple user operations
such as locks and
your snapshot so the session holds all
of the context across these network hops
yeah yeah exactly
okay and also snapshot reads and
transactions are required to run inside
of a session
so we're guaranteed to have some place
to hang this date so let's take a look
at how this works
so here is our Mongo d instance and
inside it has some session object which
belongs to some user and when a find
comes in a snapshot find it's going to
take some locks and open a wire tiger
snapshot and then when it's done before
it sends a batch of results back to the
user it will just hang up these locks
and this wire tiger snapshot handled in
the session before returning its batch
and then once we get another get more
operation which is trying to get more
results from the same cursor it can just
pick up the locks and the wired tiger
snapshot handle from the session use
those while it's running and then hang
them up before it returns its batch back
to the user so we might have you know
this happening several times while we're
iterating the cursor and then eventually
we'll have a commit transaction or an
abort transaction command come in which
tells us that it's safe to release these
locks and release this WyoTech or
snapshot because we're not going to be
reading from that point in time anymore
perfect so this just can happen across
multiple operations and all that good
stuff yeah exactly
no matter how many get mores we have its
able to use the same exact resources out
of the session perfect so and you may be
wondering why did we need sessions to
build it because we actually do have a
way to
stated cross-up find it and get more
because we have the cursor like the
cursor from remembering like where you
left off and so the answer is we could
have implemented snapshot reads that way
if that were our only goal but we had a
larger goal in mind we wanted to build
full multi document transactions so the
reason that we're going to use the
session is in order to associate State
across all of the operations in a multi
document transaction right so like all
of the multiple statements that you have
within the transit transaction itself
can be reading from the same point yeah
exactly when you open up a transaction
with read concern level snapshot we want
to read from the same point in time for
all of the operations that you run so
you might additionally have like and
update in here that wants to read from
the same point in time you could even
have like multiple cursors open at once
that are all reading from the same point
in time so we don't just want to
associate that at snapshot with a
particular cursor we want to associate
it with all of the operations happening
in the transaction yeah and oh le only
one of these can be happening at a time
because we don't only allow one
operation to be using the session or
using a transaction at a time so each of
these can safely you know come in pick
up these resources execute hang the
resources back up and then return back
to the user and then another operation
can come in and use the same resources
right so they can kind of share the
context but not all at the same time
they're kind of passing off the contacts
to each other yeah exactly this all will
be sharing the same context so this is
basically how we utilized wire tagger
snapshot reads and logical sessions to
build local snapshot reads and use local
snapshot reads and to build multi
document
actions awesome thank you so much Tess
for walking us through that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>