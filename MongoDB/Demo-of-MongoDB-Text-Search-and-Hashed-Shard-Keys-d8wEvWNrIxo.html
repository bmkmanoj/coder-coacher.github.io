<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Demo of MongoDB Text Search and Hashed Shard Keys | Coder Coacher - Coaching Coders</title><meta content="Demo of MongoDB Text Search and Hashed Shard Keys - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/MongoDB/">MongoDB</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Demo of MongoDB Text Search and Hashed Shard Keys</b></h2><h5 class="post__date">2013-01-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/d8wEvWNrIxo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so the last number we'll talk about is
380 380 is the most voted on JIRA case
number it is the feature I get asked
about more than any other feature in the
last four years and so if so the server
380 is text search basically being able
to have text search embedded in Mongo
and what does that actually mean it
basically means that people want
something that is fully integrated right
you want to go to store blog entries in
Mongo and be able to search for things
in a fairly natural way and you want to
be simple right you want it to be able
to say hey I just want to create a text
index on this in Spanish and not have to
you know go and implement a whole second
stack I don't have to look you know
right now it's very hard because you go
to take Mongo you've got to hook up
something to it and you've got to do all
that work and then you've got two
systems to run which is obviously
challenging you know a lot of people
have also asked for something that is
fully consistent right a lot of the
external solutions what they do is
they'll take Mongo and they replicate
Mongo into something else and that's
pretty good for some things but it's
also not fully consistent right so if I
go and add a new blog post it may take
five minutes or a couple of hours for it
to show up in my search index which is
definitely not ideal and one of the
things we thought a lot about is you
know this is not going to solve every
research problem in the world we're not
trying to build something we're not
trying to replicate the scene we're not
trying to build a whole new search
system what we're trying to do is build
something that covers 80% of these cases
you know I've got a blog and it's
written in Mongo I've got an e-commerce
site and I want to start four products
where the search is pretty simple but
you want to be able to to do some basic
things so let's take a look at how it
works and then we will in the process we
can talk about a couple of other
features
so first I am going to spin up a this is
on a machine I'm gonna spin up a small
twenty four shard Mongo cluster on a on
a dev machine we have so we'll just let
that spin up and one of the features
that is coming out in two four in
addition is hash shard keys so this is
another feature that people have been
asking for a lot and it's backed up for
a second
so sharding and Mongo is range based so
if you have a 24 start so let's make a
26 charge cluster the weight and you
start on last name the way it would work
is every it's like a phone book if your
last name starts with a you go to one
shard be another shard see another shark
which is great for a lot of use cases
but sometimes you want to just
distribute things completely randomly
raise it we're not randomly but you want
them completely evenly distributed you
don't really need sort of the range is
to be consistent you just want to be
like hey this document list somewhere
and so that's a feature called hash
start keys so which is which is coming
out in two four and so we can do it and
this basically what that means is as
soon as you turn on starting with the
hash tag keys you get perfect
distribution of data and perfect
distribution of load so we're gonna say
shard collection and a little precursor
so test on and run and we're gonna say
you know normally you would say this
which is basically two shard your
collection on underscore ID now if you
want hash are keys you change that to
hashed so now it's going to create this
as hashed and what you can see is that
instead of having you know for people to
be charting before it instead of having
one chunk on a single shard you've got
two chunks on every single shard so your
data is distributed very evenly
instantaneously alright so now we've got
that now we've got this set up so now we
need to now we need to import some data
so let's go ahead and we've got the
Enron email data set and beast on format
it's about 1.4 gigs so we can go ahead
and import that and this will take this
will be pretty quick
so it's in right now it's just there's
no search on it at all right now is just
importing the full one point four gig
data set okay so now we can go look at
it and what we'll see is that you've got
all these shards in the number of
documents per shard is pretty consistent
right about twenty thousand documents
for shard and it's all very evenly
distributed okay so that's pretty nice
so now we've got perfectly evenly
distributed data set we're able to
import the one point four gigs in about
you know ten seconds and so now we're
ready to now we want to search it right
now we want to actually see what's in
this data set so now we're we want to
create an it now we want to create a
text index so we're going to create an
index just like any other index but
instead of saying one we're gonna say we
want to index the body as text and we
want to index the subject that's text
and so now this is going handing and
creating a text a text in s and this
will take about one minute and so while
we do that let's just take a look at
what text search actually is so let's
make a look a little simple example so
let's say you've got posts and data
lying around so let's go and insert some
documents of tamago so we're gonna have
a title of welcome to Mongo sv and text
of Kongo sv will be a lot of fun
okay now we're gonna create an index on
this same way
sorry it's alright
now we can do a search and we'll add
some helpers to make this easier but
basically we can search for now we can
search for Mongo SV and then it will
basically give you a search and you get
scores and you can do some interesting
things with this you can do things like
negations you can do things you can do
phrase matchings it supports currently
it supports a lot of Latin languages so
it does a lot of the a lot of the
European Latin languages and it'll
basically do basic splitting and
stemming of words and so if we had
running and running it does all the
right things alright so we created our
Enron index so now if we go ahead and
look at this index we'll see that
so the data size is at 1.4 gigabytes the
the text index on the full body and the
subjects is about 2.6 gigs and so now we
can search it right so we can do a
simple search
and we get some results and to make this
a little bit easier to look at
we built a a very tiny UI which you can
actually all hit from your tree running
apparently so you connect if you get a
is you can tell where this is running
it's running on my desk if you go to
office Engine comport three three three
three you can actually go ahead and do a
search so you can search for guess which
word grandma you can search for all
sorts of things and I think this works
too the Internet is a little slow you
can search for that you can basically
just go to this and search for it search
the entire Enron email data set pretty
pretty simply so so what does this
actually mean so you know this is pretty
simple it does support lots of languages
it supports negations and phrase
matching and- phrase matching and what
we really need them most
what we really need the most to actually
figure out what to do with this feature
is is help we need help testing it and
we need help sort of understanding how
people want to integrate search with
Mongo you know this is the most
requested feature in long ago it's been
it has been for almost three years but
we need a lot of now is the datasets the
help tests and the examples to use and
what I think it's going to happen is
this is going to probably go in two to
four as an experimental feature so that
you can try it as we can get a lot of
learning from it and then so we can
figure out exactly what features we need
to add to it over the next couple of
years to make it something that people
can really use for a wide range of
applications overall we're pretty
excited about it and we're pretty
excited about hash shard keys because
that does make a lot of deployments and
a lot of the administrative things a lot
simpler so if you do want to bring up a
very large started to cluster it is much
simpler if you get going and especially
if you want to import a lot of data very
quickly right the best thing about it is
that if you've got a huge data set and
you want to import it evenly throughout
your entire cluster as fast as possible
this makes it considerably easier to do</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>