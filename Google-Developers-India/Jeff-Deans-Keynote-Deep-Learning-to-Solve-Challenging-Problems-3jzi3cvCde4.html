<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Jeff Dean's Keynote: Deep Learning to Solve Challenging Problems | Coder Coacher - Coaching Coders</title><meta content="Jeff Dean's Keynote: Deep Learning to Solve Challenging Problems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Developers-India/">Google Developers India</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Jeff Dean's Keynote: Deep Learning to Solve Challenging Problems</b></h2><h5 class="post__date">2018-04-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3jzi3cvCde4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so my name is Anand Rangarajan I'm the
site lead for Google Bangalore and I'm
very excited to be the program manager
with Pankaj Gupta for this con for this
workshop I just wanted to tell you that
you know this is the first time we're
doing a big outreach to the both the
academic and the industrial communities
here about the work we have done and the
problems with that we are still working
on we are very excited that diverse set
of people from the industry and academia
are here they're going to share their
work they're going to share the kind of
problems they are working on so
Bangalore Google bangle itself was
started in 2004 so it's it was one of
the very early engineering sites for
Google outside the US we've always been
fairly small and now we are starting to
show some significant growth yes there
are lots of chairs here please do come
along yeah through this day we are going
to have several tracks looking at
different aspects of ml and AI we will
usually have these tracks such that
there will be small 10-minute talks and
then there'll be a final ten minute Q&amp;amp;A
so if you can collect your thoughts and
then ask them at the end it might be
useful and there is the Wi-Fi
information TV yeah okay for people who
want to use the guest Wi-Fi there are
restrooms there please do try and take
breaks between talks and then during the
coffee breaks we will have the PhD
students with their posters in the cafe
so if you are curious about the sorts of
problems they're working on you can go
there anything else Pankaj yeah so for
any logistics is Ashwini there and where
is Divi who was right around here it is
tapped out
so that is that is the guest Wi-Fi
access point name and the password
alright with that we will start the
keynotes so we have we are very excited
because we have people visiting us from
us and you also have people dialing in
later in the day you will also hear some
leads in a Google Bangalore speak about
their work so after thanks Allen my name
is Pankaj Gupta I'm also an engineering
director at Google in Bangalore I lead
the engineering for consumer payments
app called taste that's part of Google's
next billion users initiative I joined
Google about eight months ago Google
acquired my deep learning startup called
Holi labs and in fact in one of the
sessions we are going to hear about at
least what one part of Holi labs was
doing later on in the day so okay / -
cue notes but let me introduce you Jeff
and then we'll play the video and then
we'll let you do the slides so I'm
really really excited to kick off this
workshop with a keynote by none other
than Jeff Dean the title of his talk is
deep learning to solve challenging
problems
Jeff joined Google in 1999 and is
currently a Google senior fellow in
Google's research group where he
co-founded and now leads the Google
brain team Google's the deep learning
and AI research team he and his
collaborators are working on systems for
speech recognition computer vision
language understanding and various other
ML tasks he has code design and
implemented many generations of Google's
crawling indexing and query serving
systems and co-designed implemented
major pieces of Google's initial
advertising and adsense for content
systems he is also a co designer and Co
implementer of Google's distributed
computing infrastructure including
MapReduce BigTable and spanner systems
protocol buffers the open source tensor
flow system for Emily and a variety of
internal and external libraries and
developer tools
Jeff received a PhD in computer science
from the University of Washington in
1996 working with Craig chambers on
whole program
combination techniques for
object-oriented languages he's a fellow
of the ACM a fellow of the American
Association for the Advancement of
Sciences and a winner of the ACM prize
in computing and the Mark Weiser award
so please welcome Jeff let me play a
video that's a really fun video about
tensorflow
we wanted to make machine learning at an
open-source project so that everyone
outside of Google could use the same
system really awesome we'll just switch
over cool all right well so thank you
very much for having me what I thought I
would do is just give a talk about sort
of some of the work that our group has
been doing on machine learning research
and some of the ways that we think it's
gonna impact some difficult problems in
the world so with that I'm gonna just
switch to sharing slides and that I will
come back in facial form at the end of
the talk let's see here great there I am
can you see that sorry wrong button yes
we can see Thanks great okay so one of
the first things is that the interest in
deep learning has really gone up
significantly over the last
six or seven years part of us is because
we've created a new term for something
that is actually fairly old so deep
learning is sort of a rebranding of the
idea of artificial neural networks but
it's a bit more than that as I'll
discuss so there's tremendous interest
in the machine learning field there has
been for quite a while but in the last
six or seven years that growth has
really taken off this is a graph of the
number of machine learning related
archived papers that have been published
per year on a paper preprint hosting
service called archive and you can see
that it's growing it actually faster
than the sort of Moore's Law exponential
growth rate of computational performance
that has been with us for quite a while
although that's not slowed down but this
field is changing extremely rapidly and
I think and many many people are
flocking to this field and are wanting
to do new research and are doing great
new things in this field I think this is
a really exciting thing you see lots and
lots of young students lots of people in
other disciplines wanting to sort of
start doing research in this field lots
of use across the industry and
organization that's that's tremendous
but as I said deep learning is really
just this modern rebranding of many of
the ideas in artificial neural networks
which have been around since the 1970s
and 80s I actually did a thesis on
parallel training of neural networks in
1990 when I graduated from undergraduate
and the idea behind neural networks is
actually a powerful one which is that
you can learn very complicated functions
through these layers that learn features
and patterns at sort of progressively
higher and higher levels of abstraction
so at the very early layers of a neural
network the features that are learned
are fairly primitive but as you combine
those powerful feature recognitions
ah pattern recognitions then you get
more and more complex combinations of
these things so many of the ideas are
relatively old in neural networks
there's been a bunch of progress as you
can see by the previous graph of the
number of research papers which is also
great but let me just go over some
pretty interesting functions because
when you here oh it can learn functions
you know sometimes that doesn't quite
resonate with people about how powerful
these think can be so one kind of
function that a neural net can easily
learn is given enough training data of
pictures and then labels of what kind of
object is in that picture it can learn
to take a new picture the raw pixels of
an image and then learn to predict a
categorical label for that from perhaps
you know thousands or even hundreds of
thousands of categories they've been
used to powerful effect in improving
speech recognition so you can actually
train a neural network end to end going
from raw audio waveform signals to a
transcript of exactly what was said in
that audio waveform how cold is it
outside and this is in contrast to how
speech recognition systems have been
built for many years which is they have
lots of they previously have had lots of
individual components that are other
kinds of machine learning systems and
and manual features now we can just
learn these things end and with a neural
network these systems can learn to
translate given enough training data of
the form you know sentence in one
language sentence another in another and
so you can input a sentence in English
hello how are you and then have the
model trained to produce a translated
output bulger coma deli food perhaps
more surprisingly you can they can be
trained to emit not just a categorical
label given an image but an entire
English sentence that describes the
image which actually shows a pretty
decent level of understanding of what's
going on in these kinds of scenes so if
you give it this image
the output might be a blue and yellow
train traveling down the tracks so why
is this all really happening now as I
said many the sort of underlying
algorithmic ideas are relatively old and
so in the 1980s and 90s essentially
neural networks were showing really
interesting results for Verto problems
but they needed a very large amount of
computation much more than we had
available at those times and so they
couldn't really be scaled to work on
problems that were you know real and
substantial and impactful although they
did show really good results on sort of
modest size problems and so other
approaches that were less
computationally intensive kind of were
the preferred ones in a lot of machine
learning tasks through this time as you
have seen by the Green Line but thanks
to Moore's law we've actually gotten
much more compute you know what I did my
undergrad thesis I was excited about
bringing to bear a 64 processor machine
on training of neural network instead of
one processor so that we could get you
know maybe a factor of 50 or 60 speed-up
it turns out what we actually needed was
a factor of a million more computation
not 50 but now that we have that neural
networks are actually a the best
solution for many many problems and that
that gap seems to be increasing relative
to other approaches as we add more and
more compute which I'll talk about it
towards the end of the talk so just to
give you a sense of the improvement over
the last few years in 2011 the winner of
the imagenet challenge which is a
challenge hosted by Stanford University
every year where you're given an image
and have to give a label of one of a
thousand categories the winner of that
did not use a neural network and the
winning error rate lowest error rate was
26 percent error and we know that humans
have about a five percent error rate on
this task um it's actually a reasonably
difficult task because among those
thousand labels are you know perhaps 40
different breeds of dogs and you have
to get the correct breed of dog by
looking at a photograph which is not
something that humans really excel at
but fast forward five years every every
entrant now pretty much uses in real
networks and the best neural networks
are down around three percent error so
the winning entry in 2016 three percent
error below human level which is pretty
significant so basically computer vision
has gone from not really working that
well to working extremely well in five
years and that's pretty transformative
if you think back to the time in you
know biological evolution when animals
of all dies were sort of at that point
in computing today where we didn't used
to be able to see very clearly now we
can see very clearly and that opens up a
lot of a lot of things that we can do
that require vision work well so for the
rest of the talk
I'd like to structure it a little bit
around something that the US National
Academy of Engineering put out in 2008
which is a list of grand engineering
challenges for the 21st century and it's
a pretty good list it's sort of things
that I think we as a society if we make
progress on these we will actually you
know improve the world and live happier
and healthier lives so I've highlighted
a few in red that I'm going to talk
about but I actually think machine
learning is going to be a significant
contributor to making progress in all of
these I just don't have time to talk to
address exactly how but I will for the
red highlighted items so one of them is
restore and improve urban infrastructure
I've been to Bangalore and I've seen the
the chaotic traffic there and we have
our own traffic problems here in the Bay
Area but one of the things that we are
actually quite close to as a society is
actually having working self-driving
cars a completely autonomous cars
and one of the things that's really
powering the fact that we're so close to
to launching these commercially is the
fact that vision that works right going
from raw sensor inputs in these cars
where you have lidar which is like a
laser range-finding depth sensing sensor
plus a bunch of cameras plus radar data
to something that can actually
reconstruct what is going on around the
vehicle in a way that allows it to plan
safely what it wants to do to accomplish
the goals of getting to its destination
and not hitting anything and behaving in
a way according to the right traffic
laws you know that requires a pretty
high level of understanding but key to
it is that vision networks and so we've
actually just done some trials in
Arizona a couple of months ago without
any safety drivers in the vehicle so
that's actually you know a reasonably
good sign that these things are you know
imminently going to be released in
fairly short order across Laurel which i
think is going to be pretty pretty
different and will dramatically change
the urban landscape you know we won't be
parking areas as much we can have cars
just come pick us up at will when we
want to be pretty amazing advanced
health informatics so our group is
actually spending a fair amount of time
on how can we use machine learning to
improve healthcare and I'll touch on
just a couple of different issues here
one is we've been doing a lot of work in
medical imaging related tasks and this
is a task called
where you're trying to diagnose whether
or not a person's retinal scan has signs
or symptoms of diabetic retinopathy
which is a degenerative eye disease
there's about 400 million people at risk
many of them actually in India and these
are graded one two three four or five by
human ophthalmologists and one of the
big problems is that if you're at risk
for this you should get screened
regularly every year
perhaps even more often and there just
aren't enough ophthalmologists in the
world to screen all the people that
should be screened and so we built up a
training set of data of this form with
human ophthalmologists giving their
opinion on the image and then you can
train a computer vision model to assign
the grade in an automated way given the
input image you say one two three four
five and we're actually now
significantly better than human
ophthalmologists this this was a paper
published at the end of 2016 in JAMA
which is one of the top medical journals
showing that we were on par slightly
better than the median board-certified
ophthalmologist in the United States at
doing this task and we've actually
improved this algorithm significantly
since then so we're now on par with
retinal specialist rather than general
ophthalmologists we've also discovered
kind of interesting new findings in the
process of doing this this work and so
we've actually been able to devise
completely new biomarkers from retinal
images that we that human
ophthalmologists didn't even know
existed and so we can actually use these
kinds of predictions to assess someone's
cardiovascular risk in a way that is
roughly as accurate as a more invasive
technique where you actually need to
draw blood and assess the cardiovascular
risk through a series of blood tests and
so this is a sign of something where
we've actually been able to use machine
learning to create new kinds of
healthcare signals that previously
didn't exist because it's looking at
very subtle patterns that human
ophthalmologist can't really detect in
the eyes we think that's pretty exciting
another kind of medical problem that
we're focused on is predictive tasks for
healthcare so given a patient's medical
record data can we actually predict the
future and deep learning methods are
actually getting very very good at
sequential prediction tasks so given
in English sentence can I predict the
French sentence or given half of a
medical record can I predict what are
the other things that are going to
happen to a patient and if we can do
that well we'd be able to answer
questions like you know will this
patient be readmitted to the hospital in
the next week or you know what are the
most likely diagnosis for this patient
right now which test should I be
considering for this patient which
patients are at highest risk for say
developing diabetes in the next month
and so we have a collaboration with
several United States Organization US
healthcare organizations to try to
assess this and we've actually just
published a paper on archive that
essentially shows that we can predict
all these different kinds of tasks using
the same rough underlying model and in
particular compared to the baselines
techniques that are used in clinical
practice today we can actually predict
things like mortality rate or risk of
mortality roughly 24 hours earlier so
this solid line at the top of the graph
is about 24 hours earlier warning of
someone's risk of mortality been the
traditional dotted line baseline here
and so that allows doctors you know much
more early guidance about which patients
are most at risk and they can pay more
attention to those patients we think
this is gonna be pretty significant
another area is actually several of
these Grand Challenges all kind of
depend on better understanding of
chemical properties of things you know
engineering better medicines is all
about finding drugs that bind to the
right kinds of things solar energy is
all about developing you know more
efficient materials for solar panels and
many of the other ones are also related
to chemistry and so we decided to tackle
a particular problem in quantum
chemistry which is given some molecular
configuration you want to predict a
bunch of things about that molecular
configuration like does this bind with a
different protein what are its quantum
properties is it toxic and the
traditional way that you
this is with a traditional high
performance computing based chemical
simulator that uses something called
density functional theory and is fairly
slow so if you run it it takes maybe an
hour for a given configuration to give
you the right answers or the simulated
answers so we we decided we could
actually use this simulator this
computationally expensive simulator as a
trainer for a neural network and so we
developed a new kind of Network our all
network architecture that's good at
dealing with graphs the kinds of
chemical graphs that you see there and
what we found is that the results on
using this neural net and then using the
neural net to make these predictions are
indistinguishable and I can receive from
the the much more computationally
expensive simulator so we have something
that's about three hundred thousand
times faster at doing these kinds of
computations and is you know equivalent
accuracy and we think that's pretty
transformative you know anytime your
tools get three hundred thousand times
faster that just enables you to do very
very different things
you know you could imagine screening a
hundred million compounds and taking the
10,000 that are most interesting and and
doing more investigative studies of them
okay the last thing I'll talk about is
engineering the tools for scientific
discovery and this will be kind of a
whole collection of improvements to
varying kinds of tools so the first
thing is our group has been producing
software to help us with our or with our
own research and with deploying these
kinds of machine learning systems into
Google products and we've been doing
this kind of work for a long time and
tensorflow
is a system that allows us to Express
machine learning research ideas and get
results quickly and it's actually our
second generation system and when we
started working on it we decided we
open-source it so that people outside of
Google can use the same tools that we
use and we can collaboratively work
together to improve those tools
therefore you people outside have been
able to use it for all kinds of
interesting things like that
introductory video had a lot of
interesting uses of tensor flow that we
never imagined when we open sourced it
and I think that's one of the beauties
of open source software is that people
can take it and use it in all kinds of
crazy and and great ways that you never
would have and collectively society
benefits from this so we wanted to
open-source this so that it would be a
great platform for everyone and this is
kind of a growth charting of interest in
tensor flow measured by github stars
which is sort of a people can express
interest in different repositories on
github which is an open source hosting
platform and this shows the tensorflow
star growth stars over time compared to
a bunch of other open source machine
learning packages also hosted on github
and so you can see people have really
taken to tensorflow and that community
is now working actively collectively to
improve the system one of the research
projects that we're working on in our
group is actually attempting to automate
machine learning so that you don't need
as much human machine learning expert to
expertise to solve a new problem so the
current way you usually solve a machine
learning problem is you have some data
you have some computational devices
maybe GPU cards or maybe CPUs or other
things and then you kind of have an ml
expert a machine learning expert take
that and stir it all together and out of
that you hopefully get a solution to
your problem the machine learning expert
runs a bunch of experiments tries
different ways of solving the problem
and hopefully if you have enough data
and ml expert is is good you'll get a
good solution what we're trying to do is
see if we can turn this into a automated
process where we don't actually need the
human machine learning expert to solve
new problems and really
if we want to get the systems that are
generally intelligent we can't have a
human in the loop for every new problem
that we want to solve and so this I
think is a pretty fundamental thing that
we really need to make progress on to
really get towards more intelligent
systems that can do millions and
millions of different tasks but really
we want to see if we can use data and a
lot more computation to get good
solutions so the way this works one of
the ideas in the work that we're
pursuing is an idea called neural
architecture search so one of the issues
with deep learning is a human machine
learning expert normally sits down and
just makes a bunch of decisions about
what kind of network architecture
they're going to use is this going to
have nine layers or 17 are they gonna
have you know three by three filters at
each layer or four by four or seven by
seven how are they going to be connected
and so the idea behind neural
architecture search is we're gonna have
a model generating model and we're gonna
train that model using machine learning
using reinforcement learning actually
and so the model generating model can
generate a description of a network
architecture and then we're gonna train
and we can generate say ten of those
models and we're going to train each of
them for a few hours on the problem we
actually care about and then we can use
the loss the accuracy of each of these
generated models as a reinforcement
learning signal to the model generating
model so that we kind of steer the model
generating model away from experiments
that didn't work very well and towards
network architectures where the results
were very good and if you run this loop
many many times
you know perhaps training 20,000 models
you end up with models that are quite
good and so here's an example on the
left of a model that the architecture
search process came up with for a image
recognition task C 410 which has the
advantage that it's been very well
studied by the machine learning
community so everything except the last
four lines here are sort of human
generated new improvements of
state-of-the-art results on the C for 10
image recognition to ask and you can see
the error rate dropping over time and
this at the time we published the neural
architecture search work the state of
the arc was three point seven four
percent neural architecture search
automatically got to a model that got
three point eight four percent so that's
pretty promising
we then scaled that work up to image net
scale which is a much much bigger
problem it's the million images that are
sort of full resolution instead of sixty
thousand images that are very small and
this graph shows you the accuracy of a
bunch of different models for image net
and the the x-axis is the amount of
computation that each model requires for
to give you a prediction for a given
image and so generally more computation
gives you more accuracy so you see this
general trend and each one of these dots
here represents years of effort by sort
of the top machine learning researchers
and computer vision research groups in
the world and the really nice thing is
when we applied Auto ml to this we
actually can get a range of models with
different computational costs but each
of those models is better than the
corresponding human generative models at
that sort of level of computation and so
that's true both at the highest end
where you see you know much less
computation and slightly better accuracy
than the best state-of-the-art models at
the time this one and also true the low
end where you might have a very
lightweight model that you want to run
on a mobile phone and you see a pretty
significant jump in accuracy for
basically the same computational cost so
that's pretty exciting and so that's
kind of an early sign that we can
actually build these flexible systems
that with enough computation can solve
new problems automatically and the only
drawback is we're going to need a lot
more computation and so that actually
comes to another point which is that
neural networks and all the algorithms
that I've been talking about have two
really nice properties the first is that
reduce precision for all the
computations in a neural network is
generally just fine it's fine to do you
know one significant digit of precision
for the computations rather than lots of
significant digits and the other
property that they have is that there's
a handful of specific operations in
these models essentially nearly all the
computations are made up of of dense
linear algebra operations things like
matrix multiply is vector dot products
things like that so if you can build
computational devices that are
specialized at doing reduced precision
linear algebra then you have a chance of
really speeding up the kinds of
computational complications you can do
here and so we've been working in this
space for a while we've developed a a
set of devices called tensor processing
units and this is the second generation
one which is a device that's designed
for all that training and inference this
device is provides about 180 teraflops
of computation which is quite a lot has
64 gigabytes a very high-speed memory
and it's designed to be connect
connected together into larger
configurations that we call pods and so
each of these pods is 64 of those
devices and eleven-and-a-half petaflop
of computation of low precision
computation but just as a point of
comparison the number 10 supercomputer
in the world is about ten and a half
petaflop to compute out of higher
precision computation but still this is
sort of on that scale and this is sort
of a dedicated machine learning
supercomputer and we've actually made
these available externally through our
cloud products so people can rent time
on these cloud GPU devices essentially
get a virtual machine with a cloud keep
you attached we're also making them
available to researchers who are
committed to doing open machine learning
research so we have about a thousand of
these devices that were making available
to researchers who have interesting
projects and you can sign up at this URL
here by sending in a proposal and we're
excited to see what people will do with
this the only requirement is that they'd
be willing to
to publish the work they do so with that
I'd like to just highlight that I think
deep neural networks and machine
learning are really producing
significant breakthroughs that are
solving and are going to solve some of
the world's like Grand Challenges which
I think is tremendously exciting if
you're not thinking about how to use
null Nets to solve your problems you
probably should be and if you look at
our team website gqo slash brain and
also intensive flawed org you'll find a
lot more information in particular the
brain website has lots and lots of our
papers and more information about each
of the sub areas that were working in
and with that thank you very much and I
will now I think you know this and go
back to not presenting but every time I
see them I'm like wow I'm really
inspired I think at least some of us or
most of us in the room aspire to do
research with that kind of exponential
curves so thanks a lot we we we want to
do some Q&amp;amp;A anyone has any questions
okay hi Jeff Manish Gupta thanks for a
great talk so you talked about in
machine learning deep learning to on
healthcare problems right predictive
problem so in our experience what we saw
was even when you have very high F
scores let's say off the order of 0.9 5
and so on f1d because of the class
imbalance you still run into the problem
that the number of false positives is
still higher than the number of true
positives for many many predictive
problems so have you been able to kind
of overcome and of those kinds of those
challenges I mean get accuracy high
enough where you are actually true
positive I mean you're false positives
not much more than the true positives
yeah I mean I think obviously if you
have kind of rare conditions one of the
things you can do is enrich the training
set that you have to make sure that you
have more balanced coverage of the rarer
conditions and the more common
conditions and then correct for the sort
of adjustment you made to the background
probability in enriching the training
set when you're doing testing and that
can really help a lot and so that's the
general technique we use for that and
also these things allow you to sort of
control the false positive versus false
negative rate with different threshold
and you know choices and one thing I
forgot to mention about the diabetic
retinopathy worked we've actually been
doing we've actually concluded clinical
trials in India working with the Arvind
I Hospital Network and we're now
actually doing patient treatment using
this model actually we are gonna hear
from Erin Wilson in a session later
today about exactly this work back
signet-ring
yeah he will give you many more detail
more questions for Jeff hi Jeff thanks
for a very interesting talk is this
parcel from IC Bangalore so like you
know there is this a well recognized
problem of explained ability in AI and
machine learning I just want to hear
your thoughts on that yeah I mean I
think it is a definite problem for some
kinds of domains you know I think there
are some problems where you just want
the most accurate thing possible and you
don't necessarily care much about
interpretability or explain ability but
there are other domains where it's
actually very important to have the
system be able to give you some insight
and intuition about why it's making a
certain prediction you know I think
healthcare is one particularly good one
it where you really do care about that
if you it's much more actionable and
usable for a doctor if you can say
something more than patient needs heart
valve replacement right it's better if
you
patient needs heart valve replacement
and it's because I see this like brief
description in a medical note from two
years ago and this test result is a
little elevated and this other
commission right and so we're doing a
fair amount of work in our in our group
on interpretability
of medical images i think you saw on the
the retinal images where we can now use
those as a new cardiovascular health
metric one of the things those models
are able to do is to describe what
pieces of the eye and the retinal image
they're actually looking at when making
those different kinds of predictions and
so I'd encourage you to look at a
website called distilled that pub which
one of my colleagues Chris Ola and sham
Carter are actually publishing a series
of articles there about how do we make
models more interpretable I may have
some really nice investigations of
visual models and interpretability for
those okay one more hello yeah hi Jeff
I'm in buff from Docs app so I'm a
health tech startup and then we are now
building systems keeping you know data
and science and learning you know at the
back end of our product so one of the
challenges we generally see is that the
volume of data in medicine is lot less
especially quality annotated data
compared to say another field likes a
bit images imaging or you know biet or
you know automated driving and so on so
how do you overcome these challenges and
how do you work with you know people
from a different community say the
medical practitioners for example and
how's that option because finally for a
tech to be useful adoption on the other
side as well as needed right yeah
absolutely I mean I think I would say
that healthcare is a you know
challenging space to operate in for many
reasons first of all the data volumes
every individual healthcare organization
generally has are modest not enormous
and so that sometimes means it's more
difficult to get the accuracy you might
want a pretty good problem there's lots
in you mean
it states especially there's lots of
regulatory challenges for deploying
machine learning models you know you
need FDA approval for many kinds of
things there's very real and valid
privacy concerns people have about their
healthcare data but in general we make
partnerships with healthcare
organizations and the ones we've been
doing the United States so far we've
sought out healthcare providers that
actually have pretty significant size
data sets we ask them to de-identify the
data set so we don't actually get any
personally identifying information for
these data sets we just kind of get the
medical record without knowing who it is
are a large collection of medical
records that allows us to do the
research that we need to do to show that
these models can have very high accuracy
for these tasks that we care about and
that I think is the beginning of a
dialogue of how do we actually you know
you know that generally gets the
healthcare organizations excited when
you can show that you can predict
something they really care about with
high accuracy and that then sort of
loosens the relationship a bit and makes
it much easier to actually figure out
what are the next steps how do we
actually take something like this and
actually really deploy it and you know
maybe get more data maybe you know label
a bunch more data in appropriate ways
and so lots of things like that I think
can lead to to sort of more rapid
adoption and success in this space
thanks a lot Jeff thank you so much for
your time I think that's I know there
are other questions but we'll have to so
thanks Jeff thanks very much enjoy your
day
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>