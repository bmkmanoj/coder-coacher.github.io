<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TechSession - Demystifying Machine Learning with Amrit Sanjeev | Coder Coacher - Coaching Coders</title><meta content="TechSession - Demystifying Machine Learning with Amrit Sanjeev - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Developers-India/">Google Developers India</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TechSession - Demystifying Machine Learning with Amrit Sanjeev</b></h2><h5 class="post__date">2017-05-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/WHw4tH9R44U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">
AMRIT SANJEEV: In this session,
we're going to talk about
machine learning from a
30,000-feet-high model.
I'm not going to talk
technology here today.
But the whole idea is
at the end of this talk,
if you guys go back and read
a paper on machine learning,
you don't need a
dictionary to understand
what is written there.
A lot of times, people have
a lot of misconceptions
about what's there.
They misinterpret certain
things for something else.
Those sort of things
are what we want
to avoid by doing this session.
A quick show of hands.
How many of you guys
are developers here?
Wow, a good number.
How many of you guys have
dabbled in machine learning?
Only one guy I have
to be scared of.
But that's Rupert.
It's fine.
A good friend.
But again, the
agenda is we're going
to cover what's machine
learning, how it's
different from artificial
intelligence, which kind of
gets interchanged and used.
Breakdown of some
of the buzzwords.
Quite a few out there.
This is a really
hot topic today.
So quite a few of
those buzzwords.
What they mean and what
you should understand
when you see them in articles.
Some of the Google tools
that we have released lately,
which allow you to kind
of get into this field
much easier and kind of apply
them to the apps or solutions
that you're building.
And maybe how you can go
ahead and improve your team
towards the end of it.
I'm not going to be
talking about this guy.
Whenever we talk
about machine learning
or artificial intelligence--
OK, the doomsday and all
the other theories come out.
But we are not talking about it.
We'll reserve it
for another day.
And in short, we'll
try and understand
some of the words,
some of the concepts.
So that when you read the
more complicated stuff,
you have the base ready for it.
To start with, when you
say machine learning,
it's about a program
that can actually
learn from its experience.
That experience could
be data that you
feed into it and the
additional information
that you provide to it.
Again, it will
also kind of change
and it can adapt
based on the new data
that you provide to it.
So as situations change,
it's adapting to it.
A very simple
example to call out.
If you were writing
a tic-tac-toe game,
if you're telling it
how to win, you're
telling all the rules
by which it wins.
All the if loops
and conditions you
write into it, that's
logical programming.
That's what most of
us are used to doing.
That's what most of the programs
that we work with actually
work like.
We give it the conditions
to create the outcome.
We also ensure
that those outcomes
are achievable repeatedly by
running those rules again.
In machine learning,
if you were to do it,
you are going to give it
a collection of games.
It will go through
those games, understand
what a win outcome is,
what a loss outcome is,
and what are the rules to win.
And it will interpret by
learning that through the input
that you give.
So in any machine
learning system,
you have two phases to it.
One is a training phase where
you're providing information
to understand all
of these aspects.
Second is the
application phase where
using that information
or the model
that you have developed to
kind of apply to a problem
that you're getting.
So initial, the training
phase is something
that we will do before
you release your solution.
And then you take the model
that you've created, and then
apply to input from real
world, and then change it.
There are multiple
ways you can do it,
so let's go down
to some of them.
Before we jump into
that, why is it
becoming such a popular
buzzword right now?
The reason there is there's
real-world large enough data
sets now, and technology
to work with that.
And machine learning
requires a lot of data.
1,000 data points or 10,000
data points is not enough.
It needs a lot of data.
There are multiple factors,
like learning coefficients
and things like
that, that you alter
in your machine
learning algorithms
which makes it difficult if--
the errors will
increase if you actually
make them try to learn too
fast with too little data.
And that's why
the training phase
has to be something that you're
going to take care of well.
And now we have hardware.
We have specialized
hardware for it.
We have computational
capability for that working
with such large data sets.
Most of these large sets can't
be even loaded into memory.
They're so large that you
have to use a streaming model
to kind of get them working.
So we have technology
which is there.
Advances in hardware
makes it well.
We're also getting
into the phase
where problems that
we solve require
some of these sort of
mechanisms and techniques.
It can't be based on rules.
If you were to make a machine
learn how to play a game
or navigate a maze, you cannot
always rely on rule-based
systems.
You want systems that
adapt to the environment.
And they're more efficient.
And sometimes, more efficient
in solving problems for us.
And how is it different from AI?
So when you talk about
artificial intelligence,
there is more aspect
than just learning to it.
Learning definitely
is one aspect.
An artificial
intelligence system
will learn from its
environment and from its input.
And it will also make
cognitive decisions.
It will be creative.
There are additional
aspects there--
creativity, knowledge
representation,
rationalization.
There are multiple
things that it
will do beyond just learning.
So you can't treat all
machine learning systems
to be artificially intelligent.
Don't make that analogy,
artificial intelligence
equal to machine learning.
No.
And again, another concept
that people talk about
is deep learning.
Deep learning is one aspect of--
one type of machine learning.
So artificial intelligence,
machine learning,
and deep learning are
three different things.
First thing to
keep in your mind.
And artificial is more
complicated [INAUDIBLE]
because it has
more aspects to it.
So let's go into the buzzwords.
Three classifications that you
most probably see all the time
when you go and read papers
is supervised learning,
unsupervised learning.
Sometimes, semi-supervised
learning, or reinforcement
learning.
These are three
large classifications
of learning algorithms
that we have right now.
And a lot of focus is
happening on these three.
Let me just make
this really simple.
This is oversimplification in
some extent, I'll be honest.
But this will help understand
the concept really well.
In a supervised
learning system, you're
having a large data set--
the input-- along
with the labels.
You're giving it properties
along with the data so
that system could learn.
The system would
actually learn using
the data plus the
properties that you provide.
And then when it creates a model
for itself, it then goes ahead.
And when you give an input,
it'll use that to classify.
So a lot of this
is task-oriented.
So if you have a task-oriented
system that you're building,
supervised learning can be
a good way of doing that.
And again, neural
networks, yes, can be
used for something like this.
[INAUDIBLE], support
vector machines.
There are many,
many different types
in which you can actually
realize a supervised learning
system.
But to give a
real-world example,
if I were to do supervised
learning to kind of identify
alphabets, I will provide a
lot of pictures of alphabets
if I'm learning from pixel data.
If the machine is
learning from pixel data,
I'll provide a lot of pictures
of alphabets written along
with what alphabet is written
because I'm labeling it.
This is English.
This is A. This is
B. This is French.
This is a different character.
That is how I would provide.
So that next time
when the system--
so when it learns, it has
provided a large data set along
with these labels.
So that when you provide
a completely new input,
it can actually use the
information it got earlier
and then decide, oh,
is this a French one?
Is it English?
Or is it another language?
One property.
And also say, or is it
A or another character?
So that's how supervised
learning systems work.
Is this clear enough?
Is this pace OK?
Good.
Moving on to the next one.
Unsupervised learning
is different.
Unsupervised learning, you
are not giving it patterns.
So you are asking
it to figure out
the patterns and
clusterings within the data
that you're passing.
You're giving a lot of data,
but you're not giving it
the additional labels.
You're asking it to find
the hidden patterns,
and then use these hidden
patterns to classify or add
properties to the new data that
you've actually passing to it.
So during the learning phase,
you give it a lot of data
and it will actually
create model--
it will create a model
that will classify
based on the properties
of the data you gave.
It infers those properties.
Second, when you're
in the real world,
you give it actually an input.
It actually uses that
information, that model,
to kind of give an output.
So anything that is
like data-driven--
pictures, classifiers,
those sort of things
can be used in this model.
And it is usually quite
useful in pattern recognition
and things like that.
Reinforcement learning, this
is like the most talked-about
[INAUDIBLE] lately.
Good credit to AlphaGo
for this when it actually
did something amazing.
Reinforcement learning
is what it actually is.
Reinforcement learning is
similar to unsupervised
learning.
But whenever you
actually give it an input
and it actually does
the right thing,
you reinforce it by
giving that data back
through back propagation.
Back propagation is very simple.
It basically makes
the data error.
So if you are saying that--
assume I am training a dog.
That's a great example of
reinforcement learning.
I am training a
dog to kind of act
on a certain task or an
action that I'm providing.
And I say, sit.
And when it sits,
I give it a treat.
That treat is the reinforcement.
In neural network terms,
if you look at it,
what we do is we
actually take your input.
We run it through the network.
Finally, when you actually have
the right outcome or the error,
you take that information
and pass it back
to adjust the weights
in your network.
So in neural network,
basically simple thing.
I mean, I'm going explain it
with neural networks, which
is one way of doing it.
It basically is
layers of computation.
And each layer has a weight
that transfers to the next one.
So based on the weight
and the computation,
it transfers to the next
layer a certain data.
And that's how you come
to a final outcome.
Now, when you're doing that,
you can adjust the computation
or you can adjust the weights.
Computation usually
is never adjusted.
It's always the biases and
weights that get adjusted.
But based on the outcome,
when you're training,
you can actually back propagate
those errors or differences
and ensure that you're
getting closer to the outcome.
Let me explain that with
the help of an example.
I'll come back to that.
Neural network.
Again, another buzzword that
you might hear a lot of times.
Neural network is how we
mimic the brain's working.
How your brain works is
basically by creating synapses,
networks of
information transfer.
When you're getting information,
it actually connects
and creates a certain network.
When information is passed
through it in a certain way,
it creates an outcome.
That's why we recognize things.
So if you have
seen a cat before,
and you know that it's
a cat, the next time
you see it, the
way you recognize
it, even though it's
not the same cat,
is because when
you run through it,
it can classify itself and
say, hey, that's the way.
Neural networks is very similar.
We have a set of
computational nodes, which can
be considered to be a nerve.
Then, the nerve ending, how it's
transferred to something else
can be considered to be a node.
Each node has weights and
the computation has biases.
These are two parameters
that you would alter in order
to get the right outcome.
So we create a standard
neural network.
Just create a random neural
network, assign random weights,
and you pass data through it.
It is not going to get
an outcome correctly.
But as it starts
getting outcomes,
if you back propagate
the errors down,
like from one layer
to the next layer,
from the last-- from the
output to output minus 1
to output minus 2, then what
happens is for the same input,
you get a much better outcome.
So if you're saying that
your tolerance would be
between 10 and 5 numerically--
I'm just making
it really simple.
Numerically, the answer
should be between 10 and 5
for this input.
And you got 8.
You're going to take,
OK, the median, 7.5.
8.
You're back
propagating that 0.5,
and then you're going to
back propagate that error.
And sometimes, errors
go through a couple
of layers of back propagation.
But at the end of it when
you give, you get 7.5.
If you're outside
the range, you give
that difference, more network
layers or more neurons
will be affected.
But at the end of the day,
the right outcome comes in--
it comes out the right way.
So reinforcement learning
is really, really strong.
AlphaGo works like this.
What it does, it actually
learns from the pixels,
understands how it learns,
and then plays against itself,
every time reinforcing
when it wins.
So two AlphaGo versions
play with each other.
Then it says, oh, I won.
It will update its
algorithm, and then
continues to play again till--
If the second guy wins, that
data is taken and updates.
So a better version of it
comes over a period of time.
in AlphaGo, I think
they made it play
30 million times or something.
So this requires a
lot of runs for it
to get to the right model.
But once the right model is
created from the training,
they can be applied
anywhere else.
And that doesn't require
all the same amount
of computational resource.
A simple neural network
example, cat and dog.
I don't know the
fascination with cats,
but YouTube is full of them.
And we assume we are
creating a neural network,
which kind of identifies
from a picture cats or dogs.
This is how it might be.
This is a deep
neural network, which
means there are multiple
layers of neural networks.
And like I said, the free input
is given to the input layer.
Then, that activates
a few neurons.
It goes to the next layer.
That creates a different
set of activations.
Goes to the next layer.
And finally, the
outcome comes in.
During the training
phase, you will
feed it a million pictures
of cats and dogs and say,
this is right.
This is wrong.
When you get the output,
we say, oh, this is right
and you back propagate.
When a dog is
identified as cat, you
will actually back
propagate that error
for it to correct itself.
And that way, it
will automatically
ensure that when it
comes in the next time,
it actually understands it.
So over a period of
time, your neural network
will start identifying
everything correctly.
To a great extent, there will
always be tolerances of error.
It's not going to be like
writing an if statement.
If statements will
always work as expected.
But this one, if you
give something which--
a cat which looks
like a dog, maybe
it can get missed because
of the parameters is used.
But this layered
approach makes it really,
really, really strong.
In Google, most of our
speech learning systems
are about 30 layers.
So there are 30
layers of networks
of neurons that actually go
in with thousands of nodes
or 10,000 of nodes.
A lot of it.
So some of them are
complicated, depending
on how complex you're solving.
Speech is a really
hard problem to solve.
So that's why it has such a
large network to solve that.
What is there from
Google side from it?
&amp;gt;From a machine learning
perspective from Google,
we actually have something
called as a Google Brain
Team, which is a team which
is specifically building tools
for our researchers to use.
And one of the things that
the brain team actually--
the Google Brain Team
actually were working--
what they found was that
there are three classification
of users for this.
One is your researcher, who's
really interested in building
a new algorithm or
a new computation
model for something.
Then, you have somebody
who's a data scientist, who
wants to take this algorithm,
apply it to an interesting data
set, and create
an outcome for it
or create a model out of that.
The first guy is creating
algorithms which kind of
computes in a certain area.
So he might find a better
way of back propagating
information, coming to a certain
conclusion in half the time.
That could be what the
researcher would do.
Now, taking that
algorithm and applying it
into a real-world problem
with a real-world data set
is what your data
scientists are doing.
A lot of the data
scientists will actually
take real-world data, use
algorithms, and then convert
into interesting
information or models that
can be applied in an
application or a solution.
Now, then the app
developers are there.
The app developers
usually take these models
and then apply it
into a solution.
They're the ones that feed
an input and get an output
and act on that.
So there are these different
classifications of people.
One of the things that we
wanted to kind of improve
within Google was the fact that
these three segments of people
need to communicate better.
And that's why the tools
that we build around it,
like TensorFlow, were
built from a factor.
They can actually perform
these different tasks
and they can transfer that
information across these teams.
Initially, some of
our teams used it.
Now, there are hundreds
of products in Google
which use machine learning,
because people have started
seeing the benefit of it.
And there are more
and more teams
using machine-learned data
to kind of optimize or solve
certain problems.
And some of these tools
and techniques have come in
and we built an infrastructure
specifically for that.
And that is something
that is applicable--
I mean, that's something
you guys can also use.
Again, from a
TensorFlow perspective,
this is one of the tools
that we have open-sourced.
This is the most [INAUDIBLE]
project from Google.
So a lot of people are
adding more data to it,
more algorithms to it.
This is a great start.
If your team is actually
starting off with something,
this is a great start.
Because this comes with
a lot of the algorithms,
a lot of the toolset that is
required to make things simple.
Rather than starting from
building computational models,
you have a set of
libraries that allow
you to do this way better.
So if you are giving
it to a data scientist
or if you're giving it to the
researcher side of things,
this makes it really easy.
The researcher can go ahead and
change something in the model,
and then transfer that
information straight off
to research--
I mean, researcher can transfer
that same thing into the model,
and then pass it to the
development team directly here.
So this makes it really,
really fast to do.
Again, it can run on
your laptop or desktop.
It can, again, run
on data centers
if your data set's large.
You can train the model, even
use it in Android, iOS, or even
a Raspberry Pi for that matter.
The models can be
applied everywhere.
This is not something completely
on the server side of things.
A lot of people have this
misconception that, oh,
machine learning,
that's a lot of data.
It will only work on
server side technology.
No.
There are a lot of tools
that you have on your phones
right now, which anyways
is using all this.
The other company, the notable
thing that we want to call out
is DeepMind.
This is an acquisition
Google made in 2014.
This company started in 2010.
And they are specializing
in reinforcement learning.
There are a lot of nice
papers that they publish.
If you guys are
interested in this area,
you should read some of them.
Lately, they publish an article
on how auxiliary tasks--
there's primary tasks for
which the reinforcement
learning is working and
there are auxiliary tasks.
And how the auxiliary
tasks can actually help
speed up the whole
training cycle.
So you should check
that paper out.
I'll share a link with it later.
But they are actually
creating these solutions,
which are actually learning
through experience.
One of the things
that they specialize
is in general
purpose algorithms.
General purpose algorithms
are slightly different.
They are not [INAUDIBLE] for
one piece of information.
So if I make it learn
one type of app,
game, the information that
it figured out from there
can be applied
onto another game.
So they are not for
one specific purpose.
It's not like, oh, this
can play just chess.
So if it gets play Go.
AlphaGo is specialized for Go.
But it can use that
information that it figured out
from playing AlphaGo and use
it to study another game now
way faster.
So general purpose algorithms
are very, very interesting.
They are how human brains
actually really try and--
I mean, very similar to how
our brains actually learn.
We learn from all
the information there
and we correlate it
with other things.
So if you have learned one
language, it's easier for you
to learn another language.
Because you use
the same techniques
that you found useful in the
first set, first language,
and you apply to the second one.
Similar thing happens with
general purpose algorithms.
So this is a really interesting
space that you should watch.
Quick question.
When is the last
time that you think
you used machine learning?

AUDIENCE: Counter-strike.
AMRIT SANJEEV: Counter-strike?
OK.
When was the last
time you played?
AUDIENCE: Yesterday.
AMRIT SANJEEV: Yesterday?
OK, good.
I like you already.
What about the others?
Do you think you use machine
learning on a regular basis,
or solutions with it?

These are some of them.
Gmail.
If you use email today morning
while you are traveling,
yes, you've used
some part of it.
Inbox.
Photos.
Google Now.
Music recommendations
from Play, all these
are based on machine learning.
This is just a
small set of things
that you might be using
on your devices today.
But the answer to the question
I asked is, yeah, the last time
I checked my phone.
Because yes, at that point,
you might have used something
from a model that is applied.
The models are actually
built on the servers,
but they were applied
on applications which
are running on your devices.
So this is another interesting
example I wanted to call out.
In this model, what we tried
to do was we gave it a picture.
And we gave it a set of
pictures, the second site,
and asked it to apply the
style to the first pictures,
to the next input.
The input is the first one.
The training data was
the second picture.
And you see the outcome.
That's what the
computer automatically
made after learning this.
You can see that it's
not a superimposition
of the second
picture on the first.
It actually understood the style
in which the second picture was
drawn, and then applied
that style back.
Imagine trying to create
a filter like this
with conventional programming.
It's going to be
very, very difficult.
Imagine you created one.
And it was successful
and you want
to create a ton of
filters like this.
Because yeah, you're making a
ton of money because of that.
How would it be,
if you're taking
a lot of time
programming it in rather
than making a machine learn it?
So these are sort of the
problems where you actually
would need machine learning to
solve them more efficiently.
More efficiently than
how we would actually
write it in code.
What can you do today?
One is identify the
three types of people
that you have in your orgs.
Because in your
organization, you
would have different
types of people.
Some people would be really
interested in using the library
and getting a solution out.
Some people would be really
interested in building
the algorithms.
Some people would be
really interested in kind
of using the data
and using the--
maybe mix match the
data and algorithms
and kind of create a model.
Now, from a complexity
to effort perspective,
you could use one of
the standard APIs,
like the Vision
API that we have.
It recognizes a
thousand features
which you can use to
make a solution, which
is kind of the less--
basically, you're using
a pre-trained model,
and then you're making
a solution out of that.
There are Indian companies
which are doing this.
There is one
company, [INAUDIBLE],
which I think [INAUDIBLE]
mentioned about earlier.
They actually use
that, the recipes.
You can actually take a picture
of vegetables in your fridge.
You can open the fridge,
take the picture,
and it will tell you what
you can make out of that.
It uses machine
learning to understand
the different vegetables or
different ingredients that you
have, and then creates recipes
and searches for recipes
with that, and then shows
it to you all in a flash.
Imagine I have to input
20 vegetables that I
have on a keyboard
into a mobile app.
How many times do
you think I'll do it?
Taking a picture?
Fairly simple.
Cooking is another problem, but
at least getting the recipes
is easy.
So things like that
are simple use case.
They are seeing tremendous
traction with this.
And this is not something
that they built yesterday.
They built it two years ago.
And they've been
training that model
for the last couple of years.
&amp;gt;From what I know,
about 18 months they've
been continuously
updating their algorithms
and now they have great accuracy
on what they are actually
pushing on there.
And it's really fast.
I have used it myself.
You should try it out.
It's really fast
and it's really fun
to do because you take a
picture and you shake the phone.
It tells you a set of recipes
in a matter of seconds.
If I were to actually
do this myself,
I'm going to take at least one
minute to input all that thing.
And that's just too painful.
So there are a lot
of ways in which you
can improve users' experience
on your solutions with this.
The second one is basically
have the interesting data
that you have, add it to an
algorithm, and create a model.
This takes a little more because
if you're building a solution
like an e-commerce solution,
you have a lot of data that you
have in terms of usage
patterns and how people are--
buying patterns, interest,
click-throughs, how much
time people are spending.
All this information
can be added to models,
and then create a predictable
[INAUDIBLE] for that.
But because that data,
interesting data is just
with you, you can
actually use that data
and use some of
these algorithms,
and then create
models out of that.
The last one is to create
completely new algorithms
for new problems.
This is more
complicated, but that's
another space in which people
can actually do work in ML.
So you would usually see
that your problem would fall
into one of these categories.
Most people would
love the first one.
Standard solution, use
an API, get an output.
Yeah, but that's
not always going
to be there because
the data sets might not
be [INAUDIBLE] for you.
You might need to
do some fine-tuning
over a period of time.
Now, to start with, how do
you get your team ready?
You need to understand the fact
that as agencies or as software
companies, we can't really
completely ignore this.
This is not a fad.
This is how a lot of the
software is going to work.
And it is not the future.
It is today.
It is a present.
It's not the future because
you see so many solutions
using this.
And so many other
solutions which
you might be using
on a regular basis,
not just Google
solutions, but there
are many other major players
in India who is actually
using a lot of machine
learning to kind of give you
better recommendations, surface
up the right information to you
at the right time.
Even newsreaders
are using it lately
to kind of understand
users pattern
and show the most
interesting news to the user.
So there are a lot of places
it's getting used right now.
So a solution that you
build will most probably
need to leverage
such technologies.
So getting your team ready
is definitely important.
And again, start looking for
these integration points.
They don't come
naturally because we
tend to think in a certain
way, the logical programming
procedural way.
You need to start looking
for points where you
can integrate some of these.
Have an awareness of what's
there as standard APIs,
and then kind of backtrack into,
say, places where, hey, this
is a place where I can introduce
something really interesting.
I've seen one where
they show a picture
and recognize how the
person reacted to it--
not when the user clicks it,
just by facial recognition.
You don't like it.
You like it.
You smiled at it.
This was funny.
So they actually would tag all
this additional information
by showing through the pictures.
And that is done
during the time you
load into the actual solution.
So you got that training data.
Your data takes 10 seconds
to load, your application
or whatever solution
that they're building.
They didn't give you a spinner.
Instead, they showed
you pictures and made
you react to those pictures.
Such a nice way of
collecting data. .
A simple way of actually
training your model.
You're getting the data
to train your model
at the end of the day.
Where they're using it
I'm not exactly sure,
but that is a nice
way of doing it.
Downloads to TensorFlow.
This particular thing
is a great starter.
There is a ton of
tutorials that we have.
I'll talk about them as we go.
And then also,
have an awareness.
Go back and be aware of what
are the APIs that are there.
If you want to add
voice interactions
to your application with
context, look no further.
There's the API--
[? any.ai, ?] which
is an acquisition,
again, from Google, which
allows you to add interactions.
If you are interested,
I can show you something
that I coded over the weekend.
It's really simple lines of--
10 lines of code gets
you voice interactions
on your application.
Like I have a newsreader.
I said, OK, now I talk to it.
I can say, OK, search for
interesting Android articles.
And it just goes
automatically, figures
out that I want interesting
Android articles, gets that.
But at the same time, I don't
have to always say search for.
Find, search, get me.
It figures it out.
So I don't really have
to, say, train the user
to talk like I have
programmed the system.
The user can say.
In most cases, it's
figuring it out.
And the success
rate is really high,
at least from the analytics
that I'm seeing so far.
And I'm yet to see somebody
talking something else.
Where I've seen a little
bit is a global app.
So it's a little bit
differences when somebody
talks in their own language.
When you say talk,
they actually talk in
like Portuguese or French.
And then the system actually
doesn't get that all right.
But when you're speaking
English, most people get that.
This is a great way of search.
If you want to actually
type in a sign.
You want to type in your
user ID or your email,
that's such a cumbersome
way of doing it.
I mean, you've got
to speak to it.
And you say, oh, what's
the latest information?
Like you talk to Google
Home, for instance.
How many have seen the
videos of Google Home?
Interesting?
What is the reaction?
If you can integrate
into that system,
how it actually talks to
you is very similar to how--
I mean, building
something very similar,
at least a rudimentary way of
building that with the data
set you have is straightforward
with tools like [? any.ai. ?]
So you should explore that one.
Things to explore.
One is the TensorFlow
tutorial set.
There is things for beginners.
There are things for experts.
If you want to actually
have code labs,
there are code labs
as well as videos.
So you can actually
go ahead and make
your teams use some of this.
Go through the tutorial,
get your team ready,
get them a better
understanding of the system.
Then, the code labs as
well as the videos kind of
help you speed up things.
The code lab, this
particular one
called TensorFlow for
Poets, it's very nice.
It's image recognition.
The existing system
understands a lot of things,
but then you can actually
train it with new data sets,
and then start applying
that model to it.
One example that I've seen
is in TensorFlow Mobile,
where you're applying that
data into a mobile application,
where they actually did show it
a lot of pictures of paintings.
It's a museum app.
So you go to the museum and you
show your phone to the painting
and it gives you information
about the painting.
It recognizes the
painting from the picture.
No matter what angle,
what lighting it is,
it actually figures it out.
Then, it actually
goes back and searches
for information,
additional information,
and then presents you with that.
Simple thing.
Now, if I wanted to add
10 more pictures to it
or 10 more new
paintings to it, it
knows how to classify
these has as paintings.
It knows how to go
and search for them.
You don't really have to
train those models extensively
for that.
Yeah.
This is a set of tutorials
that you guys have
which you guys can go
ahead and run through.
But the ML recipes is
pretty interesting.
There is a very nice talk called
&quot;TensorFlow and Deep Learning
Without a PhD.&quot;
A colleague of ours have
actually talked last year
with this content.
Brilliant talk.
You should see it.
Really interesting.
He explains it with
a little bit of math.
I have not touched
any code here so far.
I don't intend to, either.
But this talk is really,
really, really nice.
You should actually go
back and get your team
to at least watch this.
They will get new ideas.
There's a little bit of
mathematical background
that you need when you're
actually working with ML.
So if your teams are not
coming from that background,
yes, they might see
that as a blocker.
It's not like using an
API without understanding
of math behind it.
Here, you might need to
understand a bit of the math.
So that says something--
matrix multiplication-- things
like that are part
and parcel of how
you write TensorFlow programs.
Because matrix multiplication,
bare minimum at least.
And there are some best
practices around it,
which most of these
tutorials cover as you go.
So having your teams
trained for these things
is really, really important.
And that's it from me today.
I hope this makes it a
little bit more clear,
at least sparks some interest
in you guys to go back
and tell your teams to
explore some of these things.
It is a really high-level
overview, I understand that.
But since we don't have a real
hardcore developer population
here, I thought it
would be best that we
keep it really abstract.
And I'm really looking forward
to seeing you guys build
something exciting.
And when you do,
please let us know
so that we can actually showcase
it and talk about it more.
Thank you.
[APPLAUSE]
</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>