<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TensorFlow for Poets 2: Optimize for Mobile with Kaz Sato (GDD India '17) | Coder Coacher - Coaching Coders</title><meta content="TensorFlow for Poets 2: Optimize for Mobile with Kaz Sato (GDD India '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Developers-India/">Google Developers India</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TensorFlow for Poets 2: Optimize for Mobile with Kaz Sato (GDD India '17)</b></h2><h5 class="post__date">2018-01-30</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MoVSN1bKKIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is a water uptight or tensile for
parts - I'm Cass I am developer advocate
for Google crowd team the working for
evangelizing the technology and the
products to the developers and
especially focusing on the machine
learning the data processing products
such as the bigquery and tensorflow
and today I'd like to going through the
column that I told you supports - and
that co-driving is available on this
website
maybe easiest way is to access the
Google search and the search with the
keywords such as coal black and poets -
and there's a do put a pencil for poets
collab and tests of all points to coder
rap the poet's - coder rap is focusing
on how you can optimize your model for
running the model on the mobile phones
or smartphones so please open the the
poet to call the lab page with your
laptop if you have access and I in this
code rub I don't I'd like to spend my
first 20 minutes or 30 minutes for going
through the concepts and the techniques
we are going to Travis Lee he called rap
before get started with Korda rap so I
will spend ragga yeah 15 or 20 minutes
to talking about what are we going to do
and then we will be starting the
self-paced code lab based on the code
rough page so let's get started with
here concepts before start using code
labs so this code Rob is all about
complex in the compressing details of
all models the parameters and ways that
consists here your network module to a
smaller binaries smaller data so that
you can learn the chance of wrong model
inside Android or iOS devices because
the original neural network model is too
big to run on smart was because
the inception version 3 model that is
the popular imagery condition model
designed by Google that has 91 megabyte
of data Thank You 1 1 megabyte of data
consists of the parameters and and such
as weights and biases inside in GDP
neural network model so it's too big if
you really want to build young Android
applications and want to share your
applications on the Play service as a
production applications nobody wants to
the know consumers don't or under
reducers don't want to download thank
you one thing about top dictator who are
installing the euro applications so you
want to complex the model into recent 10
megabyte I think yeah or maybe at least
20 megabytes and also tensile Pro binary
itself is too big it's 12 megabyte by
default and recently we announced the
new runtime content super alright which
is a topic of the novel patience I will
have in this afternoon but usually if
you use the original the ordinary taste
of raw binary it takes 12 megabytes so
you have to compress the model and
binaries and there are many different
tips and tricks or techniques you can
use to compress the model and the
binaries to bring the technology into
mobile form a by the way when you are
talking about tensile fall or New York
networks you have the two phases one is
the training phase to train the neural
network model with your training data
and another is the inference or
prediction or runtime phase to use the
model the training module so we are all
talking about the latter part to use the
model so we don't suppose we are going
to train the model on mobile phone
because the mobile phone only has the
ARM processor from Qualcomm is too weak
to do the all the calculation for the
training so we only think about the
prediction or inference using the model
rather than training
model or mobile phone so if you suppose
that we are only using the model only
put a prediction or inference then there
there are many tips and tricks you could
use such as freezing grab or transform
graph because you are not doing training
on your mobile you can remove the any
unnecessary part of whole graph you know
specially for the tree are the
prediction or inference and also you can
use the quantization on quantized waste
and the calculations and also you can
use this some techniques such as mapping
and in this quadrat we'll be using a
part of those techniques especially
reading the graph and quantization will
be the main topic of this code right
pleasing graph that is a just a
conversion from the variables to
constants so intensive law we have many
variables for example if you have
weights and biases usually people are
using variables variable objects to
define those weights because you want to
train the model so that the weights in
the variables can you know be the
changed modified time to time by using
GPUs GPUs or GPUs but once you have
finished your training you don't have to
have those ways as variables because
you're not going to train the model on
the mobile so you can convert those
variables as constants intensive growth
so that is the one technique we can use
to compress the model and that by using
that you can remove the order
checkpoints as under also you can
improve your loading times class
transform tool is a tool provided in the
a tenth of all distribution so you can
go to the attesa progress tools glass
transforms to look at these all the
tools to optimize your graph all running
on these small devices such as removing
the all the unnecessary operations for
training removing et Bucknell's
debugging the multiplication
for watch normalization the things you
don't use for prediction or increase and
quantizations so quantization is a
compression techniques for the year your
weights and biases and the calculations
used in the neural networks pretty
sympathy's pretty simple it's just a
bunch of multiplication and as between
vectors and matrices and thing is that
you don't have to have a very high
precision on doing those operations or
calculations usually by default maybe
people are using like a 32-bit float or
64 dots succeed 4-bit Davo
floating-point numbers to representing
the weights and biases but neural
network doesn't need it actually it's
just the neurons inside new new neural
networks can get excited or not excited
activated or not activated so it doesn't
require any very precise calculations so
instead of using 32-bit floating-point
calculations we could use much purer
Precision's for example in case of the
cpu version one attends a processing
unit version one we are using 8-bit
integer for representing weight or
faster inference on the TPU chip and you
can do the same thing on the mobile post
rather than using decided to a bit
floating point or every calculations you
can compress the numbers weights and
biases into 8-bit integer still the
neural network works at certain isn't
precision accuracy intensive law
provides the primitive is to support
those quantized
numbers values and operations such as
key types for the quant I quantize
numbers Q into 8q its attitude or
quantized the floating point values or
contact to quantize buzzer or D quantize
D value with floating point numbers or
operation
suppose the quantized value such as but
MA or convolution pooling and activation
so in this code wrap we'll be using this
technique to memory mapping could be
another techniques you can use for
increasing the performance of your
applications rather than using the file
IO to loading all the parameters you can
use the memory mapping so and now on the
tensor flow departure you can find some
sample codes for using this kind of the
memory mapping techniques video or
powerful application and finally you can
compress the binary by selective
registration that means you can remove
the all the unnecessary binaries from
details of flow runtime and you can use
the only deal require the parts for the
inference of predictions and by doing so
you can compress the binary of
tensorflow from 12 mega bytes to 1.5
megabytes in case of the inception
version 3 so by applying all of those
techniques you can compress the model
into much smaller model so now the
compress is compressed inception
versions of the model can be 23 megabyte
or its weights and biases and binary can
be 1 point 5 megabytes and by combining
the other techniques popular in the
neural network area or academic academia
such as a distillation or the about
matrix factorization or pruning
so there has been so many different of
the techniques to compress the neural
network model so that you can combine
those the pretty well known techniques
with sauce-ii techniques so that you can
even have the much much smaller model
and I know that one customer option
Sorrell was able to compress the model
from tens of megabytes to a few
megabytes like a two or three megabytes
and they have actually
produced on production Android
applications that last extensive role
model inside it with a few megabytes so
so that's the concepts so let's get
started with here actual code lab so if
you have opened the your code lab a page
with your laptop basically this is a
self-paced home lab so you can start
reading the code lab page and get
started with your code lab and at the
same time I want to go through all the
instructions and the procedures with my
laptop so you go to this page you can
see there's something about 10 suppor
light but we don't use the tensor
alright batch of all this code wrap
because - so polite version is pretty
new I think this is a project in a few
years ago and pretty not stable yet so
I'd recommend not to use mystical right
here but if you are interested and you
have time maybe you can try his pro
right version later and also this code
lab is suppose that you have finished
eating soup for 4 points but you don't
have to finish it in support for poets
or now so you can get started with the
10 suppor points - without having VD
first one finished and the purpose of
this code lab is to build an Android
application which attends of role model
that is applied some of the optimization
techniques I have explained such as
quantization and freezing
setup page you need this instruction for
install testable and this called lab
requires tensorflow
installed on your laptop so please go to
the and support page and install your
answer for one time
I hope the many of you have succeeded on
here installing canceled flow and
checked out the github repository for
the points - so you can go to the cone
the git repository so that you can
chrome reports to repository to your
local and change the directory to the
port's to directory that you can check
you have the ins of all the modules on
your directories so by executing the
chequered command you can get the train
with data stored on here underscore
files directory and then you
execute the Python command on the third
section free to check if your model
works properly and if you works it works
properly you will be getting the result
such as a the process and powers this is
us in sports
don't you have you have to use the get
up to take out the hoard from the
repository and the we provide the USB
these sticks it has some files or images
and calls but the chief underscore what
is that chief underscore files directly
in the USB stick doesn't have the trend
model so to get the trend model you have
to get the econ check that from the key
to be positive so you need to get clone
the repository and at that time when you
clone the repository ETL files directory
will be empty so you have to execute the
check out mark so that you will be
seeing between model inside here path
once you have fished it down Kalon and
checked out the all the files I think
the rest of the code lab is pretty easy
maybe I I can go through the address of
these sections and what you would see
when you go through the sections so once
you have long and copied checked out the
attention flow model you can try the
testing the model and then you can start
optimizing the model complex in the
model by using the techniques I have
explained such as freezing the graph or
the quantization so in this code lab we
have prepared some scripts to apply the
optimization techniques such as it can
support Python doctors dot optimized for
inference and by executing these scripts
you can have the downloaded model
optimized for the inference and each
sections in this code lab it is checking
the accuracy of the model and it is to
make sure that the accuracy from the
model is not so degraded by the
optimization and also in the blood last
part of the section for it is using
chance award which is the visualization
tool of test overall to check the what's
the difference between the two graphs
the original graph and the optimized
graph and by looking at the as a flow
board you can see the difference of the
graphs especially in the optimized graph
because it's she has been frozen by the
toe so you can see give some variables
for the rhythm devices or convert it as
a constant and in the section five we
are trying to apply another techniques
to complexity model much more we
the original model if you even use the
gzip command doesn't much be complexed
on the 8% of the completion ratio you
would get so this is where you may want
to apply the quantization so as I
mentioned in the the concept art I you
can use the quantization techniques to
compress here the weights and biases
from 32 bits to 8-bit integer and in
this code wrap you can apply the
techniques by using the scripts quantize
graph script
you can see you can get much much more
operation ratio like a 70% compression
instead of the 8% so you can see that
the quantization technique is a huge
part of the optimization for neural
network inference or prediction and then
you will you'll be checking the accuracy
you could get from the year a quantized
model and you can check the quantized
models still has the a pretty decent
accuracy compared with the original
model in this code wrap we expect that
the accuracy difference would be less
than in person
six you'll be using Android studio to
learn the actual Android applications we
have provided their sample Android
applications in the repository so you
can just open the Android studio and
open the Android project polar from this
Android studio and Beauty project -
bounded test test application if you
have Android device maybe you can try
use it with the USB connection but also
you can use your immigrated er and you
can use the your laptop's camera as a
camera of the emulator Android device so
this is where you have this is the
instructions you have to follow to set
up the immunity to Android device and
finally you can run the Android app that
runs the interval</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>