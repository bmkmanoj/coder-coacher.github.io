<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Performance Tooling (GDD India '17) | Coder Coacher - Coaching Coders</title><meta content="Performance Tooling (GDD India '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Developers-India/">Google Developers India</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Performance Tooling (GDD India '17)</b></h2><h5 class="post__date">2017-12-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hQ7Dcz5m_Os" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">[MUSIC PLAYING]

AMRIT SANJEEV: Hi, I'm Amrit.
I'm a developer
advocate at Google.
And today, we're going to talk
about performance tooling.
Imagine you built
an amazing app,
and you've now rolled it
out to a lot of users.
They've installed your app.
And then they tend
to start seeing
that, even though you've
built an amazing UI for it,
some things are not right.
Things are loading up slowly.
There are crashes sometimes.
Or it takes too much of
battery, for instance.
These are all things
that can hurt the user
experience really,
really badly for a user.
They might not be
able to use the app,
and slowly start
uninstalling, and you start
seeing a bigger uninstall.
If you look at performance,
some of the things
that we talked about, it's
actually a two-step process.
You have to be proactive about
it and, at the same time,
be reactive to changes also.
What I mean by proactive
here is that you
go to plan, measure, and
profile your app before you even
publish it.
You might want to look
at your competition.
You want to look at how
well your app is performing
and maybe benchmark against
some of your competition
to see whether your
app is actually meeting
the expectations of a user.
And once you publish
your app, that
doesn't mean that
your job ends there.
You need to kind of continuously
monitor and at the same debug
any issues that are coming.
So once you roll out your
app with millions of devices,
and users start to use it,
you need to take that data
and start improving
upon areas that you find
that the app is lacking in.
I'm going to talk about some
of the tools that you can use
and techniques that you can use
to improve, measure, profile
your app.
I'll start with
Android Profiler.
We released this with
Android Studio 3.0.
I hope most of you guys
are using that now.
And this is a replacement for
the Android Debug Monitor.
This is the unified time
model that you most probably
work with when looking
at performance.
Let's take a look at all
the different state areas.
You have a CPU, memory,
and your network--
three things actually shown
in terms of a timeline.
And on top of it, you
also have input events.
This allows you to track
how your app was actually
performing in
these three aspects
with respect to what
the user is doing.
We also flag things
like system events,
like a rotation of the screen.
You'll see that I can show
that the screen is actually
getting rotated at this point.
The activity is
getting recreated.
And you see a small spike
in the CPU at that point.
So you can relate some of these
things in that one time line.
Now, you also have the
activity's state here,
which allows you to kind of
see what your activity is
doing at this point of time.
Is the activity stopping?
Is it actually
running right now?
Where is the CPU spike?
Where is the memory
spike coming in?
And you can use all these
points of information
together as you see
in the timeline.
Let me jump into
the CPU profiler.
You might want to understand--
because we have-- in India,
if you look at it, we have
a varied set of devices.
We have a lot of
low powered devices,
too, where the processor is
not as fast as the latest
and greatest of devices,
and people still
continue to use that.
You want to be able to
understand how your app is
performing with respect to CPU.
When you click on the
CPU part of the tab,
this is what gets loaded up.
Now let me walk you through
some of the sections here.
You have a thread list,
which is basically
all the threads that were
running in the timeline
that you've thought about.
You had a CPU activity,
which basically
has three things that you
can very quickly look at.
The green, which is
basically how the CPU is
used by your application.
The lighter green, which shows
how CPU is used by the system
so you can make a correlation
of how you're contributing
to the system's load.
And also the number of threads
that are running on the device.
The dotted line represents
a number of threads.
So you can sometimes
relate that, oh, there are
more threads running right now.
So my CPU's spiking.
The system is not loaded,
but my app is actually
using a lot of the CPU.
Things like that.
You also have a thread state.
So when there's a CPU
spike, you can see, well,
what are the threads that are
actually running in the system
right now?
And you can look
at that correlation
and see, oh, this is where I
might need to optimize a CPU.
Maybe this thread-- the code
that runs in this thread
is where I want to make
some changes so that the CPU
spike is kind of reduced
at that point of time.
But if you want to go
more deeper into it,
you need to do something
called method profiling.
This is basically tracking
the entry and exit of methods
that your app uses.
There are two ways in
which you can actually
do a method tracing.
The red button
basically starts it off,
but the more interesting thing
is a drop-down next to it.
The first method is
that you can sample.
You can do it in a
sampled manner, which
means the system will
actually-- what it'll do
is it will take it at
regular intervals of time,
and it will start
tracing, capturing
all the invocations and exits
of application functions.
And the other one is
called instrumented.
Instrumented is where every
single invocation is actually
tracked.
A lot of you might
think, oh, then
the instrumented is
much better, right,
because we get a much
more detailed information.
Not exactly.
Because instrumented has a much
more higher load on the system,
because it has to
work on everything.
So, if you use sample, the
state does not load it as much.
So depending on the use
case that you're using,
and what you're trying to solve
here, take one of these two.
Let me load up one of the
profiles that you have.
Even though I'm throwing
static images here,
these are continuous timelines
that you can actually take.
So this is a timeline
that got captured,
and then I've learned
that data in here.
If you will see,
at the bottom, you
have the call chart
that is there.
And at the top, you have
the timeline and the threads
and their states.
Let's go a little deeper.
I'm selecting a certain
section of the timeline
where I see a CPU
spike, and then we
want to analyze that
a little better here.
Now, the selected recording is
the area that is in the blue,
and you have a call chart
for that area displayed
and visualized here.
Let's go deeper into that.
Now, when you look
at the call chart,
there are a couple of
things that you want
to very quickly understand.
The orange basically represents
all the function calls,
which are system made,
so your on-create,
what activity classes
would do, things
like that, fragments would do.
And the system calls
are all the orange ones.
Your code is basically
the green bars in there.
And you can also
see some blue color.
That's basically
system library code.
So let me take one example here.
If you look at that long
green bar, which is basically
an activity create,
it is at a point
where your system is rotating.
You have the image detail
activity getting loaded.
And you see that the
on-create is really long.
But when you go a
little deeper into that,
you see there's a set continue
in the activity is only 1/3
of the time.
The rest of it is actually done
by an initialization process
called init and then
an image fetcher.
Now, armed with
this information,
you can very quickly understand
that, hey, in this case,
my activity could have
loaded a lot faster.
If not-- if I can
move some of this code
that is written by my
application-- in my application
to another later point of time
or initialize it somewhere
else, your activity would load.
So there's a point where the
user could see a slow loading
activity, and you have
an option to improve it
by maybe rearranging your code
or organizing the flow of data
that you have in
your application.
So instances like this
are very easy to pick up
when you start analyzing this.
This is not the only
way you analyze.
If you look at it, you can also
see a top down approach, where
you start from the top
thread in your application,
and you can see all the way
down to the final invocation.
This will be used when
you want to trace a path
and see all functions
that are being called
and what effect they
have on the CPU.
The other one is a
bottom up approach.
Now that you've
identified-- hey,
I have this function
is some place where
I'm going to optimize-- how
is this going to affect--
who is calling this one?
So you take that
function, and you
can do a bottom up approach.
That is this particular
screen that I'm
talking about right now.
And that helps.
The second one we're going
to talk about is memory.
This, again, for us,
is very critical.
For India, we have so many--
the variety of devices
and the amount of RAM on these
devices from low to high,
it's such a big variance.
You will see that out
of memory exceptions
is more common in some of the
applications that we build
and we deploy in
our region here.
So to help with that, you
have the memory profiler,
which basically looks at--
it color codes all
the different sections
of your memory, the Java code,
the native heap, the stack.
All these things are
color coded differently so
that you understand how they're
growing at each point of time.
You also have things like
GC events being shown here,
which lets you know that,
hey, at this point of time,
the garbage collector kicked in.
You have the option
to actually force
GC to understand the behavior
at certain points of time.
You'll see that,
at this point, when
I'm doing a lot of computation,
the memory's increasing.
Can I force a GC
to do something?
Will that affect
the application?
Now let's take a segment
of it and analyze
it a little more deeply.
Now, when you select
a set time segment,
what default outcomes
in the default heap-- as
is shown below-- that all the
allocations that are there.
This is per class.
So each class or
type was actually
shown on how much of allocation.
And the allocations happening
over that period of time
is clearly shown here.
You can also arrange
it by call stack.
This is how you would want to--
once you have
identified some areas
that you want to look
into, the arrangement
call stack and other
options that we
heard will help you really
dig deeper into this.
Now, when you
arrange a call stack,
you would see that,
hey, at this function,
my app is allocating these
variables on this much memory.
You've found out
that at this function
the app is slowing down--
or there's a lot of
GC events happening.
You want to identify why.
So you drill down and
see the allocation count,
and you can find unit to
the last function call that
has been made, and you can
look at how much of this
is allocated.
Now, there is another
option that we have
which is very interesting,
which is basically
my arrange by package.
In most of our
apps, we have a lot
of third party libraries being
added so that the users use
some of the code.
You might want to just work
on certain parts of your code
and optimize it to the
best, leaving aside code
that you don't have
actually access for.
You're actually just using
the library in that case.
So when you want to do that,
one of things you could do
is you could select by package
and avoid all the packages
that you're not interested
in, focusing on,
and then just select the ones
that you want to work with.
Thereby improving those
packages and the code
that you've actually written.

When you select one of the
allocations, what you would see
is all the instances of
that in that timeline that
got allocated as
well as de-allocated
with some additional parameters.
So this gives you a fair
sense of how many threads
are getting constructed,
how many times
this is getting called.
Should I actually make a static
variable of this to improve?
You can get it to start thinking
of all these options with that.
Now, clicking on one
of those instances,
you also get the
allocation stack.
Like in every place,
you want to kind of dig
a lot deeper into it.
So you can do a
heap dump and then
load that into the profiler.
And this is how you will see
a heap dump getting loaded--
the same way you have the
splits that I talked about.
But when you click on
the instance properties,
you can also get the
references to the instance.
So if you see that you
have a memory leak,
this is a much faster
way to kind of figure out
how you want to drill
down to that point
and see what references
are holding to this one.
So it's much easier
to work with it.
The last profiler that I
want to talk about today
is the network profiler.
Now, network, as
we know, right now,
we have a lot of bandwidth.
But people kind of
tend to optimize
a lot for network
usage, and that
is because one of
the biggest concerns
is the battery
life of the device.
Battery life can be
affected drastically
by overusing the network,
because the radio states--
as most of you might know,
when you use the network radio,
it actually goes to
a high power state.
Then as you stop using it,
it comes to this low power
idle state, but it
still consumes power.
And then it only shuts
down after some time.
If you continuously
use the transfer data
or receive data, what
happens is the device
will keep the network hardware
in its high power state thereby
consuming more battery.
You don't want an experience
where users love your app,
but your app drains
the battery so quickly
that they decide to uninstall.
So the network profiler would
allow you to kind of see
how much data you're
transferring--
at the same time, look
at the radio states
to understand where you're
actually impacting battery
because of the network.
So that blue line is
where the network--
different states of the
radio is actually shown,
where you're seeing it at
high power, or low power,
or if the person is using Wi-Fi.
Now, you have a data
transfer graph also.
You have something like how
much data got transferred--
how much data was received.
The blue line here--
the blue graph
indicates how much data
transfer is happening at once.
And the orange line,
not the dotted one--
the orange solid line is how
much data is being received.
The dotted line is the
number of connections
that you're actually having
and the network connections
are keeping.
Sometimes you'll see that you
are keeping unnecessary network
connections and keeping
a lot of resources.
So these graphs very quickly
visualize areas of concern
for you and allow
you to kind of drill
down deeper to fix the problem.
Like all the other
graphs, you can actually
take a time slice of this--
look deeper into it.
When you take a time slice,
every HTTPS and HTTP requests
are shown, visualized with
a timeline next to it.
They will tell you
what type of network
call it is, what you requested
for in the data mine,
what is the size
of that request.
So that you can go in--
and how much time it took.
So you can literally
go in and say, hey,
I want to optimize
this one network call.
If you select one
of those networks,
you actually would
get the response.
If it's an image, that image
will actually be rendered.
This allows you to
find things like, hey,
is my cache working
really right?
Am I downloading the same
image too many times?
Am I rendering the
right resolution
for the image from the server?
And you can also look at the
headers to think about issues--
find about issues, like,
how much time to deliver
is actually being
shared by the server
so that the HTTP
cache would hold this
for longer, things like that.
You can also look
at the call stack
and see additional
parameters here.
Now, with Android Oreo, you
can profile any debuggable app
without any changes to it.
But if you are actually
targeting Nougat or below,
you would actually have to
enable advanced profiling
and build it on
Android Studio 3.0.
Again, in order to enable this,
if you're running the app,
the system will actually
prompt you with a nice dialog.
So you just have to say, OK.
And the advanced profiling
will be automatically enabled
for you.
The second one I want to
talk about is APK debugging.
Once you have a
problem, you want
to go back and look a
little more into what's
happening, right?
To profile and debug,
you might be, like,
developing a game using a
completely different thing
other than Android Studio.
And you want an
option to, kind of,
go ahead and analyze and profile
your app using Android Studio.
In this case, we have
added a new section
where you can actually build
your APK when your APK is
ready, then Android Studio to
go ahead and profile and find
all the information that we
talked about earlier here.
So when you do
that, what happens
is it creates a dummy
project, loads your APK,
and then opens it up by
default in the APK Analyzer.
And you can then go ahead
and attach your sources--
go ahead and attach
your libraries
so that dependencies and
other things can be fulfilled,
and you can start
profiling your code better.
With APK Analyzer,
there's an extra
that I want to talk about.
How many of you guys
use APK Analyzer?
I'm glad-- a lot of you.
Those who haven't raised
your hands, please
go back and look at that tool.
It's really useful stuff.
So you can actually
invoke the APK Analyzer
from the build menu.
Or every time you create
a build, it will actually
show up with this nice dialog
where it says, locate your APK
or analyze the APK?
Clicking on analyze
will actually load up
a screen like this where
your app is actually
shown with its different
parameters in the APK,
the different sections,
things like classes,
the dex files, the
resources, your manifest,
how much space they are taking
with respect to total size
of your application.
By the way, there are two
sizes being displayed here.
One is a raw size.
This is a APK size of a file.
And the second one
is a download size.
The download size is
basically how much download--
how much data is going to be
downloaded for this app when
you are actually installing
it from Play Store,
because Play Store can do some
additional compression on that.
So sometimes these numbers
won't match with each other.
Play Store most probably will
compress this a lot smaller
then send it down the line.
So the user would only
download the download size,
whereas your APK size
is the size on the disk.
And looking at this--
like, in this case,
we have loaded a dex file.
You can see the classes
that dex is taking the most
amount of space in your APK.
We initialized it by
showing you the size.
The percentage of
size-- this file
is actually taking in your APK.
A lot of times, it's not the
classes.dex but your resources
that you'll see as the offender.
When it comes to
APK size increase,
you might have a resource
which is really large,
and that's occupying
a lot of space.
This allows you to kind of drill
down to the area in your app
which was just taking more
space and reduced the APK size
drastically.
And I want to also
call out that this can
be run from command line now.
So you can actually add
it to your CI systems
and make this as an output,
which is going to your--
every time a CI build
runs automated run,
you can actually run
this, and get the data,
and do comparisons.
Write a little bit
of shell script.
You can get comparisons
against your previous one,
or you can get more data
about what is increased.
Where is the area
that this build
needs to focus a little more
with respect to app size?
The last section that
I want to call out
is Android Vitals,
which is actually
part of the Play Store.
Here what we have done
is we have actually
visualized a few of
the parameters that
are in the real world.
So your app is out there.
It's being installed and
used by a lot of users.
And if you look at
these users, how
is this app behaving
on their devices?
Now, that data is collected
and actually given to you
in the Play Console.
And as a developer, when you
sign in to the Play Console,
you can go into the
Android Vitals page,
and you would see things
like the ANR rate,
crash rate in the real world.
We visualize some of these
parameters in an application
not responding.
Your crash rates--
how many crashes are
happening in the real world?
Slow rendering--
this is something
that's not easy to kind
of find out otherwise.
On how many personal devices
are slow rendering happening?
Frozen frames-- maybe it's
because GC comes into picture
at times, but this is
really good information
for you to start saying,
hey, I have this one problem
in the real world.
Let me start going back and
being reactive about things.
Let me go profile
again, find out
the areas that are a
problem, and then fix this.
Because this must
be the thing that
is affecting my users a lot.
There are more things
like stuck wake locks.
You might not recognize--
there might be coding errors
or things that you missed
out of your testing, which
has stuck wakelocks, which
is, again, going to make sure
that the CPU doesn't
shut down, or the screen
doesn't shut down,
and at the end
increased the battery
usage of your app.
Or excessive wakeups-- is your
app in the real world waking up
too many times because
of external signals, push
notifications, or just
because there are too many
alarms on it?
Any of these things-- background
processes, all these things
waking up your app
too many times.
And we also have a section in
DAC, developer.android.com,
where we have specified
for each section
how are the Android
Vitals, what are they,
and how you might want to
respond and work with them.
That's it from me for today.
I hope some of these
things are useful for you
and you have learned
something new here.
Go back and profile your apps.
And if you make
substantial improvements,
do let us know your story
so that we can come in
and help you with more stuff.
Thank you.
[MUSIC PLAYING]
</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>