<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Fundamentals of Google Cloud Platform: A Guided Tour (GDD India '17) | Coder Coacher - Coaching Coders</title><meta content="Fundamentals of Google Cloud Platform: A Guided Tour (GDD India '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Developers-India/">Google Developers India</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Fundamentals of Google Cloud Platform: A Guided Tour (GDD India '17)</b></h2><h5 class="post__date">2017-12-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pPHultov5Ls" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is Matata Mel I'm
a developer advocate at Google based in
London namaskara
a new mark my two Avenue Metta swagat ah
nice so today we're going to be talking
about yeah thank you today we're going
to be talking about fundamentals of
Google cloud platform in 30 minutes it's
gonna be a fast-paced talk because we're
gonna have a lot of things to talk about
but hopefully we'll go through it and
you'll learn something new today
yeah so sorry we'll start with a little
bit of history so there's a really cool
website called the wayback machine and
if you check that out and plug in the
Google cloud platform or search for
Google cloud platform from back in those
days you'll see what the actual landing
page looked like this is it how many
people were using Google cloud platform
in 2012 okay so a few a few diehard
folks there it's it was very simple back
then there were only four products in
the entire platform so it was pretty
easy to get your to wrap your head
around it and understand what it could
do nowadays a little bit different we
now have over 80 services and that list
continues to grow every day in fact
there's so many different capabilities
and services that I can't fit all the
all the little product icons on one
slide that's a really good thing it's
nice that we have all these I mean it's
more than nice it's really enabling and
really powerful you can build almost
anything you can imagine in the cloud
nowadays but it comes at the cost of a
lot of complexity and a lot of kind of
cognitive load so it takes quite a bit
of effort to figure out what all these
services are when to use them how to use
them effectively in your applications
and that's really the point of this
session we're gonna take you through an
overview we're not gonna go too deep
into anything but try to give you a
taste of all of the all of the
capabilities we have in Google cloud
platform so to start off we
cover all the compute options yep thanks
mark
so if I compete what I mean is that
let's say you have a piece of code and
you want to deploy to Google cloud what
options do you have that's what we want
to cover here so at the very high level
when we talk about compute there are
three distinct ways of running your code
and this is not just Google cloud but
basically in any cloud you have these
options so back in the day when before
cloud when you want to deploy your
application you would get a machine you
would decide how much CPU you want you
would decide how much memory you want
you'll get a hard drive and decide how
big that should be then you would
install the operating system and after
that you'll install the libraries that
you need on top of the operating system
and then finally you would get to
install your application so with virtual
machines it's pretty much the similar
thing except it's virtualized it's not a
physical machine anymore and you
probably don't have it yourself you have
it in someone else's data center so in
virtual machines it's the same idea you
pick your CPU your memory your storage
and then then install your operating
system and then it's yours it's your
responsibility to maintain it and to run
it now more recently we have something
called containers so the ideal
containers is that instead of
virtualizing the operating system and
all the way out to your application you
want to virtualize your application and
its dependencies so the libraries that
you need and since you're not
virtualizing the whole operating system
these containers are really small so
they are really easy to create they're
really easy to run and they're really
really easy to move around so you would
use docker push and pull to move these
images around and deploy them really
easily and then lastly server lists so
in server lists you don't really care
about virtual machines you don't really
care about containers you have a piece
of functionality or an application and
you just want to deploy it and let's
summon s manage it for you so it becomes
someone else's problem basically how to
deploy an application and how to manage
it but as a user you are basically
focusing on your code and just deploy
your code and let someone else manage
that for you now and then one thing to
mention is that most people they start
with virtual machines now they are
switching to containers because it makes
sense and they're much more agile than
virtual machines and they are going
towards server lists
but most people nowadays they're kind of
in the container world but containers by
themselves they are not enough because
containers they give you a context to
run your application in a consistent way
everywhere but when you run your
application you need more than
containers you need resiliency for
example so you probably need health
checks you need to be done Denise oh you
probably need to run multiple containers
you need configuration so you need to a
way to define your configuration and get
that configuration to your application
so because of all these things that you
need to do in production they're open
source projects like humanities which
try to run your containers in production
and make it easy for you and even
continuous by itself is not enough
nowadays because you can it is basically
makes you run your containers in
production and watches your containers
make sure they run but then you need
more than that when you write a micro
service for example you need like
service to service authentication you
need a way to visualize your services so
you need some kind of dashboards you
need logging so there's all these extra
things that you still need to do on
topic you burn it is so that's why we
have something called Sto it's another
open source project that tries to create
this service mesh so that you don't have
to create everything from scratch it
gives you this logging and monitoring
and service to service authentication
and all the good stuff now in terms of
what options you have on Google cloud to
deploy these first you need to decide
how much management you want and how
much customization you want and by
definition the more customizable things
are they end up being less managed and
the more managed they are they end up
being less customizable so on the highly
customizable side we have compute engine
call point engine is what we call
virtual machines in Google cloud you can
get a Linux machine or you can get a
Windows machine and we support multiple
versions of Linux and multiple versions
of Windows and once you have the machine
with operating system you can pretty
much install whatever you want on that
machine it's your machine to maintain
it's your machine to keep up to date and
all that kind of stuff
of course installing all this software
on your own compute engine instances it
takes a while so we have something
called cloud launcher it's a marketplace
for solutions to deploy to compute
engine so if you want to deploy for
example lamp stack or if you want to
deploy WordPress there are solutions for
that so you can just find the solution
and with one click just deploy that
solution to a compute engine so let me
quickly show you how this works
so here I am in Google console this is
where all the Google Cloud products are
and we are interested in compute engine
so when you go to compare engine page
there is VM so here you can see all the
VMS virtual machines that you have if
you want to create a new instance you
just hit quite instance and then you can
give your instance a name so I will call
this let me make this all the bigger we
will call this instance India and then
you can choose where to deploy your
instance since we're in Asia
let's choose somewhere in Asia you can
customize your machine type so you can
basically choose what how many cores you
want from 1 to 64 you can also choose
your memory on top of this we also have
pre-configured instant-message machine
types so you can choose a micro instance
or small instance so I'll just pick one
of these next you want to choose your
operating system so we have all the
flavors or Linux and Windows as well so
these are the links instances we have
windows instances I'll just choose a
Linux one you can also install
applications for example if you want to
have a sequel server instance that
there's an application image for that
you can even create your own images so
you can create your own image and then
deploy it here and then you can use it
in your own project so for this one I'm
just going to use a Linux instance and
I'm gonna also allow HTTP HTTP traffic
and hit create and this will give me a
Linux instance running in the cloud and
then once it's up and running which will
be like 30 seconds or so you can easily
SSH into it so there so known here
there's SSH and if it's a Windows
instance you can RDP into that by just
clicking here and you can just directly
go right in there and I also mentioned a
cloud launcher so if we go here there's
something called co-op launcher it has a
bunch of different solutions that you
can install such as lamps like WordPress
I can for example search for asp.net
this is a solution for deploying windows
server net framework IAS and sequel
Express so here I will just do launch on
compute engine give it a name
asp.net let's say India and then o let's
say India too because I already have one
and this time let's choose Australia and
just keep the defaults hit deploy so
with this one click I can get
the server is sick Express and asp.net
framework and I can just deploy my
applications to Google cloud all right
so let's compute engine on the other end
of the spectrum in the highly energy
managed part we have cloud functions and
the idea of cloud functions is that you
define a node.js function with inputs
and outputs and you also define how that
function should be triggered so the
trigger can be an HTTP request or it can
be a pops up message so when a message
goes to a topic then that triggers the
function for you and then that's it you
just deployed a function and and Google
maintains it for you and you don't
really care where it's running how it's
running you just specify where your
function should live in motor zone and
that's it so just show you an example of
this as well so if you go back here
under under compute we have color
functions and in the first page you can
see all the functions that you have
deployed so I have a function called
hello world
once you click here you will see the
function invocations so how many how
many times people call your function you
can see what kind of trigger it has so
this is a pop subtopic function you can
see the source of the function and it's
a really simple function that takes an
event and just logs out the events
message and you can even test it right
here so you can trigger the event and
say let's pass a message and say hello
India and then if you hit test function
now this is running in the cloud it
already run and you it will fetch the
logs and you'll see the constant log out
once you get the logs here okay so
that's functions functions are really
great and they're really easy way or
they're running your code in the cloud
in a way that you you know it's like
completely like the infrastructure is
complete transparent to you but
sometimes you need more than a function
you need an application so for that we
have App Engine in App Engine it's this
it's similar to cost functions in the
sense that you deploy your application
and you don't really care where that
application is running but it's more
than a function so you can have multiple
services now in App Engine you can have
a front-end and you can have a backhand
and you can just deploy the whole thing
together and App Engine just manages
that for you so let me show you that
quickly as well so in in console again
it's the same place we go here appengine
the first thing that you realize is that
there's a dashboard so you have multiple
versions of your application and this
version is getting 51 percent of the
traffic this is getting 49 percent and
then you can see the graphs for latency
traffic CPU utilization stuff like that
these services are the micro services
that you can do poorly on App Engine in
this case I'm just having a one default
service and then under versions you can
see the different versions that you have
so I have two versions running on two
instances so these are running on two
VMs and this is Auto scale by default so
it will auto scale from 2 to 20
automatically so you don't have to do
anything special for that if you want to
change the traffic allocation so that
lets say your new version gets all the
traffic I can easily change this to a
hundred percent it's safe and this will
drag all the traffic now to the new
version so that that's App Engine and
the last thing I want to talk about is
kubernetes engine so kubernetes engine
is basically a way to run containers in
the cloud humanities is an open source
project and it can run anywhere but we
try to make it really easy to run in
Google Cloud so that's what kubernetes
engine is so we maintain the master for
you and we also give you an easy way to
create your cluster and and and schedule
your containers so it sits between
serverless world and the virtual machine
world so if you want to be somewhere in
the middle where you have containers you
can use kubernetes engine to do that and
then we have tools we are continually
and continue registry for containers so
you can create containers in the cloud
using container builder it's a really
fast way of building containers and once
the containers are built they are saved
into a place called container registry
this is a private space for your
containers and once your continuty is
saved there you can deploy it to
kubernetes or you can deploy it to App
Engine really easily so that's how you
run your code in the cloud and one thing
that I want to point out when you're
running your service in the cloud you're
running in the same network that powers
all these products so the same network
the power is Google Google search Gmail
map serving 1 billion user each you are
running in the same network as well and
so all the improvements and
optimizations we do in our network for
our own services they benefit you
indirectly because of that and this is
how our network looks like
you can see all the edge endpoints and
you can see all the cables all around
the world so it's a it's a truly global
highly optimized fiber network all
around the world okay so that's how you
run your code now let's take a look at
how you store your data thanks Metta so
at a high level storage is is easy you
write some bits and you read the bits
and hopefully you get the same thing out
that you put in I have the feeling that
some of the folks here are looking at my
graphic and wondering what these things
are it's a young crowd but actually it's
pretty complicated stuff so anybody that
implements a real-world storage system
knows about this there's all kinds of
consistency issues acid semantics
scaling issues replications all sorts of
really fundamental computer science
challenges crop up in building complex
storage systems and there's a lot of
different ways to store data right so
this is kind of a very high-level
summary of all the different products
and what they're good for and I'm not
going to it's a bit of an eye chart not
going to walk through every every
product one at a time but I will kind of
break it down into some categories but
when I look at this I kind of have the
same reaction I had with the 8080 icons
slide it's like I just want to store
some bytes why do I have to learn all
this stuff and I'm gonna go through a
few different subcategories to hopefully
help clarify this so the first category
I like to think about is structured data
and the mental model for this is a
spreadsheet so this is where you have
your data's got a well-defined sort of
set of fields and the rows and the
spreadsheet correspond to the instances
of your data and the columns correspond
to the fields in your schema so this is
a pretty familiar way to go and you know
this is the classic relational database
system and it's driven most frequently
by a very standardized query system
called sequel and we have two different
products in this domain we have cloud
sequel which gives you the ability to
create managed database servers in the
cloud so you're still thinking about
servers and you have to decide if you
want my sequel or Postgres but the
backup of the database
the administration of it SR the
maintenance keeping it up and just
managing those servers is taken care of
for you so it takes a lot of the hassle
out of your hands and then spanner is
kind of a level of abstraction above
that it gives you a true
database-as-a-service
capability where it's global has all of
the asset semantics you would expect
from a relational database management
system and it's you know multi region
very scalable and has really a
tremendous set of value for for a
database service the next category is
unstructured data this is also called no
sequel so the mental model I have for
this one is it's a little bit like a
library you're storing data in a library
or books in a library I should say so
there's a very efficient index that you
can use to find any book on any shelf
but the contents is totally unregulated
right the librarian doesn't care what's
in any particular book and there's no
uniformity all the books have different
content and so it's kind of a little bit
like what a no sequel database is like
there's a key that gets you to the the
value you care about but the content or
structure of that value ism is up to you
and we have data store which is
hierarchical distributed key-value store
fire store which is ideal for for mobile
applications and real-time response type
scenarios and BigTable which is really
well-suited for huge volume
transactional financial transactions IOT
event sources things like that and all
of these are again managed services in
the cloud you don't have to think about
where are the nodes how many do I need
how do I configure them and install
software just make your database calls
and all everything else was taken care
of for you
the last category I want to talk about
is an object store so the idea here is
it's a lot like renting a storage unit
at one of these places where you where
you do that where you look rent a locker
or something like that and you know
there's a physical space there where you
can put your stuff and it doesn't matter
what you put in there it's up to you and
that's kind of what these object stores
are like you have you'll have a bucket
and you own that bucket you can put as
many objects in it as you want there's
no rules about the content that goes
into them and you have security
protections on it which is kind of like
your key to the locker
and you can serve those objects from the
cloud you can even serve websites
directly from these storage buckets so
that's kind of a quick overview of the
different storage products we have
there's a lot more to it but I did want
to jump into spanner again and just
highlight it because I think it's really
interesting and really revolutionary in
many ways what spanner does is it it
kind of bridges the gap between
traditional relational database systems
which are very strong in terms of data
integrity and consistency but have
always been a challenge in terms of
horizontal scalability right a lot of
people have had to do sharding and lots
of elaborate techniques to scale up
these systems and then on the other hand
you have the non relational systems the
no sequel systems which are great with
horizontal scaling but they're often not
giving strong consistency or as much
acid semantics as the relational
database families and what spanner does
is it kind of gives you the best of both
worlds so I'm just going to quickly jump
into a little demo on spanner
don't see it
there we go okay so I've got an instance
of spanner you can think of an instance
as collection of databases I've got one
here that I've called GDD India and
inside that instance is a database
called University so I've kind of
fabricated a typical database for
university consisting of three tables I
can drill down into these tables
professor has a collection of professors
with a professor ID and a name and so on
and basically you're looking at
something that looks very much and feels
very much like a traditional relational
database management system but I have no
concept of where the software is running
or keeping it administered or anything
it's all taken care of for me I can also
manage the schema directly here so let's
imagine that this student table needs
another field let's decide to add right
now I have a name a major and a student
ID let's add a GPA so we'll say GPA and
we'll give it a float type say done and
save and spanner will basically tell me
that it's gonna eventually the old
schema will continue being served until
the update completes and so it's gonna
now update my database in real time but
the nice thing is it's never going to
take the service down I can continue to
serve tremendously high volumes of
requests while it's updating my database
in the background which is really
convenient the other nice thing is let's
suppose that I just I'm wildly
successful with my database and the
traffic far exceeds the capacity I can
simply drill down into my instance I can
click Edit instance and there's a place
here called node a field your called
node I can change that from 1 to 3 and
click Save I'm gonna pay for more
capacity if I use it obviously but I've
just tripled the capacity of my database
I didn't have to talk about machines
where they might live what I might do
with them I just said triple my capacity
and the database is now going to be able
to serve 3 times the amount of requests
and that's it for spanner next up we'll
cover
data yes thanks mark so once you give
people a way to store data they're gonna
store a lot of data and then the data
gets really big so how do you deal with
that how do you deal with big data
that's what we want to cover here so big
data processing at Google static with
MapReduce who heard of MapReduce on you
or use MapReduce okay so people know
it's a it was a paper in 2004 that came
out you can really do a really nice
paper to read and not any MapReduce we
basically explained how to take lots of
data divide that into small chunks and
then send them to the multiple parallel
machines and then process those that
data on those machines and then combine
the results in the end to get the result
so after MapReduce there was a lot of
innovation at Google so we had things
like BigTable and then we have min wheel
for stream processing we had flume Java
for high level pipeline modeling and we
had Spanish that Mike just talked about
and most of these they were either
papers or they were internal
implementations at Google so it wasn't
available to outside world we recently
of course started like making these
available to people by a Google cloud so
pops up and spanner there enough
services in Google cloud that you can
use but at back in the day there they
weren't available to people so people at
Apache they seen that and they read this
papers and they started creating
open-source projects so they created
Hadoop which is an open source open
source implementation of MapReduce they
created spark and hive and all these
open source project but because the
innovation was split into two we have
two products in Google cloud to support
both so all the innovation at Google
ended up with something called cloud
dataflow it's a model and also a service
at fully managed service to do batch and
stream processing and if you are already
doing Hadoop and spark in the open
source you can bring those clusters to
Google Cloud so there's a product called
Cloud Data proc where you can get a
cluster in 90 seconds and then and just
run your Hadoop and spark classes in
Google Cloud and when you are dealing
with big data there's a life cycle that
you need to go through so mark will
explain us what that life cycle is
thanks typical life cycle involves five
steps first off you need to capture some
data and there's a lot of products
available to do that the one I'm going
to highlight today is cloud pub/sub
which is a mesh message
q you can have multiple providers and
multiple subscribers and so we can
motivate this a little bit with a
real-world example imagine that we have
a very popular website like Wikipedia
and we want to capture all of the events
from people viewing pages on Wikipedia
we could stream those events into
pub/sub and then we could have those
events routed into our data processing
phase now the data processing might
involve something like data prep which
is a kind of data cleansing rearranging
normalizing service and then from there
it might be fed into cloud dataflow
perhaps now cloud dataflow is just as
meta was speaking about earlier is a a
processing stage very much based on
MapReduce it can perform mass bulk
processing on batches at a time or it
can process streams as they're arriving
which is great for IOT and transaction
based things from there once we've
processed the data we might want to
store the intermediate results so we can
analyze it without having to continually
reprocess it there are lots of places we
can store it as we just saw one of the
key ones if we're doing analytics might
be bigquery so bigquery gives us this
columnar database that enables very fast
sequel based storage of the data we've
stored so from there we can use tools to
analyze the data there are lots of
different tools but the one I'll show
you in a moment is bigquery we've got it
in the database and then we'll do some
queries on this and finally we might
want to do something with these
analytics we've done we've interrupt on
Orianna our interactive analysis and we
might want to have a nice way to share
it with other folks coworkers rest of
the world and that's where data studio
comes in that's a service for building
dashboards nice visualizations and data
lab which is a hosted in the cloud
jupiter notebook service so for people
that like interactive notebooks it's
particularly popular in the data science
world data lab is something that you
might want to take a look at
so here's what bigquery looks like and
what I'm doing is I'm running a query on
a data set that actually corresponds to
the example I just talked about so I
have all of the data for page views on
Wikipedia from May of 2016 and I'm going
to run a very simple can people see this
I'm gonna run a very simple query that's
just gonna sum the requests and we can
just wait while it does that and it
tells us hopefully soon took 5.2 seconds
it tells us how much data was actually
processed so it was 38.6 almost 40
gigabytes worth of data it just did a
scan in five seconds and it told us the
number of events as you can see here I
think this is 19 billion so almost 20
billion rows it's scanned in that amount
of time now we'll make it just a little
bit more complicated I'll do a query
here for all the Articles that reference
Bangalore so I'll pull this up here now
it's a little bit tricky I could just
match Bangalore but in English there are
two spellings Bangalore and Bengaluru
and so the way I'd like to find both of
those is to do a regular expression so
here I'm matching bangle and then or or
ruh and sorry that's right here and what
this is going to do is actually run a
regular expression match on 20 billion
rows in a database and you saw it did
that in seven and a half seconds and by
the way this no cache results up here is
an option you can specify normally I
would turn that off because if I run the
same query again I want to see the cache
for speed reasons but I have that
disabled because I want it to be a more
true test but as you can see it did not
only a table scan but a regular
expression of twenty on twenty billion
rows in 7.5 seconds so that's the power
of bigquery
and lastly let's talk about machine
learning because everyone wants to hear
about machine learning if you look at
this chart this basically shows the
the amount of deep learning models at
Google with different products so you
can see the exponential growth of
machine learning at Google and this is
true not just for Google but for pretty
much all all companies so when it when
it comes to machine learning there are
two distinct ways of using machine
learning the easy way is to let someone
learn machine learning and and train a
model for using machine learning and
then you just consume that machine
learning using an API so that's the easy
way but sometimes the trained model is
not enough for you because you know
maybe the trained model is not exactly
what you want so in that you in that
case you need to actually build your own
machine and so you need to create your
model you need to train it in parallel
and you also want to serve that model so
that's the second way of using machine
learning so at Google in terms of using
the models we have a number of API so
there's speech API for speech to text
recognition there's a vision API for
image recognition and there's more and
more that we keep adding so this is the
way that you can consume machine
learning and we are just basically
exposing the model that we created over
the years to you with a simple API so
let me just quickly show you the vision
API so envision API I have a demo here
you can pass in an image and it tells
you everything can about the image so in
this case we have a CAD image because in
any machine learning demo you have to
show a cat that's the role so what you
get is that you you basically get a JSON
back it kind of looks like this but in a
graphical way you can basically see that
the machine learn the vision API is
telling us that this is a cat 99% it's a
mammal 97% it and it's seven even
telling us there is a British Shorthair
cat 96% and it can pick up the color and
you can tell us whether this image is an
adult image or spoof image stuff like
that if we have an image with text like
this one it can pick the text from the
image so this is a traffic sign so the
vision API is already telling us that is
a traffic sign and then from here it can
pick up the text and it can tell us
where it is in the image the text is and
I'll show you
one more with people so when we have
people in the picture vision API it
doesn't detect people but detects
people's expressions so in this case for
example it's telling us that it's a
social group with some folk dance which
is right but then if I turn this on if I
go here and turn this on you can see
people's faces and then you can see that
person - I guess this person is it's
joyful which is nice so that's vision
API and lastly we want to talk about
building your own machine learning
models because you cannot always consume
machine learning models as it is so to
build them there's something called
tensorflow and I can tell us more about
that
yeah so tensorflow is really the
technology underlying a lot of the
machine learning algorithms at Google
it's an open-source project that was
created by the Google brain team was
released about two years ago and it's
become one of the most popular
open-source machine learning libraries
on github it's really powerful you can
build your models locally upload them to
the cloud you can use them to deploy
models on mobile devices so and it's
also got great support for GPUs and
other types of hardware assist so very
powerful there's a link here well I'm
sure we'll get the slides to you through
the through the organization here but
there's a link to a really nice article
by one of our colleagues that gives a
great overview of tensorflow this
graphic just shows very quickly how much
tensorflow has taken off there are a lot
of tools out there and it's good to know
a few of these I think but tensorflow
seems like a really good one to invest
in because it's gotten so much supports
and so quickly the product that we're
using to kind of make this stuff more
approachable and more accessible is
Google Cloud machine learning engine and
the idea here is that just like in the
case with compute where you don't really
necessarily want to care about all the
details of the underlying infrastructure
you just want to write your code and
think about your application the same
kind of thinking applies in machine
learning you want to think about your
model training it debugging it testing
it making sure it's ready for production
you don't want to really be burdened
with
running machines and parallel processing
and all the kind of lower-level stuff
that that Google is very good at and has
lots of people doing all the time so
this gives you that kind of abstraction
layer you can specify kind of a meta
definition of your model using amyl and
then you can use the g-cloud command to
upload your model into the cloud for
training you can monitor the progress
through the same tool we use to monitor
or other applications stack driver
logging and then you end up with trained
models that you can operate on almost
like applications as meta showed earlier
in App Engine you can test those models
with independently through different
URLs and you can change the settings for
which one you want to serve by default
and so on so again it's really taking
you away from thinking about machines
and implementation details to just
operating on your model as an
abstraction and of its own the other
really powerful thing is you're going to
get access to the tensor processing unit
which is custom ASIC Hardware that
Google has developed for its own
internal use the initial version was
used internally only for on the order of
a year and a half and it's very powerful
but it was only for training models and
the new version which is becoming more
available publicly it's much faster and
it's also available for both speeding up
training and serving of machine learning
models so that's all we have I want to
leave you with some resources the the
main site for all information about
Google Cloud is cloud.google.com the
console we've been using is console
Google cloud sorry console dat cloud
that Google calm I'm a great lover of
code labs interactive training tools and
tutorials and if you go to G dot code
slash code labs you can find all the
code labs we've ever published or
something like on the order of 400 of
them and there's a code labs area across
the way that many of you probably have
have already seen you can get the cloud
specific code labs with gqo slash code
labs slash cloud and then finally
there's a training page there for
finding out more about our formal
training programs one important thing I
want to tell you about is the free tier
if you go to cloud.google.com slash free
you can get $300 worth of cloud credits
you
usable across the period of one year
this is a great way to get started and
without having to commit any money
upfront and I think we both believe that
the best way to learn about this
technology is to actually build
something with it so I'd encourage all
of you if you're not already working
with it try it out use the free tier try
building some applications and see what
your experience is like and we always
love to hear good or bad what you're
what you're finding so let us know we
will be over in the cloud also ours area
after this talk that's all we had thank
you very much for your attention thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>