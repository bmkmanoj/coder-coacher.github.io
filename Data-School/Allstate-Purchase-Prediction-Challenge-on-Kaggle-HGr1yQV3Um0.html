<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Allstate Purchase Prediction Challenge on Kaggle | Coder Coacher - Coaching Coders</title><meta content="Allstate Purchase Prediction Challenge on Kaggle - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Data-School/">Data School</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Allstate Purchase Prediction Challenge on Kaggle</b></h2><h5 class="post__date">2014-05-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HGr1yQV3Um0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Kevin Markham and I'm
going to be talking about the Allstate
purchase prediction challenge here's our
agenda for the talk we're going to start
by talking about the goal of the
Allstate competition why this is a
difficult goal to achieve what data we
have access to and what we can learn
from that data can machine learning help
us what approaches worked and what did
not what did I learn and then of course
did I profit so what was the goal of the
all-state competition it was a machine
learning competition run by Kegel and
machine learning is basically the
process by which computers learn
patterns from data the competition was
sponsored by Allstate the insurance
company and the goal was to predict
which car insurance options a customer
will buy so let's get some context
around this problem and then we'll move
on to an example there are seven car
insurance options each with two to four
possible values those values are
identified only by number and then a
quote consists of a single combination
of those seven options and then
customers can review one or more quotes
before actually making their purchase
here's an example this is one customer's
car insurance quote history you can see
there are seven quotes and for each
quote there are seven different options
a through G and you can see the values
they chose for those options and then
the question is what did they actually
purchase well as it turns out they
actually just purchased the options
identical to the last quote they looked
at so that might be a useful pattern to
watch out for here's another example in
this case the customer looks at six
different quotes except for five of them
they're looking at the same identical
options it's almost obvious what they're
going to purchase except that they
purchase something that they never
looked at during the quoting process
perhaps the prediction process isn't
going to be so easy after all let's talk
about the
petition and how it actually works we
have access to some training data which
is 97,000 customers and their complete
quote history including what they
purchased and then we've got the test
data which is 55,000 customers a partial
quote history and then our goal is to
predict what they purchased the
evaluation metric for the competition is
prediction accuracy so why is this
difficult well for one there's over
2,000 possible combinations of options
and importantly your prediction is only
counted as correct if you get all seven
options right so there's no partial
credit and no feedback given on which
options you get wrong and in addition
options are not even identified as to
their meaning all you know is that they
are a through G you don't know what
those options signify so let's first
start with a naive approach to
predicting for every customer let's
simply predict that they will purchase
the last set of options they were quoted
so the good news is that this works
pretty well you get an accuracy of 0.53
793 the bad news however is that
everyone figured out this strategy and
indeed 46% of competitors have that
identical score for that exact reason
but never fear because it's data to the
rescue I hadn't yet mentioned it but we
have access to a lot more data than just
the quote history we have a variety of
customer data we have data about the car
they're trying to insure and we have
additional data about each quote
including the day and time of the quote
and how much it cost so let's start
looking through the data and see what we
can learn from it I mentioned before
that there are over 2,000 possible
option combinations but perhaps only a
small subset of those are ever actually
purchased that would reduce the problem
space significantly unfortunately that's
not the case most of the possible option
combinations do either appear in the
training set or the test set
now I'm going to briefly walk you
through some visualizations I made of
the data this plot simply shows that the
more quotes you have for customer the
better that naive strategy will work the
knife strategy being simply predicting
that they'll purchase the last thing
that they looked at this plot basically
shows that the test set has been
significantly truncated in comparison to
the training set in other words the test
set has a lot less quote data for each
customer on average making this a harder
problem this plot shows that customer
behavior can vary based upon the time of
day that the customers are viewing
quotes and this is an interesting plot
that shows that what a customer chooses
for one option might affect what they
choose for another option so for example
a customer that chooses either C equals
3 or C equals 4 will almost always
choose D equals 3 let's just try
predicting what a customer will purchase
based upon these option interactions we
start with that naive approach to make
what I call the baseline predictions and
then we create a list of rules about
pairs of options and then use these
rules to fix the baseline predictions
unfortunately this approach worked worse
than the naive approach why didn't this
approach work well these rules are based
on strong patterns in the data
but patterns are of course not always
correct and more importantly you don't
actually know how many of the seven
options need to be changed from the
baseline in order to make them correct
the key insight here is that there's a
huge risk
when changing any baseline prediction
there's more than a 50% chance you will
break a prediction that is already
correct and you need to balance that
against the tiny chance that you will
take an incorrect prediction and make it
the correct one in other words it's very
important to only change your baseline
prediction if you're sure it's wrong so
I decided to use a stacked model of
approach meaning that first we would
predict which customers are likely to
change options after their final quote
and then second we would fix the
baseline predictions only for those
customers step one then is to predict
who will change I modeled this with
logistic regression and random forests
which are two common machine learning
approaches and then you evaluate a model
using an ROC curve what you see on the
left is a reference ROC curve that
explains that the yellow line means a
model is excellent the pink line means
that a model is performing well and the
blue line means that a model is
worthless and as you can see my model
was basically worthless no worries
though because we can do some feature
engineering and perhaps that will help
improve the model so this simply means
that we're going to create some new
features by transforming or combining
the existing features my theory was that
these might be less noisy than the raw
features and less likely to overfit the
training data I'm not going to walk
through the new features in detail but
I'll just show some examples I created
new features called family and time of
day this is an interesting feature I
created called state group in which I
clustered States based upon some similar
customer behavior in those states so for
example North Dakota and South Dakota
are in the same cluster because
customers were doing similar things in
those states two more features I created
were stability and plan frequency these
were basically my way of summarizing
quote history for a given customer in a
single number so we're ready to try step
one again we're going to redo our model
except with my newly engineered features
and of course again evaluate using the
RSU curve on the left is my previous ROC
curve and on the right is my new ROC
curve you might not be able to tell but
it's actually a tiny bit better
the one on the left but it's still
relatively worthless however all is not
lost because I had a new insight when
predicting which customers will change
it's actually much more important to
optimize for precision than accuracy in
other words we need to minimize the
false positives by setting a high
probability threshold so for example in
the test set about 25 thousand customers
will change options after their final
quote we don't actually need to try to
find all 25,000 of those customers
instead we need to find perhaps a
hundred of those customers that we are
sure will change and then fix their
baseline predictions now we're going to
optimize for precision I created a
cross-validation framework to predict
the test set precision of my model I
change the probability threshold from
0.5 into 0.85 and I was able to validate
that this approach was indeed working
the next step is to predict new plans
for the customers who I predict will
change there's two options for how to do
this I could build one model to predict
the entire combination of seven options
at once or I could build seven different
models each one would predict an
individual option and then I would
combine the results at the end I ended
up choosing the second option and I used
random forests and a single hidden layer
neural network unfortunately I had poor
prediction results in order for this
seven model approach to be accurate
enough each model needs to be performing
at about 90 percent accuracy
instead my models were performing with
60 to 80 percent accuracy and thus when
you combine the predictions from the
seven different options it rarely
predicted a completely correct
combination of options but I did have a
back-up plan instead of machine learning
I decided to do some human learning and
try to out think the computer so I
located nine customers in the test set
that had a very very high probability of
from their last quote I went through my
list of rules about unlikely option
combinations and one by one went through
each customer looking for options
combinations seemed unlikely and
changing them I tweaked my combinations
by comparing them against my random
forest model this is a very
time-intensive method but I figured I
could convert it into a pure machine
learning model if it worked
unfortunately it was a huge waste of
time because it did not work time was
running out in the competition but I
came up with a new strategy there was a
tip in the capital forums that
recommended that you should locate plans
that were rarely purchased and then
replace those plans with more likely
alternatives so in my estimation these
are probably combinations of options
that simply don't make sense to most
people
note that this approach completely
ignores all customer data and focuses
purely on the plans the tasks from here
are first to determine which plans are
unlikely so I calculated a view count
and a purchase likelihood for every plan
and then I needed to determine the best
replacement plan for each unlikely plan
so I was just tallying which plans were
actually purchased by those who viewed
them I calculated a metric called
replacement plan commonality and then
for all of these values I simply set
thresholds that determine how many plans
would be replaced and what plans they
would be replaced by and as it turned
out it worked it improved upon the
baseline approach and as you can see I
moved up 365 places on the leaderboard
just by improving on my best score by
point zero zero zero to four so I went
to work tuning my three fresh hold
values and submitted many different
combinations to Kaggle my best
submission beat the baseline by 0.06
percent and that's not a typo it's point
O six percent not six percent and even
the top competitor was only beating the
baseline by 0.7 eight percent
proving that this is a very challenging
problem here are the details of my best
submission so all we do is we start with
the naive approach to make our baseline
predictions and then if the plan on the
left is predicted any one of those five
plans we simply change it to the plan on
the right note that this approach
completely ignores all work I had done
up to this point in that it doesn't use
any of my models or any of the features
I engineered I also wanted to see if I
could improve this approach so I tried
stacking this approach with one of my
existing models but that didn't succeed
in improving my test set accuracy I also
came up with some other ideas but
ultimately ran out of time to actually
try them in my estimation the top
competitors are likely using an ensemble
of models that incorporates this
approach somehow so what did I learn
from this competition
number one early on in the competition
try many different approaches because
you need to give yourself time to
iterate upon a proper approach rather
than going down the rabbit hole of an
approach that doesn't actually work
number two smarter strategies Trump more
modeling and more data just because you
know how to build a model and you have
access to a lot of data doesn't actually
mean you need to use those things in the
end the strategy that worked best for me
had nothing to do with any modeling or
most of the data I had access to number
three real-world data is hard to work
with it's much harder to work with than
the kind of data you're usually given in
a machine learning textbook for instance
it's not necessarily obvious what to do
with all of this quote data that you're
given how to learn something from each
and every quote it's a very challenging
problem number four algorithms and
processes that allow for rapid iteration
or priceless so even though there are
algorithms like random forests that tend
to perform well they also take a lot
longer to run than logistic regression
so I ended up most
using logistic regression because it
allowed me to rapidly iterate through
different models and number five learn
from others around you there's so many
different approaches you can try that
it's helpful to see what others around
you were doing so that you can use that
knowledge to help focus your efforts
thank you so much for your time I hope
you enjoyed the presentation I've got
here a link to my github repository
where I have a paper I wrote about this
competition as well as all the code I
used and it also includes a link to the
Kaggle forums where many different
competitors are discussing their own
approaches to how they solve this
problem</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>