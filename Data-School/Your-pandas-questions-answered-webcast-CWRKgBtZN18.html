<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Your pandas questions answered! (webcast) | Coder Coacher - Coaching Coders</title><meta content="Your pandas questions answered! (webcast) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Data-School/">Data School</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Your pandas questions answered! (webcast)</b></h2><h5 class="post__date">2016-10-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CWRKgBtZN18" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right hello folks we are live all
right welcome to the event
the pandas event your pandas questions
answered so before I get into any
logistics or an introduction I just want
to make sure you can see me and you can
hear me so if you can see me and you can
hear me go ahead and and in the chat
just type where you are right now where
are you in the world ah let's see
Germany San Francisco Miami - from
Germany Finland San Fran New Delhi
Atlanta Tel Aviv Columbus Spain another
Germany Connecticut Portugal NYC so that
this is great very cool
feel free to continue to post thankfully
no one's at least that is responding is
having problems if you do run into
technical problems at any time during
the webcast um first you can try just
posting in chat and seeing if others are
having the same problem most likely you
know your your maybe your connection is
slow or something like that but usually
the solution with crowdcast is just to
refresh your browser or to go ahead and
try another browser um people have told
me that Firefox works really well I'm
using Chrome but really up to you but
that's usually going to be the solution
if you have any technical issues okay so
um a couple logistical items and then
I'll introduce myself and then we will
get started so um I posted a link in
chat which is of course buried now but
let me post it again right now and there
it is um okay so that is a get obsessed
and it just has five lines of code but
it's lines to load
for example data stats and if you want
to follow along with the code today
which is completely optional um you can
just watch if you like but if you want
to be coding along at home I'm gonna be
using some example data sets and you
might as well load them now so that when
I start using one you're not stuck on
not having the data set and having to
figure out how to get it so go to that
URL five lines of code run it in your
Python editor of choice and you'll be
basically ready to follow along with any
code I use during the webcast okay so
that's one thing second thing is if you
have not already participated in the
polls there is just right under the
video there's a polls tab and go ahead
and click on that and there's a couple
polls um see I'd love to know a little
bit more about the folks that are here
um and if you uh if you have some more
time and want to you can scroll down
further and look through the questions
pick out some that are of interest to
you and go ahead and upload them I will
be answering the questions roughly in
order of popularity
I might get through all of them I might
not I don't know um so might as well
pick out the questions that you are
particularly interested in and have some
influence on how I spend the time today
okay so those are just some logistics um
a little introduction about me so my
name is Kevin Markham and for those of
you who don't know I'm the founder of
data school I teach data science in
Python online predominantly I'm online
and predominantly Python and my my goal
is to make data science more accessible
so that you can either launch or
accelerate your data science career so
that's my overall goal and I hope that
some of the resources I put together
like today's webcasts are helpful in
making that happen
okay my background is in computer
engineering and I've spent a lot of time
in the classroom teaching data science
and now I'm mostly doing it online
though I was in the classroom just
yesterday in DC with some data science
students at General Assembly giving a
guest lecture yeah but I love Python I
love data science love teaching and
personally I am 36 years old live in
Washington DC in the United States lived
here about 11 years and got married a
couple months ago so those are some you
know random things about me so that's it
on kind of intro just to talk a little
bit about how it's gonna work today I'm
gonna be answering questions as you know
I'm gonna go about an hour maybe longer
if I feel like it and there are still
questions left
we'll see or whenever my voice gives out
which has been known to happen what else
um just looking over it a few notes on
things I wanted to mention okay so in
terms of the chat so the chat you're
posting in that's good for like
commenting on something I'm talking
about right now so if I'm answering a
question and you have a follow-up go
ahead and post it in chat if you have a
new question something that I'm not
talking about at that moment go ahead
and post it like use the big orange
button underneath the video that says
you know ask a question click that
button type in your question there hit
enter and that way I can get to the
question kind of separate from what I'm
talking about right then and I will try
learning learning I will try it's hard
to I it's actually very hard to talk and
read chat messages at the same time but
I will do my best to try to pay
attention to the data as well but it may
be challenging so
what else this is being recorded all the
questions will be time coded so you can
come back to this recording later and
just click a button that says view
answer and it will jump to that point in
the video when I answered it and it will
save you some time if you just want to
watch that one thing I'm not gonna spend
a huge amount of time on any one
question because there are a lot of
questions so this isn't like a 20 minute
tutorial on something I so I reserve the
right to skip the complicated questions
or questions I don't know the answer to
because I don't know everything in
pandas I know a lot about pandas and I
teach pandas but that doesn't mean I
know everything so I may skip things I
might not have a good answer for every
question but I will do my best okay so
with that let's just take a quick look
at the poll results and see who's here
and I just clicked on polls and it looks
like in terms of Python experience it is
most almost all beginner and
intermediate very few one advanced and
almost nobody who reports they have no
experience just a few folks pandas
experience level no one who says they're
advanced a lot of beginner and
intermediate but all levels welcome here
and have you watched my video series on
pandas most popular answer is I've
watched all 30 videos which I cannot
believe so thank you for spending all
that time with me that's like seven
hours of video unless you watch me
faster which is which is fine too but
yeah the video series by the way there's
a green button just below the video says
watch the pandas video series you can
click and you'll get to that you can
check that out after the webcast okay
we're nine minutes in I want to get
questions so let us jump in
oh my screen so that will just take me a
moment all right
okay all right
and let me minimize my face so you can
actually read what's on screen that's
the gist that I was talking about I'm
actually going to be in this ipython
notebook which is not something I've
posted but that's the environment I'm
gonna be using here and you can use what
you like at home okay
one more second and let me jump right in
with the first question okay question
from Eric Chen actually one of my
students can you show the best way to
use group by and pivot function on a
pandas dataframe okay um the best way
all right well I'll interpret that how I
like let's see what data set so I've
loaded my data sets here and I'm gonna
use the drinks data set for this one and
so I'm just showing the head of this
data set just so you have a bit of a
picture of it so how might we use a
group I well a group I is to answer the
question like for a given category for
each category summarize some numeric
about that category okay so one you
might do is drink stock group by the
only one that would kind of make sense
in this in this context is continent and
I won't
I won't say too much about the data sets
other than like you know this is a
country and its alcohol consumption per
year and this column contains the
continent so if I group by continent and
select for instance the beer servings
series and I can check the mean
so what I've done here with a group by
is to say for each for each continent
group by continent for each continent
what is the mean of the beer servings
series okay so for each continent we now
have it outputs a series and it has the
name of the content and its mean beer
servings so the answer for when you use
this is when you have a question that
you could phrase as for each continent
for each gender I want to know something
about a group okay I want to summarize a
group in some way what's the max beer
servings for each country sorry for each
continent so you just have an
aggregation function here at the end and
that's the usage of group by follow-up
question how to get multiple columns at
once so you could do let's see um well
let's see if you wanted you're asking
how do I get the oh okay you're asked I
think this will provide your answer and
then we can all talk about it but if you
leave out the column it will do that
operation on all of the columns so what
is the max beer serving spirit servings
wine servings total liters and country
for each continent okay and for the
country column it just used the last one
alphabetically okay the second part of
that question is about the pivot
function I might I'll talk about that a
little bit later but that's probably
more of a subject the like of a full
tutorial okay I mean one second
all right next question can you explain
the differences and when to use a pen
versus contact Marge vs. join pivot
versus pivot table versus crosstab and
stack versus unstack okay Bobby here has
done something very clever which is to
put four questions in the same question
each of which could take a while but I
mean it's a good question so I'm going
to give you kind of short answers
because teaching all of these could take
the whole hour
but um upend versus concat upend let's
see so concat is a top level method
meaning you would say like pd docked con
cap and a pens data frame method so you
you would say like data frame name dot
append and um concat is a is a more
general method it has more capabilities
append is more narrow so I actually
never use append I only use concat and
it's to concatenate either rows on but
basically you've got two data frames
either with the same columns and you
want to add them stack them on top of
one another or they've got the same rows
and you want to stack them next to one
another that's what you use concat for
so short answer I never use append I
always use concat second merged versus
join um kind of the same merge is a
top-level function so you use PD dot
merge join I think it's just a data
frame method so like data frame name dot
join and just like before so merge is a
more general more general function with
I think more power than join and I don't
think you ever need to use join I would
recommend you always use merge okay I
never use join
I don't think there's a compelling use
case for join maybe there is but I just
recommend using merge all right number
three pivot versus pivot table versus
crosstab okay um I would say that pivot
table is the most general and if you're
going to learn one of those I would
invest the most time in pivot table it
has the most options I think you can
accomplish all the same things with a
pivot table that you could with pivot
and crosstab but even more so I would
stick with a pivot table stack versus
unstack number four um so the way I use
unstack is when I have a let's think I
have a multi index and I want to go to a
regular index let me pull up let me
think about let me get a good example
for this so that you can see something
on this so if I do drinks that group by
continent dot your servings dot describe
okay that gives you a hierarchical a
hierarchical index okay it's a series
but it has a hierarchical index okay now
um if you want to turn this into a
single level in X you use unstack okay
and it kind of moves the data around
okay um I don't know how to better
describe it it changes the shape of the
data so it has a single level index
stack is the opposite um and it goes
back from a single level index to this
multi indexed or a hierarchical index
okay so that's one example of kind of
etiquette I guess at a conceptual level
what stack and unstack do um beyond that
I don't I don't know what I want to say
about that they just do their reverses
they're opposites of one another okay
all right next question
all right from Raphael
besides series and data frame I'd like
to see some examples using panel data
how to move from data frame to panel
data and vice versa
okay you you guys start guests and girls
are starting with the more complicated
questions okay
so panel data let me come up with a
quick example so that we can have visual
and then I'll kind of comment on panel
data okay so um let's see all right I
gotta create a data frame and so I'm
gonna pass it a dictionary and I'm gonna
add a couple columns and what I'm gonna
do is I'm gonna create the data frame
I'm gonna create a hierarchical index
and then I'll show you how to turn it
into a panel and back into a data frame
um so let's say we have some games how
about I want to save on typing I
wouldn't bother following along with me
on this one if you're following along
because it's gonna be more than a little
bit of typing so we've got some names
how about so those are maybe people's
names these are days one two one two and
you'll see what how this kind of all
makes sense in a second
oh actually I need quote throwing that
because these are column names will say
wait so these are two people measuring
their weights and heights so we'll say
100 103
and one 31:29 this works and maybe
heights um about this person grew an
inch in one day and this person did not
okay
so sorry for that
typing here's art be afraid okay so it's
two people a and B and they're recording
the day day one or day two
what was their height day and what was
their weight that day okay so if I set a
multi index so I'll say the F got set
index okay um I guess I will let's see I
think in the videos I've only shown
setting a single index which you can
actually set a multi index and maybe
we'll do name well it would make the
most sense to do name and day and now we
have a hierarchical index okay so what
you're kind of looking at here is for
each person we're looking at their kind
of day their you know it's kind of the
natural groupings like using just a or b
is the index you've got these duplicate
days use if you used day is the index
you've got duplicate names and you
really want kind of the logical grouping
in the data is you've got a person and
then the day like this person here's the
height and weight on day one here's
their height and weight on day two same
thing for B so this kind of makes more
conceptual sense this is a hierarchical
index and you can turn it into a panel
by with this method two panel okay and
you get something that I don't really
understand I gather that panels are from
econometrics and I'm not I don't work in
econometrics so I don't really
understand the kind of major axis minor
axis
kind of thing but it's through it's
three dimensions okay so that's why it's
called three dimensional data and it's
got an item's axis and major axis and a
minor axis but really it's just and to
get from a panel back to data frame use
this to frame method it's really just
representing the same things as this
hierarchically index data frame but just
in a different way and perhaps you slice
it differently okay or there are
different operations I think there are a
lot more operations for data frames with
hierarchical indices so I'm I'm not
actually sure if you gain anything by
converting to panels and it's possible
that in the future panels may just
disappear so I don't necessarily
recommend investing a lot of time
learning panels unless it kind of makes
sense for you but for me for this kind
of structured data I would just use a
hierarchical index okay all right next
question let's see from Wolfgang
actually also one of my students what is
the most efficient way to identify
outliers in a data frame okay um
outliers I think the best answer I can
give is that well first you need to
decide what counts as an outlier okay so
what is an outlier you could use some
sort of statistical definition but that
may not capture what an outlier means to
you so I think the first thing is
deciding what an outlier looks like and
one method would be to write a bunch of
rules a hard-coded rules or filters to
just filter the data frame looking for
those particular cases I know that
sounds very manual but it's a manual
approach not a kind of machine learning
approach another way you might do it is
with like a visualization
so um let me see what dataset I want to
use how about the drinks data frame okay
so still this data frame countries with
their alcohol consumption amounts and
how about actually let's just use dot
plot and let's use a box plot
okay so whoops there's one thing I
missed which is if you want plots to
appear in the notebook you should use
percent mat plot live in line okay and
and let's run that again and we'll see
our box box and all of these plus signs
are outliers according to the
statistical definition now this doesn't
allow you to see what like what you what
is up what are those observations it
allows you to see that for spirit
servings there are some outliers but I
don't know if that's really useful to
you so there's no like catch-all way to
do outlier detection in pandas I would
tend to use a machine learning approach
or I would tend to just explore the data
and hard code some rules for what counts
as an outlier and maybe write some
filter conditions for that okay um all
right next question from Amer how do the
pandas data structures series data frame
and panels compare to our data frames
okay is there any difference in ease of
manipulation or efficiency between the
two okay um all right let's think here I
don't know so pant let's start with data
frames
pandas dataframes and our data frames
are roughly similar um the main things
that I remember thinking about when I
learned pandas after I learned are is
that in are your data frame row names
like in our data frame row names are or
I think like look down upon or it's
discouraged
you're discouraged from storing useful
data in the row names okay the via if
the idea in our and our data frames is
you want to store all the useful data as
columns
okay now pandas dataframes have an index
and that index kind of looks like row
names but the in pandas dataframes the
index is required
there's no way not to have an index and
no one will ever discourage you from
storing useful data in the index and in
fact putting something useful and
ideally unique as the index is a good
way to use it because it allows you to
reference those rows using the row names
okay so that's probably the biggest
difference I noticed another difference
is that in our there's like the there's
a difference between a missing value and
not a number and in PI a Wellington
pandas because of numpy there is no
difference between missing value and not
a number they're the same thing okay so
um that's the dataframe differences i'm
there are probably more but those are
the ones that come to mind
pandas series is kind of like a vector
in R and I don't think there's any big
difference there well I guess series
have an index and vectors don't I don't
write much are anymore so I don't I
haven't thought about this in a while
panel data I don't know if there's
something
like panel data in our if someone in the
chat knows feel free to chime in but I'm
not aware of something like panel data
in our it probably does exist though
okay great question okay um all right
next question is from tox ads is how
I'll say your name or moniker hi for
filtering rose
I saw you sometimes to use the syntax DF
bracket row filter criteria and
sometimes use the syntax D F dot Lok row
filter criteria comma colon is there any
difference in performance or some other
reason why why you should use the
different methods or approaches okay I
like this one I I have let me show you
what he's talking about first so that in
case you're not familiar um let's see
let us use let's try movies okay alright
so let's say I only want to look here's
something I did in the video series I
only want to look for movies with a
duration a greater than or equal to 200
okay that is one way to do it
alright Rather's the entire data frame
okay and all I did is I pass this
condition into this bracket notation
okay and it filters the series okay
now the alternative that is identical is
this and I'll just copy paste for ease
okay well the movies dot Lok and I will
explicitly put the comma and the colon
okay so movies dot low
okay the Lok method is using for used
for selecting rows and columns this is a
condition that says what rows do I want
and this says what columns do I want and
it turns out that a colon means all okay
so this is these rows all columns I
could just say I only want vision or a
column I may have to put it in brackets
I can't remember okay so I could just
get that column or I could get all
columns the question was why do I do one
versus the other
well I teach the first one because it's
what most people use so you need to
understand that code you need to
recognize it and know what's going on I
teach the second one because dot Lok is
super powerful and you need to know how
to use Lok and like I guess maybe in an
ideal world everyone would write their
code like this but you know programmers
or you might be one um you know this
like kind of looks this is a tiny bit
harder to read it's got more kind of
extraneous stuff and the first one just
looks cleaner so this one's more
explicit the first one's cleaner you can
really use either the answer is no I
don't use it for performance reasons and
I'm pretty sure they have the same
performance but you could check um the
one exception I would say is I would not
here here's an alternative okay okay if
I just want to select the genre column
okay though both of these I know you
can't tell but both of these two output
the same result okay I just want the
genre column I um
this is I'm getting the data frame and
I'm selecting the genre I'm doing the
same
thing here okay so uh the the thing is I
would net I would rarely do the first in
this case I would always do the second
okay now why is that okay that has to do
with the setting with copy warning that
you'll see on occasion if you try to
like assign something here and that's
because this first line is actually to
operations whereas this second line is
one operation under the hood and so
there is some efficiency to the second
operation but the first operation can
confuse pandas okay if you are trying to
do an assignment okay so the bottom line
is if you're gonna pass a condition and
select out of column I highly recommend
using lok if you want to understand this
in more depth I've got a video about the
setting with copy morning okay all right
Oh in chat Francisco asked what's the
difference between our and pandas in
terms of the language I'm not sure I
understand the question
I mean they are like the structures are
similar but not identical but they have
different syntax so it's learning a
different language essentially um it
that's just the bottom line it's like
learning a different language okay next
question what about the jobs for pandas
in Bangalore okay uh-huh
uh well first I'll say I have no idea
about jobs in in Bangalore or in DC for
that matter I don't I'm not looking for
one and so I don't I don't haven't
thought much about it but here's here's
how I would rephrase that question if
you'll allow me
Rajesh I would rephrase that as how do i
how do I get a job
be using pandas and I think the secret
here maybe it's not a secret it's an
open secret but companies don't hire you
because you know a language companies
hire you because they think you can
solve their problems ok so if you want
to get a job with pandas or any skill
for that matter or a data scientist job
what you want to demonstrate is not
necessarily fluency with a language or a
library those things are useful but what
you really want to demonstrate fluency
with is problem-solving you want to
convince the company that you know how
to solve problems so if you're looking
for a job with panda that uses pandas I
would build a public portfolio on github
maybe also a blog where you start with
the question and a dataset and you
answer that question using pandas and
you write about it so that they know you
know how to use pandas they know how you
unit they know you know how to solve
problems they know you know how to
communicate all of those things are just
as important as the technical skills so
that's what I'll say about getting a job
using pandas okay on to the next
question from Jeff how do you clean /
pre-process / tokenized text in a data
frame without appending it to one long
list so that it is a series of lists so
I appreciate the question I stared at it
for a while and I don't I'm not sure I
understand I don't understand
what you currently are creating and what
you want to create which are kind of the
key aspects for me helping you to
troubleshoot here so I don't know I
don't know a specific kind of answer to
give you here I will say that if I'm
gonna clean text I will do you if it's
strange
I'll use panda string methods and those
there are tons of them and I highly
recommend learning panda string methods
tokenization I actually don't ever do in
pandas that I can think of maybe some
trivial tokenization but I would almost
always do that in scikit-learn using
safe mount vectorizer so whatever
structure you can always do something in
scikit-learn and then take the output on
numpy array and put it back in pandas so
that might be a solution but ultimately
it's hard for me to say without spending
some time understanding this problem in
more depth and what you're trying to do
so my apologies okay next question from
Gus what is your favorite way to style a
data frame on the web when exporting to
HTML okay well data frames do have a
method and I think it's called each
sorry I think it's just a data frame
method like to underscore HTML um that
will eight output HTML I've act I've
honestly never used it myself so I don't
have any ideas on styling data frames
however my overall recommendation is
just that well I I put things in Jupiter
notebooks they are great for
reproducibility like reproducible data
analysis and data science so if it works
for what you're trying to do and the
audience you're trying to communicate to
I would recommend putting things in
Jupiter notebooks and that way they can
see the code you use to get your output
data frame maybe that won't work for
your particular your particular problem
but that's what I would tend to do I'm
sorry I don't have a better answer there
all right
see oh okay
Jeff followed up with well I can iterate
a little pain in this data frame and
append it to one long list but what if I
want a list of Lists that is cleaned um
I still don't quite understand I'd have
to see an example if you write me like a
small piece of sample code and show me
what you have and then show me what you
want
I can help but um
yeah other than that I just I'm not
super clear on exactly what you're
looking for
let's see there have been some other
questions that have come up in chat and
I'll just encourage you to put them
click the button the orange button that
says to ask a question and put it there
so on a ket asks what's the difference
between pandas and numpy um Adrian asked
what are the apply functions from R in
pandas so I'm going to asks do PI do
pandas and R use the same commands if
you want me to answer them go ahead and
put it as a question click the orange
button and type it there because that
way I can timecode it and keep track and
people cannot vote it if they're
interested so that's really what I would
recommend okay back to the list top
question and all of these I'm answering
right now have one vote so you can get
your question right to the top by
posting it and hoping someone up votes
okay so next question what is the best
way to get value counts value counts
normalized along with row column and
grand totals in a single data frame okay
obvi alright let's write some code here
value counts what do I maybe I'll use
maybe I'll use drinks how about that all
right
drinks dots how about continent
continent dot value counts here is value
counts okay if you want value counts
normalized I'll do that as well
let's see and I think there is normalize
equals true okay so that's the
normalized value count so this is
essentially a tally of how many of those
entries exist this is the normalized
version so what percentage are Africa
what percentage are Europe row column
and grand totals I mean if you're
looking for like a row and column sum
you could do something like this
active drinks dot some axis equals zero
and like drinks dot some axis equals one
so those are totals so this is a sum
over axis zero so it's essentially what
I would call the column totals but some
people might call them row totals I'm
not sure what the quote proper
terminology is these are the inverse so
this is moving across from left to right
taking the sums of those numbers so
those are how to get those pieces of
data separately how do you get them all
in the single data frame and I think the
answer is you don't because like here's
how pandas and excel are very different
excel you can kind of like put stuff um
all like in Excel you can just put stuff
all over a sheet and it doesn't have to
be connected you could have like a chart
in the upper left corner one data set as
like a little on your on the right
another data set below it they can all
interact
um pandas is not like that a dataframe
has an index and that index identifies
like the contents it identifies its the
identifier of the row and all of the
rows kind of have to conceptually mean
the same thing so when you ask for all
of these things to be in the same data
frame my answer is you wouldn't put them
in the date same data frame now you
could use concat to put these two things
in the same data frame and maybe I'll do
that right now I feel like I haven't
been writing as much code as as all of
you are expecting so I will try to write
a bit more code so let's just save these
as a and B and we'll do PETA concat and
we'll pass it a list of objects to
concatenate and we'll say axis equals 1
to put them next to one another and here
are those two things next to one another
but I wouldn't know how to get these
other things all in the same data frame
and just to kind of hammer home the
difference between the axes in terms of
concatenation this would stack them okay
axis equals 0 would stack them axis
equals 1 puts them left and right next
to one another okay all right great next
question all right someone followed my
advice and people are voting on
questions love it is ro asked what's the
best way to convert non numerical data
from multiple columns in a data frame to
numerical form for machine learning
purposes okay
so I've got two things I'm immediately
thinking of and let's see how I can
demonstrate them okay so here's our
drinks data set let's look at drinks D
types and all my numeric columns are
already
numerix but let's pretend that the beer
servings column was actually a string
okay and let's store it as a beer okay
now we've got this column that looks
like a number but we need it to be but
it's actually a string so let's take a
look at the key types and it's actually
object type which is because it's a
string so what we actually need is it
for is it is for the beer column to be
an integer so I would just say drinks
dot here dot as type int or as type
float your choice and you will get the
numeric version now I don't know if
that's exactly what you are asking for
um okay
you asked about for multiple columns in
a data frame okay so if I needed to do
this on a bunch of columns I would
probably do it one by one so that I
could make sure I'm getting the results
I want um you can use like an apply
method with the top level function to
numeric um but that can do some
unexpected things it can error out for
various reasons you can tell it to
ignore errors there are some downsides
to that um there are there is some
discussion in pandas like I've seen it
on github about how to make this kind of
stuff a little easier and there are
different functions for doing this but
none of them is like the one function to
rule them all in other words there's not
like one recommended way and all the
other functions are useless it's kind of
this patchwork of different approaches
you could use and at some point in the
future I have a feeling they are going
to settle on a better way for this but
the moment you can research ways to do
it all at once I would tend to do it one
column at a time now if you're talking
about here's my other answer if you're
talking about categorical data okay and
you want to take categories and turn
that into put that in usage in a machine
learning model I recommend using dummy
variables and I've got a whole video
about that just check out the videos and
look for dummy D um my and you'll see
how to make those conversions but that's
kind of more than I want to get into
during the webcast okay um great
question though all right um tokes adds
let's see what's Oh something else just
jump to the top uh-huh
sorry all right okay
JC vol I use the vlookup function in
Excel all the time is there a way to do
this in pandas okay the answer is yes um
let me think
I made a note to myself on what dataset
I wanted to use to answer this let me
find that oh okay
I've got it okay I think this wall this
wall all right um I wrote down I want to
use the movies data set and I remember
why okay here's the movies data set and
let's so vlookup if you don't know what
it is I don't know how to like
succinctly describe it other than you're
like translating well I'll show you how
to do it in pandas and then even if you
have no idea what you look up is you'll
know how to do conceptually the same
thing so I will skip trying to explain
vlookup without having Excel open okay
so let's just do a value counts of
content rating content rating got value
counts okay so here are the different
options for value counts and let's
pretend so here's my kind of problem
that vlookup would solve in Excel okay I
want to define I want to define like a
mapping where if you have content rating
of our I want to put let me just
actually make the mapping with a
dictionary and I'll just call it mapping
if you have content rating are I want to
map that to UM like no kids will be at
this movie if I have a content rating
pg-13 there will be maybe I'll just say
say no like no kids would be at this
movie yes kids will be at this movie PG
we will say is also yes okay so this is
a mapping from like what I want to be
able to do with the vlookup is every
time there's an R I don't want to add a
column that says no and every time
there's a pg-13 or a PG I want to add a
yes okay so that's conceptually what
vlookup is doing so how would we do that
it's actually pretty simple if I
remember how I wanted to do this I think
we are going to just use map nothing
okay so that actually did it and let me
add this as a new column so you can well
whatever
um the point is all I did with this map
with this series map method is I told it
like here are the source values if you
will and here's what to substitute for
it so our
Maps - no pg-13 maps DDS PG maps TS so
thus we should get no no no yes no and
indeed we get no no no yes no and I get
some NA ends because I actually didn't
define all of the different possible
mappings I didn't define G etc you know
G yes okay so I didn't define all those
mappings but if you had a complete chart
this mapping this map function would
result in a series of nose and yeses
okay all right um all right let us move
on to the next one
um I'm a total newbie to pandas hashtag
best prepare for the webcast
well thanks ray for the question I you
know obviously the webcast is happening
so I can't give you a good answer there
but I can tell you that after the
webcast if you're a total newbie to
pandas I strongly recommend my pandas
video series I put a huge amount of
effort into teaching pandas kind of from
from ground zero and if you watch the
series you should get a strong kind of
foundation in pandas okay um
toks ads I would like to get something
similar to a cross tabulation but with
my own master rows and master columns my
data okay I won't read all this out I so
it's it's really hard for me to picture
this without seeing it um it would be I
could maybe do this if I have like an
exact like example and here's what I
want but I don't think I'm gonna be able
to come up on the fly with an answer I
would say maybe a pivot table but I'm
not sure without really seeing exactly
what you're looking for
sorry to disappoint I just some
questions are just too complex
to answer on the fly alright next
question what is future warning in
pandas why is there a function to avoid
it boy there are a lot of questions left
I may speed up and see what I can get
through what is a future warning okay a
future warning is when pandas tells you
that a function you're using is not
going to be supported in a future
version of python it's been deprecated
or it's gonna change how it works in a
future version of python as such um you
should probably rewrite your code to not
use what you're doing because eventually
your code is going to break so that's
the simple answer it's a warning it's
not an error but in a future version it
will become an error okay or it will not
work as you think as it used to work
okay why is there a function to avoid it
Numan asks and so i don't know the
particulars but I know that some people
like to suppress warnings why because
they don't like to be reminded that
their code will one day break maybe um
so I would i don't recommend turning off
warnings um because it's better to just
rewrite your code okay alright alright
there's a follow-up question from the
last one about the mapping what if
mapping was in another data frame so
what if let's see let's see if I can
kind of translate this question so what
if it was like this I think he's saying
so I'll just say map map mapping to I
don't know I'm not being creative here
so let's see
what will happen if I pass this into the
data frame that will not give me what I
want
let's see I would need to change the
shape I would need to say like need to
say like ratings it would be like our
pg-13 let's let's start with that
and then kids :
no yes okay so I may have gotten done
this right it's not I'm okay
so you're saying how what if I had
mapping to okay how would I use that to
do my sorry to do my mapping well let's
see I could figure out how to if I cast
mapping to to a series see what happened
fee that series nothing to will that do
anything no not exactly what I wanted um
I think the bottom line is number one I
might try to translate mapping to into a
regular Python dictionary with this as
the keys and this is the values
alternatively I might do a set index of
let's see I would use ratings and then I
would do a I think I would do a merge
with that work I think I would do a
merge between this data frame and movies
and I would tell it to join on like well
left on well if you've done emerge
well I could try right now PDF merge and
I don't remember all the what the
parameters movies maybe mapping to left
on equals on equals content rating right
on equals ratings no on now on the index
actually okay um oh I didn't set it in
place so actually I will say right on
ratings can't remember this might okay
um let's see if it worked oh sorry that
oh great
kids know where are mine on our movies
oh because all the okay yes it did work
or at least it partially worked I don't
know if there's any n hands left but the
point is using a merge I could map my
arse to nose and pg-13 s - yes I
wouldn't actually set the index and I
didn't do in place which is why it
didn't change so we'll just here's what
I'm actually merging on okay so that's
probably what I would do
okay back to the list of questions Wow
27 questions two left I'm gonna keep
going I don't know when my voice is
gonna run out but keep voting because it
will affect what one's I get - I'm
pretty sure I will not get to 27 more
questions okay alright from mr. B I want
to remove the last 30 rows of my data
frame I tried playing around with i lo
can drop but I couldn't get it to work
alright let's use a different data frame
let's use UFO okay
UFO dot-shaped is 18,000 rows
and mr. bean wants to remove the last 30
rows so what I would do is I'll oak and
I'll oak is about miniature position
so what Rose do I want I want all rose
to the last 230 from the end I think
that should work and all columns I do
that backwards let's see sorry my
computer is slowing down here so it went
through eight yeah I think that worked
okay so let me just confirm with that
shape so all I did is I said integer
positions everything up to 30 from the
end okay this is like list slicing you
know if you have range a hundred okay x
equals okay you have a list of a hundred
numbers
well let's print and if I want to get
all except the last 30 I would say
negative sorry no to negative 30
so from well and let me print that see
see it that's everything except the last
30 so I'm doing the same thing with I'll
oak I want all the rows except for the
last 30 and then I want all columns okay
and it removes those 30 rows all right
from go tug I want to go
sorry I want to create a column for year
/ month from the date/time column for
example if date/time is 2060 no 706 1559
56:19 I want to map 2016 0 7 into a
column ok great
okay so let's use UFO UFO data this time
is a date time because I defined that
during the import okay so because of
that I can do things like this UFO time
dot DT dot year okay and I get the year
out okay and I'm gonna course that to a
string okay and I'll store that as a new
column called
year and then I'm gonna get the month
UFO time not DT DT is how you access
their date/time options okay
dot DT dot month and that looks good
except I want some padding here and I
know there is a padding function trying
to remember if it stopped I think I need
to first change it to a stir and then I
can do dot that's pad does that work
alright let's figure this out pandas API
pandas API STR got padding is what I
want
let's do oh it is dot pad okay dot pad
to fill care equals ill chart equals
zero oops
it's something wrong Phil char width
sorry my computer's being slow dot pad
all right
width equals two triangle 0 series
object okay oh okay this is a string
method now I got it okay here's what I
get I called out the I know it's a long
line of code but I pulled out the time
series then I pulled out the month
attribute I coerced it to a string and
then I'm using the string method pad and
say pad with equals two and the padding
I don't want to pad with a space I want
to pad with a zero okay now um montage
says for date/time can we use stir effed
time I don't know I'm not sure what that
is I try to do as much as possible in
pandas because pandas is so powerful and
things you don't end up having to like
use apply functions and write for loops
and write if statements you can just get
it all done in one line of code so
that's how I tend to do it but there's
always a different way to do things
so UFO month it's that and how do I
finally put this all together and
actually answer the question
UFO dot year dot ster dot what is the
combined method let's see if I want to
is it concat mark think sir dot concat i
don't always remember all of these
pandas functions no that's not concat it
is
let's see cat stir dot cat okay stir dot
cat UFO dot month except equals - I
think that'll work
and look at that alright problem solved
okay so I used I took the year and I
said concatenate that with the month and
separate it with a - okay so that is and
you would just know you can store this
just as a new column okay and you know
forgot hat there you go here's the time
here's the new column there's probably a
slicker way to do this but um I don't
know it so feel free to comment on the
question al said you might be able to
accomplish this with dot - period oh I
don't know um I'm not familiar with that
but it's certainly possible okay okay I
like this question what's the best way
to create a new column or multiple
columns based on pre-existing columns in
a nested for loop and I'm not going to
read the rest of this the answer if
you're saying how can I do this with a
for loop the answer is usually don't do
this with a for loop okay
you rarely need to use a for loop in
pandas now um let me think how what can
I use for this to kind of give an
example
alright let's use sorry let's where are
we here let's use okay so here's the
kind of thing that the @ 2k I think is
is asking about he's trying to make a
call
that's like if sex is male and age is
less than 30 then the column should say
young male or something okay
that's conceptually what he's doing he's
saying if this is something and this is
something then put whatever otherwise
put something else okay that that's
conceptually what he's doing so let's
break this down okay let's break this
down
um the bottom line is you don't need a
for loop okay
you're gonna do this in one line of code
and it's actually not that hard
so let's say let's say the condition is
one of the two conditions is train dots
x equals male okay and you'll see that
that outputs a series of trues and
falses right and let me um yeah all this
let me make this a little smaller so
there's more space down here okay let's
say one of the conditions is sex equals
male and the other condition is train
dot age is less than 30 what I've done
is I've said this condition and that's
what the ampersand means this condition
okay so you want to combine those two
conditions such that the end result is
true only if both of those conditions
are met okay so the first three that
will focus on true false false that's
because this is a male younger than 30
this is not a male so that doesn't work
this is not a male and even though they
are under 30 that condition is false
because there's the ampersand so I
defined two conditions and I've said if
both are true
output true otherwise output false so
how do I turn this into a new column
well how about we do got map and we Mack
true - oh actually I need a dictionary
here now true - uh yes and false - no
and we'll call that train of Brackett
young male ok and it looks look at the
head again and look at that we've got a
new young male column that is yes if
it's a male below 30 and no otherwise
like here's a male that was 35 so it
said no ok so you don't have to write an
if statement or an else you're gonna
have to write a loop you just need to
write conditions that output trues and
falses and you can map those trues and
falses to a variety of well two
different outputs you can map this as
true becomes one false becomes zero like
that would also work and whoops I put
exclamation point true becomes one false
becomes zero that would also work so
there's a lot you can do with just
conditions okay all right graph graph
ethos I'm sorry I'm sure I'm
mispronouncing name
I've asked I've joined this to see if it
is worth to change from R to Python oh
boy that is a complicated question um so
it depends on your task but um I
personally like Python better but that's
because of what I do in Python um I work
with text a lot and I don't like working
with text in our I do a lot of machine
learning and I prefer machine learning
in Python
as far as like data munging data
cleaning data analysis I I'm fine with
both pandas and if I'm doing it in our I
would use deep liar um I don't think I
mean pandas and deep liar they're
different they use different syntax
somewhat um there definitely is a lot I
like about deep liar but should you
change to Python well my belief is
always you should um a couple beliefs
one is you should learn one language
really well before you move on to the
next language number two is there's like
a high cognitive cost of learning a new
language and all of the different
packages you need to know to do what you
used to do in the old language um so
that's an argument for just investing
more into the language you already know
however if you work somewhere that is um
you know uses a lot of Python that's
something to take into account if there
are conferences that seem to focus on
Python and you're your area of interest
and they don't have an AR conference in
that area you might want to think about
learning Python for that reason you know
it's it's really there's not like a
right answer both Python and R or great
languages for data science but if you
have a very particular task there might
be some compelling reason to use Python
or are both or popular at least for data
science python is more popular than are
for general purpose applications so if
you're building a web app off of it it
might be better to learn Python but it's
uh there's not like a strong one way or
another answer I can give you okay I
cannot even believe I haven't even
answered half the questions but maybe
the ones below are easier okay
how to find the top man Tosh says how to
find the top repeating number from an
array with their frequency okay that is
an easier one thank goodness so I can
answer it quickly I'm gonna use Trent
I'm gonna use the value counts method so
if I do trained up P class value counts
I will get the number of rows that had
the P class of three there were 491 the
number with there were 216 ones and
there's 184 twos and that's just a
column from the data frame like
similarly if it was sex you would tell
me that in the beta said there were five
hundred and seventy-seven males and 314
females okay um next one from Ã¸ystein
how can I fill in a based on a condition
say I want to fill n/a for all missing
cities in the UFO dataset but only if
the color is red
okay so this is um kind of a combination
of some of the things we've seen before
fill n/a for all missing cities alright
so we got the UFO greatest that and
sometimes the city is null so UFO got
steady dot isn't all that some there are
25 values of CP that are null so how do
I fill that but only if the color is red
okay so you would do something like this
your forgot low and what Rose do I want
to find I want to find the rows where
UFO dot city dot is null um and we're
sorry and
we're UFO dot sorry bracket colors
reported course equals equals red and I
I have to let me look at sorry my mouse
is acting up here so I'm having a little
trouble navigating let's look at colors
reported I think they're all caps colors
reported that value counts yeah it's all
it's all uppercase okay
so colors report it equals red so just
on its own this just shows me those
columns so I've got UFO dot Lok and what
Rose do I want I want the Rose where the
city is null and the colors reported is
red what columns do I want I want all of
them okay now how do I fill in a based
on a condition
um well if I want to fill the city in
that case I would just put it right here
and then I would say new value okay
that's what I do that's it I think
that's I got that right um so got loke
is great when you want to select out
certain cities I want to say when the
for these rows just specified by a
condition and this column I want to set
a new value okay all right one second
while I use my throat here okay next one
any practical tips for parallel
processing data frames how to achieve
something like a synchronous apply
parallel processing not my area of
expertise I'm sorry can you
parallel processing on a data frame
certainly using spark you could you
would use a spark data frame but can you
do it with a panda's data frame I'm not
sure if there's anyone who knows how if
there's anyone who knows I would love it
if you would post an answer but I'm I'm
sorry I just don't know Adrienne asks
what are the similar apply family
functions in our from our in Python
pandas okay in our you have like apply
and s apply and T apply and L apply and
our fi I've actually forgotten what all
of those do however there is an apply
method there's actually a date frame
apply method so you can do UFO dot apply
or more commonly UFO dot city got apply
and you can pass an arbitrary function
like that'll work
nope what did I do
I'm gonna type float I'm doing something
wrong but it's not completely obvious to
me what object of type float has no leg
alright um anyway I won't try to
demonstrate in code the bottom line is
everything you can do with those apply
methods I'm pretty sure you can do in
pandas
I don't know offhand how to translate
directly translate all of them but I do
know there is a UFO there is a data
frame apply method like this and there
is a series apply method like this oh
and you can pass it arbitrary functions
I've got a video on using the apply
method I think it's video 30 in the
series I would check that out but I
don't know how to like directly
translate the code without relearning
some are that I have forgotten all right
Marvin why isn't it called koala instead
of pandas I
zooom pandas means like pandas is short
for panel data I think and that's why
it's called pandas it's not because of
the animal but it's kind of fun as an
animal so that's why the name is as such
let's see Oh mayor what are some
examples of 3d data that panels are used
for um I don't think of like as I
mentioned previously I don't think of
panel data as 3d data as much as I think
of it as a data frame with a
hierarchical index so that's the kind of
I'm Lea I guess I don't really know how
to answer it other than that I don't
think of it as 3d data would Cartesian
coordinates be considered 3d you could
put that in a panel but I don't know if
it would accomplish your objective so
you should always start with your
objective and then end with the solution
is the panel data the right solution
probably not is a hierarchical index the
right solution I don't think so but it
depends on your goal ok so that's the
best I can say there tokes ads are you
planning to continue the video series
about pandas in any way or is it just
gonna stay at 30 videos provided don't
get me wrong the series is great but I
think not all pandas topics are coming
yet of course not all the of course is
of course not everything is covered
covering everything would probably
require hundreds of videos and I don't
think I could make hundreds of pandas
videos I would get tired of it
eventually am I gonna continue it well
probably I enjoyed making it a lot the
30 videos I did create the videos at the
beginning took me about four hours per
video to make and by the end because the
topics we're getting more complex it
probably took me
eight hours of video um so if I want to
continue with the series that's kind of
me can committing to like using one day
a week um of my work day of my work days
to give away a free video which I
probably will do but I have to think
carefully about that tree off because
I've got a lot of other projects in mind
so working one day a week on pandas
means only four days a week for any
other projects so yes is the likely
answer I don't have a timeline it will
be an intermediate topics I assume
because I've covered most of the basic
topics but I can't promise when it might
be okay Scott preferred visualization
method for exploring data native pandas
map plot lib ggplot etc I use pandas as
much as possible because my data is
already in a data frame
and I can do it in one line of code most
of the time um matplotlib is what's
working under the hood and I tend not to
write matplotlib code because I I find
it a little bit painful to do it's just
not how I think um so I find it
challenging so I tend to I mean I mostly
make exploratory graphs anyway so doing
it in pandas seems to work fine most of
the time ggplot i have not played around
with but now that it's under active
development once again I am planning to
try that out because I do enjoy ggplot
in in are I really like ggplot in R so I
will probably learn ggplot in Python at
some point and see how I like it there
but I can only imagine I will like it
because I like it how it works in our
Seabourn is another option and I like
using Seabourn it's it produces kind of
pretty visualizations it make
certain things that are painful to do in
pandas or matplotlib it makes them easy
so Seabourn is another one and I like
Seaborn I've used it many times but the
one downside is it's yet another
interface to learn it's yet another
library to learn so the short answer is
I do as much as I can in pandas okay all
right al asks when and how should you
use filter the pandas dataframe filter I
have never heard of filter but I will
pull it up on my second screen and scan
it ah and on first glance I have no idea
when to use it um I would say that me I
don't know I don't know I'd have to look
into it I've never used it personally
sorry about that at all okay he's
getting uh you know if you go to you'll
get you'll get your your quota al % %
time versus % % so time it run something
three times and I don't think it out
ball let's just try that so if I do % %
time it ah whoops let's see it's a sell
magic but the sell did I what did I do
wrong here got oh is it just personal
yes sorry one person
okay so I'm not sure like I get infused
about the one versus two percentage
signs but I don't want to use time it um
so time it runs it three times and tells
you how long it took time runs it once
and actually outputs the result okay so
I usually use time because I actually
care about the results you use time it
if you don't care about the result you
only care about seeing how fast it ran
okay so that's the difference I don't
know the parameters for time it okay
ah boo difference between pi spark data
frame and pandas dataframe need to know
when to use each so pandas dataframe is
good for in-memory computing
okay so spark is good for distributed
computing you shouldn't use spark if you
don't need distributed computing but if
you need distributed computing I don't
think you can do it in pandas to my
knowledge maybe you can and if so pipe
spark or spark in general accessed by PI
spark has a data frame structure and
that data frame structure has like
similar methods to the pandas dataframe
but they're not identical pandas is
going to be easier to use eventually
spark may catch up but you're better off
sticking with pandas unless you need
distributed computing okay Don asks tell
me why I can't plot there's no graph in
my results just like this okay so what
the problem Don had is he's trying to
plot something and it didn't appear and
if you recall that happened to me
earlier in the webcast before
I said matplotlib in line okay in the
Jupiter notebook if you wanna want plots
to appear in notebook you to run
matplotlib in line at least once
well you only need to run at once now if
you're not you know ipython or the
jupiter notebook okay I think what you
need to do is to import mat plot lib got
pie plot as p LT and PLT dot show okay
I believe that's what you need to do if
plots are not appearing in your Python
environment um and you're not using
ipython or the notebook you run the East
this code but I could be wrong I'm in
the notebook so often that I sometimes
forget okay Kiran how to check if two
data frames are the same equals is not
working also how to find the Delta
between two data frames hmm uh okay I
actually don't know if there is a way I
mean so he's saying that like say well
let's do a little test let's see how can
we do this UFO - no I don't wanna do
that one um drinks two equals P V dot
read CSV if that Lee / drinks by country
okay so let's do that and let's also do
drinks and we're saying drinks equals
equals drinks - and ah okay it outputs a
list it outputs a data frame of of
boolean's okay so here's what I would do
I would stay dot some
we'll change it to not equal okay so
this is what I would do I think so I'm
checking in how many cases these cells
in drinks are not equal
- drinks - and there's no difference in
this case okay now if I changed like
drinks bracket let's do that
I'll oak zero comma zero to be something
else
okay now there's one difference okay so
that's the meth that I would use but
that relies on them being mostly well
they have the same index at the very
least I think they'd have to have the
same number of columns and everything so
okay if you can believe it I'm still
going and there are still questions all
right I'll keep dry a lot of folks have
still stuck with me so a lot of folks
have still stuck with me so I'm gonna
keep going because my voice is not run
out from Erica how would I go about
removing subgroups from one data frame
column okay so what we're trying to do
is filter a data frame by multiple
categories okay so let's say let's look
for let me think which is a good one
how about we'll go with drinks - okay
so filtering by multiple categories so
if I only wanted to keep Asia and Africa
I would say drinks got continent dot
what's the method I'm looking for is in
and I pass it a list of Asia Africa
and that will show me only the rows
where continent is Asia or Africa if I
want to get all the ones except Asia or
Africa I would just add this tilde which
means not which means to reverse trues
two falses and falses two trues and I
get everything except Asia and Africa
okay so that's what I would do make sure
when you have these cases again I will
emphasize you don't need to write for
loops
I'll just glance at the chat for a
second let's see actually I'll come back
to the chat at the end if I still have
time and a voice all right
from Joe is there a way to get describe
to include mode and median values okay
good easy easy one for me but if you're
new of course it might not be easy so if
you say drinks got year serving stop
described it tells you the median that's
what this fiftieth percentile means
these are the percentiles this is your
five number summary your min or max
you're meeting your 25th percentile your
75th percentile and so there's your
median okay if you have a categorical
column like continent not described it
tells you the mode and it's right here
it's labeled as top okay uh Bala
Merrigan how will I specify all else
during a map command for example if I
want to map mail as one and everything
else as zero in a dataframe column how
can I do that
okay um let's see let's um let's use
head again I'll use actually these
drinks - I didn't screw it up drinks -
and
let's see let's say I want to create a
new column where if Asia if it's Asia
then I want a 1 otherwise I want a 0 ok
drinks to dot eva equal sorry drinks to
that continent equals asia and that well
actually there's a really simple way to
do this
it gives me trues and falses and i can
just say as type and and it gives me
ones and zeros okay so everywhere
there's that it's asia you can get a 1
otherwise it's a 0 if you had a more
complicated scenario you could do like
you could do an or and there's there
might be a simpler way to do this
actually there is but I'm not going to
do it right now continent equals Africa
and then wrap this whole thing and that
and now we get those and we could say
well we could just there's lots of ways
to do it from here I whatever example I
was thinking of I lost it but I was
gonna add some complexity but no need at
this point
um that's how I tend to do things Allah
is as type A Lot I used map a lot and I
use conditions a lot Scott asks I use
modes sequel Python combo are there
performance reasons to do aggregation in
sequel or should I just pull the
granular old data
um so pandas is pretty well optimized
I'm not sure kind of the two options
you're giving me what you mean by pol
granular level data versus aggregation
in s sequel just speaking to performance
pandas is pretty highly optimized you
could write the same code you want to do
in paint in sequel using pandas which is
faster it's hard to say without it's not
my area of expertise but
they're both generally well optimized
depending upon the particular operation
so it's hard for me to give strong
advice you hear other than I try to do
as much as possible in pandas cuz I know
it well
but if you know how to do a sequel well
you can do some stuff in sequel first
and then export the results and then
load it into pandas at that point
Miguel is there an easy or automated way
to switch or translate from a script do
it to a Jupiter notebook yes there is
well from a from a script to a Jupiter
notebook you yes I don't know it offhand
but I would just copy and paste it into
the notebook from a notebook to a script
what you want to use is something called
and be convert okay Jupiter and be
convert and you do it the command line
and there are some examples here and
it's how I take my notebooks and turn
them into scripts so you end up writing
code like and I'll just I'll just put it
in like you would do this at the command
line you would say something like sorry
you know Jupiter and B convert dash dash
to Python and I have a template so I
would say template and then template I
have this template called clean TPL and
then I pass it like the name of the
notebook - book dot i py and something
like that will convert a jupiter
notebook to a python script and again
you do that at the command line okay
Kumar can you please explain how to
detect and filter outliers I actually
talked about that earlier
you just have to define what an outlier
means and either visualize looking for
it or write some hard-coded rules or you
could perhaps use
machine learning obby asks when are you
gonna start a video series on tensorflow
I don't know I may eventually it won't
be in the near future but I do get a lot
of requests on deep learning series
Kumar asks what's an indicator matrix I
think that's pretty far beyond the scope
of the webcast so I'm gonna leave that
alone
well I mean I think I think offhand I
know what it is actually I might be
thinking of the identity matrix which
might be different from the indicator
matrix so I don't want to get the wrong
answer here and give you bad advice so
I'm simply just not going to answer that
one today okay
Carlo about duper notebook with print DF
the text is getting right aligned when I
use DF a float is left-aligned is there
a way to get the float in the data frame
aligned on the decimal sign not that I
know of but as always feel free to make
a comment under this question if you
know personally okay I'm Kat what's the
difference between pandas and a numpy
array so pandas is built on top of numpy
numpy under the hood everything in
pandas is for it as an umpire raised
there may be some exceptions to that but
I'm I'm pretty confident in that
statement and the thing with numpy
arrays is that everything has to be the
same type but pandas makes it so you can
have heterogeneous types so you can have
different types in every column
different data types in every column
pandas gives you a lot more high level
operations numpy is more fact focused on
how to do computations really fast
pandas takes advantage of that but the
bottom line is if you're working with
kind of real world data I generally
recommend using pandas rather than by
ciarÃ¡n asks what our primitive methods
in pandas are they more efficient than
others I actually don't know what a
primitive method is maybe it's a method
that's called by other methods I would
say the following don't overthink how to
get something done in pandas if you if
you know of a way other than like ok
here are the signs that you should
probably try doing things a different
way number one you're writing if
statements number two you're writing for
loops number three you're right apply
statements or apply method now apply is
sometimes super useful but sometimes you
can replace it with a built-in pandas
function so that's how I would optimize
my code I don't know about primitive
methods I'm gonna guess that well I
don't even want to guess bottom line is
I wouldn't focus on which pandas method
I should use if I'm using a built in
pandas method it's usually been
optimized and you don't want to try to
overthink yet alright I think the final
question that's been posted when to use
the brackets when writing conditions to
filter always safe to use them um
brackets are when you want to pass it to
something else so if my condition is
drinks dot continent equals equals
Africa brackets don't belong there okay
however if I want to pass that boolean
series to a to a data frame in order to
filter rows I use bracket notation and
that pulled out the rows in which there
was a true similarly if you're gonna use
dot lok or dot i'll okay i acts
or dot IAT which I don't even know what
it does I just know it exists but these
dot like Lok and Iloka specially you
need to use brackets and that's just how
it works okay
oh he asks when to use okay
I meant combining two conditions okay
great question so he's asking if you
have two conditions like drinks that
continent let's say or equals equals
Asia okay you actually if you use
multiple conditions in pandas it's
actually required that you use
parentheses okay it is required like um
what's what did I do
not Lok that's not what I want I just
want plain old this okay so it is
required that you use parentheses if you
are using multiple conditions and
passing it to bracket notation okay that
is all the questions there
I will glance through the bottom of the
chat for other questions
Kevin how long at Francisco asks Kevin
how long did it take you to master our
before changing to Python I I don't know
um I don't know if I mastered our I
don't know if I mastered Python I spent
maybe a year in our before I started
learning Python maybe six months in our
but I wrote a lot of our code during
that time so that helped um yeah I I you
know that's I guess that's all I would
say um number of loops al asked for time
it what's the difference between number
of loop the number of times the cell ran
the number of I think that's the same
thing I guess I'm not sure um okay a ROG
asked please recommend alert
path for a successful career in data
science I know it's off topic but I'm
sure but I'll be glad if you answer this
okay I'm gonna give you a secret okay so
if you go to data school this is not
anywhere public so to those of you who
have stuck around the entire time I want
to give you something special so go to
data school dot io / talk Python whoops
talk Python okay a to school dot io /
talk Python so this is something that I
gave to the listeners of the talk Python
to me podcast okay and it's a guide on
launching your data science career and I
spent a lot of time writing it and I
will eventually make it kind of fully
public but um since you asked and since
you stuck around till the end I wanted
to give you that so again it's the
school dot io / talk Python and I'll
just paste it in chat for you okay
so check that out I will eventually make
this maybe a blog post or I will or
something else but for now it's just
kind of set as private and it's got all
my advice in there okay let me let me go
back to my face cuz I am done showing my
screen let's see alright one second and
close the screen our height so to those
of you who very I am very impressed you
stuck around all the way to the end
thank you so much for joining me a
couple end notes before you leave number
one the recording will be available
shortly on this page the all the
questions will be time coded you can
click on it and it will jump right your
question okay if you haven't already I
highly recommend watching my pandas
video series it's free on YouTube
there's fur
videos just click the button underneath
the video that says watch the pandas
video series if you enjoyed this and
want to see another webcast I would
encourage you to follow me on crowdcast
so find something I've written in chat
and I think you can just like click on
my name and it will take you it will
take you to a page that's like my
profile page and you can click follow
and then you'll get announcements every
time I have a public webcast if you want
to follow me elsewhere go to my website
it's just data school I oh and there's
little buttons here for Twitter LinkedIn
github I have a lot on github I'm active
on Twitter I'm going to launch Facebook
page and I'm I've got obviously lots of
YouTube videos so if you want to
following me there feel free ok
I do teach an online course called
machine learning with text in Python
there's a link to it on my website it
just go uh you know scroll below this
sidebar and you'll see something that
says data school courses click on that
if you want to learn some more from me
and I have online courses and let's see
if you're not already on the on the data
school newsletter I've added most of you
I'll be adding the rest of you soon you
can unsubscribe of course but it's a
great way for you to hear about new
tutorials what it's great way to hear
about when I record new videos because
quite frankly subscribing on YouTube you
may never like YouTube doesn't
necessarily email you when I come out
with a new video you might may never see
it in your feed so that's why I like to
share everything with my newsletter
though that's kind of like my community
really glad to have the data school
community so again I will be adding
either the newsletter shortly if you're
not already on it and you can definitely
keep in touch with me
that way alright just doing one last
scan
through the comments see if there's any
other things toque sad said will the
recording be on YouTube yes I will
upload it to YouTube Kieran said it
would be great to have a webcast on
scikit-learn
I may do that I don't know if it will be
this year I would love to do it I I let
my newsletter subscribers vote and they
narrowly picked pandas but you know so
many picks I could learn that I kind of
want to do one of those as well um and
there you go so it was such a pleasure
for you guys to join me you guys and
girls to join me today
thanks again it was really fun I'm gonna
go eat some lunch and rest my throat
have a good rest of your day and I'll
see you on YouTube you can reply to my
newsletter and I will get your email and
I'll usually respond so okay again
thanks for joining me and I will see you
later
that's it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>