<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Getting started with machine learning in Python (webcast) | Coder Coacher - Coaching Coders</title><meta content="Getting started with machine learning in Python (webcast) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Data-School/">Data School</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Getting started with machine learning in Python (webcast)</b></h2><h5 class="post__date">2016-08-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xhiqLYx3R08" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey so we should be if you can hear us
say where you are from in the world in
the chat I'm gonna say where I'm coming
from so type in your city country your
your general region your timezone if
you'd like instead alright excellent so
it sounds like people can hear us cool
those folks from all over the place okay
so let's get started here first I
believe there are a lot of folks who
probably haven't seen weekly Python chat
before and I don't know if I've ever
really said what weekly Python chat is
on a video so for those who are new
weekly Python chat is a thing I do every
week sometimes on my own I teach a
Python related concept or we just chat
about something sometimes probably about
half the time now I bring in a friend an
Internet friend someone I've met in real
life someone I've never met before maybe
to talk about something sometimes we
chat about a thing that's Python related
sometimes something totally not Python
related and sometimes we show off some
code or teach something this chat it's
with Kevin Kevin Marcum I met you yes
let's see we met each other through idea
and internet I think you signed up for
my email and I wanted my welcome email
which is awesome because broken emails
are one of those things people who have
mailing was - who send you an email that
says I would like you to talk with me he
does the coolest feeling if someone
responds to you and actually says
something because you're like meeting a
real person oh be the internet that way
so I was really happy to chat with you
over email and then we both on that we
were gonna be app icon yeah we both do
some kind of teaching stuff we both do
things on the internet so it was really
cool to meet you in person
at PyCon so if you've got anything to
add there maybe - maybe I lied a little
bit about an introduction add something
else but I've heard it yeah no thanks
first thanks so much for her
Mitra this is gonna be really fun
looking forward to it and looking
forward to trying out crowdcast seems
like a neat way to interact with folks
and the chat and the video and all that
so really appreciate you having me on
here so myself I'm the founder of theta
school and in data school I make videos
and tutorials and blog posts and such
about data science very focused on
python these days I also run some online
courses my background is in computer
engineering and I spent a lot of time as
a data science classroom instructor
really love teaching and love Python
love data science classroom is really
fun but I like to reach more people
people that don't live in Washington DC
where I live so that's why I started
putting together a lot of things for
online and overall my goal is just make
data science more accessible um to kind
of the rest of us if you will so those
without PhDs or deep mathematical
backgrounds or a lot of specialized
domain knowledge how do we make data
science accessible so that's that's kind
of my goal and just perfect well let's
see my birthday was a couple weeks ago
just turned 36 I live in Washington DC
and a couple weeks ago I also just got
married so that was pretty exciting
and yeah so been a busy summer is is
what it's been so cool thank you thank
you
awesome congratulations so you I guess
I've never really introduced myself
before for people who don't know I
usually get paid to do training in
person I used to do consulting now I do
training mostly for companies on site so
I I like doing this online mostly for
free right now just chatting with people
online it's really fun to both teach
people and learn from people I make most
of my money from on-site training you
been successful enough to make your
living off of teaching people around the
world through the internet it sounds
like is that what yours yeah yeah I
school that is all I am doing cuz
everything if I found that when I was
even when I was just doing class wrong
production certainly it certainly that
helped with a lot of kind of my practice
for instructing and for thinking through
how to teach things and try out
different ways of teaching but the only
way I can put out a ton of free content
high quality content and also create
courses that cost money such that I can
actually make a living the only way I
can do that is full-time so that's why I
am I'm focus full-time on deta school
which has been really really funds
though yep chat school oh sorry good yes
if anyone does have AV difficulties I
guess let us know in the chat
unfortunately it's hard to tell when the
crowdcast is hiccup being it for
everyone or when it's just for you
refresh the page if you have a trouble I
saw a couple people as saying they had
difficulties in the chat Kevin I want to
let you take it away now I know you've
got some stuff prepared that you want to
teach us and then we'll go to Q&amp;amp;A
afterwards so cool cool cool so I'll
just give a brief introduction of today
and then I'll tell you when I'm ready
with my screen tray um so my um the the
first part will be pretty structured um
my agenda is simple in terms of topics
number one I want to talk about like
what is machine learning and how does it
work and some of you will already know
that if you don't it's fine because I'm
not presuming any understanding of
machine learning and the second is we're
gonna build a machine learning model in
python using the cycle library and i
will be doing the code and you are
welcome to code
or not totally up to you I'm I would
encourage you to ask questions
throughout and then what would you say
about the best way to ask questions Trey
is it the chat or below or what what's
the how should that go hello there there
is a big orange button that says ask a
question or suggest a topic if you could
click on that to ask your question topic
or even cooler if you said look I'm
trying to solve a specific problem
something that that's really my own
thing if you could give me a little bit
of feedback on that maybe especially if
you're new to machine learning I noticed
a lot of the questions are pretty
advanced questions do not be intimidated
to ask a question if you're in machine
learning a lot of us are I know very
little about machine learning so if you
could ask questions on my behalf that
would be awesome so scroll down below
the video click that big orange button
for questions during your your spiel
here Kevin when you're teaching us if
everyone could if you have something a
reaction that's you know in real-time
feel free to throw in the chat the only
problem with asking questions in the
chat is it's going to get lost as
everyone's seeing it scrolling pretty
quick so scroll down below the video to
ask your your questions cool that sounds
good so do ask questions throughout I
will answer a lot of the questions at
the end and as tre said a lot of the
ones below the video that have already
been asked are on the more advanced side
and I can't really answer those without
kind of building a common framework that
we're working off of so I want you to
understand the basics so that when I
answer a question about it you'll have
more context so a lot of I will answer
at the end so I let me go ahead and put
my screen on screen if you would Trey
and maybe I need to click it again here
all right I did sorry all right
yeah awesome awesome thank you so I am
going to be walking through what are
called some Jupiter notebooks and I'm
gonna use them a little bit like slides
but we're gonna also run some code in
them so what is the printer notebook I'm
not gonna focus on that because it's not
not critically important but what you're
looking at on screen right now is a
jupiter notebook which is a
browser-based python environment and
with that environment you can blend code
and markdown and plots which is why
they're really cool
for teaching and for displaying your
work however let me be very clear it is
not at all important that you know what
the notebook is that you use it today on
when we write code you can write it in
any Python environment you like so don't
worry about the notebook but just know
that that is what you are seeing on
screen now that being said the notebooks
that I'm going to partially walk through
I will go ahead and put a link to them
in chat and that way if you are
interested in like open up those
notebooks and you know how to do it
here's a github repository where you can
do it I've put that link in the chat
there okay so um let's see okay let me
just go ahead and jump right in with the
content and so we're gonna start off
with just talking about you know what is
machine learning and if you will a brief
agenda what is it what are the two
categories of machine learning what are
some examples and how does it work how
does it think okay and the reason I want
to talk about this is especially if
you're the type that just wants to jump
in and write
code I totally understand that that
interest but there's no point in writing
the code for if you don't understand
kind of the foundational underpinnings
of machine learning so that's what we're
gonna hit here first before we write any
code okay so what is machine learning
alright and this is a definition I stole
from SEM I stole from Yan Laocoon who
runs artificial intelligence the I think
the artificial intelligence team at
Facebook he's quite well known in the
field so what is machine learning
it is the semi automated extraction of
knowledge from data so there's a lot
packed in that sentence and I'll just
highlight it right here if you wanted to
kind of follow along um the semi
automated extraction of knowledge from
data so what does that mean well first
you have to start with a question okay
machine learning is not a process you
apply without a goal you have to have
some sort of goal and that goal is in
the form of a question and you believe
that the answer to your question is in
data okay you have access to data you
believe it has the answer to a question
so that is the goal of machine learning
now I'm calling it the semi automated
extraction of knowledge from that data
so I'm gonna answer my question in a
semi automated fashion its automated in
the sense that a computer is providing
that insight and you will see that today
the computer is learning something on
its own however I'm calling this semi
automated because it requires you to
make smart decisions so that is all to
say that machine learning is not an
automated process it's not a fully
automated process it is a semi
my automated process there may be a time
in the future when machine learning is
just click a button and it just happens
but for now it does require expertise
and practice and experience to be good
at it okay so that's kind of the basics
of machine learning and I'll give you
some examples in a moment and then I
want to hear your examples or what you
you guys and girls think are examples
and we'll talk about them but that at
the high level is machine learning now
there are a number of different
categories of machine learning and the
biggest one at least in terms of
popularity and utility is called
supervised learning so that is one type
of machine learning and the the way
supervised learning works is you make
predictions using data okay so one way
you might summarize supervised learning
is that you are learning from the past
to predict the future okay in all cases
for machine learning you're learning
from the past
but in the specific case of supervised
learning you are learning from what's
happened in the past to predict the
future okay so for an example let's
pretend you've got a spam filter or
rather your email software has a spam
filter and it's deciding whether every
email you receive is it's spam or is it
non spam and non-spam is another word
I'm sorry is it spam or non-spam and ham
is another word for non spam which i
think is brilliant and kind of funny but
um so the emails that show up in your
inbox are ham and the things in your
spam folder are spam so that is an
example of supervised learning okay
there is an outcome we are trying to
predict and in this case the outcome is
what is the email is it spam or is it
hand
okay there's an outcome we're trying to
predict and I'll talk in a minute about
how it decides but it's learned from
past examples so what's what's an
example and just throw this in the chat
if you have an idea
what what do you think is an example of
a supervised learning problem that you
can solve with data okay let's see if
anyone's post anything here yeah Alan
mentioned a minute ago my use case is
the classification of test failures
okay so there's some sort of testing
process there are successes and failures
the thing you're trying to predict is oh
maybe it's he's got different types of
failures and he's trying to decide which
type it is he's trying to predict which
type of failures occurring or perhaps
he's predicting failure or success
either way that's a great example of
supervised learning read says face
detection so that yeah that's great
so face detection is kind of you could
frame it as supervised learning by
saying here's an image is there a face
yes or no
so we've trained a model which we'll get
into in a minute on on past images of
faces and we showed a new image and we
say is there a face
you could also frame it as where is the
face that's a little bit trickier to
explain how that would work
Francisco at mentioned regression so
regression is a type regression is a bit
of a complicated word in that it refers
both to a machine learning model and the
type of supervised machine learning so
I'll get back to that Ricardo said a
diagnosis based on clinical features oh
great
so you've got let's say you're a doctor
you've got a patient that comes in and
they have certain symptoms and you want
to diagnose them um it might be funny to
think of it to you as like a prediction
but because you're like well either
you're right or you're wrong you're not
predicting you're identifying but in the
language of supervised learning that is
prediction because you believe there is
some truth that you're trying to quote
predict so you can think of supervised
machine learning as predicting or
identifying um if predicting sounds
strange but that's great I'll mention a
few more that have been in here let's
see detecting objects in an image great
great predicting house prices using
features of previous houses from hawk
are great so you want to predict like
Zillow how do they decide their estimate
as I learned it's called
how do they decide that well they're
actually using machine learning to
predict the value of a house based upon
attributes of that house and I'm giving
a little ahead of myself but the thing
I'm trying to emphasize here is it is a
supervised machine learning problem if
you are trying to predict something okay
now let me contrast that with
unsupervised learning which might make
this more obvious if you're at all stuck
on what is supervised learning so
unsupervised learning is when you're
extracting structure from data okay so
one example a classic example is called
clustering and you can think of it as
let's pretend a grocery store wants to
understand the type of shoppers that
come in to the store there's there's not
you might think oh well that's obviously
supervised because you're trying to
predict like
what group they belong to but that's not
exactly it okay and here's why okay when
we talk about a cluster of people we may
say oh well there's the new parents that
shop at our grocery store and they buy
lots of diapers and baby food maybe and
then there's the super healthy people
that buy only organic and certain high
quality goods without additives and what
whatever so you're coming up with groups
okay but here's the thing and this is
the key point about supervised versus
unsupervised learning in unsupervised
learning there is no right answer so if
I worked for that grocery store and they
say oh how many clusters are you gonna
make for us when you examine our grocery
store shoppers I would say to them I
have no idea because there's no right
answer I can make two groups I can make
a thousand groups and then they might
say to me oh that's strange but um you
know let's say you make ten groups like
how many people are in each group and
how often do you get it right and I
would say to them there's no answer to
that there's no right answer in
unsupervised learning you are trying to
understand your data but there's no
right or wrong answer okay there's no
thing you are trying to predict that you
can say okay I got it right or I got it
wrong or oh this person belongs in this
cluster or this person belongs in that
cluster okay so again supervised
learning you are trying to predict
something and you can say yes I got it
right no I got it wrong with the
unsupervised learning there's no wrong
right or wrong answer you are just
trying to extract structure from data
okay you're trying to learn from it okay
so those are the two types of machine
learning and we're gonna focus today on
supervised learning and
that's definitely my specialty I'm not
great at unsupervised learning there's
something about me that like I like to
know when I'm right or wrong or you know
know how look at whether I'm improving
and unsupervised learning is very on its
it doesn't kind of help you like am I
getting it right or not
Francisco asks is it just like data
description and it's not in the sense of
like doing an exploratory analysis for
example um you will learn things and you
can come up with descriptive statistics
with unsupervised learning you are
actually building a model and we'll get
to that in a minute but you you can't
say my model was right or wrong okay so
I hope I hope that helps it'll answer
it'll be easier to understand the answer
to that a little further on
um so hold on to that and and let me
know at the end if you're stuck on that
concept of the difference between
unsupervised learning and just data
description we've one person in the chat
says if you use an unsupervised approach
and only two clusters isn't that like a
yes/no classifier no in that there's
still no right answer okay so let's go
back to this picture here um this point
up here is it in the okay so and this is
actually a question for the chat okay so
let me know what you think this point
right here is it in the red the green or
the blue cluster yeah so green and it's
you're like okay well as closest to the
green so obviously it's there but what
about this point right here in the
middle I know it's colored blue in this
picture but pretend all I told you
there are three clusters and you have to
decide the color
what should the color of this point be
should it be green blue or red Trey says
GRU I like that
Bluegreen okay we've got some greens
okay so that I'm trying to make my point
that there's no right answer so
unsupervised learning does not have a
right answer it's a matter of judgment
and expertise um supervised learning you
have to have a right answer okay um
let's see Ricardo asked can we meet mix
both approaches supervised and
unsupervised in one model um there are
other types of approaches called like
active learning and semi-supervised
learning and reinforcement learning that
are kind of like a blend um but I
wouldn't call it the same model I would
just call it a different type of machine
learning okay
I'm gonna pause on questions for there
and talk about how machine learning
works um if you've at any time as we
were talking about before if at any time
you've got a question that I didn't
answer you can always scroll down below
the video and ask it there
so that we can get back to it later but
I want to talk about how machine
learning works okay so these are the
high-level steps specifically of
supervised learning okay I'm not going
to be talking about how you do
unsupervised learning there are really
just two steps number one you train a
machine learning model using labeled
data okay you train a machine learning
model using labeled data we will do this
in a little bit and you'll see how easy
it is in terms of code but let's talk
about these terms okay what is labeled
data
label data is data that has been labeled
with the outcome it has been labeled
with the truth okay this is supervised
learning and so there is a right and
wrong answer okay so label data in terms
of our email example our spam filter
label data is passed emails where a
human has said this is spam or this is
not spam okay
so label data is data that has been
labeled with the outcome
now outcome we'll talk about terminology
in a bit but outcome is like the target
so when we were talking about house
prices the outcome is the price it's the
thing you are trying to predict okay so
in order for Zillow to say oh I predict
this house is worth $200,000
they must have data of past houses with
prices and that price is the outcome
okay now so you're going to train a
machine learning model using that data
so the machine learning model what does
it do
it learns the relationship between the
data attributes and the outcome so let's
talk about a different example than I've
been using okay
so let's pretend we are predicting how
many retweets a tweet will get okay so
I'm trying to predict how many retweets
a tweet will get I have some past data
about tweets I have some past tweets and
how many retweets they got what are some
attributes of the data that you think
could be used to predict the number of
retweets what are some attributes you
think could be
used so go ahead and post your ideas in
the chat
alright so Allen says words used great
great sentiment says grant and sentiment
if you don't know is like how positive
or negative a tweet is the person who
made the tweet that's Trey and I would
say maybe more like how many followers
that person has or other attributes of
them their job hawker says today we've
got topic we've got gender we've got
subject all of those are great and let
me just mention now a piece of
terminology those things we just said
time of day words followers those are
called features okay they are the
attributes of the data so what and
Sebastien added if using a popular
hashtag great so how many hashtags are
they using are they using a popular
hashtag what is that what are the
keywords being used all of those are
called features or attributes of the
data what does the machine learning
model do it learns the relationship
between if the attributes of the data
and its outcome in other words I've got
if I want to build a machine learning
model that predicts the number of
retweets a tweet will get what I do is I
gather past data about past actual
tweets with the number of retweets the
number of followers that person had the
sentiment of the tweet the time it was
posted the day of the week their gender
all of those things I am gathering that
data about the past tweets and the
machine learning model is going to use
those things to predict for a new tweet
which gets us to step number two we
learn we train a model and then we make
predictions on new data for which the
label is unknown okay
so we
learn from the past that's step one we
predict the future that step two and by
future I don't mean like a tweet that
hasn't been written but I mean a tweet
you've written but you haven't posted
you know like you don't yet know how
many retweets it's gonna get but I can
tell you how many followers that person
has right before they hit the tweet
button okay so that is how machine
learning works if in supervised machine
learning
if you benefit from kind of a picture
this might help the what you're looking
at here is you've got two known as
training data that's past data you've
got labels which is the number of
retweets in this example and you're
getting an algorithm you've got an
Albert you feed those into the algorithm
and it outputs a trained model that says
that has learned the relationship
between gender and number of and number
of retweets it's learned the
relationship between time of day and
number of retweets and then this is step
two you pass in a new tweet to the
trained model and it outputs a
prediction okay so that's kind of the
high-level overview of how machine
learning works now when I talk about
models I'm talking about things like
linear regression logistic regression
decision trees random forests naive
Bayes um
ada boost gradient boosting machines um
all of those things are machine learning
models
those are things those are things that
learn the relationship between features
and an output okay alright so that's
kind of the high level on machine
learning I will just say um that you
want to make sure you are building a
model that predicts
the future because what you don't want
to do is predict the past okay so what
you don't want to do well this is this
is probably getting ahead of myself so
I'm gonna pause on that point okay so
that's the high level on machine
learning okay I'm gonna move to a
different notebook and just talk briefly
about scikit-learn before we get into
some code okay so as I said feel free to
keep posting questions below the video
and see if that helps
okay all right so the second notebook
I'm just gonna pull up here um I'm just
gonna talk briefly about scikit-learn
and what is scikit-learn scikit-learn is
a library or package you can think of it
as it's a Python library for machine
learning okay you can do supervised
learning you can do unsupervised
learning both in scikit-learn okay so
why briefly are we using scikit-learn um
well it provides a nice consistent
interface to machine learning models
okay in other words you know you're like
I want to try model a and model B well
you can switch between models very
easily um we're gonna talk about tuning
parameters which are things you tuned to
get your model to perform better okay
it's got great documentation it helps
you do things outside of just model
building like data preparation and it's
got a really cool active community okay
so lots of great things about
scikit-learn that's all I'll say I want
to move into some code because I know a
lot of you who are here for that I do
want to mention if you haven't installed
scikit-learn yet and you want to follow
along today or probably even easier you
want to follow on afterwards I will just
copy two links
into the chat one is how to install
scikit-learn on its own and one is the
anaconda distribution of Python the
anaconda dish is a way to get started
with scientific packages in python
including scikit-learn it also includes
the jupiter notebook arm so that's a
great way to get started with doing
scientific computing in python including
machine learning it's a giant download
so I wouldn't download it right now but
download that afterwards and it'll be an
easier way to get up and running with
scikit-learn ok so now what I'm gonna do
is get into some code and an example
dataset alright alright and Trey just
mentioned in chat this chat is recorded
and so if you're having trouble why
whatever there will be a recording you
can go through I know it's not as good
as live but that's just kind of the
reality of modern-day video streaming ok
so I've pulled up another notebook and
we're gonna talk about a dataset and
then we're going to load it into
scikit-learn we are going to talk about
some more machine learning terminology
like features that I've mentioned
already and yeah and we're to talk about
how to work with data in scikit-learn
and let me say right now um I know that
this is not your dataset and you
probably have a data set you want to
apply machine learning to and I promise
that the most important thing you can do
is to understand how your how
scikit-learn works with data so that
when the time comes to load your data
into scikit-learn you do it properly
ok so I'm gonna pull up a really simple
example data set
and then we're gonna use it to learn how
do I work with data in scikit-learn okay
now the data set we're gonna use it's
called the iris dataset alright and
there's a reason I like this dataset
number one it's simple and number two
its famous and number three it's built
into scikit-learn okay so it's a famous
data set from I don't know fifty to a
hundred years ago and the way this
dataset works is that an iris is a
flower
by the way and someone a scientist I
believe um essentially collected 50
samples of three different iris species
150 samples total okay and that
scientist measured the four attributes
of each of those irises okay just like
the features of that tweet this
scientist measured the attributes of
these irises okay so what did they
measure they measured sepal length sepal
width petal length and petal width and
it's not really important to understand
those um just know they're measurements
of an iris okay so I'm going to show you
the data set without leaving the
notebook don't worry about this code do
not bother retyping this code in Python
just trust me it's not important what I
want you to see is just the structure of
this data okay this is critical um if
you want to put your data into
scikit-learn for machine learning it has
to follow a certain structure and you
can think of it like rows of a
spreadsheet okay
so every row represents one iris flower
so this is a flower
this is a flower this is a flower etc
all the way down to the end there are a
hundred and fifty flowers and so there
are a hundred and fifty rose okay
and this last row is telling me that the
sepal length of this flower was 5.9 the
sepal width was three the petal length
was 5.1 and the and the petal width was
1.8 and this was a virginica
that's the name of the species of this
iris okay so this is the structure
you're gonna want to get your data in in
which every attribute is kind of like a
column okay and then one of your columns
is that is that outcome what we're gonna
call our response or our target it's the
thing we're trying to predict you make
that one of your columns okay so just to
come back to what we did in the last
notebook these are the features our
model is gonna learn the relationship
between these numbers and this species
and then we're gonna use it to predict
the species of new flowers okay all
right so I've probably repeated some
stuff that we'll see on the screen below
but that's okay we're gonna load this
data set into scikit-learn and the
reason I want to use a pre-built data
set is because teaching you how to load
your own data set it takes more than we
could cover during this on this webcast
so we're gonna use a pre-built data set
and I'll talk at the end about how to
load your own data set but um this code
if you are following along on your own
computer and you're typing this into
Python this code right here is not you
do need to type it but it's not
important to under
and because in the real world you're not
going to load example datasets you are
going to load your own data okay so
basically there's a and when you see
you'll see just so you know you'll hear
me click on the keyboard that's when I'm
running these notebook cells it's just
how I'm running the code in this
environment so what I've done is I've
imported a function from the SK learned
datasets module and let me just mention
while we're here that um you'll notice I
did not say import SK learn okay and the
convention is not to import the entirety
of scikit-learn the convention when
coding with scikit-learn
is to import individual modules
functions etc okay or classes so I'm
just loading one function and then I'm
gonna use it alright so I'm going
there's a special object type called a
bunch that contains the iris dataset and
some of its attributes so I'm just
running the load iris function saving it
in an object called
iris and checking its type using the
type function okay and this it's just a
special scikit-learn format okay now I'm
just gonna I respect has various
attributes and one of them is called
data so I'm just gonna print I'm running
the print function on iris data and what
you'll see is the data from this data
set the same stuff we saw above a
hundred and fifty rows and here are the
four columns representing the four
attributes okay now there's not a fifth
column because that's stored separately
so don't worry about that fifth column
for at the moment alright so a bit more
terminology
and then we will get into building our
model okay so each row is an observation
and each column is a feature
okay so observations samples records
those are all rows in the data set
okay this is an observation each column
is a feature sometimes called an
attribute or a predictor so one of these
columns that's a feature okay so I'm
just gonna print the names of the four
features okay and then I'm gonna print
the iris got target attribute because I
want to show you that scikit-learn is
representing the class it's representing
the output as numbers okay as integers
okay this zero means one of the classes
one of these species the one means a
different species and the two means the
third species okay so these are just
representations of the target classes
the response classes okay there are
three species thus there's zero one and
two and I know it's not entirely clear
from this without having seen it before
but this is allows me to know that the
zero represents so Tosa the one
represents versicolor and the two
represents virginica
okay now I know that's a lot to take in
the code we've run so far again I want
to emphasize is not the most important
part here this is about conceptually how
do i structure my data set so that it
fits into scikit-learn all right a bit
more terminology and then we will get
into model building okay I've been
talking about how that target is also
called the response or the outcome
that is the thing we're trying to
predict so in this case we're trying to
predict which species of flower and then
there are two kinds coming back to
something someone mentioned before in
the chat there are two kinds of
supervised learning problems one is
called classification and one is called
regression the only difference between
the two is that in classification the
response is categorical it is unordered
categories in regression the response is
ordered and continuous meaning numeric
so let me give you two examples okay
when predicting whether an email is ham
or spam that is called classification
because there are categories ham and
spam and they're not ordered there's no
ordering when we're trying to predict
the price of a house that is called
regression because the response is
continuous it is numeric okay so let me
ask you and I want to just here in chat
see if you if you're getting this when
we are trying to predict the species of
an iris are we doing a classification or
a regression alright great I see some
folks in chat everyone saying
classification great there are three
classes there are three categories they
are not ordered so Tosa versicolor and
virginica may be represented as 0 1 &amp;amp; 2
but they are unordered okay now okay
let's move on I can give if you have
more questions about whether something
is classification or regression we can
get to that afterwards but um I want to
harp on this idea of how your data has
to work too
in order to be used in scikit-learn and
there are basically four rules okay
number one the features and the response
the features being those attributes and
the response being the species those
things must be separate objects so I'm
just printing to show you that the type
of that iris data and the iris dot
target they are two separate objects
okay you put the features in one object
in Python and you put the response in
another object in Python okay number two
they should all be numeric okay so the
features have to be numeric and here's
why and I haven't told you about how
models work machine learning models do
math okay machine learning models do
math or something very mathematical and
logical okay and you can't do math on
text so you do math on numbers so your
features have to be numbers so for
instance if we're gonna predict how many
retweets of tweet gets we can't just put
in the text of the tweet we have to
translate text into numbers okay let me
say that again if you want to predict
how many retweets a tweet will get and
your tweet one of the features we want
to use is the text you have to translate
your text into numbers because machine
learning models do math and math
requires numbers now how do you do that
you might ask well that is far beyond
the scope of what I can do within this
webcast I do actually teach a course
that covers a lot of that
so that's the second role and I saw your
question know me and I will get to that
in a minute
the third rule okay the features and the
response should be numpy arrays and if
you've never heard of numpy that's okay
numpy arrays numpy is a package for
scientific fast computation and
scikit-learn likes numpy okay so you
have to put your data in an umpire array
now it turns out that if you put your
data in an object that looks like a
numpy array such as a pandas dataframe
scikit-learn will understand how to work
with it okay you can even put it in like
a list of lists and scikit-learn will
understand okay the fourth rule is that
you have to have specific shapes okay
and this is one of the trickiest things
about starting with machine learning but
if you have understood the conceptual
material up to here I think you'll get
it okay so don't worry about the code
but I am printing the shape of the iris
data and the iris dot target okay this
is telling me that my feature matrix is
a hundred and fifty rows by four columns
okay
so every observation should be in its
own row every feature should be in its
own column and I know that sounds simple
but I promise you it's not always as
simple as it sounds but that's what you
have to do every observation one row
every feature one column okay now your
response variable the thing you are
trying to predict it should be
a single a one-dimensional object in
which its length is the same as the
number of observations okay so let me
break that down for the iris dataset our
iris dataset has a hundred and fifty
rows and four columns okay cuz there are
a hundred and fifty flowers
the iris dot target is our response and
there are a hundred and fifty of them
why because our machine learning model
is learning the relationship between a
hundred and fifty observations and a
hundred and fifty classes sorry a
hundred and fifty response values so
what I mean is you can't say to a model
let's go back to the Twitter example if
I collect data on a hundred tweets I
have to also collect data on for all a
hundred of them how many retweets were
there because my model if I say I want
hey model I want you to learn the
relationship between the features and
the number of retweets
every observation has to have a
corresponding number of retweets because
if I don't have that number the model
can't learn the relationship between the
features and the response okay so that
is key okay my my features are 150 by
four it's a two dimensional object
my response is a hundred and fifty
period okay it's a single dimensional
object okay let me do one last thing and
then I'll answer noemi's question and
then we will finally build our model we
are going to store our feature matrix in
an object called capital X and its
capital beak by convention because it's
two-dimensional and I'm storing my
response
factor in why okay and it's a lowercase
Y and that's the convention because it's
a single dimension okay all right
Noemi asked are there separate machine
learning algorithms for classification
and regression the answer is yes
some yes the short answer is yes what
are some examples so decision trees can
actually be used for either K nearest
neighbors can actually be used for
either linear regression is a regression
model logistic regression is a
classification model neural networks can
be used for either and so on all right
tray asks am I getting the terminology
right a hundred and fifty observations
equals a hundred and fifty flowers that
is exactly correct
one hundred and fifty responses equals a
hundred and fifty classifications of
those flowers into one of the categories
yes correct
and each flower has four features that
are used for figuring out the category
all correct okay so if you just heard
what I just said and you're like wait
wait wait what was that go into the chat
and look at what Trey just typed because
that was a nice summary of what we've
just been talking about okay so the
observation is the flower the response
is its species and the features are
those four attributes of the data
all right Manoj how to choose an
algorithm I will talk about that in a
little bit
nomy is a feature and a predictor the
same thing yes those two are the same
thing okay so I am going to open up one
more notebook and we are going to
finally build the model okay now you've
noticed that we are an hour into the
webcast and I hope you are still
sticking around and finding this
interesting because we're about to build
our model
we'll let you know that crowdcast has a
hard cutoff at 90 minutes so I'm gonna
get through this hopefully in about 10
minutes and make sure that we leave
about 20 minutes for questions okay so
that's my goal here all right now um I
am NOT gonna talk about how to choose a
model right now I will talk about it
generally nor am I going to explain the
model we're about to use because that
would take quite a bit of time um what I
want to get into is showing you how easy
it is to build a model once your data
meets those four requirements okay all
right so just as a recap our data set
has a hundred and fifty observations it
has four features the response value is
the species and this is a classification
problem not a regression problem because
the response is categorical okay so
that's a quick summary of our data set
now
I'm gonna skip past this part where I
explain K nearest neighbors and I will
tell you how you can get this
explanation after today's webcast but um
this these four lines of code if up to
now you have not been following along
and we're just waiting to build a model
okay these are the four lines of code
you need to run right now in order to
catch up with where we are okay so you
haven't missed anything if you haven't
been typing in code up until now just
run these four lines of code and we will
have defined our X our feature matrix
and our Y our target vector okay and
again I'm going to print out their
shapes okay so
the X our feature matrix is a hundred
and fifty by four and the Y is a hundred
and fifty period okay
so every row has a species associated
with it okay
so here is the scikit-learn four-step
modeling pattern and I think you'll be
surprised given the complexity of
machine learning you'll be surprised how
straightforward this is okay
so step one import the class you plan to
use all right now scikit-learn is well
organized let me say there are dozens
perhaps even hundreds of machine
learning models okay I am importing one
of them I'm not going to talk right now
about how I chose it just know I chose a
particular model and I'm gonna import it
so I'm gonna say from SK learn dot
neighbors import k neighbors classifier
now what is SK learn neighbors
well basically scikit-learn is well
organized into little modules that
contain related models okay so I'm
importing
a a model that thinks in terms of
neighbors
now don't worry about what that means
I'm just saying I import it so I can use
it this is me importing a model so that
I can use it the next step step two is
to instantiate the estimator now what
does that mean an estimator is a model
that is scikit-learn x' term for model
okay and instantiation that's just an
object-oriented programming term it
means make an instance off and let me
show you what I'm doing and then I'll
explain what the point was I'm gonna say
K n N equals K neighbors classifier
parentheses and neighbors equals one now
what am i doing I'm creating a model
called KNN sorry I'm creating a Python
object called KNN and that object knows
how to do que neighbors classification
in other words que neighbors classifier
is a type of machine learning model that
model thinks in a certain way in terms
of the relationships it can learn
between the features and the response
okay so KNN is an object that can that
knows how to do KNN classification and
then n neighbors equals 1 is a tuning
parameter for the model ok these are
also called hyper parameters now you
might be asking what's the role of the
hyper parameter or tuning parameter well
if I said to you hey we're gonna use
past tweets to predict number of
retweets and I said I want you to use a
decision tree model ok that's not enough
information for you to build the model
you actually need to make decisions
about the parameters of that decision
tree now each model each type of model
has its own parameters that you have to
tune those tuning parameters those
tuning parameters determine kind of a
tweak the performance of the model now
there are a lot of default parameters
you can just use those but you're not
going to get best model performance so
for instance if we're predicting ham or
spam for an email I might get 80%
accuracy with K neighbors classifier and
neighbors equals 1 and I might get 82
percent accuracy
with K neighbors classifier and
neighbors equals five okay so I can tune
the parameters of the model for optimal
performance okay now how you tune a
model is beyond the scope of this
webcast there's I have other videos
about that and I will talk about that
but for the moment you'll just have to
kind of treat it as a black box okay all
right all the default parameters of a
model that you don't set during
instantiation which is this are set to
the defaults so here are the other
parameters of K neighbor's classifier
algorithm leaf size metric P n Jobs
metric params weights all of those are
parameters that could be tuned I didn't
set those parameters during the
instantiation so they're set to their
defaults okay so step one import step to
instantiate the estimator okay step
three fit the model with data this is
coming back to what we talked about the
beginning you want a model to learn the
relationship between your features and
your response that is called model
training that is also known as model
fitting okay so I am learning the
relationship between x and y okay i'm
learning the relationship between x and
y because what is X X is our features
what is y why is our response factor so
right now when I say KNN got fit X comma
Y I'm saying can an object I want you to
learn the relationship between x and y
ok and finally
step four predict the response for a new
observation okay this is where KN n is
our trained model and let me show you
what I mean okay when I said okay this
is so coming back to this diagram I
think this will be helpful if you got
lost anywhere this part is X okay this
is our training data Y these are our
labels for the training data okay
here's X here's Y this is KN our model
we're using once I've done K&amp;amp;N dot fit
it's a trained model that is ready to
accept new out-of-sample data okay
now the code for that is K&amp;amp;N dot predict
3 5 4 2 and what am i passing it well
I'm passing it a list of lists
don't worry exactly why um I
it would take a little while to explain
but the point is KNN is a trained model
and I am saying to K&amp;amp;N my out-of-sample
observation my new flower let me
actually step back and explain this in
plain language okay
Canon has learned the relationship
between the measurements of irises and
their species I am walking up to Canon
with a new flower and I'm saying hey KNN
my flower has a sepal length of 3 a
sepal width of 5 a petal length of 4 and
a petal width of 2 what do you think
these species is and that is what is
happening when I say K n dot predict
okay K n dot predict is saying I want
you to predict what species this um this
is okay
and it predicts a - now - means
virginica which we know because we coded
them as suit osa equals zero versicolor
equals one and virginica equals two and
importantly cannon has no idea what
these numbers represent it doesn't know
what 3 5 4 and 2 represent it doesn't
know what the outputted the predicted
value of 2 represents ok it does not
understand those things okay it is just
doing math now I will do one more thing
I will just show you that you can
predict for a new you can predict for
multiple observations at once and in
this case and that's usually what you're
gonna do so now I'm passing the predict
method to different new irises and it's
saying oh this first one I think is um
for Jenica and I think this one is
versicolor okay
I am NOT going to show you these last
two parts um
I will just say what's in them and then
we will get it to something QA um number
one here's this is just a little code
snippet to show you how to use a
different value for your tuning
parameter and this little section shows
you how to use a different and entirely
different classification model for the
same task okay so this is showing you if
you were following you might have
noticed that the model building process
took a total of four lines and using a
different model took a dew points that
is how simple the actual model building
process inside kit bar okay I think for
the
moment that it's all I'm gonna show
screen so maybe tray let's go ahead and
just put our faces back up and then I
will start answering some questions both
from the chat and from below the below
the video and let's see so so Trey asked
well I'll just repeat what you just
asked okay do I have this right KN n o
KN is K nearest neighbors which is one
type of machine learning algorithm that
can be used for machine learning that is
exactly right
k n n is a model okay
it thinks about machine learning in a
certain way a different model like
linear regression thinks about it in a
different way
decision trees thinks in a different way
random forest thinks in a different way
so there's obviously a lot to choosing
between models and actually that leads
into some of the questions from below so
let me say right now it is at least on
the east coast of the US it's 2:15 so
we've got only about 15 minutes left I'm
gonna pick out some specific questions
and I will answer the rest or some of
the rats afterwards and you can come
back to this page and look at them but
in about a 10 minutes
Trey and I will wrap up and I'll just
share some resources he can share some
more information about Python weekly the
weekly Python chat but I'll just jump
into questions now and then we'll wrap
up in about 10 minutes okay um so how to
choose an algorithm in machine learning
that is a great question so it's not
easy is um the short answer and as I was
trying to explain different machine
learning models think differently okay
each model has its own strengths and
weaknesses so for example let me just
give
to make this concrete k-nearest
neighbors is a good model when you have
a lot of observations and not many
features okay how do I know that well I
understand how King airs neighbors works
and I've studied it okay so the real
answer is if you want to know which
model to use you learn how a lot of
models work you'll have a sense for
which model is better than others not
only do you have to choose which model
but you have to choose how to tune that
model so there's really a lot
a lot to chew each call comparison of
machine learning models and I'll just
and I'll just paste it into the chat and
you can check it out and it talks about
advantages and disadvantages of
different models okay but yeah
so feel free to check that out if you
are interested one question from the
chat to scikit-learn support ensemble
not models yes it does um okay let me go
back to the questions underneath the
video time series analysis using machine
learning so what what is that and how do
you do it okay so time series data is
data in time order so the best example
of that is stock market data is like you
know every second or every minute they
record the price and that is time series
data time series analysis is an
exploratory process for understanding
that data what I think you're actually
referring to is time series forecasting
which is prediction of the future
that's like predicting the future of a
stock price that would be called time
series forecasting how do you do that
with machine learning well you can do it
but the tricky part is you have to build
your own features in a smart way so I
can't like an iris I just measure it's
flat measure its flowers and maybe I
have some domain expertise that says oh
the height of the iris is related to its
species so I'll measure the height I'll
measure its where is it located or
something um with with time series data
you have to create those features in a
different way so yes you can do that
with machine learning it's tricky which
is why there are some specialized
techniques that have been used for
time series forecasting that are not
like they don't think in the same way
that of what I've just explained ok the
next question is about neural networks
and I'll just say briefly let me say
like a simple model like K nearest
neighbors when I teach it in the
classroom I spend at least like an hour
on it when I swen I teach decision trees
like a really good lesson on decision
trees which most people think is like a
simple model I spend about 4 hours ok um
neural networks way more complicated so
I'm definitely not going to explain it
right now I'm also not qualified enough
to explain it in a meaningful depth but
let me just say this about neural
networks you can think of it as a model
just like any other machine learning
model um if you've heard of deep
learning so deep learning is like the
really hot thing and machine learning
these days and for good reason um deep
learning is a set of techniques for
training artificial neural networks and
the theory behind neural networks is
they work kind of like the brain ok um
all I can say about neural networks
briefly is um it's a really deep topic
there are different architectures um
there are skills specialized skills you
have to learn to know how to train a
neural network but I wouldn't start with
neural networks before first
understanding the basics of machine
learning ok I don't think there's anyone
who works with neural networks that if I
said oh I need you to train like a KN
model they'll know how to do it they may
not do it often but they know they
understand how to do it because you have
to understand the basics of model
training before you can move on
turn neural networks ok all right um
couple other questions I'll get to let's
see you mind if I scroll down to the
bottom the couple that were asked
waiter so you were using spider - yeah
let me you reason when I come to
libraries that make it so that you'll
use Python 3 or was that just your
choice
oh no good reason is the short answer so
feel free to use Python 2 or 3 and
you'll be you'll be good for most data
science tasks including machine learning
with scikit-learn ok um let's see oh I
like actually like your question try it
it sounds like choosing your features is
really important especially for
predicting really fuzzy things can you
use an algorithm to figure out which
features are most important for your
data and which ones are irrelevant
feature selection is what it's known is
a really tricky topic there are models
that once you train the model it can
tell you which features were important
but most models the way you do it is by
trying different sets of features and
seeing which performs better and that's
a way of backing into understanding
which are important um
so there are ways but they're tricky and
there's not like one way and it's not a
solved problem let's see what else do I
want to answer what is the process so
this is in the middle it's from grant he
says what is the process that you go
through to tune a model okay so tuning a
model means selecting a model it means
changing tuning parameters and measuring
and evaluating the model okay so um
really like there's there's model
evaluation is a huge topic now the real
question is how do I choose the right
model and know
it's the right model for predicting the
future and this is where you get into a
critically important topic called model
evaluation this is where you figure out
whether your model how good your model
is at predicting the future not
predicting the past okay
because training data that you used to
train a model is it learns from the past
okay I want to get good at predicting
the future how do I use the past to
decide whether I will be good at
predicting the future that is called
model evaluation and the way you tuna
model is by building a model evaluation
procedure and a model evaluation metric
and then you try different combinations
of things and see which performs the
best and if you've got a useful metric
and a proper procedure then that's a
good way to tell how it how to best tuna
model okay
it is oh please mr. replication is it's
a model the same as the algorithm is the
algorithm in combination with which I
use the term algorithm and model
interchangeably technically there might
be a distinction alike but basically
they're interchangeable so a machine
learning algorithm and a machine
learning model are the same thing well
to me that's what I would say um well we
are at 225 and I don't want to miss kind
of the wrap-up and I can certainly
answer some more questions in chat
afterwards and I'll add some comments on
these questions but maybe I'll just wrap
up on a few things I want to show you a
couple resources number one is if you
didn't already know the content I pulled
from today is part of the content from
my first four videos on a my video
series called machine learning with
scikit-learn it's
four hours long plus I added a
three-hour live tutorial I did that
builds upon it just seven hours of
content if you really want to get into
this stuff and I will add a link right
now in case you're interested definitely
check that out if you want to understand
machine learning with scikit-learn
or get a recap of a lot of these things
understand K nearest neighbors
understand model evaluation okay so
that's one resource another resource I
want to share is I have a video series
about pandas and pandas is a library for
data exploration and for analysis and
visualization and it is the library to
use to prepare your data set for machine
learning okay so when I said it takes
work to get your data set ready for
scikit-learn you should use pandas to do
that work it so happens I have a free
video series for be videos as of I'm
releasing video number 30 on Tuesday of
using pandas I would highly encourage
you to check those out if you want to
understand how to use pandas on final
quick plug before and then tray of
course I want you to you know any
wrap-up you have final quick plug is I
teach online courses
I'm releasing new material all the time
I'm gonna have a course launching in a
couple weeks I'm gonna have another
course probably launching in November if
you want to hear about them I would
really love it if you went and click the
green button below the video that says
subscribe to the data school newsletter
okay click that button fill out your
name and your email I will be getting in
touch with you with lots of free
resources as well as my online courses
that I that I do sell okay so let me
just say thank you so much for your time
this was really fun and I really enjoyed
it and Trey what uh you know figure out
lets you wrap up and then we'll
we'll keep answering questions till
tikal so my wrap-up is gonna be pretty
brief here
I mean first thanks a whole bunch Kevin
for coming on here this was awesome this
is the first chat that we've done that
was a little bit less of a chat between
you and me much less much more of a
learning experience a lot of great
questions people asked here thanks for
asking those questions and a lot of
great stuff that you can really broke
down I actually knew pretty much nothing
about machine learning out so very very
rudimentary understanding that it was
machines being trained to solve problems
machines like us meeting algorithms and
so this was a great breakdown thanks a
lot for this ones in case we do have
said like we've got about three minutes
left I think we started a few minutes
late I actually don't see a warning that
says it'll cut us off at 90 minutes I
think we should assume that even though
it's not there like it usually is but I
wanted to say next week's chat I usually
in this next week's chat at the end of
weekly Python chat I don't have it
scheduled yet but I'm pretty sure I'm
gonna do one on generators and
specifically there's a topic that I
haven't seen people really talk about
much turning for loops
sorry turning while loops into for loops
using generators so making a generator
and take one type of loop and turn it
into another type of loop I want to do a
chat on that next week and that'll just
be me learning along with the audience
so if anyone is interested in that next
week you can join me then probably about
the same time same day next week
questions real quick there's a couple
that I wanted to specifically ask
because I'm in this same right now right
if you are if you are okay at Python but
totally new to machine learning this is
from Alan James what type of problems
make learning make for good learning
options so you're you know Python you're
totally new to machine learning that is
where I'm at yes what problem should I
try to be trying to yes so where you'll
want to start um is with datasets that
are already ready for machine learning
so um the data set we use today is from
something called and I'll just type it
and someone can add a link it is called
the UCI machine learning machine
learning repository okay so that website
has hundreds of data sets that have been
prepared for machine learning and they
already like people know that you can
use the data to predict the response so
let me step back and comment on
something um when we say we want to
predict the number of retweets a tweet
will get and here are some features we
should put into the model to predict it
those are just theories like my theory
could be incorrect maybe the number of
followers I have has no relationship
with the number of retweets so
ultimately um I'm just guessing that one
of those features or more of more than
one of those features hopefully has
what's known as signal not noise in
other words it actually has predictive
value and the nice thing about the UCI
machine learning repository other than
the fact that the datasets are already
prepared is that someone's already used
like someone's already defined the
response value defined the features
cleaned them up and actually has figured
out that there is signal in those
features so that's where I would start
because you can actually practice the
machine learning part because if you try
to start with your own data set and data
preparation you're gonna run into a lot
of roadblocks so it is courage if not in
my opinion if in that our faculty don't
want an algorithm having to do with
Twitter they've already vetted that it
seems work on the stuff that they've
used it for so it probably maybe works
for your prediction as well if you're
trying to predict the same
two thing so it's more just to clarify
the the machine learning repository
actually contains so what it contains is
datasets descriptions of those datasets
and links to papers where people have
talked about applying certain techniques
to those datasets um you can use those
papers to get ideas for which machine
learning models to use however when
downloading the data set it will not
like tell you you must use KN and for
what it's worth it's good practice to
kind of choose your own models and
practice tweaking them and seeing the
results so the machine learning
repository its biggest value is that
it's clean ready to download datasets
just so we know I got a lying machine
crabcat the maximum recording time is
now two hours yeah so we've got a little
bit time to answer the rest of this
question all if you have time all right
I sure I will uh I did I told my wife
I'd be done after all right just a few
questions so yeah yeah no no no no
problem no let's uh let's grab some good
ones here um all right and I'll just
start at the top if you have a question
that you put in the chat and I haven't
answered you should add it into this
list below here so I see it but I'll
just start at the top question after the
live chat is someone interested in
continuing with machine learning can you
get for them projects to work on how to
practice um that you know we've kind of
answered that but I would encourage you
to go through my video series both on
scikit-learn and pandas and I really
like Kaggle as another source of
practise Kaggle is essentially a
platform for competitive machine
learning and there are some machine
learning 101 competitions meaning
specifically for beginners and those are
really fun
because you can learn the machine
learning workflow on date sets that
other people are also working on and you
can compete against them to try to get
the highest score and you can learn from
them in the forums and ask questions so
that's one thing I would suggest um
theory and practical Skittles what are
ingredients for getting hands on machine
learning using Python um theory and
practical sales boy
there are a lot um practical skills for
getting good at this stuff is like how
do I load data into Python how do I
prepare my data do I need to do anything
to it I need to explore my data to learn
what might be good features um I need to
create new features known as feature
engineering
I may need to pre-process the data I
want to I want to build a model tuna
model all of those things are practical
skills um the theory skills are like oh
sorry the theory skills the theory you
have to learn is things like how to
choose between models how does each
model work what are the useful tuning
parameters for a model in what scenarios
is a model particularly good however how
do I properly evaluate a model which is
not always straightforward um how do i
regularize a model that's a another kind
of hot topic um how do I understand why
- knees working versus not working so
there are a lot of theory and practical
skills to learn I can't give you one
answer for like here's the one source
for all of those I can just tell you
there are a lot of both and I tried to
cover a good bit of both in my video
series what the bottle at so my keys you
know the advantage isn't
advantages of Python verses are
especially for in visualization great
great I like that one um so I wrote a
blog post let's see and where did that
go
ah here it is okay I wrote a blog post
that was very popular once called where
is it and I'll just paste a link should
you teach Python or R for data science I
will paste it actually as a comment to
the back question also paste it in the
chat and the short answer is that both
are good I actually like machine
learning and Python more than I like it
in our I used to like our more as a
language now I like Python more as a
language they have their strengths and
weaknesses visualizations I actually I
really do like R for visualizations um
but the I'm really excited that the
there's a famous package called ggplot
in our that I like and the finally there
was an open source project porting that
to Python and that has made some
significant strides lately so that makes
me really excited but right now I do my
visualizations in python using either
pandas or Seabourn
and both of those sit on top of
matplotlib so matplotlib is what most
people use it's not as it's a little
more clunky than ggplot absolutely it's
kind of like base base plotting in are
like the standard plotting in R but um
that's that's kind of what I'd say
there's there's a lot to this topic I'm
happy to answer more more questions
about that but um let's see and you feel
free if you see a really good one grab
it tray but I'll just keep going from
the top proper setup of training
okay so um in this case and when you're
pulling datasets from the machine
learning repository um
the UCI machine learning repository
it'll just give you a nice clean data
set but as I said there's more you need
to do to it let me give you some
examples you want to remove features
that are irrelevant
okay so if we're predicting what the
number of retweets for a tweet and one
of the features was like color of the
person's background that wrote it
you'd be like that is irrelevant and how
do you prepare your data remove that
feature so that's number one number two
you have to remove missing values so
pretend one of your features is how many
followers the person had at the time
they tweeted if you don't have that
feature for all tweets you either have
to remove those tweets those are called
missing values you either have to remove
those tweets or you have to input what
you might think of as fake values
because remember machine learning models
do math and you can't do math on missing
values okay there are other things
certain machine learning models require
you to standardize your data and by
standardized I mean Center and scale
your data which means give it a mean of
0 and a standard deviation of 1 other
that that's one type of preparation
another preparation is categorical
features so let's pretend one of your
features was um uh the I don't know was
categorical like what's a good unordered
categorical feature for for Twitter
prediction um it would be like the
person's job category let's pretend we
had 10 job categories and your theory
was that people whose job category is
data science will are more likely to be
retweeting okay let's pretend
job category data science cannot be put
in a model and just you can't just do
math on the words or the category data
science you either have to extract the
words and turn those into numbers which
again is a deeper topic I can't really
get into but I do teach in an online
course the other way to do it is treat
it as a categorical feature and you do
what's called dummy variables or someone
asked about one hot encoding same thing
you essentially translate a single
feature with ten possible values into
nine separate feature columns okay so
that's just there are so many ways in
which you need to prepare your data for
machine learning that that is um that is
I think what you're asking when you said
proper setup of training data the other
answer I would give is just a recap on
what we talked about during the chat
which is that you have to have the same
number of observations as you do values
in or in your response factor right so I
think that's all I have to say about
that ah let's see
Diane asks what type of problems is
machine learning good for solving um
well supervised learning is okay
supervised learning is good for solving
problems in which there is a real answer
okay um if there's no true answer then
that's not a good candidate for
supervised learning um and I wish I had
a good example offhand but um in general
you don't want to use machine learning
if you don't have enough data meaning
like you want to predict something where
your theory is that your theory is that
oh um okay there's so many I've got so
many thoughts in my head right now sorry
it's
hard to get them all together if you
have a theory that something is
answerable using data but you don't have
the data then that's not a good
candidate you should choose a problem
where you believe there is data and you
can get access to it okay another
example when it's not good is for when
it's arguably not good is when it's an
extremely rare event or an event that's
never happened so if yours you said I
want to predict when when a earthquake
will hit my house well like how much
data do you have on that or has it ever
happened or maybe it happened once you
don't have a lot of instances to learn
from so you want to choose problems
ideally where you've got a lot of data
about where it's happened and where it's
hasn't you've got a lot of training data
essentially that's not the best answer
I'm sorry but it's it's a tricky
question so the question about what is
back propagation in neural networks and
then he means neural networks here he or
she can yeah believe um so neural
networks as I said is a very deep topic
my disappointing answer is I can't like
summarize that in a meaningful amount of
time nor am I really qualified to I try
to teach things that I'm really good at
teaching and I really understand well
and neural networks is not at the
present time one of my specialties so
that's that's the best I can do it there
Trey asks can machine a great question
Trey can machine learning help me
analyze my social relations what kind of
cool things could I use machine learning
to find out about my social network
okay so supervised machine learning
would be good for making predictions
like you might want to predict I want
like if I were you I mean this is maybe
not a top priority but you might want to
predict how many people will show up at
a webcast
okay and you would just have to think
through what data do you have about past
webcasts that and you'd have to
incorporate things like the time element
that's very tricky because you want to
separate out like let me say that and
this is a good teaching point there's no
when I give a machine learning model a
hundred and fifty irises it doesn't
think of them in time order it will
output the same model regardless of
whether you change up the order of the
rows in the data set now if your
observations meaning your rows of data
if your observations are time-based
there's a time element like over time
you have grown you have to find a way to
encode that as a feature such that your
model can learn that time was like how
far in the past it occurred is relevant
so that's a really trippy trippy
it's a really tricky topic so that's how
you would use supervised learning how
would you use unsupervised learning
you might cluster your followers into
groups okay um there's something called
Graham graph i'm can't think of the
graph modeling that's not the right term
i'm trying to think of the general term
which is basically creating graphs of
their connections and you learn like who
are the influencers that kind of thing
um i'm i don't work on that at all so i
can't really speak to it knowledgeably
how you do it you wouldn't do it in
scikit-learn you would use different
software I'm sure you can do it in
Python I'm positive I just don't know
the packages so um alright I'll just
keep going I mean we're at well might as
well just keep going run out the clock
PCA and one hot encoding asks Andy and
one hot encoding is another term for
creating dummy variables and you
do it in scikit-learn using the one hot
encoder that's the thing where I said
100 coding is the thing or dummy
encoding is where I said you have a
categorical feature you want to include
in your model there are ten possible
values thus you create nine features and
I actually have a video about that in my
pandas series you should check out again
if you come back to this page after the
webcast I'm gonna have added comments
probably not today but maybe tomorrow
I'll have added comments on links to
relevant things such that you can come
back here and check out the links um PCA
is is called is stands for principal
components analysis and it's actually a
type of unsupervised learning and the
way PCA works is let's pretend you have
a hundred features um it turns out that
in general models perform better if they
have less features or rather if you
eliminate uninformative features as you
might imagine PCA is a way of instead of
Cree instead of selecting ten of those
features PCA actually creates ten
features or any number of features you
want that capture the variance in those
100 features okay and that's like if
you've never heard that before I expect
like that will make no sense it's a
method for what's called dimensionality
reduction which is basically a way of
reducing the dimensions of a data set so
that a machine learning model has a
better chance of learning from it okay
and I'll put some links on that what is
the difference between statistical
modeling and machine learning modeling
um okay lots of people debate about like
what is modeling and there's something
called statistical learning which is
very similar to machine learning
statistical modeling is not necessarily
concerned with prediction
it is concerned with understanding and
sometimes you use understanding to get
at prediction okay
so here's here's one way I would
distinguish it machine learning is good
at prediction and via prediction you can
get understanding statistical modeling
is good at understanding and by
understanding you may be able to do
prediction so they fundamentally comment
the problem in a different way but then
you may be able to use them for similar
similar reasons hidden is that
statistical modeling is that machine
learning or is that something else so I
don't know much about them but I believe
you would call that a machine learning
unsupervised technique and unsupervised
is is kind of at the boundary between
unsupervised learning may sound a lot
like statistical modeling because
unsupervised learning is about
understanding you can't do prediction so
there are very fuzzy boundaries about
what counts as unsupervised learning
it's a great question but there's not
like look there's not like one a true
answer to that as far as I'm concerned
and even if there was I'm not the best
person I am a supervised learning person
so that's that's what I'm best
ah let's see um the question at the top
predictive modeling supervised learning
on stress learning I'm not sure what the
question is so feel free that person if
you want to clarify in chat or comment
you can I'm sure these are welcomed with
your the chats are so we'll just at this
point some of these because we do coatis
got it got it
cool all right I've narrowed it down to
eat questions left see if we can get
through is there a way to tell that a
given models
there is no other way to increase the
AUC and/or TPR okay all right here's my
rephrasing of that question let's
pretend I'm evaluating a model to figure
out which model to choose and I figured
out that I can predict the what whether
a flower is an iris I can predict it on
95% accuracy the question is is there a
way to know whether I could predict it
with 96% accuracy like is it possible
because there is an upper limit the
universe is not predictable the answer
is no the upper limit is unknowable okay
so the usual way of dealing with this is
you just accept the uncertainty and you
just do your best and you decide when
you've spent enough time on this or
you've run out of time and your model is
as good as it gets
um a you see by the way is what's known
as an evaluation metric so it's one way
to evaluate a classification model I
actually have a video on AUC so I can
I'll link to that later okay
I have anaconda installed under Windows
10 how do I access scikit-learn so
anaconda is a distribution of Python to
access I could learn which is a library
you just open Python and you know like
from SK learn datasets import load iris
or something now your question might be
once you've downloaded in akanda how do
you even open Python and there's
actually different answers you can use
the Python shell that's available just
type Python at the shell you can use the
ipython interpreter you can use the
jupiter notebook or you can use the
spider ide
all of those come with anaconda what I
was using is the Jupiter notebook but
you can use any of those and I'll add
comments later on like specifics of how
to access each of those but it's up to
you real time example of machine
learning
I like this um so what's a
I'm example um voice recognition okay so
when you talk into your phone and you
ask Google or Siri or whatever and say
like give me directions to something it
recognizing your voice is a machine
learning problem that it's doing in
real-time essentially real-time um
the Facebook newsfeed when you open
Facebook it has to decide what to show
you at the top okay and it's actually
quite quite good it likes showing you
things that you're like Oh honest keep
scrolling down um that is a real time
machine learning problem now let me say
that just because something is done in
real time does not mean that the
computation occurred in real time okay
if I'm Facebook I would have a database
of like I mean I don't know if I would
do it this way but when you open Oh
lemme this is a better example when you
open Netflix and flicks shows you like
hey I predict four and a half stars for
this for you okay
Netflix when the moment you hit hit its
website it did not run a machine
learning model at that moment okay I can
promise you that they did their
calculations yesterday or the day before
or a week before so that when you came
to the site it's just accessing pre
computed predictions that is machine
learning that appears to be real-time
but is likely not I don't actually know
for sure
um so real-time machine learning means
like you're interacting with it in real
time but there's no way to necessarily
tell how much of it is happening in real
time versus just being displayed to you
in real time okay um the next question
what are these algorithms is there any
mathematics used how to choose the model
I've kind of talked about that already
there is mathematics behind every model
the mathematic on the model
you can use any regression model for any
regression problem that is true you can
use any classification mall for any
classification problem and choosing
between them requires expertise yeah
okay if I am unable to make the time
will a video be available later yes it
will be available on this page
shortly after ending apart from the KS
statistic what the different ways of
determining the cutoff point of a
probability score in logistic regression
I think you mean like the threshold I
don't know what the KS statistic is so
I'm gonna have to pass on that question
um Oh
let's open oh if that was just my mouse
okay topic modeling topic modeling is
about figuring out the topics present in
a set of texts and just I mean that's
really what it is I'm not I don't use it
um it's a good way to understand what
topics are present in a data set but
like where do you go from there it's
kind of like unsupervised learning I
don't know if it's categorized as
unsupervised learning but it has the
same objective
all right to left Wow okay can a model
be biased
what is overfitting okay overfitting is
about how to explain overfitting I will
have a good link for this but
overfitting is learning the noise in the
data rather than the signal overfitting
is training your model such that it's
good at predicting the past but not good
at predicting the future okay so I don't
want a model that is perfect at
predicting the past it's I want a model
that's good at predicting the future
okay so that's what overfitting means is
when
you're good at predicting the past not
the future and the bias-variance
tradeoff is what people are usually
talking about when they talk about
overfitting a model a model can be tuned
to be high bias or high variance and the
amount of error in a model is the sum of
bias and variance so essentially you're
trying to find a sweet spot between bias
and so when people enrolling exit art
market data and it predicts the palomar
well but not the future is that
overfitting or is that okay yes that is
overfitting yes that is overfitting now
there are lots of different ways you can
overfit there's not like only one path
to overfitting
but that is what overfitting is yeah all
right I don't question like have an I
have built a model to make a prediction
how do I put in it it in production in
Python or work environment for other
people to use like shiny in our great
question so I'm gonna put ah this is not
my this is not my area of expertise
again but people have definitely put
scikit-learn models in production using
flask and then hosted it online using
Python anywhere now I agree that
something having something like shiny in
our would be super useful for the Python
community and our studio is really
killing it in terms of trying to get
data science people to use their
products like they are doing so many
great things like shiny I admit it and
Python sometimes lags on certain
elements like that but um you can do it
definitely let me see if I can find a
good example of it and Link it got a
minute left here all right so there are
a lot of people to happen right now
thank you so much for sticking until the
end oh I'm cool a lot of people looks
like they probably had the bomb out
which absolutely understandable because
we went about double the length of
either of us thought we would go which
is because you all asked a lot of really
good questions so Kevin thanks for
staying until the end and answering all
of those questions I
didn't expect that and thanks everyone
for sticking around asking those next
week I'll be doing my generators chat
just a reminder Kevin I can't remember
whether we plugged your newsletter or
data school I know we plugged that a
school but you can click green button I
think it's below you know yeah yes it is
right below the video it says subscribe
to the data school newsletter and you
just have to fill out a form and click
join and then like click you know you go
to your email and whatever but I promise
you it is worth it alright today for
those things that I just threw a link to
weekly Python chat and there as well for
anyone who didn't get the email I'm
pretty sure if you signed up for this
you got an email asking you if you
wanted to sign up for my newsletter if
you do want to you want to find out
about future chats click the confirm
button in the email or go to weekly
Python chat and sign up yourself so
Kevin's newsletter that little green
button down below the video mine over
and the chat on the left side I don't
know where I am in the video but we have
20 seconds left so thanks a lot Kevin
and thanks everyone for showing up see
you hey this is fun it's really fun
thanks bye folks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>