<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Beyond P2P: Video Routing in WebRTC | Coder Coacher - Coaching Coders</title><meta content="Beyond P2P: Video Routing in WebRTC - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Beyond P2P: Video Routing in WebRTC</b></h2><h5 class="post__date">2015-09-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cmzERa0bk0Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">greetings from wherever from Atlassian
yes we are carrying the word and coming
over here to to talk a little bit about
this fun topic of WebRTC thanks very
much everyone for coming here this is
very really a lovely event so a lot of
them yeah
so a lot of the work that we do at
Atlassian and HipChat is around this
open source project Cochiti where we do
various server components and people
that deal with web already see often use
them so I get to talk a lot of people
that experience WebRTC for the first
time and one of the things I've gotten
to hear a lot of times is we love WebRTC
because it is peer-to-peer and I
definitely understand the first part of
the sentence the second part leaves me a
little bit confused so I go and ask why
exactly are you so excited by the fact
that whether it is peer-to-peer so they
go and say well obviously it's more
secure oh so it has lower latency and it
doesn't require to deploy any servers
and it costs less so this is um it gets
more and more interesting because there
is some amount of confusion here let's
speak about security a little bit the
notion that your data is going to be
safe because it goes directly between
your peer is a very confused so first of
all unless there's a cable going between
your computer and the other guys
computing you can see the entire cable
then you're probably in for a rude
awakening there's there's a bunch of
things that you can do in order to make
your data secure it WebRTC does some of
them like be TLS support there are
others out there like said RDP but none
of them rely on the fact that your data
goes from point A to point B okay
also when you're loading WebRTC pages
they go through websites that relay your
signaling from point A to point B and
whether or not they would have the grace
to preserve the DTLS as RDP fingerprints
and very and so that they would be
properly verified by the browser's is
entirely up to them so unless
you're controlling these servers you
have to be trusting them in order to
rely on security lower latency is
somewhere in the middle okay yes it
might be true that because you're
talking to another person somewhere your
latency between you and them would be
lower but the likelihood of your
respective internet providers having
better peering arrangements with a data
center somewhere than they have between
themselves that likelihood is not low so
that it is entirely possible for you to
be able to connect better to Amazon than
between you two
and that would obviously have an impact
on latency so it's not automatic also
less hassle that is entirely untrue
first of all if you want to have web
already see you have to have web server
okay that's the first thing secondly you
have to deploy a turn server unless
you're okay with the fact that 10 to 20
percent of your users won't actually be
able to talk to each other so you are
deploying servers anyway
and whether that server relays 10 or 90%
of your data doesn't really change the
hassle of deployment and a lower cost is
the one that I respect the most I think
that's the best justification for making
the effort of supporting the right
peer-to-peer sessions because well if
you have a big service then you would
have to pay for significantly less
bandwidth on on your server side and
that would actually have a real impact
but even that only starts being a factor
after we reach a certain amount of scale
so all of these should be taken all of
these arguments should be taken with a
grain of salt bigger in some cases and
also people should not be afraid of
using media servers because they can
help you with all of these things they
can help you when you need to do
recording talk to the PSTN when you have
to do a broadcast over YouTube or
something like that they help you with
not reversal and one use case that
combines all of these ways they help you
is conferencing so we work a lot around
conferencing and this is this is this is
really what I what I love doing so I'm
going to talk a little bit about that
the different ways that you can do
conferencing with WebRTC
there are three popular architectures
that you can use with
or less success the first one
peer-to-peer mesh sort of stems out of
this love of the community for
peer-to-peer and how it's great and
secure and all of these things so when
you look at that diagram where you have
three browsers talking directly to each
other it's a beautiful triangle with
beautiful covers that stops being that
beautiful when you actually become a
real conference and this has a bunch of
problems so first of all many users will
actually be constrained in the terms of
upstream bandwidth that they have so
they won't be able to stream to a bunch
of peoples also because of the way that
congestion control works you have to
have different encodings in the
different when you're streaming to the
different people so that you can adapt
separately to the way their respective
bandwidth estimations are turning up so
you basically end up with a lot of CPU
usage now you could potentially get
around that but not with WebRTC the way
this today another way of doing
conferencing is by using the Oh pop also
popular MCU MCS are actually good for a
number of use cases this is the thing
that's basically behaving as an endpoint
you send one video stream you get one
back in though in what you get back
there's a bunch of composite images that
actually contain all the participants in
the conference but it is one single
stream very simple from the perspective
of the endpoint however relatively
complicated from the perspective of the
server you have to be decoding 30 frames
per second coming from every participant
you have to be creating composite images
scaling stuff down then Rhian coding
that is very heavy so it's going to cost
you a lot of cpu but not only that but
because this is an endpoint here you
would have to you would have jitter
buffers you would have to have
synchronization when mixing stuff so
you're going to add latency on your MCU
that you can't really solve even if you
throw more servers at it it's just the
technical delay that you cannot avoid so
this is still very good with when you
want to talk to legacy if you want to go
to sip endpoints if you want to talk to
to just PSTN and you want to mix the
media you have to do that but in case
you would like to scale then you really
have to go about have to go for video
routing I have the GT logo here because
I'm suddenly doing marketing because I'm
a great at that so this is our stuff but
can use other stuff as well obviously
there are a bunch of se fuse out there
all of them basically our video routers
and this architecture is all about the
performance all about the scalability
when we did testing in with with our
stuff we basically it was a very basic
test on a quad core exilim we got about
a thousand video streams coming off of
it taking about 500 megabits of data and
20% of the CPU was being used only on
that it was a bare metal machine not the
most powerful still not bad basically
what we got out of it is that we were
going to be bandwidth constraint much
earlier than we got CPU constrained so
that was that was pretty important now
when you start talking about video
routing too much and inevitably someone
would say yeah but more BIOS how are you
going and make me receive a bunch of
high quality streams on the mobile and
render them all there how is that going
to work you need an MCU there right well
not not yet not so fast there are these
two things simulcast a scalable video
coding that sa fuse and endpoints have
learned to do over the years that
actually help you get away with routing
video to Mobile's
and you end up with something pretty
good so we let me get into that a little
bit that what simulcast is basically
having every endpoint every browser
streaming three versions of the same
stream toward the core of the network to
warrior v toward your video router so
you would have the crappy quality stream
the normal quality stream and the high
the high definition stream all of these
would be generated at the endpoint and
they would all go toward the video
router they would be independent streams
all right they there's other than the
fact that I have the same content the
same movie or camera or something they
would not be related in any way now a
different way of achieving this multi
stream thing would be to do scalable
video coding and there are various kinds
of scalable video coding I'm going to
talk about spatial and temporal today
the one that's been very popular is
they're the most popular actually and
and spatial video coding is is actually
pretty easy to
you have to think about it the same way
as you think about images when you see
them slowly loading in your browser and
then initially you see a crappy version
of your of your image in the browser and
then when you get more data it gets
better and better and better until it
becomes the image that you're actually
supposed to see scalable video coding
sort of is something like that basically
when you get the independent of the
different video streams that the
endpoint is generating they're not
entirely independent you you do have a
base layer that is just a regular video
stream but anything that comes on top of
it is just that the information that you
need in order to complete that imaging
to a higher quality image and then again
you have just the deltas on the on the
upper layer the edge the the higher
definition image that would help you
upgrade your image to a high definition
image these streams are related and in
that direction so you could easily drop
these two and still be able to read that
one or you could drop the upper layer
and still be able to reconstruct
everything here what you gain by doing
that is a little bit of a bandwidth
optimization as compared to simulcast
and a little bit of a CPU optimization
although these will have to be weighed
very carefully because it depends a lot
on the resolution if you have big
differences in resolutions then
simulcast might actually turn out to be
more boundless in CPU efficient and then
the third way of doing scalable video
coding that I was going to talk about
today is temporal as we see and that's
again we have the concept of three in
the pantry separate streams going from
the endpoint toward the network but
rather than having differences in
quality they're all the same quality you
just have differences in in terms of
framerate so your lower layer is just
let's say 7.5 frames per second and then
in the upper layer you basically just
have the missing frames and then you
later beyond to get you to 15 layers and
then I'm the layer on top of that you
just have the missing frames that would
get you to 30 frames per second or to 60
or do however whatever frame rate you
want to support now how does this help
you in the context of video routing well
whichever of these you use
whether it says vici or simulcast or
anything your browser or endpoint would
stream them toward a video router and
from there it would basically try to
send the best that it could toward the
endpoint so if you have something
connected over fiber on the other end it
would be a router would basically go and
relay the high-definition stream that
the bandwidth test estimations that are
being done used the algorithm that's
implemented in Chrome
that's defined in these Jeff that's that
Harold wrote the same thing has to be
implemented obviously in the video
router as well for the whole thing to
work and obviously as these bandwidth
estimations start reporting lower
bandwidth between the router and the
endpoint you start dropping the layers
you move to 720p or to a thumbnail image
whenever you detect that this is
necessary and then obviously you can do
exactly the same thing on the sending
side where as the sending browser
detects that there's not enough
bandwidth it can drop the resolutions as
it needs so you can very easily adapt
not very easily but very accurately
adapt to the bandwidth and the device
and the network that you're talking to
even though you're doing absolutely no
transcoding as an MC you would do for
example now how would you do that today
this is always a very interesting topic
today there is a good way to do that in
chrome it works so you basically do your
create offer and or create answer or
anything and when you find your media
line your video media line in that and
you just put in there a simulcast group
with describing three streams or two
streams or however many streams you
would need and that's it you don't do
anything else it's actually really great
because you don't have to so early when
we were thinking about simulcast we're
thinking well we would just clone your
video track and and then we just dream
to separate things but then that means
that we have to worry from within the
JavaScript application about getting the
bandwidth estimations and we don't
actually have access to our TCP so we
have to find another way of sending them
and the whole thing isn't very optimal
to begin with
so having chrome taking
care of all of this stuff is really
really neat and the even more
interesting part here is that when you
do simulcast with Chrome in addition to
the different simulcast layers that you
get you also get temporal as we see
within some of them and at least that
was the case at some point and if that
has changed please let me know but so
you get temporal as we see in there
which basically leaves you not only with
three but potentially four or five
layers that you can choose to switch
between on the router and adapt very in
a very fine way to what's actually
necessary for the endpoint to receive
now unfortunately right now this only
works with Chrome but it is very soon
going and coming Firefox as well so this
is really great news it's likely going
to work in a similar way as then you
won't have to
and where is news news he can confirm or
or deny or maybe neither but this is
likely going to work in a similar way as
in it is not going to require it to
clone video video streams you would just
basically either using SDP or RTP sender
parameters or something like that just
tell your browser that I want you want
to have multiple tracks and it would
take care of it all which is again very
very neat unfortunately on the
standardization layer of this thing we
don't yet have a unique solution on
everyone should implement should
implement and it is unlikely that we
would see it from what I understand in
one d'Oro so there still seems to be
consensus about a number of things for
example we won't have to clone tracks
that everyone seems to see that seems
the thing is not a practical way of
doing it you may have to use the RTP
sender or it may be SDP only who knows
but there's still some bottlenecks from
that were identified on the meeting job
that just ended in Seattle yesterday
there's some work that has to be
finished in ITSM music that is not quite
done yet so maybe the decision would be
postponed toward the next epad meeting
and again it probably won't end up in
one at all but what I'm trying I guess
I'm still very optimistic because if we
get support for simulcast in the
individual browsers even though it'll be
a little bit different as long as it on
the conceptual level works the same way
browser takes care of the details and
the syntax is a little bit different
that's not a big deal
or at least not as big of a deal as it
would be if we didn't have simulcast
support at all so I'm what you should
take away out of this is that simulcast
is going to be a solution for your
conferences in the near future
regardless of the browser and without my
friends my talk is done thank you very
much thank you meal questions do we eat
too much
no questions let me start again hello
there's the question over there thank
you very much
so it seemed pretty easy to use
simulcast from the STD packet
modification that you showed does does
do you have to work on the the the
forwarding unit to choose which seems
absolutely it's actually very fun work
we've been dealing with that for the
past year we actually had even one
working version and we decided to do it
in a different way but yeah what you
have to do on the on the forwarding is
that you have to implement the bandwidth
estimation so that you would know when
to do the switches you have to recognize
the different resolutions not not as in
looking into the video content itself
but you have to indicate it somehow and
then what we decided is also necessary
is we to rewrite s SR sees basically be
able to switch video streams without the
endpoint net noticing that you're
switching them cuz otherwise you have to
implement support for that on the
receiver end as well and it the whole
thing becomes a big mess and you have to
do it every time we implement a client
and all that so yeah there is some
amount of work on the forwarding unit
but but it's a it's substantially more
efficient than say just because you
could just open multiple connections and
have different user media's give
different right so I I'm sorry I thought
that you were asking me is there
development work yes I I was right okay
but in terms of processing work there's
there's basically none okay so it is
infinitely more efficient than than
processing medium there's not a question
over there what about support for
different devices having different
codecs or different encodings that where
do you have to implement an MCU in in
those cases okay next question please
so having different codecs in a in a
selected forwarding conference is a big
problem actually the bigger problem is
having devices that do not support the
codecs that other devices are trying to
use and this is a very tough problem so
you there there are various ways to
solve it
none of them are ideal for example you
could basically make sure that they're
depending on how many you how many
devices you expect to have some weird
codec you could have
transcoders specifically for these
devices working on on your network or
something like that one thing that I
often say is that this is definitely not
something that you should implement in
the forwarding unit because it basically
modifies your scaling behavior in a very
dramatic way so you should definitely do
it somewhere separately MCU using an MCU
as a as a complementary element of your
architecture that would also be one way
of doing it but there's no there's no
ideal answer here unfortunately
so everyone should support DPA - thanks
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>