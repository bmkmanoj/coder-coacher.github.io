<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>IBM Bluemix: Mixing voice &amp; data | Coder Coacher - Coaching Coders</title><meta content="IBM Bluemix: Mixing voice &amp; data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>IBM Bluemix: Mixing voice &amp; data</b></h2><h5 class="post__date">2015-09-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xkB0qiU6PGk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so yes so today we're going to be
talking about web RTC in a doctor's
office and some cool stuff we've done
with IBM Watson who's heard of IBM
Watson thing to kick jeopardise ass um
sorry a baby on the way I need to stop
cussing but oh so we're going to be
talking about a real live use of WebRTC
in something that actually really
matters um there is a client in Houston
Texas that we were working with that
tries to help people with cancer all
over the state of Texas and they had
issues with people driving six hours of
the hospital come see some of the best
doctors in the world so they asked to
help for us to develop an iPad app for
their doctors where they could video
chat with other patients and do remote
tell consults really saved as patients
some time so Chris is going to be my my
wonderful doctor today and we're going
to go through a little quick demo so
this is so the ipad we're going to go
through an ipad app that also has 12 use
WebRTC running on it there there video
chat framework and also a bluemix app
that has it's just a note app running in
the browser that we're going to use
interact with it yes it is so I'm gonna
ask Chris to open up open up the app and
I'll be the doctor for me really quick
sorry we can't show it up here on the
screen anyways so it this is the app the
doctor would see every day let's see
some of their upcoming patients and then
they can see some of their vital
information about the patient and see
some some CT scans stuff like that
regular doctor stuff so let's say I
actually want the video chat with my
doctor today so Chris the doctor could
go online and pretty long as ours what
insurance do you have not good enough
for you so he would click little video
icon to do a little video chat with me
taught in the top right there's a little
and I'm going to video chat with them as
well so that's going down your generator
will get Justin here this justin is here
so earlier we also saw this wonderful
user experience with a WebRTC so I I got
asked to use my microphone and camera
okay so in a second it's going to come
up hopefully
the screen if the Wi-Fi cooperates come
on oh here we go cool okay so the cool
thing here is if you notice at the
bottom of the screen it's actually
typing what I'm trying to say and we get
close to the computer and try to talk
hello Chris how are you doing today I
would like to talk about the cancer
treatment we have been working turn the
volume down okay the transcription
really wasn't that good right there with
it works really well at the microphone
but it's actually not too bad what's
going on here is Watson is transcribing
this text in real time and we're going
to go through all the fun dirty stuff
I'm ready to endure it out who else is
right in there go out to see how this
works yeah so actually you just put out
Sergey pointing out really cool points
so Watson will auto correct text on the
fly they'll try to figure out what your
say in the context of what you're saying
it and try to correct it on the fly so a
really quick demo let's go through how
some of this stuff actually works now go
back to the keynote I guess I should
have had this up here earlier but my
name is Jeff's lawyer I'm a developer
advocate for something that IBM has
called bluemix we're gonna go through
what bluemix is really really quickly
and then we're going to nerd out so what
is bluemix it's basically a platform as
a service that's built on Cloud Foundry
who's ever heard of cloud foundry it's
really awesome so there's also docker in
VMs and I basically think of it as your
one-stop shop for a developer for
everything need from a database to use
in cool things like Watson running your
favorite programming language for a web
app autoscale on your web app you can
run go you can run node whatever you
want you can run so that's really what
bluemix is and that app we saw earlier
that was a node app running because i
really like note so let's go through the
flow of how this kind of work so in the
beginning uh the the patient would click
to call the doctor what i did in my web
browser the next initiates a WebRTC saw
web RTC call to twilio and then the
doctor also initiates a call from there
from his iOS device to twilio as well
so we got to call establish great basic
web RTC stuff nothing that crazy there
so this is where it starts getting cool
so after chatting the dialogues going on
the audio stream is streamed from the
web browser to a node back-end over web
sockets and then it streams to the node
back end and where it's running in
bluemix that audio is taken from the
node back-end and sent over a REST API
to IBM Watson so what does Watson deal
with it it actually takes the text and
transcribes it from the voice stream
into text and Serge pointed out great
point it'll try to figure out the
context of what you're talking about
it'll go back and try to correct itself
kind of cool so will transcribe the
audio in real time real times to keep
the key point here we just like storing
the the transcribed audio just for fun
and then lastly we didn't go over this
in a little quick demo on the iPad app
but the doctor is also one of the way a
fun cool way of seeing the the mental
psyche of their patient how they're
dealing with their cancer treatments so
there's another really cool service
Watson has that basically will you give
it a bunch of texts it'll tell you the
personality of the author so if they're
like upbeat sad there's a whole bunch of
personality traits I don't understand
I'm not a psychologist so I don't
understand a lot of them but we picked
out a couple that you can kind of see
the mental psyche of how a patient was
feeling about the cancer treatment
pretty cool and the last step send Z
transcribed audio back to the doctor in
real time of our web sockets as well as
well all in real time so we're going to
go through a couple points and how this
works so the first part see the
WebSockets piece with WebRTC how that
works and then lastly the transcription
with Watson and how that works as well
so um I love this picture it cut with
with twilio zai OS SDK and the
JavaScript SDK made this really really
easy combined with a nap in bluemix it
made this incredibly incredibly easy to
do this and I did this all in three days
it was Fort Williams conference early
this year and made us in three days
underneath the knife a lot of pressure
and got done three days and the point
I'm trying to make here is this WebRTC
and you
in bluemix together incredibly
incredibly simple makes your life as a
devs so much easier so let's get into
the code i promise you code let's let's
really nerd out now so we'll go through
some of this so this might be I don't
know how familiar everyone is with some
of the the audio streams and WebRTC so
basically what we're doing is trying to
grab the the media stream let's see if
this laser pointer thing works grabbed a
media stream from the the local audio in
the web browser grab that media stream
connected to an audio processor
basically what that does we'll go
through that in a second remember this
on audio process function here we're
gonna see that in the second what that
does and it's basically tying the the
media stream to the to a function to
allow you to do basically anything you
want with the audio you can spy on it
you can change it all around you can do
whatever you want it's pretty cool a lot
of this stuff is really not documented
well we're going to some lessons learned
later but a lot of the stuff is not
documented well on the web so the cool
part with what this is really the
WebSockets piece streaming the audio in
real time to to our to IBM Watson so we
can get that transcription the doctor
can see what the patients say in a real
time so the big what basically wed
sitting here is opening a WebSocket
connection to our node back end then
down at the bottom I should have have
line numbers on this this mess this funk
should show a result we're going to come
to that in a second again but that
basically anytime there is a new chunk
of audio that comes through a new meta
message gets sent over web sockets new
message is emitted / WebSockets to our
back-end it has the audio so promise to
you this on audio process function this
is really the guts in the meat of
everything how this works basically what
this is saying is we're going to grab
the just the data that's coming off of
the audio stream ones and zeroes and
then convert it actually this is the
dirty trick convert it into PCM 16
whoever who does what PC m16 is there's
an audio file in the room you'll know
what it is PCM 16 it's a high fidelity
audio format that's all really is but
Watson wants the audio in
this pretty specific format I don't know
why but it just does so I did not put a
function up on the screen it's called
export data buffer here on the screen it
is a dirty dirty dirty function that
converts a WebRTC audio stream whatever
the whatever formats it's in to PCM 16
pain in the butt it was not fun figuring
it out that was a lot of guessing and
checking so this function this is what
after we get that all transcript after
we could get in converting the PCM 16 we
want to send it to our our node back in
and this is traditional socket WebSocket
code it's just emitting the message with
our audio to the back end so I know this
is a really long slide when we try to go
through it there's a lot going on here
the first maybe 10 lines is just saying
when a WebSocket message comes in it's
just going to create a little JSON
object to send to Watson it's just
constructing that so remember that pc
m16 that's where it comes up again right
there and all this other stuff is just
needed for watts and so i knows how to
do it the most important line really
really simple and this is a node there's
an NPM package for Watson which is
really really awesome this uh this
method recognize live it's an absolutely
really really cool method so you give it
a JSON object and a function to call
back once wats and transcribes a text
you can get your your data in an L
Watson real time our web sockets really
cool and then what we're saying here the
line below it is we're going to wait for
results come back observe result once it
comes back from wat so we're going to
wait for it to do something and then at
the very bottom worries we ascend it
back to the back end so let's go into
this observe result mess observing
results it's really really cool how this
works so what this is saying I'm just
going to highlight one line here that's
really kind of cool so when Serge notice
this earlier Watson was renaming some of
the audio context what was being talked
about Watson gives a best guess of when
you're done talking about something
they'll try to figure out when you're
done talking about a sentence and that's
really really cool in the fact that you
can see what's doing and then you can go
back
wats let's go back and show you
something different so one last little
uh little code piece this is a this
JavaScript on the client-side this was
the cool thing that was showing the UM
the audio in the web browser and what
this is saying is this the dirt I'm
sorry this is really dirty code but
basically what this is saying is trying
to figure out a sentence structure for
when you're talking so it shows periods
and breaks in it'll go back and replace
texts Watson the figures out the text
which you're talking about and we're
going to go through some lessons learned
with WebRTC especially with twilio and
doing us in bluemix so order for
starting a call it is can be quite buggy
at least in my experience with with with
this um for the app that we did when I
made Chris actually hit the button first
to start the calls a doctor for for some
unknown reason of the call was started
first by the the patient of the client
it would not work so that was a pain
about to figure that out there is lots
of issues with WebRTC in chrome and
firefox leading up to when i did this
demo twilio uh firefox just came out
with a new version is like Firefox 38
sorry if there's anyone here from
Firefox I'm hitting on you right now a
little bit fire okay sorry a new version
of Firefox came out it was like Firefox
3802 or a one or something like that it
broke WebRTC for remote audio I was
talking on the phone with rob from
twilio and it was like we're going
cancel his demo because the this
doesn't work but eventually found a an
older version of firefox fire 30 Firefox
35 that worked so to give chrome some
hate also you cannot spy on the remote
audio I'll know if it's fixed yet in
chrome yet you cannot spy on the remote
audio from a remote participant and
WebRTC right now there's an open bug
about I'll know if it's been fixed yet
that was a fun one to work through also
thank you it has not been fixed okay so
yeah you have to use Firefox 35 really
is the best for this right now so
multiple web socket streams are really
really hard I was trying to set up this
demo where the transcribed audio from
the doctor in
patient you get both of them at the same
time if you've ever tried doing that and
node or JavaScript on the client side
it's not fun it's one of the most
complicated things in the world to do if
you've done it I would love to see your
code because I hated my life trying to
figure it out getting the audio format
was right um the api docs for watson
never really mentioned you needed the
audio in PCM 16 since this demo it's
been fixed the documentation says you
need PCM 16 but that was a pain about
doing that and then converting the audio
in the browser on the fly the PCM 16 was
not fun that was incredibly incredibly
complicated I eventually found some
algorithm that kind of did it ants over
my head yes I like it another Watson
service of convert audio from XYZ to PCM
16 like it so personality the patient so
this was what I was talking about the
doctor trying to figure out whether or
not their patients upbeat about their
cancer treatment or not so in a demo it
was the personality we cannot figure it
out until the call was over because we
were waiting for the whole chunk of text
from the whole transcribe transcription
to be there could be cooler and smart
about and instead of her done a bunch of
rest calls as a call was going on you
could see the you could see the person
out the patient changing as the text is
going through that would be kind of cool
but this didn't do it just was too much
work scaling web sockets um it's not fun
I mean you can do it with like Redis and
stuff and really make it scalable but
there's also issues like how do you deal
with the results coming back from Watson
and knowing which web sockets sessions
are sticking on to send back to the
client web sockets the scaling is not
fun with that type of situation spying
on the media stream this was I mentioned
it lists a little bit earlier it's not
well documented at all with WebRTC
really on how to do some of these piping
with the audio the streams in the
context and stuff that was really kind
of complicated eventually like cobbled
together something from Mozilla's
documentation and some other sites kind
of found some things that kind of work
oh the a lot of these things were not
really well documented was kind of
really kind of bummer lastly the
WebSocket
so Watson dropped a lot for some reason
I don't know why but I don't come in I
don't know what it was but eventually
wrote some retry logic in there to
reopen the WebSocket connection which
made my life easier uh and then this is
my wonder I couldn't have a presentation
with Alec hadn't any questions I didn't
have a unicorn but there is a cat no
it's a stuffed animal Yeah right up here
in the front there's an organization
can't remember the name but they're
using software to characterize the style
of callers and on this second call from
that caller they feed them to reps that
are specifically good at handling that
style are you aware that and he
considered building something like that
in on I've heard of something like that
I forgot the name of the company that
was doing that but there's another API
in bluemix that you can use this by a
company called alchemy API really cool
company that IBM bought you can actually
determine the sentiment and you can pull
out key words of their talk so you could
use do something like that route it
takes the sentiment of the conversation
see if they're really pissed off or
happy and then use that for rally them
to the right type of agent the level to
agent the level 3 agent whatever you
want so I think those guys were in
Chicago if that helps yeah that would be
I'll be really fun next up more homework
first is it live yet yes this is live
all this was running live on the
Internet there was actually the website
was twilio da video my bluemix net
that's that's you could actually run the
whole demo from there if you go to slash
provider you can fake yourselves as a
doctor you'll have to have the ipad app
but yeah it's all live on internet and
the patient can be in the mobile app as
well or is it no so just the patient can
only be in the web browser another only
reason we did that was twilio want us to
highlight iOS to the web browser I mean
just uh I mean maybe from use kiss
perspective and somebody is really in
trouble they would have their phone
handy then opening up their laptop and
connecting with the doctor and all of
the
it's oh no that's great feedback
actually funny you mentioned that um
that ipad app we that we was up here the
doctors actually hated it they want it
on their phone now because the ipad was
too big they don't like stick it in
their scrubs it's too big for thanks one
more just forgot a cure WebRTC for
medical and HIPAA compliance so which
pieces are already handled by WebRTC
which pieces do you need do we need us
third party developers to worry about
can you repeat the question whether
sorry um WebRTC for medical and HIPAA
compliance oh okay okay um I'll defer to
that at least on the video the video
part to twilio I'll let Rob or so answer
that later but for everything that was
running in bluemix everything else that
was the data was encrypted at rest
bluemix is HIPAA compliance so it's fine
with that we actually spent a lot of
time with this client going through how
their application can be secure they
don't get sued and yeah we spent a lot
of time with that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>