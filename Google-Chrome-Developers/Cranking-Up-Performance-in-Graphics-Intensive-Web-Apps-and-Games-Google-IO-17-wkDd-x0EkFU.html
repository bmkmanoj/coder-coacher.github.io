<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cranking Up Performance in Graphics Intensive Web Apps and Games (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="Cranking Up Performance in Graphics Intensive Web Apps and Games (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cranking Up Performance in Graphics Intensive Web Apps and Games (Google I/O '17)</b></h2><h5 class="post__date">2017-05-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wkDd-x0EkFU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon thank you coming I'm just
annoyed sad I'm a software engineer on
the chrome team and this afternoon I'll
be talking to you about ways of cranking
the performance in your graphics
intensive web apps and games for those
of you who haven't read the abstract
just to make sure we're clear this talk
is going to be mostly about canvas and a
few other things here's what we're going
to be covering today the we're going to
look at ways to get smoother image
loading this is because image loading is
often a source of jank and web apps and
also we'll look at the problems that we
face when we're aiming for 60 frames per
second and how to solve these and also
we'll look at moving web apps closer to
the performance that we get with native
apps and we'll also be looking at ways
for memory efficient and CPU efficient
background rendering and finally we'll
look into streamlining some important
use cases with WebGL in particular
multi-view rendering and web VR the
first topic synchronous image decodes so
the current practice when we load an
image asset into an app is to start
using it as soon as we get the the
signal that the image resources is
loaded so this is what we do with the
onload handler right so onload
guarantees that trying to use the image
is going to work if we use it
immediately but it does not guarantee
that it's going to be fast so the first
time that we use an image resource
usually there's a delay due to the year
to the DeCoteau ver head and that can
cause apps to be janky especially if we
start loading images in the middle of an
animation
and examples of use cases are the first
draw of an image to a 2d canvas using
the Dry Ridge method and also a texture
upload to a WebGL context using the text
image 2d call so the solution to this is
to decode the images in the background
so image a coat is not something that
web developers are used to controlling
because we kind of just leave that up to
the browser and it just happens but you
can take control of this using a new API
that's called image bitmap so this was
released earlier this year it's
available in Chrome already and it's
also available in Firefox here's how the
spec defines what an image bitmap is
it's there's a few words in there that
are a little interesting towards the end
of that sentence I'm do latency
what exactly does that mean it's kind of
subject to interpretation but what is
clear is that this is a performance
primitive and what we do know is that
image decode is a source of latency that
we want to get rid of so in chrome we we
interpret this as we want to get rid of
decode latency so here's how it works
the use case we're looking at here is we
have a web app that runs an animation
and while we're in the middle of the
animation we have a new image that we
want to load from the network and start
using it so we can do that fetch
asynchronously using the fetch API or
using XML HTTP requests and while that
fetch is pending the animation loop can
keep running and then once we get a blob
back we can call create image bitmap
this new API and that will initiate the
image decode and the Ducote is going to
happen on a separate thread with inside
the browser so your animation loop can
keep running while that's happening and
finally when we get
image back you can use it in your WebGL
context or in your 2d context and when
you're done using an image bitmap like
once you've uploaded it to a WebGL
texture it's a good idea to call clothes
this is not mandatory but if you close
the object it's going to free the
resources that are behind it immediately
instead of waiting for garbage
collection so this can help keep down
the memory footprint of your app it can
also help reduce the frequency of
garbage collection because if you have
all these dangling large objects they're
going to have to be collected more
frequently but once you you clean up an
image bitmap object it has a tiny
footprint and you can collect these over
many frames so just the old way of doing
things this should look pretty familiar
just using the image interface and
loading it and once it's loaded we use
it the new way it's not a lot more
complicated it's just you know maybe an
additional line of code in this example
we're using the fetch API but you could
also use xhr and there's nothing new
about how we fetch the blob here just
once we have it we call create image
bitmap and that function returns a
promise and the promise resolves once
the image is completely decoded so here
are some videos that well just let you
watch them they kind of speak for
themselves so the left one there's a bit
of a pause when the image changes and
that's the decode that's causing that
change and the right one is smoother
these were captured on a nexus 5x device
so this is a phone from from last year
and we were using one megapixel images
they're not that large
you know just 1k by 1k now let's look at
the dev tools timeline and see what was
going on so in the first case where
we're using an image element
there's this long image to code and on
the top row of this graph we see frame
times what's interesting is there's one
frame that took 233 milliseconds to
render that's terrible
that's definitely noticeable by the user
so what's causing this is the
synchronous the code inside the call to
text image to DS so that's what the this
flame chart is showing the image the
code is nested inside and this is what
happens the first time you use the image
resource if we were using a 2d contact
with a draw image call the chart would
look at essentially the same it would
just be drawing image instead of text
image judean we have the same problem
but the second time we use the same
image resource then the the texture of
load would be a lot faster but in WebGL
you don't really acquire an image and
then upload it multiple times you really
just need to do this once so we're not
really taking advantage of the DES code
cache and also images are not decoded in
advance for a really good reason because
people often ask us like how come when I
load an image clearly I'm expressing
intent that I want to use this image so
why doesn't the browser just go ahead
and decode it right away so that's ready
for what I need to use it but if the
browser we're always doing this with all
images it would run out of memory
because a lot of web pages have tons of
image resources and we can only really
afford to decode them as they're used so
that's why we're stuck with this problem
now this is what happens when we use the
create image bitmap API on the top on
the top row of the the main thread you
see there's a bunch of small little blue
lines
that's the overhead for fetching the
blob from the blob store
and the big green rectangle at the
bottom that's the image to code and the
image the code is happening on another
thread that's called worker pool and
what's the important part here is that
why this decode is happening the main
thread continues we can see all those
little animation frame ticks so it keeps
it keeps doing its work while this this
long task is happening on the worker
pool and now this little blue arrow you
see right there that's pointing at the
text image 2d call so this thing that
was the big source of jank before is now
reduced to about three milliseconds so
it's no longer a big issue now another
use cases where we experience jank from
image decodes is image injection when
you have a page that's just adding
images to its existing content by
injecting them well it's not really good
idea to start using image bitmap for
that and examples of of kinds of pages
where this would be an issue or really
long scrolling web pages with lots of
images like a news website or a social
media feed if we started using image
bitmap for all the image resources we
could run out of RAM because it's just
you know there could be too much content
in there especially if we're decoding
them on a mobile device so there's
another solution for that use case this
is currently under development so it's
not yet in the browser but it's going to
expect to see it soon as an experimental
feature in chrome this is a new function
on the HTML image elements interface
we're adding a DES code function when
you call this what happens is it
triggers a DES code that can also happen
on a separate thread and when it's done
there's a promise that gets resolved and
that tells you now's a good time to use
the image to for example append it to
the to the documents and that won't
cause
so the reason we want to use this
instead of image bitmap is that this API
does not pin the image resource and Ram
the image the decoded version of the
image is evicted so it's a lot
friendlier for situations were under
memory pressure so it's expect to see
that soon behind a flag and Chrome so
next topic animation smoothness so UI
performance is always a concern in all
types of applications for graphics
intensive apps and for games it's a
constant battle we add features we make
things prettier and you know our
rendering time increases the app gets
lower we lose our beautiful 60 frames
per second so we have to reel it back in
on mobile it's even harder we're dealing
with a slower CPUs and GPUs less ram and
also the touch interfaces they make
lagged more perceptible to the user so
this is what it looks like when we're
trying to drive animation using the Dom
so we have our sixteen point seven
millisecond budget this is if you're
targeting 60 frames per second and
there's the blue rectangle there the
JavaScript slice that's the time your
app has to do its work whatever it needs
to do at each animation frame and we
also have to keep a big chunk of time at
the end where we're not planning to do
anything that's just idle padding and we
need this because there's a lot of stuff
that your app cannot plan for that the
browser just does for example a garbage
collection it could just happen at any
time or there could be thread scheduling
issues if you're on a CPU that doesn't
have a lot of cores and there's a lot of
work to do the main thread could get
these scheduled and all of a sudden you
have one frame where everything takes a
bit longer to execute and also you could
have event handlers event listeners I
mean and you can have a burst of events
that happens all of a sudden and you
have to deal with it
and this is tricky so you need to have
some padding if you really want to be
able to keep that 60 frames-per-second
rate then there's the browser overhead
the style and layout this is just a cost
you have to pay whenever you're touching
the Dom directly in JavaScript and then
there's a painting and compositing
overhead this is the cost of just re
rendering the contents of the webpage
and there's no way around this
on on mobile the fixed costs that are
imposed by the browser they get
stretched right because we you're on a
slower device so that squeezes even more
your JavaScript time slot and that makes
it that makes your frame deadline even
harder - that's a respect now when we're
animating with canvas that orange
rectangle that we had for style and
layout that one just goes away because
we're not touching the Dom so things get
a little bit better the time this
timeline it's also valid for use cases
where we're using CSS animations will
certain types of CSS animations like if
you're animating opacity or simple 2d
transforms the style and layout
calculations don't don't need to be
recomputed at each frame then there's
the painting and compositing step it's
usually a little bit later when we're
using a canvas because the browser has
less less work to do so in general when
we're doing sprite based animations we
don't really need all that extra support
that the DOM and CSS give us and you can
get a significant performance boost by
using canvas and this is what a lot of
2d game developers have been doing
recently since html5 canvas appeared
several years ago now this is what your
timeline looks like when you're making a
native app first of all you have more
predictability therefore
much little idle time is required
because you know you won't get any
surprise garbage collections the threads
are under the control of the developers
so you can you have control over you
know how many threads you have and
what's the workload that they have so
you don't have to worry so much about
scheduling if you're if you're doing
things right and also your events like
your input events they can be coalesced
so there's the time that they consume is
more predictable so that's that's nice
now how do we get the mobile app
experience closer to what we have on
native well the first thing we want to
do is get rid of some of that overhead
now the the painting and compositing
overhead is necessary with canvas
animations because we have to go through
the same presentation process that as
the Dom does because we're keeping all
of our content synchronized but many
apps that use canvas they're not
touching the Dom so what if we just
broke that synchronization constraint in
order to get rid of that step well
there's a new API for that and it's
called
off-screen canvas so off-screen canvas
is kind of like a canvas element except
that it's not a Dom element it's just
it's just a native interface now it has
no style no layout it's not directly
paintable it's not composite ball so
this means it can't be a part of the
document by now you're probably
wondering so it's not paintable or how
do I do anything useful with it I the
whole point is I'm animating something
that I want to show on screen so how do
we display it well we use a placeholder
the placeholder is a regular canvas
element that lives inside the web page
and the the off-screen canvas is
connected to it so
we can inject the content that we
rendered in the off-screen canvas into
this placeholder location on the on
screen that's reserved by the canvas
element and the process of the commit
process it's very lightweight it
bypasses the Dom update mechanisms and
the presentation actually in Chrome's
implementation the presentation all
happens in the browser process so it
doesn't consume any time on the on the
main thread which is where we're trying
to save a save time for your application
this is what it would look like to use
off-screen canvas in JavaScript so the
first thing we're not constructing the
off-screen canvas directly we're calling
a transfer control to off-screen canvas
this is a method on canvas elements that
creates that placeholder connection you
get a new off-screen canvas that's
connected to the placeholder canvas then
we create a rendering contact the same
way you would on an HTML canvas and then
the animation loop well things look a
little bit different there there's this
commit method that we call and this is
what pushes the content updates to the
placeholder and you'll notice that
there's no requestanimationframe
that's because requestanimationframe is
is tied to the Dom graphics update
mechanism and we're trying to bypass
that so we're using something else
commit returns a promise and the promise
will resolve when it's time to render
the next frame so that's how this works
this is commit and it also plays the
role of requestanimationframe at the
same time so let's see how using this
impacts our CPU usage on the main thread
this graph shows two devices a powerful
workstation and a typical phone so the
the orange bars they represent the the
time it takes to
presents 300 by 300 pixel canvas to the
screen and what we see here is that in
both cases the the time it takes when
we're using an off-screen canvas it's
faster by about an order of magnitude
regardless of the dices device we're
using so on mobile we were taking two
points seven milliseconds out of our 16
millisecond budget just for pushing
pixels to the screen and that overhead
is it's not necessary in most cases so
this kind of seems like okay this is
obvious we should just always use
off-screen canvas but it's not that
that's simple that's not a free win
because we lose synchronization with the
Dom and some abs really need that but if
you're doing a game that runs in a full
stream canvas for example you most
likely don't care about that so you can
just go use this and get a perf win for
free now what happens if your main
thread is busy for example there's a lot
of event traffic happening on the main
thread and certain events have to happen
on the main thread because that's where
the interfaces are well off-screen
canvas can be used in a worker this way
we give the animation loop its own CPU
core and it can just run without being
disturbed and this way we're reducing
the idle time that we need so that's
another step we can take that brings us
closer to native performance so we're
just giving the canvas well our
rendering loop actually we're giving it
an isolated execution environment we get
more predictable run times for each
animation iteration therefore less idle
padding here's how it works the first
part of creating the off-screen canvas
that's the same as before we just call
transfer control off-screen and at the
bottom of this page the animation loop
that's also the same as before except
that it's running in a worker
the difference is what happens in
between after we create the off-screen
canvas we need to send it over to a
worker so we just we use postmessage for
that and you'll notice the way
postmessage is called here we're using
the second argument that's the
transferable list and that's really
important because the off-screen canvas
object is not cloneable but it is
transferable and when you transfer it it
preserves that connection with the place
holder so though we've moved it we move
the object into a new realm if we commit
from the worker the content still ends
up in the placeholder canvas now here's
a simple example that Oh something wrong
with the video let's retry that slide
okay what we're supposed to see here is
I'm going to picture it so you try it
you know everyone close your eyes try to
imagine this on the left there's a
canvas with an animation that runs
really poorly and it's happening on the
main thread and on the right there's
another animation oh here we go
Thanks all right so the the animation on
the right is going nice and smooth and
the one on the left is janky so the one
on the left is being rendered on the
main thread and the reason it's so
choppy is because we deliberately
inserted long tasks on the main thread
and those long tasks are preventing
requestanimationframe
from reaching its target framerate so
the point that this makes is even though
requestanimationframe isn't running at
full speed on the main thread the worker
can still pump out frames at 60 frames
per second with no issue and that's the
that's the whole point of isolating it
so that's what that show can we switch
back to the slides now thank you alright
so by now you're probably thinking all
this seems nice but there's one little
problem here I'm already using a
framework and it just uses canvas it
doesn't use off-screen canvas well maybe
but it's that really a problem there's
something really interesting is that the
the web platform is highly hackable
right people do polyfills well with
off-screen canvas often we can just drop
it in the frameworks that usually use an
HTML canvas element and you know hope
for the best and maybe things just work
or maybe you have to do a little bit of
a bootstrapping to get things working
kind of like a reverse polyfill
mechanism of that makes sense so we're
I'm going to walk you through an example
of this using the 3GS library
so QJ s is just for those of you don't
know it just a really popular framework
for doing 3d rendering on the web and 3j
s is meant to work with canvas elements
what we're going to see is not only can
it easily be set up to work with an
off-screen canvas but we can also use it
in a worker without too much work and a
quick little disclaimer the steps I'm
going to show in them and the following
slides they're not a complete
full-featured solution they're just you
know some some ideas to get the ball
rolling if any of you would like to to
try this the first step getting it to
work with an off-screen canvas usually
3GS renderers the way most people use
them is that we let the renderer create
its own canvas well we can override that
behavior because the renderer
constructor can take a creation
parameter called canvas and we use that
creation parameter to specify our own
canvas to say okay now don't create your
own I have one go and use this but this
parameter expects to receive an HTML
canvas element but if we've sent it an
off-screen canvas instead will it just
work well it almost just works there's
this one little thing we need to do
off-screen canvas doesn't have style
right it's not a Dom element why would
it have style and sometimes the there's
a bit of code in n3j s that tries to
write the width and heigh style so here
I just created stubs but you could do
something a little more clever you could
create a getter and a setter that
forward the style to the placeholder
canvas that might be what your that
might make sense for your application
maybe maybe not but anyways the stub is
enough to just get started and show
stuff on the screen the other problem is
how do we get three GS to work in a
worker three GS has dependencies on some
Dom interfaces
the most important one is HTML image
element but we can work around that
and we're going to work around it by
using the same texture loading mechanism
that we saw in the first part of the
talk where we use create image bitmap so
that's what that this diagram at the
bottom of the slide shows using xhr or
fetch to get a blob down the blob use
create image bitmap that an image bitmap
then upload that to a texture here's one
way of doing it this is a really simple
quick and dirty way of doing it of
course we could just tweak the through
J's library to make the make it do the
things the way we want but here I'm not
touching a through J as distro and
there's a good reason for doing it this
way if you don't hack it then you can
keep getting through J s from your
favorite CDN so here what we're doing is
we're hacking the prototype by
redefining what image loader load it
does and it turns out that 3GS already
provides a file loader interface and
file loader can be used in workers
because it uses XML HTTP requests under
the hood so we can just wrap that but
that's not enough we also need to
produce an image so here we use create
image bitmap and once we get our image
bitmap object back we send that to the
onload handler and the onload expects to
receive an HTML image element but we're
tricking it we're giving it an image
bitmap instead and of course this
happens to just work because if we're
using the image for a texture upload
well the the OpenGL Tex image 2d call
doesn't care if what you're giving it is
an HTML image element or an image bitmap
so we can just make this substitution
and it works now if you're making a game
engine you're probably thinking well to
get everything working in a worker also
need input events and there are no input
events and we're
so how do I get those mouse clicks and
keyboard actions going well the solution
is to forward events but this is not a
great solution it has a serious downside
because if you just have your event
listeners on the main thread when they
receive input events they post message
them to the worker where they can be
used well if your main thread is busy
you'll be introducing input latency so
this is still not ideal it's an unsolved
problem but we're determined to make
this better in the future this is like a
future next step for this this class of
solution now let's look into some other
uses of off-screen canvas background
rendering this is an interesting one
people are already doing background
rendering today this is for example
situations where you have a game where
it needs to do some asset preparation on
the client side
for example maybe you're rendering text
labels that you're going to be using as
textures if you're doing a lot of this
work you're probably doing it with
today's technology using an HTML canvas
element that is not attached to the Dom
that way it's all hidden
it doesn't appear on screen just doing
your stuff but we can do a little bit
better we could move that work over to a
worker that way you can batch all of
your background rendering you don't need
to to worry about dividing it into small
chunks so that your UI can remain
interactive or anything like that and
this is how you do it so in your worker
you create an off-screen canvas but this
time we're creating it directly using
the constructor without a place folder
and when we're done doing our background
rendering we want to capture the results
to send them back to the main thread so
that capture can be done using this this
method called transfers the image bitmap
this as the name implies this is a
transfer that means we're not making a
copy which is tearing off the pixel
buffer that the that the canvas rendered
to and because we're just tearing it off
this is basically just copying a pointer
well what this means is it's going to be
faster because there's no copy and it's
going to be leaner in memory because we
don't have duplicate copies of the same
of the same image in round and and
that's really going to help with memory
bloat and for sending the rendered
results back to the main thread or maybe
we're sending it back to another worker
if that's where your rendering loop is
well we're using transfer semantics
there too and this is just important
it's important to note that image bitmap
is transferable but it's also cloneable
so if you if you don't specify that last
that second argument there to post the
post message it's still going to work
but it's going to be slower so remember
to do this if you don't if you don't
mind what the transfer implies you know
that you can no longer use that image
object in the current context and you'll
get some good performance games so just
so you all know we've been getting
feedback from app developers telling us
that it's really hard to write
applications that do image manipulation
and that work on mobile the second you
try to use a high resolution image like
for example a picture from a DSLR camera
it's really easy to start running out of
memory and this is due to all the
multiple copies of the same image data
that we end up with in memory just
because of how the current api's are
designed so we're really trying to move
towards zero copy interfaces and that's
what these transfer semantics are about
this should really help with imaging
apps and going forward we're going to
continue to provide new zero copy API s
another use case for off-screen canvas
multi-view rendering with WebGL so
imagine a CAD software or a 3d modeling
software or animation or something like
that where you have multiple views of
the object like what we see here on
screen well when we're rendering
multiple WebGL views that use the same
resources so the same vertex buffers the
same textures the same shaders it's
useful to share resources between these
views now WebGL does not allow resource
sharing between different canvases it's
just designed that way so the solution
that most people are using is to have a
single canvas that's in the background
that we're going to use for rendering
all the views and one of you is ready we
just copy it to the presentation canvas
so this can already be done today using
an HTML canvas element that's in the
background you know that's not attached
to the Dom but we can make it a lot more
efficient by using transfer semantics
this is how it works
so the background canvas we can use
transferred image bitmap so that's a
zero copy operation and to present it we
can use this new type of rendering
context that's called bitmap renderer
the bitmap render context is a very
simple canvas rendering context that has
only one method in its API and it's
transferred from image bitmap so that
again is a zero copy method because the
alternative would be to just use a dry
image to a 2d canvas and then you're
paying the cost of compositing and and
you have an extra buffer in memory
and this is yet another use for our
screen canvases web PR this is still a
work in progress we're not sure exactly
what this API is going to look like in
the end but you know it's being
discussed right now and what we do know
is we do want to get web VR to run in a
worker because we're looking for that
advantage of having the you know the an
execution context that's isolated from
the rest of the browser so we can go can
hit that 90 frames per second or 75
frames per second on desktop and and
also just in general we want to be able
to squeeze more content to get those
rich user experiences and the worker can
help with that so finally if you want to
try off-screen canvas
well we recommend trying it in chrome 60
it is there in earlier versions of
chrome but it's not quite ready for
consumption chrome 60 it's starting to
look pretty good so you can get it for
Android on the planes on the Play Store
just search for Chrome Canary you can
also find it on the web to download it
on to your favorite desktop platform and
you can install this alongside an
existing chrome installation so it's
perfect if you just want to test it in a
sandbox and once you have chrome 60 well
you have to turn on the experiment so
you navigate the chrome flags and then
you find this item called experimental
canvas feature click enable and restart
the browser and you're good to go now if
you're interested in following the
developments with off-screen canvas
here's a link to the bug just follow
that link and there's a little star in
the corner you click that star and
you'll get email updates so you'll know
you know what's going on if it's ready
to ship what are the outstanding bugs
that sort of thing and if you do try it
out please provide feedback if you find
issues with it
submit bugs on CR bug comm you go there
and not just about off-screen canvas by
the way please web developers help us
help you go submit bugs help make chrome
better and this is the last slide let's
just summarize what we've learned today
so please yeah I see a few people with
their cameras there this is the one
slide you want to take home with you
we learned that you can get smooth
asynchronous decodes with image bitmap
reduce your rendering overhead using
off-screen canvas isolate your rendering
in a worker to improve your smoothness
improve your throughput and reduce your
memory bloat by using transfer semantics
and we saw examples of use cases where
transfer semantics come in handy like
background rendering and multi-view
WebGL so that's it thank you for
listening and I'm looking forward to
seeing what you're all going to make
with these api's</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>