<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Production PWAs with frameworks (Chrome Dev Summit 2016) | Coder Coacher - Coaching Coders</title><meta content="Production PWAs with frameworks (Chrome Dev Summit 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Production PWAs with frameworks (Chrome Dev Summit 2016)</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/e8XejNt5SZo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">that was worth the our words took to
render so in many ways polymer has been
a sort of Tesla vehicle for the chrome
team highlighting one path for how you
can shoot fast high-performance
progressive web apps to work really
really well on mobile but we work in a
really diverse community like everyone
is using different tax tax and today we
wanted to talk a little bit about how
you can use other libraries and
frameworks like react to build you know
fast progressive web apps and looking at
you know what what do you need to do in
order to make things like react qualify
to build instant experiences on real
devices Flipkart are gonna get up right
after me so to talk a little bit about
their experience shipping react pw raise
and scale and all of the lessons that
they learned and we have a little
surprise for you at the tail end of this
talk that uh you'll see you know for a
while so let's start off with the
statement frameworks can be fast if we
put the work in I firmly believe that I
think that we're at a point where you
know fast is not the default for a lot
of libraries and frameworks I think that
a lot of them a lot of framework authors
acknowledge that you know we can do
better when it comes to performance on
real-world devices but let's take a look
at what's possible today so this is
Flipkart on a real device they're doing
really really well they're interactive
in just a few seconds they're shipping
just the minimal functional code to get
area you need to get a route interactive
very very quickly they're deferring a
lot of the work that's not needed for
this route to a future point in time and
they're taking advantage of techniques
like code splitting in purple in order
to accomplish this housing calm or
similarly doing really great work in
this area again they're interactive in
just a few seconds but we talk a lot
about speed and and what it needs to be
fast at CD f's what what do we actually
mean by fast so there are a few key
moments when it comes to modern loading
performance and some of these metrics
are things you might be familiar with so
the idea of first paying first
meaningful paint but really there are
three phases here there's the is
happening moment
is it useful and is it usable now we're
increasingly trying to focus on the is
it useable phase so time to interactive
so at one point during loading is your
app actually engaged by the user if they
tap on different things inside the app
can they actually accomplish things that
are useful to them and time to
interactive is really it's the point
when I can stop and I can get something
something useful now we're saying that
ideally you know if you're with
regardless of what it is that you're
using to build these apps it'd be great
to be interactive in under five seconds
on a real device under real
representative network conditions so 3G
if you happen to be using serviceworker
caching you're gonna benefit from sort
of flying to I do we hit an instant
repeat load and your time to
interactivity is going to be even better
in those cases so serviceworker cache
and definitely worth looking at in this
case there's actually nothing on this
person's phone screen and i think
they're going through withdrawal of some
sort here so lighthouse has been
mentioned Darrin mentioned in his
keynote Lighthouse is currently one of
the best ways to easily track things
like time to interactivity it includes a
number of different performance metrics
this is a lighthouse extension it's also
available as a CLI but time takes for
actives is included inside the
performance audits
I mean if you want to take a look at how
well you're doing what I recommend is
trying out lighthouse over remote
debugging you know testing it with a
real phone I'll give you sort of an
eye-opening look at your performance on
real world devices so that's definitely
worth spending some time on so recently
I was very curious about how the react
community were shipping down code how
they're tackling things like module
bundling so I put out this call on
Twitter asking people you know how do
you ship react in production and what
were your experiences doing that and
then published a little bit of the data
on that but let's dive into it so what
JavaScript module bundler do you use the
majority of people are using webpack
this breaks down into sort of 65% of
people who are using webpack one a
smaller number using webpack - but those
numbers are increasing and
rest of these numbers are sort of
browserify and other bits and pieces so
what pack is kind of a big deal let's
let's take that from from this
particular slide I then asked people if
they were using code splitting to check
out their JavaScript and I got a very
surprising answer I saw that 58% of
people thought that they were now this
surprised me because when I talked to
like the web pack community when I talk
to the web pack authors they're like we
don't think that any more than like 10%
of people are really using code
splitting and there's something
interesting there maybe there's a
breakdown in terminology maybe people
who are using code splitting but not
necessarily doing it the right way and I
don't kind of blame them because
configuring web pack is so fun it's the
best but I think that we have
opportunity to improve that other
concepts that people were looking at so
11 percent of respondents said that they
were exploring serviceworker support so
that's good love to see more people
doing that 14 percent we're looking at
HP - and what I mean what would be
involved and sort of granularly shipping
stuff down and 19 percent we're looking
at tree-shaking so interesting stats now
we mentioned the polymer shop demo quite
a lot and the reason for that is it's
using purple it does really really well
on real world devices under 3G so on
throttle 3G this app is interactive in
about 4.3 seconds about four seconds um
if you're if you're looking at it with
like a really really bad 3G networks or
something with with more packet loss
it's still doing pretty good five point
eight seconds we take a look at Flipkart
in housing comm next and Flipkart
is in you know between these two apps I
did the averages and they're getting
interactive in about 4.5 seconds is
still fairly fast fairly good about 6.9
you know with packet loss but they're
still doing pretty well so these guys
are using basically all the tooling all
the performance best practices that
we're encouraging folks to take a look
at to shift these experiences down in
ways that are you know ideally benefit
their users at the end of the day so
here's the crux of the study I ended up
profiling over 150 react ops that people
submitted over the last couple of weeks
Brida the numbers quite a lot of times
fun so fun unreal devices and what I
discovered was that the average react up
in that survey was interactive in about
11 seconds so there's quite a gap there
between what's possible and where the
average app is right now with packet
loss we're looking at 12 seconds the
probably the worst app in that
particular study was interactive in 24
seconds so the user is going to be an
uncanny valley just by tapping around
the screen and not really seeing
anything happening so this is sort of a
timeline trace of what the average react
app built with web pack looks like in
this case I saw you know hundreds of
kilobytes of script being shipped down
just for a single route a lot of it
wasn't being used they are using code
splitting but they're actually you know
it's taking 8 seconds before all the
script and their common chunks are being
shipped down thousands of seconds are
being spent in parse and eval time and
for anyone that sort of followed Paul
Lewis and Paul Irish is guidance over
the last couple of years about you know
trying to ship a frame in sixteen point
six milliseconds well these guys have
got a frame the last seven thousand nine
hundred and seventy three so doing
really great they're great we can do
better
so first piece of advice is try not to
keep the main thread busy if you are
someone that's shipping down really
large bundles of JavaScript it's gonna
take longer to load parse execute and
run it's definitely gonna peg the main
thread
now this advice comes with nuance and
nuance is something we often lack in
these conversations it's really tricky
to pack it into a short amount of time
but basically if you're working on a
page that it's not going to be useful to
your user in any way unless you ship
that amount of script you're probably
better off shipping it if you can
however trim that down so that you're
just shipping the minimal functional
stuff that's going to be useful to your
users please consider doing that it's
going to help them out because they're
not going to need your shipping like all
of this group for the entire site or the
entire wrap in one go other things that
can impact through the main thread being
busy and time center activity or sort of
suboptimal back and forth between the
client and the server sam Saucony
touched a little bit on the idea of
JavaScript parse compile and eval
execution times being a little bit
different between desktop devices and
here we have a mega script about 250
kilobytes minified and the amount of
time it takes to parse and compile it on
what a lot of us I see a lot of MacBooks
in the room this is how long it takes to
sort of parse and execute that on a
MacBook Pro from 2015 and take a look at
the difference
like how much our assumptions are broken
when it comes to the average phone
something like a moto G this is taking
about three seconds
to parse compile and execute and that's
not even looking at load time like if
you're trying to get interactive in
under five seconds this is just not
going to cut it but all of this again
it's got nuance you need to make sure
that you're you're measuring before
you're optimizing but you're ideally
trying to make sure you're doing the
right thing for users test on real
phones and real networks this is
something that we've mentioned in a few
talks at chrome dev summit I cannot
stress enough how important it is to
test on real devices emulation is only
gonna get you so far you can be testing
with you know 3G throttling on with CPU
throttling on on desktop and the
difference between that and the stats
you get out of a real phone are still
going to be multiple seconds I think
there are opportunities there for us to
do better at its ruling level but you
know real devices have got different
mixes of cores GPU memory there's going
to be packet level differences for
different networks so do try to make
Chrome inspect your best friends and use
it so when when Alex Russell you know
carries around all these phones he's not
crazy mobile web speeds do kind of
matter in fact you know on average
faster experiences tend to lead to
longer sessions and one of the I think I
was perhaps the double clicks or the
double quick report that recently
published said that you know people that
did optimize performance we're seeing
anywhere up to two times mobile ad
revenue so test on real devices make
real money
let's let's riff on this other idea so
less code loaded better helps everyone
this is another one of those items that
requires nuance but if you're able to
load less code up for a route in order
to get it useful please do so the nuance
part comes again from that part of you
you may require more script me shipping
down 300 kilobytes of script may be very
different to someone else doing it
there's gonna be different parse and
evolve times at play there so again very
important to measure but let's let's
refine this idea of less code load it
better we're gonna use webpack a lot of
you may be familiar with what web pack
is for anyone that hasn't used it before
it's basically a popular JavaScript
module bundler attacks lots of modules
into smaller bundles so you can shoot
them down to users and so we're gonna
look at some of these ideas around the
purple pattern and how you can serve
these things down to your users
the first one is code splitting so I've
been talking about trying to ship the
minimal code down to your users I'm Co
splitting is sort of one answer to this
problem of serving people monolithic
bundles it's the idea that by defining
split points in your code from sort of
view to view for example a route to
route you can split them into different
files that get lazy loaded on demand
that can improve your start up time and
help you you know to getting interactive
much much quicker now with web pack
there are two ways of doing this but
actually there are quite a few ways
they're not just two ways with web pack
one you can use require that ensure in
order to do that web pack is going to
take a look at any where you're using
require ensure and create sort of a for
you based on that that's how you define
a split point and web pack two they
currently use system dot import from the
loader spec in order to accomplish the
same thing
I do believe web pack are also sort of
they're a little bit future facing
looking at what else is happening in the
loading space but basically these are
these are two ways to do code splitting
they're great articles that cover this
in more and more depth there are other
ways that you can do code splitting as
well the bundle loader is another option
if you don't like the pattern that you
just saw on screen you can actually use
bundle loader and prefix the things that
you want to require in to your page and
it will automatically wrap those things
into a require that ensure
were you and take care of the rest it's
also possible to sort of wait for that
chunk is synchronously before you do
anything with the code and finally if
you happen to be using react router it's
actually got really great support for
working with required uninsured so this
is a declarative option it's also got a
slightly more imperative one but
basically when I'm defining routes here
I'm able to use an ax synchronous get
component and inside there I can say
well go and please get me the user
profile view and then I can go and do
stuff with it so it doesn't necessarily
need to be included in a big monolithic
bundle up front the next thing is the
purple pattern so Sam talked about the
purple pattern yesterday it's basically
a pattern for structuring and serving
progressive web apps with an emphasis
it's got a lot of emphasis on performant
app delivery maybe looking at the ideas
of how you can more granularly do things
that are route level but it focuses very
heavily on giving you a minimum time to
interactive so the idea here is push the
minimal functional code for a route
render that route precache the remaining
routes and lazy load routes on demand as
needed again lots of nuance here but we
do have a guide on that you can go and
check out now with web pack it's
possible to do something a lot like
purple using required on insurer or
system dot import with an async get
component react router and there are a
few different options here so Sam talked
a little bit about the differences
between preload or h2 push so let's
unpack some of the ideas there so link
rel preload if you haven't used to vote
for words basically a declarative fetch
directive in human terms it's a way to
tell the browser to start fetching a
certain resource because you as an
author knows that you're probably going
to need it some people have done really
interesting experiments here where
they've used you know stuff like their
Google Analytics to decide you know what
routes should get pre-loaded based on
the navigation path of a user but with
web pack you can use things like a set
web pack plug-in in order to wire up
chunks that are generated at build time
up to your markup there's more you can
read up about link rel preload I believe
housing may have mentioned some of their
experience with preload earlier today as
well if you're exploring hb2 there's a
really violently named plugin called you
know it's aggressive splitting
why it was called that but this is
another option for basically going a
little bit more granular with the trunks
that you're shipping down to users
nuance again different JavaScript
engines might treat the way that you
split things up differently they're
going to be cases where in fact shipping
a larger chunk will just mean that it's
able to stream that javascript in and
parse and compile it a little bit faster
than you you know going and fetching yet
another chunk so know that this exists
try it out if you if you're interested
in the idea of haitch to with web pack
but nuance once again now another piece
of interesting data that came back from
my research is that code splitting
itself does not solve everything in fact
um I just focused on the apps where
people self-identified as saying they
were code splitting what I found was
that they were interactive in 9.8
seconds so definitely not where we
thought they would be right we expected
them to be a little bit closer to those
Flipkart in-housing not calm numbers
what I discovered after profiling them
in slightly more depth was that a lot of
folks were shipping down chunks for a
route that were 600 700 800 kilobytes of
script in some cases 1.2 Meg's of script
and then they were lazy loading even
more right after the fact for some crazy
reason but this is something you know I
don't entirely blame people for it
because our current tooling doesn't do
an amazing job of highlighting these
issues it doesn't really put performance
in your face so ask yourself what's in
your bundle I think it's very very easy
for us these days to npm install the
entire world it's very easy to include
more modules than we necessarily need
when we're shipping down code for routes
but I thought that maybe it would be
interesting for us to see what we could
do about this at a webpack level so I
put together an RFC for an idea I call
web pack performance budgets or web pack
performance insights and Shawn Larkin
who's in the audience over there has
actually been helping me with this and I
thought that would be interesting to
give you guys a preview of what we think
could be a better way of highlighting
some of these performance issues earlier
on in your development process so here
is what the output you'd normally get
with web pack looks like today I've got
a build here where I've got you know
I've got
most to Meg's of scripting in two of
these and to these bundles and I have as
a user if I'm not really that familiar
with web performance I don't know that
there's an issue here that I need to
solve it should be obvious and these
numbers are quite large on purpose but
it should be something that you know
maybe web pack could could tell me I
have an issue so we looked at
implementing a proposal that I put
together and this is what it looks like
so you go on run web pack on your
project and it includes this output for
you let's let's try to unbundle some of
the ideas that are here so the first
thing it does is it tells you if you
have particularly large chunks in your
bundle so you'll see at the very top
instead of just listing all of our
different JavaScript output in green
it's highlighted in yellow chunks that
are particularly large and cross a
specific performance budget that's
defined by web pack as default if it
notices that you're doing that so in
this case I've actually customized this
a little bit and said that the maximum
size for chunks is 100 kilobytes it's
going to tell you you know it's gonna
warn you say this is an issue
it also can highlight large entries so
trying to look at you know defining what
budget are you crossing for an entire
route or an entire review because you
might easily have multiple chunks that
can pose something and you don't want to
be one of those people shipping down a
mega script if you don't need to so
large entry tracking is going to help
you with that and finally at the moment
in this proof of concept that we've got
we also highlight patterns so if we see
somewhere where you think but we think
you're gonna benefit from doing
something like using code splitting
using require done ensure or system dot
import will tell you about it now again
this is this is a very early proof of
concept we've just been hacking on and
over the last couple of days but I think
that we have an opportunity to work
together with tooling vendors like web
pack to try solving some of these
performance issues together in a
meaningful way that will hopefully end
up giving users better time to
interactivity scores so something you
might also be wondering once again it is
you know can I kind of configure this
stuff and yes you absolutely can using
the performance object you can actually
set the maximum asset size the maximum
initial chunk size and turn on or off
the idea of getting those hints there's
a preview available today you
go and check out at this point we're you
know that all the UX you've seen you
might you might think that that's a
really long report in your CLI but we'd
welcome people to try out you know the
proof of concept we've got today and let
us know if it helps let us know if
you've got any feedback on the UX at all
I think that this is just the beginning
so size alone is just one aspect when it
comes to script loading performance
there's also things like you know parse
eval times execution times and so on
there are interesting opportunities for
us to use this as a baseline for
building up more tooling that then
benefits all web pack users
I'd love to explore at some point in the
future what things like code coverage
could even could even mean for these
experiences so that's the first preview
please go check it out and let us know
what you think now another thing I
wanted to recommend is there's gonna be
a point where you're optimizing your
progressive web app and you're gonna hit
a point where you can't optimize the
size of react down any further and
something that I found is actually
really great for just swapping in is
pre-act
which is a much smaller it's almost a
three kilobyte alternative to react with
the same es6 api I believe Jason Miller
who worked on pre-act is in the audience
so thank you Jason and a lot of the
traces that I've done of free act apps
are showing them like this is again on a
real device with a real network they're
interactive in under five seconds I was
taking a look so this is a source map
Explorer it's a sort of a nice a little
bit like the bundle analyzer tools that
Sam was showing in his talk this gives
you something very similar this is what
my dependency graph looks like when I
have react in place on the very right so
lots of stuff going on when I switched
over to using pre-ops and react compact
has changed quite significantly this is
with almost the same API like I I did
run into one or two bugs I will say that
and Jason kindly fix them very very
quickly but this is definitely something
that I consider you know if you're
running into you know places where you
you tried optimizing your app down
you're still finding a ball in that
react is definitely worth checking out
I'm especially if you care about your
time central activity being small
setting this up with webpack is actually
quite trivial you can use resolve
aliases to map react to compact
compact2 definitely we're checking out
now in previous years jake has talked a
lot about offline and the benefits that
you get from instant loading using
serviceworker and I'd like us to
consider layering our apps so the
network is an enhancement a little bit
more when you do this you're able to
actually give your users those almost
instant experiences on repeat visit and
you just you know you crush your times
interactivity in this case this is
housing calm on first visit on a 3G
network on a real phone they're getting
you know they're getting content on the
screen in 3.5 seconds on repeat visit
it's almost instant it's in under a
second and the amount of script and
everything that they were trying to load
up initially is no longer an issue
that's already cached using the
serviceworker cache API and they're able
to get interactive really quickly so
definitely something we're taking a look
at a lot of the time when we talk about
progressive Web Apps we talked about the
application shell model which is this
idea of caching your shell and loading
in content using javascript there are
many different variations with this
pattern this isn't the only one but if
you're trying to get serviceworker
caching in place I highly recommend the
sw-precache webpack plugin this will
integrate with your web pack build
process it'll generate a serviceworker
that pre caches your static assets like
your application shell and it just
generates a hash of all your file
contents as well there's a lot of best
practices for you out of the box we're
checking out if you know if you've tried
vanilla service workers found that
there's a little bit of boilerplate
there and you like it so it just helps
you with the rest of your workflow Jeff
is gonna talk a little bit more about
sw-precache NSW toolbox and his talk now
another thing that lighthouse tries to
highlight is progressive enhancement and
I think that this is one of those this
is one of those super contentious topics
luckily I'm on stage so I can't look at
Twitter in any shape or form
to see people's opinions on PE but I do
like this idea of supporting all your
target users using progressive
enhancement and trying to target all the
people that are in your market so the
your app at least works for them I think
that progressive enhancement as a sort
of evolved over the last few years as
we've gotten support for better
primitives like service worker so that
you know instead of necessarily
optimizing for people that have
JavaScript disabled you're optimizing
for network resilience so you know if
you're using patterns like purple and
again purple isn't you know the solution
to everything if you're using patterns
like purple you can end up shipping so
so little code to users to get them
useful that you know maybe things like
server-side rendering aren't necessarily
as beneficial in those places or as
necessary in those places that you might
need them to be
however as Flipkart are going to talk
about a little bit later there are still
benefits to things like server-side
rendering for SEO bots and there are
places where you might need to get
content on the screen quicker for those
cases react supports this idea of sort
of server-side rendering or Universal
JavaScript rendering it also has a
really good story around things like
universal data flow and data fetching so
we got provides you this this method
called rendered a string for rendering
markup on the server as part of its
story around Universal JavaScript and
it's this idea of like you ship down
your HTML you then hydrate as soon as
react and all the rest of your
components have loaded up attaching
event listeners and so on so that the
person can actually interact with the
app so react has got a good story around
this this stuff is actually not too
difficult to get set up as demonstrated
by folks like Celia who are using
server-side rendering with react however
Universal JavaScript has got issues I
don't think that this is something
that's talked about enough in the
community I think it's something that we
can probably share more data on
definitely it's very very easy to get
stuck in uncanny valley when your
server-side rendering where your users
in a place where they're able to see
content they can tap around it but they
can't actually really do anything
because they're still waiting on the
rest of your JavaScript chunks and your
modules and so on to load up in order to
attach those event handlers render to
string has also got no issues around
being synchronous so it can affect
things like your time to first byte
streaming service I've rendered react
can actually help here and I'd recommend
checking out projects like react Dom
stream we're interesting can also
monopolize the CPU and and waste
resources when it comes to rendering
components component memoization can
help there so take a look at things like
react SSR optimization another project
that tries to help with this stuff but
you know don't don't
things like universal JavaScript or
server-side rendering with react is like
you know a given solution that's gonna
be fast it's very very important once
again consider there will be nuance here
and it's important to measure if you'd
like to learn more about any of the
stuff that I've been talking about I
recently published a series of articles
called
progressive web apps with react and you
can go and check those out but I'd like
to invite to the stage
Ivanov who's going to talk about
Flipkart's experience shipping
production progressive web apps with
react at scale thanks Eddie
so I'm open up Rastogi I'm a developer
on the web team that built flipkart.com
I spent most of 2015 working on Flipkart
light or cutting-edge mobile progressive
web app that some of you may have heard
about in recent times and this year I've
been working mostly leading the team of
bringing that PWA goodness to the
desktop side so Flipkart let me
introduce you to it
Flipkart is the largest e-commerce site
and a first-class it's a largest
e-commerce site in India and a
first-class progressive web app across
all form factors and browsers and by
that I mean across mobile and desktop
we've got the opportunity to showcase a
new mobile website at CES chrome dev
summit last year and this is what it
looks like now on the side and ifs which
are virtually indistinguishable from our
native app both feature and design voice
so alex tweeted this today morning that
for all of us coming from desktop to
mobile a change in outlook is crucial
Mobile is much less forgiving and I
wholeheartedly agree with this luckily
for us we were going from mobile to
desktop so we carry the learnings along
and this is what our test website looks
like now so let me go over quickly the
kind of technologies that we are using
to build this at a very high level we
are using a combination of react react
router flux respectively and a pack to
bundle all together along with a bunch
of other technologies that help us build
this
and sort of packet together so that
includes like es6 and later JavaScript
technologies fetch promises and note on
the back end so let me talk a bit about
the architecture at a very high level of
both mobile and desktop sites for us
have a very similar architecture let's
see what that is
and we use round base close code
splitting on both we have a smartp
loading of chunks and we implement the
concept of purple which we have heard
about we have partial server-side
rendering and a concept of build time
rendering on each and we have obviously
service workers for caching different
kind of resources but an important thing
to keep in mind is that the
implementations for us are different
based on the requirements there are
significant differences on how you treat
how you need to treat mobile and desktop
users the requirements are different the
user behaviors are definitely different
the attention spans are different
network conditions are definitely
different or your mobile will har can
have a flaky network 2g or 3G desktops
tend to have a more stable and a faster
connection device capabilities are very
different as Alex mentioned yesterday
and browser fragmentation of course and
distribution for example in India the
browser distribution on mobile is such
that you see browser takes a fair chunk
of the pie of majority chunk but on
desktop it's the latest version of
Chrome which takes the majority chunk so
how you treat development in which one
you target first any I'd like you know
pre you have to take the least common
denominator you solve for the one which
is probably going to cause the most
problems and you build up on top of that
supporting more and more features
creating things like network and you
know excess CPU things like that as a
progressive enhancement so let us look
at the difference is an implementation
like I pointed out on the mobile site we
have a concept of base time rendering
which essentially means that we build
the app shells out of our code and we
create static HTML files which we serve
to the user when we get a request so
there is no request time processing
needed it's a simple file if we have a
serviceworker in place which caches that
shell
obviously after that it can work offline
first and for a mobile site it's a
composition of multiple single page apps
which I will talk about in a bit on the
other side on the desktop we have
partial server-side rendering that means
we try to optimize what content needs to
be rendered on the server we don't have
a concept of build time rendering and we
don't have a concept of apps shells now
the reason for this is simply users
requirement in the user experience I
feel and that's what we feel at Flipkart
that the user experience of an app shell
can work really well on a mobile device
where you can show a header or footer
and a loader maybe and some content but
on a desktop showing just a header and a
loader still leaves you with a pretty
big blank page it's not a very good
experience so therefore we went for a
partials of a side rendering approach
apart from that we have a chunked
response for a first request at the HTTP
response which allows us to achieve a
faster time to first paint I will
explain that in a bit
and we use server-side we use a service
workers for caching things like data and
resources like images and things like
that so here is the output from of a PAC
build web pack supports code splitting
out of the box like addy was just
mentioning and it figures out the split
points based on how you include your
components it also takes care of loading
the appropriate chunk when needed
example when it's not navigate the
benefit here is that you significantly
you have significantly reduce the amount
of JavaScript that you need to render
the first kind the first fold of your
page like for example whatever the
screenshot that I've put up here that
come the combined build that we had for
our website at some point of time was
around 206 kilobytes with code splitting
based on routes we were able to split it
for example home page only needed 32
kilobytes of JavaScript to render and
similarly other pages needed anything
from 7 kilo bytes to 100 kilobytes this
really helps a lot but there is an
important caveat here as I said web pack
loads the out of the box where people
try to load these files on navigation
when the route changes it figures out ok
this route is this JavaScript is not
present and it has a map somewhere which
tells it ok load this javascript file
which means it is downloading eval
and parsing that JavaScript after you
have clicked on a link which is a very
bad user experience so to solve that
purple comes to the rescue
implementing these concepts of chunking
streaming and code splitting you get a
picture which looks like this the first
one at the top is what you see before
all these improvements for us so you
have got your HTML passing in blue at
the top and all your static resources
and JavaScript CSS starts loading when
the HTML sparse and you get a render
time of around 2,500 milliseconds and a
copy is completed on that dom completed
around 3,500 with these optimizations in
place you get a first print of around 1
million of one second with you know your
resource is loading in parallel to the
powers of your HTML this is achieved
using things like preload script f4 and
similar things but as this only is also
for Spain what about time to interactive
and meaningful content so we think that
your interact content doesn't need to be
rendered together for it to be
meaningful for example what we do is we
are first paint our first render that we
put on this user's page contains the
search box and it's it functions without
any JavaScript which means that the user
is able to interact with the plain HTML
that we serve to him which gets rendered
even before any JavaScript has started
downloading since most of our users a
lot of our users start their journey by
searching and not just navigating and
you know looking for products on that
page this really helps us a lot
so some major wins for us that we have
seen when we did this migration this
adoption of you know progressive web app
concepts on desktop and mobile both is
that route based code splitting
Amata is is the high cost that you have
of single page apps and frameworks over
this session of the user you don't note
all the JavaScript up front you load it
across the session
similarly smart pre loading of those
chunks and using purple concepts makes
the experience seamless user doesn't
have to wait after clicking on a link
for the JavaScript to load
thirdly chunked encoding allows us to
download Jess chance while HTML is still
being parsed an interesting approach we
took was that based on the user
requirements that we figured made sense
for users in India we solved for repeat
visits on mobile specifically and for
first visit on desktop of course we care
about both on both the platforms but you
we decided to focus on one over the
other let me talk about the impact now
so up to 2x conversion during sale
events after we migrated to these
because of the high speed and
reliability and the benefits we have
talked about a progressive web apps we
have a significantly reduced bounce rate
interestingly you know a lot of people
have seen concerns around search engine
optimization you know how what how will
the crawler crawl the website what's the
impact on SEO after doing all this we
have seen a 50% reduction in time taken
by the search in the search engines to
crawl a page and a 50% increase in the
number of pages that are crawled by
Google search that's significant
improvement apart from that we have also
seen a massive 70% reduction in the
tickets that are raised the issues that
we get on the website there are less
errors in general plus it's much easier
and faster to develop and it's more
developer-friendly to mike to get new
developers on board fix those errors for
us to maintain of course there are a
bunch of gotchas where pack has been a
super useful tool for us that's what we
use as I mentioned and it's
documentation is going through some very
well-deserved improvements so working
with P appears and code splitting you
are bound to run into a bunch of you
know interesting issues and Peppa does
provide a lot of help to solve them but
some of it is buried really deep in the
documentation you have to really search
for it and mostly you find the answer on
Stack Overflow before you find it in the
docs
so the first issue we ran into was
cross-origin resource sharing and load
based course splitting so an interesting
thing that happens is which might be
true for a lot of us here javis
referrals and static assets generally
are served from a CDN which is on a
different origin as compared to your
website now when you do a link preload
you can tell it to load it as a script
and you can tell it to load it from a
different origin cross origin anonymous
and similarly when you anyway so you can
define that it's loading as a cross
origin resource but when web pack tries
to load script like we mentioned or
based on the chance when it sees it
needs a new JavaScript it will by
default not load it as a crossorigin
script and your browser may end up
blocking it which caused us quite a lot
of headaches so interestingly it does
provide a attribute or you know a
conflict that you can specify which
makes web at load those chunks as a
crossorigin script it takes care of that
internally the second one was as we know
a cache invalidation is a very big
problem apart from naming variables that
when you create chunk right and usually
for long term caching purposes the name
of the chunk the file name usually will
contain the hash right that's how you
determine whether this file is a new
version of and like if the content is
new so now what happens is that when
webpack creates these chunks it needs to
maintain a lookup table that in your
entry chunk which is loaded at your page
load it needs to know that when this
route is opened this is that I was to
finally it needs to download now that
URL that file is going to change at some
point of time so for example you have
route based chunks like I mentioned
before you have these 15 routes on your
website and you have those 15 JavaScript
files correspondingly as each
file is suppose one of them changes as
suppose you make change on one like a
product details page
ideally only that one JavaScript file
that chunk should get invalidated in the
cash only that should be needed for the
user to download again others should
still be served from serviceworker or
you know the HTTP cache what happens is
because that chunk has changed it's
finally must change the manifest in the
lookup table in the web packs entry
chance will also change which means an
entry chunk will change between the user
ends up downloading extra JavaScript
which has not actually changed so for
that over PI provides a thing called the
web pack manifest it's pretty simple in
the common strength plug-in you just
define the name for the manifest and you
end up with a separate file like 500
bytes or something which will just have
that lookup table and all your other
your entry chunk becomes independent of
the content of your other chunks so it's
these kind of small things which you
know we ran into and a lot of you may
run into when you are implementing these
kind of things so what's next for us at
Flipkart is making things faster so we
are looking into things like HTTP 2 for
enabling push of these resources smartly
we are also working on amp to make the
first visit faster so that's all from my
site you can reach out to me on this
Twitter handle or my team at Flipkart
and discotheque
to be here thank you
I've got one more thing so I'd like to
tell you a quick story I don't have a
lot of time but I'd like to tell you a
quick story about a small group of us
Scots to write some code for NASA so a
while back a few years ago nASA released
a master list of software projects
they've cooked up over the last couple
of years this is more stuff than you
just run on your personal computer it's
like apps that would help with robotics
and cryogenic systems and space
simulations and all sorts of things and
they have these in a bunch of different
places
github get labs source for it was all
over the place but this is part of like
the government initiative to try open
sourcing more stuff and it was kind of
neat to see so off the back of that nASA
released a site called code nasa.gov
that looks a little bit like this the
idea here was that at any time you come
to this site and you could take a look
at you know what what NASA engineers
were hacking on in the open just kind of
cool but I discovered this on Hacker
News one day and my friend Sam Saucony
also discovered it around the same time
and we tried looking at this on a real
device and it basically crashed my phone
what happened was we ended up you know
profiling this a little bit and there
were a number of interesting quirks with
this particular implementation
I can't kept the main thread pecked for
quite a long time in fact we we ended up
working on a number of performance
audits there's actually a performance
audit I'll be publishing shortly on this
whole thing but we ended up trying to
make this this existing implementation
as fast as we could we this was a sort
of an angular 1 app and at that time you
know that framework wasn't really built
with real mobile devices in mind at the
time and we ran into all these
interesting issues like digest cycles
taking up to a second this particular
app had 10,000 Watchers for some reason
they had they had like a github embed
for every single entry so they had like
3 or 400 projects listed on this page
and they had a github embed for every
single one so that you could go and fork
the project so that was like an
additional 3 or 400 Network requests
four walls they also have like a ton of
web fonts and other other interesting
issues here that I don't I don't think
is entirely you know the not atypical of
something that you know if you were new
to this stuff you probably run into some
of these these similar problems and so
we started optimizing this as much as we
could but we reached a point where you
know we thought this just isn't worth it
it's probably worth taking a look at
rewriting this thing and I know that
today I've been talking you know we've
been talking quite a lot about react and
pre-act and other libraries but I like
this idea of best practices being
automated I think that some of the ideas
we talked about today around purple and
code splitting and so on are things that
we can do a better job of building in by
default into today's tooling I'd love to
get to a point where things like create
react top and angular CLI and ember CLI
and so on next day ask whatever it is
that you happen to be using or
considering some of these approaches and
looking at where they can you know
provide real improvements to to
developers so we balance developer
experience with user experience so
polymer does this kind of well with the
polymer app so the box I consider it a
good reference for how to do this stuff
it's got you know Sam Sam and I think
Taylor mentioned some of the stuff so
it's got purple with code splitting
built in and lazy loading and offline
caching and support for HT server push
but you think the polymer app toolbox
allowed us to actually ship a completely
brand-new version of code NASA cough
this is NASA's very first progressive
web app that we deployed last night
thank you
I've got to give big props to Frankie
over on the polymer team and Keanu Hanna
Lee and all the folks that helped us get
this shipped but basically everything
here is faster here we were looking up
sort of you know as you would code for
the Apollo 11 mission from all those
years ago looking up ways in which you
know NASA would publish projects or even
share projects with other people all of
these views on a real mobile device
perform really well it's a massive
improvement from what they had before we
spend a lot of time on things like
making sure that the infinite scrolling
for their project list view was really
really fast so hitting 60 frames a
second and this experience works really
great on sort of desktop as well so the
experience there is again it's
responsive we can see the the list there
and actually being able to search things
really really quickly there's there's no
lag in place but all the views work just
as well they're just showing you a
slightly different look and feels this
thing but we profiled this using my
house on a real device with a real
network and this thing was interactive
in under four seconds so under 4,000
milliseconds we were really happy with
that because we actually spent in less
than a week redoing this site it's not a
complex site by any means but the idea
that you could you know completely throw
away an old codebase and try exploring
something like a purple pattern in such
a short amount of time with a very small
team was I thought kind of cool so we
really enjoyed hacking with NASA on that
site and I encourage you to contribute
to you know code that nasa.gov if you
know just being able to tell your mom
that you hacked on NASA code is kind of
neat so that's always an opportunity but
it's all open source this entire app is
an open source you can go and check it
out on NASA's github organization so
github.com slash NASA slash code - NASA
- gov I am certain we will get pull
requests from folks mentioning things
we've done wrong but I welcome all of
those so please feel free to you know
check that out and let us know if
there's anything we can improve in
closing I hope that you know some of the
ideas in this talk give us inspiration
to perf the web forwards together
because we're all in this together
I see browser vendors this being a good
place to tell you about the engine and
the performance targets we should be
hitting I say framework authors and
tooling vendors as being people that you
know ideally want to make sure that
developers are able to ship the right
experiences that benefit their users and
the experiences you're shooting for your
users so let's work together I would
love you know if you're if you're
working on any of this stuff please talk
to me please talk to us and let's move
things forward together thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>