<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Future App Model: Advanced Service Worker (Chrome Dev Summit 2016) | Coder Coacher - Coaching Coders</title><meta content="Future App Model: Advanced Service Worker (Chrome Dev Summit 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Future App Model: Advanced Service Worker (Chrome Dev Summit 2016)</b></h2><h5 class="post__date">2016-11-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/J2dOTKBoTL4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I realized that you're all probably
quite sick of me now I kind of been
around all day but um this is actually
only the second talk I've given a chrome
dev summit and the other one was the
very first chrome dev summit back in
2013 and it went a little bit like this
and the new thing is the serviceworker
actually I think this is the first talk
on it there's nothing to play with in
the browser yet so this was before
anyone had ever written a serviceworker
there was nothing in the browser at all
but now we have like two fully
independent implementations in Chrome
and Firefox and and that means we get
the other chromium browsers come along
for the ride you know things like opera
and Samsung internet and others
Microsoft they're working on their
implementation now it's a high priority
and bits and pieces are starting to land
in there insider builds as well
Safari still haven't made a public
commitments but they have been given
implementation feedback on the spec so
they've been looking at it in a lot of
detail and they've been implementing the
fetch API as well which is a big part of
it's a prerequisite if you are going to
implement serviceworkers but thanks for
the progressive enhancement we've gone
from having nothing in any browser to
hundreds of millions of page loads
handled by a serviceworker every day and
that's just in chrome and I'm not
talking about service workers I just
therefore like push messages and things
because there's loads more of those as
well I'm talking about service workers
that are actually handling fetch event
same page loads um so that means that
today which I couldn't back in 2013 I I
can stand here and talk about actual
shipped things because in 2013 I've
basically made stuff up for 30 minutes I
mean this slide in particular is a total
work of fiction it's great but I don't
know
look how happy I look they're not
wearing a suit thanks everyone
Oh to anyone who's watching this in the
video in the future they you know they
voted that I had to wear a suit for this
and it's horrible thank you everyone
anyway um but this talk I enjoyed this
talk it was a bit of a laugh so I'm
gonna do it again because a lot of stuff
we're starting to implement or starting
to think about in serviceworker land and
I'd like to share it and you know sort
of see what you think about it which
things you want in the browser right now
in which things you know not all that
bothered about I probably should have
called this talk 7 things that don't so
much is this right now but I'm pretty
excited about and you might be as well
it's going to be a journey to the future
that this is a real FAQ page for a train
company in Wales and it's just this one
question that says can I buy train
tickets for future travel to which their
answer is yes just now
I think to Wales before and it
definitely feels like time travel
maybe not forwards yeah so what if we
got coming up okay so we got streams I
love streams so and as the lava streams
already in the browser you know you can
fetch your URL just by you know just
fetch and wait it like we saw before get
a reader for the readable stream and
then you know we can sort of set up a an
infinite loop and we can call reader or
called read on the reader and this gives
us an object back which is very similar
to what iterate has returned there's two
properties it's done and value if done
is true we're done and otherwise we got
the value and and I think this code
could be nicer I always get very nervous
about kind of wild true code I mean this
works but I don't know it makes me
nervous and that brings me to the first
future feature that I want to talk about
async its arrays now I have learned from
my mistakes in in 2013 so this is this
is the vagueness graph and I'd say async
iterators are about this vague but do
bear in mind that this graph is itself
about this vague
and that's quite vague I hope that
clears everything up Xing Carrera is
there they're being specs right now
they're at stage free of the Ekman
script process so we can expect some
implementations pretty soon so how do
they actually work well instead of this
this while loop and getting a reader we
can just do this it's much simpler for
await value of stream and it works just
the same way that our while true loop
worked before and when these land in
JavaScript will start to see Dom API is
updated to use them in thinking about
things like the cache API you can have
an iterator to go over caches or over
items in caches as well I'd love to see
this added to index TV curses for you
know going through an entire dataset if
you want to know more about async
iterator is on the tc39 github page I
will tweet out all of the links I show
in the top but if you can't wait for
that you can play with them today using
Babel this is it running here in the
babble rebel I'm only showing you this
because I have an excuse to say babble
rebel which is very satisfying battle
rebel I I really really love the way we
name things in the industry we just
don't care I mean look at this this is a
totally legitimate sentence in our
industry
my tiny Yelp clone but with Redux is now
up on ember twittle my tiny Yelp clone
is now up on ember twittle I love it you
should have put it on Babel rebel and
completed the set so when you string
values from fetch each value is a you
into eight array of bytes but often you
don't want bites you want some of a
format like text and you can actually do
this today using the text decoder so I'm
going to get the new text decoder there
loop over the stream but this time I'm
going to pass every value through
decoder decode now instead of logging
bytes it's gonna log strings but having
to call the code on each value I don't
know it's a bit of a pain if you guys
just have a stream of text and that's
gonna be a lot simpler thanks to the
next feature transform streams transform
streams I'd say they're about as big as
a sink it's a race it's maybe maybe a
little less vague they're still being
specs there is a sort of JavaScript
implementation of proof of concept
and some implementation is happening in
chrome right now so before we introduce
the decoder we were streaming stuff from
the network straight into our log no
okay
tragedy thank you thank you
transform screen has become this little
bit that sits in the middle that you
know takes the pin and put something
else out in terms of code they look like
this new transform stream and then you
pass in an object of methods like start
called straightaway transform and that's
called every time a chunk is received
and then flush which is when the the
incoming stream has ended what you get
back is an object of two properties
which is a readable stream and a
writable stream at the input and the
output this works really well because
you can like pass just one of those bits
to another piece of code without passing
on the whole transform stream so so we
want to create this text decoder as a
transform stream we'd start off by
creating a function that's going to
return it set up our decoder the
internal implementation return a fancy
new transform stream we only need the
the transform function and in there just
every time we get a chunk we're going to
do controller on cue which is passing a
chunk out and we're going to call text
decoder decode and pass that chunk of
room so if we go back to our fetch code
from before that was logging out bytes
we can change this around about here and
take our stream and we pipe it through
the decoder we just created and this the
pipe through connects the sort of
writable those are the read what has put
into the transform and returns the
readable of the transform so now all
these the logs will be text at this
point now like a sinker iterators like
once this lands in the browser we'll
start to see them appear in the Dom as
well sort of api's will be changed
things like compression decompression
there's a lot of that in the browser
already laid Jesus etc image encoding
and decoding they already exist to
they're just not exposed to developers
very well and they'd be perfect for
transform streams but the first Dom API
that is going to become a transform
stream and we've wasted our time by
recreating it it's going to be text
decoder so that's going to be changed in
a backwards compatible way to be a
native transform stream and once you do
that you'll get string out of the out of
the stream so if you want to dig into
streams a bit more check out the specs
and that's where you'll find the
JavaScript implementation and I'm really
excited about streams landing in
JavaScript in case you can't tell I'm
good I think it's about time because
streams are being behind the scenes of
the browser for like about 20 years if a
page is well built you'll see it render
gradually and this is because the
browser streams the content from the
network and passes it through the HTML
parser which is you know the support
streams it can process it as it's
arriving wiki offline this is a
wikipedia PWA and it makes good use of
this ancient browser feature on a
low-end device on a 3G connection or
emulated in chrome anyway with an empty
cache the HTML takes around about you
know just under five seconds to download
all the while that's happening that the
parser is processing what it receives
and that means we get a first render in
sort of less than half a second I think
the Chrome's throttling is actually
quite kind here on a real device it
would be a bit later than that due to
SSL setup but there's so at this point
we're just displaying like the top
banner the title we haven't got the full
page of content yet but at least the
user feels like something's happening
and then at one point eight seconds we
get there the first page of content
rendered and rendering continues as more
stuff is received as an experiment I
also built wiki offline as a single page
app which is a popular pattern with late
JavaScript frameworks so here I'm just
going to return this a little bit of
HTML and then letting JavaScript handle
the rest
now this actually changes the story
quite a lot the HTML fetching and
parsing is way quicker because there's
not a lot of it and in here we get the
first render just the shell so at this
point performance it's neck-and-neck but
while this is happening
javascript is downloading and that needs
to execute and then it fetches the
actual content it needs for the page and
inserts it now we get to content render
like almost two seconds later than the
server rendered version and I'm being
kind here I think we regularly see
single page apps taking a lot longer
than this to get content on screen and
it's a little bit of a misleading graph
because it looks like the single page
app completes everything a lot sooner
the reason for this is as the
in a server rendered version as it's
downloading the HTML it kind of
discovers things it discovers things
like style sheets images fonts all of
that stuff it starts going oh actually
some of this is important for the top of
the page so I'm going to devote
bandwidth to dealing with that in the
single page app version none of that can
happen until that content is parsed and
that happens right at the end at that
render there so it's load slower what
can we do about this performance problem
well we can bring in a serviceworker and
we can store the the actual page in the
cache and so that makes that a little
bit shorter that download time goes away
really the same with the script as well
but the page content still comes from
the network you know we can't cash all
of Wikipedia the problem we have here is
that JavaScript initiates through the
content download so we have to wait for
the JavaScript to run before we can
start fetching the content we can avoid
this using link rel preload which we saw
earlier so doing this means we can sort
of run those two things in parallel but
so what like all of that optimisation
later late the serviceworker pre-loading
caching we're still slower than the the
empty cache server render just just to
let it update for everyone the screen if
my notes in just went off for three
seconds it this could be happening again
but we're still slower than the empty
cache render there and that's because we
are spending all this time downloading
content and then not doing anything with
it until we have all of it
so we've traded this gradual rendering
model here for one where we just display
nothing until we have everything in so
because there's no API that can take a
stream of HTML and inject it into the
page and we really need that I hope we
get that that one day but until then we
shouldn't be breaking performance by
using a single page app then just trying
to limit the damage we should be taking
the well performing server render and
then making that even better and streams
combined a serviceworker let us do this
so like we saw before this streams the
same is true for put a serviceworker in
the middle it doesn't really change
anything if the content is coming from a
cache it will also store
which is still important if it's like a
large video file you know you still want
that to stream from from disk but
ideally we want the mixture so we want
to serve a single HTML response where
parts come from the cache the static
parts like the you know header but the
dynamic parts come from network and you
can already do this in chrome in the
serviceworker fetch event I'm going to
get you know free parts of the page we
got to get to start from the cache the
middle from the network
I go salt include and then I'm going to
get the end from the cache as well then
I'm going to get readers for all of
those so we're going to process those
streams create my own readable stream
and I'm going to make a response using
it so I can just pass the readable into
new response and off it goes
unfortunately populating that stream is
not so easy it's like this you know it's
a big bit of code it's I'm not going to
talk through it it's quite ugly and it
involves passing every chunk sort of
through JavaScript and sort of dealing
with it in processing all of those
streams in order this is actually get a
whole lot easier thanks to identity
streams which is the next of the 2017
features I want to look at I would say
these are more vague than transform
streams mostly because the API change
less than two weeks ago so you know
things are moving around but I think
it's pretty stable now to use this in
your serviceworker fetch event just as
before I'm going to get those free parts
that I'm going to display but this time
I'm going to create an identity stream
an identity stream is just a transform
stream that doesn't do any transforming
the the input just goes to the output so
I'm going to respond with that readable
part of the transform but then before I
do that this is how we deal with the
writable we're just going to do
something asynchronously so I'm going to
have a self invoking async function
there I'm going for each of the
responses it promises that we have going
to pipe the body to the right of all I'm
going to say prevent clothes here which
is just saying hey once once all of this
stream has gone into that stream don't
don't close the other stream because
we've got more to do we're going to do
for each stream and then we can close it
out and that's it a not only is this
code simpler it's also faster because
we're no longer passing every chunk
through JavaScript because the browser
can go oh hang on like the stream that
we're receiving
is you know from behind-the-scenes it's
either coming from the network or the
cash and then the thing receiving the
stream is the HTML parser which is also
behind the scenes and it can just do the
whole thing in the background and save a
whole lot of processing time so now
we're getting the best of both we're
responding quickly from the cash but
streaming the rest of the data from the
network and the result of that like so
here's where we were before we can
optimize our server rendered version
with the the serviceworker in streams
the path starts earlier because it
receives that big lump of content
straight right at the start from the
cache and this means our first paint
happens much sooner but the important
bit is the content happens way sooner so
we get that quick offline first cached
render but still the benefit of the
streaming render for the uncashed
content so it's now over a second
quicker for content than the hacky
single page app and with a model like
this I'm actually kind of happy with
full page reloads when it comes to
navigating around so on the left here I
have a single page app so every time I
click a link javascript is going to
fetch the data and put it on the page on
the right just a web page you click a
link it's going to reload and it's going
to load that data so I set them off at
the same time you can see that with all
the complexity I added you know with
making this a single page happen and
using push date etc it's still slower
than full page reloads especially when
they're super charged by a streaming
service worker your mileage may vary it
can depend on the amount of content
you've got but I'm not making this up
although this is a demo
I actually got hit by a real-world case
of this only a couple of days ago and on
Monday I was at Heathrow Airport
browsing github on airport Wi-Fi which
is you know not so great now github will
use push States and it will use
JavaScript for all of its navigations
unless you're in a new tab then it will
it will do a server render so I'm going
to do here is I'm going to click a link
on the left here and then I'm going to
paste the same link into an empty tab so
here we go click the link paste it off
we go
and we see that the server render wins
by like a country mile lei is way faster
and and this is not throttled or
anything
well not artificially this is just
airport Wi-Fi and this is because on the
left it has to download anything before
it can show it has download everything
before it can show anything you know
that kik help here they've they've
written a lot of JavaScript to make this
quite slow you know unfortunately all
too often I hear people say that
progressive web app must be a single
page app and I am not so sure you might
not need a single page app a single page
app can end up being a lot of work and
slower there's a lot of cargo cult
around single page apps and and I know
what happens when you just sort of copy
someone else without really
understanding the situation you see I I
went out for a meal with Paul Irish yeah
that's right for the meal with Paul
Irish he wants to touch me anyway I
watched Paul taste some wine and this is
amazing he swilled it around in the
glass and he took this this huge sniff
like I'm huge sniff and intercept my
fault Wow Paul is so cool like he look
he really knows what he's doing this is
amazing and anyway couple of months
later I you know back in England work
out with some friends and we were out of
restaurants and we had some wine and I
thought I've got this I know what to do
here I've seen this done so I took the
wine ice willed it and I took a big old
sniff but I took the wine glass just a
little bit too far and dipped my nose in
it
don't know if you have a snorted wine
before is not pleasant I just kind of
sneezed it out everywhere and my friends
were just staring at me covered in a
wine mist like Jake why didn't you just
drink it with your mouth for the
sandwiches the moral of the story is you
might not need a single-page app when it
comes to you know there's a link there
you know a server rendom might be enough
especially when you've involved the
serviceworker and of course if you're
using a client-side framework server
rendering is absolutely must I mean
react ember angular to web components
they they all let you get something on
screen in a streaming manner before
JavaScript fetches just make sure it's
that you're not displaying things that
should be interactive but on so things
are looking pretty good
however Facebook had been prototyping
with this stream stuff and identified a
problem if you're serving from a
serviceworker there is the startup time
of the serviceworker to consider and
wait and that's zero if it's already
running but the serviceworker shuts down
if it hasn't done anything for like 30
seconds to preserve memory depending on
the user's device or like other things
going on that startup can add in the
worst cases carob you know a few hundred
milliseconds and that delays the content
fetch just by a little bit and we are
looking to reduce that startup time but
it's always going to be more than zero
if your serviceworker isn't already
running and are we just going to live
with that over my tiny Yelp clone we are
so we're going to introduce navigator
navigation preload now I would say this
is a little higher on the vagueness
scale we have an implementation in
progress but the spec is still kind of
moving around a little bit so it takes
with a grain of salt our goal here is to
start the HTML fetch in parallel with
the serviceworker startup which you can
enable just using this this one line
here and you can set you can do that
whenever you want but the serviceworker
activate event is a pretty good place to
do it and this means for navigation
requests the browser will make the
request to the network while the
serviceworker is booting up and that
response appears on
fetch event as a preload response and
that's a promise which a nut will
resolve if undefined if it's not a
navigation or if the feature isn't
enabled so it's always worth like
looking and if it's false II just do a
normal fetch if that's what you're
wanting now what you do with this is up
to you that you could respond from the
cache and fall back to the network but
given that this preload can happen
pretty early
it becomes realistic that the network
may beat the the cache API so why not
race the two of them and see which one
comes back first and I think upon a
point so I said yesterday excuse it was
very ripe that promise dot race is not
your friend for doing this at all when
you give promised race an array of
promises it takes the result of which
ever one ends first not whichever one
succeeds first late take this race is
race I'd say this race was in progress
because no one has won yet promise dot
race on the other hand would say oh she
fell over
don't care about anything else the whole
race was a failure because of her
promise top race is a dick yeah ice so
you will need to write your own racing
function here you want it one is the
resolve with the value of the first
promise to resolve with a trophy value
it's a few lines but you know that's
what you need for all of our streaming
code from before like a straight-up
preload wouldn't work here because like
we're not fetching the same thing that
would be fetched if the service worker
wasn't there cuz we just want the middle
of the page just that little bit before
we got the top in the bottom in the
cache thankfully this is not a problem
because those preload requests are sent
with a special header is headed here and
if your server sees that you can go oh
okay I'm just going to serve the middle
bit because this is this is going to go
through the serviceworker in it knows
how to deal with it so back in that code
we can you know we can deal with that
just right here use the the preload
response if it's there otherwise falling
back to fetch and that means for
navigation requests the you know that
will happen at the same time as the
service workers booting up and this is
something that we can improve on even
more late with this feature we could
potentially look at doing it as the
browser is booting up which is
particularly good for progressive web
apps added to the home screen and we
hope we can get there as well just as
soon as the user presses it just as the
browser booting up we can have that
request started well early if you want
to dig into this a little bit more
there's a huge thread on github about it
I don't say hell I'll post the links up
later on what else have we got ah
so the current way the serviceworker
works is that requests from your page
will go via the serviceworker your
serviceworker and that happens even if
the request is to a completely different
origin like a font service your
serviceworker decides what to do and
this is by design because it means you
can cache things that like images and
fonts even if the destination server
hasn't even thought about how that would
work or how to do that
downside to that as many sites may end
up with the similar logic for font
caching or analytics and can end up
storing the same thing independently and
in future we could look at ways of
educating that inside the browser but
the logic is still being duplicated so
to the rescue here comes
foreign fetch so I would say this is a
little Vegas still only because I'm
pretty certain parts of this API are
going to change but there is a version
of it in Chrome Canary already which you
can actually test with real users now
I'll put a link up on how to do that in
a minute
so what is it with foreign fetch this
the font service has its own
serviceworker in storage and if you make
a request for the font service it first
goes to your serviceworker you get you
know the first show of what to do but if
you send the request on to the font
service it goes to its serviceworker and
they get decide what to do which could
be to get the stuff out of the cache and
send it back so that means that if
another website makes the same request
to the font service it can get that
cache and benefit the same resource that
the font service has cached so if you
want to do this if you want it to be the
the font service and make this work in
your serviceworker you listen for this
new event like foreign fetch and this
will be triggered when another origin
request something from your origin and
from there on it's kind of it's a little
familiar you know respond with your
gonna respond with however you want
let's look to see if there's something
in the cache otherwise fall back to the
network and then return the response and
this is where things get a little bit
different
rather than is returning the response or
a promise for the response we return an
object which has a response property now
when you do this the destination server
will not have scripting access to the
content of that response it won't be
able to get at the text of it but it
will be able to include it as a script
tag or as as an image element or
something like that the same way cause
works today this is like a no cause
response just won't be able to get the
text or the pixel data of the image if
you want bit of a server to have that
access you add the origin property and
you set it to the origin you want to
have access so here I'm just passing
through event origin so I'm saying like
if I have visibility to this resource I
want them to have visibility to it as
well which you think carefully if that's
what you actually want otherwise you can
you know set up some kind of whitelist
or something you could even sort of get
this information from index DB you know
you're coding you can do what you want
so this is kind of representation of
cause but with JavaScript
you can sort of do a lot of different
things but I mean we talked about font
and image api's and analytics but you
can use this to create whole rest like
API is that work entirely offline one
detail is missing though how do we get
this serviceworker installed on the
user's machine because if it's like a
REST API or a font service like where
the fonts come from the user is very
rarely going to actually go there and
that's when the service workers
installed so to fix this when you
actually give a resource to a page you
can also serve it with this special
header which tells the browser about the
serviceworker you have and it will then
go and install it if you're keen on
foreign fetch a article by Jeff who was
speaking earlier he covers any also
covers how you could actually use this
on websites today as part of an origin
trial oh yeah so earlier on the
background sync was mentioned which is a
feature we shipped sort of many months
ago it allows you to defer single tasks
until the user regains connectivity so
say the user updated some like setting
in their profile or sent a chat message
when they had no connection background
sync lets you queue that work and now
the user can sort of navigate away they
can close the browser and later once
they have connectivity the service
worker can wake up and send that stuff
to the server and this is this is
shipped in chrome like it's done and
it's great for small bits of data like
near profile updates sending a chat
message that kind of thing the problem
here is like while the sync happens the
serviceworker has to be awake the whole
time and that's bad for privacy and bad
for battery so we're not going to do
that what we do now is if a sync runs
for you know too long we just we just
kill the process but for large uploads
and downloads we're working on something
else background fetch now it's quite
early days for this one so it's it's
pretty vague vaguer than the vague graph
itself so that's quite vague all we have
right now is a kind of API sketch and
we're starting to explore the issues and
get a feel for how it could work it's a
it's a cross browser effort so here's
the idea from your page or your
serviceworker whichever you get hold of
the registration and then call
background fetch fetch give it an ID and
then give it some requests
all right so for a movie this could
include let the video resource but also
like some metadata or something poster
image whatever and that's it that fetch
will now happen in the background even
if the user you know closes the page or
all the browser on mobile and once the
fetch complete you get an event for it
and you know that will give you
information about it you can start
having look what's the tag yeah I'm
going to actually cache this stuff so
I'll open the cache and then event dot
fetches will be a JavaScript map of
requests and responses that arrived so
you can do what you want with that of
course if you're uploading photos you
don't want to cache the results you'll
this may be showing notification so
you've got the freedom there and during
the fetch where the user will see a
notification and that will show the
progress of the download and because of
this high visibility and it being easily
cancelable we're hoping that we can
deliver this feature without any sort of
permission prompts something like that
we just need to make sure that the
privacy aspect is correct and make sure
it isn't too abusable if this is
something you're interested in um you
can take part on github
I will move that repo somewhere a little
bit more neutral like the the ycg
standard thing oh yeah earlier on I was
I showed you this this thing here like
the full page navigations being
significantly faster but I know why
people go down the SPI ruse because they
you know they want the ability to do a
nice transform from transition from one
state to the other it makes me sad
because I've seen developers introduce
like large frameworks just for basic
transitions which is a little bit of a
shame especially to have to re-implement
the entire navigation stack just because
you want a nice fade from one thing to
another and that's why we're going to
take another look at navigation
transitions I mentioned them yesterday
and I I really want to have a good plan
for this in 2017 but right now the idea
is very very vague in fact we have to
you know scale the whole graph down just
to sort of see the top of it so take
this with a a big bag of salt and it's
not the first time we've looked into
this either internet explorer 5 you
could use this meta tag to specify a
kind of enter or exit transition from a
set of configurable presets
so with this page in Internet Explorer 5
the user would click the link and
Internet Explorer would crash is what it
usually did that was my experience
anyway but a 20 in 2014
chrome dev summit we pitched this
transitions idea we showed demos I
didn't really pan out Mozilla have a
proposal as well but they're both
solutions that's kind of live in CSS and
they're limited by what you can kind of
declaratively say up front I don't think
they're expressive enough stuff like
this should be possible you know that
and that would be a full page reload
utilizing a full navigation stack of the
browser and the streaming HTML parser so
I mean I like because when you do this
you get the back and forward buttons
working for free if we actually take a
closer look at this transition the first
part we can do that without any
additional data we already have the
image we know where it's going and we
have that title already stored we can do
that bit and we can improve the
perception of performance by doing this
bit while the actual fetch is happening
and then we can bring in the content
once it arrives if it arrives while
we're transitioning we can bring it in
earlier and sort of make it part of that
sliding transition the transition outs a
little bit different and we actually
need more data to do that transition
because we need to know where we're
sending the clock back to which depends
on layout but also scroll position
because when you use the back and
forward buttons it will try and restore
the scroll position I really think we
need an API that allows this they
something like a navigate event that
fires when you know this page is going
to be changed and you can kind of say
hey I'm about to do a transition so keep
this document around for a bit and at
this point you know you can start doing
that at the very first part of the of
the transition like you're getting
everything into place where you think
things are going to be get hold of the
new window object which will represent
the page that's coming in then that will
resolve is undefined if it's a cross
origin navigation I would like us to
look at cross origin navigations as well
but they have to be pretty restricted
for security reasons but once you've got
this new window you've got scripting
access to it you can start doing what
you want like the by default I think the
new window will draw on top but the
transparent parts will show the page
underneath so here you could you know
you can start looking at where elements
are what the scroll position is here I'm
just going to set the opacity to zero
of the new document wait for document
interactive and then fade that document
in so that's a simple fading animation
this is a simple example but it's as
complex as you want to make it so Biff
this you'll be able to come you know do
these expressive animations but retain
all of the features that you know the
browser gives you for free in
navigations that's interesting to you it
was the details are on github I once
again I intend to move this repo
somewhere a little bit more neutral the
term progressive web app is it's just
over a year old but the work has been
happening for years on this stuff and
we're not done you've heard over the
past couple of days that how much we
love the web and sort of where we want
it to go but now it is over to you like
we want your feedback on this stuff
where it would be it in github at the
very early stages or playing with this
stuff in Chrome Canary so you'll come
and talk to us about it basically I
can't put it better than this this this
shop window sign where you're not tool
not happy wait we're not happy till
you're not happy nice are they over till
I don't know anyway thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>