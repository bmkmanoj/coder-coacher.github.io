<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Sure Every Call Works (Kranky Geek WebRTC Brazil 2016) | Coder Coacher - Coaching Coders</title><meta content="Making Sure Every Call Works (Kranky Geek WebRTC Brazil 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Making Sure Every Call Works (Kranky Geek WebRTC Brazil 2016)</b></h2><h5 class="post__date">2017-01-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_vQDXALdSYU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so hello guys my name is Marshall phone
so I'm an engineer at talk box
for those of you guys who don't know
about talk box we are a telefónica
company based in California and what we
do is we offer a cloud platform and
called open talk that basically helps
you a lot if you want to develop a web
RTC application so if you want to know
more information about us please check
our website talk box.com
but today I'm not talking about open
talk I'm actually talking about how you
can make sure that every cow works so
not that you start and in order to
explain better to you guys what I'm
talking about I would like to start with
send me some real user stories there are
actually very common problems that we
hear from our customers when we have an
application based on web RTC so let's
take a look at some examples so the
first one the user says hey your app is
great and everything's working fine but
the problem is sometimes video quality
is not that good so why does it happen
so this case we also have a screen shot
certainly as you can see the first
screen doesn't really have a good Billy
Cooper video quality then the second
example is the user say hey when I
journey the conference I I could see my
friend but he only saw a black stream
why do they happen so we have an example
of four streams but you are they're not
black so why did this happen right and
the third one is the user size when I
join any conference I was able to hear
sorry I was able to hear the other
person but I could not hear them so why
did that happen
so as you can see these no audio for
user one okay so based on these problems
that we again we hear very often from
our customers I belittle II have three
questions for you one how can we answer
our customers in these situations and
the two is how can we identify the
source of the problems and third how can
we avoid problems like this to happen in
the future so in order to help you with
these questions I have some information
to share well the first information I
want to share with you is a very cool
application called Tesla battery c.org
and this is the web RTC troubleshooter
that lets you identify problems with a
specific user so I will show you how how
it works
Oh as you can see in the top part there
is a start button and when I click here
what the app does basically five checks
okay so you check first my microphone to
guarantee the microphone is capturing
audio he also checks additional things
like clipping in the volume of the
microphone to see if not too low or too
high and then we have the second check
which is the camera so here the apps
check that the camera of the user
supports some defining resolutions and
it also checks that the video frames
that are being generated are not black
or frozen okay let me have the third
check with which is the network in which
we will check if the Faro is not
blocking specific protocols like TCP and
UDP and the fourth check is the
connectivity where you can test the
connectivity to our turn and stern
servers and lastly we have a bandwidth
test which will basically test our
bandwidth and our packet loss so the
other thing that I want to show you here
is that there is also a top part there
is a menu that you can click and you can
also specify some settings when you run
the test so if you have more than one
microphone you can spice it you can
specify your microphone also your camera
and you can also specify your turn and
stern servers right so it's gonna see
here you can specify turn and so when I
run the connectivity tests you will be
against a stern and understand in turn
servers so after about you see that argh
is really great but the point is how can
I avoid problems like this to happen
before users join the conference so what
I have here basically
three really really quick checks there
came to implement inside your app so the
idea here is that inside your
application users can test basically
these three things and if something goes
wrong you can just play a message to the
user before they connect to the session
right so the first part is the hardware
setup in which we will test the
microphone in the camera the second one
is the connectivity test in which you
attach the connectivity to our ice
servers our stun and turn servers and
the last part is the network test and
make sure you check bandwidth and packet
loss of the user first the hardware
setup right so the idea here is that
inside your application you can
implement a preview screen just like
this one so users before they join the
conference they can basically test their
camera and microphone to guarantee that
it's working before I join the
conference right so how can i implement
something like this the first part is
basically creating the combo boxes right
so we have two combo boxes one for
select to the camera and the other for
select the microphone so what I need
here is I need to get the list of the
devices from the client I need the list
of the microphones and the list of
cameras how can I do this
so in the media devices API there is a
method called enumerated devices and
these will return an array of media
devices each media device has basically
four information it has a kind which has
the type of the device it can be video
input if it's a camera can be audio
input if it's a microphone or audio
output if it's a speaker they may have
the device AG and the device it is
important because
the information that will pass in that
getusermedia call to specify that that
is the microphone or the camera every
once you use okay I will show you later
how we do this let me have the label
which is the name of the device right
camera FaceTime me Gigi for example and
then we have the group IG understand the
group ID as two devices they have the
same group ID if they are physically in
the same device so for example I can
have a monitor that has a camera and a
microphone inside the monitor so both
the camera and the microphone they will
have the same group ID because they are
physically in the same device so okay
once I get the devices the next part is
passing the devices to the get user
media call right so I can specify the
microphone and the camera so the first
thing we need to know is the concept of
constraints so when you call
getusermedia you basically can pass an
object containing some parameters which
we call constraints right so they are
basically two medium string constraints
which is our you in a video so we
basically specify true or false for the
audio or video but you can also specify
some additional constraints so in this
example in the bottom part i specify my
audio is true and for a video i'm
specifying resolution there so i say hey
my resolution here is to any ad by 720
right there are all the constraints you
can specify so here we have a list of
the main constraints you can specify
these are not the only ones so there are
more constraints there is a complete
list of about 15 constraints if you yeah
in the minute devices the api there is a
method called get supported constraints
they will return a complete list of
constraints and basically true or false
for each one of the constraints to see
if that constraint
or that or not so once we have the
devices and once we know how to pedal
the constraints then we can specify
microphone and camera right so I'm
creating a variable called constraints
and I'm saying that for my audio this is
the device ID I want to use if the IG of
my microphone and for the video this is
the device AG that I want to use which
is the ID of my camera and then I caught
yet user media passing the constraints
as the parameter right in this is light
I also left a reference for you guys for
how to create the outer level bar so in
that sample that I showed you in the
bottom part there was about an audio
level bar so as the user speaks you can
see the bard animating to indicate the
microphone is working okay so the second
part is checking the connectivity the
connectivity to our eyes servers so here
I have a fact which is because of
restrictive networks such as corporate
chip virus sometimes users can not
establish a call using our eyes servers
or stern and turn servers so the
question is how can users test the
connectivity to our turn and stern
servers before they join the conference
so what I have here is a simple that
explains to you how you can do this
right so what i'm doing here basically
is I'm creating a peer connection and
I'm specifying the ID servers they might
build connection configuration variable
and then on my oh wise candidate
listener what I'm doing here is I'm
verifying that type of candidate that I
get and I'm basically how many reflexive
candidates I get and how many really
candidates I get
so look analyse the type of the
candidate and then I say oh it's
reflexive okay increment the counter for
reflexive if is relay increment the
counter for relay so in the end I have
the number of relay candidates and the
number of reflexive candidates once I
have the number I can basically set my
test so when I create my offer I will
see how many reflexive and how many
relay candidates like that and then I
can say okay if I get relay candidates
it means my connectivity to the turn
server is working fine if I don't is not
working the same for reflexive
candidates if I get reflexive candidates
my can achieve it to the stern server is
working fine otherwise is not this
simple is not covering the check for
protocols right so you can also happen
that your viral can block for example
UDP traffic so you it's possible that
you can get for example relay candidates
if you deploy I turn server in TCP for
example I'm not covering this here but
just for you to know that you can also
do something more complex to also verify
things like this in the third party the
network test so I have an another fact
for you guys which is a high number of
problems related to video quality happen
because of two problems right when users
don't have the minimum bid rate required
and second there is a high audio and
video packet loss in the session of
course there are many other reasons that
can cause video quality problems but
what I'm saying here is that a high
number of problems are caused by these
cheer reasons my question is is it
possible to check the users beach wait
an average packet loss
before they connect to the conference
what I have here is a sample
which you basically run for some seconds
and you guys statistics about my network
okay
Oh better yes statistics about my audio
track in my video track and what I have
here is basically they read your betray
the video packet loss the audio bitrate
and the audio packet loss once I have
this information I can work with them
and just play a message to the user so
in this case your network looks fine
you're okay so how to implement a test
like this so in this slide I will give
you just a spoiler of next presentation
which is about web RTC statistics
because I just want you to know that
there is an API call get stats that
allows you to get statistics about your
peer connection and statistics about all
the objects inside your peer connection
your streams your outer tracks your
media tracks your ice candidates and
more so what i'm doing here basically is
I have my peer connection so my peer
connection objects they have a method
called get stats so I call get stats and
what i'm doing here is i'm basically
filtering the results because I'm only
interested to get a specific object
which is my outer track received so I
have my string received and I'm getting
the outer track for the ice cream once I
have this I just console.log the results
so I have an object with some
information there so I can get
information for the outer track for
example things like the audio level the
bytes received the ID of the object the
number of packet loss and much other
information there but I just wanted to
focus on the information which is in red
which is bytes received and packet lost
because this is the information we want
right so look how cool it is what psycho
gets
that's I can get information of bytes
received and packet loss once I have
this what I can do is I can create a
basic network test so what i'm doing
what i'm doing here basically is i'm
specifying a timeout of let's say 15
seconds and now you let my apple run for
15 seconds and after that are your core
get stats right so i'm calling there
after that I'm out I'm calling peer
connection that jet starts and I'm
getting information about the audio in
the video so I am getting statistics
about my outer track and a bio about my
video track my process that's basically
what it does is have you get information
about beats received so what I'm doing
here is I get a total of bytes
multiplied by H because it's the number
of beats and not bytes and then I divide
I divide by the number of seconds so
what I have in the end is the beats per
second right and the line above solving
the following line I have the packet
loss per second so I have the total of
packet lost divided by the number of
seconds - I have the packet lost per
second so at this point I have basically
four different information they have the
video bit rate the video packet loss the
audio bitrate and the audio packet loss
there is an observation in the bottom
part which is this sample only gets one
is not shot so I only call get starts
once you can do something more
sophisticated if you want and actually
colgate starts let's say once a second
so you can get things like Network
variation or packet loss variation
instead of just calling once because you
only you only have one snapshot at the
end okay once I have this information
what I can do here
that I can create some three shots to
display the information so I'm saying
basically is the user is okay for the
audio and video if the audio bitrate is
higher than 300 kilobits per second and
the video bitrate is less than three
percent if my user doesn't satisfy this
condition I can also try our only so
what I'm doing is if my user has audio
packet loss there is less than five
percent you would okay for the hour only
right so I have basically three
possibilities out even video audio only
or and none of them they say you're
sorry you're banned waves just too low
right in the last part you just plain
the results oh just making a recap we
have basically three parts so the first
one the hardware setup in which we test
camera and microphone then connectivity
test to our stun and turn servers and
last natural test to test the bitrate
and packet loss once you test everything
check check check
you can be sure or almost sure the every
copy work
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>