<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Quantify and improve real-world RAIL (Chrome Dev Summit 2015) | Coder Coacher - Coaching Coders</title><meta content="Quantify and improve real-world RAIL (Chrome Dev Summit 2015) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Quantify and improve real-world RAIL (Chrome Dev Summit 2015)</b></h2><h5 class="post__date">2015-11-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NrEjkflqPxQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so watching some of the presentations
this morning it's pretty exciting time
to be a performance developer
performance engineer because frankly
there's just so much data that's
becoming available it wasn't long ago
that just like a couple years ago we
couldn't even talk about something like
rail because frankly we couldn't surface
the right data for you to to act on it
and I remember the first iterations of
it when we started working on it where
we're exposing this data and it's just
big data data dumps and it's very hard
to process right and now you have
devtools kind of threading it together
bringing it to a cohesive picture and
it's becoming a really a viable thing
that you can tackle so this is all
exciting and this is necessary and it's
critical to us to our success because
you need that sort of environment the
control and controlled environment where
you can capture the data it can take the
trace you can actually bring in the
trace from another developer analyze it
look at all the parts of the stack and
kind of piece them all together so
you're not looking at memory verses
frames versus network in isolation all
those things interact and really kind of
the big breakthrough that we had in the
last year or so is starting to piece all
those things together such that you can
actually figure out what's going on so
this is critical but I'm going to claim
this is actually not sufficient because
once you've done all of this control
testing and you have all your aggression
monitoring and you run all your builds
and all the rest then you deploy your
application to the real world and the
real world is kind of messy as you
probably realize because there's just
such a big of variability in the devices
and the networks in just conditions that
your application may run it and it's a
little bit crazy ass through the kinds
of reports you'll go back for your users
for example you might never expect to
hear that hey my application runs slower
when it's sunny outside but that is
exactly the kind of scenario that at
least one of the teams that I worked
with has encountered and this was an
obvious head scratcher but after doing
some extensive user research and all the
things they realize that well it turns
out that the application is an
application that many users use while
driving so they'd like to mount their
phone and dashboard the dashboard gets
kind of hot the thermal regulator kicks
in it throttles the phone the
application runs slower so you know you
get slower frame rates on a sunny day
and that's
a crazy it's not the kind of thing that
you would model in devtools I don't know
maybe at next chrome dev summit will add
a new weather emulation mode yo you
heard it here first right like this is
funny but it's true like this is the
kind of stuff we have to deal with and
this is why we need real user
measurement to both capture the real
world data coming from the users and
also the API is to kind of counteract
and figure out what's going on on the
device so this is the part that I want
to focus on here we've heard a lot about
debugging and dev tools and other things
the part that I'm interested here is
what can we do what can we gather from
real users and turns out this is
actually an area that we've been
focusing on for a while we have the w3c
web performance working group where we
have all the different browser vendors
talking about this and we spent
internally in chrome quite a bit of time
over the course last year digging into
all the subsystems trying to understand
do we have the right AP is to first
identify and measure each component of
rail if we do or if we don't how can you
make them better and if necessary can it
can and should we add new capabilities
to the space so you can actually bring
those data from the real world so the
good news is we're not starting from
scratch the web performance working
group has been hard at work for for
quite a while and we have a collection
of api's that already fill in some of
these gaps and in particular we do a
pretty good job on the loading part so
the networking part and if you're not
familiar with these api is I definitely
recommend you check out the perfect
timing primer which kind of threads the
whole story together for what's the
harbor high resolution 10 timestamp and
why do you want that what's a timeline
and how do these events get emitted and
how do you measure the say loading time
a web page versus resources and all the
rest so we have some good resources
there but of course that doesn't capture
the full arc of the rail experience
where it's not just the first load but
also the interactions afterwards so we
started looking at first of all how are
developers using the current age
yesterday are they sufficient even for
the low part and can we do better and
one pattern that we found maybe not this
exact pattern but something very similar
is that due to the nature of how these
api's have been implemented inspect many
developers are actually pulling for
performance data so the typical pattern
is you want to observe that some event
has happened that for example the
research fetch has finished or maybe the
application is emitting custom metrics
and you want to observe that so if I'm
an analytics vendor I will just sit
there and pull periodically the page I
will pull out all the entries from this
global buffer and I'll then dip them or
try to dip them from the previous day to
try to figure out if something is new
and this creates a lot of unnecessary
work obviously for the platform because
oftentimes there's just no new events
and there's this is just unnecessary
work it also has some funny race
conditions and because it's a global
buffer if somebody else comes along and
clears that buffer then some other
applications losing data so this is not
great so after some work in the space
and thinking through the plausible
solutions we actually introduced a new
interface and this is already available
in Chrome Canary that you can put this
up and play with us today this is an
observer interface where instead of
pulling for these events you can
actually say what type of events you
would like to listen to so for example
if you're interested in fetching or
infectious going on in the browser you
can subscribe to resource events which
will be emitted when the resource has
finished sketching or things like marks
and measures which are user Italian
metrics that the application may be
emitting so this is an API that an
analytics vendor or your application can
subscribe to and get these notifications
and we can actually deliver these
notifications in a smart way you've
already heard about the concept of idle
time and pushing some of the
non-critical work into these idle box we
can schedule these types of events into
the idle time such that your raft loop
does not get interrupted so you can play
with us today and i encourage you to
this is a very nice addition to the API
now let's move on to the response so
response is a big component of braille
right we've learned that we want to
respond to all user input within hundred
milliseconds so where exactly is that
100 milliseconds spent and we spent a
quite a bit of time with the input team
trying to figure out all this different
stages of where the latency goes today
so when you tap that glass the hardware
actually has to register that fact and
deliver it to the operating system the
operating system that needs to dispatch
the events to the browser the browser
has a bunch of event loops and needs to
deliver that event to the correct event
loop finally that event loop gets to
your handler dispatches the the callback
you execute your code right there is it
quite a few layers in here and doing
some testing this is just a device that
was done in the lab the actual numbers
will vary depending on hardware and
other things but we found that the
hardware to operating system like this
can be as high as a couple of frames so
30 to 50 milliseconds which is quite
significant similarly getting the event
from the operating system to the browser
and then finally to the application can
also take another couple of frames so if
you think about our original hundred
millisecond budget we're already
spending quite a bit of time just
getting the event to your application
and finally your application has to run
and then we looked at how you would
measure that today or how developers are
measuring today right and you would use
something like the user timing API where
you get that call back you you do a mark
start then you finish your work you do a
mark end and then you have your duration
for the handler and that's that's your
response line and of course that's not
great because we want to provide better
accountability both for the browser
developers and engineers or developers
building all these applications so
there's a big question mark here it's
like how do we surface this and the
proposal that we have on the table right
now it's actually being implemented in
chrome and a few other browsers is to
change the definition of the event
timestamp so there's an existing
timestamp property on the event object
but turns out today due to various
implementation bugs it's not terribly
helpful it uses a different time based
it's not terribly accurate so we're
exploring changing this to Adam high-res
time stamp which is a high resolution
time stamp which will have the same time
origin as all the other performance
events and more importantly for this
particular case is that for input events
it would reflect the timestamp of when
the operating system got the event so
this is a much more accurate higher
fidelity time step that you can use in
your applications which is quite nice
and then for other events that are not
input events it would be equal to the
time when the event is created by the
browser so this is something that's
going through the implementation phase
right now and I'm hoping to see this
come to Chrome soon
so with this code you can actually the
new I guess you would use this is if
you're trying to track the response time
of say your touch events you would
subscribe via touch start listener you
can then compute the final time by it's
just subtracting the performance now
which also returns the high res
timestamp and get the full direction or
at least a much more accurate duration
which is nice right this is ideally this
is kind of where we want to be except as
we started digging further we realize
that there's some gotchas here so when
we look at scrolling which is one of the
most fundamental and important
interactions on your device we found
that in many cases there's a huge delay
100 milliseconds sometimes even 500
milliseconds before the browser can
actually do the scroll and if you dig
into understand why it's actually quite
tricky and interesting so let's go back
to original flow diagram here you get
the colonel event to dispatch it to the
browser the browser says hey are there
any touch handlers registered on this
page because if there are non great i'm
done and i can just do the compositor
scrolling i don't have to talk to the
main thread or do any work at all this
is the fast path and this is nice and
beautiful right but in practice most
every application will have some sort of
handlers register so really what happens
is then you say okay fine we can't do
the compositor path now we need to
actually dispatch this event to the main
thread and just this one hop this
synchronization to the main thread is
already a bottleneck because just adding
one single handler will force this
entire path so we dispatch it to the
main thread we then run your handler and
then we have to check in the handler did
you call prevent default because prevent
default allows you to base if
effectively stop the browser from doing
its default operation right so we have
to block on this and this is critical
and of course this is not great because
now if you if let's say your application
is executing something on the main
thread scrolling is blocked and even
just as the synchronization is expensive
so clearly we need something better and
this is a good example of perhaps in
this some missing functionality or some
missing API is that
will allow us to build much better and
more responsive applications so one
proposal that's currently being
discussed ins under development is this
idea of passive event listeners where
when you register the event listener you
can actually declare it to be passive
and effectively those two things it
promises that you will not call prevent
default or rather even if you call
prevent default that is effectively oh
no up so you will not prevent the
default action and it also allows and
that allows the browser to then proceed
with scrolling without blocking on that
execution so if we go back to our
original diagram there's a lot of points
errors here but the important part is on
the bottom right so we say is there a
touch handler yes the res is it passive
if it's if it is declared to be passive
then we can continue with the scrolling
but we will still dispatch the event so
you'll still get the event in JavaScript
plan you can still process what you need
and ideally actually you would take that
handler and move it into some idle time
right where you can process it and
unblock all of your critical work such
that your animations run as fast as they
can and this is really nice so as I said
this is one of the proposals on the
table and I'm a bit curious to see if
there are if there are others but this
is what we're currently experimenting
with so as a quick summary for response
we have a vent time stamp which provides
much better granularity for response
time do be careful with event listeners
this is something you may want to audit
on your application today just to see am
I registering these things are the
things that I'm including on my page
registering these things because even
just including one may have much higher
cost than you may expect and then
finally you probably want to start
experiment experimenting with
performance observer at least checking
if it's there and leveraging where
possible because that will allow you to
eliminate a lot of this extra polling
work so moving on animation this is a
big use case that we found perhaps you
may not think of it as animation but
this has come up in animation because it
overlaps with scrolling an animation a
lot about the use cases which is
visibility we have this concept of
visibility right and there's a lot of
best practices that we craft around some
concept of visibility where we say like
we have these long pages but not
everything
is important in the sense that some
content is visible and you may want to
prioritize it so maybe that's fetching
maybe that's rendering maybe it's doing
some other work there's things like the
lazy loading and infinite scrolling
which depend on knowing the position on
the page then finally there's analytics
I want to know if a certain thing was
seen and how long it was seen for and
other use cases and this is very very
common we've certainly had many
discussions around this topic on the web
performance working group but we never
really had a good solution for it or
just kind of collating all these use
cases and really what it boils down to
is the core use case here is the
developer wants to say I want to know
when this particular element or section
of the page intersects with the browser
with the viewable with the visual view
port if you will and if we think about
the properties of such an interface
right if it was to exist then we would
like it to be simple and easy to use
because that's certainly not the case
today if you want to do viewability sort
of patterns today it is possible many
people have built them but it's actually
very very hard and tricky and often
times it comes with a very egregious
cost in terms of performance because you
have to listen to scrolls and everything
else and all the things we just talked
about you're doing all of them so you
pretty much guaranteed to be on a slope
at some fraction of the time so we want
great performance obviously another one
is we probably want to be expressed as a
passive query this is actually a common
thread that I think you're going to
start to see here which is instead of
pulling and asking we want you to just
express what you want to know when we
will notify you and this interface also
allows us to then delay the delivery or
schedule the delivery of such events
into appropriate time blocks where
you're not interfering with other
critical work so because we're very
inventive with our names we call it
intersection observer and this is
another API that's currently being
implemented and being discussed and the
idea here is pretty simple as the name
implies you have an observer you can
give it an element so here I'm using a
document Korea selector I'm just passing
it an element the root bounds modifier
is a funny name but really what it's
saying is you can actually define a
margin so if you think of that green
block
on the right in a diagram there's the
red blocks which effectively say the
margin so i can express things like I
would like to know when this thing is
one and a half or half or whatever
viewports away which is quite nice
because if you're building something
like say a lazy loading section you
could actually say well I don't want to
start loading the assets when it becomes
when that section becomes visible I
would like to start pre loading them
sometime before and such that those
resources are actually done by the time
the user sees them so you can play with
this and we definitely welcome your
feedback because there's a lot of
different use cases that I think this
would make much much more efficient so
take a look at the speck there is bugs
for implementation open up Chrome and
I'm hoping to see it come soon because
it'll certainly be very helpful now
another funny thing i noticed so as I'm
watching the presentations this morning
I think I've figured out Paul's master
plan so a couple of summers ago or maybe
a last summit we started talking about
the requestanimationframe that you have
16 milliseconds to do all your work then
when Paul wrote his rendering course he
actually changed that number to 10
milliseconds so now we have only 10
milliseconds to do this work and then
finally today in his presentations he's
lowered a number again to eight
milliseconds so I think his master plan
is to just keep lowering it it's kind of
like gradually increase the temperature
or decrease the temperature but which
point at some like chrome summit 2020
it'll just like zero you're not allowed
to execute rafts at all all right and
that's it but more seriously this
actually does get to an important point
which is how much work can you do in 16
milliseconds and why is it that we say
10 milliseconds 8 milliseconds and
you'll hear five milliseconds thrown
around and the answer is frankly because
there's just such high variability in
the CPUs and GPUs and all the rest so
what runs efficiently on your particular
hardware may run slowly somewhere else
right and there's other subjects or
other criteria that may change this so
we're now actually seeing devices that
have small small and big course so your
application may migrate between a small
core which
a slower core and a big core just based
on what's the temperature what's the
battery what's what's the other
environment factor is around you so it's
really quite unpredictable and the
important part here is it's actually an
unknowable answer all right like we I
cannot tell you how much more he can
execute even if you ask me right before
because there are other things make that
make again the operating system made the
schedule us and another application may
want to run so it's really hard to
reason about and what you end up with is
a picture with a picture that looks
something like this right we have
different rafts and these are just
different scenarios right where we
execute some of a code and then the
browser has to do some work and
depending on what kind of operations
that you execute it the browser may have
to do different amounts of work so you
may have invalidated a huge section of
the page which means we need to repaint
and do some other expensive operations
or maybe you touch something that's very
efficient and it's all very quick and if
everything runs nice and if you follow
Paul's advice and you say great i'll
limit myself to 8 milliseconds and then
i'll be very careful about the kinds of
operations that are being executed
everything will finish quickly right and
then i know i'm guaranteed pretty much
that I'll get my smooth and solid 60fps
all the way out except there's another
problem here right like now we have this
unused time so really we're relieving
this time on the table this is time that
I've could have spent perhaps making my
applications better because of exit I
could execute better animations and do
more work right like if I'm running a
spell checker I could actually do more
work and do provide a better service to
my user so we kind of have this odd
trade-off right and there's no one
number that really makes sense so one
question to ask here is like how do you
even know when you're missing frames out
in the wild when when we deployed
applications today we have pretty good
tooling for getting thing for getting
data on the network performance but we
don't have any way to gather data on the
animation part and that's what brain
timing is all about effectively what
we're doing here is we're exposing this
concept of a frame which is loosely the
time between the two V sinks in a
browser and we want to capture that and
deliver that when
we exceed that budget such that you can
subscribe to it and get that back to
your developers right we're not this is
the important part here is we're not
exactly telling you why you're slow this
is the kind of data that you would get
them devtools we're just telling you
you're slow so you can identify that in
some part of the world when the
temperature is really high here are you
are actually missing wraps right sounds
kind of crazy but that's what it is and
once again you would use performance
observer to get at this data so you
subscribe to the new frame type and
periodically you would just get these
events that would give you the duration
of the slow frame so I say you can
aggregate it you can run your own logic
on it you could even adapt to it if you
want it because if you're consistently
getting these slow frames perhaps you
want to throttle your canvas or you're
something else and run it at a slower
refresh rate so this is both could be
both the runtime optimization and also
just making it back to analytics such
that I understand why and where this
problem is happening so i think this
this will be very useful so some
takeaways here intersection observer i
think this is going to be a very
powerful and a very big feature for many
different applications so i strongly
encourage you to take a look at the
explainer and give us feedback this is
this is the right time to give us
feedback and then finally a frame timing
API will definitely help as well for
identifying animation I don't idle
something that we've already kind of
talked about a little bit so let's dive
a little bit deeper this is that earlier
problem that are surfaced right we
execute our work in some limited amount
amount of time because we said we're
going to fix it to eight milliseconds or
less there's some unknown entity of time
that the browser will take to do its
work and it's really hard to reason
about what amount of time that will
actually take right like if you if you
constrain yourself to some fast
operations you can kind of guarantee
that you're not going to go like really
expensive but it's still hard to reason
but but then there's that chunk of time
left at the end right and and the better
performance you want to get the more of
that chunk is going to be left there
which is kind of unfortunate because
with likes we make use of it like that
this is a lot of time they're just being
left idle so we have this new API
requests idle callback and Paul already
talked about or some long and then go
into a great deal but effectively it'll
you to move some or all of your work
that is not critical to the actual
rendering out of your rafts and other
logic and into this these idle blocks
where you know that you're not going to
then blow the budget as long as you stay
within the provided deadline so this is
this is the kind of thing where you want
to be very accurate or very precise
about how much time I have left and make
sure that you don't overrun because if
you do then we're going to miss a frame
right so this definitely kind of thing
you want to avoid and Paul has a great
write-up with number of different use
cases for how to use it where to use it
and all the rest so I encourage you to
check that out and experiment with it
this is already available in chrome you
can start leveraging it and hoping to
see it another browser soon as well so
for response move your non critical work
into idle callbacks I think you've heard
the steam removing garbage collection
right we're removing scheduling and
delivery of these performance events
into idle and I think you're going to
find that we're going to be moving more
and more work into that such that we
unblock your application from doing the
critical work that it needs to do to
make everything nice and smooth and then
finally load right this is something
that of course we actually have pretty
good tooling for already but we're not
ignoring either yesterday we learned a
lot about some of the new and exciting
architecture primitives that we're
getting with service worker and in
particular this idea that you can now
take your entire critical path and move
it onto the device itself right so
instead of being at the mercy of the
network and at the mercy of the rtt you
can take your HTML your CSS and
javascript the things you need to
actually paint some pixels on the screen
put them right on a device that's the
app shell and make that visible
regardless of the network you're on or
whether you even have connectivity at
all so even if you're offline you can
paint those pixels and then put
something like a loading spinner or
something else to let them know that hey
I'm fetching content so I think this is
very very important but of course the
next question is I need to start the
worker right that also takes some time
there's there's another thread running
there's a maybe even many threads
because we have many different service
workers so we'd like to know how long
that takes and you can actually measure
this now so we've added the workers
attributes to resource timing and
navigation timing which allows you to
see if the worker was active you'll be
able to tell if it was active based on
the time stamps and also how long it
took to start the worker if this request
was blocked on starting the worker so
the difference between the worker start
and a fetch start if you're familiar
with those specifications would be the
time to start to work which is very
handy so this is already enabled in
resource timing in in chrome and we're
working on adding this to navigation
timing as well so I think this will be
critical for augmenting your existing
ROM analytics once you enable service
worker and then similarly you also need
the same kind of tooling and
capabilities within the worker itself
because now that your scripting a lot of
your fetches and other logic and put
then service worker you probably want to
move some fraction of your rom analytics
to live in a worker as well so for that
you need things like user timing which
allows you to specify custom metrics so
you can just put marks along the
timeline or measures which any time span
between two marks and also get the same
fidelity resource fetching data for
things like how long that the TCP
connection take and the DNS and all the
other components of making the request
so this is now also enabled in service
worker and you can start using it and an
important point here is we have resource
and user timing there's also the
navigation timing which is specifically
for the HTML document but navigation
timing is not enabled in worker because
from a workers perspective every fetch
is a resource fetch even a navigation
request itself like there's no
difference right you can get the same
fetch event so there are no plans to
enable navigation timing because
everything looks like a resource fetch
so if you're wondering that's why and
this is available in the worker today so
if you're running Service Worker
definitely enabled us so workers start
and resource and user timing and with
that I think we're at the end and thank
you guys
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>