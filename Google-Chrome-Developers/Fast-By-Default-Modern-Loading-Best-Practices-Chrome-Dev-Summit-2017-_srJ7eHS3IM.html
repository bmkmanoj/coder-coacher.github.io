<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Fast By Default: Modern Loading Best Practices (Chrome Dev Summit 2017) | Coder Coacher - Coaching Coders</title><meta content="Fast By Default: Modern Loading Best Practices (Chrome Dev Summit 2017) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Fast By Default: Modern Loading Best Practices (Chrome Dev Summit 2017)</b></h2><h5 class="post__date">2017-10-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_srJ7eHS3IM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey folks so today we're gonna talk
about loading performance on the web
mobile has changed everything it
challenges the way that we deliver
modern user experiences on the web and
the shape of success over the next year
is going to be whatever lets us ship the
least amount of code while still
delivering value to our user experiences
now what actually impacts loading
there's a number of things on mobile
that can impact it could be slow
networks it could be thermal throttling
parsing JavaScript cache eviction in
fact there are so many things that can
impact how slowly a page loads that we
simply don't have enough time to cover
all of them in a single talk today some
of the things that we've seen teams
successfully used to ship fast and
deliver fast experiences to included
things like shipping less JavaScript
down the wire caching effectively using
HTTP caching and service workers to be
resilient against the network
pre-loading critical resources but what
end goal are we actually trying to
accomplish using these best practices
well it's a lot to do with user
expectations now to talk a little bit
more in illustrate user expectations I'd
like to introduce you to Gary
so gary is trying to load up a webpage
on slow 3g on an average phone he's been
waiting a few seconds and he hasn't got
any meaningful content on there just yet
you can't even read the text of this
article just yet for Gary at this point
he's starting to question his life
choices he's wondering if he should have
tried loading this page up on a slightly
more capable device like a Tamagotchi or
maybe a fisher-price my first laptop or
maybe even an abacus poor Gary so
talking about you know expectations a
little bit more back in 2015 we
introduced rail a user centric
performance model real had this idea for
load where we tried to encourage folks
shipping down you know main content for
the page and under a thousand
milliseconds the reality is that on slow
3G that's really hard to accomplish but
it also doesn't talk too much about you
know this idea that loading is kind of a
journey and so over the last year in a
bit we've been focused on a newer set of
user Happiness metrics that culminate in
time to interactive this point during
the loading of a page but we think that
the user is probably going to be able to
accomplish useful actions things like
being able to tap around hit menus hit
buttons actually have something useful
happen so a lot of things we talked
about today are going to be focused on
this idea of improving time to
interactivity now Alex Russell says of
developing for mobile the networked CPUs
and disks are not our best friends the
reality is that as we shift more client
heavy architectures we can end up paying
for the things that we send down in ways
they are not always that obvious in the
traces that we see today as we profile
different teams sites Java Script ends
up being one of the heaviest costs that
we experience in fact the cost of
parsing Java scripts is quite heavy
here's a breakdown of the spread of the
time it takes to parse JavaScript on
modern devices of high-end devices at
the very top average devices in the
middle and then slightly lower end
devices all the way down this is for a
Meg of decompressed scripts take a look
at the Delta and how long it takes to
parse scripts on
very very high-end phone versus
something more average like the moto G
for that your users probably have out in
the wild we can zoom in on this we can
actually take a look at a real site like
CNN and if we compare the performance of
processing script on something like at
the the AAA 11 Bionic chip in the iPhone
8 takes about four seconds Moto G 4
takes an additional nine imagine how
long that's going to push out how
quickly you were able to get interactive
so there are still opportunities for us
to do better here
whenever you're developing a modern
mobile experience it's very important to
be testing on representative average
Hardware over the last year we've seen
some teams have success with the purple
pattern purple is a pattern that shows
you through aggressive code splitting
how you can actually get interactive
really quickly so it has this idea of
pushing the minimal code needed get
interactive if you try to render that
really quickly
you then use serviceworker 4 pre-caching
resources you don't have to keep going
back out to the network and then you
lazy load routes as they're needed this
is a pattern that's been used by sites
like we go and is baked in to modern
toolkits like polymer app toolbox and
pre act COI I wanted to take a
data-driven approach to explaining why
patterns like this are useful here's the
v8 runtime call stats this is basically
a granular look at where JavaScript
engines like v8 spend their time of 10
popular progressive web apps mobile
sites well we can see in orange is that
parse dominates in many cases the amount
of time that we're spending here and all
the way down at the bottom we see sites
like we go using the purple pattern
they're actually not spending as long in
parse and are able to get interactive
much more quickly so opportunities again
for us to try making sure that the
tooling that we use these days tries to
prescribe you best practices for
performance out of the box earlier I
talked about Chrome's cache hit I talked
about caching something that we haven't
shared before actually is Chrome's cache
hit rates this is what it looks like so
we here we have a breakdown of cache hit
rates for CSS JavaScript fonts and
images now we have memory an HTTP cache
shown in this table in most cases when a
web page needs a resource chrome starts
by looking it up in the memory cache if
that cache doesn't have it Chrome's then
going to go out to the network stack and
eventually try getting it from the HTTP
cache what we can see is that CSS has
got a relatively decent
hit rate take a look at JavaScript what
we can see there is that we've got a
pretty poor cache hit rate and it could
be for a number of reasons it could be
because we're you know pushing out new
releases way too often and invalidating
those cash JavaScript bundles it could
be because we just don't have decent
enough HTTP caching headers set so
opportunities for us to do much better
there now when it comes to being
successful at optimizing your load
performance we've seen teams have great
success by making sure that the entire
team owns performance as a topic and
setting performance budgets can really
really have a big impact here let's talk
about budgets for things like time to
interactive if we set a budget of about
five seconds or under for time to
interactive on first load and let's say
that we take a global baseline of a 200
dollar Android device on a 400 kilobytes
linked with a 400 milliseconds
round-trip time this can end up
translating into a budget of about 160
to 170 kilobytes for our critical
resources we can zoom in on this a
little bit more what we see is that
that's composed of a lot of different
things that budget includes your
application logic your framework which
could be anywhere between 4 to 40
kilobytes your ecosystem pieces like
your router your state management your
utilities and a question that you have
to ask yourself is how much Headroom do
these ecosystem choices end up leaving
you for your actual application code now
as you're trying to decide on these
things it's very important to carefully
evaluate those libraries those
frameworks that you're using when you're
trying to build from mobile take a look
at their network transfer costs their
parson compile times and whether they
introduce any additional runtime costs
like long tasks being added into the
page that can end up janking the user
experience so if you're trying to be
successful on mobile what we suggest is
this this is a good recipe developing an
average phone so that you can feel those
CPU and GPU limits keep your JavaScript
parse and compile time relatively low
and have a good performance budget in
place so five seconds for first load
under two seconds for repeat visits now
there are a number of good tools
available for performance budgeting some
that we've tried out and really enjoy
our caliber speed curve and bundle size
we've seen teams use these as well
many other tools like web packs
performance budgets with some great
success and if you're interested in
learning more about this topic Alex
Russell just published a really awesome
article on this topic where he asked can
you afford it
and he talks about real-world
performance budgets so check that out
let's let's switch it up and talk about
the health of the web as a whole now
over the last few years we've given you
good tools for understanding the state
of your performance in synthetic lab
conditions things like the chrome dev
tools lighthouse web page test as well
as suggested using rum for understanding
the performance your users experience
out there in the wild we've also given
you good tools for understanding trends
so things like HTTP archive so you can
take a look at how the web is
constructed and get insights like you
know what is the average size of the
images folks are sending down was the
median size of those types of resources
now if you've checked out HTTP archive
before you might know that it doesn't
include a lot of those modern metrics
that I was talking about earlier
it also doesn't include some of those
graphs that we were highlighting and so
today we'd like to change that I'm happy
to introduce a new version of HTTP
archive the HTTP archive beta this is
available at beta HP archive.org and I'm
pretty keen I'm pretty stoked actually
about this release because it gives you
access to a lot more data a lot more
power to get insight it includes things
like response bodies for CSS HTML and
JavaScript lighthouse reports for
hundreds of thousands of sites bring
feature counters there's newer
performance metrics and all of this is
queryable what does this mean for you
well it means that you were able to get
insights such as the state of JavaScript
on mobile so we can learn from this is
that at the 90th percentile sites are
shipping down about a megabyte of gzip
JavaScript decompress that's going to be
even larger when it comes to parse costs
and we're seeing the site's end up
spending four seconds parsing and
compiling that code our sites using a
mega of JavaScript up front what we
actually took a look at the top 50 sites
and using the chrome remote debugging
protocol the dev tools remote IO 2000
protocol we actually discovered that
most of those sites consistently only
used 40% of the code that they loaded
onload we also took a look at this 30
seconds in to the page and discovered
that the situation didn't really change
and what this highlights is
opportunities for us to be shipping less
Java
down to our users taking advantage of
patterns like code splitting and it's
ensuring that we're reducing our network
transmission costs as well for these
types of codes we can also take a look
at the state of the web on mobile and we
can see at the 90th percentile sites are
shipping down almost five and a half
megabytes of resources 70% of this is
images so still opportunities there for
us to be compressing things better using
things like Moz JPEG or WebP each reduce
how much we're actually sending down
over the wire and we can also take a
look at web speed metrics like time to
interactive and at the 90th percentile
sites are taking 35 seconds before
they're interactive that's 30 seconds
longer than the budgets that we're
prescribing today so we still have some
work to do there if we don't want to
make Gary sad
so that's hey cheffy archive beta the
reality is that out in the wild
demographics can vary pretty wildly for
your real users some users are going to
have a crappy device some are going to
have a crappy network and your
competitors may have a faster experience
than you do
wouldn't it be useful if we had
something like HP archive but which gave
us queryable rum for the web now to talk
about a new initiative here that's going
to help I'd like to introduce to the
stage ilya grigorik and brian McQuaid
alright thanks daddy hey folks so as I'm
sure you've experienced yourself
scanning the headlines on any given day
it's inspiring to see examples of well
off to my sights delivering great user
experience but at the same time there
are also definitely pockets on the web
where we all know we need to do better
and honestly sometimes it's a little bit
hard to tell looking at the headlines
whether we're making progress overall on
the web are we improving the user
experience and therein is actually one
of the big challenges that we've have
both as site developers and browser
developers how do we understand the
macro trends of where the web is heading
how do we find examples beyond just the
great examples that we're highlighting
here at CES of great user experiences
and that we should learn from and
similarly where do we focus our
attention to improve the overall
experience on the web so to address that
question
we're actually announcing the chrome
user experience report today which is a
public data set that we're hosting on
bigquery and the data set provides a set
of key user experience metrics and
initially we're focusing on loading
performance and of course addy mentioned
a lot of other metrics and we're hoping
to add more or more metrics in the
future the report will also provide a
sample of 10,000 origins which is
something we're also hoping to improve
in the future and I know what you're
thinking show me the data
so let's actually take a look at the
schema so first of all a high-level
overview the report itself is aggregated
by origin and keyed by origin so you'll
have example.com and we're providing two
key dimensions that we found to be
critical when actually working with this
data ourselves the first one is a form
factor so you can segregate this data by
tablet phone or desktop second one is
the effective connection size which is
determined by the network information
API and this one is actually powered by
a real user measurement data based on
the round-trip time and the download
speeds on the client so you can tell if
the connection is fast or slow based on
the actual user experience you can be on
Wi-Fi connection that can feel very slow
and it will say so in this case and then
finally we have a set of metrics and as
I mentioned we're focusing on loading
metrics to start so we're start
with the four that we have here first of
all the paint API so first paint in the
first content flipping getting stuff on
the screen is important just to give
user perception that stuff is happening
and of course don't content loaded and
unload defined by the HTML standard so
those are four metrics finally we have
the actual histograms so all the data is
split into time slices and each slice
has a start and an end and a density
value which is the fraction of page
loads that fall into that range and with
that I'll let Brian pull back the
curtain a little alright thanks Julia
I'm Brian McQuaid I'm a software
engineer at Google and I work on making
chrome and the web faster so let's dig
into the data in the bigquery table for
the chrome user experience report will
you know see what kinds of questions we
can answer and what kind of insights we
can gather from digging into the data so
here let's take a look at here's our
first query we'll look at a few queries
and work through things here in the
bigquery web UI and so what what we're
doing here is this query will help us
answer the question what percent of page
loads on the dub-dub-dub google.com
origin results in a fast first content
full paint and so we're defining fast
first content full paint here as a first
content full paint that happens within
one second if you've seen some of Ilias
past talks or you're familiar with jakob
nielsen's work you may know that you
know one second is that threshold of
time where a user has their train of
thought typically interrupted after that
point right so ideally we'd like to keep
as many of our page loads under that
threshold as possible so let's go ahead
and run the query and see how we're
doing so here we can see at the bottom
we've got our results and we can see
that 81% of the loads on dub-dub-dub
google.com are below the threshold so
generally we're doing really well here
which is great so let's take a look just
at a couple pieces of the query so first
you know here we've got the name of the
table or query and so this is the chrome
user experience report table for 2017
October is the initial release
we're querying the first content full
paint metric and what we're doing with
that metric is we're summing all of the
density values that Ilya talked about
for the histogram bins for that metric
but only where they represent samples
that were recorded in less than a second
or less than 1000 milliseconds all right
so there's that query let's drill down a
little bit one of the things you know
we've talked about that the data set
enables is also drilling down on certain
dimensions right so let's take a look at
performance broken down by phone versus
desktop for Google News so here we've
got our query we're gonna update it to
group by and aggregate on form factor
which breaks up by phone and desktop we
do have to add a little bit extra to the
query here because since we're no longer
aggregating at the origin level we have
to normalize so we're sort of dividing
the bins that meet our goal our
threshold by the total bins and the
aggregation criteria and you can learn
more about that in the documentation but
let's go ahead and we'll dive in and run
this and let's see how we're doing
broken down by phone versus desktop and
so we can see here that you know well I
desktop we're doing reasonably well
right
almost half of page loads are completing
under our target threshold our fast
threshold we've got a little bit of work
to do it looks like on phone right so
this breakdown really helps to give
insight into differences in performance
right between phone and desktop and we
see this pretty commonly for origins on
the web right so we definitely recommend
that as you're digging into the data and
analyzing origins you do these kind of
breakdowns to see if the performance
differs in the two dimensions or in the
two phone and desktop breakout all right
so one more query one of the things that
the chrome user experience report
enables us to do is to compare
performance across different origins so
let's finish up with an analysis of the
google.com origins in the data set right
so we've got a wild card query here and
we can run that and we get more data and
here because we're sorted by you know
fastest we can see sort of our fastest
performing origins at the top of the of
the set here and then if we were to page
through the data we would see areas you
know where we can improve as well so so
these are the kinds of insights that the
data set enables we definitely encourage
you to dig in and see what you can find
and share feedback with us to let us
know
how we can make it more useful and the
last example that Brian gave here is
actually a great demonstration of the
underlying power of the data set where
you can actually look across the web and
figure out what are the trends how is
the user experience changing and let's
go to the next slide here going
backwards but one of the things that we
discovered as we've been looking at the
data set itself is you have to be
careful when you're working with real
user measurement data because the
population of users that visits the
website actually affects a performance
which should be intuitive but just as an
example I can have a small site that is
visited by users that happen to be on
fast Hardware and on fast networks and
the site may not be well optimized might
in it may appear fast and vice versa you
can have a big service let's say Google
News which is visited by a very diverse
set of users with a wider distribution
of hardware and on slower networks and
that will be reflected on the data so
when you're comparing origins you should
be careful with drawing conclusions and
kind of try to control for those things
so as Brian mentioned we document some
of these best practices in our
documentation and on that note to get
started please check out our blog posts
which has more details on the
announcement and how to access the data
set and it has a link to the developer
Docs which have a walkthrough guide for
how to get started with bigquery if you
have not used it before plus some sample
queries that you can run similar to what
you've seen here and you can start kind
of getting a feel for the data itself
and with that I'm too free keen to see
what you guys will build with this data
and let's welcome Maddie back on stage
thank you
so that was the chrome user experience
report as a browser what's chrome doing
to give you as developers more power to
control your loading experience well
over the last year we've been working on
a few new features the first of these is
font display which we introduced in
chrome 60 and is now available as a
work-in-progress in Safari and Firefox
font display as a descriptor allows you
as a developer to decide how your web
fonts are gonna render or fallback
depending on how long it takes for them
to load I personally love using font
display optional because it basically
says if a web font can't load quickly
don't load it at all if it happens to be
in the user's cache the next time that
they come and visit the experience we
can then consume it but otherwise we
don't end up blocking for it you've also
asked for the ability to adapt the
content you served down to users based
on the estimated network quality now
Chrome's had the network information API
for a while but it kind of only provided
you theoretical network speeds imagine
being on Wi-Fi but connected to a
cellular hotspot and only getting 2g
speeds well navigator connection type
would have effectively given you that
would have told you that you're on Wi-Fi
and we'd end up shipping you down a much
much larger video file in this case over
in chrome 62 we introduced effective
type newer property and this uses the
new network estimation quality work that
we've been doing in chrome this uses RTT
and downlink values and effectively what
this allows you to do is get a much
clearer picture on the actual effective
connection type that the user has so you
can make sure that you're giving them a
slightly more accurate representation of
data that their connection can handle
for many of us in this room we're used
to building single page applications and
our waterfalls can end up looking a
little bit like this we push down some
HTML which then requires some JavaScript
to be fetched before we go and you know
query an API for some JSON responses now
the way that we've given you to control
a little bit more of your loading in the
past backing from 50 is link rel preload
something that's making its way to other
browsers and this basically allows you
to tell the browser that there are they
discovered resources that are pretty
critical to your experience and can it
try loading those up much earlier on now
in Chrome
up until chrome 62 you were able to use
the fetch API with this general goal of
preload once again and starting the load
of that resource without having to wait
for the timing for scripts or elements
to request them and you can now use this
consistently with the fetch API as well
so fetch API and preload work together
now and for folks that have been
building progressive web apps there have
been some situations where your
serviceworker boot up time can end up
delaying a network response navigation
preload something that we introduced in
chrome 59 allows you to fix this by
allowing you to make the request in
parallel with your serviceworker boot up
time so in cases we are particularly
slow connections and slow devices you
can end up with you know a few hundred
milliseconds delaying overall
serviceworker boot up this can now
improve things and at the 95th
percentile our current estimates are
that this can end up saving folks
anywhere up to 12 20 percent on their
page load time so exciting work being
done there what's up for the future so
we're working on a few things we're
working on trying to improve the
performance of our es modules
implementation today you currently still
need to bundle for most cases in
production on the serviceworker front we
are working on off main thread fetch and
script streaming and we're also working
on a new navigation architecture for
loading that should hopefully lead to
some improvements in time to first
content full paint over the last year
we've talked a lot about progressive web
apps and how in many cases they're
becoming the new normal for new mobile
web experiences and today we've got some
new ones to share so please join me in
welcoming to the progressive web app
family two new sites
so let's start off with Pinterest
Pinterest spent three months building
out the logging experience for their
progressive web app which is now rolled
out to 100% of users this started
because they were focused on
international growth and when they took
a look at their old mobile web
experience which often pointed folks the
native app they discovered that not as
many people were actually clicking
through and installing that which made
you know it kind of made sense for them
to explore mobile web is an opportunity
for improving their conversion rates so
they ended up building this experience
it didn't take too long to get the
initial version out this is based on
reacts react Redux and react router web
pack I kind of love Pinterest
I'm a heavy Pinterest user myself it
allows me to take a look at some really
beautiful crayon arts that people end up
creating and it also saves me time
because it shows me what my version of
this would also look like so I don't
have to do with myself Thank You
Pinterest taking a look at the
performance of the old Pinterest site
well we can see on first load is that
they used to get interactive in over 20
seconds it would often take 23 30
seconds before you could actually
interact with those pages and start
saving your pins I'm happy to say that
with the new progressive web app
experience that they've just shipped
this changes quite a lot they're now
able to get interactive in under 5.6
seconds so really nice boost there
they've also managed to drop down the
sizes of their JavaScript bundles all
the way down to 150 kilobytes they've
reduced the sizes of their CSS bundles
at the 90th percentile the time it takes
to load up
pin pages is also down and on repeat
loads thanks to serviceworker caching
they're actually able to boot up and get
interactive in under 4 seconds on
average mobile hardware which has been
great to see and we can compare this to
some of their native applications as
well so this isn't necessarily an apples
to apples comparison but I will say that
for the core home feed experience what
you're able to get in under 150
kilobytes is reflective of the same
experience delivered in 56 Meg's
of their native app on iOS 9.6 Meg's on
Android now you could say that yeah as
you
you know navigate through this
experience you are going to end up
fetching more data but this cost is
amortized over the lifetime of the
application as those subsequent
navigations don't end up costing quite
as much data as the native apps do we
can take a look at the business metrics
off the back of this and I was quite
happy to see these as well we can see
comparing the old mobile website to the
new PWA is the time spent in the
application is up 40% user generated ad
dollars are up by 44% core engagements
are up but we can also see compared to
the native app the time spent is also up
in the PWA compared to that baseline as
well as user generated ad dollars if
you're a developer like me you probably
care more about their JavaScript serving
strategy so let's talk a little bit
about that Pinterest are using an
interesting bundle splitting strategy
where they have a vendor trunk which is
used for their framework and library
codes their reax the redux to react
routers we have entry chunks for their
core logic and then they have a
synchronous chunks for anything that's
lazily loaded in later on their web pack
configuration looks a little bit like
this it's using the Commons chunk
plug-in they maintain a list of all the
different frameworks and libraries that
end up getting you know squashed into
that vendor bundle they're using things
like react router for their overall code
splitting and lazy loading story so in
this case they're using web packs magic
comments they're creating a loader
registering it to a particular pin route
rendering the route with react router
for a synchronously loading route
bundles but pure components as needed
and rendering components as their nests
needed which it's been cool to see
something of a trend that I keep seeing
with teams that we work with is the
value that they've gotten out of closed
bundle analysis so this is what their
web pack bundle analysis output looks
like and well you can notice in the
Purple's the blues and the blues and the
pinks is that this represents a
synchronous chunks of code that included
some duplicates so they had duplicate
logic across a lot of these different
chunks and through using webpack bundle
analyzer they were actually able to
discover opportunities where they could
move a lot of that common code all the
way into their entry chunk which
increase the size of that chunk by 20%
but actually decrease the size balls the
a synchronous chunks by anywhere up to
90% it's really great to see
on the serviceworkers front they were
able to explore a very iterative
approach to adopting service workers so
they initially started off by just
runtime caching a synchronous chunks of
JavaScript so that they could be opted
in to v8 s-- bytecode cache they then
moved on to doing this for vendor chunks
their most popular routes there are
global sites they also do this for their
locale bundles and eventually they ended
up using the application shell pattern
and a cache first approach their
JavaScript and CSS now Pinterest are
planning a few other additions in the
future they're working on web push
notification support trying to fix some
desktop error decisions that led to some
slower API responses than they'd like
and also adding link rel preload in for
pre loading their JavaScript bundles
next up we've got tinder so tinder
swiped right on the mobile web which was
cool to see the Edit support for things
like service workers adds a home screen
push notifications for chat and the
original MVP of this took about six
weeks to build out and then three months
to actually initially launch this has
been something they've been building as
an opportunity to explore other markets
and it's also built on react and redux
it's rolled out globally two-hundred
percent of users right now and initial
signs are positive also taking a look at
sort of the amount of code that's
necessary to ship down their core
experience tinder are able to deliver
that core experience and about ten
percent of the data investment for
someone in a day to costly your data
scares market compared to the Android
native app so metrics at the moment are
looking positive and I'm looking forward
to tinder seeing a few more concrete
details about this in the near future
let's take a look at their performance
so some lighthouse reports before they
started work on this they were getting
interactive in about seven point seven
seconds after it they managed to shave
off about one point five seconds and one
of the ways that tinder accomplished
this was by adopting some really really
concrete performance budgets remember we
were talking about the importance and
the need of performance budgets earlier
on and so they have performance budgets
for all their different types of chunks
they have a 155 kilobyte budget for
their vendor trunks so they're their
framework code as synchronous chunks
also have a budget as well as CSS the
approach that they took to code
splitting was moving away from
statically importing in everything in
one go
/ - using things like react router react
loadable and the commons trunk plugin so
they were only including in code that
they needed when the user would actually
need it they also took advantage of
react loadable support for pre loading
scripts and this just meant that there
were opportunities to preload in scripts
for additional views so that they were
probably in the cache when the user
needed them in a future point in time
taking a look at the impact of this
adopting code splitting for tinder ended
up taking load time from about 12
seconds all the way down to four point
six nine from their Google Analytics we
can also see that the average user is
able to load up this experience in under
six seconds which is a lot better than
the older experience that they
previously shipped tinder also adopted
link rel preload they previously had a
situation where some of their scripts
were being loaded early on some of them
were being discovered late and so using
link for a preload they were actually
able to push all of this work much much
closer to parse time and this actually
able gave them an opportunity to reduce
first paint by 500 milliseconds and lo
time by one second we were talking about
wet packed bundle analysis earlier and
tinder were no different they actually
found great value in closely looking at
their dependency graph for areas of
opportunity to reduce they found that
they were shipping down a lot of unused
polyfills and so they used babel preset
end to address that situation they used
low - web pack plugin to strip away
parts of low - that they didn't actually
need to be shipping down to their users
they replaced local forage with raw
index DP as well as a number of
optimizations for CSS that and a whole
actually dropped download time
furthermore at this point in time - 4.5
seconds they also adopted a CSS loading
strategy so they now use atomic CSS to
create highly reusable CSS styles and
the idea here is that most the style is
or if most the Styles already been sort
of fetched and it's in the net of the
HTTP cache then you can cache it for
longer and it doesn't have to be
refreshed for every release because
you're doing it a much more granular way
so this also led to decreases at that
point in time in overall page load time
which is awesome and finally well almost
finally they updated - web pack 3 very
recently and saw a reduction in Java
parsing time of 8% so they're using the
module concatenation plugin and there as
well they also recently updated to the
latest version of react react 16 and saw
a reduction of almost 7 percent in their
vendor chunks sizes we're gonna be
talking a little bit about work box in
the next talk but tinder were also using
work box for their offline caching their
service workers story jeff posnick is
going to talk a little bit about this in
his talk but that's it for tinder
improving performance is a journey it's
not something that you just do in a
single sprint and then leave alone it's
something that you iterate on over time
and lots of small changes can actually
end up leading to large gains what I'd
like you to take away from this talk is
not like going back to your boss later
on today and saying I sat through three
thousand addy slides and now we have to
rewrite everything instead if you're
starting a new project just consider
picking a set of tools that give you a
strong performance baseline and if
you've got an existing experience that
could use some work
just remember mom measure optimize and
monitor because there are probably
opportunities there for you to do better
than the baseline that you're shipping
to users today on mobile that's it for
me I hope that you found this useful
thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>