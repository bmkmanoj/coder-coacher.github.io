<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Loading on the Web (Chrome Dev Summit 2017) | Coder Coacher - Coaching Coders</title><meta content="The Future of Loading on the Web (Chrome Dev Summit 2017) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of Loading on the Web (Chrome Dev Summit 2017)</b></h2><h5 class="post__date">2017-10-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DKyHVGh666s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone my name is Sam ciccone
you may know me a little better like
this
this might seem more familiar but Here I
am it's a pleasure to see everyone and
hopefully it's alright seeing me so
today we're going to talk about the
future performance on the web and a look
into performance patterns that will be
coming to the platform soon hopefully
I've never been so excited to be a web
developer in 2017 we have all these
amazing primitives at our fingertips
from WebGL from serviceworkers for
offline to web USB to interact with
physical devices that we can plug into
our computer we have so many ways that
we can express ourselves on the web like
never before but as Eric put Sowell
chrome chips a lot of features in the
past four years it's shipped over a
thousand features in chrome and if
you're like me I get a little
overwhelmed all these new things coming
at me all these blog posts about new
things that I can do and I lose track of
what's coming up because I can barely
keep track of what's already landed so
before we go into talking about
performance I want to make sure we have
a common language that we can use when
talking about performance so let's zoom
out and think about performance in three
primary colors we have our network bound
operations our parse and execution bound
operations and finally our render bound
operations you can think of network
bound as when you go to a web page you
have to download some files and how
those files get to you is important
because the facts are they get to the
user the faster that you can actually
run them when we finally get those files
and run them we enter into this phase
where the files are being evaluated and
executed and how they are run impacts
our user experience and impacts how fast
we can get things to the screen and
finally when our files have run we drop
into a renderer phase where the page
takes all the side-effects of our
operations
and paints them onto the screen so to
start I want to talk about bundling
performance bundling performance is
bundling your files together and getting
them to your user over the network and I
want to take a look at some future
patterns which are going to kind of
question our common best practices apps
today kind of look like this if you've
shipped an app or looked at the network
profiler when you've loaded an
application you might see this sort of
shape you have an application bundle a
vendor bundle and a style it's that CSS
and these are the combination of all
your individual files compiled together
if you've read any sort of performance
blog posts or books it will always say
you need to bundle you need to be
combining your assets together before
you ship them to your user because it's
going to get the assets to your users
faster because they're not going to have
to round-trip with the server over and
over again however this approach has
some performance downsides that not too
many people talk about let's consider
the following situation our application
bundle has page one j sfh to j s and a
common J's file that's required in both
our vendor bundle and our application
bundle for these bundles to be valid
think of these like string utilities
something that's required in both files
to even run and in our Styles file we
have our individual CSS files rolled up
into one single bundle but we have this
common J's file that's shared so this
means that when we change a single
bundled file so comment is all dependent
bundles are invalidated and validated is
a fancy way to say that the browser
needs to redownload them because now
when I load the page for the second time
the browser will say app bundle has
changed vendor bundle has changed so I
need to refresh them from the network
redownload them reevaluate them reparse
them and finally execute them so a small
change like an update to your strings
that J s file and command J s might
cause all of your files to be
invalidated and that's and the sorry
downloaded which will cause
a negative impact for your end users
ideally something that we want to avoid
so i postulate what if our applications
looked like this some of you may already
be doing a form of this where you're
shipping
assets based on route where you're using
something like react router and web pack
to do route based splitting but I want
to push it a step further and say what
if we took our individual routes and
also our individual libraries and
started shipping them independent of
each other so page 1 page 2 modal
library framework and all of our CSS
individually as well
now when you would go and make a bug-fix
to page 2 that Jas instead of your
entire bundle having to redownload you
only need to redownload one single file
not these entire bundles meaning that
when your user reloads the page they
already have the majority of the assets
in their cache and do not have to
round-trip for those assets now when we
ship granular assets there are some
other interesting wins that come along
with that so let's walk through what it
looks like to load a single javascript
file when we load a javascript file we
first have to download it from the
network the JavaScript file once we have
it enters into this parse phase where
the JavaScript engine has to take this
textual representation of your code and
turn it into a shape that the browser
can understand once it has that parse
phase done it drops into a compile phase
where it takes that parsed structure and
compiles it into a machine and
platform-specific binary format that
then can be run in v8 or in your
JavaScript engine of choice so we start
shipping granular assets this means that
our initial download gets saved on
repeat loads because we have that asset
locally and cached we then have to still
do our parse compile and execute phase
but we have a significant savings
already now wouldn't it be nice if there
is a way that we could get around this
parse and compile phase which is
non-trivial for large scripts well it
turns out that v8 is smart and does some
fancy optimizations when you reload a
script in
time's v8 will say hey I've seen this
page one that Jay asks multiple times
now and I'm going to take the parse and
compile work that I've done before and
reapply it back to this file so it can
cut down the amount of time that your
JavaScript engine is spending in parse
and compile because it reuses the work
that it's done now on average this
yields about a 40% reduction in parse
and compile time and this is across all
sites now you can think of this number
as an implementation detail in v8 this
number is only going to rise and I know
the team is actively working on driving
this down but by shipping granular
assets we opt into the savings whereas
before we were invalidating entire
bundles we now invalidate single files
which means that the engine can reuse
the logic that it has to reapply parse
and compile onto the same file so with
all these optimizations we end up saving
a non-trivial amount of time when
redelivery assets to the user on second
third fourth reload so the good news is
today it is possible with script type
module to load completely unbundled code
via es2015 imports script type module
and you're good to go
chrome engineers recently kind of put
this to the test they asked the question
well what would it look like if I went
all in and loaded all my code completely
unbundled so they took some popular
libraries like moment J s and 3j s and
tried to load them without having any
compiler phase and what they found is
that when you unbundle everything it
gets slower unfortunately in the case of
moment J s which this graph is from the
perf gap was over a hundred milliseconds
of loading moment J s which is hundreds
of files using es2015 imports as
compared to bundling not minifying in
this case just bundling the files
together so this is kind of
disappointing as a developer right now
and it kind of leads into the fact that
delivering granular assets and ensuring
good performance is tricky / not really
possible to do today so why are we
talking about granular asset loading
well it's because I want to talk about
where we're going and some of the
performance patterns that are going to
be unlocked on the platform soon in the
examples that we've talked about we've
sort of looked at loading all the
individual files upfront and paying that
cost and in that case bundling makes a
lot of sense however would it be nice if
in the browser we could have some
information about what the current state
of the client is before we send off
those requests so we can intelligently
choose what to request and when to
request it well this brings in this
feature that has landed in chrome for
dynamic imports
dynamic imports is j/s code loading on
demand in the browser this looks
something like this
we have a import here that uses a
familiar import syntax that can load a
file it returns a promise one that
promise is resolved we have that module
that has been loaded in the browser
inside of an if condition here which is
the interesting part and then we execute
run which is an exported function from
that model now dynamic imports are cool
but that
didn't really show their full potential
so I'm going to lean on another new API
that's the network information which
you've heard about a little bit already
the network information API allows you
inside of the client to determine the
runtime conditions so that you can then
choose how you're going to fetch your
assets so we can look at things like
type download round-trip time estimates
download max an effective type to figure
out what is the correct solution for
this specific client
so using that primitive + dynamic
imports we can come up with a dynamic
loader a bit of code that can determine
should I be downloading a bundle for
this client or should I be downloading
granular assets and thus getting that
repeat page load performance gain that I
get from granular assets so we're saying
if the round-trip transit time is over
500 milliseconds go ahead and download
the bundle because we don't want our
users to pay the cost in this case
otherwise drop into granular assets
because we want that repeat page load
performance so with client conditions
and dynamic imports we can start
delivering optimal performance across a
multitude of client conditions so one
case or one one solution won't have to
fit every one of your clients so we've
talked about loading now I want to talk
about the next phase that your browser
drops into and it's once you have these
assets getting to interactive faster so
painting what's important for your users
on the screen as fast as possible I
think that we are at sort of a loading
inflection point on the web we're moving
from a world where the client has been
initiating fetches to a world where the
server will be pushing us assets we are
moving from a world where the browser
discovered all of your assets to you as
a developer are able to declare your
assets upfront without your browser
heavy having to read all the files and
finally we're moving from a world where
assets have inferred priorities about
what's important and what's not to
explicit priorities that you as a
developer can say what's more important
than something else
the first part of this is cash digest
with HTTP to push now I've been a vocal
critic of HTTP to push and saying that
it is a foot gun that can get you into
trouble
however this proposal sort of course
corrects and gives us a new primitive
which will allow us to get around one of
the major problems which is over pushing
so consider the following situation
imagine your client is repeating a page
load on a web page and for that page the
server says you're loading index.html
I'm going to need assets A through F I
know you are because I'm the server I
know exactly what I'm going to be
sending you but the client already has
assets a through D locally so the server
pushing assets viii or D would result in
an over push occurring so wasting
network resources to send these assets
that the client doesn't really need so
in this case I call this over pushed
it's unnecessary cache digest would
enable a client to tell the server
exactly what it has in its cache so it
would be able to say as soon as that h2
connection is opened hello server it's
nice to see you here's what I have in my
cache whatever you do don't send these
files to me because I already have them
and the server would say ok cool I see
that you have a through D here are ENF
go on have a great day so in this case
we are no longer over pushing and the
user has a faster load in experience and
this is one of several solutions this is
just a proposal but there's a lot of
people working on this which I'm excited
about so this brings us into the next
phase when it comes to delivering assets
not all assets should be treated with
the same priority what does this mean
well it'd be great if I as a developer
was able to hint to my browser exactly
what was important and what was not and
we can do this via a proposal for
priority hence explicit priorities
versus inferred priorities think of your
browser's sort of like a gigantic
inference engine it loads an index that
HTML file it scans through the pay
it looks at the position of your script
tags of your images of your CSS and it
says this is critical to the page this
is not critical to the page
this seems medium priority but because
it's an inference engine it doesn't
always do the right thing when you as a
developer know exactly what you want it
to do so priority hints give you as a
developer explicit control over what you
load and how you load it now before we
had to do some kind of silly things to
hack around priorities where we would
use a link rel preload tag to force an
async script to load as high priority or
do something even crazier like use an
image tag to load a javascript file that
we were dynamically important to the
page on air kind of strange stuff but
hacks more or less priority hints give
us a path to remove these hacks and to
opt in to this explicit performance path
so let's take one of my favorite sites
my my favorite hat site so this site has
three images or two images in a
javascript file no I want my users to
always see my favorite hat first so what
I'm going to use is use resource
priority hints to use a syntax of group
to say I want you to download my
favorite hat first and once that's
downloaded go ahead and download cool
hats gif in the background and hat store
dot J s in the background because the
most important thing for users to do
when they load this page is to see my
favorite hat I could care less right
away about my cool hats showing in my
store now this proposal goes a step
further and it's not just for image tags
and script tags but it's also for
fetches so this means with a fetch you
can set the priority of a fetch so that
it doesn't cause contention in your
network stack for low priority fetches
so consider you had a long pull
operation that paying the server every n
seconds wasn't really important didn't
need to happen right away you could set
the priority for that fetch as low and
offload that work from the critical user
story around your network
next async images basic images is a
intent to ship proposal from chrome that
unlocks the explicit control over image
decoding and allows you as a developer
to move images outside of your critical
path what our async image is why would I
want this okay well let's look at this
example we have a very large image and
then we have a JavaScript file so what
can happen in this case is our image
starts downloading on top our script
starts downloading on bottom our image
download finishes before our script the
image goes into this phase of decode and
a decode of an image ties up the main
thread that means that it actually
blocks that script from dropping into
parse compile an eval so it pushes out
when that script runs so I'm guessing
that your website maybe an image isn't
as important as delivering your
framework to actually show the page so
this seems undesirable with the async
proposal we'll be able to work around
this we'll be able to free up the main
thread from the image decoding overhead
so we would mark this image as async and
now our waterfall looks like this we
download our script file we download our
image file the image says hey I have an
async attribute I'm going to defer the
decoding of this off the main thread off
the critical or it's still in the main
thread but it's off the critical path
and then the script is going to say I'm
ready I'm going to drop in to parse
compile eval and once my critical main
path story has been completed the image
is going to go into a decoding phase
which is going to unblock the rest of
the interaction on your page ok so we've
talked about bundling and delivering
assets and making sure those assets are
to our users when we want them and
things are executing in the order we
want but we still have the entire
runtime phase of our web app so our
assets are running our page is now
interactable but we want to optimize the
actual runtime of what's going on under
the hood so I want to talk to you about
how to move work out of the critical
path
and how to do more work without
impacting user experience this brings in
my friend web workers now web workers
are not service workers web workers are
a utility that you can think of as
friends that you can give JavaScript
tasks to that will run these tasks and
keep your main thread responsive because
your main thread is concerned with doing
other things so imagine our browser here
in the middle and it has all these tasks
that are coming down react to user input
download this script file calculate pi -
10 digits okay doing them doing them
great but then our page starts to get
overloaded we ask the browser to do more
than it can keep up with and this
results in jank we've all had the
experience where we load a page and try
and interact with it nothing happens
we're tapping and nothing's loading and
all of a sudden everything snaps in this
is because your browser was overloaded
in trying to catch up but with web
workers we can take these tasks and hand
them off to our web worker friends and
the web workers will execute these tasks
for us and then pass them back to the
main thread when they're done this
leaves the main thread open and
available to react to user input to take
care of the critical tasks that the
browser needs to do to make sure you
user experience is great so I made a
demo to illustrate exactly what's
happening here all this demo is is I'm
moving a rectangle across the screen in
canvas I'm doing it on the main thread
on the top and then a worker thread on
the bottom and I'm passing just an array
buffer for the screen or for the canvas
back to the main thread to draw this we
can see that the worker thread goes
quite a bit faster than the main thread
and why is that well it's because the
main thread has a lot of stuff to do the
main thread has to render all this the
main thread has to react to user input
the main thread has to keep track of a
whole bunch of stuff but my worker
thread all it's concerned with is move
the box by one pixel move the box by one
pixel and because it's focused on just
one specific task it's a lot it's able
to do that a lot faster but as web
developers we
find ourselves working with the Dom
often and basically always working with
the Dom and if you've looked at web
workers at all you may have noticed that
web workers don't have access to the Dom
which is painful as a web developer and
makes it seem like it doesn't quite fit
but I'm excited because there are some
proposals in the works to lift this
restriction to make it possible to do
Dom manipulation in a web worker Dom
change list is one of these proposals it
enables the construction of Dom
operations in a web worker that can be
backed by an array buffer so you can use
that array buffer to transport the Dom
operations the Dom operations in between
the web worker and your main thread so
what does this look like well here's the
API it looks familiar but new we
construct a Dom change list
we then batch up a bunch of mutated
operations and then we apply those chain
apply those changes from the Dom change
list you can think of this like a
transaction on a database where it can
be accepted or rejected now this is
really interesting in a web worker
because as I said this Dom change list
can be backed by an array buffer and
array buffers are very inexpensive to
send in between the main thread and the
worker thread and back and forth so
imagine that you had a library that had
to do a lot of Dom diffing well that Dom
diffing could actually take place in a
web worker freeing up your main thread
to be still responsive while calculating
what it needed to update and then
finally post messaging that new mutation
set out and applying that to the
document on the main thread now sharing
messages as I alluded to earlier between
a worker and the main thread is a little
different than you might be used to you
have to use message passing or post
message but post message has a slight
overhead so for applications that have
chatty needs meaning you have to go back
and forth a lot post message can
actually get in the way but there is a
proposal that has shipped in chrome and
several other browsers that sort of
unlock this limitation shared array
buffers
this is a scary thing to say in a room
of developers it's mutable shared memory
meaning multiple threads and multiple
processes can mess with this memory at
the exact same time and stomp all over
each other
it's scary let's just avoid that for now
but let's talk about what this unlocks
well here's what it looks like if we
were to use it we can allocate a shared
array buffer we can post message that
shared array buffer into our web worker
and start acting on it but unlike
regular array buffers the shared array
buffer in this case refers to the same
thing it doesn't pass the whole array
buffer into the worker and then pass it
back out we're creating a direct link in
between our worker and our main thread
what does this let you do well I made a
silly demo where I count up from 0 to
10,000 on the top one I'm using post
message to post every single time that I
mutate my counter so I have 1 2 3 post
message post message post message and
the shared a rougher array buffer case I
don't have to use post message because I
have I have the data that shared in both
places so I'm able to simply read from
that shared array buffer think of it
like my shared array buffer is a model
and my view in this case just reads from
that model whenever I want to so I'm
able to work around the post message
overhead which roughly translate to
about 10 milliseconds per message now
normally post message is great it works
fine but in applications where you need
to be super fast and you need to make
sure that the data can go back and forth
really quick shared very buffers might
be your answer now you may be thinking
web workers seemed really great they
seemed super powerful but I don't want
to have to write a framework that
utilizes web workers because it seems
tricky and difficult and I would agree
with you share array buffers and web
workers are very hard to grasp concepts
and hard to translate into normal web
development use cases but luckily for us
frameworks have already started taking
these low-level primitives and applying
them at a higher level in their
works pre-act is one example pre-act
actually has a demo where they're able
to do most of the work inside of a web
worker so this is this works today it's
pretty amazing I recommend that you
check it out a library from the Google
Chrome team called comlink has a pretty
advanced idea where it allows you to
export a class via a worker to your main
thread so you can write our class in
this case app which is running on our
worker and then we can expose it via
comlink so on the left side we commlink
proxy the worker and then we're able to
call methods on the app class from our
main thread even though it's running in
a web worker so this is one of those
building block primitives that I think
has a lot of potential and people can
really latch on to and build some
interesting demos with finally angular
angular actually ships with the ability
today to run fully in a web worker you
have to opt into this mode but it works
and it works great it's surprising I
didn't think it was this easy and I
asked someone on the angular team they
sent me this demo and it just worked so
angular is able to do the majority of
their work in a web worker which means
that your main thread stays super
responsive and able to react so this is
amazing because angular is a very high
level framework and the fact that it
works like this is kind of jaw-dropping
all right so where do we go from here
well I would encourage you to take a
look at these api's that we've talked
about today and experiment push the
limits see what breaks see what things
are missing share your demos with us
tweet at us post bugs and just in
general provide feedback so ideally with
your feedback and the things that we're
pushing on we'll be able to push the
overall web performance for our end
users to be a fast experience regardless
of what kind of device you're on and
regardless of what kind of network
condition your user finds themself on
thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>