<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of Audio and Video on the Web (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="The Future of Audio and Video on the Web (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of Audio and Video on the Web (Google I/O '17)</b></h2><h5 class="post__date">2017-05-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z9unKFzAj1w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my name is John palette and I'm a
product manager with the chrome media
team and I am Francois and I love
working with with api's we were here to
talk with you about the future of video
and audio on the web and we are going to
talk about a little bit about how we got
where we are today we're going to talk a
little bit about what you can do today
and show you a couple of demos and then
take a look at what's coming in the
future that's an awful lot to cover in
40 minutes and so we're going to get
right into it so to give a bit of
context let's start back in 2000 when I
bought my first HD television the Super
Bowl was just broadcast in HD for the
very first time I was pretty excited
there weren't any DVRs for HD or
anything like that but it seemed like a
pretty good thing and it looked great
and it played great but over the next
few years there wasn't a ton of stuff
that happened DVRs came onto the scene
Skype came out and we were able to do
postage stamp-sized video conferencing
on the desktop which was pretty cool
YouTube came out in 2005 Amazon and
Netflix started streaming about 2007 but
for a large degree of us for most of us
this really meant that we were watching
video on the desktop or sitting on the
couch watching television at home so at
the end of the day over 10 years there
wasn't a huge amount of change in terms
of mainstream user behavior well now
let's look at what happened with my
daughter about 2010 is when she really
started consuming media and around about
that time is when tablets came out and
all of a sudden you could take your
video and you could watch it anywhere
this is also about when
videoconferencing really did go
mainstream with apps like FaceTime 2011
twitch video games streaming comes
online and all of a sudden people are
sending video all over the place and
2013 is when snapchat came out 2014
musically and suddenly millions of
teenagers are creating little music
videos and sending them to all their
friends and then in the last couple of
years 360 video augmented reality
virtual reality you can see that in the
last few years the pace of
nation has really accelerated for video
and really when you look at it the as
mentioned the state of the union seventy
percent of the bikes being shipped over
the internet today or video and that's
actually projected by Cisco to go to
eighty percent in 2020 this is a really
big deal this is the decade of video
things are happening fast and it's a
really great time to be thinking about
videos so if you're wondering what
session to be in this is in fact the
right one for this time slot it's a
really really pivotal point but here's
the problem we look back over that time
where was the mobile web some of the
apps I mentioned actually have URLs as
names but when you go there it tells you
to install an app the mobile web didn't
play a big part in the innovation that's
come so far which is a little weird
because it's frictionless you want
people to get in you want to get out you
want to be able to see things quickly
these are all things the web is really
really good at you'd be forgiven if you
thought well yeah that's because the
mobile web is not very good at video and
it's true over the past few years as
recently as a year ago there have been a
number of problems with the way the
mobile web handled video let's look at
first one buffering a lot of video
publishers were so focused on flash that
html5 was a secondary thought the mobile
web wasn't even a thought and in a lot
of cases what you'd have is you'd have a
giant video file sitting on a server and
when you went to access that over the
mobile web it would take a long time to
download and you'd be stuck waiting for
it to play or they would think about the
mobile web and they'd create a very
small video file and now you would
download it and it would look awful so
great no buffering but the video quality
is just terrible the publishers who
didn't think about the mobile web from a
video perspective often would do the
layout for the desktop site and not
check some of the mobile sites now to be
fair a lot of the api's to do this
correctly didn't even exist a year ago
so there has been a big change in the
web over the last 12 months in terms of
the ability to do video but this is what
you are looking at a year two years
go and of course if you went offline
your media experience was pretty
terrible
I like the dinosaur game it's not going
to keep me going on an airplane for four
hours so now let's take a look at where
mobile web media is today
to show you this we have a demonstration
application which was written by Paul
Lewis in a developer relations team
let's go to the application please and
what I'm going to show you is what you
can do today on the mobile web so this
is a progressive web app and it's called
Biograph when i went to the web site for
the first time and asked me if i wanted
to install on my home screen which i did
and so now when i launch it you can see
it comes up gives me a nice splash
screen and goes right into the frameless
app if i take a look at the task manager
you can see there's no chrome frame
around us I'm going to keep
re-emphasizing the point this is a web
page this is what you can do with a
progressive web app it looks great it
doesn't look like it's in chrome but
under the hood it's actually being
delivered by the browser so I can scroll
through you can see it's fast it's
seamless it's very responsive if I hit
play on video it comes up very quickly
we didn't get a buffering event at the
beginning now I wish I could say that
the Wi-Fi here at the show is so
fantastic that you will never experience
buffering with video but that's not
what's going on here in reality because
of this progressive web app it's able to
pre cache the first second of video or a
few seconds of video so when I hit play
it was instantaneous let's take a look
at some UI elements here if I rotate I
can go full screen you can see that I've
got custom controls allowing you to go
back and forward I can also drag on the
timeline I can get some great thumbnails
not really what you'd expect for mobile
web playback is it if I go back into
portrait mode the device automatically
pops back let's take a look at what
happens if I go into lockscreen
so a lot of cases where I might want to
hear the audio on the video but I might
not necessarily want to be watching it
you can see here it's a little dark but
there's a background image filling the
entire frame and I have media controls
video in this case in media through
as well is now a first-class citizen on
my mobile device and it lets me know
what's going on in the background if I
unlock and I go to the notifications you
can see I have controls there as well
now this is all great but what if I'm
getting on that airplane well I have the
ability to take media and make it
offline in this app this is using an API
that's still in development called
background fetch what's neat about
background fetch is that now it's
pulling down the video on the device but
if I switch pages or even exit the
browser and then come back let's go back
you see the download continued and
finished up even while I was on a
different page and this is great because
now if I go into airplane mode and I go
back to the home screen the app can
actually keep track you'll notice that
some of these video items are grayed out
it knows that they're not available
offline let's go into this one I'm going
to hit play on this video which is
offline and we'll notice that after a
brief second it starts playing so you
really can do a complete excellent video
and audio experience on the mobile web
today one thing I want to mention about
this video this is actually protected
content before I hit play on this it
already had a pre authenticated licence
and played it so we talked about doing a
great media experience this is something
that everybody can do for all use cases
it's ready right now
so for those of you who are interested
in trying this out the app name is
Biograph you can access it at the urls
on the screen it's also open source
there are a lot of really good learnings
in here paul has been doing a series of
developer Diaries explaining a lot of
the tips and tricks that he has used to
build the app including things like how
to get those thumbnails to scrub in the
player control there's a lot of really
good information there we'll come back
to these links later in case you missed
them right now
so what did we see let's start breaking
this down I think that was a pretty
great experience because there was fast
playback you had the ability to watch
anywhere it had great UI and it had
really high quality video so this is the
anatomy of a great video experience
let's tackle these one at a time it's
been mentioned before that you'll lose
users if your page doesn't load fast
enough Akamai did a study and they show
that after two seconds you start losing
about 6 seconds of your viewers if your
video doesn't start playing fast enough
so it's not enough to just have a great
page load you've got to be able to
deliver up video fairly quickly and the
other thing that other studies have
found is that you need that playback to
be sustained it needs to be continuous
it doesn't matter if the network goes up
and down any time of video buffers
you're going to lose people let's start
with the playback the challenge with
playing back video is you have to pull a
lot of data over the network and the
network is not constant the user might
go through a tunnel they might lose
bandwidth so there's a way of dealing
with it's called adaptive bitrate
streaming what we'll do is we'll encode
the video at multiple bitrate here I
have low medium high in practice you'd
have 6 10 12 or more different bait
routes bit rates that you're encoding -
the next thing I'll do is I'll break the
video into segments in this case 6
second segments I'll include the video
segments at each of those different bit
rates the reason I'm doing this is now
when the user hits play the player can
look at a playlist which knows where all
of these different segments or fragments
are and as the video plays it can adapt
to the bandwidth going up in quality and
resolution when there's more bits
available on the pipes and go
going down when the bandwidth goes down
this in the demo was done through the
open-source Shaka player and what it
does is it reads a playlist and then it
pulls the appropriate fragments of video
and feeds them into the video tag using
MSE media source extensions another
thing we need to talk about is startup
make sure it plays back quickly this is
a proof of concept done by field player
and what they're doing will wait for it
to come back in a second what they're
doing in the first second section here
is they're using service workers to
precache the first few seconds of video
as you user browses page so here we go
the user is browsing their page and
eventually what they'll do is they'll
select the video and start playing but
they don't wait for that indicator to
get ready for video playback even while
the user is here they've already pulled
down the playlist or the event of the
presentation description and you notice
on the Left where it's been pre cached
the video playback starts right away on
the right it takes a few seconds and in
fact if your pre caching with service
workers in their example they were able
to get playback from over three seconds
before the video started down to about a
hundred milliseconds so service workers
really can make a big difference
progressive web apps have a lot of
powerful capabilities that they bring
the video and in fact you saw this pre
caching in the bio graph demo you
remember when I hit play it started
pretty quickly
well that's because under the hood bio
graph had used the serviceworker to pull
both the presentation description and
the first segment of video into the
browser cache and then when Shaka went
to access it that presentation
description and that first segment were
pulled by the serviceworker from the
cache after that fragment started
playing Shaka then went and started
pulling the next fragments of video over
the network what this means is the user
gets fast fluid instantaneous playback
which really is like almost every other
element in html5 you want something
responsive and quick that happens right
away I cannot overemphasize how useful
and important service workers are to
optimizing the speed of your site one
recent case study that we did with
Viacom 18 on their route site optimized
their mobile
webpage their page load times went up by
5x so five times faster and this had a
big impact this is a media site it had a
big impact in terms of return engagement
for their users as well as the
engagement of new users 77 increase
percent increase and then conversion
from new visitor into an actual video
viewer and then at fifteen percent
increase for all of the users in terms
of the number of videos that they
watched on average so you can see a
little bit of optimisation and a little
bit of performance goes a long way in
terms of increasing the engagement so
that's fast and fluid playback let's
move on to offline offline is really
really an important use case for a
number of reasons
one is obviously the airplane which is
something that I of course because I fly
around care about there are also a lot
of cases where you'll have viewers or
potential viewers who would like to
access the video in places that do not
have internet access we've actually seen
those users trickle load using the
default html5 player videos waiting
until they get all the way into the
cache and then they'll take the device
and go somewhere else saving the video
for later that's really not the best way
to do offline for anybody who's thinking
oh that's going to be my new offline
strategy please don't do that
what you can do instead is use service
workers and when we saw this in bio
graph what bio graph had done with the
offline video is it pull down the
playlist or actually the presentation
description in this case it pulled a
presentation description and all of the
media segments at a reasonable bit rate
into the cache so that I could play it
back here at the show now you might ask
which bitrate would I want to choose who
I want the highest bitrate do I want the
lowest weight that's really up to you
you control the logic in the
serviceworker you control what quality
or you can give the users control let
them download an HD version if you want
or let them do a low bitrate one if they
want to save more on the device I keep
talking about video this is a really
great use case as well for audio this is
something you could do with a podcast
it's also something you can do with a
variety of other audiobooks other types
of audio material now I mentioned during
the demo that the actual section
of it the pulling into the browser cache
was being done by an API called
background fetch this API is still in
development this is a good example of
something that we very much would like
you to look at it now and give us your
feedback it's available if you turn on
the experimental web features flag but
take a look at the spec this is the time
if you have feedback on how this should
work please do let us know I mentioned a
second ago that there's a decision
either for you or on the part of the
user in terms of how much video do you
really want to put on the device would
it be great if you could get twice as
many videos on the device without
sacrificing quality well of course it
would be and this is where video
compression really comes into play video
compression is what gets used to take
video and turn it into something that we
could actually send over the network and
vp9 is the WebM approach to video
compression it's also known as a codec
which stands for a coder decoder and so
if you hear me say the vp9 codec that's
what I'm talking about it's a
compression technology what's great
about vp9 is that compared with a lot of
the other common video compression
codecs it can get up to about 50% better
compression efficiency meaning you can
cut your file sizes by 30 percent 40
percent up to 50 percent while
preserving the same quality or just
offer a better higher-quality level now
the other thing you can do with vp9 is
you can actually deliver higher quality
I mentioned this is a key pillar to a
great mobile web experience vp9 is
supported on on over 2 billion devices
and so if you want to play high quality
video vp9 is an excellent codec choice
to look at so good that when YouTube
adopted it they saw a video starting 15
to 80 percent faster using vp9 compared
to some of the other codecs 50% less
buffering and more HD worldwide there
are some really great gains that come
from using vp9 a really great high
quality experience the last piece of the
anatomy is the user experience and one
of the things you saw was the lock
screen there are a lot of cases where
you might not want to watch a video you
might just want to listen to the
if what your deal with is audio then
this is absolutely a primary use case
for you now the great thing about this
API which is the media session API is
that it allows you to put your metadata
and images on the lock screen as well as
on wearable devices it's also great for
the user because they can tell what's
going on on their device and they can
control it so let's take a look at
what's going on in order to use the
media session API the first thing I'm
going to point out is this is a great
example of a progressive feature the
first thing we do is start with an if
statement if the device supports media
session if the browser supports me to
session great we'll use it to make
things appear you simply provide a
little bit metadata title artists album
and then artwork typically you might
have a longer list of images that you
would provide at different form factors
for the sake of brevity here I have two
512 by 512 which is the most common
Android size for the lock screen as well
as 256 by 256 which is useful for some
older devices once you've provided that
metadata you'll also want to be able to
respond to the controls and here you
want to be able to speak back forward
play pause next track previous track and
what you do here is set up action
handlers so that when those actions
happen when those events happen you can
take care of them you may also want to
be able to control the playback state so
that the user if you're doing custom
controls get reflection of the media
session state inside the lock screen or
the notification in terms of
implementing these action handlers it's
not that hard all you're doing is you're
setting controls to the audio or video
tag just like you would if you were
doing controls on the webpage so it's
pretty easy and it gives a much better
user experience here's another key part
of user interface full-screen mode this
is a good experience I hit play if I
turn into landscape it automatically
goes full screen this is also a good
example of something that you couldn't
do a couple of years ago let's take a
look how you do this with the screen
orientation API again a progressive
feature if the device supports the
orientation feature then what we'll do
is we'll listen to when there's an event
changing that orientation if the
orientation has become landscape we'll
go fullscreen otherwise we'll go
what a full-screen that's it that's what
eight lines of code and all of a sudden
you can make the user experience
significantly better for media on the
mobile web so you really can do great
media experiences on the mobile web
today
fast playback the ability to watch
anywhere great user interface and high
quality playback and this is really
great stuff it's all available today
and anybody who's sitting here
remembering the title of the talk is
going to be saying wait a minute I
thought you were going to be talking
about the future of audio and video on
the web this is actually the beginning
of the future and a lot of sites are
just now adopting this technology I hope
people in the audience you're looking at
this and saying you're going to do that
as well so to some degree this is the
short-term future but let's look a
little bit further out that because all
of that is available today let's talk
about what's coming out afterwards so
let's start with color there is a new
set of there are a new set of standards
that are coming out around video which
are dramatically improving the realism
of what can be displayed and they're a
new set of displays today televisions
coming soon to mobile and desktop near
you which increase the realism
dramatically part of that is color so
for people who don't work with photos
and videos all the time like I do it may
be a surprise that your display cannot
actually reproduce all of the colors
that you can see with your eye this
curve shows the full spectrum of colors
that the eye can see in fact it doesn't
because that projector and this screen
can display all of the colors that your
eye could see but let's pretend it does
your standard srgb monitor today can
only represent part of it the new video
standards around BT 2020 are
dramatically extending that color so
colors like my shoes these shoes
probably are not going to represent
properly on that screen but some of the
new televisions you're going to get a
lot closer another aspect of the new
video standards is the ability to show a
wider range of brightness and what I
mean by that is brighter brights and
darker darks if you look at the standard
monitor today it's doing what's commonly
called standard dynamic range or
see our and the range of brightness that
are compared to what you see in the real
world isn't really that dramatic the
blacks aren't really that black and the
brights aren't really that bright as we
move into high dynamic range what's
happening is that displays are coming
out that cover a much broader range what
this requires under the hood is a change
in terms of the electro optical transfer
function the EO TF which you may have
heard of as the gamma function there are
a whole new set of functions for
converting digital values of brightness
into what actually gets displayed on the
screen what this means for anybody
working in video is you need to know
whether or not the device can support
those EO TS and also make sure that you
understand the characteristics of the
device you're playing it on so let's
take a look at how we could do that both
for color and for HDR from a color
perspective this is where the CSS media
queries level 4 come into play the color
gamut query is now supported in Chrome
and will allow you to query the device
to determine the breadth of coverage of
color on the device on the bottom
there's new is type supported strings
coming which will allow you to query for
vp9 which by the way does do wide color
gamut and high dynamic range with vp9
profile to full tendeth allowing you to
determine whether or not HD are
supported as well as the electro optical
transfer function these new advances as
well as some of the most demanding
low-end bit rates all come bring me back
to video compression and there's some
exciting news going on here on what I
want to talk about briefly is the
Alliance for media or the AOM which is a
cooperation between the number of
companies create a new open-source
royalty-free compression format this
includes YouTube Google Amazon twitch
Netflix Microsoft Mozilla Hulu the BBC
are all part of this cooperative effort
to create a new compression format that
will tackle not only HDR and white color
gamut but also a Kay and 4k 360 video as
well as an arguably more importantly
four
providing video in the most demanding
low bitrate situations imaginable
important for billions of people around
the world who do not have the same level
of connectivity that we do this work is
going on now the name of the codec that
they're developing is a b1 and just a
few weeks ago netflix came out with some
of their first analysis on the
performance of the codec and what they
found is it's not even done yet and it's
already getting 20% better compression
vp9 this is not yet available we're in
the future section of the talk but this
is absolutely something to keep an eye
on as it rolls out but when it does roll
out one of the questions you might ask
yourself is great well can my device
play it back and this is something
that's interesting and unique to the web
not all devices perform the same way
ultimately you want to give the video
the user the highest possible video but
the one gigahertz system on the left
probably doesn't have the same kind of
hardware decode support as the device on
the right this is important when a v1
comes out it's also important right now
quite frankly four different video
playback capabilities so let's look at
vp9 if I want to detect whether device
can play vp9 today I'll use the can play
type function I'll pass in web MVP 9
I'll say can you do that and it will say
probably and you'll say oh ok here's
some vp9 please go play it now what that
doesn't really tell you is are you going
to drain the battery or are you going to
play this back at high quality there
you're going to be dropping frames so
there's a new API coming out to address
this called the media capabilities API
and this allows you to fine tune the
video playback experience for the user
on the top again a progressive feature
you say if we have this media
capabilities API I'm going to pass in
the resolution and bitrate and the codec
of the video I want to play as for the
decoding information and then it will
tell you number one is it supported
number two will the playback be smooth
and fluid and number three will it be
power efficient now you can use this
information to make decisions about not
only what type of video you want to send
but also what resolution of videos you
want to send to optimize the viewer
experience based upon your specific use
case
but we haven't talked about what I think
personally is the area of greatest
innovation and growth in video and audio
that we are seeing right now
particularly over the last few years
my daughter's ability to make mobile
music videos on her phone and her
ability to put things on her face and
tell and communicate with other people
is all social it's all about sharing
it's all about communication hear this
it's hard to remember this was not
mainstream as recently as five or six
years ago but it has quickly become very
mainstream the whole premise here with
social is you want people to get in get
out and be able to do things quickly
which is great for the web so let's talk
about the most personal social media
video communications web real-time
communications web RTC is not new but
what is kind of interesting over the
last year or two has been the rapid
adoption both by the browser
manufacturers as well as the app
platform there are sites now that are
using it on the scale of tens and
approaching 100 million users on the
site so what is new is the progressive
web apps make WebRTC really easy
interesting on the mobile web you have
the ability to provide people with a
website that uses WebRTC on the phone
and let them jump in communicate jump
out add to the home screen they can come
back so there is a next step here as far
as peer-to-peer personal communication
and that's fine for one-to-one let's
talk about another type of social event
which is live streaming how is this
social well if you're sending video to
ten people they probably want to
communicate with you if you're sending
video to a million people they probably
want to communicate with each other
it really depends on the event and
what's really neat about this is that
where you look at all of the platforms
of support live streaming today the
weather has a pretty unique advantage in
terms of the feature set as well as the
way people use it if you want to share
something you simply send somebody a URL
they don't have to download an app in
order to watch it because this event is
happening now
don't make users wait this is where the
web can really come into play now the
truth with live streaming is that
there's a whole infrastructure challenge
underneath the hood and what I mean by
that is if you're deploying to a million
people and you want latency a low
latency rather you might take a
different approach using files that are
getting placed out onto the CDN or even
files that you're reading while they're
growing as are placed out on the CDN or
you might use data channel WebRTC and do
peer-to-peer CDN to deliver it I am NOT
going to go into all the details on that
because I would use all our time but
what I will let you know is that the web
does support live streaming both in
terms of WebRTC
as well as the ability to put out the
video segments in the form of files and
play them back and in fact Shaka has the
ability to do this by reading dynamic
presentation descriptions and then as
the segment's become available in
network knowing the appropriate seek
range as well as the end so that it
knows what to playback and all of that's
great but there's the last piece of
social media that we want to talk about
and that's creation if you look at the
way that something where you are
creating video and sharing it with your
friends works it's really a beautiful
cycle it starts with somebody finding
something and watching it and getting
inspired and then they say now I want to
make something and then they capture and
they create and they encode and they
upload and they share it with their
friends and then their friends say whoo
that's very cool and they get inspired
and they want to capture in it so this
really only works if it's easy to
discover it's low-friction to watch and
then also low-friction to get into
capture scenario that this cycle can go
very very fast as long as the whole path
is very easy the wave has a lot to bring
here and to show you an example of
what's coming in this space I'm going to
take you to francois thank you Jung
I'd like to share with you a single web
app I've been working on and use it to
showcase some awesome media capabilities
coming to the web may we switch to the
Android devices so this web app is
called moo-stache and you will
understand why soon I have previously
added boost - to my home screen and
specified in the web manifest that I
wanted to run it in standard mode so
that the browser UI just not show up it
is quite hard almost impossible to tell
that this is a web app so now you can
see me with moustaches on wearing a
funny hat not that there is no lag here
is perfectly smooth may I say creamy
okay say it let's press the record
button and at all at the bottom right of
my screen I have a preview videos myself
that I can share now click the Chevron
and let's do it for instance Boop or not
please
and that's all let me describe what
you've just seen and may not have
realized by walking you through all the
API has been using for that let's start
with the basic this is how you get
access to a camera video stream on the
web today said video attribute a sassy
object to the asynchronous result of
navigator that media devices that get
user media and you're good to go
as soon as the video plays not that the
only media constraint I pass there is
video true but my mustache app actually
asked for more
the ideal video with high frame rate and
facing mode the browser will do its best
to accommodate your request so it
doesn't hurt to ask my custom draw
function is going to be called to is
going to be called sorry every time the
browser ask for frame to be elevated
thanks to the requestanimationframe
thank function here since I'm looking
for the smoothest experience there that
means the draw function is going to be
called approximately 60 times per second
and each time it's called I'm going to
draw a live video frame on my canvas at
that point we have a face on the screen
and that's not bad but let's go further
now using the experimental shape
detection web api i was able to draw
some mustaches and a hat on my moving
face while keeping the app running
smoothly at 60 frames per second as a
matter of fact that wasn't the case last
week so thank you amigo for working hard
to get this demo ready for today as you
can see this is a pretty simple and easy
to use API as hardware accelerated
detectors may potentially allocating
whole significant resources I recommend
you read the same say detector object
when doing several detection the first
mode option here is a hint for the
browser to prioritize speed over
accuracy which is exactly what I'm
looking for in that case let's look at
what is happening now in the draw
function calling state detector the data
cameras return asynchronously an array
of detected faces in the canvas
not that the processing is all done and
devised so there is no internet
connection required there when s is
naked I use its position X Y width and
height to draw some elements on top of
the video frame one best practice is to
use a simple balloon like easy taking
faces to avoid the very needy API as the
draw function is called all the time
break all right DCPI along with the
barcode QR code and text detection API
will be available to everyone later this
summer for testing purposes in chrome
stable note that you can already play
with it today by enabling the
experimental web platform feature flag
in chrome by well we love feedback so if
you want more features such as eye or
math addiction that's about example we
have it but if you want something else
something more or if you simply stop
relevant bugs please let us know now how
about media recording is that how it is
not agreeing
this is the full code at use in my
moustache I grab the stream from the
canvas by calling canvas Dodge Charger
stream and use it to instantiate a new
media recorder the mine sub option tells
the browser which correct to use for the
recording it can be h.264 or vp9 for
instance if you leave it on specified
though the browser will choose the best
one which usually boils down to the
other way accelerated one if any you can
also pass the bits per second option to
customize the video quality of the
recording recorded start actually start
recording the media and each time the
recorder delivers some media data we
store them in an array object I called
chunks when the user stops recording we
call recorder stop which fires a stop
even allowing us to create a new blood
object containing all chains we recorded
so far and upload that video blog to a
began I could also choose them to
directly stream g-strings to an article
collection by the way the media
recording API as being chrome for a year
now so it is predictable as proof some
popular Chrome extension uses intensity
to record up to one hour of counter
such as video and tutorials when I click
the share button did you notice that the
native Android share UI showed up and
included all my native app that supports
sharing text on my device I was able to
do that with the experimental web share
API which enables sharing data such as
text and suit images from the web to an
install a power user Julie as you can
see this is as simple as calling
navigated share and pass it the title
some tags and the video you are and that
is pretty much it these four lines of
code enables signature and artists we
can't wait for this API to be able to
everyone later this year
Thank you Thank You Francois that's
pretty awesome right there's a couple of
things in there one is the media
recorder API which I want to highlight
because what is great about that is the
web creating media for the web that is
something that we see over the next few
years is becoming more and more common
but what's really great about this is I
love the way that with in a plugin free
world
you can connect these items together
like nodes meet and pipe them together
using media streams so camera the canvas
the media recorder to upload microphone
to web audio to rtcpeerconnection there
are a lot of different things you can do
with these tools if you want to access
the mustache demo here again to remind
everybody this is a relatively new API
it's still in development so you do need
to turn on the web experimental features
flag if you want this to work and we
would ask that you would use Chrome
Canary for that so that was a lot I told
you at the beginning we were going to
cover a lot so what did we see today we
showed you a couple of demos and we
talked through a lot of api's many of
which are available today so in the bio
graph temmo which was really about
playback service workers were used
heavily shaaka player was used for media
playback and then there's a long list of
supporting cast of api's including the
media session api the fullscreen API the
screen orientation api and a variety of
others
you don't have to remember all of them
fortunately because Francois has written
a wonderful article on best practices
for mobile web video playback which is
available at the link at the bottom and
if you're looking to do your own
progressive web app doing media playback
please do take a look at the sample code
provided by Biograph on the mustache
side media stream recording API as well
as media capture and streams these are
both available today and at the bottom
is the link so that you can access a
much demo again Chrome Canary on your
mobile device and make sure to enable
the experimental web features which
brings me to arguably the most important
point we want feedback some of what we
showed you today the title of the talk
was the Future 3 of the API is in
particular background fetch to allow you
to do downloading immediate even while
the user navigates away from the page or
closes the browser it will resume when
they come back the shape detection API
the ability to look for QR codes text
spaces and other objects and the web
share API the ability to share items
socially all of these are being
developed this is your opportunity this
is a great thing that's coming in the
future but frankly it'll be better if
somebody in this audience looks at and
says I would like this and our developer
team and the other developers on the web
working on the API say that's a pretty
good idea please do help us make this a
reality by going to these sites and
providing feedback look at the api's and
tell us what you'd like to see or you
can come see us in person we will be in
the sandbox behind the stage and so a
lot of great api's were happy to talk to
you about them and frankly we are just
really excited if you look at the pace
of innovation over the last few years
the web is coming to play the mobile web
is coming to the media game and we just
cannot wait to see what happens next
thank you everybody whoo</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>