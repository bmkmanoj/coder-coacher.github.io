<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>V8, modern JavaScript, and beyond - Google I/O 2016 | Coder Coacher - Coaching Coders</title><meta content="V8, modern JavaScript, and beyond - Google I/O 2016 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>V8, modern JavaScript, and beyond - Google I/O 2016</b></h2><h5 class="post__date">2016-05-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/N1swY14jiKc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi thanks for coming everybody my name
is Seth Thompson and I'm a product
manager on the chrome web platform team
and I'm here today to talk to you about
the v8 JavaScript engine and in
particular we're going to spend a little
bit of time talking about v8 and how
it's used in chrome by real users and
also how it's used in other contexts
it's for example and it's and bettors
like nodejs on the server and we're
going to spend a little bit of time
focusing on how the JavaScript language
itself is changing and then talk about
two new exciting projects on the horizon
so let's get started
first I'd like to go over v8s mission so
this is the mission that we use to drive
the work that we do to speed up Chrome
and v8 and the mission reads to speed up
real-world JavaScript performance scuse
me real-world performance for modern
JavaScript and enable developers to
build a faster future web and there are
two parts to this that are equally
important the first is that as we make
the web and browsing with chrome faster
that we make sure we're right making the
right performance enhancements for the
JavaScript that's currently out there
JavaScript that's being written as it is
today and the second part is also
important it's that for Yuga for you in
the audience who are building new web
sites we want to empower you with the
right tooling the right language
features new additions to the language
and new resources to make you successful
writing faster apps to begin with in the
future and both of those two parts
together will ensure that the web is
fast and the ecosystem healthy in the
future so that's what drives us and I
think it's important which is why I
wanted to start with it so let's talk
about this notion of real-world
performance what what is that what
performance isn't real-world the
important part about this focus is that
we're it's reflected on web sites that
exist has real users browse them in the
wild and that's important and to know
why it's important we're going to take a
quick detour
into some JavaScript history so this is
a chart about how JavaScript has been
measured and benchmarked in the past in
the early days engine you engines used
micro benchmarks to determine whether
they were faster version a version or
whether different engines were faster
and micro benchmarks served their
purpose but they were highly tuned for
very specific language features and in
some cases fairly artificial you may
have heard of the SunSpider benchmark
well SunSpider has some code that runs
bitmask operations 10000 times in a hot
loop or it measures regex string
replacement but 10000 times an exclusion
of other features so this is useful for
finding things like regressions but it's
not necessarily representative of the
code that actually gets run in the web
browser
on real applications so really the
second big era of measurement were that
was the introduction of static test
Suites and benchmarks like octane from
the v8 team or speedometer Jetstream
these are all names you've probably
heard of the goal with these new
benchmarks at the time was to include
code that was more reflective of real
applications octane for example contains
the code that decodes PDFs in Chrome PDF
j/s it also includes a Gameboy emulator
so these are real applications they're
no longer just testing specific features
but at the end of the day these were
still static test Suites since 2002 and
we introduced octane we've really only
made bug fixes but the web has changed
so much in the last four and a half
years and octane and reflection is
really more about computationally
expensive peak performance measurements
so I'm excited because I think we're on
the verge of a new era and really the
third era and measuring benchmarks will
be measuring real webpages as they're
accessed by users there's no substitute
for the real thing
and it's particularly important I should
just note that the reason you have to be
good at measuring JavaScript and
measuring the performance of your engine
is because every new
feature you add every optimization you
make is driven by this notion of being
able to measure whether you're
inherently faster than before so at the
beginning of the year the v8 team took a
hard look at what sites were most
commonly browsed across the web and we
ended up instrumenting chrome to be able
to record special traces of v8
JavaScript execution when browsing sites
you'd be familiar with things like
Google tumblr Twitter TechCrunch Flickr
and other international sites too
everything under the Sun that users were
actually browsing and we were able to
compile the data and a really amazing
new visualization something we hadn't
done before so the details of this are
pretty are pretty hard to read but the
important parts are that on the side we
have a list of top 25 web sites these
are things you're familiar with reddit
Wikipedia Yandex from Russia Amazon
Taobao and we measured how v8 runs a
page load and in particular where it
spends time so you can see that we are
measuring the execution of JavaScript
code itself but also things like garbage
collection API calls to web the web
platform the compilation the parsing of
this textual JavaScript before we can
even start running it all of these
things are broken out and they're not
all the same but there are some patterns
to the way that all of these websites
use JavaScript now here's the crazy part
we compared that to what octane measures
octane measures something that's not
necessarily reflective of these top
benchmarks so octane you can see spends
very little time in parsing and
compiling much more time in the running
of actually optimized JavaScript code an
octane may be useful it is useful it's
reflective of things like decoding a PDF
or running a gameboy emulator but for
the long tail of sites that are perhaps
more attuned to just browsing there's a
huge difference in the types of code and
the way that v8 is execute
when it's running these pieces of
JavaScript so this was a really
important conclusion for us to make
which was that as we go forward we need
to constantly be measuring at scale the
web as it exists today for users and
this is a new I have to stress were at
the dawn of a really new era it's only
we've only just managed to put together
some of this initial data but already in
the last couple months we've used it to
figure out which JavaScript built-ins
appeared most commonly on real web pages
and we were able to say not just that a
particular built in was used most often
but that it actually was used enough on
any given page to contribute
substantially to the load time of the
page and we use that knowledge to
optimize things like object out assign
object ease the in operator and with
this data and I have to stress that the
optimizations here are not the important
part
the important part is that we have data
to be able to rank these and say let's
target an optimization for object to
sign before we want write one for object
keys because it will help the most web
page as the fastest so this is really
exciting and I and I think the the real
benefits of this measure this way of
measuring JavaScript are yet to come
okay so now let's talk about the bread
and butter of what v8 has been working
on for the past year things we've
shipped or about to ship and
architecture changes so javascript is a
dynamic language and in the process of
running JavaScript you end up creating a
lot of objects and there's an inherent
trade-off between the ability to run
fast and the consumption of memory on
the system on the browser or on your
mobile phone and at all times you have
to make sure that you're not consuming
too much memory so garbage collection is
important because by implementing
something like Orinoco which is our new
mostly parallel and concurrent garbage
collector we're able to have higher
throughput in the garbage collect and
garbage collecting in general and lower
the memory but we're able to do it with
less jank because garbage collection
runs on Chronos main thread and so any
pause or any time that you spend
cleaning up unused objects on the heap
for example results in a
small pause in JavaScript execution in
the worst of cases this can mean you
visibly see a pause and an animation
that's playing on the page but we're
excited to announce that with this new
architecture already we've noticed that
the median garbage collection pause and
this is on Windows devices in the wild
already the median 50th percentile pause
is down to four point four milliseconds
so short and that's four times better
than just four chrome releases ago so
we're excited that Orinoco can bring
more and in reducing the actual pause
times that impact JavaScript execution
now there's another important aspect of
garbage collection on the rendering side
of Chrome when you are trying to get a
smooth page or a smooth browsing
experience think rendering a video
playing a game even something like
infinite scroll where you're on a mobile
device you're scrolling quickly and
these elements are shooting by on the
screen very smoothly in order to achieve
that you need 60 frames per second and
that gives chrome 16 milliseconds
between frames to compute the frame to
render it and to paint it to the screen
so the process looks something like this
you can see at the bottom the ticks that
represent actual frames that we need to
hit to enable smooth of smooth browsing
experience as chrome is is is rendering
these frames and JavaScript is computing
them memory does naturally climb up as
you're creating these JavaScript objects
which then become unused before this
idle time improvement when the memory
reached a certain threshold garbage
collection just automatically kicked in
and brought the memory down but because
it's on the main thread and because it
blocks execution to create JavaScript in
Opera excuse me to run a garbage
collection opera operation at an
opportune moment creates a missed frame
as you can see here it just so happens
that the memory reached the threshold
right before chrome was about to paint a
frame garbage collection kicked in and
disrupted the painting of that frame
well chrome as the renderer in chrome
has exposed a lot more information about
how long it's taking to compute for
and when it actually has idle time
between before it needs to paint the
next one and by piping information from
that rendering scheduler into the V a
garbage collector we're able to more
intelligently schedule when we perform
garbage collection and with this new
knowledge we can even perform more
garbage collection than before in
smaller chunks hidden in the idle time
between frames so an improvement like
this allows the memory to be lower
overall but it keeps the renderer able
to hit 60 frames per second and we've
seen the statistical improvements as
well on real websites so we measured
infinite scroll across websites like
ESPN Yahoo on certain pages we were able
to completely hide garbage collection in
the pauses between when screens were
rendered in idle time between when
frames were rented to the screen and for
long-running pages imagine you know you
open Gmail and it's sitting in a tab on
your desktop for weeks hours maybe at
least but often weeks in situations like
that where the page is running for a
really long time this proactive
scheduling of garbage collection during
idle time when you're not doing anything
with the page allows us to reclaim up to
50% of the heap and lower the memory
usage of a page long running page so
both of these are really exciting and it
contributes to a smoothness in the
browsing experience which is really
important okay
another big architectural change is an
upcoming interpreter so v8 historically
has had an architecture built up of
compilers we actually take JavaScript
code we parse the JavaScript code and
then we compile it to native code and
this allows for truly blazing fast
speeds but the parsing and compilation
occurs sometime before you can execute
the newly compiled code and to compile
JavaScript into machine code also
creates machine code which takes up
space and memory so the interpreter is
designed for two things to skip or to
improve startup and and and lessen the
amount of time that we usually take
compiling
but also to lower total memory usage of
a v8 and chrome which is particularly
important on things like low memory
devices you have mobile phones which
often only have 512 megabytes of memory
and every last little bit of memory
savings we can get out really improves
the the usage experience so you may be
and actually yet we've we've already
measured that there's five to 15% in the
total reduction of Chrome's memory usage
when we when we enable something like
the interpreter but you may be thinking
our interpreters slow here's a diagram
which shows just how these trade-offs
could work this is actually an example
page and different pages as you saw from
the earlier screen run JavaScript
differently but in certain examples here
can actually be beneficial and and take
less time overall to use an interpreter
which has slightly slower JavaScript
execution but faster and parsing and
compiling and so this means that v8 will
now have a third tier in its
architecture and we're adding this
interpreter we're calling it ignition on
the left-hand alongside of our baseline
JIT and our optimizing compiler okay
so let's talk about something which
probably impacts the work you do more
the write the JavaScript that you're
writing es6 and es7 two major language
updates now es6
is an update or ACMA script is is
actually the the language specification
that determines javascript the syntax
and semantics of javascript and it's
it's written and updated by a standards
body called tc39
so every so often they release a new
version of JavaScript ESX and they put
out the spec text so es6 was such a big
update to the language it had had so
many new features that actually the the
page itself of text describing what the
features do was over two times as long
as the previous version of the spec text
for atma script so there's just a
massive amount of features in there any
one of these could could take up the
time of a whole lecture but just briefly
there's classes to make object-oriented
code easier to write arrow functions
destructuring default spread and rest
pram
template strings simplify templating let
and Kant's new scoping iterators in four
of makes it easier to iterate over
arrays for example generators new
dictionary objects map set week map week
set we have proxies and reflect which
allow you to intercept things like
property access and actually provide
custom behavior symbols you can now
subclass built-in so you can extend the
string object for example Unicode
regular expressions and promises which
make asynchronous code a lot easier to
write just a massive amount of features
and we've been chipping away at their
implementation so in 32 39 we
implemented these features 45 we
implement more and all the way to the
present but we didn't just work on es6
features es7 was actually a language
update released just this earlier this
year and it is it includes fewer
features because it's only been a year
after the last update but it has a rate
up prototype includes an exponentiation
operator and a bunch of spec updates and
changes to the previous version and
we've implemented features here too so
we're excited to announce that as of
chrome 52 v8 will support natively ACMA
script 6 and ECMO script 7
yes 2016 so it's it's actually it's a
huge accomplishment that the team has
been working really hard and i should
mention that
es6 one of the most popular features is
modules modules require interaction with
the dom the HTML import and though that
side of the integration is still being
worked on so modules don't work out of
the box yet but as soon as the HTML
implements it they will and tail call
optimization z' we're also originally
specified in es6 but they're under
recent discussed discussion at the
standards committee and there's a
proposal to change the syntax of how
they operate so those aren't included in
there either but at the end of the day
this means that with Chrome Canary today
and with chrome 52 when it hits stable
you can write and ship es6 applications
and so we've also we're not just
stopping there yes next is the
a colloquial term for the future future
features that are still being
standardized but coming soon is
async/await we actually landed an
implementation a prototype
implementation in v8 we're hoping to
ship that very soon make dealing with
asynchronous code a lot easier and if
you follow node package management
ecosystem concerns there was some left
pad hassle but we're really excited to
announce that javascript will support
left pad out of the box with the pad
start and pad end and we've landed a
prototype of that too so that should
really improve things yeah but you
probably are using es6 features already
and you're probably using something like
a transpiler Babel tracer why does it
matter that the browser supports these
at all if we can just transpile them
well there's four important reasons
there are polyfills and transpilers
can't replicate all features so there
are certain features that just can't be
polyfilled with existing es5 code those
require native browser support this is
something like proxies there's less
overhead you know on the left here is an
Fibonacci sequence using an iterator in
es6 and this is the transpiled code
which allows that to run in older
browsers I mean there's just so much
overhead there which you have to both
ship to your users and the parser has to
parse before you can even start
executing so there's benefits to
enabling this natively on the overhead
side finally debugging is a lot easier I
can't even with something like source
Maps if you're in the browser and the
browser is running es5 code and you're
trying to step through things and debug
them there's this mental context switch
that you have to perform to jump over to
es 5 which is your source is written in
and easier to bugging has had when
chrome supports these things natively
and finally we haven't had time because
these features are so new to optimize
them yet but over time it's much more
possible for the browser to optimize
native features than for you to write
fast versions in userland code so
something like a
an array iteration is much faster if
done natively in the browser and with
time es6 will be much faster than the
transpiled versions so with that let me
quickly just show you how cool it is to
be able to run this stuff natively I'm
going to switch to a demo here and yes
so I think we're ready here we have to
do MVC I don't know if you're familiar
with this it's an application which
shows a same application written in many
different versions with many different
types of JavaScript and excuse me we
have we have a version that's been
around for many months it's a written in
es6 you can download this today but in
their installation instructions they say
you should compile es6 to 5 using
browserify and babel well i don't want
to do that i want to do this more
efficiently so i've got the source here
and you can see that oops let me quickly
open it up here you can see that this is
really es6 source you've got import
exports you've got classes arrow
functions i'm just going to run this
through one step now this is not
transpiration this is something called
roll-up it's a tool to take import and
export statements and just concatenate
files and put everything in the global
namespace so the reason I have to do
this is because I mentioned the modules
are still not supported natively but the
result of that process still gives the
exact same es6 code and this we can run
natively in the browser let's check it
out ok so hopefully this works oh that's
not the same demo this is on 8080 yes I
think I think this is my to-do
application that's opposed we milk
but it's running it's working and this
is the coolest part if I go to inspect
and I look at my sources panel for
example if I had to debug something or
step over things I'm actually seeing the
es6 natively in dev tools there so
there's no source Maps there's nothing
this is just appearing right as it is
yeah it's really very helpful and
figuring out debugging something okay so
let me jump back to slides really
quickly here and we'll continue with
something else okay now we're talking
about about debugging and a bit about
dev tools one of the things that is most
frustrating to me when I'm debugging is
is when I run into a 500 internal server
error so you've probably run into this
yourself you you're in the front end and
you're in this particular mental context
during a particular codebase working on
your front-end app and you hit an API
and it returns a 5 on an internal server
error and to debug the logic of the
back-end
you've got to totally switch context you
often have to move to a completely
separate codebase you have to kill your
existing app process you've probably got
to start up a debugger which is a
different debugger than the one in dev
tools and then you might fix the problem
but then you got to restart your app and
then finally you're back in front-end
and this cycle is just such a hassle to
move back and forth so dev tools D bugs
JavaScript and VA and v8 powers nodejs
so we thought why is it so hard to debug
node J s using dev tools there do exist
some UI solutions for debugging nodejs
but none of them are a proper
out-of-the-box integration between dev
tools and nodejs so as of this week i'm
happy to announce that we submitted a
pull request a node core to add proper
dev tool support to node j s
so we're crossing our fingers that the
technical issues the review goes well
and that this can be merged into node
core but what it promises is the ability
to use the same binary that you're using
to run your app with an additional
command line flag and suddenly you can
integrate or excuse me you can
introspect your app using dev tools in
any Chrome window using all of the dev
tools features immediately after they're
shipped and this is a much more faster
and there's just so much less machinery
between the two environments so let me
give a quick demo of this as well
okay so I'm working on an app here it's
progressive web app called weather
wonder and I have a relative timestamp
here that I just know is the wrong one
it says 46 years ago I know my weather
data was updated sooner than that so
something's wrong and you know my normal
experience here and and you know you've
probably done this many times is you
inspect the element you try to figure
out where that string is coming from in
this case I can I can save some time
here and I know that it's coming from a
request to a back-end that I'm running
it's a node.js back-end and it's getting
a JSON response so I can actually see I
can just verify here that the time is
returning from the backend with this
error and the string now because this is
one of those things which is really on
the border of dev tools normally in the
past I'd have to completely switch
context go through that hassle as I
mentioned to try to figure out why the
string is being returned as the wrong
time and then come back into the
front-end to see it updated so here's
here's something cool I've built the
I've got my gulp running my front-end so
this is just the sass and the HTML of
the front-end of the app but I've also
just got a simple node process running
my back-end it's a single API now I
especially built that pull request into
a binary it's called node 2 but this is
a normal node installation
and if I just start it up again but this
time pass in an inspect flag that's it
just one flag I get a URL back that I
can paste into any Chrome window so
let's do that in chromium a canary
excuse me to get the latest some of the
latest dev tools features and just like
that
we can see our node application running
in dev tools so this is let's take a
moment to see what we've got this is the
sources panel it contains all of the
debugging that you're used to currently
doing step stepping over things but it
also contains some of the more recent
features that dev tools is shipped
things like async stack traces to be
able to debug across asynchronous
contexts something like set timeout
contains inline values black boxing if
you're trying to debug code but you
don't want to dive deep into the library
code and and all of these features just
work out of the box we've also got a
console which is really useful if you're
trying to interactively interact with
your app just to prove that this is no
js' running in dev tools let's actually
take a look at our global object this is
the global node object off of global is
process and off of process is the
version v7 point 0.0 this is bleeding
edge node so this really is a an
interactive dev tools console that's
looking at my notes AS main context and
we've also got profiling so the same
profiling tools that use in the front
end to figure out where you're spending
time in JavaScript you can use on the
back end you can record a JavaScript CPU
profile and we'll actually profile your
node.js code there's a mazing demo of
this that was just given it a couple
days ago at i/o where it was used to
trace es lint and they found a 50%
increase in speed just using this CPU
profiling view so it's an immensely
incredible I think these tools will
allow you to introspect your app in
totally new ways but let's quickly try
to fix this bug now that particular JSON
was coming from this route right here at
City JSON in my node applique
so just like I would on the front end
I'm just going to set a breakpoint and
try to hit that functionality again so
if i refresh my route you'll notice it's
not responding it still got that circle
spinner there
that's because I've hit the breakpoint
I'm debugging my backend and I can use
all of the tools you're familiar with I
can step over and we can see in line
values I can see my city came back
correctly I've got a response that
didn't get hit and that if loop and I'm
actually going to continue down to this
timestamp just continue to loops
continue to here and let's see what we
got now the nice thing about the console
is it actually shows me my context of
the area that I'm step stopped at the
breakpoint so if I put timestamp in
that's undefined because we haven't gone
to the contact line yet but currently
time there's a timestamp and I've got my
moment library which is a node library
that I'm using to provide the conversion
from a timestamp to relative time and
that is just the regular object so I can
kind of take a look and introspect this
now one thing that I think might be a
problem here is that the timestamp I'm
getting from weather forecasting API
it's coming back as a time stain but I
think it's a UNIX timestamp but moments
a JavaScript library so it's expecting
things
oops in the form of a JavaScript
timestamp well look at those two numbers
the JavaScript timestamp is longer
that's because JavaScript timestamps are
measured in milliseconds and the UNIX
timestamp is seconds since the UNIX era
so this is the example of something that
normally would be so difficult to track
down using different debuggers across
different environments but by putting
the front end and the back end
environment all into dev tools I can
really quickly see oh hang on this this
response for my back-end is in a
different format so I believe the fix
here is just to multiply my data up to
the API by a thousand to convert seconds
to milliseconds but here's the other
cool part
instead of having to go over to my
source make the fix and restart my note
process dev tools already includes live
at it you can modify JavaScript on the
fly so I'm going to go here and just add
in and I just have to type in in this
screen multiply by a thousand okay I hit
save and that's it it hot swaps that new
code and I don't have to restart the
process at all so I'm going to continue
with that old request and remove the
breakpoint now let's see without any
other changes did we fix our front end
let's just hit refresh there look at
that immediately a few seconds ago so
the speed at which you can iterate here
is just so much easier and the full
power of dev tools is exposed to to no
js' so we're really excited about
working more closely with the node
community and continuing to improve a
tool like this and shipping them by
default hopefully as well so thank you
let's go back to slides okay
so this last thing is totally separate
than JavaScript it's actually a
completely new language web assembly
this is something I'm excited to tell
you a little bit about it's a cross
browser low-level language and it's
designed to run native C and C++ code in
a tiny binary format so why is this
important well first there's a lot of
applications out there on the web things
like games but also media transcoding
full editing suites things like
scientific computing really the high end
of performance which you might typically
think of as being constrained to the
desktop
they should all be possible to build on
the web but currently javascript is not
the best solution for delivering native
like speed so web assembly is a project
run and being designed in a community
group that includes all major browsers
it includes Apple Google Firefox and
Microsoft and we're currently designing
this format but it's not just being in
the design phase I should also mention
to it it's an open standard its plug-in
free and web assembly will give you a
native like code environment which can
access the same web platform api's
you're already familiar with there's no
new permissions it exposes its view
source enabled so you'll still be able
to see the best parts of the web where
you just click and try to look at your
app from the dev tools it's a familiar
tool chain web assembly is going to be
able to be compiled to from LLVM using
an out-of-the-box LLVM distribution it
interrupts with JavaScript so there's no
separate model or trying to replace
JavaScript these two are meant to live
together it's the same browser sandbox
so it's a secure environment to run this
this code and it's compatible with
something you might already be using
which is as an Jas
now the main benefit over Asma Jas is
that web assembly is a binary format so
instead of shipping your application
compiled to textual JavaScript which can
get very large we have a binary which is
smaller in size and much much faster to
decode and I'm really excited to
announce that not just as this
own project but it's one in which other
browsers have embraced as well so
already Firefox has shipped another
experimental implementation and
Microsoft edge has announced that they
have an internal build with
implementation running too you can go to
their blog and check out a video so it
this is really historic in that a new
language has been embraced so quickly
and across all of these different
platforms so let me give a really cool
demo of web assembly this is actually
the first time that any web assembly
application has been shown live and this
is this is going to be let me pull it up
here a demo that you can you can access
to if you you get a recent version of
Chrome Canary or Firefox nightly and
enable a flag you can go to the web
assembly github page click on the demo
and let's see if we get a native game
running look at that
this is web assembly so look at how
smooth this is now one thing I want to
point out is this isn't necessarily
cutting edge game but it is a game which
exists today in as MJS and with just one
flip of a flag on the compiler we were
able to target web assembly so this
isn't some whole new platform you have
to learn it's really easily targeted if
you're already building with Emscripten
and and making azzam JS games but here's
where web assembly really shines I'm
presenting on a MacBook Air here and
it's actually a MacBook Air from 2012
so it's a pretty old machine and you can
see here that this this game is running
fullscreen it's so smooth but not only
that the web assembly is so efficient
and so fast at what it does that I've
been able to run in a background window
the exact same game in Firefox at the
same time my whole presentation so both
of these have been running in the
background on my macbook air from 2012
the whole time and you can just see how
how much more smoothly it is than
existing technologies so we're really
excited to see web assembly mature so
yeah
and I'll go back to slides now okay so
that concludes this presentation but I
just want to thank you for coming out
and if you have more questions about
these features please do reach out to
the v8 team we have a Google Group and
we also have a lot more instructional
videos about the way the web platform is
changing in general from i/o at the
youtube link there so thank you so much
my name is Seth Thompson and I
appreciate coming out</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>