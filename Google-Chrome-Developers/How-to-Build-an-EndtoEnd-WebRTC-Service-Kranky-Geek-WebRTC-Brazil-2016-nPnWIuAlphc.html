<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Build an End-to-End WebRTC Service (Kranky Geek WebRTC Brazil 2016) | Coder Coacher - Coaching Coders</title><meta content="How to Build an End-to-End WebRTC Service (Kranky Geek WebRTC Brazil 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Build an End-to-End WebRTC Service (Kranky Geek WebRTC Brazil 2016)</b></h2><h5 class="post__date">2017-01-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nPnWIuAlphc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so to get things right this is not
rocket science it's kind of simple so
it's manual application of KISS so let's
keep all of this as simple as possible
so before we get started we've seen that
diagrams but what is signal and really
so signaling is the offer answer
exchange process that it's needed set up
a peer-to-peer connection between two
participants I normally think of this as
the handshake how do we agree on the
connectivity pieces so another sequence
diagram so we have four pieces we have
Alice and Bob their application sites
and Alice weber's a library instance and
Bob's web or DC library instance Alice
torch all of this off by calling create
offer that gets her an offer which is
sensor cost Bob by any means in this
case we call it carrier pigeon Bob uses
that offered to call create answer send
that back to Alice who can complete the
handshake by calling set remote
description once that happened we have a
peer-to-peer connection created between
Alice and Bob and through the magic of
ice stun and turn that has been
mentioned before so the title of the
talk is fast reliable and scalable
what does does that really mean so fast
means we want to minimize the call
set-up latency reliable means we want to
have really reliable call setup so we
have as few failures as possible both
for the users but also for the
developers you've got that wrong you're
gonna have pissed-off developers that
tries to use your system and the final
thing is you want to have a system that
actually survives survives the stampede
of your own success so what's the impact
of doing this as I said I've been on a
bunch of products and in our experience
we managed to reduce the call set-up
time from about 10 to 2 seconds we
managed to get significantly more
reliable signaling
or coal setups the system is a lot
simpler to build and run than what we
used had before and turns out it's
pretty cheap to run as well so let's
replace the carrier pigeon with some
details we have some more components to
look at in this system we have HTTP
servers and a database and we have the
same use case as before we want to set
up a peer-to-peer connection between
Alice and Bob and just as before Allah
starts off by calling great offer she
then sends it to Bob using a post HTTP
POST operation Bob is sort of by magic
already polling the system trying to
receive that offer so that once it's
inserted into the database Bob is going
to receive it as soon as Bob receives it
he can use it just as before to call
great answer on WebRTC send it back to
Alice using post Alice as soon as she
did the post she entered her waiting
loop so she keeps pulling waiting for
the answer to come back as soon as
inserts completes then al is gonna
receive the answer she can call set
remote description and the peer-to-peer
connection is going to be created that's
good right not really so if you build
this and you try to run it at scale
you're gonna detect that it's slow it's
unreliable and it doesn't scale at all
so as always the devil is in the details
so what are the problems with the
previous solution so Pauling is pretty
crappy it dives over it both on the
server side and the database side it
also adds a lot of latency using polling
and HTTP adds sort of double latency
because you need to pay for the poll
cycle and you need to pay for the TLS
handshake for every single poll which is
going to be crazy
use of a single database also have a set
of problems it's going to add latency
because that
database needs to live somewhere
globally it's gonna have replication
problems because it's just one small
database and it for sure won't scale
there are some other details to this
there isn't any delivery acts if you
don't have a delivery acts in the system
you actually don't know if the message
made it across that's gonna make
developers a lot happier if they know
and beyond that we don't have any new
rendezvous system so as I said we rely
on magic for Bob to know when to start
pulling so it just doesn't work so the
details that we sort of need to go
through and design we need to build a
roundover system we need to look at the
semantics of message delivery so we get
those right we need to figure out how we
do system shorting or partitioning so we
get the properties out of the system we
want we need to have a better
client-server protocol HTTP get them
post they're great but if you actually
want to have performance anyone have
performance on mobile devices you need
something else and finally but probably
the most important from a developer's
perspective let's make sure the system
can handle retries and importancia
otherwise it's gonna be a Saturday so
rendezvous it's kind of fancy name for a
really simple question how do you Bob
know that alice is calling him right so
we have two main options we have GCM and
a penis or we could be larger build our
own system GCM or firebase Cloud
messaging or Google Cloud messaging
same thing different them names is
really push notifications for Android
and it's reliable in quotes and it has a
reasonably low latency so the normal
latency is about 350 minutes
assuming you can actually reach other
device if it's in a drawer somewhere
without battery it's going to take
longer and I say reliable within quotes
because there are corner cases where
they drop and suggests silently
especially if you run out of if you run
out of capacity on the server to store
more messages for that endpoint
a penis so this is Apple push
notification service it's built into all
iOS devices it's bad for best effort by
revolt so it means that we're gonna drop
messages both client-side and
server-side and I'm fine with that at
least they promise they deliver what
they promise I'm not the GCM approached
and they have better latency and most of
the time then GCM so about 250 MLS it
sort of depends but you can counter it
you have the third option you could
always go off and say hey I want to
build my own thing you could use a long
limited speed connection from the device
to the cloud handle that you can make it
as reliable as you want to you can make
it really really low latency turns out
it's scary hard to implement especially
at scale it will most likely drain the
battery rather than make rather than
make the user happier and on iOS it's
almost impossible to actually implement
the cost of the constraints put on
background processes on iOS so message
delivery semantics but really important
what does delivered really mean right so
message is delivered we define it as
it's been delivered as it has been
received by the destination device and
handled by the application successfully
so what would that mean in our example
that means that the offer from Alice has
been received by Bob Bob have been able
to apply it using create answer and that
operation succeeded first at that point
we can first when we reach that point we
mark that message has delivered
everything else is just lost or random
we have some other details in here and
we need to decide how strict we're gonna
be with message delivery
there are really two big options we can
say in order or any order in order means
that we promise to deliver all messages
in
the same order as there wasn't our
option is to say let's be a little more
relaxed and say we deliver them most of
the time in the same order as they were
sent but sometimes we get it wrong the
reason for this sometimes is when you
scale out you're gonna realize that
servers go up and down at the worst
possible time and when that happens you
need to retry and that tends to
rearrange stuff on the wire the second
thing which is also sort of semantically
but critical you can say that we're
going to deliver every message exactly
once or at least once right
so exactly MA once means one message was
sent with delivered exactly that one and
the other one is yeah sometimes we
deliver more than once so from an in
Ihram perspective it feels kind of nice
to say ah let's let's provide in order
and exactly once right we all have four
options that's the one that sounds
really simple to use but when you apply
latency and complexity dimensions you're
going to realize it's slow and it's
scarier to build so the Google ways
let's make it simple and let's make it
fast we need to handle the problems
client-side but still it turns out that
works really well system shoring we need
to partition the system we're building
we also know by experience that most
calls are made within a single region
right you only call your friends most of
the friends are in the region that you
are most of the time if we wouldn't do
this then every single request that
leaves one region has to go to another
for no good reason at all is gonna add
another 250 milliseconds round-trip time
to every call so if we apply this to the
initial sort of polling 1 that would
mean that the lowest possible latency
would be 250 minutes because that's the
cost of round-trip even if you got
extremely lucky if you got unlucky it
would be worse so the thing we realized
from this is we need to store user data
in the region whether you're celebs and
we need to avoid costs radian calls if
at all possible
the last word is critical right if at
all possible so we know we need to char
the system we need know we need to short
it by users so how do we do it we can be
very lucky and lazy as we were we do an
L o a sa hey this is phone number base
phone numbers are by default sort of
regionalized we can still use that one
works ok there are other options a
really simple one is to rely on a
registration system and eNOS so you rely
on gdns to find the server that is
closest to the user and that user that
that server to actually know which
region it belongs in so it's the simple
example alright so we have Alice again
we have a global user database we have a
DNS system happens to be the one Google
provides but you can actually use any
one then you have servers in each of the
regions right so when Alice want to do a
registration the first thing she does is
she's gonna do a DNS query for some
deenis if you configure DNS correctly
that's gonna end up resolving to the
closest use the server that is closest
to the user that server knows which weed
units in all the cloud providers you can
squarey the metadata for the instance
and it's going to return the region when
we update the user record in the global
database we can say Alice is home in EU
for example the drawback of this is if
Alice is traveling to the US the first
time she uses the application she ends
up in the US and she's never moved she's
gonna have a bad day so you need to add
some kind of use of migration screen if
you do it like this ok
so a few times here I've said local
storage or global storage so what does
that really mean the local storage is
really some kind of storage could be my
sequel database running within a single
region low replication factor but we can
use it at scratch a scratch that means
we're gonna have super fast writes and
we're gonna have super fast reads global
storage is the thing we want to avoid
sadly as you can probably tell you can't
it's globally replicated
it's very cacheable because we don't
change it very often reads can be fast
because we can cache everything but
writes are gonna be glacially slow right
that's just the fact so don't do it
often but you can live with it
okay client-server protocol as I said we
know that HTTP polling is expensive and
slow right
TLS overhead overhead of us doing extra
call Audigy round trips especially on
mobile networks we risk hot spotting
databases because you keep reading the
same entry over and over and over again
it's not very well good so we sort of
have there's a wish list for mobile
devices on how should the client-server
protocol work we want it to be this
report server to client push so we don't
need to do the polling we just need to
do one TLS handshake and then when the
server knows something it can tell us
about it we needed to be really cheap on
the wire right sure we're gonna set up a
mobile call so soon that's gonna burn a
lot of data but still the actual
negotiation should be cheap we want it
to be fast really really fast and the
last one especially as a developer it
should be simple to use shouldn't be
complex and harder so at Google we use
protocol buffers there is this standing
yoke at Google that are only two kinds
of jobs you do produce proto will go
proto GUI and that's all you do at
Google as a software engineer
essentially it's true
so protocol buffers is a very
flexible way to define data structures
that are language independent they are
pretty easy to use once you get used to
the quirks they have some they are
strongly typed and I have a really nice
compact binary representation so when
you send them across the wire their
sheet dissenter about a year ago we
released something called G op C D as
Google and remote procedure calls so
this is a public port of an internal
system that we use more or less
day-to-day for everything we do it's
defined using proto buffers so you
decide you define your service as a set
of operations on a service
it supports server to client pushes
through long-living bi-directional
opposites so essentially the client
connects and then you can start to send
and receive across that connection
without retrying it's based on HTTP 2 or
quick 4 do we used quick and nuts in
sort of publishes and the nice thing is
it has support for more than 10
languages so when you want to build
something that's like iOS Android
server-side and something else you don't
need to write the same server service
API library multiple times okay probably
the most critical things to get this
working for real you need to realize
that mobile networks or flaky I can't
stress that enough right they're really
flaky even though they seem to work they
don't you have frequent disconnects you
have a lot of timeouts and packet loss
and you just need to deal with it so in
practice that means that every single
API that you publish has to be retry
friendly it's the fancy world for a
fancy word for that is idempotent
right so what it means that you need to
be able to do the same operation
multiple times with the same arguments
and you should only have the same
outcome
but in this example we have a really
crappy retry loop that tries to send Bob
and offer if it failure if it succeeds
we break out of the loop
and if it fails we try again if this
isn't implemented with in a retry
friendly way we're gonna send Bob three
copies of the offer if he's on a crappy
Network but because the call may succeed
even though client the sender think it
failed right because of timer so the
request makes it to the server the
server processes the request that sent
it on but the client timeouts before it
actually realized that he worked so
design summary here then we want to have
a round of your system based on GCM and
a penis we want to define delivered as
successfully handled by the application
we want to have a delivery model that
say yeah we're gonna do it at least once
and in any order so that means the
client needs to handle with duplicate
messages out of order messages all kinds
of crazy stuff
the lucky thing is that's kind of easy
to do on the client doing that on the
server that's strictly I'm really really
hard
shirring we say hey let's do it by year
on the first registration and protocol
we make sure to build everything as
idempotent gipsies in a simple no rocket
science as I said so
we'll remember this one wait this is
where we store it Mallis HTTP POST and
get sampling and we already know what
this is bad so a reliable GRC solution
looks more or less the same somewhat you
could even claim that it's a bit more
complex but if we work it through you're
gonna realize it's it's kind of nice and
easy to reason about we have a new
server type CS connection server like
the first thing you connect to you have
GCM which is good Google Cloud messaging
years to make it simple and not have a
penis and all this in the same picture
and you still have Alice app and Alice
library
Bob's library and Bob's app okay
so how does this work
Alice called Bynes as food as soon as
she pulled the as soon as application
starts we want to do it as early as
possible to make sure that this is ready
when we want to send right setting up
the connection is going to be the
slowest thing bind in this case is a
bi-directional GFC so it's going to stay
up and it's the one we're going to use
fall of the subsequent operations as
soon as the offer is created we send it
to Bob using the bi-directional bind
channel that's gonna hit one connection
server just any random one we're gonna
tickle Bob because we know that Bob
isn't around I'm gonna go into details
soon this M is gonna forward the tickle
- Bob's application causing it to wake
up and actually do something about it or
actually causing Bob to actually answer
really on the other side Bob is going to
do the same bind to sort of set up the
connection as soon as he said calls bind
the offers sent by Alice is gonna be
delivered but we say that this is offer
and is coming from Alice as soon as Bob
receives it it calls crate answer once
that succeeds he acknowledges the offer
and sends it to Alice we know that alice
is connected so the first connection
server
yes forwards the answer directly the
Alice's connection server we don't need
to go through any other loops Alice does
the same thing she receives to answer
called set remote description and then
acknowledge the answer so once again we
have the peer-to-peer connection up or
running so that's pretty simple
not very hard it's kind of easy to
reason about anyway so let's give dig
into the actual details on how to
implement this this is a bit gritty but
this is the way it is again connection
server
DCM and other connection server we have
a local connection database we have the
global user database and we have the
local message database Alice starts by
issuing her bond as soon as she binds to
a connection server we write her
connection information directly into the
connection table that's essentially IP
port and some number identify her
Alice's stay on that connection server
when we bind you also check the messages
table no one called Alice so there's
really nothing to fetch I always want to
send the first message again so she
called send addresses it to Bob and
passes in the message we need to verify
that a Bob is a valid user and B where
he is because we know that it's not
unlikely that it's going to be in the
same region as soon as we know where Bob
is we can issue a select to actually get
the connectivity details for Bob but as
we know Bob isn't around so that's going
to return empty we also insert that
message directly into the database this
is actually the point where we tell
Alice that this operation succeeded and
the reason we do it as early as possible
is to minimize the risk of an error
internally propagating out but as soon
as we return to Alice we actually
continue we call GCM and say hey tickle
because we need to reach Bob at some
point further in the future GCM is gonna
wake up the application on Bob side and
we sort of I've started the first thing
okay the application is running on Bob
side we he calls bind once again we
insert his connection info into the
database we check any messages pending
yep there is a message from Alice so
we're going to deliver that one Bob
handle it by calling great answer then
he calls act
on AK we update the state of the message
in the database but we don't actually
delete it it saves a bit of overhead
especially our database but it also
requires you have some kind of cleanup
system that goes around after the fact
and deletes all of these old messages so
Bob want to send his answer back to
Alice so he calls and once again we
check does Alex even exist that's pretty
cacheable but we do it anyway we figure
out where's Alice connected and we know
that Alice is connected so we're
actually gonna get to result back and
then we insert the message into the
database right we know that Alice was
connected so we got her IP port and ID
that means
Alice Bob's connection server can create
the direct connection Dallas and direct
call saying hey here's the message but
the trick is there's always a tiny tiny
risk that Alice goes away and loses her
connection before we managed to deliver
it so we always tickle GCM even if we
know that there is message there even if
we know that there is a connection there
there gonna be a race between the
delivery of the message and the Chico
from museum we just need to live with
that client-side that's kind of easy to
do server-side it would be a pain once
again Alice receives the message call
Zack she updates the state in the
database and done oh how does this
really work when you have a bigger
system with all the pieces in place so
once again connections reverse GCM local
state local state and global user
database as I said this is drawn as sort
of global only but think of it as highly
cacheable State you can move about so
again Bob's wanna send his response to
Alice
it goes out Oh whereas Alice's home then
goes to the connection database in
chocolate that region and shakes is
Alice connected at the moment and also
inserts the messages into the database
Alice is connected so Bob's connection
server connects directed directed
Alice's and forwarded the message we do
the tickle in parallel to make sure we
don't lose the connection and we have
the normal race Alice receives answer
calls set remote description that
succeeds so she says act as soon as user
says a qui updates the entry we update
the entry in the database that say this
is now delivered that message will never
be delivered again there are of course
races where you sort of a message coming
in reconnects and stuff like that so
that may actually be delivered again and
that's why we say it may or may not the
client needs to deal with it ok so again
back to the overview of the reliable
solution it's kind of easy to reason
about because you don't have polling
loops you don't have strange state it
has clean and simple operations one
thing that this doesn't show is that a
lot of the operations in this slide and
the previous slides are very easy to
paralyze so you can do them at the same
time and you can also do them a bit sort
of optimistically
just try and if it fails it's just the
cost of a fail there has been a lot of
details in there right but stuff we
haven't covered which is equally whore
or simple depending on you look at it is
authentication identity load balancing
idempotency how do you actually
implement that to make it work message
identity cache erection especially a
global state how do you make sure you
evict the stuff that's in the cache we
can update it and how do you handle
poison misuse in the current system if
you get the poison message in that
actually caused Alice's their receivers
clients to crash we can never get out of
that sites it's going to keep crashing
keep crashing but
since we delivery dice so that needs to
be handled so the summer of this tiny
talk you got to remember the details
because that's where the actual
complexity of this is don't go home and
build a custom rendezvous system it just
won't work it has been tried once too
many so let's start to repeat repeat
that make sure you have very clear
message delivery semantics it doesn't
need to be exactly the ones I picked
here but make sure they're clear so the
client teams know what to expect
sure the system based on actual user
behavior right for duo and hangout so we
know how the US was paid but however
your users gonna babe I don't know you
need to figure it out or assume
something when you start use something
really fast and really lightweight as
kind server protocol preferably
something that's easy to use as well
because it's gonna make your developer a
lot happier and finally and I can't
stress this enough
make sure all API is or we tribal
because if they're not you're gonna have
very strange States flying around in
your application that's it questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>