<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Polymer Developer Summit 2017 - Live Stream Day 1 | Coder Coacher - Coaching Coders</title><meta content="Polymer Developer Summit 2017 - Live Stream Day 1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Polymer Developer Summit 2017 - Live Stream Day 1</b></h2><h5 class="post__date">2017-08-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yTASiOaXlck" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">♫  ♫
[music playing]
ing]
[ Applause ]
&amp;gt;&amp;gt; Hello, everybody.  We have a 
packed house here.  We had no 
idea what to expect.  Welcome to
 the third annual Polymer 
Summit.
  Woo!
I am Matthew
 McNulty, developer for Chrome 
lighthouse, a bunch of stuff 
like that.  This is our biggest 
Summit ever.  And our biggest 
venue every.  More codelab 
space, more space to talk to the
 Polymer team members, more 
space to get food.  We're 
responsive to the comments that 
people leave every single year.
So the biggest number one 
comment
 from last year, I don't know if
 anyone recalls, is wider  
chair.  Unfortunately fire code 
says we have to strap them 
together.  Tried to skirt that. 
 Weren't successful with that.  
But should be more room for 
everyone else.  Two full days, 
24 talks.  A few quick notes and
 then get started.  Bathrooms on
 the wall behind you.  
Additional
 unisex bathrooms and more in 
the courtyard.  That was the 
second-most commented thing last
 year.  So meals and breaks take
 place directly across the hall.
  There's a mother's room and 
prayer room in the back corner 
next to the restrooms.  But most
 important is the code of 
conduct.  It's incredibly 
important this is an inclusive 
community and event.  And in 
order to really get that across,
 we decided to make a neat video
 about it this year.  So check 
it out.
&amp;gt;&amp;gt; We want everyone to have the 
best experience possible at this
 year's Polymer Summit.  This is
 an inclusive community.  No 
matter your experience or 
background, you're welcome here.
  We encourage you to be 
excellent to each other by 
saying hi to new faces, building
 on one another's ideas, and  
reporting any uncomfortable 
experiences.  We have a zero 
tolerance policy for harassment 
of any kind.  This policy is 
posted on large signs around the
 venue and our full community 
guidelines are on the event 
Website.  Please share your 
positive and constructive 
feedback with staff and 
speakers.  Staff and speakers 
can be identified by their  
speaker badges or shirts.  Let's
 make this the best developer 
event ever by creating an 
excellent experience at this 
year's Polymer Summit.  Thanks!
[ Applause ]
SPEAKER: All right.  So let's 
get this party started.  Welcome
 to Wendy Ginsberg, product 
manager for Polymer.
[ Applause ]
WENDY: Good morning!  Hey, 
everyone, I'm Wendy.  I'm a 
product manager on the Polymer 
project at Google.  Welcome all 
of you to the third annual 
Polymer Summit.
[ Applause ] we're absolutely 
stoked to be here in Copenhagen 
for a couple of days celebrating
 the web platform.  It's awesome
 to see so many different people
 at these events.  From all over
 the world representing all 
kinds of different companies 
with all different roles, 
skills, and passions.  And this 
year is no different.  Folks 
have come from far and wide, 
representing almost 100 
different countries.
There are people from industry, 
open source contributors, 
weekend warriors, and even 
people who are brand new to web 
components and Polymer.  Many of
 whom we met this morning at the
 codelab.  But no matter who you
 are, where you're from, if 
you're in the audience, at a 
watch event, or at your own 
computer on the live stream, we 
are so glad to have you here.  I
 think I speak for everyone on 
the Polymer team and on Chrome 
when we say how much we love 
these Polymer Summits.  It's a 
huge opportunity to get a group 
of smart, bold, future thinkers 
in one room to talk about 
awesome stuff in the web 
platform.  We love being able to
 meet real  developers using our
 products face-to-face.  To 
learn more and get feedback.  
Sometimes we don't find out a 
company is using Polymer until 
they reach out at an event like 
this.  If you were at the 
previous summits or watches on 
YouTube, they have evolved a 
bunch over the years.  A show of
 hands and see where we are.  
How many of you were
with us last year in London?  
Wow.  That's a lot.  How about 
the first year in Amsterdam?  
Awesome.  Great.  So to all 
those that have been to past 
events, awesome.  Thank you so 
much for coming out.  The first 
Summit was just one day.  And 
frankly, we didn't know if 
people would show up.  But 
luckily they did, over  700 of 
them.  And at that time Polymer 
1.0 had just recently been 
released, and all the Summit 
talks are were from Polymer team
 members themselves.  It was the
 first, big, long-form 
opportunity to tell the Polymer 
story directly to you.  What we 
were doing there, what we were 
trying to accomplish.  And we 
had such a great time that day 
that we knew we had to do it 
again.  So last year in London, 
we doubled everything.  Two full
 days, more talks, more space, 
more codelabs, more rain, more 
everything.  Polymer 1.0 was in 
the rearview mirror at that  , 
and now lots of real companies 
were using Polymer.  We  wanted 
to showcase how much our 
community had grown. 
So for the first time, we 
invited some of the companies on
 stage to tell you how they used
 Polymer and how important web 
components and Polymer were to 
their companies and workflows.  
And that brings us to today.  
2017.  Things feel a lot 
different now, even more than 
they did just last year.  You 
can tangibly feel the web 
components community coming into
 its own.  For the first time we
 opened up talks to the wider 
community.  And we were blown 
away by all of the suggestions. 
 It took us much longer than 
anticipated -- it took us weeks 
to go through them all.  And 
that, as you know, even delayed 
registration a little bit.  And 
just from that call for top Is, 
we found out about amazing 
community projects and several 
big companies that were using 
Polymer.  And a lot of them were
 here today.  We, of course, 
couldn't fit everyone, but we 
did everything
 we could to give a voice to the
 parts of the community.  These 
are the speakers you will see 
from companies large and
small, universities and the 
research world and the open 
source community.  Some will be 
talking about Polymer.  But many
 will be talking about different
 web components libraries or 
tools.  We're hitting that fun 
part of the J-curve in the web 
components ecosystem.  Thanks to
 both those long-time web 
components champions who have 
done such amazing cutting edge 
work for so long, and the 
newcomers, looking to give a new
 technology a shot, adding your 
voice to the community.
Our first Summit was just two 
years ago next month.  And it 
blows my mind when I think about
 how much things have changed 
since then.  The Polymer project
 itself has gone through a long 
journey through many distinct 
phases to get to where it is 
today.  The Polymer project was 
conceived a few  years ago by 
some engineers on the Chrome 
team.  They wanted a team of web
 developers who lives in the 
future.  Who can look at web 
development not as it is today, 
but as it will be, and report 
back to the present to help 
inform the platform.  The first 
official phase -- or the infancy
 of the project -- was an 
experiment to prove out the idea
 of web components itself.  To 
work side by side with spec 
authors and browser implementers
 to naturally expand the 
platform.  To hand flexibility 
over to  developers by giving 
them access to the browser's 
component model.  And they want 
to do this without introducing 
concepts that would be foreign 
to the way the web platform 
itself worked. 
We built Polymer to tinker with 
the steps.  To wrap them 
together in various ways, to 
invent new patterns, to 
anticipate how these specs might
 be used in the future.  And at 
that  , the only people using 
Polymer were us, a handful of 
Google teams, and a little 
sprinkling of crazy, brave 
souls.  Is the Comcast team 
here?  We will clap it up for 
taking an early risk.
[ Applause ]
So the real promise of web 
components, though, the real 
value of baking these new 
capabilities directly into the 
platform, it couldn't be 
realized until the majority of 
users were on browsers that 
natively supported web 
components.  This meant 
convincing other browser vendors
 of their value and working with
 them to shift compatible  
implementations.  We couldn't 
make this case on our own.  We 
needed developers to make the 
case through real-world usage 
and actual, tangible results.  
That was our cue.  And we 
transitioned the Polymer project
 from a small experiment to a 
full blown production-grade 
library.  This was to unlock web
 components in the wild for 
everyone.  Polymer 1.0 attracted
 a lot of friends and a 
community.  Blue chip companies 
like General Electric, 
developers and communities all 
around the world from Nigeria to
 Spain to India and Indonesia, 
developers everywhere were 
diving into web components.  
Unfortunately, our friends at 
Safari,
Firefox and Edge, and across web
 standard bodies worked hard to 
hash out a new take on the web 
components APIs.  Ones we could 
agree on and ship.  Where 
weretist last year before V1.  
Native was varied and scattered.
  Template was across the board.
  But ShadowDOM and custom 
elements were behind a flag or 
entirely unsupported.  But now 
the web component specs have 
gelled with custom Elements and 
ShadowDOM V1.  It wasn't as fast
 as we hoped, but we have 
arrived.  It's all green.
  Yeah, web components are here!
  They're native on over 1 
billion mobile devices and every
 else with  polyfills.  The web 
reaches farther, to more  
extremes of geography and 
weather conditions than any 
other technology.  And now web 
components do  too.  So we were 
able to transition the Polymer 
project yet again to the next 
phase.  Polymer 1.0.  And 
Polymer 2.0 paid down technical 
debt from the specs upgrading 
and unlocked the future-forward 
technology
today.  A lot of what you're 
going to hear about at the 
Summit, capabilities we unlocked
 with the advancements of 2.0.  
Major companies from around the 
world have continued to adopt 
web come mountains.  Konga
 Jumia travel.  Over 700 
projects at Google.  A few 
you'll hear from today.  
Netflix, YouTube, Electronic 
Arts, USA Today and Simpla.  As 
a community we have grown 
webcomponents.org to have over 1
,000 high-quality open source 
components in just over six 
months.  I know many of the 
people who helped us get there 
are here in the audience.  So 
thank you so much.  Because web 
components is huge.  It sees 
over
 60,000 users, over a million 
page views a month.  And over 
the last six months we have seen
 work on supporting web 
components from libraries to 
frameworks.  Major frameworks 
like Angular and Ember have made
 public commitments to web 
components, whether by giving 
talks, or by releasing Glimmer 
JS with web components.  We have
 done work on making it 
super-easy to support
web components.  And tomorrow on
 this stage Ionic will be here 
to talk about how they have been
 embracing web components as 
well.
So the first goal of the Polymer
 project was to get web 
components up the mountain.  
Well, here we are at the Summit.
  So what's next?  Well, we have
 this concept of a weirdness 
budget on the team.  It's a very
 scientific measurement system, 
but  basically it states we can 
only be a certain amount of 
weird.  We can be as weird as we
 want.  I can bring my pet 
lizard, Julian, to the office, 
and no one bats an eye at that. 
 But we have a budget.  And 
every project has a weirdness 
budget.  You can only stretch so
 far outside the mainstream and 
be  relatable.  And with web 
components support growing with 
leaps and bounds, it's less 
weird.  Super native, ES6 
classes.  Now we have the 
opportunity to be less weird on 
another big front.  In this next
 phase of the project, we can 
both embrace a lot of the 
amazing work that's being done 
in the broader web development 
ecosystem as the platform grows 
in capability.  We can also 
expand beyond just a singular 
view of web components to a
much better place of building 
apps that users will love.  And 
all of this is thanks to Polymer
 1.0, web components V1, and 
growing support for other new 
platform features, and the 
expansion of our community.  
With this solid foundation to 
grow upon, we can more  easily 
take advantage of some major 
pieces of the web platform and 
web community.  So I'm extremely
 excited to announce that as of 
today we will be  joining the 
massive, sprawling JavaScript 
ecosystem of npm.
[ Applause ]
And we will be embracing the 
power of
 ES modules.
  This is a critical step in 
bringing Web  Components to the 
mainstream.  There's so much to 
say on this topic, as you can 
imagine.  And I want all of you 
to hear directly from one of the
 folks on the project themselves
.  So Fred Schott from our 
awesome tools team will share 
more information on how we are 
approaching this, why we decided
 to do it now, and how you can 
check out a super-early sneak 
preview yourself.  And that will
 be the first of many awesome 
talks.  Over the next few days 
you'll hear about using Polymer 
with other frameworks, about 
building Polymer projects with 
Webpack, using Polymer with 
Redux.  Not using Polymer at all
 and using other approaches for 
building Web Components.  How 
companies, universities and 
teams are using web components. 
 How specs are made.  Not just 
how to use the platform, but 
what it is.  Hear from Polymer 
technical leads.  About all the 
collaboration in the broader 
ecosystem. 
Cover VR, SEO, and server-side 
rendering for web components.  
And we'll get our hands dirty at
 the very end with some live 
coding.  So I'll say it again, 
we have a packed schedule.  
We're covering a lot of bases 
and venturing into territory we 
have never had the luxury of 
exploring before.  And this 
Summit represents a major 
transformation for the Polymer 
project.  But as the Polymer 
project grows, we are going to 
maintain our core values.  Of 
course, to use the platform.  To
 take advantage of powerful new 
features being  shipped in the 
web platform.  To minimize 
abstraction.  To keep overhead 
down while  maintaining those 
developer ergonomics we care so 
much about.  And to inform the 
platform to work hand in hand 
with vendors to push the web 
platform fundamentally forward. 
 I'm excited about the work and 
ecstatic to see how far we have 
come as part of the Web
 Components community.  And I'm 
excited to see what's next.  
Thank you.
[ Applause ]
So on that note, to kick things 
off with the first window into 
our future, welcome one of our 
amazing tools team engineers, 
Fred Schott.
[ Applause ]
FRED: All right.  How is 
everyone feeling?  Exciting, 
right?  Woo!  All right.  Well, 
thank you, Wendy.  Thank you, 
everyone, for being here.  On 
behalf of the entire Polymer 
team, I'm thrilled to be here to
 help answer the question, 
what's next for Polymer?  We 
have this motto on the team, 
we're pretty subtle about it.  
Maybe you haven't seen it.  
Maybe you have a poster or a 
podium.  But in case you 
haven't, our motto has been to 
use the platform.  And four 
years ago Polymer launched this 
simple mission, to invest in the
 web platform and make web 
components fast, accessible, and
 easy to use.  In 2015 we 
launched our first official 
version of Polymer, Polymer 1.0,
 a production-ready library for 
building with web components.  
And last year's Summit, an early
 look of Polymer 2.0 with the 
specs that the browsers were 
shipping with.  And so today 
native web components are 
becoming a reality on all major 
browsers.  So that's it!  We did
 it!  Nothing left to do, right?
  Thank you
all for coming.  Get home safe. 
 No.  No.  Of course not.  Even 
as native support continues to 
grow, there's plenty to do.  
Plenty of opportunities to make 
web components  easier to use 
than ever before.  That's why 
I'm excited to share three big 
changes coming to  Polymer.  The
 first is that Polymer will be 
moving off of bower and joining 
the npm ecosystem.  Npm has over
 a million developers and half a
 million  packages.  Soon 
Polymer developers will have 
anxious to all of them.  But 
that's not all, fully bracing 
JavaScript and ES Modules to 
give a fully loading script 
across the browser and tools for
 developers.  And finally, to 
help you with all this and make 
where are upgrade and move as 
easy as possible, an autoupgrade
 tool to make this super-easy to
 use.  I'm excited to announce 
today that together these three 
changes will become the next 
major version of Polymer, 
Polymer 3.0.
[ Applause ]
And even though this is just a 
very early preview, we wanted to
 share our first look of what 
you can expect from our next 
release.  We're really excited. 
 But before we get into it, a 
quick look back at how we got 
here.  When the project kicked 
off in 2013, there was plenty of
 challenges and problems we had 
to solve and two problems in 
particular I want to talk about 
today.  Component load in and 
package management.  For web 
components to work, we needed a 
fast, native in the browser.  
And support deep dependencies to
 load other people's code and 
build off of each other.  And 
inlining and bundling have been 
options on the web, we didn't 
want to force an extra build 
step just for development.  So 
these were our requirements.  
And there wasn't much to choose 
from to do this  natively.  They
 could load their own scriptings
, but not their dispensies.  
There was whispers of JavaScript
 in development.  Years away 
from consensus of what it might
look like and behave.  Instead 
of waiting, we proposed a new, 
native  loading system called 
HTML Imports.  This would give 
the browse the ability to load 
on demand.  And load scripts and
 styles.  So essentially with 
one loader you could load 
JavaScript, CSS, HTML, all of 
that.  We like this because it 
was incredibly simple and 
straightforward, which allowed 
us to move quickly from 
prototyping and spec writing and
 on to implementation in the 
browser.  So loading was handled
 thanks to HTML Imports.  But we
 also needed a way to package 
web components and make them 
easy to share across projects 
and teams.  And remember, this 
is 2013.  So a package manager 
for the web, a crazy idea at the
 time.  Handling updates was a 
pretty manual process for most 
teams.  But we wanted to build 
an ecosystem, we needed a way to
 manage dependencies.  And 
because two versions of the same
 web components can't exist on 
the same page at the same time, 
we needed a way to resolve 
version conflicts and
install a flat dependency tree. 
 And lastly, we wanted web 
components to work anywhere with
 any framework.  We needed to 
choose an active community 
available to the entire web.  We
 chose bower.  It was new on the
 scene but growing fast.  
Resolving dependencies, 
dependency trees.  And best of 
all, its goal was to be a 
package manager for the web.  
This aligned really nicely with 
our mission and goal to be 
accessible to any web developer 
in any framework.  Got our 
native loader, got our package 
manager.  With these two settled
, we  launched our first version
 of Polymer and continue to rely
 on them to this day.  But a lot
 can change in four years.  And 
a lot of those core ideas we had
 in 2013 have finally gone 
mainstream.  Thinking with 
components, and encapsulating 
styles, native ShadowDOM and 
native custom elements.  The 
last year was a good opportunity
 to look back and reflect and 
look back at HTML Imports and 
Bower specifically and ask, are 
these still right for Polymer?
Do they meet our needs and are 
they the best for web components
 going forward?  I gave away 
already -- spoiler alert.  In 
looking at these and how they 
look like, how they do a better 
job of solving the issues from 
the beginning.  Start with 
packaging.  Because frontend 
development has come a long way 
since 2013.  And probably the 
biggest change is JavaScript.  
Exploded on to the screen, and 
the npm community builds 
everything for JavaScript.  
Node, the web, tooling.  I mean,
 even space.  NASA is  using npm
 to develop space suits.  I 
mean, that's the final frontier 
of JavaScript.  And so npm has 
brought everyone together using 
JavaScript into a single shared 
ecosystem.  Bower hasn't been 
doing as well.  Most of you are 
probably aware, when you go to 
install Bower today, you'll see 
this message along with a note 
explaining that Bower is  
deprecated and you should move 
to npm instead.  While the Bower
 community was growing, everyone
 has moved over to npm and the 
Bower
 project is winding itself down.
  But you know what?  It's still
 a good package manager, flat 
expensey trees are guaranteed to
 be as flat as possible.  Maybe 
this makes me a JavaScript 
hipster to say, but Bower is 
still a really great technical 
choice for web components.  
Which is why we stayed with them
 for so long.  But the world has
 moved to npm.  And npm has back
 the world's largest community 
of packages and  developers.  
Look at those numbers.  That's 
absurd.  Those are some crazy 
numbers.  So by moving to npm, 
each of those packages becomes 
available for your project with 
no extra hassle or setup.  But 
the package manager itself has 
never really supported version 
conflict resolution or flat 
dependency  trees.  So with npm,
 you can end up with multiple, 
nested versions of the same 
package.  While this can be fine
 for Node, on the frontend, it 
bloats and slows your 
application.  And with web 
components, it completely breaks
 them.  They expect to be unique
 on the
page and can't be overwritten.  
Luckily Yarn came on as an 
alternative client for npm.  Our
 team worked with them early on 
to add the support we  needed 
for web components.  So with 
Yarn, you get the same great npm
 ecosystem, but with a package 
manager that supports everything
 we need out of web components. 
 Just like Bower.  Getting 
started is easy.  You install 
Yarn and run a knit.  And if you
 end up running our automated 
tool, which I'll get  to, you 
skip all of this.  It'll do this
 for you.  It's good to 
understand what this will look 
like.  I'm going through it 
anyway.  So Yarn will generate a
 manifest for your project that 
looks like the bower.JSON you're
 used to.  And some have the 
same on Bower and npm.  Which is
 great.  Your code doesn't need 
to change much.  So one path 
works on  Bower, name on npm.  
No need to change the code.  
Some change.  All Polymer 
packages are nested under the 
Polymer name space.  That wasn't
 the case for  Bower.  You need 
to remember to
update any import paths as well.
  Polymer on Bower becomes  
@polymer/polymer on npm.  
Another thing to keep in mind, 
building an application and 
reference Bower components, 
that's not going to exist.  Yarn
  installs in a Node module.  
Update any paths.  And that's 
it.  Then you can run -- sorry 
-- not npm -- Yarn install to 
install your dependencies.  From
  npm.  Remember that Yarn 
doesn't use that flat dependency
 tree by default.  You need to 
tell it you need to install 
flat.  Add this package to your 
 JSON, and when you run Yarn, it
 will install the dependencies 
for you.  If it comes up, it 
will help you resolve it just 
like Bower did.  But Yarn has a 
ton more features on top of 
Bower.  Smart caching, fast 
installs, lock styles to free 
your  dependencies.  There's a 
ton of cool stuff here that I 
know I'm really looking forward 
to using.  And I'm looking 
forward to the move to npm in 
general.  Because it really 
helps us complete that
original promise of web 
components.  To create elements 
that work on any framework on 
any browser on any project.  And
 asking developers on Polymer to
 set up Bower for one, it's a 
hard sell.  This is what I'm 
most  excited, as a developer, 
the platform should be able to 
meet you where you are.  If 
you're on npm, then Polymer 
should make it easy to work on 
npm.  With Polymer 3, that's 
exactly what we're going to do. 
 That's packaging thanks to npm 
and Yarn.  Now let's talk about 
module loading.  Because with 
all the excitement around 
JavaScript, the plan for a 
native module system has moved 
forward.  Different ideas were 
considered, different features 
debated, and finally the spec 
was finalized last year for ES  
Modules.  And meanwhile, HTML 
Imports, they haven't progressed
 as much.  Chrome and Opera 
added support, but others 
haven't moved forward.  Most of 
the developers aren't asking for
 them.  We really hoped they 
would catch on, but that just 
hasn't happened.  And that
means that polyfils are required
 in most browsers and will be 
required for a long time.  We 
revisited ES Modules to see if 
they could meet our needs.  
Essentially they unlock two new 
features, import and export.  
Import, let's you tag this 
module variable and Polymer 
element.  And the import keyword
 lets you import it from 
anywhere else in your 
application.  So really 
straightforward and really 
explicit about what you're 
using.  And so we revisited 
this, and turns out they meet 
every one of the requirements.  
And not to mention, the 
JavaScript community is really 
enthusiastic about them.  And 
not only that, browsers are 
excited.  Safari shipped native 
support, and Chrome and Opera in
 beta, and Chrome and Edge 
aren't far behind.  Back to the 
chart, they are a viable 
alternative to HTML imports.  
And because we decided to go 
with them, you guys see this, 
right?  Look at the chart.  It's
 completely green.  Do you know 
what that means?  It means no 
polyfills are required on those
browsers for the first time 
ever.  How awesome is that?   
Yeah.  So cool.  So exciting.  
So pumped for that.
[ Applause ]
So this is the result of years 
of work from developers across 
all these different browsers and
 we're just so happy to see it 
all coming together.  Okay.  So 
what does this actually look 
like for Polymer?  Well, let me 
show you with an example.  Let's
 convert this basic Polymer 2.0 
element I have, Pretty Button.  
And move it to Polymer 3.0 on 
JavaScript and npm modules.  
Three things you need to do, 
update your exports, exhorts and
 move the template.  
Straightforward and simple.  
I'll show you what I mean.  For 
exports, instead of attaching 
things to the global, shared 
window, you can be explicit and 
tag it as an export for that 
file.  Now we can change this to
 export prettybutton directly 
from the file.  That's all you 
need to do to change it.  Super 
easy.  This baby even knows how 
easy it is and excited he is.  
I'm not sure that the baby knows
 what JavaScript is, but this 
baby is excited about HTML -- 
sorry, JavaScript export.  Okay.
  Let's keep going.  Imports.  
We're going to
switch to JavaScript imports.  
And, again, super-easy and 
straightforward to do.  It's 
going to look a lot like what 
we're already used to.  So you 
can call it imports with the 
exact same path.  Exact same 
type of path.  And you're going 
import the element from it.  And
 this is important.  Because 
we've already worked with npm, 
and you might be used to 
importing packages by name.  But
 modules on the browser expect 
to import a file by path.  And 
so we're going to keep the same 
path style imports we have 
always used in Polymer so he can
 work natively on the browser, 
no bundling required.  You can 
bundle if you want  to, totally 
up to you.  But it's not a 
requirement.  Can't see that 
path, but it's almost exactly 
the same.  And finally, you're 
going to need to move your 
template.  So traditionally 
Polymer templates have lived 
alongside the class definition, 
and behind the scenes Polymer 
connected for you.  Now r the 
template is going to have to 
move.  We can move it ourselves
directly into the class 
definition.  The classes are 
where we describe properties and
 servers and mixins.  It makes 
sense this is where we'll 
describe the look and feel of 
the element as well.  So all we 
need to do is move the template 
in and we're officially 
completely off of HTML.  And 
don't worry, I'm just using a 
simple string here for an 
example.  I know what you're 
thinking.  That's gross.  I get 
it.  You're not wrong.  I agree.
  Writing HTML in the own file 
format is much better.  Editors 
understand it, highlighting is 
easier.  We definitely 
understand we're losing 
something here.  But bringing 
our templates into JavaScript 
give us new options, including 
the option to go beyond simple 
tempt strings.  I won't say more
 now, but I highly recommend you
 check out Justin's talk 
tomorrow on expressive 
templates.  Imports, exports, 
templates.  All straightforward,
 easy changes.  And now bring it
 together.  There's the example 
we were looking at.  And now add
 the import and
reference properly.  And add the
 export.  That's it!  There's 
the new Polymer 3.0 element.  It
 looks exactly the same, just 
with a few small changes.  And 
if you're using hybrid mode, 
don't worry, Polymer 3.0 is 
going to work with that too.  
And so by moving the JavaScript 
modules, we get a native load 
for the  web.  Just a few small 
changes are all you need to get 
there.  And just as importantly,
 this unlocks the entire world 
of JavaScript for the Polymer 
3.0.  So you can now use Webpack
 to bundle.  You can set up 
Babel to go to older versions.  
And all the JavaScript tools 
will work just out of the box.  
Without any extra plugins or 
configuration needed.
just like with Bower, HTML 
imports, were also limiting how 
well we could work with other 
projects.  And asking them to 
use imports or download 
polyfills for a single Polymer 
element, that's a hard sell.  So
 JavaScript modules are another 
way we are growing to meet 
developers where they are.  This
 is great for everyone.  Polymer
 developers, you can access 
that, and non-Polymer 
developers, you can use that 
cool element you found.  And you
 have the chance to meet 
millions of new people, millions
 of new users on npm.  So that's
 just a brief summary of the 
changes that are coming to 
Polymer 3.0.  And the last thing
 I wanted to share is something 
new.  Something we've created a 
handle all of this for  you.  
Because no one likes painful 
upgrades.  If we decided to 
change a lot of things at once, 
it would be impossible to make 
the move safely.  A punch of 
changes to Polymers -- wouldn't 
work.  The core Polymer library 
is not changing for the move.  
How we use Polymer is
changing, definitely.  As we 
move to npm and JavaScript 
modules.  But the Polymer 
interface, behavior, hybrid 
mode, how that all  works -- 
that's all changed as little as 
possible.  We focus on just the 
things we need to change and 
create a new automated upgrade 
tool for Polymer 3, a Polymer 
Module lyser.  It's still under 
active development.  But as you 
can see, it does a lot of things
 already.  It can generate your 
package .JSON.  And I don't have
 time for a demo, but the most 
important thing to take away is,
 it's awesome.  It's available 
to try out today.  And the 
reason we know it's awesome is 
because for the last few 
minutes, we have been eating our
 own dogfood.  Does that 
translate in Danish.  I want to 
be clear, I don't eat dog food. 
 The   is just the same.  The   
is, we use our own stuff on the 
Polymer team.  We're using 
modulizer to run on our 
elements.  It's looking pretty 
good.  I have one last exciting 
thing to share.  As of about 
five minutes ago, all of the
official Polymer elements have 
been modulized and published to 
npm.  As part of our early 
preview of Polymer 3.  
Super-exciting.  So please go 
check them out.  Play around 
with them.  We're all really 
excited about this change.  This
 has been years of work and 
we're excited about where it's 
going.  Npm is the package 
manager for the web.  We're 
really excited to join that 
community.  ES Modules provide a
 native loading experience 
that's going to work across all 
browsers.  And we have an 
automated tool so you don't have
 to worry.  This is going to be 
a really easy change.  So I'll 
end on the most important part, 
right?  How can you try all this
  out?  Well, the first thing 
you need to do is install Yarn. 
 It's how you work with Polymer 
on  npm, but it's a good client.
  And today, we have an early 
preview of Polymer on npm, the 
elements converted.  And package
 authors, if you have  packages 
you have published, check out 
our modulizer on GitHub.  And on
 npm.  Give us
feedback.  We're really excited 
to see how that works.  Just  
remember, this is an early 
preview.  We're doing this 
because we want your feedback, 
but work is still in progress.  
Some bugs or missing features, 
that's still expected at this 
moment.  And don't worry about 
should I use Polymer 2 or 
Polymer 3 early preview, use 
Polymer 2 for anything in 
production.  There's going to be
 an automated tool.  It's going 
to be super easy.  No rush.  
This is just a rough timeline.  
So don't hold us to it.  But 
this is a pretty rough look at 
where we're going to be going.  
Browsers are going to continue 
to move forward.  We're going to
 be really focusing on 
documentation and tutorials 
going forward.   Improving the 
modulizer and improving our 
general overall tooling support.
  So a ton of exciting stuff 
coming down the pipe.  So check 
the Polymer blog for news and 
updates.  Great blog posts 
coming out during the Summit and
 going forward this year.  And 
if you have any questions,
 I'm sure you do, we have a 
lunchtime brown bag Q&amp;amp;A.  You 
can come to the main stage and 
we will have a few people up 
here answering any questions you
 may have.  I'm excited to get 
things out there, get people 
playing with it, and to join npm
 and the JavaScript community.  
Thank you all.
[ Applause ]
SPEAKER: So just a quick 
correction, the brown bag is 
actually going to be in the 
codelab room.  You will have a 
spot to put your lunch and 
everything.  15 minutes after 
the lunchtime starts, it's in 
the codelab room.  Ask your 
questions there.  There's 
Polymer members in the Ask 
Polymer Lounge the entire way as
 well.  But if you want to get 
in deep with modules, go over 
there at lunchtime.  So one of 
the interesting things about 
Polymer is a lot of times we 
have no idea who is using it 
until they reach out.  The call 
for topics that we put out a few
 months ago led us to not only a
 bunch of  speakers we have 
today, but finding out companies
 that were using us that we 
didn't know about.  Sometimes we
 have a -- Eric
 wrote an extension, lights up, 
we use that sometimes.  And 
using that about a year ago, we 
found out that Electronic Arts 
was using Polymer.  A big game 
publishing company.  About five 
months ago, a lot of us went up 
there.  Went from the airport, 
and Taylor got us
a very terrible hotel with a 
casino.  But we met the 
Electronic Arts guys and saw 
just how much they were using 
Polymer.  It was really, really 
awesome.  Even though they 
promised we would be able to 
play video games and didn't, we 
still invited them to speak 
today.  I would like to welcome 
to the stage Alex Zobheb from 
Electronic Arts.
[ Applause ]
ALEX: Hey, how is it going, 
folks?  My name is Alex Zobheb, 
and for the last eight years I 
have been working with EA as a 
technical director.  I'm here 
today to share the story of how 
web components and Polymer has 
really facilitated a monumental 
transformation from the building
 of transient sites to the world
 of reasonable components and 
rich, engaging player 
experiences.  So before we dig 
in, I'd like to set the stage 
briefly about EA's place in the 
world.  We are a gaming company 
that is driven by our core 
purpose and values to inspire 
the world to play and to be the 
world's greatest games company. 
 We deliver on this purpose by 
being organized into this 
concept of studios.  Such as 
BioWare, Dice, and E
 EA can have sports to name a 
few.  The 22 studios are 
comprised of 10,000 people in 30
 locations worldwide.  Each 
studio has one or more 
franchises.  A franchise is kind
 of like a movie series.  Each 
game in a Fran economize is 
usually a bit of a different 
story,
characters, et cetera.  But 
generally follow some systemic, 
thematic  elements.  Many much 
of you have heard of Dragon  
Age, Mass Effect, battled and 
FIFA.  We manage and deliver for
 the most part in a centralized 
model by the 100-person team 
that I work with, Pulse.  
Through this centralization 
model we can achieve efficiency 
through economy of scale in our 
efforts, and overall just ensure
 an engaging and consistent 
experience across that diverse 
EA ecosystem.  This means that 
our group must meet the needs of
 those 22 studios totaling over 
50 franchises that release 20 
plus games to our players every 
year.  So today I'd like to go 
over three topics.  First, our 
journey and decision making.  
The process of kind of how we 
ended up with web components and
 Polymer.  Second, an overview 
of the design system and 
component library we've created 
over the last two years.  And 
last, some highlights of how we 
have been applying this design 
system and how it's been a huge 
win for EA
and our players.  So let's start
 with the story of how we landed
 with web components.  So we 
need to go back about two and a 
half years.  So basically a 
decade in frontend world, to 
February of 2015 when we really 
started our journey with web 
components and Polymer.  The 
approach to web was very 
different back then.  We 
embodied Conway's law to the 
fullest in how we delivered our 
disjointed web ecosystem.  And 
for the most part, we designed 
and developed  EA's web more 
like an internal agency.  One 
project, one site at a time.  
This siloed and disjointed web 
was really a sad place for our 
players.  And equally a sad 
place for our designers and 
developers too.  We were 
spending 80% of our time on 
commodity web, such as 
navigation, footers, news 
articles, media galleries, video
 player, you know, bypage.  
Leaving only a fraction of our 
team to innovate, excite, and 
engage our players with custom, 
game-specific experiences.  So 
naturally in the world we wanted
 to live in, we
would flip this allocation of 
time and focus around and spend 
the majority of our time on the 
fun, engaging stuff instead.  So
 we started really thinking and 
talking about, okay, how do we 
go from this 80/20 bad to 80/20 
good?  And voila!  The Network 
Design System was born.  Project
 name aside, this is about 
designing well known concepts to
 how we did web.  The idea was 
that by having all of our team 
members from product managers to
 designers to developers to QA 
embracing the complexity of the 
web with a component-based 
approach.  We could drive the 
efficiency and make our core web
 features turnkey.  But before 
we  started hitting the keyboard
, we took an  introspective look
 at ourselves.  What other 
requirements, needs, wants, did 
we have beyond those of a 
standard, component-based design
 system?  What special 
challenges did our context bring
 to the table?  In the end, our 
special needs and wants for the 
NDS distilled down to these four
 items.
Number one, to facilitate deep 
theming capabilities.  To work 
with any language and any 
framework.  To support our 
micro-site architecture.  And to
 deliver user interface as a 
service.  So let's look at these
 each in more detail.  Starting 
with
 facilitating enemying 
capabilities.  We would work 
with the entire spectrum of the 
theming needs.  One perspective 
being the brand out of the box 
EA corporate brand.  To the 
opposing stream, one that is 
heavily themed in a very focused
 and specific manner for a 
specific game.  And in some 
cases,  meeting the very 
stringent style guide 
requirements from a -- such as 
with Lucasfilm for the Star Wars
 franchise.  And now, number 
two, to be language and 
framework agnostic.  This is 
2015, still.  And our group at 
the time was the as a result of 
several team mergers and 
shuffles.  And we had a plethora
 of languages and framework in 
play.  Frameworks and library, 
Drupal, Rails, Spring, Angular 
and Dropwizard to
languages including PHP, Java 
and YouTubey.  And content 
management systems such at Adobe
 experience manager and 
Alfresco.  We have diverse 
technology diversions.  So where
 to end up with the stack in the
 future, we didn't want to get 
locked in with one backend or 
frontend framework or language. 
 This must work for the unknown 
future us as well as the rest of
 EA.  So all right.  Number 
three.  Our
 micro-site architecture.  We 
have -- and to some extent still
 have -- many discreet 
applications that have their own
 teams and life cycles, et 
cetera.  But are one single 
cohesive player experience.  
What this means is that some 
design elements such as global 
navigation, responsive UI break 
points and grid, login flow, 
preorder page, need to be 
centrally controlled and 
consistent across all of our 
sites.  While other design 
elements can be customized for 
our site.  Last up, number four,
 user interface as a service.  
So given this micro-site 
architecture, how do we avoid
projects that aren't being 
actively developed from falling 
behind and getting out of sync 
with the rest of the EA 
ecosystem?  How do we keep all 
the projects  ing to the latest 
version of this design system 
with minimal effort?  By 
delivering our UI conceptually 
as a live service, we hope to 
address these issues and really 
embody the mind-set of  &quot;Leave 
no site behind.&quot;  Okay.  So 
begin our goals to build this 
component-based network design 
system, coupled with our four 
special needs, where do we start
?  I mean, what's the approach? 
 The architecture?  The systems?
  The tech?  The tools?  I mean,
 there's a lot of questions.  
So, just like the purple pattern
 states, and like any developer 
should be, I am lazy.  And 
knowing that our general problem
 space of building a 
component-based design system 
was not a novel concept, it made
 no sense to start from scratch.
  There's so much out there.  
And there's so many people to 
learn and leverage from.  So we 
have begun reading, listening,
experimenting with, and 
consuming anything and 
everything we could possibly get
 our eyeballs, ears, and hands 
on in regards to the topic of 
style guides, design  systems, 
and UI frameworks.  
Serendipitously, a new podcast 
from Styleguides.iO was out and 
posting fresh podcasts on this 
topic right around 2015.  What a
 bonus.  I would like to talk 
about three particular paradigms
 and systems that were quite 
inspirational and key to our 
path to web components.  
Bootstrap and sort of friends, 
Lonely Planet, and the 
government of the UK.  Starting 
with the  ever-popular 
Bootstrap, and more generally, 
UI  frameworks that follow this 
same approach.  So here is a 
simplified example of what 
integration of a Bootstrap-like 
component library might look 
like.  You include a pre-bundled
 CSS and JavaScript file from a 
CDN location and go off and use 
the  components the system 
provides.  Seems easy.  Seems 
awesome.  Seems good, right?  So
 let's use this
pagination component as an 
example.  It's a good one 
because it has the complex UI, 
different states, some brains 
inside, and it really needs to 
interact with other components 
and code to actually do 
something that's meaningful.  So
 let's see how we integrate this
 component.  We start by going 
to the documentation for the
 paginator, find the HTML 
snippet, and copy and paste this
 large chunk of code into our 
application.  Okay.  That's not 
good from a reusability and 
upgradeability standpoint as we 
have essentially forked this 
chunk of code and will need to 
manually merge those updates as 
they come along.  And 
additionally, little to no 
encapsulation, all the style are
 exposed as an integrator.  What
 is the public API?  All of it? 
 We're not done.  We need to 
hook up some behavior now to 
this pager by means of 
JavaScript.  And this is 
generally completed by  grabbing
 a reference to the root element
 of the component, passing to a 
factory and constructer as
shown here.  Okay.  So the 
Bootstrap model shows us one way
 to do it.  Let's move on to 
Lonely Planet and see their 
approach.  Much like us, Lonely 
Planet had a micro-site 
architecture.  Many sites, each 
with their own stack and team 
around them, that need to work 
together to provide a single, 
cohesive user experience.  Their
 initial approach was to create 
a shared UI layer following the 
Bootstrap-like model we just 
explored.  And in this diagram, 
taken out of a talk by Ian 
Feather of Lonely Planet, you 
can see the two core problems 
around spring reuse depicted.  
The shared layer has the most 
reuse, but changes here can 
affect all the applications that
 use it, risk is high when 
making applications, especially 
without a clear API boundary.  
Due to this lack of API, you 
really don't know what people 
are doing with your component.  
So over time engineers shy away 
from doing things in the shared 
layer because they're afraid of 
breaking stuff.  So the shared  
layer atrophies
 while the site-specific grow.  
 Basically the antiphony of any 
shared UI system.  So what 
Lonely Planet did with their 
system, dubbed Rizzo, was move 
away from the copy-based 
approach by encapsulating each 
component into a Rube on Rails 
component.  And one, being the 
name of the  component, and the 
second parameter being the clean
 and minimal set of data that 
the component needed to render. 
 This is much, much better.  By 
 complementing this component 
layer in the API between the 
shared layer and the specific 
sites, they're able to share or 
reduce the risk of making 
changes to the components as 
well as ease overall integration
 efforts significantly.  So the 
Lonely Planet folks really plus 
oned the Bootstrap model with 
their Rizzo system.  Naturally, 
this is my face after coming 
across Rizzo.  So excited and  
essentially ready to lock in and
 go with this approach.  But not
 so fast.  Sometime after Rizzo 
will be humming along in 
production,
Ian Feather put up a blog post 
called what we would change 
about Rizzo.  First, the 
solution was tied very tightly 
to Ruby on Rails and templates, 
and was not usable by 
applications that employed 
different frameworks.  He 
hypothesized about using 
mustache templates to mitigate 
the issue.  Second, the CSS and 
Ruby that made up Rizzo was 
bundled with a Ruby gem.  Each 
update to Rizzo meant a 
dependency update, build, test, 
and release cycle by each of 
their ten plus integrating 
sites.  Okay.  So Lonely 
Planet's Rizzo was an excellent 
overall approach.  Clean, API,  
data-driven components.  But 
before moving on, being Canadian
 and all, we thought it would be
 a good idea to check in with 
the Queen over in the government
 of the UK.  Edd Sowden, working
 with the government of the UK 
really wanted to resolve that 
issue of the effort and cost of 
propagating those changes from a
 component UI layer into those 
integrating sites.  So building 
on the core approach of Rizzo, 
they added
 the concept of a template 
resolver.  Whereas all of those 
ERB templates were shared out of
 the gem to a shared location 
and loaded to the location and  
cached locally for a short 
period of time.  This combined 
with the pre-bundling the CSS 
and JavaScript on to the 
location allowed changes to be 
propagated with minimal effort 
to all of their apps.   As you 
can see, the gov UK folks took 
the already awesome Lonely 
Planet approach and plus oned it
 big time with the addition of 
the template resolver.  Now, we 
got quite excited about this 
approach.  It seemed like an 
option to head down.  Before 
going in too deep, our four 
special needs to see how things 
measure up.  So number one, deep
 theming  capabilities.  Now, 
reminder, this is still early 
2015.  So CSS cuts and 
properties were only available 
in 10% of users' browsers.  
Okay.  I'm not sure how we can 
do this exactly.  You know, I 
guess we can figure something 
out.  Perhaps each site can 
build their own CSS
override file that has the CSS 
rule sets to be modified to 
theme those components.  Okay, 
but what happens when we 
refactor CSS or introduce a new 
component.  We'll need to 
rebuild the override files.  
Okay, tools to build, process 
some documents, people to train.
  All right.  Number two, let's 
see.  Working with any language,
 any framework.  Well, I mean, 
we could just use mustache 
templates, coupled with the same
 dot UK resolver approach.  We 
could build client libraries for
 every language we need to 
support.  That's like PHP, Java,
 JavaScript, ideally.  And 
ideally, have first-class 
integration into the frontend 
and backend frameworks we might 
use.  So that's at least four 
frameworks.   Oh, boy.  There's 
already a lot of open questions.
  Plumbing and miscellaneous 
pieces to worry about here 
already.  Now, remember, I'm a 
lazy developer.  I don't want to
 write and maintain code if I 
don't have to.  I really wish 
that there was just an off the 
shelt solution that I could
just grab, read some docs, gives
 me everything I need, and one 
nice, cohesive package.  Okay.  
So back to the drawing board.  
What else?  What else?  What 
else?  I mean, we have designs 
for all our components now.  
Like, we need to start getting 
on some code really soon.  So I 
remember this hipster tech that 
was brewing for what feels like 
years now.  Sounds cool on 
paper.  Web components and 
Google Polymer I think it was.  
That's right.  I remember.  
There was a talk at Google I/O 
in 2013.  Oh, yes, now I 
remember.  A  fun-looking toy.  
Terrible performance due to some
 nasty, invasive DOM polyfills. 
 Basically  Chrome-only.  I 
mean, way too hipster for this 
job.  This is all of the web 
hinging on this decision.  I 
need a solution that's ready for
 production at EA scale.  Like 
today.  Oh, wait.  What is this?
  Polymer 1.0.  Just released.  
Like now.   Production-ready web
 components.  Really?  All  
right.  Sounds good on first 
glance.  Backed by Google.
Focused around components and 
not  full-blown applications.  
All right, all right, chill out.
  Alex.  Back to our special 
needs first and see how things 
measure up.  Number one, okay, 
deep-theming capabilities.  We 
get theming right out of the box
 using CSS-custom properties and
 mixins that work everywhere.  
Cool.  And theme the components 
at run time too.  No build step 
 necessary.  Pretty awesome.  
All right.  Number two, working 
with any language, any 
framework.  Well, I mean, it's 
really just an HTML element at 
the end of the day, and almost 
standard DOM interface.  So 
hypothetically, anybody or 
anything that can put an HTML 
tag into a document could 
technically use our components 
built with Polymer.  Oh.  And 
all the  CSS, HTML, and 
JavaScript is bundled up 
together into an HTML import for
 client-side support, no tie in 
for frontend or backend needed. 
 Awesome.  This is sounding 
really good.  All right.  Number
 three, support our micro-site 
architecture. 
Well, it seems we can control 
the API however we want on a  
per-component basis.  That 
should work well.  And last up, 
user interface as a service.  
Well, it's just client-side 
integration.  HTML imports seems
 like it has some of the basic 
working pieces to make this 
happen.  So -- yeah.  This is 
looking really good.  So my mind
 is blown at this  .  An off the
 shelf solution that meets all 
of our special needs and lots 
more.  Tooling, docs, et cetera.
  Less code for my team to write
 makes me very happy.  And bonus
 is that most of the gnarly 
parts of Polymer are promised to
 be native web platform 
primitives sometime soon too.  A
 frameworks roadmap that states 
it wants to get smaller, do less
 over time, and eventual may not
 even need to exist?  That's  
amazing.  So with Polymer this 
hipster web components thing 
just became our top contender.  
So compared with the already 
awesome approaches of Lonely 
Planet and the government of the
 UK, web components and Polymer 
1.0 was
like a plus 100.  So in 
September of 2015, we decide to 
officially lock in with web 
components and Polymer as the 
core technology for the network 
design system.  Now, let's fast 
forward two years later.  Down 
our journey with web components,
 Polymer and the NDS.  What did 
we end up building?  How did our
 four special needs sort of hold
 up in real life?  Did web 
components and Polymer meet my 
mind-blown expectations?  I'm 
pleased to say that we have 
approximately 75 components 
arranged into one of six 
component families.  Which are 
just logical  groupings of 
components based on their 
purpose.  Lest look at a few 
examples.  Starting with our 
most commonly-used component, 
our call to action, or button 
component.  It looks quite 
polymorphic and supports text, 
text and icons and images, and 
so on.  And comes with dual 
analytics tracking out of the 
box, ensuring that every button 
on every site sends consistent 
and meaningful data.  Next up is
 our pagination component.  
Something
with quite a bit more logic and 
state than a button.  To me this
  paginator really showcases the
 power of web components.  All 
that complex structure, style, 
and behavior are a nicely 
encapsulated away behind this 
minimal, clean, declarative -- 
and imperative --  API.  In this
 example, we just listen to the 
page change event and do what we
 need to do with the  data.  We 
also have some very high-level 
components that are almost like 
encapsulated mini applications 
all on their own.  This 
newsletter sign-up has various 
states for unanimous users, 
authenticated user, already 
signed up, as well as it 
provides a multi-step flow 
complete with error handling and
 integration with a few external
 service API.
All right.  Now with the sample 
of components in mind, let's 
look at how we have combined web
 components and Polymer to bring
 these to fruition.  Starting 
with facilitating that broad 
spectrum of brand specificity 
and fidelity we needed.
we have about 300CSS custom 
properties set at the 
system-wide level there to 
mostly control color and 
typography.  We love that even 
back in 2015 when CSS custom 
properties were not widely 
available, the shim that came 
with Polymer 1.0 allowed us to 
use this powerful tool to theme 
dynamically at run time with no 
build necessary.  In fact, we 
now control these primarily 
through our content management 
system.  So a designer and a 
product manager can spin up a 
site and theme it without any 
developers involved.  We also 
have many CSS custom properties.
  Used as internal design 
tokens.  And are really there 
just to keep things dry from a 
development standpoint.  But 
they should not really ever be 
exposed or altered by our 
integrators in any way.  And so,
 you know, these are rules such 
as our responsive grid, gutter 
and column widths.  So what we 
do is that at build time, using 
post-CSS, we substitute and 
compile in the static values for
 these design tokens, making 
them essentially
immutable, and leaving only the 
themible CSS properties exposed.
  So this is our tile, or our 
card component.  And used in 
mace places where we have lists 
to display.  Such as a news 
article, videos, or characters 
or weapons.  And although CSS 
custom properties are great for 
granular CSS-level control, 
using attributes to theme and 
control a component has been 
deemed to be very powerful.  An 
example to illustrate this well 
is the attribute on this tile 
that has two possible values, 
horizontal and vertical.  Using 
the host pseudo selector, we can
 have this single attribute 
impact the entire presentation 
of the component.  From 
placement and size of the media 
assets to different layouts 
completely.  Mobile versus 
desktop.  All by letting CSS and
 the browser do all the hard 
work.  No imperative JavaScript 
needed.  So just by using those 
system-wide, themible CSS custom
 attributes and the 
per-component HTML traits, we 
can deliver all of these tiles 
using the exact same
component.  All themed at run 
time to boot.  Okay.  Number 
two.  Let's talk about how the 
need to be language and 
framework agnostic has gone.  
Here's a very  simplified view 
of our overall stack today.  We 
have an experience manager as 
the CMS manager,
  Lightbend's middleware.  And 
the backend.  When we think 
about a component, we think 
about the entire stack, not just
 the frontend.  Ensuring we can 
drag and drop a component on to 
the page in the CMS, pull on in 
the middleware, and serve up the
 component for Polymer to 
render.  Each has first-class 
integration top to bottom.  This
 is an example of a button.  But
 this does not mean that 
integrators must use our full 
stack to get the benefit of the 
network design system.  As each 
layer of the stack is loosely 
coupled and has clear API 
boundaries, it's really easy to 
use just the frontend Polymer 
component on its own.  No gem, 
no client library, just a simple
 HTML import.  Okay.  So number 
three, our micro-site
architecture.  So recall that 
some components need to be 
centrally controlled and 
consistent while others can be 
more customizable.  Web 
componentses and Polymer makes 
it really easy as we get to 
control how narrow or broad the 
API is on a  per-component 
basis.  Components that we need
 100% consistent across all 
sites, we restrict the API into 
that component.  And others that
 are supposed to be 
super-flexible have all sorts of
 knobs and switches, HTML custom
 properties and slot 
disposition.  So our pre-order 
by widget, newsletter sign-up, 
footer, all examples of where we
 keep the API minimal.  Next up,
 number four.  User interface as
 a service.  Now, we apply it 
very, very diligently.  
Super-careful to keep the NDS 
backwards and forwards 
compatible with a strong focus 
on not bumping our major version
 number for as long as possible.
  Sticking to backwards 
compatible changes, resulting in
 minor version bumps only.  So 
this  mind-set has worked really
 well as
we are currently at version 1.
31.0.  And in practice, we could
 update a site from 1.2.0 to 1
.31.0 without any code changes 
or issues.  Currently, we deploy
 a pre-built version of the NDS 
to a CDM location using a naming
 convention as shown here.  So 
this gives the URL meaning as to
 the version, the artifact type,
 and the artifact that's being 
referenced.  By supporting fuzzy
 version mask on the major 
release version, means that the 
site can ask for a one dot star,
 a one dot X, and get back a 302
 that redirects them to the 
latest 1.X release.  Which as it
 is a tagged and unchanging 
artifact, it's sent back with a 
very aggressive caching policy. 
 So as you can see, our special 
needs have come to fruition 
thanks to web components and 
Polymer.  Now, I'd like to 
briefly cover a few more wins 
and show off some of our  sites.
  So as mentioned, we have 75 
components in production.  
They're now powering about 30 
sites in total.  And that number
 is growing rapidly every  day. 
 On
the left is EA.com, corporate 
site, using the out-of-the-box 
default theme.  And on the right
 is the more heavily styled 
Titanfall 2 site.  But both 
using the same version and the 
same HTML  import.  And here are
 a couple more with Mass Effect 
on the left.  And on the right, 
an upcoming new franchise from 
BioWare, Anthem.  And we have 
gone from a previous tedious and
 lengthy process to bring up a 
site to now only taking one and 
a half weeks of content-only.  
That means no development effort
.  So component-type thinking is
 really just how we operate all 
functions now.  We don't design 
and build pages anymore.  We are
 always looking to decompose and
 then compose with 
component-based building blocks.
  And as a bonus, to the delight
 of our digital intelligence 
team, we have been very 
consistent and complete 
analytics tracking across all of
 our components, allowing us to 
compare apples to apples across 
our different sites.  And, of 
course, efficiency and economy 
of scale.
We've reduced duplication.  We 
have better engineering mobility
 between projects and teams.  
And with a predictable, proven, 
and streamlined system, we have 
much, much lower project risk 
and a far more dependable 
schedule.  So going back to this
 original goal of living in a 
world of making our commodity 
web turnkey, low effort and 
maintainable, how have we done? 
 I would say a resounding 
success thanks to web components
 and Polymer.  Thank you very 
much.
[ Applause ]
SPEAKER: All right.  It is time 
for our first break.  We're 
running a little bit late, which
 is Polymer Summit tradition.  
So this is coffee and tea and 
light snacks available over in 
the catering  area.  And we'll 
start up again at 11:35.
 [Music playing]
SPEAKER: I got some music to 
play me out this time.  All 
right.  So our next two talks 
before lunch are actually the 
two core engineers of  Polymer, 
that's Steve Orvell and Kevin 
Schaaf.  They do everything 
together.  They're sharing the 
same talk block.  Monica called 
them Stevan.  And Steve 
complains it's not fast enough 
and good enough.  So we put it 
in charge of it and now he's 
here to talk about it.
[ Applause ]
STEVE: Hey, everyone.  My name's
 Steve Orvell, I'm an engineer 
on the Polymer team.  And we're 
here to talk about the next 
generation of Polymer  elements,
 like Matt said.  We're still 
pretty early in this process, 
but iterating quickly as I hope 
you'll see.  So it's this kind 
of reusable elements that we're 
talking about.  They're used in 
almost every app.  And we have a
 pretty large catalog of them 
that we've published on the 
polymer project.  They have been
 out for a while, a couple years
, since Polymer 1.  So we have 
been asking ourselves, what 
needs improvement?  Matt gave a 
preview of  that.  We have 
gotten a ton of feedback from 
users inside and outside of 
Google.  And YouTube built an 
application with Polymer.  They 
asked for it to be faster.  
People come to YouTube to watch 
videos.
It will make YouTube better.  
And Chrome has asked us to make 
Polymer elements smaller.  Which
 is kind of crazy since you 
don't have to download them to 
get the settings page.  They 
download with the Chrome app.  
If we make them smaller, it will
 make it faster.  Uses like 
that.  And our own team,  easier
 to maintain.  They have 
specifically voiced concerns 
about our behavior system in 
Polymer 1.  It was a little bit 
cumbersome to use and a little 
bit hard to make maintainable 
code with.  So they asked us to 
work on that.  And, of course, 
all of our  users always want a 
lot more features.  We have 
gotten a ton of GitHub issues on
 that.  And we actually know 
that all of our users actually 
want all of these things.  They 
want elements to be  faster, 
smaller, easier to maintain, and
 have more features to size.  
It's especially critical if 
you're making PWAs that load on 
small 3G networks.  Of course 
you need things to be as small 
as  possible.  So we thought of
this feedback when we were 
designing Polymer 2, and we 
realized that the needs of these
 reusable elements, like inputs 
and check boxes and buttons, are
 really not the same as the 
kinds of elements you're making 
when you're  making big 
applications.  When you're 
making these application views, 
you're concerned really with, 
you know, getting data from 
server and transforming it to 
the UI.  Managing those complex 
interactions.  You want the 
ergonomics to be good.  With 
reusable elements, it's size and
 speed and look and feel.  So we
 realized that one size does not
 fit all in Polymer 2.  We 
decided to throw out our 
behavior system in Polymer 1.  
And in Polymer 2, embrace  
mixins in JavaScript.  And make 
it more modular, pay for play.  
Features are there if you need 
them.  And allow tows hit the 
use cases.  And the existing 
elements, hybrid elements, and 
these are a bridge to the 
future.  We haven't addressed 
the feedback we have gotten in 
these elements.  They're there 
to let
you transition from Polymer 1 to
 2 seamlessly.  So with that in 
mind, we're starting to think 
about what it means to make the 
next generation of  elements to 
start addressing that feedback. 
 So we're going to take a look 
at some of the topics that we're
 thinking about, and you're 
going to get an early peek at 
that.  First we're going to look
 at addressing the feedback to 
make it smaller and  faster 
directly.  Then look at using 
extension, a new feature in 
Polymer 2, what that means for 
elements.  And finally, dive 
into some improvements that are 
coming in the platform around 
styling.  All right.  So let's 
start and we'll look at making 
elements smaller and faster.  
And to do so, we'll go ahead and
 remake an old friend of ours.  
&amp;lt;paper&amp;gt; input.  With a small, 
fast one, material design look 
and field.  Animation, 
validation effect with the 
customizable message.  And need 
the native features from the 
input element, access ability, 
the types and all that.  To make
 it
smaller and faster, ask 
ourselves, what is the minimum 
we need?  And start by making a 
base class.  And we can use this
 for in input element and maybe 
other elements too.  Back to the
 modular design of Polymer 2.  
Built on top of HTML element.  
And a number of mixins.  Helps 
us manage getters and setters.  
Templatestamp, helps stamp a 
template.  And wrap it all 
together in Polymer Element 
which we think is good for 
building the application view 
elements.  Just about 12K my any
 if Id and Gzip.  That's a good 
tradeoff.  But a small and fast 
element, it's a lot more than we
  need.  So we're going down to 
property accessors and use that.
  That's just 2K out of the 
works.  It's going to help us 
with making the element really 
small.  To make it fast, go 
ahead and use the  mantra, do 
less and be lazy.  Do as little 
work as possible to render the 
element and do work lazily only 
as the user needs it.  The last 
two slides were from previous 
talks given at Google I/O this 
year. 
Monica talked, Polymer: billions
 serves; lessons learned about 
the modular design of Polymer 2.
  And I gave a talk last year, 
see the universal.  Practical 
with Polymer.  And dive into  
propertyaccessors and see what 
it gives us out of the box.  
Helps us make accessors, getters
 and setters, where we can react
 to changes when  properties are
 set.  And synchronize 
attributes which is important 
when uses HTML.  As has an 
explicit API for turning on 
properties.  That's to better 
integrate with the bootup 
process as it comes in and take 
the attributes and able to 
process as one set of changes.  
It's more efficient.  And 
triggers the life cycle method 
to allow one-time initialization
 work.  And finally, we have an 
entry   called properties 
change, allows us to react to 
the batched set of properties 
changes.  And in Polymer 
Element, this is implemented for
 us, we get data binding and 
property observers and things 
like that.  But we can implement
 this and do the work
we need when properties change 
to update our rendering.  All 
right.  So now that we 
understand property  accessers, 
now build a base class on top of
 it to make the paper input
 replacement.  And that sounds 
good.  Enable properties, 
callback is the good time to do 
it, turn the system on.  And 
then it'll define a template 
getter, and we'll use a string, 
works well for
 modules.  This is currently 
optional in Polymer HTML 
element.  And input the ready 
method, and stamp the template 
into shadowRoot.  Which is 
great.  And create the ID map.  
IDs for template it's because 
we're working with the IDs 
directly.  Call it super.ready. 
 This is the easiest way to have
 a broken element, forget to 
call super.  Do that.  So that's
 all we need to do to put in the
 base class.  Property 
accessors, and simple element.  
And then simple input.  This 
relayses paper input.  Look at a
 decorator pattern, I'll explain
 in a second, look at the 
template and finally
the code.  Specifically the 
ready method and the properties 
changed method.  So first, we're
 going to use the approach, the 
decorator pattern.  Ask the user
 to put the input and the label 
into the element.  This is a 
change.  We didn't do this in 
paper-input.  And it was a big 
pain.  And the reason was if we 
put the input in the ShadowDOM 
and wanted to expose the power 
of the element, we have to 
forward all that information.  
That's a lot of complexity to 
manage and not a good tradeoff. 
 Use the decorator pattern, 
makes it simpler.  And get the 
native accessibility and the 
type ability out of the box.  
All right.  So let's define the 
template.  And we have some  
styling.  This is the minimum we
 could do to get the material 
look and sign.  I won't bother 
with that since you're CSS gurus
.  And then the slot for the 
shadowRoot and the label.  And 
then some  non-semantic nodes 
that we get out of the way.  And
 here we have an underlying node
 that helps us manage the
animation.  That's really all 
there is to it.  So let's look 
at the ready method.  This is 
the  bootup work.  And since 
we're using simple element, we 
call super.ready, we're going to
 stamp the element.  This is 
before the element gets 
rendered.  That's fine.  But we 
have to be aware of that work 
since we want the element to be 
fast.  Anything we do is after 
the first render of the element.
  Set up the CSS so the initial 
render is free.  We don't have 
to do anything to get it to 
show, right?  And after the 
render, immediately find the 
input.  Just using some Shadow 
damn API to do that.  And add a 
couple of event listeners and 
use a private property to track 
the focus state and I do a 
little bit more for the label 
too.  And that's really all we 
need to do in ready for that 
setup work.  And then go ahead 
and implement properties changed
 where we react to the 
properties being set like 
focused and a couple others.  
And basically we'll be 
manipulating the DOM directly.  
Here I'm
going to add a class to the 
underline element to tell if 
it's focused and an animation.  
And the label and the error 
message.  And we get this this 
which is hopefully looks the 
same as the paper-input.  
Material look and feel, has a 
validation guide.  And looking 
pretty good.  So how do we do on
 size and speed?  Well, pretty 
good.  Just a little over 3K 
using property  accessors.  The 
little base class that we used. 
 And then, you know, the code we
 have for the simple input.  And
 now compared to paper input, 
which is a hybrid element, not 
leveraging Polymer 2's design, 
it's the legacy from Polymer 1, 
it's 10 times  smaller.  That's 
a huge improvement.  And by 
using the decorator pattern and 
cutting out features, made
 it 5X faster to render.  Which 
is a humongous improvement.  But
 the features we eliminated, 
users want.  What to do about 
that?  The next topic, which is 
extension, and see if this will 
help us at all.  So extending 
elements, as I mentioned, is 
sort of
a new feature for Polymer 2.  
And we get to rely on JavaScript
 for doing this.  And here's 
some things to kind of keep in 
mind as you're using extension 
and making elements.  And the 
first is to keep our base 
classes simple.  We did that 
with  SimpleElement, that's 
good.  Using extension to add 
features.  That's the answer to 
add the missing features we 
didn't support yet.  And 
importantly, if we can design 
with extensibility in mind, at 
least in the obvious ways we can
 anticipate, it's easier for us 
as we extend them.  So, as I 
said, JavaScript classes really 
give us a lot of help with 
extending elements, because it's
 native now.  And that's  great.
  But when we're kind of 
designing this, we were thinking
 about -- what are the 
templates?  Especially with the 
designing in HTML, we were 
concerned we might need a system
 to help us do the kinds of 
things to do when you're 
extending  elements.  When using
 modules, and especially the 
JavaScript string
template literal to define a 
template, that might change 
things.  Investigate that.  Two 
use cases, specifically.  The 
first is a subclass of an 
element and you want to wrap 
around the superclass template. 
 That's a common use clays.  The
 other common case is the 
subclass of an Element and it 
wants to experts into the 
superclass  template.  And 
hopefully do it in a way that we
 don't have to copy and paste 
the entire superclass network.  
Let's look at the two use cases.
  This is a contrived example to
 see what's going on.  A simple 
element that asks, how do you 
feel?  And responds.  Now, if we
 make a subclass of this, define
 the template and use a stream 
template literal, and a native 
class to refer to the 
supertemplate.  Do that for free
.  And to do the wrapping, 
insert the content.  Adding a 
header there and adding another 
question.  Kind of get that for 
free.  So that seems pretty 
good.  But now let's go ahead 
and say, what if we wanted to 
subclass this?  And we realized
that the way that we've 
organized this here -- well, 
there's a header and there's 
some sort of list of questions 
-- can we design this element to
 make it better as a, you know, 
better to subclass?  Easier to 
subclass?  So if instead we hear
 -- we have a template for the 
header, and we expose that, then
 now we've created an override  
 that the subclass can 
customize.  And the same thing 
for the questions.  You can see 
we have added very little to the
 base class and the rendering is
 the same.  But if we want to 
subclass the element and make it
 look like this with a different
 header and maybe a couple other
 questions, then all we need to 
do is override the header 
template like that and the 
questions template like that.  
It's just that easy.  So we can 
kind of see that extending 
templates when we're using those
 string template literals, it's 
possible to do a lot without a 
system.  Especially, as I said, 
using those string template 
literals.  And using classes and
 mixins for
polymorphism just like we saw.  
So how can we apply any of this 
to the simple input element?  
Let's go back to the  template. 
 And we know from our experience
 with paper-input that people 
want to do a lot of  
customization with the actual --
 how the input looks in the 
material design, look and feel 
there.  They want to add icons 
to the beginning of it, maybe to
 the end of it.  And we can add 
a lot of complexity to our base 
class to support all of those 
needs.  Or we can just expose an
 override   for the input 
template, and that adds a very 
minimal footprint to our base 
class, but it's going to expose 
a lot of power as we subclass 
the element.  For example, if we
 make something like this, a 
credit card input, to show a 
credit card after the input, we 
can customize that input, add 
some styling, call it super, add
 an element for the credit card 
and then it would look like 
that.  Obviously we want more to
 do a full credit card input, 
restrict to numbers and validate
 the
card.  But the subclass gave us 
a helping hand.  We're excited 
about leveraging extension to 
build new elements.  And we know
 this because it's going to help
 us factor our code better.  We 
factor our code better, it's 
going to be easier to maintain. 
 It's easier to maintain, we're 
going to have more time to add 
features and have a good helping
 hand to adjust the core 
feedback we have gotten.  Okay. 
 So, move on to the last topic, 
some changes coming to styling. 
 So you might ask, why we're 
talking about styling?  Isn't 
this a solved problem with web 
components?  We have Shadow
 ShadowDOM, help us encapsulate 
styling.  Leaking into or out of
 the elements.  And we that is 
with theming, which is a more 
global concern.  But we have an 
answer, CSS custom  properties, 
natively available on all major 
browsers now.  They naturally 
flow through the ShadowDOM 
boundary.  We can use them in 
the custom elements if we want 
to.  And let's sketch this out 
so we
understand this.  So I didn't 
show this, but here is a little 
custom property that we can set 
here in a content view that 
might have a simple element in 
it.  And then the CSS that I 
didn't show in the simple input,
 might use a custom property 
like this, we're going to 
default the underlying color to 
Navy.  And in this case, it's 
going to be orange.  That's all 
we need to do to expose the 
color to be themible to the 
outside world of our element.  
And that works great.  And we 
also had in the styling here in 
the simple input a little bit of
 opacity.   The designer said 
that's there to make it look 
good.  But then we might have a 
user that says, oh, that 
opacity, I want to be able to 
set that too.  So then we have a
 little bit of a problem.  And 
that is because, you know, we 
could expose a property for the 
opacity, but then the user might
 want to, you know, make 
president padding different or 
any of the other hundreds of 
properties in CSS.  We have a 
scaling property with
custom properties like this.  So
 there's something missing here.
  And on the Polymer team we 
help
ed propose @apply which you may 
be familiar with, as an 
extension to custom properties. 
 And we worked with tab Atkins 
who works at Google.  And you 
put whatever information you 
want as a custom process.  And 
opacity here as the underline.  
And make it with the custom 
element.  And we changed the 
variable name to match here.  
And all of those could be 
applies with the custom element.
  This would totally solve our 
scaling problem.  So we have a 
pretty good story with styling 
with ShadowDOM for encapsulation
 and custom properties for 
theming.  But @apply is an 
important piece of the puzzle to
 solve that scaling problem.  So
 I have some good news and a 
little bit of bad news, and some
 more good news.  So first the 
good news, although @apply is 
not standard in any browsers 
today, we have a shim in Polymer
 that's been around since 
Polymer 1 and carried to 2 and 
used out
of the box in the hybrid element
s.  Along with the spirit of 
Polymer  2, it's a opt-in you 
can load with the Applysubpoena 
shim.  Bad news, it's probably 
not going to make it into native
 implementation of browsers.  
The reasons are complicated.  
Issues with nesting.  And issues
 with how it integrates with 
colon focus, colon  hover.S and 
this a link to Tab Atkin's blog 
with the details and information
 about that if you're 
interested.  Back to some good 
news, tab and crew have a better
 alternative, that's part and 
theme.  So why is it better?  
It's actually kind of how the 
platform itself accomplishes 
this type of theming, as we'll 
see in a second.  And it's also 
a revival of a previous proposal
 from a couple years ago.  But 
the issues with that earlier 
proposal have been addressed.  
Let's take a look at that really
  quickly.  So this is a native 
input element, and it has an 
attribute called placeholder 
which probably a lot of you are 
familiar with.  And
it's shown in the input if 
there's no value there.  And 
when this was out of the 
platform, users said I want to 
style  that.  Style what it's 
going to look like.  And the 
platform answer is pseudo 
elements.  They have the colon, 
colon syntax.  Similar to 
@apply, and  customize how the 
place holder looks.  In this 
case, orange and center.  That's
 how it does it with the pseudo 
elements.  And the custom 
element with this new proposal 
would do it like this.  The 
slider element.  And the 
shadowRoot, and I can expose by 
part attributes.  Make the 
slider have a track and thumb 
that's stylible, themible.  And 
then users would be able to 
target these pseudo elements 
like this with that same colon, 
colon syntax.  Now with part and
 the name of the part in parens.
  So this kind of solves some of
 the same problems as @apply.  
That's looking good.  Works 
better with pseudo  classes.  
That's great.  But notice one 
issue, which is we had to be 
able to target the slider 
element. 
That element had to be in our 
shadowRoot in order to styles it
 part.  We can't do it from 
outside.  So it's not great for 
theming where theming is more of
 a global question.  This is 
actually the fundamental problem
 with the earlier proposal.  It 
didn't support this kind of 
composition.  And the new 
proposal has an answer, this is 
forwarding.  This is a crazy 
syntax that may change.  It's 
earlier still.  But uses the 
arrow, users of the content view
 element here can style this 
slider's thumb by this new name 
here, slider1-thumb.  And it's 
separated.  I can do the same 
thing for the track.  We have a 
catch all here and that would 
expose all the parts with the 
prefix or the suffix.  Say the 
content view element was in a my
-app element.  I can target the 
exact slider parts with the 
slider1-thumb and make it blue. 
 And that's powerful and looking
 good for theming.  There's, of 
course, probably the more savvy 
of you are saying that looks 
cumbersome, I have to forward 
all
the information.  That's good, 
that's explicit.  Probably what 
you want to do all the time.  
But there's an answer if you 
can't do that all the time.  
That's::theme.  We don't have to
 forward everything.  If we use 
::theme, it's every in the 
shadowRoots and elements inside 
of it.  So how might we use this
 in our simple input example 
that we have been kind of going 
through?  Look at the template 
and look at the div that was for
 the underlying animation that 
users wanted to apply that 
styles to that we used @apply 
for.  We can just as a part.  
That's all you need to do.  So 
that's actually looking pretty 
good.  And promising.  So part 
and theme were proposed earlier 
this year at the CSS working 
group meeting.  There's a lot of
 enthusiasm for it, because, 
again, as I said, it's kind of 
how the platform itself 
accomplishes this same goal.  
And Tab is fleshing out the spec
 you can have input if you want.
  We're right now in the process
 of thinking about what this 
means and when this is
going to come actually natively 
in the platform, which we think 
is at least a year or two out.  
And how we might make a shim for
 this in the meantime.  And so 
then if we kind of zoom out 
again and go back to the 
feedback that we had at the  
beginning here, making elements 
faster, smaller, easier to 
maintain and add more features. 
 We kind of think that if we 
make things sort of along the 
lines of that simple input using
 extension, adapting to the 
platform as we need, squint a 
little bit, that we might 
actually have made a lot of 
progress towards that.  So let 
me now go back to the sort of 
demo they showed at beginning 
here.  And this actually is not 
it.  This is a new version 
that's sort of -- we have been 
prototyping with some elements 
made sort of along the same 
lines as that simple input 
element.  You can see that 
there's some missing stuff yet. 
 It's not all there.  But the 
old version was built with 
hybrid elements.  And it's 
actually a lot of code.  You 
know, it's bringing
 along all that Polymer 1 legacy
 API.  And it's more than 100K. 
 The new version so far -- 
again, not done -- is just 6K.  
So that's a ton better and we're
 really happy with that.
[ Applause ]
So there's still a ton of work 
to do.  It's still early.  But 
we're iterating pretty quickly. 
 And that's all I have.  So 
thank you.
[ Applause ]
SPEAKER: All right.  So now we 
have the second half, which is 
Kevin Schaaf.  So the thing to 
know about Kevin is he's 
actually a Game of Thrones  
high-hard fan.  So feel free, if
 you see him around, or in the 
Polymer Lounge, ask him about it
.   Normally the code of 
conduct, being kind to each 
other, means no spoilers.  So 
make sure -- he's seen the 
latest episode.  Make sure no 
one else is  around.  He may 
protest, he may say, no, I never
 watch that damn show.  Why did 
Matt say that?  It's just an act
.  So Steve is here talking 
about  elements and how to make 
our elements better.  We get a 
lot of questions on how to make 
apps with Polymer and state 
management and how to do the  
things you need to know to build
 an app with  Polymer.  So with 
that we have Kevin Schaaf.
[ Applause ]
KEVIN: Thank you, Matt.  Such a 
jerk.  My name is Kevin, a 
developer on the core Polymer 
library.  Today we're going to 
talk about apps.  As you may 
know, web componentses are great
 for building highly reusable
 components like the ones on the
 screen.  That's what the web 
components were designed to try 
to solve.  But on the Polymer 
team, we have shown that web 
components are great for 
building applications as well.  
And in lots of cases, the only 
component model you need to 
build an application.  However, 
that's not to say that web 
components are all you need to 
build robust apps  using the 
platform.  And we get a lot of 
questions on the team about what
 that looks like.  What's the 
end-to-end experience with 
building applications are 
Polymer and web components.  
That's what I'm  focusing on 
today.  So imagine this scenario
.  It's Monday morning.  Sitting
 in your office minding your own
 business.  Kind of a jerky 
boss, like Matt, runs in, I have
 a great idea.  I know
how we're all going to get rich.
  I need you to build us a real 
estate listing app.  Okay?  Stay
 with me.  It's going to be 
awesome.  It's going to have a 
slick, cool, user interface.  
Really modern.  Users are going 
to search for whatever they 
want.  It's going to come up in 
a nice list.  You'll have 
sorting and filtering.  Go to 
the map view to the house meet 
your criteria.  Maybe a mortgage
 calculator in the corner.  All 
is kept in sync as its changing.
  The users can log in, bookmark
 their favorite homes.  Of 
course, a responsive layout, and
 it's got to load super-fast on 
3G.  Amazing SEO so users can 
find all these houses.  Of 
course, it's got to be 
accessible and international to 
reach the most number of users 
we can.  And you have two weeks 
to get it done.  Right?  So this
 is the question: do you feel 
like you have all of the tools 
and patterns that you need to 
get up and started quick
ly?  To build out  features 
quickly and iteratively to 
create a great
user experience with 
maintainable code that's going 
to scale well into the future?  
Because that jerky boss is going
 to want you to keep adding 
features after you get this 
first proof of concept done.  So
 if we walk through the scenario
 from start to  finish, there's 
a lot of things that we, as web 
developers, kind of have to 
learn and master and know where 
to start.  So we have to make 
sure that we know how we're 
going to structure our 
application to deliver great 
performance to our users.  We 
want to scaffold out our app 
from a good starting   so we 
don't have to reinvent the wheel
 with every app we're doing.  
Make sure we're following good  
patterns with the UI so it's 
maintainable and reusable.  
Internationalized and 
accessible.   Following good 
layout patterns for responsive  
layout.  We want to make sure we
 have really solid and 
repeatable patterns for managing
 state in our application and 
make sure the application is 
easy to
reason about.  Good workflows 
for server and  debugging and 
linting and testing during the 
development.  Optimize our build
 for development.  Efficiently 
serving the application for 
deployment.  It's a ton of stuff
 to master to get an awesome 
user experience out.  It can get
 kind of blurry trying to figure
 out where to start.  But the 
good news is, there's help.  The
 Polymer app tool box we 
launched at IO last year 
provides answers for a lot of 
these topics.  So the Polymer 
CLI, the init command there, 
scaffolds for a good template.  
A good starting  .  We have the 
app-localize-behavior, helps 
format strings in the Polymer 
templates.  And browsers have 
good cross-platform support for 
formatting numbers and dates.  
The paper-elements have had a 
strong focus on accessibility.  
Our app-layout provides 
components for common responsive
 layout idioms.  The serve 
command in the CLI gives us a 
nice development server to use. 
 Chrome Devtools has a great 
support for web components.  And
we're committed to helping the 
Chrome team improve the 
development experience using web
 components.  Polymer lint, 
static, and  
web-component-tester, framework 
for continuous integration.  And
 the Polymer build provides the 
optimizations for minification, 
translation, that sort of thing.
  But as you can see, there's a 
few places in the story that if 
I sat down and built this 
application that I talked about 
for this  talk -- and there are 
a few places in the story that I
 realize we probably deserve a 
little more focus than we have 
given them in the past.  These 
are what I'm going to talk about
 today.  Talking about how we're
 going to structure the 
application to hit the best 
performance, how to manage the 
UI, manage state in a complex 
application like this and how to
 serve it for deployment.  So 
there's a reason that I put 
performance first on this list. 
 And that's because, like, the 
number one way you can make sure
 that your application 
performance is going to be
horrible is to think about it at
 the very end of the app you 
built and go, hm, I wonder how 
fast this thing runs.  You owe 
it to your users to make 
performance the number one 
concern for how you're 
structuring your application.  
And a lot of the frontend web 
development world is enamored 
for this before performance.  
Serve down static HTML first 
painting on the screen waiting 
for the rest of the JavaScript 
to load.  Unless your 
application is just a shell 
around passive, static content, 
what the user actually wants to 
do is interact with your 
application, right?  They want 
to select a departure date.  Or 
sign up for a newsletter, or 
bookmark a house in our real 
estate application.  And  
server-side rendering helps with
 none of this.   Gives them 
something to look at until the 
code loads and they can do what 
they want to do.  So if you have
 to send down a huge bundle of 
JavaScript to transfer that 
initial rendering into an 
interactive application, users 
are going to hate
you.  And if you don't believe 
me, these are two real-life 
server side rendered 
applications.  So I'll get this 
going.  So as you can see, they 
render to the screen really fast
 and they give you this 
impression that you can start 
using the application.  It's 
there.  I have this throttled 
down to 3G.  This is running in 
Chrome Devtools on mobile
-typesettings.  Results in this 
horrible experience for the 
user.  They have to sit there 
wondering when the thing is 
actually going to become 
interactive.  And this is not to
 say that server side rendering 
is wrong or a bad technique to 
have in your arsenal for good 
performance.  In fact, Trey is 
here to give a talk tomorrow 
about awesome work he has been 
doing to be able to server side 
web components on the server.  
But rather it just says that 
there's really no shortcuts to 
delivering a good user 
experience.  We just have to be 
focusing on the right metrics.  
And for a lot of  applications, 
the right metric is probably not
 the
time to first paint, but the 
time to interact.  The time 
until the user can actually do 
something on your site.  And the
 best way to ensure a good time 
to interact, don't make the user
 wait for anything they didn't 
ask for.  That means only send 
down what the route requires in 
as few round trips as  possible.
  Sending as little duplicate 
information as possible between 
routes.  That sounds easy  
enough, but historically it's 
been fairly difficult to 
achieve.  That's why on the 
Polymer team we have been 
working hard to promote and 
getting people to think about 
the PRPL pattern.  This gives a 
 straight-forward pattern for 
factoring applications for 
optimal delivery.  So in short, 
we would start by factoring our 
application around decoupled 
routes that could sit back 
together in an interactive 
experience.  And then push down 
only the code that's needed for 
the initial route.  Only what 
the user asked for in the URL, 
that's all we burden them  with.
  And then
the initial route interactive.  
While the user is enjoying the 
route they asked for, the 
service worker can boot up, and 
we can be  pre-caching the rest 
of the application.  So the code
 needed for the routes in the 
background, so when the user is 
ready to move on to other parts 
of the application, we can 
lazily import the remaining 
routes right out of the cache 
and get those as well.  PRPL, 
push, render, pre-cache and lazy
 load, lazy import.  We're 
giving the user exactly what 
they want and no more.  But 
that's not good enough, just to 
follow the pattern.  We have to 
measure.  We have to measure the
 metric that makes sense for 
that.  And we recommend using 
web page tests for this.  So 
they've recently added an easy 
mode.  Go to  webpagetest
.org/easy.  And it will open up 
the site preconfigured for 
testing on mobile devices.  So 
you just want to check the 
lighthouse check box there.  
Drop in your URL and hit start 
test.  It will run a performance
 test of your
application using real mobile 
devices and real throttle 
networks.  Once it's done 
testing you'll get a result 
page, something like this.  If 
you click into the lighthouse 
score, you can scroll down just 
a little bit.  And in there 
logical the timed interactive.  
This is a really good metric to 
be focusing on when building 
your app to judge how good your 
experience is going to be.  And 
then to ensure a good experience
 we recommend, you know, setting
 a budget for yourself.  We like
 to target around 3.5 seconds on
 these mobile 3G networks.  And 
on these settings, the first 
byte from the server actually 
doesn't get down to the client 
until 2 seconds.  That's because
 SSL negotiation requires a lot 
of -- to the server.  That 
leaves a second and a half to 
get something interactive -- 
what the user wanted to do on 
the  app -- get that interactive
 on the screen.  And we found 
this 1.5 seconds of budgeting, 
if that's what we're bumming, is
 about 50 kilobytes of code.  
Doesn't
sound like a ton, but that 
starts out around 12K.  40K left
 for the budget.  As you heard 
in the last talk, we're doing a 
lot of work in the future to 
make sure our element sets are 
highly optimized to help you fit
 into this budget.  And we found
 that the best way, any time we 
were putting a recommendation 
out, give it a name.  Names are 
powerful.  As soon as you have a
 name, you can talk about it 
with other developers.  We're 
calling this PRPL-50.  Apply the
 pattern and budget yourself to 
50 kilobytes.  That's a good 
rule of thumb to ensure you are 
hitting performance.  See what 
applying the PRPL-50 pattern is 
in the application here.  Start 
with the shell, responsible for 
handling the route on the 
client, handling the top level 
clients for the route.  And then
 think about breaking the 
application down into meaningful
 routes.  For this application, 
might have a home route, an 
explore route and the detail 
route.  Start with those 
features and we can add more 
later on as the boss
asks us to.  And then for each 
of those routes, a custom 
element that encapsulates the 
view for the routes.  A home 
page, something like that.  And 
then following the PRPL-50 
pattern, try to keep an eye out 
on the code in each route and 
stay within our 50 kilobyte 
budget.  This is the general 
idea how we're going to approach
 meeting all of our performance 
requirements and ensuring we 
have a good structure for the 
app.  Okay.  So we've got the 
structure  down.  Now let's move
 into how we're going to start 
building out our user interface.
  So this usually involves 
taking UI mocks that the 
designer might have sketched up.
  Factoring those, drawing boxes
 around them and bringing down 
into individual components.  
Some are off the shelf, and some
 are application-specific 
components.  We use it to build 
it up into our final application
.  So we're going to want to 
leverage reusable components 
wherever possible because the 
best line of code is the one 
that you didn't have to write.  
Just
like npm is kind of our go-to 
source for JavaScript libraries,
 webcomponents.org is our go-to 
source for reusable web 
components.  And see what might 
fit our needs in any given 
application we're trying to 
build.  So for a lot of our app 
UI, stand on the shoulders of 
those in the community and not 
have to reinvent the field.  Out
 of the library, maybe tabs for 
navigation, icon buttons.  And 
the Google map.  There are 
components for things like maps 
in the catalog as well.  But, 
again, using custom elements are
 not just for reusable 
components.  We can use those to
 build our application-specific 
components too.  And this has a 
lot of benefits over using a 
non-standard component model.  
Some other library to do your 
application.  We can achieve a 
smaller payload.  We're using 
the model built into the 
browser.  Don't have to download
 to get that.  And encapsulation
 is important scaling out to a 
team when developers aren't 
working closely together.  And 
we get encapsulation
for free with web components.  
Built into the browser.  Like I 
mentioned before, Chrome has 
great support components for 
ShadowDOM.  And not locked into 
the framework silo.  That's an 
important  .  I don't mean 
you're just locked into a 
different silo.  That's not the 
 .  The   is that as long as 
you're using custom elements as 
your component  model, and 
properties and entitles as your 
interface for the component, and
 ShadowDOM to encapsulate the 
rendering, really how you 
transform the inputs into the 
component into whatever the 
component does is purely an 
implementation detail of the 
component.  We have a nice 
interaction between the 
interface and the actual 
implementation.  We can extend 
from whatever base class we
 want without losing 
interoperability.  We can extend
 the Polymer  Element, with 
Polymer 2.0.  But that's just 
one choice.  Down the line, 
switch over to the simple 
element base class that Steve 
talked about building.  Those 
can
work side by side in your 
application with Polymer 
elements.  Try SkateJS.  He 
might sell you on SkateJS.  Try 
it without switching the whole 
application over.  And someone 
is bound to make a better 
component class in the future 
that we to want shift to.  We 
can do that over time without 
throwing our application away 
every time.  Think about that.  
If you wanted to change from 
popular framework one to popular
 framework two today, that's a 
rewrite.  Throw away the 
application.  Building 
applications out of web 
components, we can change over 
time without having to throw 
everything away and without 
losing kind of the ability to 
innovate.  Okay.  So back to our
 real estate app, right?  So 
let's look at how we factor our 
application views down into 
components.  So let's just focus
 on this one route, this explore
 page element.  And then we can 
use reusable elements from the 
catalog.  So the Google map, the
 paper icon button, even use 
native selects here. 
The style especially, right?  
And might want to factor some of
 the rest of the view down into 
other application-specific 
components that we're going to 
compose together.  Break down 
and compose back up until we 
have the final view for our 
route.  And then at the top 
level of our application will be
 tour app shell.  And this is 
responsible for the top level 
layout of the application.  The 
top is the app shell.  Might 
have app tool bar, paper tab.  
Doing the layout and the 
navigational components.  And 
then the app shell is also going
 to have the code for the 
router.  And the knowledge of 
how to lazily import the 
components needed for each 
route.  So if I go to the 
explore route, the app shell 
would be responsible for loading
 that explorer page element and 
getting it rendered in 
interactive.  User  changes to a
 detail route later, it would 
load and get that element 
rendered.  So to get started 
with an app shell template, kind
 of set up for this sort of 
factoring, you can check
out the Polymer starter kit 
template in the CLI to get 
going.  So we talked about 
structural performance, 
factoring the UI.  Next we need 
to bring our application to life
 by loading it with data and 
managing state changes in the 
application.  So application 
state management is kind of one 
of these areas that the web 
platform has really had the 
least to say about.  And so it's
 an area that we get a lot of 
questions about.  It's probably 
our biggest area of confusion 
and questions and that sort of 
thing and request for guidance. 
 So two years ago at our first 
Polymer Summit in Amsterdam, I 
gave a talk called thinking in 
Polymer.  And was how we think 
about
 composing and  coordinating.  
It owns them and it responsible 
for propagating data down to the
 components.  Listening for 
events from the components to 
handle user interactions.  That 
sort of thing.  And based on 
those events, perhaps mutating 
data and propagating down, and 
as well as up and out via events
. 
The mediator pattern is 
responsible for handling those 
that have complex changes 
internally and communicate the 
changes up and out.  It 
encapsulates the statement 
management so it's portable.  
These are in web components.org.
  Things off the shelf.  Don't 
tell you how to do the state 
management, it kind of comes 
along with it.  And using this 
pattern, we've shown that you 
can actually just kind of keep 
composing mediators into 
mediators.  And as you keep 
building that up, you have a 
top-level mediator that's 
mediating other components.  
It's kind of the turtles all the
 way down mediator concept.  
However, the community has shown
 there can be benefits to have 
been less granular and even 
global mediators of state.  
There's a tradeoff space in the 
spectrum here.  Particularly as 
components become more and more 
app-specific and largely used to
 compose more generic components
 with application-specific 
logic, having one mediator for 
all application data can make 
the
application more easy to reason 
about.  And it opens up nice 
developer workloads that we'll 
see in a minute.  So these 
global mediator patterns -- so 
flux is one really popular 
example.  Popular in the React 
community.  Formalized this 
concept of having one central 
place to put the application 
state that flows down to 
components.  And one place to 
put events that causes 
application data to be mutated 
and passed down.  We can think 
about these global mediator 
patterns, the instances at a 
global level.  Right?  Now, 
there are lots of choices out 
there to complement the global 
mediator pattern.  Kind of too 
many to go to in this talk.  A 
lot of times developers say tell
 me what to use, I'll do  it.  
If you're looking for that 
answer, we think Redux is a good
 choice.  It relates well to web
 components and people have had 
success with it.  So Redux is 
really simple.  It really has 
very little magic in it.  It 
implements a really simple 
mediator pattern.  And there's a
really strong ecosystem that 
Redux has built.  The library 
actually starts really simple.  
Very easy to understand the 
concepts.  And as the needs of 
your application become more  
complex, there tend to be 
ecosystem-based answers to 
handle that complexity.  So a 
lot of times these take the form
 of, you know, kind of add-ons 
that help you manage async flows
 of data in and out of the 
server, for example.  Or kind of
 complex flows that the user is 
going to take.  That sort of 
thing.  Okay.  So let's just 
take a look at what applying 
Redux to this application would 
look like.  Introduce terms.  
The redux, the global mediator 
is the store.  And passing data 
down into the application from 
the store, there's a subscribe  
callback that they can be called
 to be notified of any changes 
to the global state of the 
store.  And actions can be 
dispatched -- kind of in place 
of events, actions are 
dispatched to the store to tell 
the story to kind of change the 
current state of the
application.  And those are done
 using what they call reducers. 
 So these are functions that we 
write and give to the store that
 tell how to change the state 
based on actions.  So like I 
mentioned, there's a bit of a 
tradeoff going from localized 
state management where it's 
self-contained to global state 
management where you put it all 
in one spot.  But one of the key
 elements is it opens up nice 
developer workflows like in 
Redux.  This is a  screenshot of
 the Dev tools that you can 
install into Chrome and they 
just sit there in your Dev  
tools.  And on the next screen 
I'll show what this looks like. 
 But basically because we're  
centralizing all of the actions 
that can possibly mutate the 
state go, it is able to log 
everything in the app that led 
to a state change.  And because 
the state is it in one spot as 
well, it let's us see all of the
 state together.  That helps 
make it a lot easier to reason 
about as you're building an 
application.  So here's an 
example
kind of using the application in
 the Dev tools.  And as you can 
see, for eruser interaction that
 happens in the application, in 
the interaction log, we get an 
action log.  We can have a log 
of every event  leading to a 
state change and actually see 
the state changes over time in 
the application.  So for each 
user action, you get an action, 
state changes.  And then what's 
really neat is it introduces in 
concept of time travel debugging
 which you might have heard 
about.  Let's you scroll back up
 into the action  log.  And 
because the Dev tools are 
snapshotting that state object 
at every action, you can play  
back.  You can go back in time. 
 If you had a bug.  Say this 
pop-up got screwed up there.  I 
can jump up in time, find the 
action that caused the change to
 cause the bug.  And it makes it
 easier to be debug your app and
 find out what's going on.  
Okay.  So there's lots of ways 
to connect custom elements to 
Redux.  It's simple to do so.  
There's lots to do  it.  But
one way is to build your 
elements as generic views that 
just accept properties and fire 
changes out and don't mutate any
 state themselves.  And then 
what you can do is then subclass
 that element so that the 
generic element you could use  
in, you know, any application in
 your lineup, that sort of 
thing.  But then you can 
subclass it and connect it to 
the store of a given 
application.  And then in the 
subclass, to connect it to the 
store, we would just have the 
element called the subscribe 
call back to Redux to get any 
state changes and set those into
 properties.  And then we could 
add event listeners.  Just 
normal DOM event listeners that 
listen to events.  And change 
the action of the story that's 
going to be the data.  And one 
pro tip, if you're looking at 
moving into global state 
management techniques, most of 
them, you know, don't come out 
of the box with a way to kind of
 separate all of the state 
management code.  They kind of 
lead you towards having a big 
blob of
all of your application -- it's 
global state management.  So you
 put it all in one spot.  This 
runs afoul of our PRPL concept. 
 Only want to load for the route
 added.  That's something to pay
 attention to that we'll see 
here.  So very briefly.  Pretend
 that the  explore-page is the 
element we created, the view.  
Takes elements in and out.  And 
subclass it.  And the 
constructer, we're going to call
 redux's subscribe method.  Get 
a new state object.  And 
dereference any state needed in 
the components and into store 
and set those into properties.  
And I'm using the Polymer 2.0 to
 set batches really efficiently.
  And then on the other side, 
dispatch actions and event 
listeners.  For any events that 
cause the state to change, event
 listener and then call the 
Redux method.  Here I'm using 
action  creators which are 
functions that we write that 
take parameters and return the 
action project.  I'm creating an
 action and dispatching to the 
store. 
We're going to do that for any 
events that the application 
fires that needs to mutate 
state.  And last, we want to 
make sure we're lazily loading 
any of the state management code
 along with our element and not 
putting it kind of centrally in 
the application.  And the way 
I've done this here is I've -- 
Redux has a lot of extensibility
 hooks.  So I wrote a very 
simple enhancement to Redux to 
allow me to add an API to the 
store to lazily manage into the 
store.  As more and more 
elements come in, they're lazily
 adding the code to the 
application.  Here the listings 
reducers is responsible for  
handling any changes to the 
listings.  I handle this along 
with the component.  And with 
the PRPL  pattern, that's lazily
 loaded.  And install it into 
the store.  And like wise, any 
action-based logic, you want to 
make sure you're importing that 
along with the component as 
well.  So we will continue 
experimenting with patterns for 
state management
and how they can fit into web 
components-based apps.   And I 
wanted to call out a community 
library, Polymer Redux, which 
takes a declarative approach 
combining Polymer to Redux.  
Check that out.  And like I said
 before, it's a ton of 
innovation happening in the 
community.  And Redux is one of 
those.  Most can be happily 
paired with web components.  
Encourage you to share your 
ideas with us and other people 
at the conference today.  All 
right.  So we're done managing 
state.  Finally we have to serve
 our application to our users.  
So we'll need to host and serve 
to our clients.  And although a 
lot can be accomplished by 
statically serving our client 
application, we feel that there 
are a few kind of key minimal 
features required to be 
implemented to get the best 
server experience.  These 
include serving the app shell 
for all routes.  So based on any
 route in your application, make
 sure you're serving the app 
shell, which is responsible for 
lazily
loading the components that you 
need.  Using HTTP/2 Push when 
possible to reduce round  trips 
and sort of granular components 
when that  makes sense to 
improve the efficiency of your  
caching.  And when HTTP/2 is not
 possible, the bundled assets 
and route.  We want to send down
 the optimal code for the 
capabilities of the browser.  
For ES6, take advantage of 
native subclassing by sending 
non-transpiled code, for 
example.  And make sure we're 
serving SEO-compatible output 
for any bots that might visit 
our site.  So we have been doing
 a lot of work on a reference 
server that does all of these 
things, PRPL-server-node.  And 
that's
 working hand in hand with the 
outputs from the Polymer build 
system.  It's a server that's 
set up for client-side routing. 
 And has a lot of extra features
 to do these smart things.  When
 I was doing a run through a 
couple days ago, Chris, a 
developer on the team, was 
you're underselling the node by 
 using the lame clip art.  I put
 the
sparkles on there to make Chris 
happy.  But basically, had some 
presets in there that can 
automatically detect the 
capabilities of the browser and 
serve the optimal code for each.
  So for browsers with ES6, take
 advantage of the native ES6 
subclassing of custom elements 
in the browser.  And then there 
are browsers that don't have ES6
, serve transpiled code as well.
  And differentiate between 
browsers with  Push, granular 
components and reduce round 
trips if possible.  And for non-
push compatible browsers.  And 
serve the right set for the 
capabilities of the browser.  
And then last, kind of under 
this heading we're calling bots.
  So these are things like  
Google, Bing, search crawlers, 
as well as social snippet 
generators that create the cards
 that show up in social network,
 we're integrating PRPL 
PRPL-server-node aimed at 
tackling with SEO problem with 
HTML components.  That will have
 fully rendered HTML.  I'm going
 to tease that today.  We have a
 talk
on that tomorrow that you should
 stick around for and check out.
  So you can check out the beta 
of the prpl-server-node here.  
Give us feedback.  This is set 
up for a hosting site like app 
engine, something like that.  
Sit behind a CDN and get really 
good at serving efficiency.  
Okay.  So.  With 
prpl-node-server, we fill in the
 last big gap in our story how 
to deliver the awesome 
experiences using our platform. 
 And hopefully you feel more 
confident you have the tools to 
build robust real world apps 
like this real estate app.  In 
the beginning, we had like two 
weeks.  That was our setup.  Two
 weeks to build it this.  So the
 down side, didn't have a whole 
lot of time to put this talk 
together.  But I wanted to build
 an app.  And I was able to 
build this out in two dis.  This
 much.  This is a proof of 
concept.  I need to get the demo
 ready.  But a whole day was 
just generating a bunch of fake 
real estate JSON so I didn't get
 sued by people for showing 
their house in my
talk.  So hopefully, you know, 
from this proof of concept I 
feel that I'm way for confident 
now that I have a well-factored 
UI with components that I can 
reuse across applications.  I 
have easy to debug scale 
management, adding more routes 
and features.  I know I'm going 
to be set up well for 
performance.  I've got a 
structure that scales well for 
performance with the PRPL-50  
pattern, and a great serving 
environment with  
prpl-server-node.  Hopefully you
 feel you can be this productive
 too.  And we will take the best
 practices that we come across 
as we tackle more and more 
challenges on the web platform 
and provide guidance and 
features and guidance to help 
move this along.  Thank you very
 much.
[ Applause ]
SPEAKER: All right.  So it's 
lunchtime.  Just a couple quick 
announcements first.  So food 
will be over across the way.  
There's a station for kosher and
 halal meals.  If you can't find
 them, ask a staff member.  And 
in about 15 minutes in the  
codelab space we start a casual 
Q&amp;amp;A.  And Steve and Kevin will 
be talking about Game of Thrones
 in the Polymer lounge.  And 
there's a quick tour.  You can 
look at the getting started 
guide and help us hone that.  So
 we'll be back here at 1:30.
[
Afternoon session]
[Music playing]
ing]
&amp;gt;&amp;gt; Hey, everybody.  Matt, again.
  I'm Elliott, I'm a software
 engineer on the Polymer team.  
And welcome again to the Polymer
 Summit 2017 in Copenhagen.  
Hope you had a great lunch.  We 
have a lot more talks on the 
way.  It's going to be a lot of 
fun.  Actually.  So up next we 
have Ziling and Mikhail, part of
 the YouTube team.  Mikhail 
almost didn't get here because 
of visa issues.  So some of our 
YouTube content wasn't available
 in this  country.  But we'll 
give a round of applause for 
Ziling and Mikhail coming to you
 live.  And not YouTube live.
[ Applause ]
SPEAKER: Hi, everybody.  My name
 is Mike.
ALEX: And I'm Ziling.  I'm a 
software engineer at YouTube.  I
 work on tech.
MIKHAIL: And I work on web 
architecture and infrastructure.
ALEX: We are going to talk about
 YouTube.  But let's talk about 
YouTube just for a second.  I 
know it's kind of an obvious 
question.  You can ask anyone, 
and the person says it's where 
grow and it's popular and 
everyone is using it.  Kind of 
makes sense
.
MIKHAIL: We know that YouTube is
 popular, but how popular?  We 
went to Alexa to check and we're
 number t
&amp;gt;&amp;gt; And unsurprisingly, we are 
using 1.9 million a month.  And 
some of them are never using 
desktop at all.  It's one of the
 largest and fastest growing 
platforms that we have.
MIKHAIL: Unsurprisingly, people 
come and watch a lot of videos. 
 How much?
ZILING: 1 billion hours to day. 
 And this is across all 
platforms.  But what is it 
billion hours?  Well, it is 
114,000 years.  It's not 114 -- 
which would be a time before the
 ice cream cone was  invented.  
It's enough time in one day to 
go back all the way to the stone
 age.  So every time you talk 
about anything that we do, you 
have to add that we are one of 
the largest at doing that.  Be 
it just but thing bytes through 
the inner tube, or maybe image 
hosting or social network or 
even a search engine.  So 
hopefully you get the idea, 
we're kind of really a big 
Website.
MIKHAIL: So our motto is, 
&quot;Broadcast yourself.&quot;  That 
means being inclusive.  We are 
in 80 different languages and 
continues to grow.  And we are 
accessible and consider a first 
class citizen.  Even building a 
Website from scratch picture has
 to be accessible from day one.
ZILING: And a lot of browsers 
with extensions that are 
specifically targeting YouTube. 
 And while we are dealing with 
the crazy world happening 
outside of us, we do the -- the 
main thing that we want to do on
 YouTube, we serve our videos.  
And we do it pretty efficiently.
  And thanks to the amazing job 
of many engineers that spend a 
lot of their time making sure we
 do it really fast.  Actually it
 takes us less than two seconds 
worldwide to start video 
playback.
MIKHAIL: In Denmark, that's 1.5 
seconds on the median.
ZILING: Way to go, Denmark.  
Anyway, YouTube is a very huge 
and complex project.  And by no 
means is it a monolithic 
Website.  We have dozens of 
internal and external mini 
Websites that fulfill different 
roles within the YouTube 
ecosystem.  And also YouTube is,
 I think, 12 years old right 
now.  Which means we have over a
 decade of engineer decisions.  
We have over a decade of code 
that we have.  We rewrite the 
code from time to time, but 
still we're talking about more 
than a decade.
MIKHAIL: So we found this post 
on Reddit that we wanted to 
share with you.  I'm fairly 
certain that in the eight years 
since Google bought YouTube that
 very little origin code 
remains.  This guy has a lot of 
faith in us.
ZILING: So the thing is, when 
you spend 12  years working on 
something, you end up optimizing
 the product.  And despite 
having this very large code 
base, despite working on it for 
so long, it is a highly 
efficient platform.  Because a 
lot of clever engineers spend 
their time working on this 
platform.  Yet we realize that 
this platform has limitations, 
and at some   these limitations 
became too obvious for us.  We 
are hitting some of the 
performance indications that we 
were unable to overcome with the
 stack that we have.  And we are
 hitting some of the engineers 
problems that we're unable to 
move as fast as we wanted to do.
  So we started to think, how to
 make things better and how to 
move forward and what is the 
next thing to power it?  What 
did we have?  What was our 
starting  ?  We have a server
-side rendered application.  And
 we always render the 
server-side.  Even going through
 pages or an AJAX mitigation.  
All the magic still happens on 
the backend.  We built a lot of
homebrew frameworks.  It's more 
like tools that we built for 
products.  We have homebrew for 
styling and layout.  So 
basically we build things that 
fit our needs at a specific time
 frame.  And the thing is, we're
  looking for something that 
would be a little bit more 
modern than what we have before.
  And we had a couple of goals. 
 We had a couple of restrictions
 of what we wanted.  We have a 
couple of requirements from the 
frameworks that going to -- 
reuse the  framework.  We wanted
 a lightweight framework.  And 
both in terms of the size that 
it will add to what we have, and
 in terms of the footprint on 
our ecosystem.  We wanted 
something flexible.  We didn't 
want a framework that would 
force us to do things.  We had a
 lot of unique challenges and 
business reasons to do things a 
specific way.  So we didn't want
 the code to be in our way.  We 
knew that component model is 
what we really, really want.  
There are a lot of benefits of 
using components.  And if you 
can look at
these benefits from different 
angles, there are benefits of 
organizing the code as a 
component because everything is 
very localized.  There are 
benefits of deploying and 
building the application as a 
set of components, because by 
doing that, you create clear 
boundaries.  And even the 
framework can provide 
encapsulation
 that works on the clients.  So 
that's better.  So we wanted 
components.  We wanted to 
iterate fast.  And at some   we 
realized that what we had wasn't
 good enough.  The way our 
engineers work was not efficient
.  We wanted to be faster and 
build new, cool features.  When 
new engineers join our team, we 
want them to be able to get up 
to speed faster.  We don't want 
them to spend a lot of time 
learning.  Also, we didn't want 
to stay with a stagnant 
technology.  And we wanted to do
 as little infrastructure work 
as possible.
SPEAKER: It's beneficial when 
you have a team of specialists 
working on the platform that you
 build your application on top 
of.  So we wanted to be able to 
work with the platform and build
 relationships and feedback that
 are beneficial to everyone.  
After all, YouTube.com runs on 
the web platform, and the health
 and growth of that platform is 
good for YouTube.
MIKHAIL: Also, this is a big 
surprise, but we had a direct 
and simple order from our 
President, to make YouTube great
 again.  And that is a real 
Tweet.  We don't know why.  But 
that was pretty obvious.  And we
 did.  Anyway, back to reality. 
 We had a lot of requirements, a
 lot of features, a lot of  
processes at our Website.  We do
 things a specific way because 
YouTube is an existing product. 
 It's been live for a long time.
  We had to make sure that 
whatever we do next, will help 
us transition into the new 
world, not break it.  And we 
looked at Polymer.  We actually 
looked at many different  
frameworks.  And now because we 
are here at owner conference and
 talking about Polymer, it kind 
of makes sense, we picked 
Polymer.  It wasn't that obvious
 when we just started, because 
Polymer was actually not the 
first choice on the list.  But 
as we went through this list and
 we checked the check boxes, we 
realized that, you know, other 
frameworks, while great, and
sometimes fulfilling a lot of 
the check boxes that we have, 
not necessarily give us the 
flexibility and the full picture
 that we wanted.  And so also 
the Polymer at the time was just
 an article going from.5 to   A,
 I believe.  So it took a while 
to get used to the idea that we 
were going to use Polymer 
potentially.  And just going and
 rewrite YouTube in Polymer, 
that would be too crazy.  Even 
for us.  We didn't want to do 
something that big.  So we 
wanted to do something -- wanted
 to try something smaller.  We 
started with tiny  experiments. 
 Tiny tools.
ZILING: And then after that, we 
launched YouTube gaming .  This 
happened about a year ago.  It's
 focused on videos and live 
streams of games.  Afterwards, 
we launched YouTube TV.  This is
 recent in the last few months. 
 YouTube TV focuses on TV 
streaming and DVR.  These two 
are both complex projects with a
 large user base.  But they're 
not on the scale of YouTube.com.
MIKHAIL: Also known as one of 
the largest Polymer deployments 
in the world, because, again, 
YouTube, we do everything at 
this crazy scale.  And building 
all this amazing Website gave us
 an opportunity to learn.  It 
gave us an opportunity to polish
 our infrastructure, develop 
best practices.  And at some   
we finally realized that maybe 
it's now the time to do what we 
planned all along right from the
 beginning.  And we announced 
that we're launching -- we're 
building YouTube on Polymer 
during the last Polymer Summit. 
 And we are actually launching 
YouTube on Polymer.  I don't 
have an exact date, but we're 
like this close to doing this.  
Very excited about that.  And 
this is going to be the largest 
Polymer deployment in the world.
  Obviously.  Right?  Because 
this is YouTube and we do 
everything at scale.  I mean, 
we're pretty confident it's 
going to be the largest one.  I 
really hope.
ZILING: Some of you may have 
seen articles or have even tried
 it.  The important thing is, 
YouTube is available for opt-in 
right now.
MIKHAIL: Yep.  You just go to 
YouTube.com/new.  There is a big
 button right in the middle of 
the screen.  You get the new 
experience.  And please, there 
are a lot of articles on the 
Internet talking about how you 
can edit cookies and everything 
will be great.  Everything will 
not be great.  Don't do that.  
It's not the right way.  Just go
 to  YouTube.com/new.
ZILING: So what is it made of?  
Well, the site is 100% Polymer. 
 And by that I mean, from the 
app tag down you can inspect the
 site and see all of the 
components right there.
MIKHAIL: We have about 400 
components that are just 
YouTube-specific.  More than 
1,000 components across all the 
code bases.  And we are happy 
that we can share a lot of our 
components across different 
projects.
ZILING: So let's talk a little 
bit more about how we use 
Polymer at YouTube.  But before 
I go into that, let's take a 
small step back and let me 
explain to you that we have this
 thing called -- it's our 
universal data API.  And it kind
 of shapes all the applications 
we build.  Keep in mind that 
YouTube runs on everything.
MIKHAIL: And the very 
sophisticated naming process, we
 internally called it inner 
tube.
ZILING: So here's a small set of
 apps that run on this universal
 API.  Not just web, we have 
apps on iOS, game consoles and 
TVs.  And different verticals, 
apps for kids, apps for 
creators, apps for TV.  Apps 
that replace your TV that run on
 TVs.  And all these run on this
 universal data API.  So what 
does it look like?  What we 
ended up with is a 
presentational API.  It's an API
 that defines how your page 
structure will be based on the 
JSON.  And we found this maps 
really well to web componentses.
  And that defines the children 
that the web components will 
render underneath it.  And in 
the component, takes a sub-tree 
and passes it down to the child.
  In continues until you hit 
that.  And while doing this we 
realized that what we do is 
render a lot of lists.  In fact,
 YouTube --  YouTube's a bunch 
of lists.  You may think that we
 serve video, but from a web 
framework   of view, we draw 
lists over and over.  They're 
super-dynamic.  Machine-learned,
 ranked in their massage. 
And every time you come to 
YouTube, these lists are 
reranked, reexperimented on and 
it's going to chan
MIKHAIL: Also, if you are a list
 fan, this is a I told you so 
moment.
ZILING: This is a standard 
YouTube page.  There's lists 
here.  I'm going to highlight 
just a few to make it more 
obvious.  Menus, navigation 
results, search result 
descriptions, video lists, list 
of horizontal shelves media 
list.  They change.  And they're
 dynamic.  And every time you 
come to the site, you have to 
redo it.
MIKHAIL: We have to stop at some
  .  This is not all the lists 
we have.  It became too crowded 
to show all of them.
ZILING: So because lists are so 
important, we spent some time 
and optimized our list 
rendering.  We did stuff that's 
well known, efficient use of the
 DOM.  But we do things like 
signal base referral.
MIKHAIL: Meaning we can block 
some of the content rendering 
and you can get the signals.  
And we can wait for the content 
to appear or wait for the video 
to start playback.
ZILING: As well as doing that, 
we also do lazy and budgeted 
rendering.  To explain that, I 
have a simplified view of how 
the render thread works.  People
 think you play video, fetch 
video bytes, give it to the 
browser and video place.  But 
YouTube is not that simple.  We 
do adaptive bit rate, use dash. 
 You have to use a media source 
extension.  The render looks a 
little bit more like this.  This
 is still a simplified view.  
But you have to fetch the audio 
and video bytes, initialize the 
video API, pen the bytes, and 
then the video starts playing.  
You can see it's fairly busy 
from this event.  And then you 
introduce the UI code.  UI code 
can take a lot of render thread 
time.  In this case, you get the
 squiggly lines.  What those 
mean is we're not able to 
receive an event on the render 
thread fast we want it to be.  
How to solve this?  With the 
scheduling system we have with 
lazy rendering and budgeting, we
 break them into small chunks 
and fit it in between the time
these entitles come back.
MIKHAIL: Also, we're cheating a 
little bit on this screenshot.  
In this screenshot, there are no
 user interactions here.  And 
our users do all sorts of weird 
stuff like typing or scrolling 
or sometimes resizing the page. 
 And while that can obviously 
affect the performance, 
splitting the UI into  smaller 
tasks allows it to go as high as
 possible in this case.
ZILING: Also, I mentioned 
scheduling.  We have a global 
scheduler on the YouTube Website
 and deals with priorities.  
This is very important.  Not 
every single piece of code and 
UI  is of the same importance.  
So let's say you cam to the 
YouTube watch page.  The most 
important thing for us is that 
video.  This is the thing that 
we want to prioritize over all 
other elements on the page.  But
 following that, we have things 
like the watch next.  This 
generates a lot of watch time on
 YouTube.  This is in the lazy 
budgeted format.  And some are 
extremely deferrable, like my 
comment here.
MIKHAIL: We know that YouTube 
comments doesn't have the best 
reputation, but they're kind of 
still important.
ZILING: They have gotten a lot 
better.   Basically, this 
rendering, it's a foundation of 
performance at YouTube.
MIKHAIL: So let's talk about the
 development process.  How does 
it look from inside for an 
engineer working for Google?  
The cool thing about having 
components is as you can render 
this component, as long as you 
can create is separately from 
the rest of your application, 
you can bypass a lot of issues 
that we had before.  YouTube is 
very large.  Bringing up the 
development environment to work 
with V2 takes time and 
resources.  And being able to 
just take one component and test
 it  separately or create a 
demo, or feed it with some data 
to put it in a specific state is
 critical for development 
process.  So this is an example 
of a component.  And the image 
on the left is
 what the engineer created.  
This is a component that
 consists of some other 
component.  But on the right, 
that's the two special flavors 
created automatically unless the
 engineer wants to change them 
in some way.  And the new 
screenshot is the dark mode.  I 
would highly recommend trying it
on the new YouTube.  And the 
right image is the RTL, right to
 left version of the Website.  
And all of these versions of the
 component are being tested and 
screenshotted separate.
ZILING: So you can see here.  
There's some changes on this -- 
on this component.  It's not 
very obvious, just looking at 
it.  But once we add  screenshot
 dipping, we can tell things 
have shifted down.  Some padding
 has changed.  This is a level 
of testing that has never been 
possible as YouTube before.  But
 we real embraced it and it's a 
core part of how we develop now.
  In addition to that we took 
this granular component and 
testing approach and took it 
further.  We created something 
called storybook.  What 
storybook is, it's a way for you
 to interact with a component 
during development.  We have 
here a storybook for something 
called a video list cell.  And 
on the left of the component is 
a list of stories that have been
 generated.  This is either a 
fixture that we saved before, or
 some data that was 
automatically generated.
and this allows you to pick up a
 storybook and click on any of 
these stories and you can see 
your component rendered in that 
state.  This is the pretty much 
one of the best ways to interact
 with the component during 
development.  But moving 
further, we integrated storybook
 into our internal Polymer 
catalog, which is another way 
for you to bring up a component 
without needing to type anything
 on the command line.  You can 
seven for a component and bring 
it up in any time in the history
 because of the integration with
 the system.  You can browse the
 documentation, bring up the 
storybook and unit tests and 
bring republic the API and all 
that stuff.
&amp;gt;&amp;gt; Also, all these tools are 
Polymer projects.  So welcome to
 the component inception.  
Because the Polymer dashboard is
 a component or a set of 
components rendering a storybook
 which is a set of components 
rendering a component which 
renders
 a lot of lists.
ZILING: So what's the state of 
Polymer V2?  We mentioned we 
have over 400 components on 
YouTube.com and over a thousand 
components across all  
properties.  So we have a data 
model that maps well to web 
components.  We have a highly
-optimized risk rendering 
system.  And the testing and 
debugging tools.  But there are 
a few things we are trying to 
bring up to date.
MIKHAIL: Which probably not V 
big surprise from a Website that
 just drew IE9
 support.
ZILING: We're still on Polymer 
1.X, and using a migration path.
  We are excited about Polymer 
2, has extensibility.  And we're
 still on Shady DOM.  And 
YouTube has been a little bit 
more conservative when using the
 cutting edge APIs.  So we're 
relying on polyfills, but 
excited about ShadowDOM.  And 
moving our tools and our 
infrastructure to support this 
in the future.  So to wrap it 
up, we feel like we're building 
for the future.
MIKHAIL: We finally have modern 
tools and we're working with the
 web platform and we help push 
the web forward.
ZILING: The site is fast to 
iterate on and more test 
coverage.
MIKHAIL: And Polymer played a 
major role  helping us organize 
our internal workflow.
ZILING: The site is faster.
MIKHAIL: Up to 15% faster 
depending on the  page.
ZILING: And developers are 
happier.
MIKHAIL: We are sharing 
components across the projects 
and using the stack instead of 
developing everything by 
ourselves.
ZILING: And we can't wait to 
start shipping all these cool 
new features after we launch.  
Thank you.
MIKHAIL: Thank you, everybody.
[ Applause ]
ELLIOTT: So up next we have 
Kunal.  He is from Netflix.  So 
Netflix, as you guys know, have 
been going through a lot of 
modernization offer the last few
 years.  Like if you think about
 it, they used to mail out 
physical DVDs and not use web 
components.  But also I don't 
know if you guys have heard 
about, like -- have seen like 
Netflix's recent financial 
report.  But they're actually 
spending $16 billion on web 
components.  So here to tell you
 more about their new Netflix 
original series on web 
components, we have Kunal
 Kundaje.
KUNAL: Hello, everyone.  My name
 is Kunal  Kundaje.  I'm a 
software engineer on the cloud 
platform team at Netflix.  Today
 I would like to talk about our 
journey and how we used Polymer 
to do that.  So let's get 
started.  Here's a quick 
overview of the topics we'll be 
covering today.  I'll start with
 a brief introduction to the 
cloud platform engineering 
organization at Netflix and what
 we do.  We'll then go on a 
quick whirlwind tour of a few 
different types of apps we have 
been  building with Polymer.  
Five apps in five minutes.  And 
then reboot, our component 
library and tooling we built for
 a better developer experience. 
 Then we look at the road ahead 
with Polymer 2 and the 
incremental approach to migrate 
with minimal pain.  And finally,
 circle back to app and state 
management in apps and some 
experimenting we're doing in 
that space.  So cloud platform 
engineering.  Who are
 we and what do we do at 
Netflix?  The teem's charter at 
a high
level, we provide a common set 
of foundational building blocks 
to Netflix engineers so that 
they can focus on core business 
value rather than re-creating 
these infrastructure layers.  
Some examples of these building 
blocks include data stories like
 Dynomite and Elasticsearch.  
And Kafka messaging and stream 
as a service.  At las, our 
internal service for aggregating
 across the  services.  All of 
this sounds like stuff, but all 
of these provided as an 
organization become much more 
usable when we offer cell 
service apps to empower 
engineers to get onboarded 
quickly and leverage the system 
without road blocks.  Inside 
tools like dashboards and 
visualizations, together with 
control plans, help the 
engineers detect issues and fix 
them quickly and effectually 
without switching between 
multiple tools and command line 
scripts when they get paged in 
the middle of the night.  And 
building all of these apps is 
where we come in.  So let's go 
on
a tour of some examples of Apps 
built for these systems.  
They're all quite different from
 each other.  This segment 
should give you a good sense of 
the variety of app types that 
can be built using Polymer and 
web components.  Let's start 
with Lumen.  Lumen is our 
dashboard builder for 
operational insights.  And it's 
widely used by engineers across 
the company to plot time series 
data collected and aggregated by
 Atlas, our data store so they 
can look at the metrics over 
periods of time.  So here's an 
example of the dashboard used by
 our cloud databases team to 
track ways and cluster metric
 like IO and web components over
 time.  It's a great use case.  
We can have a simple API for the
 components, and fetch the 
metrics and render them.  And 
enable anyone to drop them into 
any internal app, including 
those built in React, Angular, 
which we have in Netflix as 
well.  But Lumen also supports 
more than just time series data.
  It also supports the concept 
of cell types, which are
components that visualize the 
data that's passed into them in 
different ways.  So, for 
example, there are cell types 
for pie  charts, histograms, 
bubble charts, data tables.  
What have you.  And each of 
these is  written as a custom 
element using Polymer.  We see a
 different data source connect 
sod six different is cell types.
  Users can automate and take 
the data that's passed into them
 and convert that to a format 
understood by any visualization 
type.  This is data from 
Elasticsearch and visualizing 
that data in didn't ways.  Next,
 let's take a look at Cassper 
that we build for our fleet of 
Cassandra database clusters.  At
 a high level, Cassper looks at 
the health of the Cassandra 
clusters.  Simply, red, yellow 
or green.  The size of the boxes
 are like the cluster 
themselves.  The cluster names 
are anonymous here.  And you'll 
find this on a wall-mounted TV 
right next to where the cloud 
database team sits in the
office.  What makes this unique 
is that a data source is a high-
volume fire hose of data being 
streamed in web sockets from 
over 10,000 different Cassandra 
cluster nodes.  So in order to 
not completely lock up our main 
rendering, we process this 
incoming data in event worker 
and post message back when we 
need to render changes.
  So when a specific cluster 
goes  red, an on call engineer 
can look at Cassper's cluster 
detail page to get orientated 
with the cluster without having 
to switch between multiple labs 
or online script.  This 
describes the topology of the 
cluster, the instances it has, 
what regions it's in, any 
running maintenance jobs that 
might be impacting cluster 
opinions.  And includes charts 
of some of the most relevant 
metrics.  And in fact the chart 
you see at the bottom here are 
the same ones from Lumen 
earlier.  That's the power of 
the component there.  And now 
you'll notice that this 
dashboard also supports a dark 
theme, which is unlike most of 
our other apps.  So
this was a good test for the 
team with some of our 
components.  So our Polymer 
elements exposed CSS custom 
properties that they could 
override with the color scream 
to get them all to blend in with
 its look and feel.  Now that 
you've seen a couple examples of
 dashboard apps, let's continue 
with something a little 
different.  Keystone is our 
real-time data pipeline that 
allows engineers to send events 
and logs to hive tables
, Elasticsearch tables and 
others.  And this is every test 
we run, as well as -- and this 
is Keystone self-service.  A map
 for engineers to manage their 
data streams.  We use D3 to 
build out the data stream as a 
directed graph with colors and 
tool tips along the edges 
reflecting actual metrics.   
Engineers can use this view to 
make config updates to outputs, 
or change the topology of the 
cluster -- of the data stream by
 dragging and dropping to 
rearrange them.  So it was 
really beneficial here because 
we could build a simple graph --
 this graph
component -- as a self-contained
 component with a simple public 
API.  And all of its complex 
implementation details neatly 
hidden away.  Since all of the 
SVG nodes are within the shadow 
root, they're protected from the
 CSS tails.  Moving on to the 
Netflix data explorer.  This 
allows our  engineers to explore
 and update the data in our 
cloud data stores.  So here 
we're looking specifically at 
the data explorer for Dynomite. 
 Our key value store built on 
top of Redis.  It allows us to 
support other data stores as 
well.  So using the Redis API, 
Dynomite explorer allows you to 
search by keys.  We needed to 
scale to handle millions of keys
 per cluster.  So we used a 
virtualized list like the 
awesome iron list element.  And 
pagination to keep the UI 
running smoothly without 
skipping a beat.  You can see 
it's handling about 145 million 
keys in this case.  In addition 
to simple data types like 
strings, Dynomite explorer 
supports complex data types like
 JSON values,
hashes, lists, sets.  And with 
data explorer the engineers 
never need to figure out which 
boxes to hop on to and which  
data-specific commands need to 
run when they need to update or 
look up data.  You may have 
noticed this makes heavy use of 
the paper and design elements.  
 So having this rich palette of 
well-built,  well-tested 
components available to us 
allowed us to rapidly test and 
build this out in a short period
 of time so we could build out 
our NodeJS
 layer as well as additional 
features like single file and 
auditing and so on.  And last, 
but not the list, is Winston  
Studio.  Our app for operational
 runbook automation.  Say you're
 an on-call engineer, and paged 
in the middle of the night for 
an issue, you go through a 
series of tasks to diagnose and 
fix the issue.  And Winston 
allows you look at that.  And 
Winston studio wires up, authors
 and tests the automation.  Here
 is an example of a simple 
automated and emails them when a
 failure fires.  So you can
edit the Python code for this 
automation right in the browser 
with syntax highlighting and 
checks.  And prior to promoting 
it, you can test this 
incrementally with a fixed set 
of input parameters.  This is 
not a unique app compared to 
other examples.  It's like an 
ideas in the browser itself.  
Using -- and the nice thing 
about a component-based 
architecture is we can lazy load
 these larger third-party 
dependencies only when a user 
actually gets to this page in 
the app.  So those were just 
some of the many apps that web 
busy building using Polymer 
within Netflix.  To recap, here 
are some of the interesting 
takeaways that emerged from some
 of these examples.  Custom  
elements in ShadowDOM give us a 
great encapsulation model, 
allows us to build components 
and simple public API and 
Shadows to shield them from 
styles.   And achieving using 
CSS custom properties.  We're 
also looking forward to the team
 specs that were talked about 
earlier.  Event workers are 
great to do
background work off the main UI 
thread.  Virtualized lists like 
the iron list, for example.  
Combined with paginated APIs is 
going to give us fast, fluid 
performance, even when dealing 
with huge amounts of data.  And 
a component-based architecture 
allows tows lazy load just the 
dependencies we need for the 
view that the user has 
requested.  All right.  So now 
if you're looking closely, you 
may have noticed that many of 
these apps have a lot of things 
in common.  So modern web 
development across most 
libraries and frameworks these 
days is centered around apps 
composed of components.  In the 
case of Polymer, they are 
components, or more 
specifically, custom elements.  
In this section, I'll talk about
 our approach to building 
component libraries and some 
tooling we built for a better 
developer experience.  So being 
a small team with lots of apps 
to build and maintain, we take a
 more pragmatic approach to 
building new components.  When 
we can find high-quality, 
stylible
components in the ecosystem, and
 there are many, we use them and
 build on top of them rather 
than reinventing our own.  We 
then augment these with our own 
elements that are specific to 
our internal use
 cases.  And we use CSS 
properties from the internal 
style guide to apply consistent 
styling across the components in
 terms of colors, typography, 
spacing and so on.  Now, when it
 comes to building our own 
components, we wanted to have a 
consistent and streamlined 
developer experience.  This 
includes things like scaffolding
 out new elements and iterating,
 generating docs, demo pages, 
and make it easy for semantic 
versioning when you need to 
release new versions of the  
elements.  So a couple of years 
ago, before the awesome Polymer 
existed, we built something  
specially.  This is a tool that 
the developer can use with npm. 
 And then scaffold up with a 
consistent structure, a common 
profile and is a set of common 
tasks to perform various 
actions.  The npm run Dev
task, like you probably expect, 
just fires up a Dev server so 
you can begin building and  
creating on your new component. 
 But there are a couple other 
interesting things that a good 
CLI can do.  The first of these 
is autogenerating API docs for 
events.  We do this through 
piping through a custom Babel 
plugin that generates a markdown
 file, containing a list of 
property names, types and 
descriptions.  List of custom 
events, so on.  And this also 
includes links to the specific 
line  numbers of the source code
 for all of these things.  So 
having this in the markdown file
 makes it really easy to look up
 the API for an element.  Either
 directly in the Git or Stash 
repo, or in the catalog where we
 can work that to HTML.  The 
second is easy and consistent 
semantic versioning of elements.
  So when you're ready to 
release a new version of your 
element, you simply run npm run 
release and tell if it's a major
, minor, or patch version.  And 
then it automatically figures 
out the
current version  number, 
autoincrements the position, and
 updates package Johnson JSON, 
create the Git tag and -- all in
 one step.  We have been using 
Polymer 1 for a little while now
 and built a bunch of components
 and apps.  Now it's time to 
start migrating those over to 
Polymer 2.  We just started 
going down that path recently.  
I thought I would share an 
approach depending on the app 
type and so on.  So to start 
with, we are making the latest 
stable version of Polymer 1, the
 base across the shared elements
 and the apps that use them.  
This is -- this basically 
ensures that we can safely use 
hybrid-style elements 
everywhere.  It's a good 
practice to regularly keep up 
with the latest Polymer versions
 anyway.  So this step should 
not involve any big breaking 
changes.  Now, we usually start 
working on a couple of brand new
 apps.  These were perfect 
candidates for actually starting
 out with the new Polymer 2 
library and ES6 classes for the 
app's specific elements.  But 
these
new apps also depend on shared 
elements from our component 
catalog.  So we took this 
opportunity to convert those 
shared legacy elements so they 
can work in the Polymer 1 and 
the new Polymer 2 apps that 
we're building.  When we 
eventual have ES6 class versions
 of those shared components, we 
can simply swap those in and now
 we have a fully migrated 
Polymer 2 app.  But what about 
existing apps?  We can take two 
different approaches depending 
on the size and date of change. 
 For small apps and apps that 
aren't updated much anymore, we 
start using Polymer 2 and 
upgrate the app-specific 
elements
 directly to ES6 classes.  
Because these  apps are small 
and not changing frequently, you
 can skip the intermediate step 
of converting to hybrid 
elements.  And, again, once we 
have the shared element updated 
to the class as well, swap those
 in and you have a 
fully-migrated app.  For larger 
apps and ones that are still in 
active development,  things get 
a little
trickier.  It's a bit  
challenging to do a big bang 
migration all at once.  For such
 apps, started converting the 
app elements to the hybrid-style
 force.  While still running the
 Polymer 1.9 version of the 
library.  Once that's done, we 
can just replace Polymer 1 with 
Polymer 2 and continue running 
in hybrid mode.  Any new  
app-specific elements that we're
 writing now will then be 
written as ES6 classes and we 
can  retroactively start 
converting some of the older app
 elements to the 6 style as 
well.  And, again, like the 
previous two cases, once the 
shared elements are upgrades as 
well, we will have a fully 
migrated app.  Those are just 
some of the different  
strategies we can take depending
 on what type of app we're 
talking about.  That brings us 
to our last topic, which is 
state management.  Also happens 
to be
 my faith one, probably.  
Because of the stranger things 
reference.  As we were working 
on larger  apps, with lots of 
nested
components, we started  running 
into shared state issues.  Let's
 briefly dive into what the 
problem was using a couple of 
examples.  So say I've debate 
got a component and  its child 
that share a common bit of state
.  A common pattern in the 
situation is to make the parent 
component the source of truth 
for that state and pass it down 
to the child as a property.  If 
the child then needs to change 
the value of that state, it 
simply emits an event that the 
parent listens  for.  The parent
 then makes a change to that 
property and passes it back down
 to the child.  And everything 
just works.  But consider this 
example, there was a deeply 
nested child that cares about 
the same bit of state as the 
parent a few levels up.  In this
 case the property has to be 
passed down every intermediate 
component in the hierarchy.  
Even hope the intermediaries 
don't care about the state, 
they're just acting as pass 
throughs.  Same thing with the 
events bubbling up from the 
child.  And here's
another situation, in this one, 
two sibling components need to 
share a bit of common state.  So
 now you have to find a common 
parent ancestor and store this 
date in that even though it 
doesn't do anything with that 
state besides passing it down to
 the children as properties.  
This illustrates a potential 
problem when the refactor or 
design change causes one of 
these child components to move 
elsewhere in the visual 
hierarchy.  You now have to move
 the component there, find a new
 common parent and play the 
property passing game all over 
again.  So this is a popular 
product, Redux, aims to ease 
some of the pain.  It's 
described as a predictable
 state container for JavaScript 
apps.  And you heard Kevin talk 
about this as well.  We have had
 several teams within Netflix 
using Redux quite successfully 
with React.  But there is 
nothing React-specific with 
Redux.  We have started 
experimenting in so much of our 
larger Polymer apps as well.  
The central state in redux is a 
Redux store.  It
 contains all the information 
for a shared -- and it can be 
mapped to specific slices of the
 store so they're automatically 
updated when the state  changes.
  Components can dispatch 
actions to the store when they 
need to update part of the 
state.  It's only passed to 
components that actually care 
about it.  And so an open source
 library called polymer-redux by
 Christopher makes using Polymer
 with Redux quite simple.  Once 
your component class extends to 
the library, add the path to any
 of your property definitions 
and they'll change when they 
want to store that part of the 
state tree.  Components also 
inherit a dispatch method from 
the mix inthat we can use to 
dispatch methods,  instructing 
the store to make a state change
.  So what's next with our 
experiment with Redux?  
Unfortunately, we still 
evaluating.  So Redux may or may
 not be the right solution for 
every app type or use case.  
We're finding out where it makes
 sense to use it versus not.  
Second, in
apps that are using Redux, most 
of our shared app state already 
lives in this Redux store.  But 
there's also this additional 
state that literacies in the URL
 in the form of pod parameters 
and query parameters.  Would we 
have the Redux store so the app 
can handle all of that state in 
the same width?  Can we keep the
 React and Redux store in the 
same way directionally?  We just
  started exploring that a few 
weeks ago, in fact.  It looks 
something like this.  So similar
 to how the Polymer Redux 
library has the state concept.  
You can declare parameter here. 
 And the mixin is responsible 
for keeping the URL always in 
sync with the Redux program.  
Our app can basic life read the 
state exactly the same way.  So 
diving into the depths of Redux 
can be a whole talk in and of  
itself.  And we don't really 
have much time for that today.  
The entitles work really great 
in many case.  And stick to that
 pattern if it's working for 
you.  But if you could like to 
learn more
about Redux and how it can be 
used with Polymer, here are some
 resources to check out.  The 
Redux site itself, of course.  
There's the polymer-redux 
library I  mentioned.
and then there's a couple 
awesome polycasts on YouTube by 
Rob Dodson that shows you the 
library and how to do the async 
stuff with it.  Yeah.  And that 
covers everything I wanted to 
talk to you about today.  Again,
 my name is Kunal Kundaje and 
you can find me on Twitter 
@kunal.  Thank you for being a 
great audience and have a great 
time at the rest of the Summit.
&amp;gt;&amp;gt; PAUL: Cool.  All right.  So 
coming up next is one of four --
 yeah -- count it, four -- 
Australians giving a talk here. 
 So many Australians that we're 
going to rename this are the 
Polymer Australia Summit.  So 
get your passport out.  I'm sure
 border security will come by 
and check it.  But Bede's going 
to come up here and give a great
 talk about how web components 
make CMS.  Give a big Aussie 
welcome to Bede.
[ Applause ]
BEDE: Hi, everyone.  So my 
name's Bede.  I'm a developer 
from Melbourne in Australia.  
And I work on a content 
management platform called 
Simpla.  I'm here to talk about 
web components for content 
management systems.  I have been
 working with CMSs for a while. 
 And Hobbsly, I have been a bit 
frustrated with them.  From a 
developer's   of view and a 
content editor.  A couple of 
years ago I  started using web 
components, and I realized these
 could potentially really change
 the way we look at content 
management, and they could help 
resolve some of these 
frustrations.  That's what I'm 
going too talk about today.  I'm
 going to talk about content 
management systems, where they 
have been in the past and where 
they are now.  And how web 
components could potentially 
change them.  I'm also then 
going to go over some of the 
patterns you might use to build 
out your own custom element for 
content management.  So let's 
first look at a monolithic  CMS.
  So a
monolithic CMS is a WordPress or
 Drupal that essentially gives 
you all the functionality you 
need in one single app.  On the 
one hand, this is great.  It's 
easy to set up and get going 
with.  But like any monolithic 
system, it means it's quite 
rigid.  So from a developer's 
perspective, it can be quite 
difficult, for example, change 
the way you're displaying the 
content.  If you want to use a 
different framework templating 
system, it's hard to wrangle 
that in with the monolithic 
system.  And for a content 
editor, you're going to have a 
bit of frustration there.  Most 
of these systems, you're going 
to have some kind of a dashboard
 where you log in and edit the 
content in a form.  The problem 
with this is that content there 
is in a completely different 
context than what the user is 
going to  see.  So for your 
content editor, they're going it
 get a real disconnect between 
what they're saying and what the
 user is saying.  Over the last 
few  years, there's been a huge 
rise
in popularity for something 
called the headless CMS.  It 
takes the system and gets rid of
 the view layout.  It replaces 
it with a really consumable JSON
 API or similar.  Essentially 
for developers, this is 
fantastic.  At this   they don't
 have to deal with the CMS.  
They're dealing with an API.  So
 they can use whatever framework
 or library or backend that they
 want to talk to that content.  
Generally, though, these systems
 are going to end up with a 
dashboard just like the 
monolithic systems where you 
have to come up with a form and 
edit the content to the  users 
viewing the content.  This is 
where components come in.  What 
if we had a componentized model 
for content management?  The 
idea is you essentially build 
upon a headless system with the 
API to a consumed content, 
except you take the view layer 
and break it down into small 
chunks of data such as image, 
text, or something a bit higher 
level like a blog post.  So this
 is already being done on the 
dashboard of these other
systems.  If you go in, you'll 
edit a content part.  So a 
componentized manner.  But the 
view layout is embedded into the
 component itself when it's 
delivered to the user in the 
browser.  On top of this, we're 
also adding in an editing layer 
that's embedded inside the 
component itself.  So for the 
content editors, they can go in 
and edit the content in the 
exact same place and same 
environment that users are going
 to be viewing that content.  
Also, because this is a small, 
modular and componentized 
system, we're  trying to 
maintain a level of flexibility 
for the developer so they can 
have control over this content 
and how it's displayed.  So why 
am I talking about this now in 
the context of web components?  
So first of all, custom elements
 is the first time we truly have
 interoperability.  Before any 
model was going to be
 restricted to the framework it 
was built in.  This way we can 
build components that can be 
distributed to any HTML 
environment.  And encapsulation
through ShadowDOM, so editing UI
 isn't have any side effects to 
the rest of the DOM.  What would
 this look like?  Here we have a
 dynamic image custom element 
with a pass property that maps 
to a central URL.  Essentially 
mapping to data.  I want it to 
fetch an API and render content.
  So in this scenario, that 
means an image tag.  Later on, I
 want it to save back to that 
same end  .  So we'll do a put 
request there.  This is for a 
developer, this is generally 
what we'll see.  What about that
 editing experience?  We want 
the editor to be able to come 
in, interact with that image in 
an isolated environment.  Upload
 a new one, manipulate it in 
some way and be able to escape. 
 All in the context of that one 
image and see what the user is 
going to see.  So how would we 
build that?  So I'm going 
through a basic primitive.  
Through that dynamic image and 
focus on the fundamentals of the
 content part of that component.
  So I won't touch on the server
 or the internals of that 
editing UI. 
So this means I'm going to look 
at, how did we store that 
content?  How did we render it 
on to the pick for the user?  
How did we toggle that UI to 
manipulate it?  And how did we 
get that content over a network?
  First of all, we need a create
 a basic dynamic-image element. 
 Inheriting from the basic 
Polymer element.  And we want to
 set up an image that's going 
that act as a rendering   for 
all of that data we're going to 
have.  Next up we want to append
 this into the light DOM and the
 connected pullback.  We want to
 do
 this in the connected pullback,
 because then they will want to 
consume the content.  And into 
the light  DOM, not the 
ShadowDOM.  It should be 
accessible to the user.  For 
example, if they want to use a  
third-party style sheet or 
third-party library that expects
 an image tag to be on the 
screen, you have to make sure 
that's accessible this opens up 
the door for easy server-side 
rendering.  So as long as your 
content is in a live DOM, 
anything that can spit
out an HTML string can 
server-side render.  So let's 
look at some properties here.  
Essentially what we want is 
properties that are going to be 
able to hold all the content to 
display that image.  So for us, 
that's pretty simple.  That's 
just a source on an old 
property.  You can add more meta
 information, but this is 
fundamentally what we need.  We 
also have a render function.  
This is an observer for the two 
properties.  This is going to 
get called every time and pass 
the props down to our image.  
This might be more complex in 
other scenarios.  Say, if you're
 building an article element 
that's based on markdown.  Might
 stall in markdown so your 
render function has to take that
 markdown and convert it into 
HTML.  So at this   we're 
storing some content and 
rendering it out to the DOM.  
Which is great.  But it's basic.
  It's a wrapper and an image.  
It's not doing much.  So let's 
look at adding in some editing 
controls.  So at the right, I 
have my template, which is how I
 want
my ShadowDOM to look for this 
dynamic image element.  And 
we're encapsulating all the 
functionality into it.  The 
editing controls is surrounding 
the content.  But that's 
depending on the structure of 
your editing  UI.  It's 
important and beneficial for all
 of your editing functionality 
to be packaged into one element.
  Just because this means it's a
 clear separation of concerns 
and also going to give you a 
performance benefit, which I'll 
talk about later.  So first off,
 we need a way to make sure that
 our -- we can toggle those 
controls open and closed.  So 
just add an editing property to 
the host and an open property on
 our editor controls.  This is 
making sure our host can control
 when they're open and closed.  
We also need to pass down those 
properties and data to the 
editor controls.  We don't care 
what editor controls is doing 
under the hood.  Might prompt 
for a while, bring up a canvas 
to manipulate it.  But at some  
 in the future we know we're
going to want that changed data.
  Lastly, I want to look at a 
load controls measure.  So most 
of the time with the dynamic 
image, most people that use it, 
most people that come to your 
site with a dynamic image on it 
are going to be viewing the 
content.  They don't want to 
edit it.  We don't want to 
burden them with the 
functionality that comes with 
the editor controls.  We want to
 have this observer function, 
when editing goes through, it 
has the definition editing 
controls inside of it, and then 
when they want to edit, we can 
boot up for editing.  And you'll
 notice this ShadowDOM is for 
editing.  You can defer all of 
your work for dealing with a 
ShadowDOM until the user is 
actually editing  content.  So 
now we have a dynamic image.  It
 can be display some content for
 the user.  And you can add an 
editing property which will open
 up some controls that you can 
start manipulating it.  This is 
pretty simple.  And it's a nice 
base to work on.  We have an 
interactive and dynamic
image element.  But it's not 
there yet.  We need to have some
 kind of  networking to be able 
to load and persist that data.  
So first off you need some kind 
of process that is going to let 
you uniquely identify the data 
you have chosen to talk to.  I 
have chosen a path here to map 
to some kind of URL.  But you 
can choose whatever, 
essentially, is going to pass 
you back to a unique  URL.  We 
need a deserialized
 function.  Essentially a way to
 take whatever the server is 
giving to us and hydrate our 
properties from that 
information.  Again, these APIs 
are simple.  Straight up.  But 
in other scenarios, you might 
not have control over the API, 
so your de-serialized function 
might have to do work.  And the 
serialized function, same in 
reverse.  That's our properties,
 package it into an object 
literal that can be sent over 
the wire later on.  And 
obviously we need some methods 
to actually perform these 
requests.  So our load method is
  fetching a URL based on that 
path
property.  We're taking that 
JSON, passing it, and giving it 
over to our deserialized 
function.  And we're getting 
that serialized function, 
calling it, turning it into a 
string, and sending it over to 
our API by our  method.  So this
 save function, you're probably 
going to want to wire that up to
 some external UI.  For example,
 a save button on the page, or 
an internal event like the 
editor controls.  Maybe when you
 close, automatically save.  
Lastly, make sure we're loading 
in the content at the 
appropriate  time.  I'm doing 
this in the connector callback, 
because you want to make sure 
you're not making a network 
request too early.  But you want
 to make sure they're getting it
 at the right time.  So once the
 element is in the DOM, we're 
making that network request.  
But you could be a bit smarter. 
 You could use an intersection 
observer so you load in the 
element only one the page has 
been scrolled on the page 
itself.  We have a simple image,
 but it
can display content.  Provide an
 editor UI and edit it in place 
and get feedback
 on the editing.  And 
dynamically fetch the network 
and send it back to the same 
endpoint.  This is one 
component.  Ultimately, to get 
to a CMS, you need more than  
this.  You need a whole library 
of components.  That's what we 
have been doing with Simpla.  We
 have been looking a the video, 
text, and bringing them together
 with authentication systems and
 global management systems that 
are able to synchronize save 
events amongst all of the 
elements and make sure they're 
all editable at the same time.  
But more than just a single CMS,
 wouldn't it be great if we had 
an ecosystem of the dynamic 
elements where people could mix 
and match and use the ones they 
need based on their Website or 
app.  What if we could have a 
plugin for the APIs so you can 
choose the content source you're
 using for a specific element?  
You could have multiple content 
sources on the one page.  
Ultimately, I think using all of
these together and utilizing web
 components and the fee cures 
that it gives us, I think we 
could see a different approach 
and a better way to manipulate 
and use content on the web.  So 
thanks very much.  I hope this 
has been interesting.  Please, 
if you're interested at all, 
come and chat to me afterwards. 
 Thanks.
[ Applause ]
ELLIOTT: Awesome.  Last year, we
 had Gannel up here.  And they 
loved it so much, they had to 
come back and bring a friend.  
Fun fact.  One of the speakers 
is a black Smith and brews his 
own beer and lives on a mountain
 and his name is not Ron Swanson
.  So -- so also
 -- Gannett is the parent 
company of USA Today.  Most of 
the people are from USA Today.  
To bring you the USA of tomorrow
 today we have Jesiah, Josh and 
Marianne.
SPEAKER: Well had been hello, 
good afternoon, everybody.  
Welcome to the talk with a very 
long name.  Designing a design 
system for modular modules and 
building a team to build it.  My
 name is Jesiah McCann.  Joining
 me on stage are Marianne 
Epstein and Josh Trout.  Josh 
and I are representing the core 
web development team.  And 
Marianne is here representing 
the UX design team at USA Today.
   First, I want to start off by
 saying thank you, Polymer team,
 for having us up to speak 
again.  Last year was a really, 
really fun year.  Very, very 
practical talks.  And I'm really
 excited about the talks 
tomorrow and the rest of the 
talks today.  It's been a great 
conference so far.  So I want to
 share a little bit about the 
USA Today network and what we're
 all about.  And we're all about
 making communities stronger.  
And we do that -- and to do
 that, we have to inform them, 
equip them, and empower them, 
fostering deep and vital 
connections between members of 
our
community and the world around 
them.  And we connect these 
communities all together through
 our national brand, USA Today, 
and our 109 local media 
organizations.  Merging our 
national voice with the local 
communities.  As an 
award-winning news organization,
 and a modern media company, our
 500 plus digital products
 reach 110 readers every single 
month.  We reach 43% of the 
Internet population with our 
content, resulting in  1.5 
billion page views every month. 
 And as you can imagine, this 
level of scale and fragmentation
 between so many Websites has 
its challenges.  And today we 
want to share our success as a 
Dev and a design team focusing 
on very practical points you can
 immediately walk away with and 
apply to any size team or 
project.  So to give you a 
little bit of context of, you 
know, here's what we have been 
up to since we last spoke.  A 
year ago we launched our new 
Polymer base web framework.  
We're test drive -- we test 
drove it with a few different 
microsites.  We talked
about one last Summit, our 
Olympics coverage.  Our 
data-driven Olympics coverage.  
And after that, we launched our 
continuous coverage of the 
election.  All converging on 
election night, the biggest news
 night of the year.  Where the 
framework made its big stand, 
taking on
 heavy amounts of traffic.  It 
was a great process to see how 
much faster and efficient we 
could build on this new 
framework, while also 
identifying rearings that needed
 to be improved.  And at the 
beginning of this year, we began
 replatforming our current sites
 on to this framework and doing 
a complete redesign at the same 
time.  Right now,
 USAtoday.com on mobile devices 
is completely powered by this 
new Polymer web  framework.  
Part of this new framework
 is, we want to figure out can 
we build quickly, can we build 
more efficiently?  And it 
really, really worked for us.  
But this new approach that we 
took, this module everywhere 
approach, is key to our success 
in 
building for a large news 
organization with many 
developers scattered all over 
the nation.  So this approach, 
it's adopting a module way of 
thinking.  And web components on
 the client are front and 
center.  They're a Polymer-based
 approach.  But  also, not just 
our client.  We have server-side
 modulization through a 
micro-service ecosystem.  This 
modules everywhere approach is 
very decoupled, allowing for 
maximum component reuse, not 
just across our team, but for 
any of our web developers spread
 across the entire network.  
Reducing the cost
 of experimentation, maximizing 
shared code use across each and 
every property.  And to support 
this development philosophy, 
design had to be on board and 
think modularly as well.  And 
here to talk about our new 
design system that supports this
 framework is Marianne.
MARIANNE: Okay.  Hi, everyone.  
As Jesiah said, our design team 
has spent the past year working 
on a new modular design system. 
 And today I'm
 going to talk about what a big 
change this was for us.  As well
 as what worked well for our 
design and Dev  teams in case 
your teams might be approaching 
sort of similar challenges.  
Heading into our redesign last 
spring, we had separate desktop 
and mobile sites and adding new 
things over a couple years.  
Over time, the designs veered 
off in many different 
directions.  Here you can see a 
story on the desktop site and 
also the mobile site.  And they 
look very different from one 
another.  And if you were to 
hide the logo at the top, you 
would think they came from two 
different publications.  And 
these differences were causing 
problems for our business.   The
 journalists couldn't predict 
how the stories were going to 
look.  And from analytics, we 
knew the  readers weren't as 
happy as they could be either.  
And these sites were sent
to a hundred different news 
rooms, they were frustrating 
people every day.  Which, on the
 UX team, is the opposite of 
what you want.  So there were 
good reasons for everything 
looking different.  First, a lot
 of things changed since these 
sites were build.  Reader 
habits, our story teling and 
response to those.  And our 
scale.  We had grown a lot as a 
news network.  Meanwhile, we 
were not set up well for all 
this change.  We didn't have a 
style guide.  So whenever we 
needed something new, which was 
pretty much all the time, we 
would try to make it match.  But
 more often than not, we had to 
design from scratch.  We wanted 
to understand our problems 
before diving into redesign.  We
  shadowed our journalists to 
find out what they  needed.
and then took inventory.  We 
screen capped erone of the 
Websites to see how we're 
meeting the journalist's needs. 
 We found hundreds and hundreds 
of one-off experiences.  Here's 
a specific example to show you 
what's happening.  We're a news 
organization, so one of the most
 important things we do is 
promote stories to help readers 
find things they're interested 
in.  And we call these story 
promos.  And at the time of the 
inventory, we found this.  This 
is 12 versions of a have been  
similar-looking story promo.  
But each could be used in a 
specific place.  This one was 
only on home   pages.  And this 
one over only ever on blog 
pages.  This one on mobile 
article pages.  And this one 
only in desktop search results 
and on and on for all of these. 
 And if you look at these more 
closely, almost every style here
 is unique.  So every headline 
has a slightly different font 
treatment, the values of the 
grays, they're different.  It 
had been designed and Deved 12
times.  This was just one 
example.  We saw this same 
duplication happening for video 
promos, shared tools -- pretty 
much everything on the site.  So
 to step back for a second, as a
 designer, unearthing this was 
very exciting.  Seeing the same 
thing done at so many times at 
such scale and knowing how it 
was causing problems for the 
journalists and users, that 
meant we had a good problem to 
solve.  It was actually two 
problems.  We had a lot of 
design sprawl.  And a lot of 
inefficiency.  And the design 
team thought a lot about how to 
solve these problems in such a 
way that we wouldn't have the 
same ones again in another  
year.  And rerealized our focus 
had to be reusability.  And we 
had to take anything we were 
doing over and over and do one 
thing instead.  And that meant 
we needed smarter modules.  So 
for us that meant modules that 
would either do the same job in 
different places.  So, for 
example, a promo that could live
 on a home page or an article.  
Or across use cases.  One
promo to support a video story 
as well as a regular story.  And
 we needed smarter styles.  So 
we wanted to reuse them across 
these modules to keep everything
 cohesive and fight design 
sprawl.  So here's a short 
version of how we got there.  
Based on inventory, we distilled
 the site into categories.  For 
us, promo, story, media, ads, a 
couple of others.  Then we 
distilled all of our style needs
 into style ramps.  Anything we 
used again and again, type, 
color, spacers -- we  abstracted
 those into variables.  And 
finally, some documentation to 
help us stay organized.  And for
  us, documentation was the key 
part of getting this all to 
work.  Because if there was one 
thing we learned from inventory,
 is that reusability doesn't 
happen by accident.  Even if Dev
 moved to a component-based 
approach, design had a role in  
making sure the components met 
the needs and actually fit 
together visually on the page.  
And we found that reusability 
only happens when we pay 
extremely
careful attention to details and
 then write them down.  So this 
is quite an adjustment for our 
team, because not everyone loves
 writing things down.  But we 
have come to love what it does 
for  us -- which is to help us 
design things that are, in fact,
 reusable.  And I'll share our 
version of design documentation 
in a moment.  But first, I want 
to show you where we ended up.  
So here's our new story promo, 
which now has a new name.
   Promo-story-thumb-small, or 
P1 for short.  This was our 
single reusable answer to the 12
 versions from before.  This 
module can live on a small 
screen or a large screen.  It 
can
 live in the main content well 
or the side well.  It can 
promote a video story or a 360 
video story.  It can promote a 
story without an image, which is
 often the case for breaking 
news.  Or a story without a 
timestamp, which helps us 
showcase our best evergreen 
content.  And it can live on a 
home page or an article page or 
search results or any other page
we built in the future.  And it 
is made entirely of reusable 
styles.  So here you can see 
that everything in this module 
is  ing to one of our style 
variables.  Even the space 
between elements.  And Josh is 
going to talk a little bit about
 that for a second.
[ Applause ]
JOSH: So we implemented this the
 usual ways of styling Polymer 
applications and elements.  
Custom style element for our 
theme.  And that had CSS custom 
properties, mixins and some 
classes.  The sample shows the 
colors and typography used in 
that promo, and also shows how 
we mirror some of the  mixins 
into classes so that we can use 
that  server-side HTML.  We also
 built custom elements for some 
of the more complex design 
elements like icons and buttons.
  In this example on the screen,
 which is like a label header 
that goes above a lot of our 
list of promos.  And now 
Marianne is going to talk about 
documentation.
MARIANNE: Thanks, Josh.  Back to
 our friend, P1 here.  A lot of 
attention to detail went into 
making this one module to be 
reused in so many ways.   That's
 where the documentation came in
.  We wanted the documentation 
to be minimal and lightweight 
and make sure we weren't missing
 anything.  And one exciting 
thing we learned is that Dev and
 design actually needed to know 
the same things.  We found to 
make a module reusable, we had 
to agree on the answers to five 
basic questions.  What is it 
called?  What is it made out of?
  What variants do we need?  How
 does it scale?  And what styles
 is it using?  And here is peek 
under the hood at our version of
 design documentation for that 
P1 module.  On the left we have 
our functional spec, and on the 
right, design spec.  We call it 
our matrix.  It's a visual 
matrix of how it can look.  And 
together these documents answer 
those five questions.  So 
question one, what is it called?
  We never used to pay attention
 to this.  But now anything we
build gets a specific name so we
 can keep track and reuse it.  
And collaborated with Dev, a 
short hand ID, P1,  makes it 
easy to talk about things.  
Category ID, promo, and a 
descriptive ID.  Story thumb 
small.  This is a small thumb 
image.  Next question.  What is 
it made out of?  We established 
this module has a headline and 
optional things like labels and 
image and nested modules like a 
timestamp and an icon.  Question
 three, what variants do we need
?  This is where to capture the 
use cases.  Different media 
types, advertiser content, and a
 couple of others.  Question 
four, how does it scale?  Here 
we have a narrow and wide 
version, and the matrix tells us
 how these sit on the grid, as 
well as what the two sizes look 
like.  And finally, our styles. 
 We call it the style variables 
over here.  And helps us avoid 
the one-off styles we had so 
many of.  So I hope you see that
 documentation is not an end in 
itself.  It's turned into a 
thinking tool for the teams to 
check our work
for reusability.  And over the 
past few months we have used 
this to built MVP modules for 
the site which launched to 100% 
last year.  And here is the new 
story page design.  It's much 
more on brand and trustworthy 
than the previous one.  And much
 more predictable for our 
journalists and  readers.  But 
what's more important to me 
about the design, we have an X-
ray vision into it.  The team 
can look at the page and know 
the modules that built it.  And 
this X-ray vision makes us more 
efficient than before.  When we 
need to change things and get 
feedback and our needs change, 
we can change in one place 
instead of 12.  And reuse things
 we have already built.  We have
 been beta testing this for a 
few months.  Our readers are 
spending significantly more time
 with us per visit on the new 
site.  So while we love the new 
design system, our readers 
loving it the what we care the 
most about.  So we're happy with
 that result.  And it's brand 
new, a work in progress and a
lot to learn.  Thank you so much
 and Jesiah will take it from 
here.
[ Applause ]
JESIAH: Thank you, Marianne.  
Very good stuff.  So building a 
team to build stuff.  So we've 
unified around a module base 
decoupled web framework.  We've 
established a shared design 
system that organizes our vision
 behind every component we 
build.  But we need to think 
about how to structure a web 
development team around 
component-driven web 
development.  Because I believe 
we're in the  post-abstraction 
era of coding for the web.  And 
as we unify as a team around a 
standards-based  approach, 
element encapsulation, and heavy
 reusability, we need to 
structure our team for maximum 
efficiency and effectiveness.  
We have all been building 
Websites and web things the same
 way for a very long time now.  
But web components  changes this
 work dynamic entirely.  And 
because of that, it was time to 
think about a new kind of team 
organization.  In our internal 
observation, we identified three
 coding styles that make up our 
 team.  The innovative artists. 
 The
disciplined scientists.  And the
 very reliable craftsman.  And 
it's really important for us to 
understand how these different 
coding styles work together in 
order to build an effective team
.  And every style has its 
strength and weakness.  No one's
 greater than the other.  And 
some of us fall -- don't really 
fall cleanly into one column or 
the next.  But some projects may
 benefit from one style being 
more dominant than another 
style.  For example, a banking 
application is very focused on 
being accurate and not time to 
market.  While if you're working
 for an innovative startup, 
pushing that code out the door 
that's changing the world, we 
want to do that very, very 
quickly for our investors.  A 
balance team -- a balance team 
can cover the weaknesses of one 
single type.  But only when
 good communication and  
empathy-driven teamwork is 
applied.  So let's learn a 
little bit more about these 
different coding  styles.  Let's
 take the artists.  The 
surrender, the innovator,
the fast-moving.  The problem 
solver.  Always figuring out the
 problem.  Always finding a 
better way.  While cutting a few
 corners in there.  I can 
identify with the artist the 
most.  It's like tests.  What 
are
 tests?  I don't know.  I don't 
know what a test is.  Our 
weakness, as an artist -- unique
 solutions are great for pushing
 innovation and doing things 
better.  But unique means it's  
harder for someone else to pick 
up and maintain  code.  How an 
artist would approach building 
the P1 modules, oh, I'm going to
 use the new CSS grid  
framework.  That's how I'm going
 to make this  happen.  But we 
already have a grid framework 
for the company.  And we just 
fragmented company standards.  
All of a sudden somebody else 
comes around to reuse it, what 
did you do with the CSS 
framework?  So instead artists 
need to innovate the right way. 
 By focusing on things to 
improve everyone's workflow, not
 just the current vertical that 
they're working at.  The 
scientist. 
Pursues code as a discipline to 
be mastered.  They're  focused 
on best practices, have very 
well-tested code.  And this is 
really, really good.  But it can
 all come with a cost of 
overengineering solutions and 
slower time to market.  And the 
scientist, they would approach 
that P1 promo module that
 she showed us.  We need the 
image resizer.  It's clunky to 
work with, it needs refactoring.
  Or, how we're fetching data 
for this P1, it's not very 
elegant.  I think I'm going to 
rewrite it.  All of a sudden we 
have take an small scope module 
and really, really  extended the
 scope.  But the positives are, 
they're continuing to improve on
 a framework and plugging holes 
in framework and pieces of code.
  Carefully, tested, 
disciplined.  Always seeking the
 best industry standard 
practices.  Slower to market.  
Overengineering.  You don't know
 anyone like that, do you?  
Maybe.  The craftsman.  Very, 
very important.  These are often
 underlooked
 coding  styles
and people that you work with 
every day.  They are the steady,
 dependable, delivering 
consistent on-time code that's 
very, very reliable.  Sometimes 
they can lack innovation and 
deeper technical expertise.  
They might approach that P1 
module like this.  They're using
 two keyboard
.  Who uses that?  They might 
approach it.  Oh, I wrote 60% of
 this code last week, or code 
like it.  I'm just going to copy
 my code.  Bring it over here 
and reuse all this code.  Great.
  And that's awesome because 
we're keeping on the company 
standards, we're doing a lot of 
reusing.  But not so good 
because no one has stopped to 
think, hey, is there a better 
way to do what I'm doing?  Is 
there a better way to solve this
 problem?  Maybe copying the 
code from last week is great, 
but if I'm copying code from a 
month ago, a lot of things can 
change in a month.  Overall, the
 craftsman is a very, very 
important addition to the team. 
 Often overlooked by the other 
personalities.  Now, web 
components on top of
these styles.  Web components 
resonates with each of these 
styles in different ways.  The 
artist, they get to forge ahead 
on these new best practices.  
They get to blaze a new trail.  
We have been building thing the 
same way for a long time.  They 
get to go back to the drawing 
board.  The scientist, they get 
their  standards-based web 
development.  Even though this 
is a free solution, they get the
 encapsulation.  They get clean,
 organized code and the ability 
to test things logically.  The 
scientist loves this.   The 
craftsman, they get to use 
familiar tools and technologies 
that they already know.  HTML, 
CSS and JavaScript.  And Polymer
 has such a straightforward, 
simplified API, it's not like 
throwing a new abstracted web 
framework at a craftsman 
expecting them to learn a 
completely new API.  They get to
 use the tools they have.  
That's how they resonate with 
each of the styles.  We know and
 understand the different styles
 a little better.  So how do 
these
different styles work together? 
 How do you balance a team with 
these styles?  And we have to  
remember -- when you're working 
with a team of different style 
coders, we're all in this 
together.  And we can either be 
building each other up, or  
tearing each other down.  And 
balance is really struck but the
 scientists bringing that 
structure, bringing the hey, we 
need to harden this and test 
this to the artist.  And the 
artist saying, let's solve this 
problem no one has been able to 
solve.  Let's do it with 
innovation.  Bringing it to the 
craftsman and the scientist.  
And the craftsman is like, 
reality check, everybody.  We 
have to be on schedule.  We have
 something to deliver and we 
just got to go, go, go.  The 
interesting thing is this can be
 applied to entire Dev teams.  
As entire development teams lean
 one way or another.  How to 
solve for team-to-team 
interaction?  That's harder than
 managing a team and figuring 
that out amongst the team.  And 
it's through empathy. 
It's through clear communication
.  And it's through cooperation.
  So empathy -- you throw out 
that word.  But what does that 
look like practically?  It's 
like a bunch of scientists on a 
team saying, I can't believe 
they don't have 100% code 
coverage in that project.  And 
we do this all the time.  So 
stop and let's empathize.  What 
does empathy look like right 
here?  Empathy says maybe they 
are focused on delivering 
something fast with imperfect 
code.  That's what they're 
focused on right now.  And then 
the artist, why aren't they 
using the absolute newest way to
 build things?  Well, let's 
empathize.  Maybe it's safer and
 easier to build on a proven 
industry standard for their 
project than going off the rails
 and building something else.  
Because what we want to do, we 
want to fight against extremes. 
 And both the artists and the 
scientists, they can look at the
 craftsman and say, oh, they're 
not real coders.  They're not up
 at 3:00 in the morning 
contributing to open source
repositories every night.  But 
they're the bread and butter.  
They're the ones churning out 
all this work.  We have to fight
 against extremes.  We have to 
remember to empathize or 
craftsman will get imposter 
syndrome and the  walls of 
hubris and ego will be built up 
with scientists and with 
artists.  So now Josh is going 
to talk about how we structured 
our web components developer 
experience specifically.  Josh.
JOSH: So we put this into 
practice in our Dev team in a 
few ways.  The first is focusing
 on the API over the element 
implementation.  Because there 
will also be times when you must
 compromise on code quality.  
Speed to market is more 
applicable to the business than 
having the most rock solid code 
ever.  What that means is 
focusing on reviewing the API, 
which is the names, the 
properties and public  methods 
of an element.  The 
implementation of all of those 
things can be refactored later, 
very safely, without having to 
worry about breaking anybody  
else's code.  The way we 
actually make sure that 
refactoring actually happens on 
our team, we have a program 
called adopt a module.  We bake 
in time every sprint allowing 
developers to review modules 
that we haven't touched and 
clean up documentation, clean up
 JavaScript that might be messy.
  Maybe some styles aren't 
implemented as cleanly as 
possible.  That lets us kind of 
get code out to market quickly, 
but come back and
make sure we are having really 
good code that will be 
maintainable and long  lasting. 
 So what that look like in 
practice is this is a really 
simple sample element.  And 
showing a good API with some bad
 code.  See the horrible string 
function that's filtering out 
spaces for some reason.  But 
it's got a nice name for the 
element.  It's got a good 
property title.  And all the bad
 stuff can be refactored out 
later.  On the flipside, you 
have a bad API, good code 
module, which has got a really 
nice implementation for the 
filtering.  It's much cleaner.  
It's got some air checking.  But
 there's a problem with it.  
There's a misspelling in the 
title change handler and you 
can't go back and fix that.  
Because if somebody else is 
already using that, you can't 
fix the spelling.  And the 
property is just called T.  So 
now all the elements set T 
equals whatever, they're going 
to have to change that.  And the
 element name is not great.  
This is a bigger problem when 
you're dealing with
other teams using your code.  
And the biggest problem when 
you're open sourcing your code 
and the rest of the world is 
using your stuff.  You don't 
want to break their applications
 because you got a little sloppy
 at the start.  So to get this 
focus, we built things 
backwards.  Demo driven 
development.  We start by 
building examples of how the 
code, element, will be used.  
And this is pretty because 
because of the spec documents we
 have.  They list out the 
different variants that design 
has told us to account for and 
we can show what each of those 
look like and how the element 
will be used to build out each 
of those things.  Once we have 
that solid and we like it, then 
we actually build out the 
elements implementation.  And 
then finally we'll come through 
and add tests and make it 
production-ready.  So what this 
looks like for oh promo module 
is listing out stuff like the 
normal variants, the version 
with no image, a version for 
video, version for galleries.  
And all of this live
s in a demo file that's right 
next to the element and it goes 
through our custom Dev server.  
So as you're developing your 
element, you can be test on this
 demo page.  And as you build 
out the implementation, things 
come to life.  The whole thing 
is working and you're done and 
you're ready to start building 
those tests.  So the last thing 
that we get from web components 
is division of labor.  And 
what's nice is you can break out
 who works on which element 
based on their skill-set.  So is
 you have an element, we're 
really not sure how to build 
this thing out very well.  So 
let's give that to our artist.  
Because their going to be able 
to come up with an interesting 
solution for this.  If you have 
an element that's really 
complicated and you need someone
 that's going to put a lot of 
tests behind it, give that one 
to the scientist.  And if you 
have an element that you know 
how to build it, but want it 
built on time and get it out at 
the right moment, give that to 
your craftsman.  And
the great thing is you can come 
back and have the other style 
dot refactoring later.  The 
scientist can add more tests to 
the artist's code.  And the 
artist can say, craftsman, you 
could have built this better.  
That's great.  We hope this 
glimpse into how we build things
 will help you build great 
things with Polymer as well.  
Thank you all for being here and
 have a great rest of the
 conference.
ELLIOTT: All right.  So howdy, 
everybody.  So before we go for 
break, have just a few  
announcements.  So in ten 
minutes Valdrin Koshi, really
 interesting.  Light knacks and 
coffee are right across.  And if
 there's anything that you heard
 earlier today and you have any 
questions for them, they should 
be hanging out in the lounge.  
And we will be back at 4 p.m. 
with Monica, Rob Dodson and web 
pack and stuff like that.  It's 
going to be a lot of fun, guys. 
 Have a great break!
[Music playing]
BRANDON: Hello, Polymer 
afternoon audience.  Is everyone
 still awake?  Yeah!  My name is
 Brandon, I'm on the tools team 
at Polymer.  Working on CLI and 
bundler and build and polyserve.
  Many, many tools.  Our next 
guest is a developer advocate.  
Developers -- developers, 
developers.  No.  You know him 
from
 polycast and the many good 
videos.  I had a special 
introduction to Rob when I was 
recovering from surgery.  I 
watched about 9,000 videos of 
his as I was learning Polymer.  
He was the angel that ushered me
 into the future of web 
components.  Here is Rob Dodson!
[ Applause ]
ROB: All right.  All right.  
Hey.  How are ya'll doing?  Good
?  Yeah?  All right.  Cool.  So 
this talk is going to be about 
my journey to try to get the 
whole world using custom 
elements.  And some of the 
interesting things that I've 
learned along the way.  So I 
have been at Google for maybe 
like a little over three years 
at this  .  And during pretty 
much that whole time I've worked
 on custom elements and web 
components.  And it's my belief 
that if you're building a UI 
library and you're working at 
like a mid to large-size 
company, so you want to build a 
whole bunch of components and 
share with teams on different 
stacks, and custom elements and 
web componentses are really the 
way to about doing that.  This 
and this story is basically what
 I have been advocating for all 
these years.  And being the   
person for custom elements and 
web components means I get a lot
 of feedback on that idea.   
Feedback that looks like that.  
This was a Tweet from a fellow 
googler who was
trying to use web components 
with another framework.  Every 
few days I see someone like Rob 
say that web components work in 
all frameworks.  All of our 
problems are solved.
and it's really clear that no 
one has tried
 all of the above.  And this is 
Tweet 6b of a long list of 
grievances and sub-grievances 
that were in the Tweet storm.  
Very organized and emblematic of
 the feedback I have gotten over
 the years.  We say that custom 
elements should work everywhere,
 right?  They are based on web 
standards.  They are the future 
of the platform.  So we say 
that, and then, like, why don't 
they?  Right?  And the more I 
thought about this, the more I 
started to wonder, if, like, 
perhaps we put the cart before 
the horse.  And did we maybe get
 so caught up in the fact that 
we could build custom elements 
that we didn't stop and spend 
time to think about how we 
should build them in the first 
place?  And if custom elements 
and the things that we build, if
 they are unpredictable or 
inconsistent, does that then 
make it harder for frameworks to
 work with them?  So that's 
really what I set out to find 
out.  So I split this talk into 
two parts.  The first is my 
journey to
identify what is a quote, 
unquote, &quot;Good&quot; custom elements 
should look like.  And the 
second part, how frameworks 
should work with those elements.
  By the end I hope you all have
 a better understanding of how 
to author your components, and 
what to expect with other  
frameworks or libraries.  Let's 
dive into the first   .  What is
 a good custom elements?  To 
start this journey, I went to 
the Chrome engineer who was in 
charge of implementing custom 
elements APIs in the browser.  
And I said, do you know if there
 are any reference custom 
elements that I could look at?  
Stuff which you think really 
lives up to the standard?  My 
thinking there was that the 
people who write the specs and 
implement the APIs in Chrome, 
surely they have built a bunch 
of custom elements and these are
 the ideal components and these 
ideal components should live up 
to these.  His response was, 
nope.  It was surprising.  I was
 like, hmm.  We need to identify
 the best practices for custom 
elements.  I'm not sure
how to do that.  But maybe we 
could assemble a crack team of 
engineers and together we could 
probe the depths of the HTML 
spec and uncover the treasures 
that lay within.  That is 
exactly what I did.  Working 
with my teammates,  Sirma, 
Monica and
 Ava, we built vanilla custom 
elements, not Java or anything. 
 Just java.  And discover how 
they should be authored.  And 
along the way, we learned a lot.
  And in fact, we're still 
learning a lot.  But I wanted to
 go through some of the stuff we
 have tried to capture so far.  
I have been doing this work 
inside of an element set which 
we call the how-to components.  
So the how to components, these 
are collection of educational 
custom elements.  We're saying 
that this is sort of like 
literate code.  So we want folks
 to actually look at the 
implementation, read them, look 
at the comments, understand why 
we did the things that we did.  
Now, I want to be really clear, 
these elements that I'm talking 
about here,
 these are not things you should
 use in production.  They're not
 even styled, really.  These 
won't be going on web 
components.org or anything like 
this.  Instead, we wanted the 
developers to read the source 
code side by side with the 
comments and learn from the  
elements and understand why we 
made certain  decisions.  And 
then take that knowledge and 
actually go apply it to the 
custom elements that they are 
building within their own 
company.  And I want to be also 
really clear that, like, this is
 a work in progress project.  
You know, don't be surprised if 
you're looking at the repo, we 
start changes things around.  
Because, basically, as we learn 
new ideas, and it happens all 
the time, we learn new ideas and
 bring them to all the elements.
  Update all at once.  It's not 
a production thing.  Don't use 
the code.  But read it, 
interpret it and look at it.  We
 want to have a conversation in 
the open on GitHub about why 
should we do this?  Why should 
we not do this?  You
can check this out.  The repo is
 on GitHub.  Here is a direct 
link to it.  And I would like to
 walk through some of the best 
practices we have learned as we 
were doing this.  So I split 
this up into kind of three 
topics.  We're going to try and 
cover.  How do you deal with 
ShadowDOM?  How do you handle 
attributes and properties?  And 
how do you manage events in your
 elements?  And I want to be 
clear that what I'm going to 
talk about today are guidelines.
  So these are not meant to be 
like rules or laws that you have
 to follow.  Because the web 
platform is not really 
consistent all the time.  Not by
 a long shot.  And so you should
 always feel free, when you're 
building your own element, to 
color outside of the lines if 
you need to.  If your element 
calls for it.  You get to make 
is that decision.  I want to 
dive into some of the best 
practices and start with 
ShadowDOM and some of the things
 we have learned.  The first 
thing that comes to mind when 
using ShadowDOM and as a
vanilla custom elements and not 
using any libraries or anything.
  Is, does my element need 
ShadowDOM?  I have to admit that
 personally over the last year 
and a half I kind of got a 
little cranky with ShadowDOM.  
Got a little frustrated with it 
at times.  And I've the team -- 
Polymer team -- got to use 
ShadowDOM when building custom 
elements.  Got to use it.  Hey, 
ShadowDOM, it can be annoying to
 work with at times.  Hard to 
retheme.  And polyfill can be 
wonky.  Don't tell Moe what to 
do and I will build my own  
elements.  Deal with it, boom.  
That is actually how we started 
this process.  We are going to 
build vanilla custom elements.  
We're to the going to use 
ShadowDOM.  We're going to do 
our own thing.  The first one we
 created was a check box.  Very 
simple.  Howto-checkbox.  It is 
a single tag, doesn't have any 
children.  I didn't see why 
something like this would need 
ShadowDOM.  Instead, okay.  
Cool.  We have a
 JavaScript for our element 
definition
and a  CSS file for our 
definitions.  But very quickly 
we discovered in they take your 
element and you're  using a 
global style sheet like that, 
and they put it inside of 
another element that uses 
ShadowDOM, all of your styles 
are broken.  Because you don't 
have a way of getting your style
 sheet into that element's 
scope.  Make link out to the 
style sheet or have a build tool
 or a build process inject your 
process into their element or 
something.  But it basically 
means that it's up to you and 
that developer to figure out how
 you're going to get your styles
 into their scope.  So I felt 
kind of not awesome about that. 
 But whatever.  And I should   
this out.  This is really 
interesting.  There is actually 
a discussion to see if we can
 streamline this a little bit.  
There's a thread where Steve, a 
member of the Polymer team, has 
proposed if you have a custom 
elements, with no children
, could you  maybe, as you 
register the element, give a 
style sheet
object.  And that would work as 
a user agent style sheet just 
for that tag.  This is a cool 
proposal and I hope we land it 
at some  .  This is not real, 
this is not shipping anywhere.  
And it made me realize that you 
probably need to create a 
shadowRoot if your element is 
going to self-apply any styes.  
And you might have a shadowRoot 
that only contains a style tag. 
 And that's totally okay.  The 
benefit is that your element 
becomes easier for people to 
reuse.  Outside of ShadowDOM, 
inside of ShadowDOM.  And put it
 inside of more complex elements
 and it just works.  Now, as we 
were working through
 this first element, a 
conversation kind of popped up 
on my Twitter feed.  And someone
 said -- I'm paraphrasing the 
original thread here.  But while
 we have thing like CSS-in-JS 
for scoping our styles, do
 we need shadowRoot?  Can I use 
these fancy tools? and it was 
Trey who will be speaking 
tomorrow speaking on Twitter 
saying that style  scoping is a 
benefit of ShadowDOM.  But one 
of
the other major benefits is DOM 
encapsulation.  So if you're 
building an element, as it 
creates its own children as part
 of its implementation, you can 
hide those children, you can 
hide that implementation inside 
of that DOM-scoping bubble.  And
 this is crucial for framework 
interoperability.  So he  shared
 an example I want to walk you 
through.  It's interesting.  Say
 we're building an element.  A 
counter.  It's saying count, and
 have a number next to it, one, 
two, three -- and so on.  So I 
have a div in my tempt with the 
word&quot; Count&quot; and then have slot.
  And the framework or library 
that I'm using this element 
with, they're going to put the 
number in there for me.  Two 
versions.  The first is count 
with shadow.  Create a shadow 
root.  The element is 
constructed.  And then the other
 version I'm going to create is 
called count without shadow.  
Instead of using ShadowDOM at 
all, we're going to stamp into 
the DOM.  I'm cheating a little 
bit.  They don't work outside --
 go
with it.  Pretend it does.  What
 happens if we try to use this 
in React?  I'm going to try to 
stamp out both of those 
elements.  And I'm just going to
 have React pass in the count.  
So every tick is just going to 
pass a number as a child of each
 of these elementses.  One, two,
 three, and so on.  So what do 
we get when this renders?  Well,
 you might be a little 
surprised.  The first element 
looks like we would expect it 
to.  Right?  Got count one.  The
 second element, though, looks 
totally broken.  And I wanted to
 dive into that a little  bit.  
Why is that?  In this first 
implementation, all React can 
see inside of this element is 
just the number one, which you 
put inside of there.  Now, we 
know there's a shadowRoot, and 
inside of that shadowRoot is the
 word &quot;Count&quot; on our slot tag.  
React can't see that.  It's not 
piercing the boundaries.  That's
 good.  It means our 
implementation is hidden.  If we
 look at the second element, 
though, it's kind of more 
interesting. 
Because it seems like React 
created an element and then put 
some text inside of it, and then
 attached it to the document.  
And then our connected callback 
ran and our stuff stamped out 
after the content.  So already 
that looks broken.  Probably not
 what we want.  But it gets 
worse too.  The next tick, React
 is going to look at this and be
 like uhhh -- in my render 
function, you told me about the 
number, but didn't tell me about
 the div thing here.  You didn't
 tell me how to render any of 
that.  So what's it going to do?
  It's just going to delete it. 
 And so the next phase, throws 
away the light DOM children and 
now we have just the number two 
inside of that element.  Now I 
did some tests and found other  
frameworks may leave your light 
DOM children in place, or may 
not.  There's really nothing to 
enforce that.  It's kind of a 
convention that they may or may 
not adopt.  What we learned from
 this, if you're authoring an 
element that creates children, 
you probably want to put
those children inside of a 
shadow root.  Those children are
 part of your implementation, 
and the rest of the page should 
not need to know about them.  
After all this thinking, back to
 the original question, does 
your element need ShadowDOM?  It
 does.  It can be frustrating 
and cranky to work with, but 
without ShadowDOM, you lose 
guarantees of safety.  You want 
to put your element inside of an
 element, inside of a framework 
with other JavaScript actors at 
play, ShadowDOM protects them 
from the outside world.  It is 
the framework to make the 
interoperability.  That takes 
care of ShadowDOM.  If you're 
self-applying styles, 
shadowRoot.  And any children 
you create, inside of the 
shadowRoot.  Let's talk about 
attributes and properties.  How 
does your element handle data 
and reflecting state to the 
outside world?  Might seem like 
minutiae or a boring topic to 
talk about, but when it comes to
 framework interoperability bugs
 and issues, this area is 
actually where I found the
most problems and the most 
differences across the board.  
And this is like a really 
contention topic,  actually.  
The even the Chrome team, the 
people that work on specs and 
others have different ideas how 
to work on attributes and 
properties.  I wanted to get to 
the bottom of this and put out 
some semblance of best 
practices.  When we think about 
attributes and properties, what 
would we consider canonical 
behavior?  Okay, well, I mean, 
where would I even look to 
figure that out?  Well, there's 
HTML, right?  HTML has a spec.  
If you read the HTML spec, it 
explains how attributes and 
properties work.  I guess we'll 
read the HTML spec and do
 everything it says.  I don't 
know how many of ya'll read the 
spec and dive in there.  It's 
pretty gnarly the deeper you go.
  If you dig down deep enough 
you'll find inconsistencies, 
anan crow niches, and stuff that
 predates standardization.  
Older elements, like input, are 
super-weird.  It can make it 
hard to distill out what one 
would
consider the best practices.  
But for all its faults, it's 
also kind of the only model we 
have to follow.  If you can make
 a custom elements that's mostly
 indistinguishable from the 
built-in native tag behavior, 
there's a good chance frameworks
 will be able to work well with 
your component.  Here are some 
of the best practices we came up
 with.  The first is that for 
primitive data -- strings,  
numbers, bullions -- accept that
 as either  attributes or 
properties.  Ideally, both.  
Someone should be able to walk 
up to your element, settlement, 
set property for a corresponding
 property, and both should just 
work.  And ideally, reflect back
 and forth between your 
attribute and your property.  So
 let me give you an example of 
that from a native element.  So 
look at the native video tag
, I want you to see the 
behavior.  It's interesting.  It
 has a preload property and a 
preload attribute.  They 
correspond.  I can go up to this
 element and query it and say, 
all
right, what is your preload 
property value?  And by default,
 it's auto.  And I can set that 
property to none, and it sprouts
 an attribute when I do that.  
And then I can read that 
property value again, and it's 
actually reading it off of the 
attribute.  That's interesting. 
 Can we mimic the behavior of 
built-in elements with our own 
elements?  My understanding when
 talking to spec authors, the 
way this is implemented in 
native HTML, there are getters 
and setters for all the of the 
properties.  And the  getters 
and setters are really dumb.  
The only thing they do is 
reflect back and forth the 
attribute.  I'm going to make a 
fake element, called custom 
video, and my getter, I'm going 
to try to get the value from the
 attribute.  If there is one.  
I'll return it.  If there's not,
 I will return a default value. 
 Right?  So this is that default
 autostring that we saw.  This 
is kind of interesting, because 
you're co-locating the default 
value with the property, with 
the
getter and setter.  In the  
setter, all we do is we take the
 value that was  passed in and 
we reflect that to the 
attribute.  And because the 
getter is leveraging the 
attribute, we have now synced 
our properties and attributes.  
So change one, changes the 
other.  Right?  That's pretty 
interesting.  We don't have to 
write any additional code.  We 
don't have to have an underscore
 property that you're sort of 
managing under the hood and this
 private state.  Instead, these 
two worlds are just in harmony 
now.  That was interesting.  You
 can see this in action with the
 custom video element I created 
here.  So you can go and look at
 it.  And basically the same 
behavior.  We get the default 
value out of that getter.  We 
set it.  Now sort of spring an 
attribute and then we read the 
property again, it's reading it 
off of that attribute.  So for 
primitive data, I feel like this
 behavior works quite well and 
makes things consistent.  So 
someone can fiddle around and 
get the right
attribute.  There are exceptions
 to the rule.  You might not 
want to reflect properties that 
are high-frequency.  The native 
video tag has a current time 
property.  And that, you know, 
is  basically every millisecond 
it's updating the current time 
for the video.  So reflecting 
something like that, don't want 
to do.  Again, HTML spec, 
there's inconsistencies and 
quirks and reasons to color 
outside the lines.  But 
generally speaking, primitive 
attributes and properties 
reflecting is a good thing and 
simplify the model as well and 
help you write your component if
 you're consistent.  That's 
primitive data.  What are for 
objects and arrays, Rich data.  
You probably only want to accept
 that as properties on your 
element.  And there's reasons 
for this.  Oh, you probably 
don't want to reflect rich data 
from properties back to  
attributes.  And the reason is 
because, one, it's expensive to 
reflect.  So stinging an object 
and reflecting that, doesn't 
seem useful.  Polymer used
 to do this.  Polymer 0.5, we 
reflected everything.  And we 
stopped because people were 
sending these massive JSON 
objects down.  And we would 
stringify it all for very little
 gain and spending a bunch of 
time parsing and unparsing 
JavaScript.  The other reason is
 a serialized object loses all 
of its identity.  This is 
something my teammate, Justin,  
   ed out.  And it has objects 
and you call JSON  string, you 
have broken the references.  
They don't work anymore.  Pass 
that to an element.  And maybe 
the person is expecting, 
mutating the object to mutate 
some of the original sub 
properties and that just doesn't
 work.  So if you just stick to 
 properties, you avoid all of 
this weird spring bizarreness.  
Definitely think about that.  
Attributes and properties, quick
 recap.  You know, primitive 
data, you want it as either 
attribute or property.  Ideally 
want both.  And you want them to
 reflect.  And then for rich 
data, objects and  arrays.  I 
think your
element should really just 
accept those as properties.  And
 that'll make your life a lot 
simpler.  Last thing -- I'm
 going to be quick about this --
 events.  When should an object 
dispatch events?  It's weird to 
think about, but it's 
interesting.  If you look at 
native built-in elements, they 
do not seem to dispatch events 
in response to like a host 
setting property or anything 
like that.  And I think there's 
a good reason for this.  It's 
kind of superfluous, right?  You
 set a property, and you set an 
event.  You don't need to tell 
me the value, I said it.  It's 
weird to dispatch an event then.
  And if you're not careful, you
 might end up causing an 
infinite loop.  Hey, this 
property changed.  And if you 
have a unidirectional app set 
up, using React and Redux.  The 
host is like, I don't care that 
the property changes, my model 
says this.  And sets the 
property.  And the property 
says, hey, the property changed.
  And the host says, no.  And 
you end up in an infinite loop.
I recommend not dispatching 
events in response to the host 
setting a property.  This 
differs from how Polymer does 
things.  Polymer changes things 
whenever you change properties. 
 This powers Polymer's data 
binding system.  But since it 
does the additional work to 
guard against firing an event if
 you set the value
 to the same property twice, 
it's okay.  Not an infinite 
loop.  But with a vanilla custom
 elements, there's not a lot of 
value in firing property change 
events.  That leads to the next 
question which is, when should I
 dispatch  events from a custom 
elements?  And here what you 
want to do is you only want so 
dispatch events in response to 
internal element activity.  What
 is internal element activity?  
Well, this could be things like 
a user interacting with your 
control.  An asynchronous task 
finishing like something  
loading or an animation 
completing.  Basically, any time
 the component knows something 
changed and the host does not.  
And we need to clue the host
in.  Need to tell the rest of 
the app, hey, something new has 
happened.  This is a good time 
to dispatch an event.  And this 
kind of mirrors what native  
built-in elements do.  So last 
to recap really quick on events,
 don't dispatch them in response
 to  downward data flow.  Do 
dispatch them when your 
component has special private 
knowledge that the rest of the 
app does not have.  I realize I 
went through all of these like 
super, super fast.  And that's 
because, you know, we're short 
on time.  And this is by in 
means an exhaustive lists.  Many
 of these are things Polymer 
does for you already.  If you're
 using Polymer, that's awesome. 
 Don't have to worry about this.
  But I wanted to go through the
 process of documenting all of 
these things and  trying to 
figure out how stuff should 
work.  So we have been 
collecting all of these best 
practices we have learned while 
building the how-to components 
ands and developed a new section
 on  developers.google.com.  And
 it
takes our existing material 
around web components and custom
 elements and organizes it 
better.  AP primers, checklist 
of custom elements and best 
practices.  And a few example 
how-to components are up there 
as well, demonstrating how to 
implement those best practices. 
  You can check this out.  
Here's a direct link to it.  Now
 that we've looked at custom 
elements, I want to switch gears
 now, and here is where the talk
 gets a little bit more fun.  
Because I want to look at the 
other side of things.  And I 
want to talk about how 
frameworks should then work with
 custom elements.  And this is 
like a really tricky problem to 
solve, because, like as you all 
know, there are as many 
JavaScript frameworks as there 
are stars in the  Milky Way 
Galaxy.  This is not something I
 have to tell you.  This is a 
known fact.  But I thought what 
we could do is take a sub-set of
 the most popular frameworks and
 write automated tests and 
publish the results to the web 
to see what does and doesn't
work and hopefully learn.  I'm 
exciting about a new project I 
have been working on.  A new 
site, custom elements 
everywhere.  Making sure custom 
elements and frameworks can be 
best friends forever.   The  URL
 is custom-elements-everywhere
.com.  You can check it out.  
But keep paying attention to 
this talk to.  This is a quick 
run through of how it  works.  
Every framework on the site has 
a little section.  And in that 
section I indicate how many 
tests they're passing.  There's 
a little write up to explain 
like any quirks or gotchas or 
anything weird like that.  I 
went through and tried to track 
every GitHub issue for the 
libraries so you can keep tabs 
on everything in one place.  And
 you can click the button and 
view all of the tests for the 
framework.  All right.  What 
passes?  What doesn't pass?  So 
you can have a better 
expectation of I'm going to use 
this custom elements in React or
 Angular or  whatever.  This is 
what is and what is not going to
work.  Oh, yeah, this is where I
 wave my arms around and 
apologize.  All right.  If a 
framework is not represented 
here, it's not because it's not 
important or awesome or 
anything.  I think all of them 
are awesome, it's just really 
hard to write a Webpack file for
 every framework.  Have ya'll 
tried that?  It is not fun.  So 
I have done my best here.  But I
 love help from the community to
 add more libraries to this 
site.  I really want everyone to
 feel like the tools that they 
use and that they enjoy that 
they, you know, are fairly 
represented on here.  And the 
other thing that I want to   out
 is there are some known 
unknowns to this process.   
Like, have I rigorously tested 
every feature of every framework
 in every permutation of outlets
?   No.  I don't know the 
features of all the  frameworks.
  But I wanted to have is a 
starting   just to help some of 
these things shake out.  So 
check out how we did.  So I'm 
going through these scores in 
alphabetical order, starting
with A for Angular.  And Angular
 actually got a 30 out of 30 in 
the test that I wrote.  I was 
not able to write any tests that
 Angular failed.  New Angular, 
not old Angular.  New Angular.  
And like I said, known unknowns.
  So if you are using new 
Angular and  running into 
issues, please, open a PR.  Open
 an issue on GitHub and help me 
track those downs.  Write some 
tests.  The tests I have written
 so far, Angular passes all of 
them.  Preact, 24ous of 30,  
80%.  React, 16 out of 30, 53%. 
 We'll talk about why that is, 
and Vue, 30 out of 30.  They're 
getting
 100.  So far I have not 
encountered any major issues 
related to ShadowDOM as long as 
the custom elements is following
 the best practices that I 
talked about before.  In the 
past this is an area where 
things did not work.  In 
particular with like polyfill.  
But these tests run, and against
 the ShadowDOM and against the 
polyfill, and so far no 
ShadowDOM  issues.  So fingers 
crossed, maybe we're in a better
 place today. 
That would be exciting.  Let me 
talk about the two areas where 
we did encounter issues, though.
  That was around handling data,
 so  attributes and properties, 
and dealing with events.  And 
the tests for attributes and 
properties, these mainly check 
that you can pass data to an 
element declaratively.  So using
 a framework's binding syntax, I
 can get the data into my 
element like I need to.  And I'm
 kind of generalizing here, but 
I think roughly speaking there's
 like two ways you can think of 
doing this in framework land.  
There is what I'm calling the 
manual approach where the  
framework has explicit syntax 
you can use to tell  it, hey, 
either set up property on this 
element or set an attribute on 
this element, but it's sort of 
up to the developer to make that
 decision.  And then the 
automated approach where there's
 one binding syntax.  And the 
framework has a heuristic that 
it uses at run time to figure 
out how to pass an element.  I'm
 going to go through these
and indicate which framework is 
which.  Again, start with  
Angular.  This is the binding 
syntax for Angular.  This is how
 to pass data to any element or 
 component.  If it's an angular 
component or custom elements, 
it's what you use.  It's saying 
set the foo property equal to 
bar.  Bar is some property 
inside of your Angular 
component.  In other words, my 
element.foo queal bar.
  So you can pass objects and 
arrays.  Like but talked in the 
best practices, that's how we 
want to pass rich data.  This 
works really well.  If you need 
to explicitly set an attribute 
for any reason, you can do that 
as well.  You can add this 
attribute modifier to your 
binding, and tells Angular to 
explicitly call set attribute.  
And this falls into the manual 
bucket.  Do whatever you want in
 your syntax.  Vue is similar, 
but it's the inverse of what 
Angular does.  So for a 
component that Vue creates 
itself, a component written
 in Vue.js, it will pass 
properties.  But when it 
encounters a
custom elements, it will pass 
data as attributes.  That's like
 set attribute.  But because Vue
 also falls into the manual 
bucket along with Angular, they 
have
 a .prop modifier.  And you can 
tell it explicitly, pass a 
property to an element.  Which 
is good.  Now we can pass 
objects and arrays to elements. 
 React falls into what I'm 
calling the automated bucket.  
It has a heuristic that it uses 
to try to decide how to pass 
data to an element.  Currently 
when it encounters a custom 
element, it will always pass 
data as attributes.  For 
primitive data like a string or 
a number or bouillon, okay, 
maybe this is fine.  But when we
 get to rich data, this becomes 
a problem.  When you call set 
attribute in React, you indeed 
up with something like this.  
And that's not very useful.  I 
can't do anything with it.  In 
React there's not a good, 
declarative way to pass rich 
data to a custom elements.  You 
can work around this.  You can 
grab a reference to the element.
  And in the render function you
can manually set the property on
 it.  But because there's not a 
declarative way to do it, React 
is different.  This is like a 
hiccup, not a show stopper.  You
 can use custom elements with 
React, you have to know about
 this gotcha.  They are looking 
at switching this attribute.  
This is an RFC for React 16.  I 
think it would be awesome if 
they did this.  You can check 
out GitHub issue to follow the 
discussion.  Finally, Prect, 
like React, it uses JSS.  But a 
different heuristic.  So when it
 encounters a custom elements, 
it will use the property on the 
custom elements if it is 
defined.  If it is available.  
Otherwise it will fall back to 
using an attribute.  So the way 
this works in Preact is this.  
In check, if foo in my element, 
use the property.  If it's not, 
okay, we'll fall back to the 
attribute, then.  We'll treat it
 like configuration.  This is 
cool and works well.  As a 
result, it passes all the tests 
I have written so far.  And they
 have a pull request open so if 
the
element it's working with is not
 upgraded yet and passing rich 
data like an on or array, it 
will use that as well.  Let's 
talk about events.  So the test 
here check that you can 
declaratively add an event 
listener to the DOM events 
dispatched by custom elements.  
So the way this works in Angular
 is anything that you put in the
 parentheses there, that is the 
event name that you are telling 
it to listen to.  The value, 
then, is the handler to run.  So
 this is like saying my element 
add event listener, foochanged. 
 On.  And we can use any basic 
event name inside of the 
parentheses.  We can use lower 
case, caps case which is good 
for URL changed or DOM ready.  
Think of like acronyms and 
things like that.  That'll work.
  Camel case, kebab case, 
Pascalcase, my personal 
favorite, Assholecase.  Do not 
actually -- no, no, no.  Vue on 
the other hand, is basically the
 same behavior as Angular.  So 
anything you put after the v-on 
 directive, doesn't matter the 
case.  It will
pass in view.  React is a little
 tricky.  React doesn't have 
declarative syntax for listening
 to DOM events.  So React 
implements its own synthetic 
event system that sits on top of
 the DOM event system.  For 
native elements they have a 
white list of events that they 
know to listen for.  But that 
doesn't work for custom elements
 because we could dispatch 
infinite different event names. 
 So unfortunately this looks 
really tempting, but it does not
 work.  Bummer.  Again, like the
 attributes and properties thing
 before, we can work around 
this.  You can just grab a 
reference to the element inside 
of your render callback.  And 
then using, like
, component did  mount, a hiccup
, not a show stopper.  But 
something to be aware of.  And 
they have a GitHub issue to 
bypass their synthetic event 
system for custom elements.  I 
think it would be really, really
 awesome if they did this.  But 
this is still being discussed.  
And finally Preact.  And the 
exciting thing about Preact is 
that it uses
 native DOM  events.  So this 
right here totally works.  
Mostly.  It mostly works.  
There's, like, some gotchas.  
The only thing is that Preact 
will take everything after the 
word&quot; On&quot; and call two lower 
case on it.  So if your event 
was actually named Foo Changed 
and those capital letters, it 
would change it to lower case 
and maybe ne'er hear your event.
  You're now thinking the same 
thing.  Which means it doesn't 
support AsSholecase.  Major WTF.
  I showed this to Jason Miller,
 the creator of 
preact.  And he calls it mixed 
case events.  He's Canadian and 
very  polite.  But we know what 
he means.  So with that, I think
 we're nearing the end and I 
want to recap some of the things
 we learned along the way.  So  
regarding custom elements, I 
don't think there are really 
any, like, rules which dictate 
how you must write a custom 
elements, but I do think there 
are best practices that we can 
start to follow which will make 
it easier for us to, you know, 
write
elements consistently and easier
 for other  developers to then 
consume those elements that we 
create.  And when it comes to 
frameworks, the good news is 
that most of what seems broken 
today I think is actually very 
easy to fix.  And there's 
already issues open for most of 
it.  And if we can generally 
agree on how custom elements 
should behave, and then in turn 
how frameworks should 
communicate with them based on 
those assumptions, I think we're
 pretty close to this cool 
inter-op framework utopia land. 
 Seeing we have libraries that 
basically get perfect scores on 
the tests I have been
 able to write is really, really
 encouraging.  I want to thank 
all of these awesome folks.  The
 folks who worked on how-to 
components, reviewing the site 
and the tests.  And also just 
hash out these best practices 
with me in docs and threads and 
everything.  These are all  
very, very nice people who were 
kind enough to share their time 
with me and I appreciate that.  
And thank all of you
for taking the time for 
listening to me today.  I am 
excited to see what you build 
and I hope you enjoy the rest of
 Polymer Summit.  Thanks.
BRANDON: Awesome job.  I want to
 see a bumper sticker that says 
co-exist, but with the 
JavaScript framework logos.  I 
think Rob was on a good path 
there.  Our next guest I met 
through a bunch of GitHub issues
 he was filing on our tools.  
And I have spent the last year 
trying to get our stuff good 
enough for him to use.  And his 
next talk is going to show how 
some of that work is irrelevant.
  This is Chad

Killingsworth.
CHAD: Thanks.  I work for Jack 
Henry and Associates which you 
have probably never heard of.  
We write U.S. banking software. 
 Why am I talking to you today? 
 In that role, I contribute to 
Polymer and another is Google's 
closure compiler.  But  today, I
 want to talk to you about a new
 project, and that's using 
Polymer with Webpack.
  Now, I can tell from the 
amount of questions I have 
already had that there's a lot 
of interest in this subject.  
Hopefully I can give you the 
detail you need to actually use 
this today.  Before we dive deep
 into the internals of how 
Polymer and Webpack can operate 
together, I want to talk a 
little bit about why this is 
important and how we got here.
  So my team has been building 
JavaScript applications for a 
long time.  A number of years. 
 app was bound
to the framework.  We didn't 
have a good set of choices.  We 
were either making the same 
framework choice we already 
made, kills innovation, or 
rewriting and duplicating code 
we had already written.  Which 
is never fun.  And the other 
thing we found with it is that 
modern JavaScript frameworks 
tended to
, you can't break old code in 
the platform.  So if we were 
using platform-based
 code, we're guaranteed 
backwards compatibility.  Great.
  This is perfect.  This gives 
us our long life span.  In 
addition, Polymer, as a library,
 was really light syntactic 
sugar over the standards.  And 
in fact they went out of their 
way to not re-implement or even 
make easier in some
 case
native APIs, which we love.  
While it might require us to 
write more code locally, that 
code was closer to the platform,
 thus producing our longer life 
 span.  So with the promise of 
Polymer 1, I dove into it fully 
with my team and helped develop 
this rich component library that
 we can share among all of our 
projects of UI elements.  The 
idea being, as each project spun
 up, we could reuse what we had 
built as Rob so aptly 
demonstrated and talked about, 
but not be locked into this huge
 framework.  So we did it.  And 
in most cases things worked 
great at the element layer.  
When we put a Polymer element 
into an old Angular project, it 
worked.  Now, there's caveats.  
Angular couldn't see in 
ShadowDOM.  That was 
intentional.  We expected that. 
 But once we got beyond, hey, 
this actually works, how do we 
build  it?  Life was not near as
 fun.  The really interesting 
thing came down to Polymer being
 mix of HTML, CSS and 
JavaScript.  Now, like most 
teams, we had been through the 
full
gamut of frontend build systems.
  Started with Grunt, moved on 
to Gulp and even experimented 
with npm scripts and rewriting 
Gulp ourselves.  And truth be 
told today we have projects that
 use
 each of these.  Didn't matter 
which of the systems we chose, 
integrating Polymer was not fun.
  One of the problems we 
encountered is when you did 
this, Polymer used HTML Imports.
  Everything else out there uses
 modules of some sort.  CommonJS
, ES modules, didn't matter.  
They used a module-based syntax.
  So those dependency trees, 
there was just no good way to 
mesh them.  What we ended up 
doing felt pretty icky.  We had 
to create a synthetic Polymer 
import element and add any app 
we might want to use in the app 
to our import and use it over 
and reference it over in the 
JavaScript.  But when we switch 
back or refactor, we have to 
remember, oh, now I no longer 
use this.  I need to remove it 
from my HTML import over here.  
And be careful, because I'm 
really not using it anymore.  On
larger projects we ended up 
writing custom  tooling to add 
checks that those two didn't get
 out of sync.  Again, not a lot 
of fun.  What we found ourselves
 struggling with was just the 
sheer weight of the build system
 code.  Over and over in my  
team's retrospectives it keeps 
coming up.  Got to be a better 
way.  I don't like writing all 
this build system code.  The
 other clue that it needed 
fixing was that it needed fixing
.  I did not go out to write a 
build system.  I sent out to 
write a product for my company. 
 Webpack.  Webpack is a build  
system.  And I'm talking about 
solving build system problems 
with a new build system.  It's 
okay.  It's totally worth it.  I
 know you have heard that a 
hundred times.  Give me a chance
 to prove this is the case.  So 
Webpack is a little bit opinion
 ated.  But tends to be in the 
ways that help you as a 
developer instead of getting in 
your way., for instance, there's
 a lot of tedious tasks that 
Webpack bakes in.  Calculating
the hash of a build file system 
to do cache busting.  There's 14
  kaJillon plugins that do that 
in Grunt and Gulp.  Webpack has 
it included.  Don't mess with 
it.  Just use the naming 
convention and away you go.  One
 of the other big benefits of 
Webpack is that it comes with 
the Webpack web server, which is
 a local development server and 
an extremely stable file 
watcher.  And I reference that, 
because if you have tried to 
roll your own Dev server, you 
know how easy it is for the 
exception to crash your Dev 
server.  Doesn't happen with 
Webpack.  One of the other 
defining points of Webpack is 
the dependency graph.  This is 
not new.  Lots have the 
dependency graphs where they 
crawl your site and find the 
used code.  The difference with 
Webpack is it's all your code.  
Not just your JavaScript, your 
CSS, fonts, images, all your 
static acids are added to the 
build graph and copied to the 
distribution folder.  That means
 when you stop using them in 
your code, they don't get
copied to the distribution 
folder.  This is magic and just 
works and is something I never 
want to deal with out again.  
There was one caveat with 
Webpack, though, only handles 
JavaScript modules.
  So how can we add static 
resources to our dependency 
graph when they're not a 
JavaScript module?  That's the 
job of a Webpack loader.  A 
Webpack loader takes one input 
file.  And its sole goal is to 
transform it into a format that 
the rest of Webpack can  handle.
  This makes most sense when we 
start out with ECMAScript 
modules.  Maybe we're writing 
latest and greatest stage two 
proposal ECMAScript and want to 
transport down to ES5 for 
delivery.  The loader does that,
 JavaScript to JavaScript, no 
problem.  The next part comes 
with TypeScript.  That's a 
little bit different.  In a lot 
of ways, I'm in a different 
language.  Well, the TypeScript 
loader does what the command 
line TypeScript loader does, 
down to a JavaScript module.  
Still okay.  Now we get 
interesting.  What about SCSS
files?  There I might need two 
loaders.  And you can chain 
loaders in Webpack.  You can 
compile through a Sass loader 
and through a CSS-loader and 
that will make a style module 
which is JavaScript and can be 
dynamically add styles at run 
time.  Pretty cool.  So Webpack 
just handles that.  After we've 
got our loader set up, the next 
thing we deal with in Webpack is
  plugins.  And plugins can deal
 with any part of the rest of 
the compilation life cycle.  The
 natural thing everyone thinks 
about is minification or any 
other
 minifyer you want to use.  I 
tend to use closure compiler.  
Not for everyone.  Webpack has 
plugins to do framework-specific
 things.  Webpack has plugins to
 handle licensing, for  
internationalization.  Optimize 
modules so that modules don't 
get duplicated or get bundled in
 incorrect ways.  On and on.  
Keep in mind, a plugin works 
differently than a loader.  It 
works across multiple files.  A 
loader is a single file.  One of
 the other
strong benefits of Webpack is 
how easy it makes code splitting
 and lazy loading.  Again, these
 are not new concepts, but they 
have been frequently painful in 
build systems.  You, as a 
maintainer, has to maintain how 
does my input map to my output  
files?  In your code you have to
 import them in a way that 
actually works.  Webpack does 
away with all of that.  Instead 
it looks at how you wrote your 
JavaScript and builds the 
modules for you.  It also adds 
the loader for run time work so 
you don't have to do that 
either.  You don't need a 
separate module loader.  Webpack
 adds it as part of your build. 
 Let's take an example.  So in 
this case, we have a main 
JavaScript bundle where the 
whole app is a bundle.  And the 
last section, aptly called huge,
 is rarely used.  We want to 
split that off and lazy load it 
and make our initial page 
payload smaller.  All we have to
 do is change how we import the 
 module.  So instead of using a 
standard import statement, which
 is static, we
change to a synchronous import 
statement.  And don't worry, 
we'll talk about a couple 
formats for this.  This is the 
new dynamic import for 
ECMAScript, it's  promise-based.
  Importing the same model just 
in a different way.  Webpack 
recognizes this,  automatically 
outputs huge.js to its own file 
and injects run type code.  I 
say injects run type code.  
That's scary to anyone who likes
 to know what's going on in the 
JavaScript.  The run time code 
for this uncompressed is about 
150 lines.  So don't feel like a
 lot is going on here.  It 
pretty much stays out of your 
way and does the bare minimum 
and does it well.  So with 
Polymer, we're obviously going 
to need a loader.  Again, the 
tricky part here is that a 
Polymer element is mixed 
content.  That's the problem 
with build tooling in the first 
place.  So the 
Polymer-webpack-load recognizes 
the type of content in your file
 and processes each one a little
 bit differently.  So the first 
thing it does is it goes
through and looks for any HTML 
imports.  Instead of relying on 
HTML imports, it simply  changes
 this to a JavaScript import 
statement.  Great.  That one's 
easy.  The next one's a bit  
trickier.  What to do with the 
DOM module and the template?  In
 this case, we just make a big 
string out of it and call a 
custom run time function which 
registers it with Polymer's DOM 
module loaders at run time.  So 
just adds it in.  And then the 
last part is the script tags.  
So external script references 
also become module import 
statements.  And in-line script 
tags just become the module 
body.  So splitting up, handling
 all three different contents, 
what we end up with is an 
all-JavaScript bundle.  One of 
the side effects of doing this 
-- wait for it -- you're no 
longer using HTML Imports.  At 
all.  So now you're not relying 
on a spec that's not going to be
 implemented outside Chrome.  
And you've got a JavaScript 
bundle which then the rest of 
your tooling is free to optimize
 in the way
it sees fit.  So one sticky   
with all Polymer developers has 
been, I just want to import from
 Node modules and use it in my 
element.  With Webpack, you can.
  You don't have to do anything.
  It just works.  You're already
 in a JavaScript module.  One 
little note here -- and I'm 
going to talk about this 
multiple times -- the script 
element has type
 equals module.  This is that 
you're opting into syntax and 
that's a little bit different 
than normal.  You may have code 
that's not all using npm yet if 
you're  using Polymer.  So you 
can also configure Webpack to do
 the same type of lookup from 
your bower  components.  All 
right.  So we talked about 
adding static files to the graph
.  What about images?   Well, 
typically with HTML files in 
Webpack you would use the HTML 
loader.  It would scan your 
file.  Look for any image 
sources and add them to the 
dependency graph.  Now, adding 
an image to a JavaScript module
 dependency graph may seem odd, 
but Webpack,
again, really shines.  One what 
it does, you typically use a 
file loader for images.  That 
loader's job is copy this file 
using the naming conventions I 
specified to the distribution 
folder, and the JavaScript model
 part of it is the path name I 
just copied to.  So then I have 
a valid JavaScript module, which
 in this case just returns the 
image path.  And everything just
 works.  The trick is, Polymer 
Elements, we have already done 
all this manipulation on.  So we
 can't use the normal Webpack 
bundlers and loaders to handle 
this.  The
 Polymer Webpack bundler does 
this for you.  It's going to 
pass it off and do a similar set
 of steps with your styles.  
Both of these can also minify as
 they go, giving you more bang 
for the buck.  So there's a few 
differences in how you write 
your code when you're using are 
Webpack.  One of the things to 
note, in Polymer to lazy load an
 element, we use Polymer H ref. 
 That's HTML imports.  That's 
not going to work.  Instead, we 
need to use
JavaScript asynchronous imports.
  There's a couple of different 
varieties.  The ECMAScript 
import statement -- you can hear
 about this tomorrow in  Sam's 
talk -- it's the easy way to do 
this.  It's promise-based, and 
then dot then and then the  
results.  And perhaps you're not
 there yet and you want to use 
CommonJS.  This has been 
supported for a long time, no 
one knows about it.  But there's
 a require call called require.
ensure which takes a callback 
and does a very similar thing.  
The job is to asynchronous load 
a module and call the callback 
when it's ready.  So we can use 
that in Webpack today and then 
we have the dynamic import.  
Both statements work in Webpack 
and will be treated as a split  
 for code splitting.  Now, 
you'll notice in my paths that 
I'm importing HTML files.  Don't
 let that trip you up.  At this 
  those files have been packages
 as a JavaScript bundle.  So 
it's totally appropriate to 
import them using a JavaScript 
function.  The Webpack config 
itself
is kind of interesting to look 
at.  I think of it is as kind of
 the best of both worlds between
 the Grunt configuration file 
and Gulp programmability.  You 
don't have to do near as much 
works and doesn't get near as 
out of control as Grunt does, 
but it's a lot more declarative 
than Gulp ever was.  So like 
most systems, Webpack is going 
to start from an entry   or a 
set of entry points.  With 
Polymer, your entry   is 
probably going to be an HTML 
element, and that's just fine.  
The loader will do its job and 
everything will just work.  But,
 like I said  earlier, we 
probably also want to tell 
Webpack where to resolve and 
look up named modules from.  By 
default it's already going to 
look in Node modules, but we 
might want bower components too.
  So we just override the lookup
 algorithm and specify  
twofolders.  It will now look in
 both and I don't have to worry 
about it.  Now we need to 
configure our loaders.  Loaders 
are just a set of rules.  Each 
rule has a test that
filters down what files it needs
 to look at.  Normally the test 
is just a regular expression on 
the file extension.  Followed by
 that it use block with a list 
of loaders I want to run 
through.  One note on this, it 
runs last to first.  So in this 
case we're running the 
Polymer-webpack-load to have a 
JavaScript bundle, and then 
running that bundle to 
transcribe to ES5.  And last, 
you can use include and exclude 
 definitions to further restrict
 where it looks.  In this case 
I'm restricting it to any source
  components folder so the rest 
of my
 HTML in my project doesn't get 
treated as a Polymer component. 
 Now, remember, everything in 
Webpack is a JavaScript module. 
 Modules do not have the same 
semantics as scripts.  Probably 
the biggest difference here is 
as soon as you use a module, 
you're no longer in the global 
scope.  The easiest way to 
address this with Webpack, if 
your own code, is simply to 
declare your elements on the 
window element.  Thus forcing 
them to
be global.  Now everything works
 again.  You only need to do 
this if you need to reference 
the class constructer or the 
class itself somewhere else.  If
 you don't need to reference it,
 if you just need to define it, 
you don't need to do this.  If 
you need to reference this 
somewhere else, you can declare 
it as a property on the window 
element.  But perhaps you'd like
 to use a more modern method.  
You can also use module 
importing and exporting to do 
this.  Again, notice the script 
type equals module.  The import 
and export keywords are not 
valid in a browser unless you're
 in a module.  So they won't 
work in a script tag.  By 
telling the browser that I'm in 
a module.  Now, one note, 
Webpack doesn't care one way or 
another.  You're going to be in 
a module.  This is just an 
indication to anyone else 
looking at your element, what's 
going on.  So now that I've 
script type in module, I can 
just say export, default, class,
 whatever.  And that's now 
exported.  Other things can
now import it.  One little note 
here.  You can't actually import
 from an inline script tag.  So 
while this is valid syntax, it 
doesn't really make any sense 
unless you're using Webpack.  
And then that block of code will
 become my module body and I 
most certainly can import from 
it.  So if you're trying to live
 in two spaces at once, this 
might be a good way to handle 
it.  But a lot of the code we 
deal with isn't our own, it's 
library code.  And for that 
case, we can't go change how it 
was declared.  Webpack has a 
whole set of shimming options 
where you can, at build time, 
make minor adjustments to how 
it's declared to make it work.  
At the top I have script tag -- 
I do mean script  tag -- it's 
not global scope.  It's add some
 mixin.  I need to use it in 
another module.  Well, since 
it's no longer going to be in 
the global scope, Webpack's 
exports loader helps.  I can 
declare what file I'm talking 
about, and I need the add sum 
mixin symbol.  Webpack adds the 
import statement to
the bottom of the file, which 
doesn't interfere with source 
maps with and everything goes 
from there.  On the reverse side
 is the provide plugin.  So 
let's say a different piece of 
library
 code expected the mixin 
function to be global.  Now it's
 not.  The provide plugin says 
if any part of my compilation 
tries to add some mixin 
globally, add so it's  defined 
locally.  So you can shim back 
and forth in that way.  Now, if 
you have a large existing code 
base that uses a lot of script 
semantics, you're going to be 
doing a lot of shimmying.  So 
just keep that in mind.  Don't 
expect this to be just a plugin 
and it works for all scenarios. 
 There is a little bit of play 
around here.  You can do it, but
 there will be a lot of 
configuration to make that work.
  One of the other really cool 
things about Webpack is that it 
natively normalizes modules.  By
 that I mean it understands an 
ECMAScript static import, an
 ES next import statement, the 
CommonJS require call, and the
asynchronous CommonJS 
require.ensure call.  If all the
 rest of your code is using 
language semantics already 
supported in your development 
browser, you don't need a 
transpiler for modules.  Why is 
this a big deal?  Well, one, it 
speeds up your builds not to 
have to run them through a 
transpiler like Babel.  But two,
 debugging is a whole lot nicer 
when you have the native,  
untranspiled code right there to
 look at.  One of the gotchas 
here, though, is if you start 
using Webpack and module syntax,
 especially with Polymer 2 and 
earlier, you're going to lock 
yourselves in very easily to 
Webpack-specific syntax.  That's
 okay for your own elements.  
Just be aware, you've limited 
your ability to share your 
components with others.  Here's 
an example.  We're importing 
from Node  modules.  Awesome.  
This works.  We're using the 
Node module resolution format.  
Except that anybody else who 
uses this element also has to be
 able to use the Node module 
resolution format.  So we just
limited our ability to share 
this to  webcomponents.org.  
That's just not
 allowed.  So keep that in mind.
  Another thing to keep in mind,
 how a browser resolves a URL 
and how it resolves modules and 
how Node resolving modules, they
 have different semantics.  For 
example, the top link in the 
import section is my component. 
 You know ma
 means find my component in the 
directory I'm in.  Except with a
 JavaScript import, could mean 
import from Node modules or a 
siblings folder.  To get around 
that ambiguity, we require a dot
 slash.  So the Webpack loader 
is going to add that for you.  
But what happens if you wanted 
to use a named import for a 
component?  Well, Webpack adds 
specific syntax for this.  And 
come up where a specific URL is 
used.  By adding a tilde in 
front of the URL, you tell 
Webpack, I want this to be a 
module resolution and not a URL 
lookup.  But, again, that's very
 Webpack specific.  So be 
careful where you use it.  One 
of the really tricky things
that happens when you get away 
from HTML Imports is that the 
polyfills start feeling very 
fragile to get bootstrapped.  
You have to do this precisely in
 the right order.  So a couple 
things, one, if you're 
transpiling, you'll need the 
custom elements ES5 adapter and 
any browse their has native 
custom elements support.  But 
you can't transpile that folder 
and shouldn't bundle it with 
other polyfills, because by 
design it can throw an exception
.  So watch out for that.  The 
next thing is, the rest of the 
web components, polyfills, if 
you're using the web components 
folder, load asynchronous.  So 
you have to delay the main 
bundle load until after the 
ready event fires.  Now, if this
 all seems a bit tricky, it is. 
 But there's a demo folder in 
the Polymer Webpack folder that 
shows how to do this.  I 
recommend you reference and 
follow that and try not to 
overthink this.  A lot of 
Polymer developers always seem 
to ask, how do I use a CSS 
preprocessor like Sass with my 
Polymer 
elements?  The standard answer 
is, you really don't need them. 
 Which is true.  But not what 
they ask.  And sometimes, when 
you're working with other  
frameworks, you just really want
 to reference those global color
 variables.  Without using it.  
The problem is that the shady 
CSS polyfill features can't see 
an external style sheet.  Adding
 an external style sheet 
reference like I'm showing here 
is completely supported by the 
ShadowDOM spec.  The imported 
styles will automatically be 
added to ShadowDOM and properly 
scoped.  But, again, the Shady 
CSS polyfill doesn't see it.  So
 older browsers, you can't use 
custom CSS properties.  In no 
browser can you use the add in 
mixin syntax.  We have an opt-in
 option, in cases like this, it 
will inline your CSS into the 
development.  You can run your 
pre-processer on it, and the 
inline elements will let the 
Shady CSS polyfill match it.  
You can have both worlds at that
  .  All right.  What about 
Polymer 3?  So all of the 
functionality
that the Polymer team is moving 
towards with Polymer 3 can 
already be used with this 
loader.  In fact, it's doing 
almost exactly the same thing.  
You can bundle and use 
ECMAScript modules as you need 
right now.  Where are we going 
with Polymer 3?  Well, so maybe 
you're not thrilled with the 
idea of authoring your HTML 
inside a template literal in 
ECMAScript  modules.  Don't 
worry.  Webpack should be able 
to do that for you.  So we'll 
just run the same process we run
 today and stick it in the 
template property once Polymer 3
 is farther along in the 
development that makes sense.  
My team -- in fact I didn't 
actually do most of the code.  
The developer who did is with me
.  We wrote this
 to reduce a lot of the build 
friction we were seeing.  We are
 using this with Angular JS, and
 I know developers using it in 
TypeScript projects.  My team is
 going to collaborate with the 
Polymer and the Webpack team to 
improve the experience in 
Webpack and Polymer
 for both of these to give
you the best of both worlds.  We
 tried to design this to 
leverage the strength of both 
systems rather than to let them 
fight together.  A couple 
takeaways for you, in the 
Polymer-webpack-load project, 
you're going to find that demo 
project I referenced earlier.  
Rob Dodson wrote it.  It's a 
great reference   for the bare 
bones examples of what to use.  
But my team  maintains the 
Polymer starter kit to show the 
 changes needed make to a 
Polymer app to link to an app.  
You're free to reference both.  
Thanks.  And I'll be around 
later for Q&amp;amp;A.
[ Applause ]
BRANDON: Thanks, Chad.  All 
right.  We got one more.  And 
our next speaker is someone 
unclass  final.  You're going to
 see live coding.  When I asked 
for a live intro, she suggested 
meow, meow, meow, meow!  Here's
 Monica!
[ Applause ]
MONICA: It's not wrong.  What's 
about to  happen.  25 minutes.  
Hi, ya'll.  I have to make some 
banter with you.  So I hope the 
nightmare setup where I have 
slides for 12 minutes and a live
 demo for 12 minutes.  Two 
computers.  Everybody loves me 
right now.  Cool.  I'm just 
going to go.  Awesome.  Hi, 
everyone.  I'm Monica.  I'm not 
clicking.  Can I have a clicker?
  Please?  I'm sorry.  Hi, I'm  
Monica.  I'm that person with 
the cat.  I'm on Twitter and 
GitHub and Internet places.  And
 I have been on the Polymer team
 for about two years.  You may 
have seen me meowing about web 
components a lot.  I started 
right before Polymer 1 was 
shipped.  Back then, I thought 
web components were cool.  
Nobody knew about them.  I would
 quo to conferences and say I 
work on web components.  I don't
 know what that  is.  Is that an
 iFrame?  No, it isn't.  I like 
doing that.  I was like a 
traveling sales awesome.  Let me
 tell you how web components are
 right for you.  I'm glad I
did that, talking to people I 
sort of formed a story about the
 kind of teams that web 
components were good for, and 
the kind of people that enjoy  
using web components.  And that 
story starts with the world 
around us.  The world around us 
is built by people like you and 
me.  Sometimes we're crafters 
and sometimes we're assemblers. 
 What I think about that, think 
about your kitchen.  Somebody 
made you a table and a chair and
 a bunch of cabinets.  And maybe
 you or someone else assembled 
them together in a nice-looking 
kitchen.  You didn't go into the
 forest, cut down a tree, sand 
it down, and put the screws in 
it -- I crafted the shit out of 
this  chair.  Even Ikea, you 
assembled it.  Somebody produced
 instructions and pieces for you
.  And you essentialed.  You 
took other things that people 
did and made a thing out of it. 
 The same if you cook, take the 
ingredients and mix them 
together.  You don't find your 
own tomatoes and corn and churn 
your own butter and grind
your own spices.  This is good 
that you don't do this.  Because
 assembling is  faster and more 
efficient and accessible.  I 
have no idea how to farm my own 
tomatoes.  I know that because I
 have a plant.  It's in the 
patio.  It  makes one tomato a 
month.  I would die of 
starvation if that was my on 
tomato.  And as a society, 
assembling was -- the industrial
 resolution -- Revolution.  From
 crafting a lot and doing manual
 work to assembling more and 
making it faster and more 
oriented.  The exact is true for
 the web.  The web is like a 
society.  But on the, we tend to
 be more drafting than 
assembling.  That's a little bit
 weird.  We're not going to 
progress as a society if we 
don't learn from the societies 
we have.  And the reason I like 
this crafters and assemblers 
metaphor is web components sit 
nicely as a bridge between these
 two.  If you think about 
somebody who makes components or
 elements.  They have a lot of 
institutional knowledge about 
what makes that element good.
And all the heavy lifting that 
you need for that element.  
Something like paper dialogue 
requires a lot of the really 
weird knowledge about animations
 and the CSS spec and what a 
stacking content is.  And how 
you can't produce one from thin 
air every time you want one.  
But on the other hand, somebody 
has made you a web components.  
This enables people to pick it 
up and use it.  And form a 
really nice experience with it. 
 I can use anybody's custom 
elements, I don't need to know 
how it works.  That's great.  If
 you take my metaphor from 
before this is great.  It's 
faster to make things and more 
efficient.  The CDO of IMG said 
this last year, he said what he 
wants to see in the world is 
less crafting and more 
assembling . less people doing 
things by hand.  You shouldn't 
have to know how to build a 
table from scratch to have a 
nice living room.  Shouldn't 
have to know what a CSS stacking
 complex is to have a modal 
dialogue to tell somebody 
there's a sale on your Website. 
 This is true
of any other industry.  But it's
 not true for the web.  In the 
real world I can be a crafter if
 I want to, I can be an 
assembler if I want to.  But a 
lot of the web we have to craft 
and assemble at the same time.  
And that isn't really great.  
And all of this comes together 
in design systems.  When I say 
design system I mean like the 
elements -- with the elements 
library, the things that your 
brand should look like.  The 
colors and the patterns margins.
  Before web components, having 
a design system of the 
craft-oriented.  Look at 
Bootstrap, which is  amazing.  
But somebody crafted you an 
enormous CSS file with all the 
styles and it was great.  But 
even putting the elements in 
your page was a little bit hand 
held.  For example, this is a 
brand that you could have in 
your application, a NAV bar.  I 
took this from the Bootstraps 
site.  But imagine at some   
your brand changes.  Maybe you 
need that container fluid class 
needs to go away.  What do you 
do then?  You have to literally
 go in all of this DOM you 
produce and start deleting or 
adding code.  That doesn't feel 
a lot like assembling to me.  Of
 course we know this, web 
components came and fixed this. 
 Because now we have a custom 
element that abstracts all of 
this garbage that we don't care 
about that somebody else built 
for us.  Because the only thing 
you care about in this element 
is just that image.  So that's 
good.  But the thing is, this 
story only works if we have 
tools around us.  The story only
 work it is you know like 
Bootstrap we have a catalog of 
elements.  We know, as a 
developer, like all of these 
things that are available to me 
and I don't have to reinvent 
them from scratch.  Somebody 
already made the perfect kind of
 blue button that I want to use.
  So we made webcomponents.org. 
 You know well.  It's a public 
catalog of web components.  And 
everybody can upload components.
  And it's got demos and docs, 
and the world was good and we 
were happy.  Only we weren't 
super-happy.  Turns out that
didn't work for everyone.  
There's a lot of companies like 
EA and Comcast that use web 
components a lot.  But they're 
not public.  They can't use 
webcomponents.org, they can't 
publish  them.  They built their
 own catalog.  Webcomponents.org
 solves a different problem, how
 to let people upload arbitrary 
components.  That's not the 
problem that companies with 
private elements want to have.  
They want to display the limited
 set of components they have.  
There's no such thing as a one 
size fits all.  Steve told you 
this morning tags about 
elements.  It's about apps and 
solutions.  80% case.  80% of 
developers probably want to 
upload a public web component.  
But in the 20% case, it's edgy 
and weird and you have to do 
something different.  It's 
usually a more simpler and
  assemblier solution.  I built 
Indie elements  catalog.  It's 
not amazing.  But it's a 
specific problem.  You have a 
JSON file.  And in it you decide
 what elements you want to load 
docs and elements
for.  Polymer 1 or 2 elements or
 vanilla custom elements.  And 
they can be anything you want.  
And the code is there for you to
 do this.  And if this doesn't 
work for you, which is fine, you
 can fork it, you can clone it, 
you can fix it to make it work 
with your workflow and then it's
 good.  And the world was good 
again.  Only it really wasn't.  
We, again, solved another 80% of
 a bigger problem and left 20% 
off.  It's really great that now
 your developers know what 
elements are available for  
them.  But they also need to 
know how they fit together.  
Because an organization with 
real workflows and real people, 
you need to be able to validate 
your prototypes against code 
that you actually have.  Not 
code that you think you might 
have.  And most of the examples 
when I give talks are from the 
Chrome -- from Chrome the 
browser because I used to work 
on it.  And I know the 
developers and the workflows.  
And this is a page from the 
settings.  And the way the 
Chrome settings page gets
designed is first we give to a 
designer, Allen, he's a 
fantastic human being.  And he 
designs all of these workflows 
in Sketch.  He calls these 
sticker sheets because he 
basically has stickers of all 
the material elements that he 
would like to use according to 
material design rules and 
configures them together and 
figures out screen.  He does 
iterations, should the button be
 on the left?  The right?  
Should the text be centered?  
And then he produces a whole 
bunch of screenshots and gives 
them to developers.  But the 
thing is, real elements have 
bugs and have problems.  They 
have implementation limitations.
  And I know this because I 
wrote those elements.  A lot of 
times Allen would be, this 
toggle button needs to be 16 
pixels.  And the developer would
 be, it only works at 18 pixels 
because Monica didn't make it 
resizable.  This is annoying 
because the prototype can't be 
implemented.  This is what I 
call is what you see is what you
 hope you get.  The prototype 
you get from the
designer you get to see in real 
life.  There's no guarantee 
about it.  Nobody's
 fault.  Not always working like
 it's on paper.  Because what 
you need is a common ground.  A 
tool that has a common ground 
between developers and designers
 so they can look at the same 
elements and improve that 
workflow.  Which is a what you 
see is what you get, WYSIWYG.  
And something like this has been
 a long time dream of many of 
the Polymer team members.  We 
had this in  0.5.  It was called
 Designer.  It was really  
awesome.  And Justin is the 
visionary on our team.  He's had
 this big dream of Designer 2.  
An app that was going to build 
an app for you.  Let you do the 
 UI and the JavaScript and the 
data bindings and
 optimize shit.  Throw a service
 worker in there.  And literally
 from using the app, what you 
would see is what you would get.
  He's dreaming up the Polymer 
CLI and others that you'll see 
tomorrow.  So he's never 
finished this.  But lucky for 
you, I have small ideas
and little patience.  I had two 
free weeks and stole his milk 
shake and built this other 
thing.  Which is a getting 
started tool.  It gives you the 
ability to create something like
 a  prototype, but not a full 
blown app.  It doesn't work 
super-well all the time.  But 
helps you get started.  You 
deserve Justin's tool.  But 
instead you get a WYSIWYD, which
 is a shittier version of that. 
 I'll show it to you.  Maybe.  I
 really, really hate live demos.
  I'm nervous.  Hold all of your
 fingers and toes.  This is 
WYSIWYD.  I just got a screen 
saver.  It's going well.  Okay. 
 It's in Polymerlabs.gitHub
/WYSIWYD.  It's kind of 
terrible, but you'll live.  What
 the app does is it has a couple
 of pains.  You can select 
elements and drag them in.  So I
 can do something like a div, 
which is a native element.  I 
can resize it, I can move it, I 
can change some of its styles so
 I can make a background color. 
 And if you see over here, it 
has properties.  I'm going to 
zoom in.  It's got like a
class list, hidden and title.  
There's also things like custom 
elements.  So, for example, I 
can find a good one.  
Paper-input is my favorite.  And
 when I add it, paper-input has 
different kinds of  properties. 
 Because we actually crawl the 
prototype chain so we look at 
what elements or attributes your
 custom elements has.  So in 
this case you can see that I 
have something like value and 
labeled and disabled.  And the 
pattern.  And all that goodness 
that comes with paper-input.  
And you can change them.  You 
can change styles.  Flex is just
 the collection of like the flex
 attributes you might  use.  And
 once you're satisfied with the 
code you have been producing, 
there's a code tab where you 
actually get the code for this 
element.  It's got two imports. 
  The Polymer element and paper
-input.  Which makes sense when 
you zoom in.  And then as you 
scroll, it basically gives you 
an index.HTML that has the 
definition and the declaration 
at once.  We have the app and 
the DOM
module for the app.  It has the 
styles, I added a paper-input.  
Here they are in my template.  
And then it has the element 
definition at the bottom.  You 
can also see a live preview of 
it, which is where we actually 
render the code.  Because I 
don't trust the designer pane.  
So I give you this.  And, 
because this code isn't editable
 -- because, again, that would 
be a very complicated app and I 
want have to rerender 
everything.  There's an option 
to pop this out into a JS where 
it's conference Wi-Fi is 
amazing.  There it is.  It's 
your paper-input and it does all
 the things.  And you can from 
here on start adding logic or 
JavaScript or whatever you want.
  Cool.  So let's build a thing.
  Let's delete all the things 
first.  And then build a thing. 
 What I'm going to try to build,
 again, thoughts and prayers, is
 a YouTube  app.  Where 
basically I'm going to bang on a
 paper input and get a whole 
bunch of YouTube videos  related
 to that input.  And in 
particular, they're
going to be related to cats.  
Because why not?  See how I'm 
doing for time.  Okay.  One of 
the tabs I am showing you over 
here is the samples tab.  These 
are basically combinations of 
elements I have added because I 
don't like rebuilding the same 
thing over and over again.  And,
 again, this is the kind of app 
that you would be able to clone 
and fork and take home and you 
could add your own samples for 
whatever team you have or 
whatever your particular 
workflow.  So in this case I'm 
going to start with a header 
sample.  Which is basically an 
app header with a tool bar in it
.  And it has a div.  And over 
here I'm going to rename my div 
to meowtube.  And put some emoji
 in there.  You can tell that 
I've practiced this.  Put a 
television too.  Sweet.  So 
that's it.  And now when I save 
it, it's there.  If I preview it
, it's there.  If I look at the 
code, I actually have an app 
header with all of its 
attributes.  A tool bar and 
everything
 else.  Cool.  So I have my 
thing.  And now I want
to render my results.  So in 
here I'm going to add a DOM 
repeat.  Because I'm probably 
going to get a whole bunch of 
results.  Actually, I need an 
iron AJAX first.  We're going to
 need to ask YouTube for this.  
 Iron-ajax.  Here it is.  We are
 going to populate.  A URL, 
which I'm going to paste.  
Nobody can remember this, unless
 you're zooming, probably.  So a
 bunch of parameters.  Here is 
things like your API key, your 
query.  Which in this case I'm 
hard coding to cats.  What do 
you care about?  Which is the 
snippet?  Handle as JSON.  This 
tells iron-ajax whatever it gets
 back from the server, it should
 be a JSON.  Set it to true so 
it fetches this.  These are just
 attributes that you can get 
from the  iron-ajax 
documentation.  They're not made
 up or anything.  And last 
response, I want to populate an 
object.  Here I put videos.  
What this means is that 
iron-ajax is going to get a JSON
 object from the server and put 
it in the object.  This is a 
regular Polymer data
binding.  If you're familiar, 
it's exactly how you would write
 it.  Cool.  Now I have my iron-
ajax.  It's set up.  Now create 
my DOM repeat.  This is where 
everything can go south.  So DOM
 repeat.  Here we go.  I have 
it.  I'm going to drag it in.  
It's hanging out.  It doesn't 
look like anything.  I also have
 a paper-card-sample, which 
basically has an image and a 
link in it.  And I'm going to 
move it around so that it goes 
into my DOM repeat.  So there's 
these arrows here, because 
sometimes dragging and dropping 
is infour rating . if you don't 
want to do that, you can 
traverse the tree.  Speaking of 
the tree, here on the left-hand 
side, I haven't shown you this 
yet, it's basically all of the 
elements in your app so that you
 can see the hierarchy and you 
can click on them and select 
them.  Because, again, dragging 
and dropping is infuriating.  
And I know this, I built this.  
It was just rage.  You have 
iron-ajax, getting it for us, we
 have a DOM repeat.  Stamps the 
same thing over
and over again.  So it's going 
to stamp these paper carts for 
every result we have.  And told 
the DOM repeat to take the 
elements from iron-ajax.  
Populating an object called 
videos.  Because I've memorized 
this demo, there's a sub object 
called items, which is the one I
 care about.  Here, video items.
  The DOM repeat is going to 
take everything in the object 
and create the object.  Now to 
the paper card I can now give my
 item.  So I have an image.  The
 image should be this thing that
 I'm going to paste called item.
snippet.thumbnails 
item.snippet.thumbnails.hi.URL. 
 Very memorable.  And then for 
my link, I'm going to change the
 text content -- let me zoom in 
again.  Oh!  Hello.   Item
.snippet.title.  And then for my
 H ref every snippet has a video
 ID.  So it's going to be item  
ID.video ID.  Now if everything 
goes well, if I go to the 
preview, I get nothing, amazing.
  Something didn't go well.  So 
let's figure it out.  We have 
our image.  And -- oh, maybe we
don't have data.  Let's wait for
 it for a little bit.  Nope.  
Okay.
  Pardon me?  Oh.  Way louder 
and --
 thank you!  See.  Drag and 
dropping.  Move this one back 
and move it into the DOM repeat.
  Nailed it.
[ Applause ]
 but -- thank you!  But I'm  
honestly kind of surprised that 
work.  I'll be honest.  So it 
looks a little bit terrible 
because links are, you know, 
display inline.  And we don't 
have an input.  Let's do that 
now that we know our thing 
works.  So first of all, we're 
going to change our link to be 
display in line block so that 
it's sized correctly.  And then 
because I don't want it to grow 
so that all my things are still 
aligned correctly, I can also 
add extra styles.  So the thing 
that I did in here is that, as a
 lazy developer, I didn't add 
everything single CSS style to 
this designer because that would
 be crazy.  So instead I give 
you the option to add whatever 
you want.  If you add garbage, 
nothing is going to happen 
because the CSS parser is smart.
  So in this case I want an 
overflow.  Auto.  And then that 
will be great.  So I have my DOM
 repeat.  I need my  input.  So 
let's add a paper input again in
 here.  And then I'll drag it 
into here.  And then move
it before the DOM repeat.  And 
my paper-input is going to have 
a label.  And it's going to say 
&quot;Find your meows.&quot;  And whenever
 you type it into an input, it 
has a value property.  So I'm 
going to save that into a query 
property.  Cool.  And now all I 
have to do is give this query to
 the iron-ajax.  So move back to
 iron-ajax.  It had a parameters
 object.  And one of the things 
in here was cats with the query,
  Q.  And add the query here and
 keep the cats.  It's  Meowtube,
 we only look at cats.  Why 
would you ever want to look at 
anything else?  Now check the 
code for a second.  Have a whole
 bunch of styles, a whole bunch 
of imports.  A whole bunch of 
DOM that I didn't have to create
.  I just dragged and dropped 
and typed into text fields.  And
 look at the field.  I look far 
burrito.  I get burrito cats!
[ Applause ]
Here is a wet cat.  And if I 
opened that video, it should 
work.  And it does.  Here is 
your favorite cats just getting 
wet and miserable.  Oh.  That's 
 it.  That was my demo.  Cool.  
So this is live
.  It's Polymerlabs.gitHub/IO 
WYSIWYD.  And you can check the 
code and judge me and complain 
about it later at the party.  
And I think I have like one more
 slide to tell you about if we 
can switch back to the -- sweet!
  Oh, my god, it worked.  Never 
doing a live demo again.  Until 
tomorrow.
[ Applause ]
So because we had that 80/20 
problem, I know this is not 
going to fit all of your 
problems.  It's not going to fix
 every single workflow out 
there.  And it's going to enrage
 you because drag and  dropping 
is kind of annoying.  But the 
nice thing about it, because 
it's open source and how I tried
 to build it, you can take it, 
fork it, clone it, change it, 
and make it work for you.  Maybe
 you need a marketing site 
assembler to build things so 
your marketing team can put 
together pamphlets.  Whatever 
marketing does that sells shit 
and give use money.  Fork this 
tool and build that into that.  
Maybe you need where your 
designers can use four of their 
UI elements to build things.  
Please fork it and build it into
 that and give to your team.  
Maybe designers instead of 
designers instead of designers. 
 Because why not would you want 
that if your name is Dan 
Friedemann.  You get a bigger 
screen and do nine of them 
inside each other.  Best use of 
designer ever.  Wendy said she 
wanted to
bring web components to every 
browser and every developer.  
The way to do this is thinking 
about visual tools.  It's not 
all about your CLIs and your 
Webpacks and Gulps and whatever 
tools you use.  Sometimes 
assembling is really visual.  We
 haven't been good about 
building visual tools for visual
 people.  I hope this proves 
there are a value to do this.  
It's kind of exciting to build 
and use this.  And brings us 
closer.  We're now a little bit 
closer to assembling more things
 and crafts less.  Thank you.
[ Applause ]
BRANDON: Awesome job.  So happy 
end of day one, Polymer.  
Thanks, everyone, for coming.  
Thanks to our live stream 
attendees for joining us.  Got a
 full day tomorrow starting at 
10 a.m.  I got some 
announcements for our in-person
 attendees now.  The bullet list
 was getting longer and longer. 
 I memorized the points until 
there were 20 of them.  We have 
a party going on in a little bit
.  So stick around.  We have a 
fun after party with dinner, 
drinks and a D.J.  There are 
both non-alcoholic drinks -- 
drink responsibly.  And don't 
forget the community guidelines 
that are posted around the 
venue.  On a similar note, 
before you get started on the 
party, have a plan for how 
you're getting home or wherever.
  If you need help figuring out 
how to get a taxi, you can talk 
to the staff members  wearing 
the pink shirts.  They'll help 
you with that stuff.  Coat check
 will be open until the end of 
the night.  Tomorrow morning we 
have breakfast starting at 8 
a.m. 
There's also starting at 9 a.m.,
 you may attend the Polymer 
Women's Breakfast
.  That will feature a panel 
discussion with Wendy Ginsburg, 
Mariko and Monica Dinculescu.  
Sessions tomorrow start at 10 
p.m. sharp.  And finally -- oh, 
anyone that attended the 
Codelabs, some of you might have
 noticed we might be rate 
limited on the GitHub API with 
the calls.  If you are 
encountering that issue, you can
 go to the Polymer Elements -- 
let me just read this verbatim. 
 If you are running into this 
issue when running Polymer init,
 you can instead just press the 
download zip button in the 
Polymer starter kit repository </div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>