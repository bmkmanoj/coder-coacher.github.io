<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>V8 Performance from the Driver's Seat (Chrome Dev Summit 2015) | Coder Coacher - Coaching Coders</title><meta content="V8 Performance from the Driver's Seat (Chrome Dev Summit 2015) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>V8 Performance from the Driver's Seat (Chrome Dev Summit 2015)</b></h2><h5 class="post__date">2015-11-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/oDFWIb0pi4U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi everybody my name is Seth Thompson
and I am a PM on the chrome v8 team but
I'm here to represent the whole team and
it's a big team we have folks in Munich
San Francisco Mountain View New York and
contributors from around the world so
this stuff is really due to their
efforts ok let's get started so v8 is
shares the same name as a race car
engine and I don't know much about cars
or even mechanical engines but I am
fascinated by formula 1 for 2 reasons
the first reason is it's just so fast
the cars are going at such speeds around
the track that I read if they could
actually get enough runway on the
ceiling they generate enough down for us
to stay on the ceiling that's crazy so I
think we picked the right name for
suggesting unparalleled speed but the
second thing about Formula One that I
think is more pertinent to this talk is
the fact that every year the cars that
the racers drive undergo drastic changes
to all sorts of parts of the car the
engine the brakes the shape of the car
the steering say I mean here's just a
picture over the years of how much each
car has changed and you can imagine how
different they must be to drive around
that track the track is the same and the
driver is the same often but the cars
that they're working with have just
different performance characteristics
you know year to year a team might
change the tire tread that means
increased traction that means that the
the driver has to be cornering in a
different way than they did with tires
that that were smoother they might
upgrade a v8 engine the v6 engine to VA
this creates more power and torque but
it changes the performance
characteristics once again team might
change the turning radius to accommodate
a particular track i think Monaco the
track has such tight turns that they
need to change how steering works to
actually get the car around the turns
and the driver has to accommodate for
that on the fly and the shape of the car
the body of it changes in ways that
fundamentally affect the aerodynamics
just a small modification to one the tip
or the tail can feel different as a
driver going around the track so when I
joined Google or before I joined Google
I thought that the v8 engine which turns
dynamic javascript in a native machine
code was done when they first announced
it I mean I was such a major improvement
in speed really ran almost as fast as
native code for a variety of
applications I assume the team packed up
gave each other high-fives went home
were happy they were done but I could it
have been more wrong ever since then the
team has been working on an amazing set
of features things like adding new
support for language semantics and
syntax as ECMO script changes and
JavaScript changes they change the
heuristics that they tune for
optimization things like code cashing in
lining type inference there's a bunch of
hacks in there to really squeeze out
extra performance and the results are
dramatic chrome today with v8 of today
is a turbocharged version of the
original v8 so the engine really is
changed and unlike a car which gets a
new release maybe yearly v8 gets a new
upgrade every six weeks as new version
of chrome and chromium is released so
this talk is about the engine and the
driver working together v8 in chrome and
you the developer writing code for v8
working together to make the fastest
possible web apps so the talk is in two
parts the first part is what we're doing
on our end to make all JavaScript
currently out there faster improvements
in the engine to eke out extra
performance and the second part is how
you as a developer can best take
advantage of these changes and adapt to
machinery that's being evolved
underneath you because ultimately the
goal is to write fast JavaScript that's
fast today but then that remains fast as
it stays out there on the web and has
browsed via new browsers within
continued improvements
so let's start with what VA has been
working on what the team has been
working on in the past year I'm just
going to highlight for big areas we
released a new optimizing compiler we
drastically improved garbage collection
by making it smarter and more
intelligent we've added support for xmas
script 2615 aka es6 and we have this
incubation project which is really cool
which is a spell interpreter and i'll
talk more about why we did that in a
second so let's start with turbofan
turbofan is the code name for a new
optimizing compiler now v8 as an engine
I mentioned compiles dynamic JavaScript
to native code but it has actually a
bunch of different compilers and it
chooses which one to use based on the
code itself how long a function is how
expensive the function is what language
features a function your writing might
use and especially how hot the function
is the more you run a particular
function in JavaScript we pull out the
big guns and we use a compiler which is
takes longer perhaps the compiler code
but results in much improved
optimizations so why do we write a new
optimizing compiler well we wanted to
start up from the ground up with a new
approach turbofan represents the
JavaScript ast in a sort of interesting
new form called a sea of nodes this
reduces the loads and property axis ii
is at a really low level in the memory
to this giant soup that we can have more
freedom and how we schedule which
accesses and which loads come first and
last the scheduling freedom is is
unparalleled and allows us to to
architect new and improved optimizations
but what does this mean for you well
turbofan is designed from day one to
support atmos script 2015 so it's true
some atmos crypt features even if we
supported them syntactical e in our
older compiler we couldn't use all of
the optimization techniques that let's
say another compiler used because the
the support was spotty but turbofan will
support all of es2015 and beyond and it
will make it fast this is really
exciting turbofan uses static type
information for the first time
previously we inferred type as a
function ran we made guesses about what
the type was but with turbofan win there
static type information we can leverage
it from the beginning so I'm very proud
to announce that we now fully optimized
or will fully optimized asthma Jas with
turbofan this is a this is a big
improvement and soon when the web
assembly language spec is finished we'll
be able to optimize that as well so
rather than guessing at what types are
you're using in JavaScript if you use
asthma Jas compile C or C++ code we can
run it like native code because we know
from the beginning what types are being
used so turbofan is great but this next
improvement i think users will really
feel fastest so idle time garbage
collection is a method of freeing memory
in the browser more intelligently now
i'm sure you use chrome and you know
that when you have a lot of tabs open
the memory consumption is non-trivial so
all of these optimizations make the
browser feel so much lighter so what's
going on well blink the rendering engine
in chrome released a scheduling api
recently this is amazing because for the
first time a single API has a global
knowledge of what tasks are happening in
the browser that is when clicks are
coming in when a scroll event is
happening when the page is actually
being rendered to the screen for a frame
and of course when v8 is busy performing
a JavaScript execution on the main
thread so with this new scheduler API we
have a sense of what's going on now I'd
like to show a quick diagram here that
explains why jank happens in the browser
why something that should be a smooth
animation feels kind of jerky and
stuttery well for smooth animation you
need 60 frames per second so the bottom
of this diagram has markers for frames
going look forward in time and in
between those frames the browser's doing
work it's running JavaScript execution
to figure out what to paint to the frame
for the next screen and you can see here
it's it's often variable some frames
have a lot of JavaScript work and some
have idle time
now as the javascript is running its
creating new objects the memory profile
is increasing soviet has to have a
garbage collector which comes along at
some point and says how these JavaScript
objects aren't being used we can free
them up and lower the memory profile but
normally it waits until the memory
profile hits a certain point and then
schedules garbage collection it does
this because it doesn't know any better
you can see here how big that garbage
collection chunk is and if it comes at
the wrong time it may postpone execution
of the JavaScript for the next frame and
miss the frame this is a janky disrupted
animation with the scheduler API though
now we know when these idle spots are
happening from v8 so we can proactively
schedule garbage collection is smaller
chunks before we really need to garbage
collect so you can see here we've got
some free time in that second frame so
we'll go ahead and garbage collector and
reduce the the profile bit having this
global knowledge of idle times allows us
to make garbage collection essentially
happen when you're least expecting it
resulting in smoother animation here is
a demo of the or online 3d benchmark and
you can see after these improvements
just how much smoother this is in fact
the the video that's playing in keynote
right now is is not representing this
correctly if you try this in your
browser on the right it's even smoother
than it looks here and it's faster to
you can see how much further we are
along in a benchmark than we were before
and again this happens because we know
more intelligently win to schedule
garbage collection in between frames now
there's another improvement that this
knowledge of when the browser is idle
brings v8 has this heat of dynamic
JavaScript objects this is what makes
the memory profile so big what takes up
space and in your memory and often a
page creates a bunch of memory or a
bunch of objects when it initially loads
you can see our this graph of a page
creating a bunch of objects and
increasing memory right after the page
loads we go to increase the heap size to
that limit Prime but then garbage
collection kicks in we reduce the memory
footprint a bit
and then I background the gmail tab so
let's say I go away I'm not using it
actively and the page goes idle we can
see the the usage of the creation of new
JavaScript objects kind of tails off and
we don't have much memory consumption
but before these improvements that heap
size had still been raised and we were
taking out more memory than we needed
well now blink knows when you background
the gmail tab when you're not really
interacting with the page and we can use
that time when it's in the background to
clean up after ourselves shrink the heap
and just take back a bunch of memory so
here's a another demo there flip this
time so be careful on the right is
chrome 43 the old version on the left is
chrome 45 after we implemented these
improvements and you can see when you
initially allow it to the page memory
consumption is pretty high it's around
150 200 megabytes but the crazy part or
the excuse me well it's it was about 150
150 on the other side but after both
tabs goes idle only in the new version
does chrome realize hey were idle we can
free some memory and quickly I think
you'll see it it happens soon here we
save a bunch of memory as we shrink the
heat boom it's down to 80 megabytes
right now so it's about half of the the
memory that the older versions of Chrome
took this is huge and it's really it's
out there in the wild right now you and
your users will feel that chrome feels
lighter and snappier because of this so
that's garbage collection improvements
but here's one that developers as
developers you might be particularly
excited about we are spending time right
now working on implementing es2015 and
v8 so xmas script is the body which
determines what the JavaScript language
is and this last year they've announced
a new specification with a bunch of
really cool features got promises
proxies arrow functions ja v8 has
shipped a bunch of these features
already so you can go out today and use
classes on newer syntax and semantics
for better object-oriented JavaScript
programming
we shipped arrow functions not only is
it shorter to write this you know what
the right those anonymous functions
anymore but it's much easier to deal
with lexical binding of this so that
this in this case refers to the correct
thing whereas in previously even when
you're writing this long hand you might
have to bind the context of that inter
set interval to the outer context and
we've shipped spread and rest operators
these just make it so much easier to
write arguments that create that take in
something like an array and we've staged
a bunch more features these are just two
highlights default parameters and D
structuring assignments but we've got a
bunch more on the pipeline we are really
committed to delivering es2015 in the
browser and like I mentioned because
we're doing this in turbofan it's not
just that we support these features but
we're really committed to optimizing
them and making them fast too so here's
a project which is new and it's a bit of
an experiment but it's pretty exciting
designing v8 is all about trade-offs as
you try to go faster you grapple with
increasing memory and having a more in
computationally expensive CPU operations
but as tall mentioned yesterday
increasingly a bunch of users on the web
are browsing from what we call spelt
devices or these android phones or
phones in general that have drastically
reduced memory profiles so while you may
be using an iphone or an android nexus
in your pocket with 3 to 5 gigabytes of
memory many of our users in fact a huge
number of them are browsing with just
512 megabytes of memory this makes it
really tough to perform optimizing
compilations for javascript so ignition
is an experiment to trade off a bit of
speed that's true an interpreter is
slightly slower than compiling code to
native but it is drastically reduced
memory footprint so already based on our
experiments this project ignition has
shown that we can create a byte code
from your JavaScript AST that's three to
four times smaller than unoptimized code
than what we normally would run it off
the bat in a browser
and this is it really will be noticeable
for users on mobile devices that just
are not as beefy as some of the things
that chrome or v8 were originally built
for so really excited about this but
what's next briefly I want to talk about
frameworks v8's motto is to make all the
JavaScript on the web fast but how many
of you use frameworks when you're when
you're starting a new website is the
first thing to do to find a new
framework usually it is people use react
angular ember polymer all of these
frameworks perform in different ways
they're often setting Dom objects
rapidly they might have a virtual Dom
implementation some of them use in a
mutable pattern where they create a new
object every time the object changes and
some of these AP is are designed to be
organ AMA canned really flexible and
easy to use but they turn under the hood
and it's things what we call polymorphic
functions which are bad for performance
so v8 historically has made these these
types of applications with frameworks
fast just by making all JavaScript fast
but next year we really want to dig down
into the specific usage patterns that
modern frameworks are using and optimize
for them in particular so we want to
reduce boot time of frameworks and we
want to turn the patterns that they all
use into really optimized code so this
is something that historically I think
we haven't spent much time looking at
but we're really excited to tackle this
and we've been working internally on
some advanced benchmarks which use real
websites and are able to load them
deterministically for our testing so
we'll be testing on the web on real
websites that of course are using
frameworks so this is what v8's been
working on and what we'll start we'll
keep working on but there's another half
to the equation and that's the code that
you guys as developers are writing
obviously you know to use efficient
algorithms and you know optimize the the
types of data types you use for
something but as Paul showed just
earlier and as you
seen at this entire conference there's
times when you're optimizing for
something like rail and you dig into
devtools and you see just the in the in
the flame graph JavaScript execution
taking up a massive amount of time and
sometimes you can't do less so the
question is how can you write that same
job javascript in a way that v8 can make
faster so I've shown a bit how the v8
engine is like a Formula One car it's
this incredibly powerful machinery that
allows you to move at blinding speeds
but it could be finicky sometimes and
more importantly over time its
performance characteristic and
performance affordances change as we
make evolve the engine and make changes
to it so I'd like to think about how
drivers in Formula One actually adapt to
changing machinery like an f1 car so one
of my favorite drivers is Ayrton Senna
the three-time world champion I actually
showed this deck to my team and got 40
emails back with different names that I
should mention instead but I'm gonna
talk about Ayrton Senna and I like to
imagine what if he was a JavaScript
developer you know how would he apply
this knowledge of adapting to a new car
to the browser and adapt to new versions
of v8 I'm going to give four tips that I
think are inspired by the sort of things
that drivers do the first tip is
understand how modern engines work now
Ayrton Senna doesn't have a mechanical
engineering degree he doesn't neither
should you read the source of v8 but
having at a high level a sense of what's
going on to the hood is really useful so
I'd like to share two things which are
fundamental enough that they're they're
actually shared architecture across all
of the JavaScript engines out there on
the web because really you want to write
code for everything so this includes
sunspider and Fire excuse me spider
monkey and Firefox javascriptcore and
Safari and chakra and edge look at this
code right here and it's pretty simple
I'm just creating a point class and Stan
Shih ating a new object three times over
well I mentioned that the v8 engine is
turning this dynamic code because
remember in JavaScript your objects can
have any number of properties and you
can change the shape of them at any time
under the hood v8 needs to turn that
into native machine code and it does
this in a way that you can imagine as
creating structs likessee likes trucks
for every object of C's so when it sees
this this point it infers as the
function is run or as this code is being
run it infers that that object is not
this dynamic dictionary but it's
actually a struct that looks something
like this it has two properties x and y
and they're both ends so when you create
these three points it knows that the
shape of the object you're creating is
the same and it optimizes for them so
these 33 points share the same object
under the hood thus we call that a
hidden class internally but in
JavaScript you can dynamically set
properties so if I modify my third point
to add a new attribute a new properties
e under the hood we have to go back we
notice this we still support it
obviously because it's valid JavaScript
but we have to undo that optimization
where we said all points will share the
same hidden class and we create a new
hidden class it looks something like
this it has an extra attribute Z and
this is really bad over time because we
have a bunch of other optimizations that
rely on there being the smallest number
of hidden class as possible here's a
quick example oh and let me just show
you how to fix this you should always
declare all of your properties in the
object constructor cuz v8 can look at
that and say AHA all points will share
these properties and I can optimize that
for that from the beginning so this is a
much more effective pattern I'll say
that one more time declare all
properties in object constructors don't
dynamically add or remove them here's an
example of why this is so important if
you have code like this say a function
twice this function just adds the input
together and returns it in JavaScript
you could throw an integer at this and
they would add them using math you could
throw a string at this and we
concatenate them you can throw a bunch
of different types at this
so when v8 sees this code here it's a
really hot for loop and it runs twice
ten thousand times 9999 of those times
the input to twice is in this case a
string excuse me an integer am I reading
that right a straight and it sees this
so it says AHA we're going to optimize
twice it's gonna be optimized for
integers hooray but then on the 8,000th
time you send an integer down the chute
and it says well we we tried to do this
special optimization but it broke so
we're going to have to diop to a slower
version so when I when I talk about
integers and strings what I really mean
is these hidden classes that I was
talking about before javascript doesn't
have types but we think of objects as
having particular shapes so it's
important that when you call a function
you use the same shape of arguments and
returns so that v8 can turn them into
highly optimized machine code versions
and consistently use them without d
optimizing now this is called mont
amorphous and that's just a fancy word
for now i mentioned two high-level parts
of the architecture these are unlikely
to change because they're so core to how
all modern JavaScript engines work but I
don't expect you and in fact it's an
anti-pattern to go memorize all of the
other heuristics that v8 and JSC and
spider monkey and choc are use because
they're changing so fast so in general
it's a bad idea to memorize rules and
it's a much better idea to use the tools
the suite of tools that chrome and
chromium provide you and others so for
example the v8 engine has a headless
version called d8 and if you use it you
can pass in certain flags and introspect
what's going on into the hood there's
some information out there on the web if
you want to do that a Paul and others
today all the pulse have been showing
you how to use dev tools and find flame
graphs where you can dig into actually
which functions are taking the most time
in fact in the CPU profile page
you can see those same D optimizations
that I was talking about a couple slides
earlier you could see them because
there's a little warning sign next to
the function in devtools on the cpu
profile page and there's a couple more
interesting tools out there if you
really want to dig into the nitty-gritty
something called ir hi jor which
actually shows for any javascript how we
turn it into native machine code but i
want to quickly give a brief demo of a
little tip that you can you can do today
probably without installing anything
extra so i mentioned d 8 which is the
headless version of no of v8 but i
actually don't have it installed and if
you're not a chromium developer you
probably don't have it installed either
but i do have knowed installed and node
embeds v8 in particular node has all of
the v8 options available as flags that
you can pass in a node when you execute
something now before I show you this
demo I want to make one important caveat
it's important to check the version of
node you're using because you want to be
on the same version of node as the one
in the browser so if i run this i can
actually see what version of v8's
included it's 4.6 that's the same as
chrome version 46 that's what I'm
running in the browser so check that the
versions are the same but with when i
have know'd installed i can pass in this
flag called and this works for d8 too
but you probably have note all ready
compassing a flag called trace d opt and
what this does is it executes a
JavaScript file and it logs out when
those those horrible d optimizations
that I talked about happen so I'm going
to run it on the code I showed in the
slide remember this is this twice
function which has a polymorphic
function call you pass in a string for a
while and then an integer if i run this
node and v8 d8 under the hood will tell
you that now this is a bunch of
low-level assembly but in particular
this first line here is really important
that's the one that's that we want to
look for it's actually grep for just the
word d opt this will print out when it
hits a particular function diab so you
can see here it says if you read it
across J
s function twice was d opted you can
imagine doing this on a bigger code a
bigger piece of code let's say something
that has four thousand lines and
Counting how many d ops happen this is a
good way to sort of figure out at a just
by squinting at it kind of how optimized
your code is or how much the room there
is how much room there is for
improvement let's take a second to run
12 okay so and no I can compare this to
another body of code or change the code
a bit and see if it D ops list but let's
apply the knowledge to this example so I
mentioned that polymorphic calls are bad
where you pass in two types into the
shame shame function so what if we
remove this if statement and just pass
in a I actually have it over here it's
called monomorphic so in this version we
do the same thing we have this really
hot loop but we're only passing in one
type of object one shape of object it's
a string and this time v8 can optimize
this and not hit those those d ups and
have to revert to a slower version you
can see here it runs without a problem
because there's no more d optimization
so this is just a quick tip start with
dev tools and the flame graph but if you
really want to look under the hood can
use node ok so that was to use tools
don't memorize rules what are some other
things you can do well definitely stay
up to date you can bet that Senna
understood when the car got a new brake
or when the engine was updated he was
talking with his engineers every day
well we have a really easy channel for
you to figure out what's going on in v8
under the hood and with developer facing
improvements it's the v8 blogspot at v8
project a blogspot com so read this and
see what's going on you can also read
the change log in our source tree
although this is is more fundamental
architectural changes and doesn't get
updated quite as frequently so the
blogspot is a good place to start and
I really want to impart that v8 is
constantly changing we're constantly
making improvements on it that are
driven by the types of code that we see
out there in the wild that you guys as
developers are writing and we can move
faster with this feedback loop by just
communicating more so if you've got code
and you're not sure why it's slow you
know you've you've looked at some of the
dev tools you've dug in and tried to
remove things that are obvious but it's
still slow file up up because in v8 and
all the modern JavaScript engines
reasonable code should run reasonably
fast engage with the team on
communication channels like
stackoverflow and in particular you can
send mail to v8 users at
googlegroups.com talk with us show us
new frameworks and libraries if you are
using the latest and greatest framework
and for whatever reason you're seeing a
long boot time or a bunch of D
optimizations when you shouldn't be show
us this framework show us this library
it helps us stay up to date with what
developers are actually using and
finally the biggest help is if you
contribute benchmarks of real-world apps
for us to test against because the way
we figure out if we're making good
performance changes to v8 is by running
benchmarks against it and we want those
benchmarks to be as close as possible to
relapse it's best if they actually are
real-world apps so send us stuff that
you use to test speed and we can work to
optimize it and finally to anti-patterns
I mentioned these earlier don't memorize
hard and fast rules there's some
information floating around on the web
about how v8 doesn't optimize try-catch
statements well it's true it's true
today but we're working actually we're
about to ship optimized versions a
try-catch so these characteristics
change and if you just used a rule that
you read one time on Twitter or on the
internet you'll miss it when VA finally
ships the improvement and actually in
Firefox they are we have shipped it so
these things are changing so fast you
can't rely on rules you've got to rely
on tooling to figure out what's betaine
and lastly don't use micro benchmarks to
make design decisions
when I talk about benchmarking and
profiling and running a performance
audit it's very important it's on your
actual app and not some slimmed down
version it doesn't help to write a four
line JavaScript statement and try to
figure out what way of iterating over an
array is fastest because I can guarantee
you that when that same array iteration
happens in a 50,000 line real world
production app a bunch of factors the
context will be different and you can't
guarantee that v8 will perform the same
so don't use micro benchmarks and lastly
to bring it full circle one of the
things that I was so struck by sin on
these f1 drivers is how closely they
work with the team that built the car
they constantly talked and the team
really was just as essential in winning
races as Senate was as a driver so when
you are Santa you're the developer you
are the driver and the v8 engineers are
this team of engineers working to make
the machinery that runs your code faster
so let's work together help us help you
reach that checkered flag thank you very
much you can contact me at set Thompson
at google com and send mail to v8 users
at googlegroups.com look forward to
hearing from you and sharing more about
the exciting things that VA it's working
on thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>