<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Instant-loading Offline-first (Progressive Web App Summit 2016) | Coder Coacher - Coaching Coders</title><meta content="Instant-loading Offline-first (Progressive Web App Summit 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Instant-loading Offline-first (Progressive Web App Summit 2016)</b></h2><h5 class="post__date">2016-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qDJAz3IIq18" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay
writes do I have everything plugged in
now I've got to click it's it okay so a
lot of times when people do these kind
of pools of an audience that they ask
people to raise her hand it's kind of
totally meaningless it's just to kind of
make sure you're all awake but I'm gonna
ask you a question and it's actually
going to it's going to decide the talk I
give
so here goes who here it has sort of
seen a talk about service workers before
or I can know roughly what they are okay
right so I'm not gonna do the intro talk
then so if you don't enjoy the talk that
I'm about to give it's actually your
fault you pick this so you should pick
the other one
sort of firstly I'm going to do a little
bit of a recap I built a little web app
the web app called emoji which you can
find at this URL it started just as a
website but I turned it into a
progressive web app and if you're
looking to do the same thing the first
thing you need to do is to integrate the
site with the operating system and the
UI and one of the ways of doing that is
in the head of the page you can use a
theme color and you know chrome will use
that to kind of change the color of the
location bar there so it's a small quick
win for integration but the main part is
this web app manifest so inside the
manifest it looks like this it's got
details on the name of the app the icon
all that sort of stuff and once you have
this a use will be able to add the site
to their home screen and they get the
icon and the name that you specified but
not only that when the user taps the
icon they get a splash screen this is
reasonably new in Chrome and this is
while the browser is booting up and
while your page is getting to first
render and so the icon the text there
and the background color and the purple
strip across the very top there that's
all taken from your manifest so you can
configure all of that and once that goes
away you get your site but without the
URL bar or desk so that's an option you
can have so here it just it feels like a
native app however this whole illusion
of native comes crashing down when
you're offline so this is pretty bad
right the user has launched our app
they've come back to our app they've
added it to the home screen that's how
much they liked it but we have failed
them to such an extent that the browser
has had to step in and defend us and
do this by blaming the user saying you
are offline
this is your fault if we're going to
compete with native this is this is like
an operating system level error message
like a full crash so this is not good
enough but things get worse so offline
isn't the worst thing that we face this
is I call it life I this is when your
phone says it has connectivity but it
doesn't really I think we've all
experienced this that the life I
experience is just that so that the
splash screen goes away when the the
site gets to its first render but with
life I that never happens that this is
worse than offline with offline you get
a quick answer the answer is no but it
is a quick answer here the user is just
left waiting you're forcing the user to
stare at this or give up and with every
passing second they hate the user
experience a little bit more and this is
why we should avoid treating online and
offline as these kind of binary states
is if we cater for online and we cater
for offline as separate things this
situation goes completely unsolved and
that's why the gold standard here is
offline first offline first solves these
problems with offline first we assume
offline and do as much as we can with
local content then try and get content
from the network and the more we get to
render without a connection the better
so you should think of the network as a
piece of progressive enhancement an
enhancement that might not be there and
here's how we did it so to begin with
register for a serviceworker and this
isn't some kind of magic manifest format
it's just JavaScript because we thought
why do we invent a whole new thing when
we've got like a room full of JavaScript
developers go world full of JavaScript
developers and loads of existing tooling
of course we should where I put this
register call here in a simple feature
to text because you know there are all
the browser's out there that don't
support serviceworker and this feature
detect prevents them from hurting
themselves and others around them anyway
in that script I'm just going to
register for this event this fetch event
song can have a debugger statement there
and when I do that now if i refresh the
page i hit a breakpoint and you get this
event object and it has a request
property and this is the request for the
page
you get things like the URL the headers
the type of request but you'll also get
one of these events for every request
that the page makes the CSS the
JavaScript of fonts that the images get
the event for these avatars even though
they're on another origin so it's not
just your own origin so by default
requests will go from the page to the
network and it's not a lot you can do
about it but once you introduce a
serviceworker
it controls pages and requests will go
through it but like over events on the
web you can prevent the default and do
your own thing and that's where things
get really interesting so let's use that
to go offline first so the first thing
we need is an application shell which is
just the the site but without the
messages in this case we want to serve
this and the CSS it requires and the
JavaScript requires before we even try a
network request before we even think
about going to the network because even
if you have a great network connection
serving this locally is it's going to be
faster and that's the offline first
approach so we need to cache this ahead
of time and the serviceworker has an
event for doing this it's the install
event this is fired when the browser
sees this version of the serviceworker
for the first time it's your opportunity
to go and you know fetch everything you
need to work and store it in a cache so
here I'm opening a cache called static
v1 and in there I'm adding the HTML for
the shell the CSS and the JavaScript and
it needs but these won't be used by
default service what could doesn't do
anything for you it kind of it waits to
be told what to do so over in the fetch
event I'm going to start by pausing the
URL so we can look at the component
parts of it and then if the request is
to the same origin and it's just slash
as interest it's the home page we're
gonna respond with the app shell from
the cache so calling respond with here
is is my indication saying like I'm
going to handle this request I'm going
to take over here and we pass in either
a response object or a promise that
resolves to a response caches match that
that returns a promise which resolves of
a response from the cache so it's
composed it together really well
otherwise we're going to try and respond
with cache content that matches the
current request so that's how we're
going to pick up the CSS and the
JavaScript when the the shell page
requests those if there's no match it's
going to resolve with undefined so as a
fallback if response is false II will
make a network request so this is the
offline first approach we're treating
the cache as our priority of our primary
source and then falling
back to the network whatever connection
the user has so using this pattern you
know the page goes to the serviceworker
and so sort just pulls the the shell
from the cache and the CSS and the
JavaScript it needs so that gives us our
shell render without going to the
network and now we're running JavaScript
on the page so we can splay even more
content
so with a mojo in this case I actually
went to index DB and pulled out the pass
messages the last messages the user saw
and render those on the page as well so
the user is looking at messages without
having to go to the network and then we
can go to the network for newer messages
if we can and we can show update content
and additional content so if this
network request fails it doesn't matter
because we're displaying content that's
a good offline experience if the network
is slow then that's maybe ok because
these might just be looking at past
messages and we've given them that so to
see the benefits of this let's pick the
original online-only
site against this new shiny offline
first version we must go to the compare
inator there was going to be sound there
now never mind
so first up the online experience go so
we get instant full content why is the
original lags behind having to fetch
stuff from the network or about the
offline experience well instead of
complete failure we have instant full
content all about life I instant full
content rather than the white screen of
death in fact with our progressive web
app the experience is the same no matter
what connection you have and that's the
offline first call the network only
matters when it comes to fetching new
content and this is how we compete with
native and compete with me if we can I
decided to pit the Mojo progressive web
app against a native app or Google
photos in this case because a well built
well refined native app and it's wanted
to launch them at the same time and see
what happened so pressed on at the same
time and it's really close this is
native versus web and in fact the Mojo
is about not 0.2 seconds slower to show
content that's 200 milliseconds not a
lot and that's compared to a well built
native app but that's starting from cold
the browser isn't in-memory if the user
who's used the browser
sometime recently and let's face it the
browser is a pretty popular app so it's
likely to be in memory this happens this
is a progressive web app beating a
native app to content render by almost
half a second now a few people said to
me is like well what about Android
instant apps what about those or my
answer to that is progressive web apps
are shippable today and they're not
Android only you can build one app
across thousands of devices operating
systems and browsers and it can beat a
native app to content render so
serviceworker is in the stable versions
of chrome firefox opera samsung browser
as well and it's coming to Microsoft
edge it's a high priority implementation
for them it's under consideration by
Apple but progressive enhancement means
you can use it today you just don't get
the the offline features in Safari but
if you use serviceworker and suddenly
your stuff has more features or becomes
faster in chrome and firefox and it does
in Safari then that will give Apple more
reason to implement serviceworker as web
developers you are in control of the
future of the web here but not enough
about the things that are support today
I'm going to talk about the future so
what I wanted to get onto the idea was
to build something like Wikipedia but a
Wikipedia that ran offline first so it's
something that was very much less of an
app because the Mojo is very much built
like a native app it looks like an AF
app but what is this stuff applicable to
sites like is it something that you'll
be able to use for your blog and with
what Wikipedia is a really a really good
demo of that so the idea was like when
you're online you're going to get a
server render because that's how
Wikipedia works but with a serviceworker
that we can we can start doing different
things so the first thing I did when I
built the Wikipedia demo is is to create
an app shell as well that's right so I
built an app shell for the article pages
it would load this generic shell without
the network and then the pages
JavaScript will handle the fetching of
the appropriate from thing from the
network so without serviceworker it was
kind of just a standard website but with
serviceworker adriatic rihanna texted it
to be more like a single page app so I
was dead excited about what I built
so I ran straight to the compare inator
to see how it you know everything
changed so I'm gonna set the normal
website here against my shiny
serviceworker version and I'm going to
load it over a throttled internet
connection
or as most of the world call it their
internet connection three two one go and
I watch this and I fought it got
slower like way slower here this again
first render is actually quite fast but
the content which some people would say
is the important bit is over to second
slow run free G now I had a mild panic
not as much as the panic I just had two
minutes ago but a mild panic that we'd
really messed up the serviceworker thing
but it wasn't serviceworker that was the
problem
see I was using this app shell and
letting JavaScript do the rest which is
fine if your design already sort of
dictates that you do something like this
but it wasn't the case here
I'd reacted a site into a single page
app and single page apps are incredibly
slow and this is why you'll see me moan
about frameworks all the time on Twitter
here's what a website does to get to
first render HTML starts downloading CSS
downloads and now we start rendering
content and we render more as more HTML
downloads we might download JavaScript
as well but it should be async so it's
not gonna block render contrast this too
soon a single page apps web apps where
HTML downloads usually instantly because
it's normally really small CSS downloads
and then we get our first render
assuming the JavaScript isn't render
blocking widget off the news but let's
be kind anyway this is just a basic UI
render no content and then JavaScript
downloads it parses and executes and
then it goes off to fetch the content
and once it has all of the content it
adds it to the page and we get to render
and this is this is how slow happens you
know and in my case I wasn't losing too
much time on the CSS the HTML and the
JavaScript download because they were
all cached in the serviceworker but it's
the problem here is at the bottom the
JavaScript has to download all the
content before showing any of it the
more I think about load time performance
the lor realize it's not about the size
of your CSS the size of your JavaScript
it all comes down to being progressive
and this is related to progressive
enhancement but not quite the same I
mean show them what you've got like
all the time you're low
the user is watching and waiting don't
make them wait until you have everything
before showing them anything prioritize
the first render the first interaction
show the use of what you've got as you
get it and that's where I was failing I
was hoarding all the content and only
showing it once I had all of it in
retrospect it seems kind of stupid to
cram a site into this single page app
model but for me this was my app cache
hangover
you see app cache nearly nearly lets you
use the page shell pan but not quite but
it lets you so close like you can almost
smell it but it just sort of baths you
away at the very last moment so once app
cache was out of the way I was like
really app cache is gone does that mean
I can have all of the page shells I want
and nothing is going to stop me but I
didn't stop to think that the best
answer wasn't the one the app cache
nearly let me have it was the thing that
it didn't let me anywhere near what I
wanted was streaming and with streaming
you get to finish the is a simulation
here and you can see this sort of final
render is somewhat quicker than the non
streaming version but the important bit
is that a render happens ages beforehand
than in a non streaming model so this is
the full HTML spec loading here over a
throttle internet connection right it's
a free megabyte document it's still
downloading but it gets on screen after
only 20 K is fetched which is great
that's streaming but for a long time we
had no access to streams in JavaScript
but that is all starting to change so we
designed the fetch API alongside
serviceworker mostly because we needed a
lower level representation of requests
and responses but it was also a good
opportunity to kind of to look at xhr
and make something that's a bit easier
to use because xhr is almost 18 years
old I don't want to be using xhr when
it's legal to drink you know it's bad
enough when it's sober so this is this
is fetch it returns a promise for a
response there it is
but that only resolves when we've
received headers we haven't received the
body yet you have to choose how you want
to read it and that gives you a promise
as well and then you get your data at
Jason in this case this compress is
really nicely using arrow functions and
even better using async functions so
that the keyword await there it pauses
execution of the function until the
promise resolves
and it's pausing an async way so it's
not blocking the Fred it's not blocking
interaction I think so edge has this in
their preview bills I think we've got
stuffing in canary as well but they will
let you use it in other browsers as well
and it produces much easier to read code
I think it's great and so if you haven't
encountered it before you can pretend
that async code is is sync it makes it a
lot easier to read anyway you don't have
to read the responses Jason we added a
lot of different methods for common
types of you'd want to read we added
these for two reasons like there are
nice convenience methods but we wanted
to ship fetch before streams were ready
so we needed a waiter to read the body
but we did reserve response stop body
first streams when they when they landed
and they landed in chrome and opera
around a year ago and they've been
actively developed by Firefox edge and
even Safari as well they're working on
them here's how you use them so you
fetch something say the HTML spec we're
going to fetch it as a stream and we
called get reader so I'm saying I want
to open the stream I want to get a lock
on the stream and then we can read some
of the data read returns a promise
result is an object result done is true
when there's nothing left in the stream
so if result done isn't true result
value is a chunk of the data and that's
a ewtn's eight array of bytes that
you've received it's not the whole
response it's just the first part of it
and when we want the next part we can
call read again so if we wanted to get
the length of a whole response we could
do this you know we gonna have a
variable there to keep a running total
and then we're gonna create a loop
I'm just gonna keep calling read until
result done is false and in there get
the value add the length to the total
and then log it out and that's it done
we should be able to see that working I
don't know I feels really risky doing
live demos after what happened before
but let's give it a go let's see here we
go so this is let's see if I can make
this bit bigger wrong window maybe I
can't make it bigger where's my mouse
pointer there we go so if we refresh the
page here we can see the sort of log at
the bottom there and it's reading the
HTML stuff and we can see that the we're
inspecting parts of the response here
but we're not having to keep it all in
memory and you see the chunks are of
different sizes so that's something you
have to deal with that kind of around
about 30
but not always so here we're reading
that the full-size it's 8 megabytes I
think the the uncompressed size right
down at the bottom there but we don't
have to have the whole thing in memory
we're just sort of reading bits and then
there can be garbage collected straight
away so a more practical use of
something like this would be to search a
stream for a given string so say we
wanted to search the HTML spec for the
word horse here's how we do so this is
fairly a simple way of doing it we're
kind of fetching it reading it as all as
text and then searching but this means
we have to load that full 8 megabyte
document into memory and then search
across it we can do better with streams
instead of fetching all the text loop
over the stream as before but the
problem here is that result dot value is
in the array of bytes
whereas we need a string to do the
matching in future this will be really
easy you'll just be able to pipe the
stream through like a text decoder and
that will kind of read in the bytes
convert it to text and pass it out the
other end
but transform streams haven't been fully
specs yet there will come coming soon
but at the moment you can do things a
little bit manually with with text
decoder so here we fetch get a reader
but also create a text decoder and then
we'll loop through the stream as we did
before but on result dot value I'm going
to call decoder decode and that'll take
the byte and give us a string back it
decodes it assuming utf-8 there are
other options as well the stream true
there that's that's actually really
important that changes how things work
so it's going to show you that so here's
a simple demo of so this is the the code
you saw before
I've got three chunks of text there and
for each one I'm going to decode each
part and if I run that everything is
broken but if I add that stream option
in
and run things again right we get the
poo emoji the toilet emoji in an
exclamation mark so the reason this
happens it's a emoji of 4 bytes long in
utf-8
so we've stream true it tells it that
you know it should it might be receiving
more bytes later it's part of the same
message so we're stream true it receives
the first three bytes and it goes this
is part of a character this is not the
whole thing so it just returns an empty
string and it holds those three bytes
the next time we call it it adds the
next three bytes on so it adds the one
six nine the first byte and it goes ah
right I've got enough now to show the
the pooh emoji so I'm gonna pass that
back and I'm gonna hold onto the last
two bytes and then we add the next chunk
on the next three bytes and it goes ah
right I've now got enough to it for the
toilet emoji send that back and also 33
at the end there is the character code
for an exclamation mark so you can send
that back as well so now we can check
these chunks as they come along now
we've got them as text to see if it
contains the word horse and not only
that we can also cancel a download when
we find it and this is really efficient
so if there's an 8 megabyte document but
if you find a match in the first 20k
that's great we can stop the download
and save all that bandwidth but there is
actually a bug with this implementation
it works fine if our chunks are like my
lovey and then horse running through the
field oh there's the maps in the second
chunk great but what if the chunks are a
my lovely huh no match running through
the field no match we miss it because
the the the match was across to chunk
boundaries so when you're doing things
like searching or filtering streams need
to defend against this and the way we do
it is by keeping a buffer that is the
size of the thing we're looking for -1
so in our case horse 5 characters we
need a buffer of 4 so that means that we
you know you could see my lovely H fine
and then we keep those last 4 characters
and add them onto the next chunk and
then we see horse so the code for that
my slides have gone off again isn't that
great
whatever you did oh it's back excellent
so the code for that same as before but
we create a buffer
heart rate is going so fast so we're
creating a buffer we're going to loop
through the stream we're going to decode
it add it onto the buffer and if it
includes horse great and then we you
know cancel otherwise we reduce the
buffer down to those last four
characters so now we're searching a
large documents we're keeping the memory
usage down and we can stop the download
early so I'll show you an example of
that as well so we're just going to run
this on on the HTML spec it's a slightly
longer piece of code because I'm going
to keep a larger buffer so I can show
the search term so with horse which I
didn't expect to be in the HTML spec but
if we run it through is a match and it's
because Tommy forsen is one of the
contributors who needs got a horse in
his name let's run a different example
someone give you an example of something
that probably won't be in the spec but
might who do that means you are so much
more polite than they meet up in London
that I gave this same talk to very
recently because when I asked for a
suggestion there was actually a lot of
silence for and then so on at the back
of the audience to sort of stood up and
pointed at me when okay I'm gonna
pretend that's not a heckle and I'm
going to do that nervously okay this
would be fine
obviously you're not expecting anything
to happen but as it's so sighs a wall
doesn't match probably it's because it's
a canvas region okay a canvas get
region okay okay where are my slides so
oh yeah some some developers in India
and where connectivity is quite poor and
they were sending this a bit of blob of
JSON down for some search results and
they wanted to detect 2g versus free G
so the idea was like oh if they're on 2g
we're gonna send fewer results because
they'll you know get on screen faster
you'll get a faster render but detecting
connectivity is really unreliable
especially in India where you can you
can have free G or a 4G packets but it
will be the speed of two G so it's much
better to do something else like serve
something like this where it's not Jason
but every line is adjacent object and
this is something you can stream then
you can pass each line
separately as Jason and deal with the
data as it arrives and that means you
can deal with the first was all
before dealing with the rest and there's
a real it's a huge performance benefit
to this so here I've got an example of
that I'm going to throttle the network
down to 2g there we go so a regular
fetch of this Jason will take well it
depends on the connectivity but it will
take around about okay so it's all over
at five seconds and with regular Jason
it has to download the whole thing
before it gives you any of it so the
first bit of Jason arrives after five
seconds and so just a second but with a
streaming solution it getting the last
bit of date is going to take roughly the
same amount of time yes so sort of five
seconds but we get that first bit after
three hundred and sixty-four
milliseconds so there's a huge benefit
here for slower connections we can start
showing results before we've received
the entire the entire file so you might
be wondering how I can use this to speed
up my Wikipedia demo well I can't
because although you can use fetch to
read a response and little chunks
JavaScript had no access to the
streaming HTML parser it might look like
here I'm sort of happily adding HTML
into an element but plus equals is the
same as getting then setting so you're
asking the browser's to serialize the
Dom and then you're asking it to pass
some more Dom like you've added some
more to the end this is a performance
disaster don't do this because the
elements at the start of your string get
created like hundreds of times I'm
hoping we can get like a streaming HTML
parser document fragment or something in
future but it's not there yet but in
chrome beta and Chrome Canary we have we
can create our own readable streams now
this is something that's also being
developed in in Urfa browsers too it
looks like this you just pass in an
object with these methods and say we
wanted to create a stream of random
numbers so we kind of store in interval
I'll show you why in a moment you know
create a stream and I'm going to pass in
a start method this is called
straightaway so in here I'm going to set
up an interval that pushes a random
number to the stream every second and
the control has other methods as well
such as like close to signal the end of
the stream but we're not using that here
I'm also going to add a council method
this is when the the user cancels the
stream after they're done reading it you
get this council method so I can use
this to abort the the interval and so
this is just like fetch streams now as I
show you an example of that running I
think is this one so yeah
here we go so this is just that the code
you saw before but I'm going to read the
value three times and then cancel and
then try and read it again but what
we'll see if the page loads which would
be great you can see this log down at
the bottom here it's getting those
numbers it gets free of them but then
it's had enough of it so this is a this
is a push based stream because we're
pushing data into it so if no one's
reading from the stream those numbers
are gonna build up and up in memory and
eventually you'll get memory problems
the opposite of this is a pull stream
the pull method is called when a reader
is waiting on a value and we don't have
anything left in the buffer so when Paul
is called I'm gonna return a promise
that waits for a second and then pushes
the the random number on and this is
much better because you're not
generating random numbers if nothing's
waiting for them your streams can be of
anything that we fetch we saw there a UN
state array of bytes here it's numbers
it can also be objects this is one
interface for all of those things the
designers of web streams they talked a
lot too to the node folks because they
have they've had like four three or four
versions of streams and they've they've
made mistakes along the way so it's a
really good source of like well what did
you do wrong so we can avoid making the
same mistakes so you might be wondering
how I can use this to speed up my
Wikipedia demo well I can't because you
know not just using streams on their own
anyway because things get much more
interesting when they're combined with a
Service Worker
so this this already streams finally
just as it automatically the browser
connects the dots same with this the
browser will stream it from disk from
the cache but in chrome beta and Chrome
Canary you can create responses from
streams you can create your own streams
and then stream those into the browser
so my fetch event gonna create an
encoder this is the opposite of before
it takes a string and turns it into
bytes because response streams must be
bytes we saw that before then I'm gonna
create a stream with a pull method which
waits a second and then pushes a
paragraph onto the page so again see
I've got encoded item code to turn it
into into bytes and then I create a
response give it the stream and then say
that this is HTML give it the HTML
header so if we run that it should be
here
we can see random numbers appearing on a
one-second interval so but as far as the
browser is concerned it is just
receiving text very slowly and you can
see that the spinner at the top there
it's as far as the browsers where it is
just loading a page very slowly so you
might be wondering how I can use this to
speed up my Wikipedia demo what I can I
actually can this time before we were
piping content you know straight into
the the browser streaming HTML parser
and that is the key to it all here you
know this is what app cache wouldn't let
us anywhere near so instead of turning
like a perfectly capable server ended
site into a JavaScript driven single
page web app I can use serviceworker
more like my server so here's what I did
for it for a wiki offline I fetched the
article header the body and the footer
so the header and the footer are coming
from the cache the body is coming from
the network but it will fall back to the
something in the cache if it fails then
I combined those streams together into
one single stream and combined as a
function I wrote it's about ten lines
it's kind of a manual process right now
it's like creates a single stream that
reads the first stream into it then the
second then the third and so on until
it's run out and then it ends and then
we create a new response using that
stream so one response made of multiple
different parts and places just like you
do on the server you get some stuff from
a database some stuff from a template
etc etc treating your serviceworker to a
server Maps really well to content sites
like blogs and Wikipedia which are a
server driven you see the result of this
for one final time we got back to the
compare an 800 this time this time great
you'd normally be so bored of that sound
by now but that was the first time so
here's how it compares so on the Left
the app shell render and on the right to
the streaming service worker both of a
free G so launched them at the same time
so the difference is absolutely massive
but the app shell was a performance
progression anyway so let's compare it
to the original server render so we get
the benefit of that quick cached first
render which happens without the network
but that allows us to get Network stuff
on screen quicker because there's less
to fetch we've already sent the header
and stuff down
I'll play it again so the first render
is almost like a second faster but
content render is half a second faster
even though it's just coming from the
network the same network
in each example so needless to say I'm
quite excited about streams but that
doesn't mean the app shell model is bad
you saw it being used to a mojo earlier
and the result was a progressive web app
which launched faster than the native
app but a streaming solution will be
faster and easier for you if you use
server rendering say like switching to
an app shell model here could be a lot
of work and could land you in for
performance regression if you're already
a single page web app you have that
performance regression already so knock
yourselves out
carry on doing that consider streams if
your initial content may come from the
network the benefit of streams is being
able to build content from multiple
sources if your initial content comes
from the cache or a database entirely
then you don't have so much to gain from
streams so and that was the case with a
mojo I was getting all the first render
content from caches and databases so
streaming wasn't a whole lot of use
there consider streams if a partial
content render is valuable to you and
that I think is in most cases but
especially written content so if you're
looking to build something like an
offline first new sites like The
Guardian or a shop like Amazon or your
blog streams could be the faster and
easier way to do it and no lining in
chrome in the next few weeks and they're
being actively developed in Firefox and
edge if you want to know more I've
written an article about streams of
gushing praise on my plug and I suppose
I do some silly stuff as well like kind
of transcode and an MPEG to a gif on the
fly or or transform content actually did
this with the I run a transform stream
on the Wikipedia page for cloud
computing this is it but every time it
sees the word cloud is replacing it with
but which is great to read where is that
I've got a favorite bit in here see if I
can find it there it is Oracle announced
the Oracle but while aspects of the
Oracle bus are still in development this
bus offering is placed I love the term
but offering that's great I don't know
so serviceworker is this is Bruce
Lawson's logo for serviceworker I like
it it kind of makes me feel slightly
drunk it's great
you can polyfill new Network features
with it you can become a faster Network
resilient and more Network resilient
we've gone through a lot of stuff here
at lightning speed and that Monnett has
gone off and I've got one slide left so
let's rush there's also a free Udacity
course where you can take a website from
online only to offline first to use it
of a series of examples covers the app
shell modeling indexdb and with that
before everything just sets on fire and
breaks thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>