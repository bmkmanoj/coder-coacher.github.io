<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>iOS Development with WebRTC (Kranky Geek WebRTC 2016) | Coder Coacher - Coaching Coders</title><meta content="iOS Development with WebRTC (Kranky Geek WebRTC 2016) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>iOS Development with WebRTC (Kranky Geek WebRTC 2016)</b></h2><h5 class="post__date">2016-11-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_64EiziqbuE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">
ARIK HALPERIN: Hello,
I'm Arik Halperin,
and I'm going to
talk about how to do
iOS development with WebRTC.
So first we look at how
to build an iOS WebRTC
app using the AppRTC pod.
And then we'll talk about
building your own pod
and compiling your
own code for WebRTC.
And we will talk about
PushKIt and CallKit, which
are frameworks from Apple,
which are meant to help
in building VoIP applications.
So what we will
see is how to build
an application, which is similar
to the example code in WebRTC.

It connects to an AppRTC server.
AppRTC is an open source
project from Google
that you can find on GitHub.
And our application will
connect to that server
and be able to make video
chat with another client also
connected to the server.
So about the AppRTC pod.
It's listed on CocoaPods, the
CocoaPods.org/pods/AppRTC.
And it also has a
GitHub repository.
It's on ISBX/AppRTC-iOS.

It contains the podspec, header
files, and a demo application.
And the code there, for WebRTC,
is updated from January 2016.
It's a pristine I/O
compilation of WebRTC.
So how do we use the pod?
We create the project.
For example, we'll
call it KrankyGeekDemo
And in the project
directory, from the console,
we run a pod install.

And it will install
the AppRTC pod for us.
So what we get is the workspace
where in the upper part,
you can see the files
for the AppRTC geek demo.
And we also have a pods
project containing the code
from AppRTC pod, which
actually has two dependencies.
One is the libjingle peer
connection from pristine IO.
And the second one is
the SocketRocket library.
And this is the pod itself.
What's important
to look at here is
first you can see the way the
GitHub path for the AppRTC pod.
And you can also see
the frameworks that
are needed in order to
build an application using
that pod, the iOS frameworks,
and the native libraries
that you will compile with, and
the two dependencies bridging
your peer connection,
and SocketRocket.
So in order to make
the code, these
are the key ingredients
in the application.
In our app delegate,
we will have
to initialize the SSL library
that comes with WebRTC
and then initialize it,
the necessary libraries
used in order to be able to talk
to our server in a secure way.
So in initialization, we
call the initialize SSL,
and the point termination
then initializes SSL.
When we start the
application, what we will see
is the domain view where we
will input the room number
on which we want to connect.
When we press start call,
we will start connecting
and then our code, what we will
do is create a Jingle client.
They are the upclient.
This is an object that knows
how to talk to an AppRTC server.
It's part of WebRTC code.
And we will tell it to
connect to our room.
The client will know
that we its delegates
have to call back with
methods on the events
and the notifications.
So a little bit on the
anatomy of application.
We'll have a
CallView Controller,
and that CallView
Controller will
have a video view
with two subviews,
one for the remote video and the
other one for the local video.
And this is the process
that will happen.
Our ViewController will ask
they ARDAppClient to connect
to the AppRTC server.
It will send the
connect request.
And when it does that, it
will also start the camera.
And we will get a
callback from it
that the a local
video track exists.
After it says connected,
video will start streaming
from the network, and it will
give us another call back
about the remote video track.
And what we will do--
so for the camera,
we will-- WebRTC
will open the camera
and create an RTC
video source for it.
And then it will use that one
to create a local video track
and give us the callback so
we can store it and point it
to our local video
view for rendering.
And this way, the camera image
will show on our local view.
For the remote, it's similar.
An RTC video source will be
created for the remote video.
A remote video track will
also be created by WebRTC.
And we'll get the call
back from the app client.
And we will attach
it to our view
and show the remote side video.

So this is how it's
done in code It
did receive local video
track is where we attached
the local view to
the video track,
to the camera video track,
and did receive remote video
track is where we will attach
the view to the remote video
track.
And more on video increase
signal tones session right
after me.
So hanging up will just call
the client's disconnect function
and clean up the code--
clean up after ourselves.
So this is how to
use the AppRTC pod.
But what if you want
to use your own pod?
And there are several reasons
you may want to do that.
So the first, you want to use
the latest code from WebRTC.

Second, you want to
make changes to WebRTC
and customize some stuff.
For example, later we'll
talk about CallKit.
In order to work with CallKit,
you can't use WebRTC as is.
You have to make some changes
that are not still there
in the code.
And so you will want
to customize WebRTC.
And maybe you want to
use a different server.
You don't want to
use AppRTC server.
You have your own server,
your own protocol,
you want to work
in a different way.
So you want to
make your own pod.

So what I did was I took AppRTC
from GitHub and I cloned it.
And then cloned it under
ArikHalperin/AppRTC-iOS.

And then I changed it to
use WebRTC from last month.
It was the latest code
when I prepared the pod.
It's not listed in
CocoaPods, so in my pod file,
I will put the GitHub path
instead of just putting
the name of my pod, WebRTC.

And then I built
the WebRTC code.
So how did I do that?
You have the link.
It's under
WebRTC.org/native-code/iOS,
where you can get an explanation
on how to build WebRTC for iOS.
So first you get
the prerequisites,
which is to install depot_tools
and get the latest xcode.
And then you fetch the
code using fetch command.
It's part of the depot_tools.
And you specify where
you want WebRTC iOS.
And you run gclient
sync, and that's it.
You have the code for
WebRTC on your computer.
It's important to disable
spotlight indexing
on the directory
where you get it
because later when you build,
it takes a long time to build.
And if you disable spotlight,
it will be a little faster.

So for each architecture I
built for ARM32 and ARM64.
I didn't bother
with the simulator.
Main reason was simulator
does not have a camera,
so it was not interesting.
So for each architecture,
I built WebRTC.
And what happens when
you build WebRTC?
WebRTC is made of many models.
And each model has
its own static file.
And it's a nightmare to compile
all of them in an application.
So I took them, and I put
them all in one big file.
And I used libtool
in order to do that.
And for the release version, I
also stripped all the symbols,
and this reduced the
file by a factor of 10.

And using lipo, I took
all the architectures
and made one file that I
can use with the Xcode.

Then I copied all the relevant
header files and compiled
library into my pod.

And the scripts for-- that
can show you how to build
are in the scripts directory
in my GitHub repository.
So if you want to look and
see how this magic is done,
you can find it there.

So what we see until now?
We look at how to build an
iOS WebRTC application using
the AppRTC pod.
And then we talked about
how to build your own pod
and compile WebRTC from scratch.
And next, we're going
to talk about PushKit.

Why do we need PushKit,
and what is it?
In order to get an incoming
call with a VoIP app,
you have to be connected
to your server.
But the problem with being
connected to a server
is that you have to listen
all the time to things
that come from your server.
And the main issue with this
is it drains your battery.
You use battery all the
time, even if you do nothing.
And the second problem,
which is harder
to-- which you can't overcome
is that this, on iOS,
was being done using a
thing called VoIP socket.
It was deprecated in
iOS 9, and in iOS 10,
it no longer works at all.
And Apple introduced
the VoIP push in iOS 8.
So how does VoIP push work?
We have two clients here.
And both clients, when they
start working, what they do
is they get a token from
the operating system, which
identifies them in the APNS,
Apple's Push Notification
Service.
They take this token, and
they tell the server, listen,
I'm client X, and
this is my token.
So from now on, when the server
wants to talk to client X,
it knows which token
to use in APNS.
And Client1 wants to send
the message to Client2
and wants to answer a call.
So it sends a message to
the server-- call Client2.
The server looks up Client2 and
finds its token and tells APNS,
I want you to send a push
with an incoming call
to the client identified
by this token.
APNS looks at the
token and says,
OK, I know this client is
located at this IP and this pod
and sends the push
to the client.
And the client gets
the push, wakes up,
and can answer the call.
So if you want to
use PushKit, you
have to prepare your
application for that.
In Xcode first of all, you need
to have the background mode
called the VoIP notifications.
And the in Apple--
as usual with Apple,
everything is a
bit of a headache.
You have to create an iOS
VoIP Services Certificate
and compile the application
with that certificate.

A little code in your app
delegate, you import PushKit.
And when your application
finishes launches,
you do VoIP registration.
And this is done by creating
a PKPushRegistry object
and telling it that the desired
push type we are going to use
is PushTypeVoIP.
VoIP.
And the main advantage
of PushTypeVoIP
is it has a very high
priority on APNS.
And so you will get it
in the minimal latency
and as fast as possible.
So handling credentials update.
Credentials update is where
there iOS updates your token.
So when your application
starts, or whenever
iOS changes the token,
you will get the callback
in your app delegate, which
is didUpdatePushCredentials.
And when you get
that call back, you
can take the token
out of the credentials
and update yourself
and say to the server,
now my token is this.

And when you get an
incoming push notification,
you will get the
didReceiveIncomi
ngPushWithPayload, and there
you will get the PKPushPayload.
And the PKPushPayload
is a special field,
which is the UUID, and it
identifies the push transaction
in the system, and we'll soon
see, when I talk about CallKit,
how to use that.
So CallKit.

What is CallKit?
Apple are saying that the
CallKit is the framework that's
going to elevate your
search party applica-- VoIP
applications to a
first party experience.
And what does that mean?
So first it means
receiving and making
a call on your
VoIP service appear
like any other native call.

You can start your VoIP
calls from contacts, recents,
or any other way native
calls are started.
The incoming call screen will
now look like a native call.
Anyone of you who has the
VoIP application, which
updated to VoIP
call, probably notice
that when you get a call, you
no longer get the usual screen,
but you get the native quotes.
And I was very surprised when
Skype did that for me, so.

The call screen also
looks like a native call.
And here, you have an example.
You can see the incoming call.
And the difference between
the incoming call screen
here and the usual
incoming call screen
is that here I have my
service name on the screen
instead of saying, for
example, mobile or whatever.
And the call screen also
has a small difference.
There is an icon for my
application with my service
name that I can press and change
the UI to my application UI.
So CallKit is built
of two main classes.
One is the CXProvider, and
one is the CXCallController.
And what are they used for?
So let's look at them,
one versus the other.
CXProvider is used to receive
out of band notifications.
These are not user actions.
For example, an incoming call.
CXCallController,
it's used for requests
from your application, which
are local user actions.
And these are internal
events like start call.
It interplays also with our
providers in the system.
For example, if I'm doing a
call with the usual mobile
telephony, and I want
to start a VoIP call,
I can ask CXCallController
to start my call,
and it will hold the
current telephony call
and allow for my
call to take place.
Example uses, we use
CXProvider to report
incoming calls,
outgoing call connected,
call ended on the remote side.
CXCallController we
need to use to request
starting an outgoing
call, answering a call,
or ending a call.
So CXProvider sends messages
to the system via an object
message called CXCallUpdate.
And it receives
the notifications
from the systems with an
object called CXAction.
CXCallController
sends a notification
to the system via
CXTransactions.

Let's look at some use cases.
So we get an incoming
call via push.
Our incoming call
handler is called.
We say to CXProvider,
CXCallUpdate incoming call.
And notifies the
system, and the systems
shows the native
incoming call screen.
When the user
answers, the system
notifies the CXProvider
with the CXAnswerAction,
which notifies our handler.
And we now notify
our VoIP server
that the user answered the call.
Ending a call,
similarly, but this time
it's a CXEndCallAction.

So we set CallKit
in our application.
And did it finish
launching with options?
First thing we do is we
create a configuration object
for our VoIP provider.
And we create a CXProvider
with that configuration.
Configuration contains our name
and several other parameters.
And we say to the provider
that our app delegate
is the delegate for a call
back from this provider.
And we also create
the call controller.
So if you receive a call
from push, first thing we do
is we extract the
UUID from the push
and we use that UUID to save
the call in our database.
We will identify it by the UUID.
And we will create the
CXCallUpdate object
and report to the system
via-- to CXProvider
via report new incoming
with UUID provide
that the call is incoming.
And we give it the UUID.
And we may get an error.
For example, if the user sets
the device to do not disturb,
then the call will
not go forward
and CallKit will
return an error to us.
But if everything works
well, a call link to Apple,
we need to allocate an audio
controller object for the call.
But this is something you
don't do when you use WebRTC.
As Chris will
explain later, WebRTC
handles its own audio session.
And doing this will
create unexpected results.
And contrary to what
Apple is saying,
don't mess with the audio
at all when you use CallKit.

So when the user
answers the call,
we first say the
action is fulfilled.
And then we notify our
server that the user
answered the call.

And when CallKit starts
audio, according to Apple,
we need to start the
audio on the device.
And again, since we are
using WebRTC, don't do that.

Ending calls, so the user
presses the hangup button.
And we need to tell our
server that the call has ended
and fulfill the action.
Starting a call, for example,
I won't cover the case
where it happens from
recents and other places.
But let's talk about when
it's done from our UI.
We call the call controller,
and we give it a CXTransaction,
which means start to call.
The system accepts that
CXTransaction is if it's
possible to start the call.
Or maybe there was a telephony
call that was going on,
and the system needed
to hold that call.
After it holds the call, it will
give us the CXStartCallAction.
And [INAUDIBLE] start call
handler will notify our server
that we are starting a call.
So this is how
it's done in code.
We create a
CXStartCallAction, and then we
request the transaction
from the call controller.
And when the system authorizes
the starting of the call,
we will get the
performStartCallAction
where we will tell our
server that the call started
and fulfilled the
action for CallKit.
So if you want to
read more on CallKit,
you can find it on
Apple's developer site.
There's a very nice presentation
there from WWDC 2016.
[MUSIC PLAYING]
</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>