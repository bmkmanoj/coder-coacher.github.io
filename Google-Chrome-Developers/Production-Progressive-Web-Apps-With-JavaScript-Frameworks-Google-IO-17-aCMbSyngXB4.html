<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Production Progressive Web Apps With JavaScript Frameworks (Google I/O '17) | Coder Coacher - Coaching Coders</title><meta content="Production Progressive Web Apps With JavaScript Frameworks (Google I/O '17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Google-Chrome-Developers/">Google Chrome Developers</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Production Progressive Web Apps With JavaScript Frameworks (Google I/O '17)</b></h2><h5 class="post__date">2017-05-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aCMbSyngXB4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello i/o last year I was up on the
stage talking about the potential for
building progressive web apps with
frameworks the promise of being able to
use some of the world's best DX to ship
some of the best you ExxonMobil in the
last year we've seen amounts of promise
here we've seen many large global brands
start to ship progressive web apps as
part of their default mobile experience
and many others starting to experiment
with this stuff too so today I'm going
to talk about some of the technical
insights and the journeys that many of
these large companies took to ship these
experiences using frameworks now before
we get started I've got a little bit of
a confession right before i/o my wife
Ellie had to tell me to stop playing
video games and start working on my i/o
slides so I did stop playing video games
and I did work on my slides I built my
i/o deck as the video game and my main
character is my wife Ellie I'm going to
get in so much trouble for this let's
get started today we're gonna play
progressive web gaps so let's get
started we go in our first level we
start our quest to building a fast
progressive web app using a framework
and we run into Alex Russell who says
use a job as your framework that gives
you Headroom on mobile ignore the fact
that he's shooting us in the face with
an arrow what Alex means here is that
you need to understand the cost of your
abstractions especially on low-end
devices you see on desktop the time it
takes to parse and compile JavaScript is
often several times faster than it is on
mobile where it can sometimes take four
or five times as much time in order to
process this is one of the reasons why
we see a lot of the web apps being built
today using frameworks on mobile taking
about fifteen or sixteen seconds to get
interactive unless you're keeping an eye
on how to optimize that now in order to
help you get fast and stay fast your
framework needs to give you the best
possible Headroom to
seed think of it like a budget if you're
trying to get interactive in five
seconds you want to make sure that you
have enough budget for your application
code and that your framework isn't
taking up that entire budget right as if
you're going to start slow you're very
likely to stay there now thankfully over
the last year we've seen a huge increase
in the number of good options for
starting to build progressive web apps
on mobile that have low parse and
compile times in addition to polymer 2.0
joins us with pre-act view Jas and
svelte Jas these are all excellent
options and I'm starting to see an
increasing number of companies consider
them now over the last year one of the
main pieces of feedback that I've got
from large teams that are building you
know used building with frameworks and
trying to ship progressive web apps is
that they wish they had more reference
material they wish they had better demo
apps that showed them how to properly
hold a framework so that would perform
well on mobile and so I got together
with a number of different framework
authors and today we're happy to
announce a new project
that's the successor to do MVC we call
it hn PWA
hacker news readers as progressive web
apps this is a new project that has an
entire suite of progressive web app
references implemented using some of the
best practices today's frameworks and in
case you're wondering HN PWA com is a
PWA itself now our suite of hey Chen PWA
apps includes apps built using pre acts
polymer view angular reacts lots of
other frameworks the pre acts polymer
view ones are interactive in less than
three seconds even on emerging market
connections and the polymer one is using
the purple pattern which we'll talk
about later and they happen to be hosted
on firebase functions using h2 server
push as is the pre act one it's using HD
server push to the way that we validate
these implementations is using
lighthouse in fact we'll link out to a
lighthouse report for every single
implementation and we use web page test
to test these apps out on real devices
showing you how long they take to get
interactive so check out hn PWA com I
hope you'll find it useful
now the first framework that we're going
to talk about today is react react has
made a painless to create interactive
UIs and build components that manage
their own State and just last week react
crossed a million NPM downloads a week a
huge milestone for them and it's being
used in many PW ways the first one we're
going to talk about is Twitter light now
some folks in our team Alex Russell and
myself we had the honor of getting to
work with Twitter on some of their
pieces of Twitter light and I thought
I'd talk about some of their journey
tutor light took their old mobile
website and turn it into a rewrote it to
be a PWA and they saw massive
improvements in both time to
interactivity the number of tweets sent
they saw 76% increase in tweets and a
2.7 percent increase in page views and
one of the other awesome things about
Twitter light is that it's interactive
in under five seconds on 3G
now using a framework like react to
accomplish this on mobile requires a
little bit of additional work so let's
dive in to what they used to look like
so the old version of this site when
they were first rewriting it had a few
issues it was interactive in about 15 or
16 seconds it was heavily dominated by
script they were using suboptimal
loading patterns and so they had to put
in a ton of work in order to get to a
good place and so we return to our quest
and the next place that we get to is
performance guru Samm Ciccone
who has purple bats that are trying to
eat our faces off now pattern
Sam has got a pattern he suggests he
says use purple only load what you need
for the current view
so what's purple well purple is a
pattern for structuring and serving
progressive web apps with an emphasis on
the performance of application delivery
and launch it tries to encourage you to
prioritize loading code that a user is
immediately going to use deferring
loading other code until idle time this
is a pattern the polymer team discovered
last year and which has great promise
now we're initially going to focus on
the push and preload part of this an
idealized version of the purple pattern
would try to avoid you
having multiple round trips to the
server where your first of all fetching
your HTML parsing it and then having to
go and fetch all the other resources
necessary for the page by taking
advantage of HT - server push because
everybody in this room as authors knows
what's important to their pages more
than we the browser vendors do and so
you can take advantage of things like HT
server push to push in one RTT
information the resources that are the
most important to your page and you can
avoid having to over push stuff locally
by taking advantage of service workers
so that on repeat visits you're just
reading from the local cache instead now
Twitter weren't able to use HT server
pushes at least early on in their
journey so they decided to focus on
using resource hints and link rel
preload now in this case the first thing
they looked at was using link rel DNS
prefetch now DNS prefetching with link
rel prefetch is an attempt to resolve
domain names before a user tries to
follow a link twitter we're connecting
up to multiple servers and they found
that by dropping in link rel DNS
prefetch for some of these today at some
of these end points they're able to see
an 18 percent improvement in their
initial load time they then explored
using link rel preload the link rel
preload is amazing it's a declarative
fetch that forces the browser to make a
request for a resource without blocking
the documents onload event now preload
can be couple the load event from script
parse time and in many cases you're able
to get this set up with low friction
even if you're in a wrap that happens to
be using react react view their web pack
plugins that you can use to wire up your
preload for a synchronous chunks that
important scripts in your pages and in
Twitter's case they saw 36 percent
improvement just by switching to using
this now before preload the net request
usually starts like for like far further
down in your network waterfall and after
preload it shifts the left right up to
parse time which is great
next we move on to render so getting
meaningful pixels on the screen now
Twitter is a heavily you know multimedia
based application as you scroll through
your timeline you're going to end up
seeing lots of pictures lots of videos
lots of animated gifs and those have a
cost now one of the things that Twitter
ended up doing was more intelligently
taking control of scheduling inside
their application they used request idle
callback to accomplish this the request
idle callback
is a web platform feature it allows you
to schedule work when there's free time
at the end of a frame or when the user
is inactive and what Twitter light found
was that by using request auto callback
to defer the loading of images using
JavaScript they're able to see a for buy
improvement in render performance now
something that we're all still very much
guilty of doing is shipping images that
just have way too much bloat on the web
and Twitter Lite wasn't an exception
what they found was in many cases
originally they were shipping images
that just had way too much about that
mention they weren't using all the
pixels that are being shipped down and
those images weren't properly compressed
what they found was that by properly
optimizing those images and only
shipping down images with the correct
dimensions they were able to both reduce
bandwidth as well as image decode costs
in some cases taking it down from 400
milliseconds all the way down to 19
another thing they did was introduce a
data saver mode as we're on the go some
of us end up on you know very data
limited plans and so having a data saver
mode that can blur images and videos
until our taps can actually end up
saving us on our data plants this
actually introduced a 70% improvement
for many users twitter also investing in
trying to explore using the saved data
client hint which is a nice other web
platform feature here now I've been
talking about a bunch of web platform
features but there are also react
specific things that Twitter ran into on
slow devices they discovered that it
could take a long time for their main
navigation bar to respond to taps in
some cases anywhere up to two seconds
and one of the reasons for that is that
mounting and mounting large trees of
complex components like timelines of
tweets can be very expensive in react
ideally you want to defer mounting and
unmounting those complex trees and so
what they ended up doing was using a
double requestanimationframe trick that
was discovered by owen campbell more
recently and they created a small
higher-order component on top of that to
improve 4c performance if a component
wasn't reacting this effectively allowed
frames to complete to allow other
components to update and re-render
before mounting expensive wrapper
component this led to almost instant
changes as soon as you were tapping
through their navigation
another thing that they ran into was a
number of cases where unnecessary
updates were hurting their performance
now in react whatever components state
changes it's going to rerender the
component and its children occasionally
the component and its children may not
have really changed all that much and
yet you end up rendering everything in
this case in this video clicking the
heart would result in any conversation
component also needing to rerender using
reacts should component update allows
you to bypass rendering using the
virtual Dom completely and in this case
ended up with fewer updates being
necessary as well as CPU cycles being
saved next we move on to pre cache and
we go back to our quest so who's going
to be the next person we run into well
the next person we run into seems to
have what looks like a Java Script poop
monster but it's Jake Archibald it Jake
says to leverage the serviceworker
he promises it won't bite too much now
Twitter had a very incremental journey
with adding support for serviceworker
the initially serviceworker cache bears
static assets their JavaScript bundles
or CSS the emoji that you use when
you're deeming someone they then
switched up to having a custom offline
page and eventually switch to also using
things like the application shell model
so that you're able to load the UI for
the experience locally instead of having
to keep going back to the network the
result of this is that instead of it
taking over six seconds on a good 3G
network to load the experience on return
visits pre cached it took less than 1.5
this was a 75% improvement for most
users it was definitely worth investing
in in 2017 if you aren't considering
using serviceworker
you're leading potential performance
wins on the table so consider using it
and then we move on to lazy load and in
react pre Acton view we often end up
using webpack to accomplish this so we
go back to our quest now many people's
first experience with web pack can feel
like walking through fire I love web
pack still and here we've got
that guy there maintains webpack and
here on this screen we've got Shawn
Larkin and Priestley who work on webpack
telling us to always bet on it it is
worth using in the long run the number
of bundles savings you can accomplish
using webpack are phenomenal and one of
the things they've been trying to do
recently is investing in a web pack
styoli to help people migrate from web
pack one to two as well as helping
people navigate the web pack complexity
waters a little bit better but back to
Twitter they tried to get things like
code splitting initially set up but it
was tricky they ended up with three
JavaScript assets totaling over a
megabyte in size
that's about 420 kilobytes G zips the
parson compile time of that was still
really high on mobile devices we're
talking somewhere between five and a
half seconds for most people so what
they ended up doing was investing in
code splitting using require done
inshore with web pack 1 and the commons
chunk plugin for extracting common
modules across all their chunks
effectively moving them towards route
based code splitting this meant that
they could get faster time line renders
and they broke up the entire experience
into 40 on-demand JavaScript chunks that
were amortized over the lifetime of the
entire Twitter light experience this
meant that it only took three seconds on
a 3G network and 3G condition you know
under a real phone for this javascript
to actually process and load to learn
more about twitter lights journey we
just published a case study this week
that you can check out and Paul
Armstrong on the Twitter light team is
one of their web performance experts
recently wrote an awesome drill down
into their experiences here so check it
out but they're not the only ones
they've been experimenting with some of
these ideas tinder are also
experimenting with a progressive web app
they're using react they're using react
router and web pack now they've seen
near-instant repeat loads using
serviceworker
they've seen a 50% reduction in time to
load code just by adopting code
splitting and link rel preload and
similar to twitter light we've also been
deferring non-critical work using
request idle callback now the important
thing to note here is as you hear about
all these stories the Twitter lights the
tenders the housing calms the Flipkart's
you'll start to notice these
patterns form of what different teams
are independently running into I think
that helped their overall performance on
mobile I'm excited to see tenders PWA
continue to evolve and they're not the
only ones that are working on PW A's
right now the NVA are also working on PW
a season react and I'm excited to see
their work hopefully get released at
some point in the near future and so we
return to our quest and one person that
we very regularly bother when it comes
to react best practices is Dan Abramoff
Dan created well he worked on crate
reactor a zero configuration tool for
making a lot of things easy and so we've
been working with Facebook for the last
while on something that I think is a
little bit special I'm very excited
about it this is change literally landed
at 6 a.m. in Europe like yesterday
create react off one of the de-facto
ways for building react ops will now
give you a PWA by default thank you I'd
like to thank Deneb Ranma Tomica Chino
and jeff posnick on our team for all
their work in making this possible this
is a huge shift for the ecosystem as we
start to see more and more frameworks in
their tooling adopting progressive web
apps by default we're able to shift that
baseline closer and closer to tools like
you know polymer app toolbox and so what
does create react give you
out-of-the-box now it gives you
progressive web app support with
serviceworker for offline caching it
gives you code splitting with dynamic
import it gives you support for web pack
2 where you can import in ES modules as
well as support for performance budget
tracking so you can stay on top of your
performance it gives you helpful
overlays for on caught errors and has
just 20 built in there as well for
snapshot testing I'm really excited
about this release this is one of the
biggest create reactive releases that
have been out in a while so I hope you
go and check it out a normal you know
global install of create react top we'll
give it to you today comes with a decent
Lighthouse score out of the box and in
terms of the amount of headroom that
this gives you on mobile create react
ops output will give you about 1.5
seconds on that overall
five second budget four times
interactive for your own application
code now the thing to keep in mind there
is that you probably want to make sure
you're using code splittings you're
shipping like a thin core for your
applications initial view your initial
routes and then using lazy loading to
defer that the rest of that loading
across the rest of the experience so I'm
really excited about that next up we
have pre act now most UI frameworks are
large enough to be the majority of lappa
patience javascript size pre acts a
little bit different it's small enough
that your code is usually the largest
part of your application that means less
JavaScript to download parse and execute
and more budget for your own application
code always been seeing is that many
companies that are starting to build
progressive web apps are taking
advantage of reactant production the
first one we're going to talk about is
tree bo tree bill is india's top-rated
budget hotel chain and they operate in a
segment of the industry worth 20 billion
dollars they recently shipped a new
progressive web app that's using pre-act
and what they saw was a 70 percent
improvement in time to first paint
compared to their old experience and a
31 percent improvement in time to
interactive you can check out tree
welkom for their experience but i'd like
to dive into some of the things that
they had to do in order to get this
experience out so they started off with
web pack and using web packs default
setup they ended up with a monolithic
javascript and CSS bundle this had a
first paint of about 4.4 seconds and
first interactive came roughly after
that point now like some companies they
thought you know we're going to try
optimizing our first paint a little bit
and see how far we can get and so they
invested in trying out server-side
rendering now it's important to note
server-side rendering is not free it
optimizes one thing at the cost of
another
however in Treves case using server-side
rendering dropped the first paint times
in their proceed performance the users
still got a full page with javascript
disabled it was still good for SEO but
the con was that it had a negative
impact on time to interactive because
the browser had to first of all wait for
the server-side rendering HTML to get
down the pipeline had to receive that
payload and then it has to go and fetch
and render and execute all the
JavaScript this meant the first
interactive happen about seven point
seven
seconds in which is also not ideal so
the next thing the tree bough looked at
was code splitting this is how they are
basically doing server-side rendering by
the way they're just using reacts
rendered a string nothing particularly
fancy and they're injecting state for
the application initial boot up so route
based code splitting what they did here
was they split out their vendor their
web pack runtime manifests and their
routes into separate chunks this reduced
the time to first interactive down to
4.8 seconds the con was that it started
the current routes JavaScript download
only after their initial bundles were
executing which is also not ideal but it
did not least have some positive impact
on the experience so what can they do
next well we can go back to the purple
pattern we can say well ideally use h2
server push if you can at least
experiment with link rel preload and
that's exactly what they did
now again for route based code splitting
and this experience they're doing with
something a little bit more implicit
they're using react routers declarative
support for get component with a call to
asynchronously load in chunks so with
pre loading they use preload to preload
the current routes JavaScript ahead of
time this had the impact of dropping
their first interactive times since the
Russ JavaScript was already in the cache
when their main bundles executed it
shifted the time down a little bit so
first interactive currently happens at
four point six seconds the only con they
had with link rel preload is that it's
not implemented cross browser however
there's an implementation of link rel
preload in Safari tech preview I'm
hopeful that it's going to land and
stick this year there's also work
underway to try landing it in Firefox
another thing that they looked at with
HTML streaming so trying to get some
sense of progressive rendering into
their application they would stream the
head tag with link rel preload tags set
up too early for load in their CSS and
their JavaScript they then perform some
server-side rendering and send the rest
of the payload down the pro of this was
that resource download started earlier
on dropping their first interactive in
first paint times the con was that
accompanied connection open for a little
bit longer between the client and server
which could have issues if you run into
the longer latency times now the way
that they're doing HTML streaming is
effectively defining an early chunk
again with the head content
have the main content and the late
chunks all of these being injected into
the page and what this looks like is a
little like this effectively the early
chunk has got their preload statements
for all their different script tags the
late chunk has got anything that's going
to include States or actually use the
JavaScript that's being loaded in and
finally like this is an app that
originally was using react they switched
from reacts to pre docks in production
this had the impact of dropping their
vendor bundle sizes from 140 kilobytes
all the way down to 100 kilobytes this
is all G zips by the way the pro was
that it dropped first interactive times
they were interactive in 3.9 seconds on
average mobile hardware which is awesome
the con was that they did have to end up
putting together a few workarounds in
order to get pre-act working exactly
with all the different pieces of the
react ecosystem that they had to use and
that's been one of my experiences as
well react is great for like the 98 98
99 percent use case but there are still
a few educates bugs thankfully Jason
Miller who works on pre Acton is
somewhere in the audience there's Jason
if you run into any bugs bug Jason now
switching from reactive reactant
production is relatively straightforward
you can do this in your web pack config
by a leasing react to pre at Kong Pat
and react on to create comp at as well
tree Bo has been good open source
citizens they've been using a lot of
open source software in return they've
actually open source most of their web
pack configuration as well as a
boilerplate that contains a lot of the
setup they're using in production we've
also committed to trying to keep that up
to date so as they evolve you can take
advantage of them as another reference
housing com another site that are taking
advantage of free ax housing com shipped
housing go a progressive web app last
year did somewhere in the region of 50
million visits and they saw 38 percent
increase in total conversions across
browsers now they've been experimenting
with pre acts for the last two months
and is now sticking in production but
they saw a 15 percent average
improvement to their times Interactive a
medium CPI of about five and a half
seconds and huge savings on the overall
startup time and is not just Indian
companies that are considering using pre
acts forbes.com
I've also recently been investing in
progressive web apps in March they
shipped a new PWA as part of their
default mobile web experience and this
is an experience that was initially
using react it switched over to using
react Lite which is a little bit like
pre-act
and they're currently in the process is
evaluating free app for production
overall this is an experience that gets
interactive in four seconds on a merging
market 3G and for most of us in this
room is probably interactive in three
seconds so again doing really really
well and so we get on to the next part
of our quest and Jason tells us to you
know make our code not our framework the
largest part of our application is this
particular level represented making a
framework that's smaller than pre acts
which is about three or four kilobytes
and as much as it does I don't think I
could pass it I try passing this level
about 15 times and whatever Jason is
doing whatever magic pre-act voodoo I
just couldn't pass them now
I love pre-act I think that it's small
size helps us stay incredibly efficient
but I also really respect the work
that's come out of the polymer team with
the purple pattern and I thought you
know what if we tried combining these
three two things together and so we
started working with a number of people
in the pre AK community on a new project
that I'm really excited to share with
you today today we're announcing pre act
CLI a brand new toolbox for creating
purple first applications using pre acts
we think that this is going to make a
lot of the react community incredibly
efficient at shipping better loading
strategies and I believe that Jason is
probably tweeting out about it right now
so pre axial is available today and in
addition to giving you a 100 on
lighthouse right out of the box it also
includes support for things like
automatic code splitting across routes
it's got built-in tracking for bundle
sizes zero configuration for pre
rendering and server-side hydration it's
got support for CSS modules it's got
support for helpers to help you
transparently code splint any component
and it goes out of its way to make it
easier for you to deploy purple patterns
h2 server push support on firebase
functions so I hope you check it out pre
axial is available today it's just an
NPM install away so NPM install global
pre axial I if you notice any issues
please follow them but I'm really really
excited about this I think this is like
a really great opportunity for start
taking some of the great learnings from
polymers app toolbox and bringing them
to the rest of the ecosystem
so what head room does this gives you
well pre axial I will give you three
seconds in that five second
interactivity budget for your
application code this is huge the
framework itself only takes up two
seconds of it and so you as an author
I've got more application budget to
write code that's going to be useful to
your users if you're not using h2 server
push that budget is about two and a half
seconds but we've tried to make it as
easy as possible for you to deploy h2
serverpush using firebase we've got a
built-in server for it we've got
manifest generation and we're also
excited to take a look at the polymer
team's purple node server implementation
to see what ideas we can share there so
that's pre active Co live the base that
it gives you sits on top of four
kilobytes so there's pre-act and webpack
there's two kilobytes if you're using
the router and a synchronous support and
about another two kilobytes for fetch
and promise polyfills which we can
conditionally load in for you
check out the pre-act hn reax
implementation it also takes advantage
of a lot of the patterns that we've
baked into here next up we've got
another framework that I'm a little bit
excited about view Jas view is designed
from the ground up to be incrementally
adoptable and Evan you the author has
tried to take some of the best ideas the
best inspiration from
multiple frameworks it's heavily
inspired by polymer by angular I react
by other things in the ecosystem it's
got a nineteen kilobyte core it's had
over three million downloads over the
last year and they have a lot of active
users so some of the things coming to
view j/s this year that I'm excited
about are over here things like support
for progressive booting hydration using
requests tidal callback support for
custom elements if you assess variable
theming seamless support for web pack
code splitting I would in fact say the
vue.js has got some of the best
server-side rendering in the industry
they've got support for streaming
support for component caching and in
fact they take that even further UJS if
you're using their server-side rendering
support will attempt to infer what
javascript chunks in your application
are important enough to link rel preload
what isn't important enough to use link
rel prefetch on and whether or not
there's critical CSS that can be inlined
or web fonts that can also be
intelligently loaded in I think that
this this illustrates a step forward we
can take with our tooling where we're
trying to make the best decisions for
you and I love the view Jas is
experimenting with a lot of these ideas
now one of the companies that recently
shipped a brand new progressive web app
using view Jas is ulema the biggest food
ordering and delivery company in China
they recently switched from an angular 1
mobile site this is their old site over
to China's first large domestic
progressive web app with a time to
attractive about 1.2 seconds on their
target devices they're using view Jas
because it boosted their productivity
view support for single file components
which actually look a lot like polymer
imports enable them to easily share
components across pages and adopt things
like you Jazz's ecosystem support for
views or view router very easily now
ulema is interesting because it's not a
traditional single page application this
is a multi-page app they actually have a
number of pages that are their own
dedicated micro-services a number of
pages that are technically single page
apps in their own right and yet they
wanted to ship a progressive web app
that takes advantage of some of the
other ideas that I talked about today
and so they looked at the purple pattern
one of the first things they tried doing
with HT be to server push for they are
API responses they found that this cut
time to first byte by about 500
milliseconds over regular 3G and they
want to bring this back into the mobile
experience now we've been talking about
link rel preload as well and they tried
that out now this is one of the first
examples of where link rel preload
actually didn't make a massive
difference to them see routes in multi
page applications tend to naturally
fetch only the code that that particular
page to that particular route needs and
so they have a relatively flat
dependency graph and so el Emma found
that by using link rel preload they
didn't actually see that many gains for
timing to direct sometimes interactive
if however you are building an SP a I
would consider using it the next thing
they tried to do was just improve their
overall rendering times now for every
single page they effectively have
something that's a lot like the
application shell model they pre render
the application shell for the page they
try to make sure that they're only
loading in script that's necessary for
the current page and keeping their
overall times for any content that can
be painted as low as possible this is
something that's a little bit more
straightforward for them because they're
not worried about you know the
performance of subsequent views quite as
much as individual pages then they got
on to pre cache and their performance
pre cached with serviceworker was
significantly better than their old
experience without it now this got
interesting because the site wasn't
exactly a single page application so
every URL was effectively its own HTML
page they needed to cache the entire
HTML page as well as make their current
and future routes available it's a
little bit like the application shell
pattern but not they had to also end up
pre-caching their scripts their style
sheets anything else that was necessary
in order for entire service or entire
individual app to be useful offline they
still saw some performance wins with
this now in this application again
because it's a multi-page app and
they're relatively you know diligent
about only shipping down the JavaScript
needed for each page what they found was
that their times interactive scores are
relatively decent with vjf it's got a
low startup time and so view itself was
actually their main bottleneck they
found that the View runtime components
other libraries you might drop into the
page with our made major bottleneck
however they put in a lot of extra work
into making this multi-page application
setup still have a good user experience
they invested in skeleton screens for
transitioning from one view to another
from one page to another they also
looked at how they could defer the
execution of views framework itself by
using set timeout on next tick now Ellen
I have tried documenting a lot of the
challenges and workarounds that they ran
into in a new technical case study that
I hope you'll check out but after
adopting the purple pattern they
effectively saw their time to interact
as scores drop all the way down to one
point two seconds now I do have to
caveat this with LLR work in a part of
China where their users have very
powerful phones about eighty-five
percent of their users in fact are using
Wi-Fi or 4G and have at least something
that's equivalent to a nexus 5 or better
and so it would be unfair to say they've
got a really good time interactive
without comparing this on a moto g4 on a
moto g4 which we consider to be roughly
average mobile hardware they're
interactive in under 3.5 seconds under
three with serviceworker enabled this is
still quite impressive
another site that recently shipped
support for view Jas is trueCaller true
crawler is the world's largest phone
number directory with over two billion
searchable phone numbers in there the
recently added support for using view jf
u2 with you CLI webpack to with code
splitting they've been using link rel
preload and they've actually seen some
decent wins their time to interactive
scores have significantly dropped just
by using link rel preload from 2.1
seconds all the way down to 1.6 now in
terms of the view ecosystem they're
using a global event bus but they're
considering using view 'kz they're
experimenting with Knux jf which is
another server-side framework that works
really well with view they try to do
intelligent things around link rel
preload for you as well and they're
using serviceworker caching and so we
get to the final level of our game now I
must not have had a less sleep that day
because this is the one level in this
game that you cannot pass you cannot
hurt Evan you the author of UJS and this
at all i've tried
buteven and sarah Dresner who both view
Jas experts say to use a progressive
framework when you're building
expressive web apps is something that
can enable you to get productive and
stay productive for an extended period
of time we've been talking today about
this idea of trying to move the
ecosystem forward trying to take
advantage of lessons that we've had in
chrome across the rest of the ecosystem
so we've seen you know create react app
that supports you know outputting a PWA
by default pre-act
now supports outputting a PW a defaults
and today we're also happy to announce a
brand new template for view jf that's
available via the view CLI view and nits
PWA
will give you a progressive web app by
default thank you now in addition to
giving you over a 90 on lighthouse right
out of the box it will give you code
splitting with dynamic import it gives
you version hashing for long term
caching a fantastic web pack setup by
the way it's got bundle size analytics
once again for helping you stay on top
of your JavaScript bundle sizes so that
you're trying to make sure that you're
as interactive as possible when you're
doing things and it will also
intelligently link rel preload or
prefetch your bundles depending on
whether you've got a synchronous chunks
in there or there are things that can
wait until later on we're making this
available today you can go and check out
view CLI so in salt view CLI and the
view net PWA will give you a views
progressive web app boilerplate it looks
a little bit like this it will of course
make sure to pass all the tests in my
house so I hope that this is useful and
with respect to the headroom the view j
asses new PWA template will give you on
mobile it gives you about two seconds
not too far away from pre acts but it
gives you about two seconds the
framework takes up three of that budget
got about two seconds to ship the user
down something useful and get
interactive now I don't have a lot of
time left but there was one more
framework that I wanted to give a nod to
angular I think that the angular team
have done a fantastic job trying to
fully chip away at both bundle size as
well as
and time for people trying to use it to
build on mobile we took a new hacker
news application built using angular a
few months ago and worked with Hussein
Durga in the community to try adopting
new features that the angular team were
shipping over the last while so he
started off with a two hundred and forty
five kilobyte bundle that was the
default with angular 2.4 this got
interactive in about 23 seconds so much
worse than many of the apps that we saw
in our research with angular support for
ahead of time compilation this dropped
all the way down to 8 seconds upgrading
to angular 4 with their new view engine
drop this down to 132 kilobytes from the
bundle size and they got interactive in
6.6 seconds and by using code splitting
something I know that the angular team
are trying to make a default for all
their users as well we got our
interactive scores all the way down to
6.3 seconds on real devices I think that
the angular team are making excellent
strides and I'm looking forward to the
day where a lot of these practices are
just a default for all users what we're
trying to accomplish this year is fast
Bank being the default for everybody you
want it to be the default for react
users and pre active users and view
users and angular users and of course
polymer users get it for free with
polymer app toolbox so we're almost at a
time we've announced a few things today
that I hope you'll find useful
hÃ± PWA comm your reference for how to
build progressive web apps with
different frameworks efficiently we
announced create react app with support
for pw AS
pre act CLI and view and it PWA and so
with that promised at the end of our
journey I hope that from this talk you
take the idea that it is possible to
incremental e ship an instant loading
progressive web app using a framework if
you're willing to put the work in the
way that I like to think about
incremental development for pw a's on
mobile is to first do it then do it
right then do it better and many
companies have demonstrated this is
possible so with that I would like to
ask for a big round of applause to all
the members of the community that
contributed to making the
possible today did you take in a few
months from work for their restless
nights I would like to thank the react
team to go down Abramoff I would like to
thank Jason Miller and Chris working on
pre acts I'd like to thank the polymer
team Steve's down Kevin and everybody
else on wet pack and other tools that
have been trying to make it a little bit
easier for us to ship progressive web
apps so with that thank you I hope that
this was useful</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>