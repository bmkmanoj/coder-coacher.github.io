<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dave Herman - Building an Open Source Research Lab - Curry On | Coder Coacher - Coaching Coders</title><meta content="Dave Herman - Building an Open Source Research Lab - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dave Herman - Building an Open Source Research Lab - Curry On</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9OHcJzJQ2Nk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">can people hear me Wow okay perfect so
maybe hey let's get started so we're
very lucky to have Dave Berman here from
Mozilla research who is the director of
strategy for Mozilla research I knew it
was a director of some kind I just
wanted to make sure and he's been
involved in you know a little language
called rust which everybody takes a lot
of inspiration from in this room and a
lot of other little projects like servo
Jess is also one of the projects
underneath the umbrella of Mozilla
research so he's quite is you know this
is organization as their hands in quite
a few interesting and important
open-source projects and also effective
JavaScript so if you use JavaScript you
probably read his book so we're really
lucky to have him here and he's going to
talk to us today a little bit about open
source research lab at Mozilla
all right thank you very much it's hard
to tell if the mic is on you can hear me
yeah okay all right this is really
exciting for me
carry on is has a theme that speaks to
me I really believe that research and
practice have a lot to teach each other
so it's but it's not easy and I think I
think one of the reasons why it's hard
for the two worlds to talk to each other
is they kind of start from different
axioms or they have different incentives
behind what they're trying to do so
generally speaking researchers are
rewarded for novelty that's the thing
that they're trying to do is come up
with new things and if it can have
impact that's great and I think
basically everybody's here because
you're interested in impact but you're
not necessarily rewarded for impact all
the time
and it's basically the opposite when it
comes to to industry and industry like
we just have to survive
so like leather businesses live another
day if that works with an old idea if
that works with a new idea we honestly
don't care as long as we survive but I'm
here because I think that new ideas can
also be one particular way for us to
succeed in industry so the two have can
it can meet at the at the point of
novelty but but they don't always know
how to speak each other's languages also
I think my story's a little bit relevant
because I started out in the academic
world I'm now in the industry world I've
sort of been on both sides of the fence
at least I was a baby academic I got as
far as as my PhD so I may still have
kind of an infantile version in my head
of how research works but at least I got
a glimpse of how that works so really
what I want to talk about today is my
learning process going from the academic
world from in years to a PhD I'm not
going to tell you the value of n to
about six and a half years now that I've
been working full-time at Mozilla and
it's been a fascinating learning process
for me to watch how my own axioms have
shifted over the years where I still
have some of the things that I've
learned from academia
but the things that I'm trying to
accomplish are very different and that's
changed my thought process so when I
came to Mozilla I had no idea what I was
doing I'm not going to try to sell you
some like crystalline gem of a model
that came fully formed from my head all
I knew when I came to Mozilla was that I
had this intuition that research and
Mozilla's culture of open source of open
collaboration might be able to work well
together I might be able to you put that
to good use for Mozilla it might have
strategic value for what Mozilla was
trying to accomplish and a few of us at
Mozilla had some interesting experiments
we wanted to try so little by little we
started building what you might call an
open research lab if this is a term I
haven't really heard it before I just
basically coined the term I'm just gonna
pretend like an open research lab is a
thing but it's my closest way of
describing what it is that we do so I'll
just cut to the punchline is basically
the thesis thesis statement of this talk
an open research lab is a research group
that engages directly with the market
that works via open collaboration and
that uses these to close the feedback
loop between ideas and practice and to
close that feedback loop faster so
that's basically what we do at Mozilla
research and I think it's an interesting
model I don't claim at all that it's the
only model for research I think there
are many important models there are pros
and cons to all of them but I think this
is one that's maybe underappreciated
underexplored
so it's what I want to talk to you a
little bit about today and I think it's
been pretty effective so Heather
mentioned some of these that's very kind
of you I'm pretty proud of what we've
accomplished it was we have the RUS
programming language which is doing
quite well we have the servo browser
engine which is younger than rust but
making good progress
we spearheaded the Azzam j/s subset of
JavaScript and have been playing a
leadership role in the web assembly
initiative we also have an initiative
that's working on patent unencumbered
high-quality video codecs so we're not
all about languages I'm actually not
going to talk about that one today but
I'm happy to talk to people more about
that and in fact Michael Bonita is here
and heavily involved in that project if
anyone wants to say hear more about that
one so I think for a relatively small
research lab with a pretty small budget
we've been able to accomplish some
pretty big things so I'm gonna talk to
you a little bit about how we do what we
do which means it's not going to be a
very technical talk this is really more
about my way of thinking so that that
learning process that I talked about I
think for me a lot of it centers around
how do you actually get software
adoption because what we're trying to do
in engaging with the market in building
open-source ecosystems is actually build
software for adoption we're trying to do
innovative things we're trying to do
research but we're trying to do it by
building real stuff that people really
use so for me coming from an academic
background a lot of this has been about
learning how reality works which I
didn't know as much as I thought I did
about so I think of this as sort of
discovering the laws of nature and the
laws are not always pretty the law the
laws sometimes really contradict what I
would like to be true
and what's what part of what happens in
that mental shift over time is instead
of looking at these as necessary evils
you start to think of these as things
you can actually use to your advantage
so that's sort of a thing you'll see in
several of these laws but I just want to
jump in and start talking about what
what some of these laws that I've
discovered are I'm sure that not
everybody's going to agree with all of
them but I found them to be pretty
universally true in my experience so
let's get started with the first one the
law of progress so this law is about
backwards compatibility and I used to
think of backwards compatibility I
actually started working on JavaScript
as an academic in grad school I was
working on the JavaScript
standardization
anytime you're dropped in the middle of
a real world technology and asked us to
help move it forward the first thing
that you think is how on earth can we
undo some of the mistakes that have
already been made and it took me many
many years to get past this idea of
thinking of backwards compatibility is
this necessary evil then I put up with
day after day after day that you forced
me to accommodate sins of the past and
to think of it instead as a really
powerful tool so the rule here is the
compatibility moves mountains one of the
things I've learned is that breaking
changes are immensely costly and it's
really easy to under count that cost
when you're on the side of the divide
between users and implementers that is
the one who's responsible for the design
the one who's responsible for the
implementation you feel the pain of all
of those warts in many ways more than
your users do because your users just
code around them they just get used to
it but you're the one who's stuck having
to support that legacy mistake forever
and you really wish that you could
change it but if you think instead from
the users perspective if a user has
offered a new feature and they're given
a choice between you can have this new
feature and you can keep all of your
existing apps unchanged or you can have
this new feature and you have to throw
everything that you've already done away
and start from scratch
obviously they're going to choose the
keep all of my apps working as they are
every single time so there's huge power
in convincing users to adopt a new thing
if it doesn't require them to give up
something that already works for them
before now that may mean it it imposes
an extra cost for you as the designer
that may mean imposes it imposes an
extra cost as an implementer but it does
mean that you'll be able to get adoption
a whole lot faster so there was a nice
talk from Peter O'Hearn a a few days ago
or yesterday about the culture of move
fast and break things there's kind of a
a sense in the whole Silicon Valley
culture that everybody's constantly
disrupting everybody else everybody's
always throwing everything away and
moving the old out in to make room for
the new but in fact in my experience
that's not how the web works at all the
web even has a slogan this is a slogan
that is pretty entrenched in the entire
standards community for example and that
slogan is don't break the web
backwards-compatibility is at the heart
of how everything actually keeps moving
forward so there's no question that it
has a cost but backwards compatibility
comes with enormous power so the story
in our experience that Mozilla research
where I really took this to heart was
the story of smj s so to give you a
little bit of background of where Adam
Jay s came out of there was a constant
desire for more performance out of the
web platform more capabilities but in
particularly more performance and more
predictable performance to the point
where people would build plug-ins that
would allow them to port native code or
compile native code in a way that could
run at very high speeds ActiveX was an
older one the one of the places where
you really saw a demand for this was in
the games industry where they really
wanted to push on getting as much
performance out of the web platform as
they could so there were things like the
unity Web Player which was a plugin that
allows you to run unity unity based
games on the web so there was an
initiative coming out of Google called
Google Native Client where they were
trying to create using some very cool
technology a safe sandbox way to run
high-performance
native code embedded in the browser and
they were trying to push this into a
standard and there were a number of
concerns that Mozilla had about this
technology at the time there actually
several different browser vendors who
were concerned about this technology
doesn't really matter the details but by
and large Google was putting a large
amount of resources into building pretty
advanced technology but they weren't
getting the standards buy-in because the
other browser vendors weren't interested
so it wasn't getting a lot of adoption
at the same time we were taking kind of
a different approach at Mozilla research
we started with let's say
the platform as it is and let's see how
far we can push it let's see what we can
do with it so the first step in our
process was let's just take the browser
as it is the language JavaScript as it
is the api's that are there and digits
as they are just not even try to change
any of the JavaScript engines and let's
try compiling native codes native code
to JavaScript and see where it falls
down so this was actually a personal
project at first of my colleague alone
Sakai he built this compiler called him
scripting which compiled C and C++
programs using clang as a front-end into
JavaScript which is of course ludicrous
and it really was just two basic tricks
that he used that worked to a much
higher degree than than he thought
possible and pretty much took everybody
by surprise the first trick was you can
represent the the entire heap you can
record represent the program store with
a binary blob using the web's array
buffer API pretty straightforward that's
simple enough you can alias different
kind of typed views onto that so that
you can do 32-bit integer as you can do
32-bit 64-bit floating-point you get all
the basic types that you need in a C
program ok now you can manipulate the
program store so far so good
the second trick was observing that
JavaScript despite the fact that it
doesn't have integers as a first-class
datatype it does have a few built-in
operators that operate on floating point
numbers as if they were integers so by
doing this bitwise or on a
floating-point number if the number
happens to be and within the integer
range of floating point numbers that's
actually going to be a no op but you get
a guarantee from the results of that
operation which is you know for sure
that the number that you have coming out
the other end is a 32-bit integer again
represent it as a floating-point number
but now you actually have a type
guarantee that you can even tell in a
JIT compiler by inspection you know for
sure when you see or zero that the thing
that comes out the other end is going to
be an integer there's another sort of
peephole observation you
can make which is that if I do if I have
two numbers that both of which I know to
be integers and I do an addition
followed by immediately another or zero
bitwise or of zero I know that the
outcome is not only going to be
guarantee be guaranteed to be an integer
I know that the operation is precisely
integer 32-bit integer addition so by
combining these operators of JavaScript
in a very particular way you can
actually know for sure that what you're
doing
corresponds exactly to the basic machine
operations that C programs are doing and
it so happened that there were enough
there was enough reasoning going on in
jits at the time that this was already
actually pretty fast so just the very
first version of M scripts in happened
to be tickling the fast paths of the
jits so that c++ compiled to JavaScript
was sort of shockingly fast like within
an order of magnitude of the speed of a
native program this would this worked
well enough that it got argit engineers
thinking well how could we actually push
the boundaries of this how could we
actually provide ourselves with a
guarantee that we'll get the performance
that we want so from there Luke Wagner
had the insight that if we could
recognize certain patterns of code as a
sort of strange insidious syntax for
type annotations we could actually treat
this pattern of JavaScript as if it were
a statically typed subset of the
language that's effectively operating as
a virtual machine a low-level virtual
machine so together the three of us
described this subset which we call as
MJS and I provided the type rules now
this was not super advanced programming
language theory this was like first
semester graduate student my first type
system level of of types the only sort
of interesting part here is that the
syntax is just totally bizarre
this is really the hammer that in a type
declaration in this language actually
takes the form of a reassignment to a
variable in the prologue of the body of
the function with a no op so it's
guaranteed to actually have no
interesting outcome in the program but a
no op that comes with a type guarantee
based on the semantics of JavaScript so
by saying P is is assigned P or 0 we're
saying I want to assert that this is
supposed to only be used with 32-bit
integers the next sort of section of
recognized syntax and as MJS is the
local variable declarations in this case
I believe we default to 32-bit integers
so I didn't have to do a type annotation
via another of these no op casts then
you have the function body and then we
have the return type annotation again by
simply looking at the end of the
function body finding the return
statement and looking at the coercion on
the body of the expression you see what
the return type of the function is so
this was our backwards compatible hack
for recognizing a high-performance
subset of JavaScript that could be used
as a compiler target so the the next
step that we that we pulled was to put
an ahead of time validator in the the
JIT of our JavaScript engine so that we
could recognize these patterns and say
if we can actually validate via type
checking that you're in this subset of
the language we can actually go to a
effectively the best possible code gen
path you could get and at that point we
started being able to get our
performance differential from native
code down to first it was about 2x of
native speed we got down to about 1.5 X
of native speed we've been pushing it
down further and further so we're
getting like we're closing the window
between the speed of running a native
executable on a Windows machine and
running JavaScript code compiled via
LLVM from c++ passed through a JIT
within ahead of time validator squirting
out machine code on the other end and
doing this all in
fly in a web-browser and it's almost the
same speed so this was a very impressive
outcome it's also syntactically
disgusting we were we had no misgivings
about this but you know I thought was
hey this is just this is intended for
code generators anyway this isn't
intended for humans - right so who
really cares about how how pretty it is
so this worked great we got fantastic
performance results but we also got
results in in practice we got results in
the industry so one of the first big
coos was that the Unity game engine
announced that they would be shipping a
version of the game engine that worked
via azzam j/s without any without the
need for any plugins and so that's
really the key for them that that one
little bit this they refer to it as a
barrier-free experience that's that's
code for we unity are gonna get better
adoption from this if we don't need to
require our users to install a plug-in
that's one less obstacle our users have
to go through in order to make use of
this so what we'd managed to do at
Mozilla Research was by hook or by crook
we found a way to allow people to
compile their code for the web get
acceptable performance for even the most
demanding games and do it in a way that
got them better adoption and without the
need for Standardization without the
need for plugins and that's the thing
that Native Client wasn't able to
accomplish the next step was the the
epic game engine made a similar
announcement again without the friction
of plugins again friction that's one of
those code words for we're gonna get
more users out of this okay so so this
brings us to the next law this is a law
that probably everybody in this room has
heard before worse is better I'm not
sure if dick is in the room I think I
saw him in the hallway so dick Gabriel
wrote a famous letter to the Lisp
community in 1991 sort of hanging them
for taking the wrong approach
to adoption and I have probably read
this essay dozens of times in my life it
gave me heartburn almost every time I
read it it didn't want it to be true
I think probably most of us here believe
in our hearts that quality matters I
know I do quality is a big part of why I
do what I do and here is this article
telling me that the worst thing is going
to win out over the better thing and how
could I possibly fit that in my head
it's actually a pretty challenging
article I think I I feel like the last
few times I've read it I've been getting
more insight into what he's actually
saying there's a lot of details that I
think aren't actually that critical I
think there's really there's really two
things that are the most important thing
one is he's saying he's not saying you
know worse coat is better than better
coat he's saying that a particular
strategy has better survival
characteristics than aiming for the
right thing in the beginning that's a
descriptive thing that's not it's not
normative that's just he's describing
reality again these are laws of nature
right the second one is it's undone
desirable to go for the right thing
first it's better to get half of the
right thing available so that it spreads
like a virus once people are hooked on
it
take the time to improve it to 90% of
the right thing so this is a far more
optimistic view of that article than
just the idea of you should ship
whatever crop you come up with and you
know maybe if you're first to market
you'll win so when you look at it from
that perspective he's actually saying I
think a much less controversial thing
he's really just saying this
beware of waterfall waterfall is
dangerous and we know this right we all
know that iterative processes work
better than big upfront design I think
this is actually not a particularly
controversial thing in our industry
anymore the way I look about the way I
think about this is the iterative
process is a learning process and I
think all software is about learning and
there's actually a concept that this
maps to directly in in philosophy called
the hermeneutic circle not related to my
name this I think it originally came out
of religion it's it's been used in
interpretation in epistemology the basic
idea of the hermeneutics circle is you
understand the whole in terms of the
parts but you understand the parts
better when you have an understanding of
the whole which means that the
understanding process can actually go
through multiple iterations and you can
get deeper and better understanding each
time you go through that process it's
also sometimes called the hermeneutics
spiral which i think is a nicer way of
showing that it can actually approximate
a fixed point if you just think of it as
a circle you might never know when to
stop but that's what I think
worse is better is really ultimately
about it's about you don't know what the
best thing is you actually you may be
aspiring to come up with the right thing
but you don't even know what it's going
to be so you're better off finding a way
to get something that people really want
get it into their hands and get useful
feedback about what works and what
doesn't work so that you can improve on
your ideas and have a better next turn
around the loop and that's really what
we experience with as MJS so I think
there's no doubt that as MJS was a worse
is better solution compared with Native
Client Native Client had a custom binary
format it was informed by work that came
out of Ella VM you know it was really
sort of there's an intuition everybody
had of if you're going to design a
binary payload for the web gzipping
javascript is clearly not the right
thing and you know creating an actual
binary format is but we found a way of
actually getting something that could
get shipped we actually found out what
was effective what what parts of the
design could be made efficient where the
where the issues were and that allowed
us to then get together with the other
browser vendors and say okay we have
something that works now let's all work
together to build on it so the next step
of the process was the web assembly
project and web assembly has really been
a remarkably successful consensus-driven
standards process so here you see one of
the early web assembly demos this was
running in firefox but it was actually a
coordinated release with Firefox Chrome
and I believe ie as well I think they
all announced on the same day that they
had preliminary working versions so you
can see now web assembly is a github
organization you can actually see nice
pictures of people who work at multiple
our companies and people who don't work
at browser companies at all so it's a
it's a very healthy process and the aim
is roughly by the end of this year to
have a first shipping version in
multiple browsers people aren't making
an absolute commitment to that but
that's the rough timeline and you can
see they've gotten religion about
iteration their first goal is a Minimum
Viable Product the actual thing that
they're aiming for initially is roughly
equivalent functionality to as MJS so as
I'm Jess I think was really a key
stepping stone to getting to a place
where we could design an actual custom
binary format that could have faster
load time that could be better designed
that could allow us to create custom
debugging formats so that you could have
a better debugging experience so this is
allowing us to have a second iteration
that will be much better in a lot of
ways than as MJS but where we have
something working and shipping to the
web all along and at the same time
iteration does not have to mean
unambitious there's plenty more places
that web assembly can go and the people
involved in the web assembly process are
really interested in very big ambitious
goals like better support for dynamic
and high level languages integrating
with the garbage collectors that are
shipping in browser engines possibly
even evolving those garbage collectors
to be concurrent so that you could
really have basically all threaded
garbage collected programming languages
shipping high performance high quality
experiences on the web we even have sort
of more wild-eyed crazy ideas like could
we re architect a a production
JavaScript engine so that it's highest
here highest performing JIT backend is
actually generating web assembly instead
of native code a so that we can reuse
the code generation B so that we reduce
the trusted computing base of the
browser so that the only thing that's
generating native code is a very high
quality web assembly implementation but
C can we do that without loss of
performance so that's going to require
some pretty advanced techniques for
figuring out how to take this safe
assembly language and allow it to be as
fast as an unsafe assembly language so
we might need techniques like typed
assembly language for doing that
so just the the last sort of parting
thought about worse is better is dick
also makes a point of saying at the end
of the the article a wrong lesson is to
take the parable literally and to
conclude that C is the right vehicle for
AI software the 50% solution has to be
basically right and in this case it
isn't but this is an important point
right I mean this idea of can we get
something that actually ships and that
is viral and that allows us to
kick-start the hermeneutic circle it has
to be at least plausible it has to be
good enough that people can actually get
value out of that so so the next law is
really addressing the question of what
happens when it's not good enough yet so
this law sort of bizarrely named the
ugly baby and the hungry beast these are
not my terms this comes from a book by
Ed Catmull he was the founder and
president of Pixar and is also the
president of Walt Disney Animation
Studios he wrote a really nice book
called creativity Inc that talks about
the creative process and how they do
it's not it's not exactly necessarily a
research book but I found it very
relevant to thinking about the process
of research and he has this may be
strained metaphor of the life cycle of
an idea and he talks about how in the
context of a company that has well-oiled
machines which he calls the hungry beast
this beast is has a particular way of
doing things
it's very optimized for efficiency you
have a lot of people who have a very
clear understanding of what their job is
and they know particular ways of doing
things but given a new idea a new idea
that maybe doesn't work the same way as
the way they've always done things
before that idea is often likely either
to get just shredded and destroyed or
distorted into something that is really
unrecognizable to what it was trying to
go there's a sense that these machines
like production teams that a production
company aren't really prepared for a new
idea that may be fragile and it may not
without the protection of the people who
are still trying to figure out what
this idea is it just might not be ready
to feed into the beast so this was our
experience with a language that Heather
mentioned which i think is a very
excellent language the the Russ
programming language but rust went
through a long route to get where it is
today and there's no question that in
the early days rust was pretty
unrecognizable compared to where it is
now it really was the ugly baby
okay so just quickly what's rust about I
would love to talk in more detail about
the you know the technical details of
rust but I just don't have time tonight
so I'm just gonna give you the very
high-level pitch okay from the website
it says rust is a systems programming
language that runs blazingly fast
prevents seg faults and guarantees
thread safety kind of a the level of
intention of why was it why was Mozilla
interested in a technology like this
basically there's been a tension between
speed and control over performance and
safety since time immemorial in
programming languages and it's a
terrible Faustian bargain especially
when you're put in particular
competitive environments where even the
slightest bit of performance loss can
mean death in the market in those kinds
of contexts when faced with a choice
between speed and safety programmers
will choose speed every time so we
wanted a language that would allow us to
build a competitive high performance web
browser Firefox is our flagship product
but one that allowed us to move past the
state of the art of writing you know
roughly on the order of 10 million lines
of C++ code to build one of the world's
most important software platforms so
there are a lot of secret weapons inside
of rust there's a lot of really
interesting research under the hood a
lot of it is known ideas a lot of it is
sort of new takes unknown ideas or
interesting combinations of known ideas
there's some really I think novel ideas
in there as well so there are things
like affine types region based memory
management
ownership transfer of ownership and
temporary borrowing of ownership these
are sort of key concepts that the type
system tracks that allows you to do
manual memory management in a way that
is actually guaranteed to be safe we use
type classes which actually surprised me
at first I was sort of resistant to it
for awhile but it turned out to be a
perfect fit algebraic data types and
pattern matching that was just kind of a
slam dunk from from day one everybody
was clear that we wanted that although
there's some interesting ways in which
that interacts with a language with
explicit memory management that are not
obvious inherited mutability is one of
the more interesting pieces again I wish
I had time to talk about all the
technical details this is really just to
show there's a lot of non-trivial
technology going on in rusts to make it
actually able to accomplish what it does
and really the point of this is super
super hard this took us many years to
get to so we mozilla first sponsored the
creation of a small team to work on
rusts full time in the very beginning of
2010 that was actually right when I
joined Mozilla it was two years before
we even had the first 0.1 tarball
released of the year to the world and
that that version of rust itself was
just utterly different from where we are
today
it was another three years after that
before we finally got to rust 1.0 final
which is the point at which we made
strong backwards compatibility
guarantees so you can see a five-year
process from inception to release a lot
happens in five years a lot happens not
just technically in five year so that
happens culturally in five years if you
build a team that's given time to go off
and do something on their own with great
protection so that the ugly baby
survives that team can get quite
divorced from the rest of your
organization and we all know a famous
cautionary tale of what happened when
you take a team you set them off to do
really cool things and you let them work
completely independently from the rest
of your company Park in the 70s Xerox
PARC in the 70s was famous for
generating way more cool ideas than we
have at mozilla research but just a
million great research ideas and then
not ever getting them
adopted within their own company in fact
a lot of those ideas were in danger of
never getting to the rest of the world
at all there's the famous story about
Steve Jobs coming in for one day and
getting all sorts of ideas that led to
the Macintosh so Bob Metcalfe was
actually one of those researchers at the
time and I think I found this really
fascinating quote from him I think it
had to have been partly based on his
experience working at Xerox PARC he says
real companies can't afford to do
research other than monopolies and then
four years AT&amp;amp;T is a monopoly sat on
innovation IBM after that and Xerox
after that so let's kill those
monopolies and have research done at
research universities he went on to say
we worry about technology transfer how
do you get technology transfer from the
lab into the marketplace this is very
much the theme of carry on and he says
the best way to do that is with people
and it's the business of universities to
graduate people so his thesis was
industry R&amp;amp;D doesn't work we should do
our R&amp;amp;D purely in universities it was
also interesting this was in the context
they were saying you're you we
understand that your politics are a
libertarian and yet you did all of this
this this work with government-funded
research do you see this as a problem
his answer was no it's actually so
valuable that this is one of the things
even as a libertarian and I think is
important for the government to fund so
my experience is far more positive my
experience is a Mozilla is most
definitely not a monopoly we're not even
that big of a company and we have a
pretty small budget and we've managed to
do some innovative work and actually get
it out into the market so rust has a
community package manager called cargo
and it's still fairly young the numbers
are fairly low but you can see about 55
million downloaded packages a little
over 5,000 packages in the ecosystem
today we're only about a year into being
a one dot of the language so pretty good
numbers the numbers are steadily
increasing so we're seeing you know good
community adoption healthy number of
companies that are making use of rust so
Russ is really happening in the world
and the really key differentiator here
is just open source the fact that we
didn't have to wait for company buy-in
to be able to ship something we put
something out there and people got
excited about it in the world and
they're using it and we're also able to
put the head to advantage internally
within our own company a little slogan I
always remind my team of nothing
succeeds like success so even before we
were shipping 1.0 we were still actually
shipping right we were getting people
sort of little by little started with
hobbyists but more and more people
talking about Russ getting excited about
Russ using Russ it was being seen more
and more as a success the more that was
seen as a success more the more Mozilla
could feel like this is our success this
is a good thing for Mozilla and the more
developers were getting excited about it
developers within Mozilla were getting
excited about it so I really see this as
a bottom-up adoption strategy within my
own company that you had a bunch of
developers who were excited about the
technology they were excited as Mozilla
ins to to see this as a success and they
started talking to their bosses and
saying hey how can I start using rust
for my day job so in fact it got to the
point where we didn't even have to go
sell it to anyone else at the company
people just came to us and they said we
want to start shipping rusts what do we
need to do to make this happen so
there's a lot of technical boring stuff
that you have to do to get that happen
you have to work with your release
engineering team and you have to figure
out Linux distros and all sorts of
boring details which we went through
that process so I was very excited to be
able to finally announce to the world
last week I wrote this blog post here
that we are shipping our first rust
implemented component in production in
Firefox with Firefox version 48 so it's
really happening Mozilla's really
adopted rust but we were able to do that
without having to get by in first from
the rest of the company even with a long
prelude to get to that point five years
of incubation okay so on to the next
challenge
I'm talking about doing adoption with a
tiny research team so you know how is
this actually possible how is it
actually possible with a small team of
researchers that we can build a 1.0
programming language product this is
just a massive amount of work and the
answer to that is
it's impossible without a community
there's there's absolutely no way to do
this without an open-source community
and in fact I pushed very hard for a
long time to make sure that rusts while
being sponsored by Mozilla was not owned
by Mozilla and I think that's a very
maybe a subtle difference of the use of
English language but I think it's a
really big difference in terms of people
in the community perceiving their
ability to be first-class members of the
project and in particular we have a core
team leadership structure that is
completely independent of employment at
Mozilla and as a director in the in the
research department I've made sure that
we don't have any decision-making status
nobody at Mozilla unless they are
actually a member of the core team has
any decision-making status on the
project so the next law is really all
about community and that could be the
subject of one or even many more talks
I've learned many things about community
over the years so I don't really have
time to go into a complete community
model but I'll just get at the one most
important law this is the law of why
wasn't I consulted so this is a quote
from a blog post by a guy named Paul
Ford he wrote why wasn't I consulted is
the fundamental question of the web it
is the rule from which all other rules
are derived well he doesn't say all but
I might say all humans have a
fundamental need to be consulted engaged
to exercise their knowledge in this
power and no other medium that came
before has been able to tap into that as
effectively so he wasn't talking about
open source at all he was just talking
about the title of the of the blog post
was the web as a customer service medium
it's a really thought-provoking article
I highly recommend it
but that slogan why wasn't I consulted
rank so true for me it it it really
represents basically the heart of almost
all conflict that I ever see involved in
an open source project so got a hurry on
here sorry
so I'll just briefly mention one other
person that's been very influential on
me this this is somebody who actually
worked at Mozilla
for I did I never met him Frank Hecker
talked about open-source communities as
deliberative democracies and he talked
about how to handle disagreements and
open collaborative projects the the key
insight that he has here is that our
goal should be to make decisions that
stick this is all about decision-making
through communities and he describes
something called the rule of reciprocity
the basic idea is you justify your
decision in terms that others who
disagree with you can potentially accept
this is a little bit of a mouthful but
the basic idea is you're working
together with people who have varied
ideas varied philosophies varied values
and you're trying to conserve the amount
of disagreements you're trying to
decrease the amount of disagreement
possible and find ways for people to be
able to come to consensus even if they
might not all have the exact same idea
about where you should go a sort of key
corollary that Ahrens are on of the of
the RUS team discovered was what he
called the no new rationale rule which
is the core team are leaders they're
responsible for making decisions
ultimately but any time they make a
decision and they announce it based on
rationale that has not yet been publicly
vetted everything goes south everything
falls apart people freak out but if they
announce it based only on rationale that
has already been part of the discussion
has already been debated people are able
to accept it even if they didn't
necessarily agree with it I know that's
not enough there's so much I could say
about community there's all sorts of
other parts of the community model but
I'm running out of time so one last law
this law is invariance our shared values
have a little nod to Matias here so
Matias wrote a paper that was very had
an impact on me called on the expressive
power of programming languages where he
describes the way I think of it as
programming like programming language
design is inherently attention between
expressive power allowing people to
avoid repeated programming patterns
basically syntactic abstraction versus
local reasoning and extra invariance and
there's no one point on the spectrum
that's the right answer for all cases
it's it's a continuous challenge for
every language that you designed to
figure out how much power do we need to
allow people to say what they need to
say but with
going so far that it starts ruining
people's ability to do to reason about
their programs and the the fact is that
no matter what no matter what language
you design there will always be cases
where you need to give people some
expressive power that is going to hurt
some invariance that you wish held of
all programs a key example of this in
rust is unsafe rust we call a safe
programming language and yet we have
this unsafe escape hatch that lets you
violate all of the invariants of the
language I'll also point out that rust
is not at all alone in fact every
programming language ever has the
ability to do this Haskell has unsafe
perform I oh ok ml has object magic comm
dot Sun unsafe in Java everybody has
some sort of an escape hatch to violate
all the invariants of the language so
this is not a mistake this is not us
making a bad decision
this is allowed an ecosystem to build
things that no one single small team
could do on their own so these are just
three examples actually the top one is
my side project these are all language
bridges or in notes cases yeah they're
all language bridges right so neon is a
bridge that allows node programmers to
call into rust Hilux is a bridge that
allows Ruby programmers to contour us
and rustler is a bridge that allows
Erlang programmers to call into rust
these all inherently rely on having
access to the FFI but now we are
depending on the entire ecosystem to
play by some rules in order not to
destroy all of the guarantees that rust
tries to promise to all of its users so
what's the answer and the answer can't
be that we must always protect all
invariants in the programming language
because then we couldn't do this so the
answer there is you have to instill some
shared values in your ecosystem and that
really comes down to messaging that's
part of the role of leaders in an
open-source project and that's been a
huge amount of work that the rust team
has put into learning how to talk about
rust learning how to message the valid
the core values of the language in such
a way that nobody in the in the
community would ever blink an eye at
someone saying hey you made a mistake
that's not safe you need to fix it
they wouldn't say well who cares I can
do whatever I want they would say oops
yes I made a mistake
that violates the invariance of rust so
what the rust team has put a lot of
effort into is figuring out what does
rust represent and this was a really
nice blog post they wrote a few months
ago where they talked about how prior to
1.0 they spent a lot of time figuring
out how to reach clarity on what rust
represents and they really narrowed it
down they talked about all of these
different shared values memory safety
without garbage collection concurrency
without data races abstraction without
overhead stability without stagnation
and they crystallized that down to one
slogan hack without fear that actually
really encapsulates a lot of the core
values okay so I'm pretty much out of
time so I don't think I'm going to spend
too much time on a negative example I
just wanted to point out that I'm not
trying to claim that everything that
we've ever done has worked in fact we
did have one project which was a super
cool project but didn't ever make the
cut
it didn't make it into production this
was a self-hosted implementation of the
flash platform using nothing but web
technology if I had more time I'd point
out that if you look at these different
laws we really didn't exploit many of
them we weren't able to put those to use
and you can see that it sort of failed
to get buy-in within the company and
I'll just point out briefly that we have
another project server which is younger
and I think it's already making good use
of some of these laws and I think
there's more things that we can do so
this is a little screen cap that we made
recently showing that servos making real
progress
you can browse some real websites with
it once you get through the load time my
network stack isn't really fully
implemented yet once you get through the
initial download you can see it's very
snappy it Scrolls very nicely so servos
making great progress and we're able to
go into this with six years of
experience of having learned how to do
you know research that's trying to get
adoption so my last parting thought is
this is a work in progress this is my
mental model as I see it today I don't
claim it'll work for everybody I don't
even know if it will work for anybody
other than us I know that Mozilla is
uniquely positioned to do
source research and of course I'll model
all models are wrong as we know the
question is are they useful and for
Mozilla research I think it's been going
pretty well thank you very much
I'm not sure however we are I have a
question here was it a lot of discussion
before this table released what should
get in that and what should be thrown
away and afterwards when you get a
stable version and you weren't able to
break things that often you would like
to like you did before
before stable version was that some
regrets that you brought something that
okay so if you're not experiencing
tremendous
tremendous pain in releasing a 100
you're probably too late that's sort of
part of the worse is better take away
even after five years there was still a
lot of heartache around what had to get
cut that people really wanted and what
had to go in knowing that it really
wasn't the way we'd want it to be and I
would be really dishonest as a person
who's PhD is in macros if I didn't stand
up here and openly admit that the macro
system being shipped in the state that
it was was one of the regrets
so and everybody knew this everybody
knew that the macro system was not where
we wanted it to be there's you know one
of the things that happens with
backwards compatibility constraints is
you end up with multiple versions of
things so it's quite possible we'll have
two macro systems in the grand scheme of
things no pun intended and we wouldn't
be the first language to have two macro
systems so that you know that's one of
the issues there are some aspects of of
the interaction with unsafe code the new
kimitaka hsihu is one of the leads of
the project has told me that he regrets
you know ultimately it's about can you
squeeze every last drop out of
performance out of code that's mixing
safe and unsafe code so that's not
unrecoverable there there are things you
can do like pull the unsafe code out of
the module into a separate module but
yeah there's there's always regrets and
a lot of those
but all of those discussions were
happening within the community so
everybody was collectively coming
together to decide what's in what's out
and some of those were more painful than
others for sure okay so the question is
it's kind of a little bit story first so
there was this paper in 2013 at OOP slow
about the sociological sort of adoption
programming languages by Leo Maravich
and Arab Caen and in this paper the
basic like the main point was well look
at all these languages the most
important thing in their adoption is
like some kind of big ecosystem
libraries and things existing and then
you can look at languages like Clojure
and Scala and say well probably a huge
part of their adoption is the fact that
it's JVM ecosystem you can just use Java
libraries so maybe this has something to
do with like the rapid adoption these
languages yet rust is kind of
counterintuitive to that because there
was no huge ecosystem can you I mean
it's sort of you know make its opposite
to what the paper says kind of it's
somehow being adopted without this
ecosystem so do you have any intuition
or can you make some explanation about
why this is happening
I certainly can um I'll try to keep it
short first I think I I should say Leo
is a friend I think he does awesome work
he has given us a lot of ideas for servo
but I think his paper is asking the
wrong question I think it's kind of like
saying what is the strategy that makes
businesses work it
it depends right it depends on the
market they're in it depends on what
they're trying to accomplish certainly
having access to an existing ecosystem
is one particular tactic that can be
effective but I think really you know
for for any technology there has to be
some value proposition that's so
compelling that people are willing to do
something new and in the case of rusts I
think we actually probably easily I
think we easily could have failed I
think one of the pivotal moments for us
was in 2013 Patrick Walton wrote a blog
post he's one of the members of the team
he wrote a blog posts
effectively holy cow we actually don't
need a lien on the garbage collector
we had like this intention of having a
garbage collector all along and we had
these signals in the language that meant
this is a garbage collected value but
was actually implemented with a
half-broken reference counter because we
just hadn't gotten around to it but we
always had this belief that you know by
default you'll do garbage collection and
in the you know in the cases where you
can manage it you'll do stack allocation
or you'll do you know linear usage or
affine usage and Patrick started doing
some experiments where he was like wait
I can write entire programs without
using the garbage collected types and
maybe we can actually evolve this in a
direction where you don't need to lean
on the garbage collector at all I think
that was a pivotal moment because I
think that was when people realized this
is a quote unquote
real systems language and for the first
time it was like you can do the same
stuff you can do in C and C++ but with
actual safety and that's a truly novel
thing that's a the other aspect that
I'll mention is two more two more
there's a lot that goes into this so one
of them is Kathy Sierra is somebody I
look up to a lot she talks about
software adoption and marketing and she
if you'll forgive my friend she talks
about um user badassery how can you make
your users badass and I think that there
is a sense that rust combines two
elements of user badassery that like
makes you such a super badass that it's
just really compelling one is that you
get to do these new fangled you know
super advanced type things like Haskell
like we've got that we've got the
badassery of Haskell that comes from
type classes and you know big mouthfuls
like sub structural type systems the
other badassery is that you get to do
systems programming and that's a thing
that's traditionally seen as a you know
as relegated to a very tiny cabal of
super hacker wizards so the fact that
you can do both of those things and that
because it's safe it's not as scary
that's partly why I think hack without
fear is a message that's resonating with
people so so we're bringing a level of
badassery that lets you lets you do new
things at the same time there's a
challenge that people have of like well
what should I do okay
excited to become one of those badasses
but I need to I need an idea for a
project so that's the thing we need I
think to help people on the final piece
I'll mention is package management
I think package management is one of the
things people talked about tools a lot
these past couple of days package
management has become a basic
requirement of programming languages and
I think not all languages are quite
catching up to this fact so not not
recognizing this fact and we had the
incredible good fortune of being able to
work with Carl Ertz who's been here I
don't know if he's here tonight but he's
been here these past couple of days Carl
lurch and you who did Katz who had both
designed the bundler package manager for
Ruby they helped to design the cargo
package manager for Russ which has been
a huge success so when you talk about
ecosystem part of the problem of
starting fresh is your bootstrapping an
ecosystem and package managers are a
really great way to help facilitate that
bootstrapping process and it becomes one
of those the hope is that it becomes one
of those self fulfilling things that the
bigger that sort of nascent ecosystem
gets the bigger it gets again I think
probably the the first time I was made
aware of this idea was the first time I
saw Sipan and it just it just was was
totally clear to me that creating a
single place where people can come
together to share code is going to make
the growth of the ecosystem visible and
give people a sense of the momentum
behind it so those are those are some
sort answers some long answers the short
answer is I think every language is
different I think the strategy for every
language is different and you have to
find what the core value proposition is
and it's not as easy as a single answer
in a in a single paper sorry for the
long answer I think so how did you
manage to keep rest as the ugly baby
like under the radar for five years what
were you feeding the beast in the
meantime good question so you know part
of it was the good fortune of having a
couple of champions at the time my boss
under a scowl had co-founded Mozilla
research with me along with Brendan Eich
who was his boss and was CTO at the time
and Brendan really championed Mozilla
research and rust in particular at the
executive levels so there was a real
sense of a strong executive protector
behind us
in some ways those days are behind us
Andreas and Brendan are both gone from
Mozilla but we have a pretty good
portfolio at this point we're starting
to have some credibility within the
organization so people are starting to
believe that ok maybe these people know
what they're doing maybe we should let
them try their experiments although I
wouldn't say that we have any projects
at the scale or scope of rust or servo
starting on day one right now we have
kind of we're juggling a lot of things
right now so it sort of remains to be
seen for the next really big project
that we decided to take on how long of a
runway will we will we be given it's
it's it's not clear hi
I've been forming rust for a while and
p1 release it was amazing everybody was
super happy you threw a party and
everything I remember I wanted to ask
why you speaking of the future of rust
in embedded systems or maybe in in
mobile development which is my specialty
so we when you're talking to people they
are expecting to have some kind of
multi-platform code that you're able to
load and right now seeing simplest
person or an option because they come
with too much overhead so maybe Rath
could be one of the alternative
absolutely I think that's a development
is I mean it's it's not just
hypothetical there's a lot of people who
are interested in it and working on it I
think I just heard this week actually so
Dropbox is one of our early adopters and
their original use of rust was in server
farms but I think I just heard that
they're starting to look into using it
for for mobile development there's
there's basically a few pieces of
infrastructure that you need and you
just have to build it and that's in
progress so one of the main ones which
is a kind of top priority right now is
having really really smooth
cross-compilation workflows
so if you're if you're gonna do mobile
development it needs to be really
trivial to be able to build it and
deploy it to your test devices and
that's just--that's work in progress but
it's going really well
but it's a more general question of like
which which adoption areas do we think
are going to be the best there's a huge
list and there's a bunch of people
exploring different areas I don't think
it's gonna be the same kind of
straightforward story as something like
node where it's like you're right
servers
that's what notice for it's for servers
but servers are such a huge market that
all you need is that one thing and it'll
be huge I think with rust it's probably
gonna be more like a bunch of different
things and I think that servers will
eventually become a bigger and bigger
market for for rust but I think in the
beginning it's going to be people who
are really trying to squeeze every last
ounce of performance out so you're gonna
see people who are doing you know
massive server farms where they can save
on power consumption they can save on
the number of devices that they need to
use where they're really trying to push
on performance but I think ultimately as
the ecosystem starts to build better
abstractions better frameworks you know
put them on crates IOR
packaged ecosystem it'll start to be
easier and easier to piece together
smaller server apps and then you'll
start seeing people say well hey it's
actually pretty convenient to use rusty
even for a smaller app it doesn't have
to be I don't have to be shipping to a
huge server front today and now I know
that because I've written it in rusts
it'll be able to scale up to the big
server from tomorrow there's all sorts
of other things there like high
frequency trading companies that are
looking at it there's people doing
machine learning there's people looking
at crypto because they're really
interested in the safety guarantees so
there's a lot of different areas that
people are interested in for us I think
it's always a safe bet that if you can
if you can start getting on servers
though you're you're gonna get pretty
solid adoption
so I think I think we should thank Dave
and just say a few things to sort of
wind down the whole event first of all I
have to thank everybody who is here
because I sent out this wonky email that
was like you guys got to ask questions
everybody comes from totally different
backgrounds somebody has no idea what a
type system is they've never heard about
it they've their first language was
something that they they made themselves
they don't know any of this stuff so
somebody if somebody asks help them and
I really saw a lot of that there were a
lot of people who were really just
asking totally honest questions and not
totally unafraid people who seemed very
quiet not that kind of person to ask
questions were asking questions so I
want to thank everybody for making it a
good environment so that that could
happen so please give yourselves a round
of applause for doing them also I want
to say a few words about how this
conference kind of works so it's
actually really largely a volunteer
thing the way that this whole thing
works
it's totally not-for-profit you the
University I don't have to say it
properly Sapienza the the University of
Rome they organized all of this local
stuff they organized an amazing party
that you all went to you know this was
totally just different groups of people
in different places organizing this
thing to make it cool and the money that
that you know came in that that didn't
cover that it was a little bit extra
than the costs that went to covering
students and underrepresented groups
from tech here at the event so it's a
little bit of a weird event and a lot of
people had to just volunteer tons of
time to make it happen so again I want
to thank all the local organizers and
everybody else who put a lot of time and
energy into this thank you to all of
them I don't know if their own the room
but thank you
and finally um there tonight at nine
o'clock I don't know does anybody know
where it's starting from there are some
Rome walks roaming around Rome I'm not
sure where the starting point is right
there you can sign up the I believe it's
the the folks from the local folks are
going to be taking people around showing
them around the city so if you're
interested in a little walking tour when
the weather is cooler outside you can
sign up at the registration desk and I'm
sure there will be instructions about
the meeting point so go have a look at
that if you're interested and I have
some more carry-on stickers and one one
women's t-shirt left so ladies who
didn't get a shirt please come to me but
that's it thanks for coming and I hope
to see you guys in Barcelona next year
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>