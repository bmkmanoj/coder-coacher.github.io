<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Úlfar Erlingsson - Data-driven Software security - Curry On | Coder Coacher - Coaching Coders</title><meta content="Úlfar Erlingsson - Data-driven Software security - Curry On - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Curry-On/">Curry On!</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Úlfar Erlingsson - Data-driven Software security - Curry On</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iOd9EGMB_Cg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">they're live-streaming the sessions okay
we're on the internet okay yeah yeah I
never signed anything to affirm it that
yep they they are do you need me to get
them into knowledge yeah that's a good
point I'm actually
yeah I mean maybe because it's in here
yeah yeah I know I didn't it didn't even
occur like I I know that I mean I've had
to sign it it's honest I'm so it's okay
you don't need me to okay I'm gonna go
bring it up so
okay so I'm over Arlington I run a
security research group at Google before
that I was at Microsoft Research for a
while I've done a bunch of start-up work
and done a lot of language based
security since the mid-90s onwards so
this talk was is has a very buzzword
compliant title lots of buzzwords in
there but actually they they are
relevant and make sense of context that
said there's a lot of content in the
work there is a paper for I Tripoli CSF
that's about six pages that sort of
contains the details you can find it on
archive if you look for a data-driven
software security so if you are missing
something as you're following along then
just look for that now I don't know how
many people here actually work on
computer security but you all write
software and as such you all interface
with computer security in one way or the
other
people quickly realized that the
security of software artifacts and
computing was a critical element and as
soon as there was multi-user computing
in in the 70s and in the early 80s most
of what we think of as the core
abstractions and concepts of computer
security as practice today were already
developed maybe some of the few things
that that weren't there already were
things like firewalls but the key
concepts were there software protection
and access control papers from the 60s
and early 70s by Lampson and Saltzer and
Schroder from the late 70s or sort of
the seminal papers of outlining what is
computer security and how does it relate
to things that we craft now
unfortunately those papers were
describing concepts that needed to be
applied in practice to
secure computing systems but somehow we
don't have secure computing systems in
fact you could argue that we have less
secure systems now than we ever had
before and by most metrics that you
would think of sort of end-to-end
metrics like how likely is a user of a
computing system to be affected by a
software security problem in a given
year we definitely are at one of the
worst points that we ever have been
probably at the worst point certainly we
are worse off than we were in the 70s
and 80s when these principles were being
defined so what's up with that
now one of the people who sort of
defined the field Butler Lampson gave a
series of talks about 15 years ago and
wrote a couple of papers trying to
figure out well what is this thing
computer security and and what happens
when it meets the real world and one of
the conclusions from those
contemplations and retrospectives in
those papers is that computer security
might be imagined to be easier than real
world security because after all
computers are very good at doing exactly
what we tell them so we just have to
tell them exactly what to do and define
that well and they won't allow any bad
things to happen but in reality this
precision by which computers work
actually works against us and computer
security turns out to be harder than
real world security and that's because
real world security has a lot of
built-in attributes that simplify the
problem such as the fact that somebody
who wants to break a window although a
window is a very weak defense against
burglary has to be there right at the
window in most cases so there is this
built-in assumption or Bayesian prior
that you can only be attacked by people
who are physically present whereas in
software security we really are dealing
with the correctness of software and any
one problem can be attacked and utilize
in an exploit as often as the attacker
desires the computer will do exactly the
wrong thing in exactly the same way
every single time and the attacker can
be present anywhere in the world so this
is a problem but one of the really nice
things in this line of work by Butler
from 15 years ago this is the same line
of work where he defines what's called
the gold standard of a user
authentication audit and authorization
is that he describes how software
security is actually not a different
problem from what we usually think about
when we think about software it's just a
form of correctness and as O'Hearn was
talking about this morning programmers
are not very keen on giving functional
specifications for the programs that
they write it takes a lot of time it's
difficult it's hard to maintain etc but
at least programmers might know what a
functional specification should look
like now in security the specification
is called a security policy and it
defines what should be allowed to happen
the problem is that nobody knows what
the security policy looks like it
depends on how you're supposed to be
using this code who are the users what
is the purpose in using the code etc so
the programmer is not the right person
to be writing that in most cases now
just as we have for functional
correctness we have a specification and
then we have an implementation that
hopefully implements correctly that spec
and correctness is something where we
can check and strive for we can use
different methodologies to try to
simplify establishing that correctness
in particular we can use functional
programming which is one particular
methodology or we could use logic
programming or various other programming
methodologies that actually help
establishing correctness but you know we
could also just establish correctness of
machine code it's just going to be
harder
in security it's the same thing the
implementation is called an enforcement
mechanism it takes this security policy
that nobody knows how to write and make
sure that that actually is enforced
correctly at runtime or even beforehand
you can have two static analysis and so
on and if we know for absolutely sure
that there is nothing bad that can
happen that will violate the security
policy we have assurance and all of this
happens just as we have these different
methodologies all of these happens in a
security model a way of thinking about
how we write down these security
policies and there are lots of different
security models just like there are lots
of different programming methodologies
and this correspondence between
methodology and security model is
something that I added to what Butler
defined in his papers but no matter how
you intend to define the security policy
no matter what model you like it's
basically really hard to get one so it's
much harder to get a security policy
than it is to get a functional spec and
a functional stack is already very hard
to get we never get those so they most
successful and again security is a very
dismal field so things really have been
getting progressively works but the most
successful aspects of security is when
we get the policy for free somehow and
one of the best ways of getting the
policy for free is to get it from the
programmer without having to get the
programmer to write it down so Mark
Miller just sat down so he likes a
methodology where programmers write in a
certain structured style using
capabilities and automatically as they
write the program that way we should get
some properties of the program when that
it runs when it runs that actually will
help with security most other developers
like type systems so so we like to write
things in a type safe language and we
get guarantees that way but even in an
untyped language we can actually
that guarantees if we analyze the
program such as you can analyze
JavaScript and actually figure out that
certain things are true or not true
based on static analysis in C one aspect
that has actually been very successful
is to take some of the implicit things
that the programmer is excluding such as
the code should not be messing about
with the return value that is stored on
the stack this is an implicit assumption
that the programmer makes when when
writing the program and why don't we
just enforce that at runtime so that's
called stack guard it's been baked into
compilers at for at least at least 15
years it's ubiquitous there are various
other similar checks that actually are
making undefined behavior in the C
language be defined as a violation and
halt and so simply if you take all of
the things that are undefined like say
jumping into the middle of a function
body or an expression evaluation and
disallow those you actually improve
security without having to get the
programmer to write a new spec for these
low-level languages and this has been
very successful you can think of that as
what we sort of have as a programmer
intent security model so let's just
figure out what the programmer intended
to happen as much as we can and have
only that happen at runtime and that's a
form of software security now in this
talk I'm going to propose a data-driven
software security model and since I work
for Google I like to use big data and
imagine how we could actually figure out
using big data to get the world into a
better place so why might we do data
driven approach to software security
well remember that what we think of as
computer security was really defined in
the 60s to the late 60s to the early 80s
but the software we use today has
absolutely nothing to do with the
software that existed at that time so if
you have seen these orange juice makers
that are popular in
Europe and and you sometimes see them in
the US as well where you have this
machine that takes oranges at the top
and it rotates and it has the oranges
and it makes juice and juice comes out
the bottom that's kind of what we think
of as software we have a seat of Algol
60 or a sheet of algorithm and that's
our program and we statically analyze or
we reason about that program that
software as traditionally imagined
certainly as imagine for these security
concepts in the 60s to 80s but in fact
what we have today is a lab stack that
implements an orange juice maker with an
HTTP request and you get orange coming
out so you can think of that as sort of
a pentagon size building with libraries
and other things somewhere inside of it
doing all kinds of things for who knows
what purposes but you know that there is
a receptacle for oranges on one side and
and there's a spigot that gives juice on
the other what happens inside we we
don't really know now we can think of
them as as software is really a found
artifact so it's a spaceship that came
and it seems to serve the purpose of
making orange juice and we just have to
deal with it now this seems a found
artifact you could use a data-driven
approach to trying to reason about what
is it and what should it be allowed to
do and and what does it do and it sort
of nicely fits in with a bunch of other
things where we have big hard problems
and we use data like on spam fighting
and so on now in particular I said that
one of the things that wasn't sort of
thought about in the in the 70s was
firewalls so firewalls are actually an
essential part of modern computing and
they're kind of hidden we forget that
there are a huge success story but
imagine if we turned off all the
firewalls on our machines and just let
network packets flow well we would
immediately have worms and viruses and
basically the world would grind to a
halt and that's because the software is
so bad so it's kind of like that
pentagon size building all of a sudden
opening all of its windows and then
anything come in well bad things would
happen and by having those windows be
closed and only having that one
receptacle we managed to greatly reduce
what possibly could be happening inside
that building although we don't really
know how much we have achieved we've
achieved something so a data-driven
approach might use historical evidence
what has happened in the past as a way
of trying to figure out what should
happen in the future and trying to limit
the attack surface trying to see that
well it people tend to use this
receptacle here for the oranges and they
tend to use this bigoted here to get use
out collecting all of this historical
evidence is one reason why previous
attempts at something like this really
fallen into the case of intrusion
detection where you have some test
software that you look at and you try to
figure out well what could happen but
the reasoning is limited by dynamic
analysis of some tests we could actually
change that so right now because of
software security updates etc really
every single piece of an interesting
important software is connected in a way
where we could get high-level
information about every single execution
that has ever happened and we could
simply collect that from every single
software user so the proposal is then a
data-driven software security model that
uses historical evidence to guide
enforcement so we get the policy for
free because we just look at what has
happened in the past and we somehow take
some abstraction of what I said in the
past and say that's what's supposed to
happen in the future and we've solved
the hardest problem in secure software
security which is figuring out what the
policy is and in the Associated paper I
defined this abstraction of an empirical
program that captures at some level of
abstraction all of the security
irrelevant event ever seen in every
single execution including executions
during tests including executions to
trial deployments etc now in the model
of security this is very simple you you
have this is the canonical
authentication and authorization model
of Lampson
it has sort of an outlet for audit
records now you simply say that well
that's not just an outlet that's also an
inlet we have to look at what has
happened to figure out what should be
happening and there is an alternative
model of software security a security
model that that's based on information
flow and it's exactly the same thing we
look at how has information flowed in
the past to figure out how should
information be allowed to flow in the
future
now what would actually benefit here
well the Microsoft Windows solitaire
game could always be used as a complete
Network command and control server that
captured everything that you were doing
and controlled your computer in
arbitrary ways it has all of the
networking functionality built in it has
all of the necessary libraries to
control and command different processes
inject code etc etc in fact it has
unbounded behavior but it has never used
for any reasonable purpose the
networking libraries so if you had
information on the what I'm sure are
hundreds of billions of executions of
the solitaire game you would realize
that networking is not something that it
really does and this historical evidence
would allow you to prevent that process
from being used as a host for a remote
intrusion tool similarly with the
heartbleed vulnerability in open SSL if
your abstraction of what the program has
done in the past simply captures what
functions or messages are invoked and
what is the magnitude of their arguments
so one of the messages it was a
keepalive ping you would know that open
SSL actually doesn't do a lot of keep
allies because that code was relatively
recent it wasn't frequently used on the
Internet
but some of them existed what didn't
exist was any keeper lies with a large
buffer this simply or a huge buffer
let's say that so you would actually be
able to at least eliminate the magnitude
of the acceleration angle here now
possibly you can actually say that this
is so infrequent that in critical
deployments like at Google we're simply
not going to allow
that feature nobody hardly uses it this
is a common thing that Google does it
takes pecs and simply decides to
implement a sub spec to eliminate dusty
corners because in the dusty corners the
dragons lurk so similarly in the
beginning of this year there was a key
cuddle system called that's in Linux the
key cuddle system call had a description
of a keychain it's actually a security
measure in the Linux kernel added in 2.6
for keeping secrets in the kernel that
processes can use but you don't have to
get the secrets out well similarly to
heart leet there's a problem in one of
the control structures this allowed
arbitrary takeover of the Linux kernel
ring 0 code running interestingly this
system call is never invoked by any
software except for the key cuddle
utility now there it potentially used by
software so in that Pentagon building
there is a key cuddle system call in
some gilepsy library it's just that
nobody ever calls it in any reasonable
software so we have not made use of that
historical evidence in most cases I'll
give you one example that counters that
at the end but we should because that's
a very dangerous system cause in fact
all system calls are dangers especially
the uncommon Lee used with complex
arguments like this one now how would we
actually do apply data-driven software
security while we define what the
program is the program could be a Linux
binary or source code or something like
that
what's our security relevant event is it
an RPC message with some abstraction of
the arguments or is it simply a system
call some simple set is what we've been
using at Google and what I'm proposing
here not a trace abstraction or an
Engram or some something more complex
like that by keeping it two simple sets
of observed behavior it's very easy to
collect and merge sets of behavior from
all instances of the software
and interpret and enforce that enforcing
for instance how system calls should be
executed is relatively simple especially
in the latest versions of the Linux
kernel which include better mechanisms
for that some of which were actually
developed and deployed to support this
type of enforcement now one easy thing
to do is just simply focus on what is
dynamically dead so remember that
pentagon size building now clearly to
make orange juice most of that building
is not going to be used all of that
building is a potential security risk
and in fact that building includes code
and behavior that allow bad guys to do
arbitrary things so if you think about
HelloWorld in Java
take the HelloWorld program in Java
execute it with the Sun or now Oracle
Java Runtime and try to reason
statically about what might this
HelloWorld program do if you include the
command-line arguments to the Java
Runtime tool you immediately have to say
well this program could do arbitrary
things because I don't know the
environment and therefore I don't know
the class loaders I don't know the
static initializers of the classes in
fact this code has can do arbitrary
things most programs when subjected to
an analysis without knowing the precise
execution environment you find out that
yes like a lamp stack they can do pretty
much arbitrary things and behave
arbitrarily at their interface which
might be a system called interface or a
network interface that's not a good
situation to be and and historical
evidence would allow us to greatly lock
that down in particular we would be able
to figure out what never happens which
is most things most things are not going
to happen now importantly you have to
capture all executions it's not enough
to just look at the things that have
happened commonly enough to be saying
seen during some training examples and
you have to capture all of the different
users and contexts because those vary
widely if you try to deploy anything in
real world you'll see that users are
very innovative and do weird things and
you have a long tail of behaviors now if
you capture all of the behaviors you are
left with the
question that if something has not
happened in millions or billions of
executions and is now happening for the
very first time even if that's a feature
that's in the your program it's a
command-line argument it's a it's a
module that is there and written by the
developer if nobody tested it it nobody
ever used it before is that a feature is
that a book is the use of this code for
the very first time on some users
machine a book or something that you
want to allow and it's easy to argue
that well it's easier to treat it as a
bug file a bug report and say you have
to actually have to test this and ship
it in the next version that's something
you want to support now that gets into
versioning and how you might actually
deploy this in practice fortunately most
software is rolled out mo software is
used at scale and affects a lot of users
is rolled out in this sort of crossing
the chasm curve where you have
test-driven development or some
reasonable process early on you have
trial deployments say with chrome you
have a dev release and a beta release
and then only eventually you have a
gradual rollout of a stable release all
of which will give you plenty of it time
and data to build a reasonable profile
of historical evidence to do enforcement
when the code is affecting a lot of
people and you have to do that with
every single release and and sort of
look at differences between releases now
that's the approach what are the
challenges there's actually a bunch of
challenges to doing this first of all
let's look at how might we actually
monitor things efficiently enough we're
gonna add monitoring code to every
single execution of every single program
we better be doing that efficiently if
nothing else we're gonna be treating
drinking the battery of people's mobile
devices because everything is mobile now
so we've actually done work on this with
a bunch of collaborators at Google and
we focused on the simple aspect of
system call tracing and so we put as I
said some things into the Linux kernel
as like alt syscall is the latest one
that actually allow for
very efficient monitoring of what system
calls are made in particular allows for
especially efficient monitoring of what
system calls are not made because you
only have to deal with the first time
that something has happened there's a
one time cost there and so on
interestingly so this data is sort of an
abstraction of a big binary and when I
say a big binary I mean a binary that
was so big we had to modify the linker
standard linker in Linux because the
debug build that the binary is more than
two gigabytes so so it's a very big
binary the binary in the limit only uses
about 80 system calls now it's an
internal binary at Google what's even
more interesting is that eventually this
binary pretty much does handful of
system calls there's a bunch of stuff
that happens during sort of Lipsy type
startup and then there is the sort of
app startup that has most of the fancy
system called work but then eventually
this is a relatively simple behavior
profile and similarly with similarly
with the behavior on the network
interfaces so if you choose the wrong
abstraction however and you choose the
wrong mechanisms like let's say you
wanted to estimate detailed frequencies
and and build up frequencies of
different system calls you'd find that
this is much harder and this is just
sort of an example of how much variance
you could get with sort of doing
monitoring at the wrong level and and
trying to count things so here you see
noise adding up as things become less
frequent so I'll get to you later three
time questions at the end so now I
promise that the buzzwords in the title
were not just there for show
so we actually implemented a bunch of
mechanisms to try to make these this
approach realizable in practice one of
the things is how can we learn from
every user's machine without violating
that users privacy and so my favorite
example here is that at a certain point
about ten years ago a certain font
function in the ffmpeg player relating
to devack codec daebak's codecs
was basically one-to-one associated with
playing stolen movies copyrighted movies
and actually could get you easily into a
lawsuit with some very legit Isleta
Jewess parties now collecting detailed
information on who is using that
function would have been bad certainly
you wouldn't want the database of that
so we develop ways of collecting data
about what's happening on client
machines with privacy this has recently
been taken up by Apple and announced so
we'll give you some details from what I
can tell what they're doing is
indistinguishable from what I'll
describe to you so so you have a picture
here and we'd like to learn this picture
with privacy if we look closely at
what's happening on individual machines
we'd see detailed information turns out
that we can add a lot of noise to that
detailed information and zoom out and
still see the big picture so and that
noise can be added in such a way that it
gives the strongest form of privacy that
people know how to achieve which is this
differential privacy stuff we use that
in Chrome for the last couple of years
here's for instance a chart that shows
who on the web is still using
Silverlight is a question that we wanted
to know at a certain point where because
we wanted to try to get rid of
Silverlight usage and so repor actually
does things on the client site that
means that we can give rigorous rigorous
and meaningful privacy guarantees for
each user because they add noise to
their own data before sending it and
they can reason about what their privacy
leakage is without thinking about the
rest of the world or without trusting
anybody there is no central database of
actual user data that could be attacked
or subpoenaed and there are no
externalities from like sending unique
identifiers or something like that so it
works quite well for URLs and other
types of things like that
this is statistics on home pages because
people can set home pages as whatever
string they want like their own personal
server that's also privacy concerns so
here we can collect we can basically see
the forest without possibility of seeing
any one of the trees
it works as follows just very quickly
because we're in Italy I ask you have
you ever been a member of the National
fascist party which was Mussolini's
party and you might be embarrassed to
say yes at certain points in history and
so instead of answering truthfully we
agree ahead of time that you will flip a
coin and if the coin comes up heads you
will say yes the embarrassing answer if
the coin comes up tails you will say
tell the truth now I know that half of
you will say yes because of the coin so
I can just subtract out half of you as
the SS and I can then see the ratio of
the remaining answers and that will be a
very very good estimate of how many
people actually used to be members of
the National Socialist nationalist
fascist party so now with the rise of
sort of nationalistic parties again in
Europe the no answer might be sensitive
as well so it might not might be
embarrassing to say no I've never been a
member of the National fascist party and
so that's easy to do that side of it is
just instead of deciding ahead of time
that you will say yes if the coin comes
up heads we will say okay we'll flip
another coin if the coin comes up heads
and you will just say yes or no bit
based on that other coin turns out that
this way of answering has differential
privacy which as a service is the best
we can do now
effectively what this means is that
instead of strings reported we actually
have a signal here are four signal bits
but this signal is actually masked with
a tremendous amount of noise so what
gets sent this is the bits at the bottom
and notice that some of the signal bits
actually get canceled out this is
actually an open source project has been
up for a couple of years and anybody can
use this now finally and and I know that
I'm kind of out of time deep learning or
the fancy machine learning that people
are doing is it a hot topic and security
and in many other fields I'm not a big
believer and it's used for many
traditional security purposes like
antivirus and so on however what it is
good at is trying to figure out what do
people really think so
sort of approximating what a person
would do is something that deep learning
is actually good at and so if we look at
how people relate to software even
software that's complex as a Pentagon
size building we might actually figure
out that people expect that building to
be creating orange juice for them and
that's in fact how they want that
building to behave as an orange juice
maker so we can then take software that
does one purpose like orange juice
making and group that software and try
to figure out what are the differences
between all of the orange juice makers
and which ones are kind of like black
sheep they're doing things weirdly and
and more aggressively than the others
and we have done this is actually
deployed in the Play Store at Google as
a way of ranking what software does and
you can see that users expect for
instance gaming and messaging apps to
use the Internet but they're not so sure
that messaging apps should be making
phone calls but absolutely not gaming
apps should not be making phone calls
and so therefore a gaming app so we can
sort of actually use a deep learning
model to learn this and and then use the
user's assumption that the game is not
going to be making phone calls to figure
out who are the black sheeps amongst
games and so actually what we do is we
take metadata like the text and so on
for the apps we do a deep learning
analysis on that cluster it and the
clustering actually has this very nice
property and deep learning where the
positions of different points this is
called a deep learning embedding in
particular we use something called virtu
where were to vac and the relationships
here between different software and so
on are such that not only are all of the
messaging apps together but if you take
a messaging app and you go in the
direction of a game you will actually
get a game if I'd messaging app so
that's where you will find things now
data-driven software security really
means that we're trying to limit what
can happen to
attack surface reduction similar to
firewalls trying to make lab stacks only
make orange juice so it's certainly
worth considering I said I would promise
that I promised that I would tell you
something that actually has used this in
practice it turns out the machine i'm
using here Chrome OS was developed using
a technique similar to this and a lot of
the approaches I've been talking about
were used to define a sandbox for
everything that happens on this machine
as partly as a response as a result of
that actually directly as a result of
that the key cuddle attack at the
beginning of the year had no impact on
the Chromebooks so with that I can take
questions Sarita
so you had that picture where you had
the vertical bars and I'm trying to
understand you had these very hard
boundaries with to which you attach an
interpretation saying this was the
initialization this was the app startup
and I guess I'm trying to understand
first of all how do you know when to
draw I was first of all presumed where
the bars are completely a matter of
interpretation that you superimposed but
this kind of a learning that's happening
that's learning something like the bar
right and so what is what does it mean
to learn that bar and is it over
physical time or virtual time how do you
account for machine differences
synchronicity things like that so that's
a that's a complex question there's a
lot of interpretation here as elsewhere
I would advocate that one start with
something very very simple
in this particular case software at
Google has a very well-defined library
initialization time and software
initialization timer application in this
realization time and there's a barrier
after the application as initialize
before it starts production used and
this is a universal thing certainly true
for this particular binary it is
interesting that you can have different
abstractions like our events in the same
thread treated differently than events
in different threads or do you actually
so so you can define the abstraction in
many different ways
again there I would start by something
very simple let's look at the and that's
where having a set is very simple we can
just take the set of things that happen
in all threads and merge them together
and that's the set of things that happen
in this program so on but clearly you
could try to be more fine-grained so
follow-up question then some years ago
we worked on something called
participatory networking which is where
applications talk to the network and
talk told them a little more about what
the app is doing so they can get much
better performs from network so I'm
seeing a connection you and I'm
wondering whether it makes sense to have
a participatory operating system as well
where the application actually sends
high-level signals down to the operating
system or some lower level monitoring
layer saying this is a semantic
disposition in my program and that would
give much richer information to
monitoring system absolutely yes and so
we can in fact take two very important
and popular points in that particular
space one of them is the permission
model which is now somewhat ubiquitous
on Android and so on
the other one is the zygote model which
is used in Chrome where you actually
start off with a fully fledged process
and have that process lower its
privileges permanently and say that I am
now done initializing I only want to do
those handful of lines afterwards and
this is something the application
chooses to do and so but yes absolutely
true it's about enforcement when you
detect some anomaly how did you if you
stop the application sometimes that is
too dramatic so the deployment scenario
matters here what the deployment
scenario that I have been working with
mostly is the diplomacy area at Google
where you have let's say a million users
or a billion users why you know add
three zeros fine so the each one of
those users may be happier if you decide
to shut down what is happening on their
machine if there is a significant risk
that it is security violation and then
the user has to retry so think about it
as somebody is operating in the
telephone center and they pull a wire
and you have to redial
redialing will give you the service you
want maybe permanently you cannot go to
this one webpage because it always
crashes but the rest of the web seems to
work now again if you have done your
models correctly this may be preferable
than having being completely open which
is the standard at the moment in the
backend data center we have something
very similar where we have maybe
hundreds of thousands of processes that
are effectively doing the same thing and
the software is written in such a way
that any one of them can go away in any
point because they're not
mission-critical there
actually designed to run in a failure
environment and so we can actually hold
them there is a point however that I
didn't make very clearly in the talkers
of time you have to actually know and do
statistical estimates of how likely is
it that you have converged in your
policies and it turns out that you can
do that you can actually look at how
much data have I learned so far in my
tests and my dev and beta deployments
and estimate the likelihood that
something will happen in the field and
when that likelihood has gone down low
enough you can actually enforce with
high confidence that not very many users
will be affected in some cases it's not
going to converge for instance if you
try to learn policies about what URLs
people type into the URL bar it simply
won't convert in other cases like system
calls the set of system calls it will
converge and you will get to that point
learning the models do always we'll have
some data false positives yes we have as
I said so you basically converge until
there is no false positive and you can
treat every single false positive as a
bug and so you can in fact automatically
file a bug report for the false positive
and and so on there is some possibility
that there's a y2k like scenario where
the software will on every single
instance behave in a different way
that has not been tested but it's still
critical to work in some way so in those
cases what we've decided is that after a
certain amount of failures we may
actually keep a counter and simply fail
open so if a hundred thousand users have
had a problem that is blocking them
deterministically every single time they
try to run their web browser you may
decide to let that happen but that
should give enough time for the security
team or whatever team is handling those
types of things to do at least a
preliminary assessment but in our
experience like for things like system
called those types of things don't
happen
it's just that you know there's a theory
that they might happen there's also
there's a interesting connection here
between pl theory and practice
like maybe static analysis could help
assess how likely is things like that
are to happen okay let's thank the
speaker</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>